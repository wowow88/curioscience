name: Daily Articles Update

on:
  workflow_dispatch:
  schedule:
    # Ejecuta cada día a las 05:15 UTC (~07:15 Europa/Madrid en verano)
    - cron: '15 5 * * *'

permissions:
  contents: write

concurrency:
  group: daily-articles-update
  cancel-in-progress: true

env:
  TZ: Europe/Madrid
  PY_JSON: workspace/astro/public/articles_py.json
  JS_JSON: workspace/astro/public/articles_js.json
  FINAL_JSON: workspace/astro/public/articles.json

jobs:
  update:
    runs-on: ubuntu-latest
    env:
      DEEPL_API_KEY: ${{ secrets.DEEPL_API_KEY }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
    steps:
      - name: "Checkout"
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: "Setup Python"
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: "Instalar dependencias Python (si existen)"
        run: |
          set -euo pipefail
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install requests feedparser beautifulsoup4 python-dateutil
          fi

      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: "Instalar dependencias Node (root y Astro, si aplican)"
        run: |
          set -euo pipefail
          if [ -f package.json ]; then
            if [ -f package-lock.json ]; then npm ci; else npm install --no-audit --no-fund; fi
          fi
          if [ -f workspace/astro/package.json ]; then
            pushd workspace/astro
            if [ -f package-lock.json ]; then npm ci; else npm install --no-audit --no-fund; fi
            popd
          fi

      - name: "Ejecutar data_pipeline.py (genera articles_py.json)"
        run: |
          set -euo pipefail
          python -V
          if [ -f data_pipeline.py ]; then
            python data_pipeline.py
          elif [ -f workspace/data_pipeline.py ]; then
            python workspace/data_pipeline.py
          else
            echo "No se encontró data_pipeline.py" && exit 1
          fi

      - name: "Ejecutar fetch-articles.js (genera articles_js.json)"
        run: |
          set -euo pipefail
          node -v
          if [ -f fetch-articles.js ]; then
            node fetch-articles.js
          elif [ -f workspace/fetch-articles.js ]; then
            node workspace/fetch-articles.js
          else
            echo "No se encontró fetch-articles.js" && exit 1
          fi

      - name: "Ejecutar merge-articles.js (fusiona en articles.json)"
        run: |
          set -euo pipefail
          if [ -f merge-articles.js ]; then
            node merge-articles.js
          elif [ -f workspace/merge-articles.js ]; then
            node workspace/merge-articles.js
          else
            echo "No se encontró merge-articles.js" && exit 1
          fi

      - name: "Validación rápida de archivos generados (logs + conteos)"
        run: |
          set -euo pipefail
          for f in "$PY_JSON" "$JS_JSON" "$FINAL_JSON"; do
            echo "::group::Comprobando $f"
            test -s "$f" || (echo "$f no existe o está vacío" && exit 1)
            jq . "$f" >/dev/null
            count=$(jq 'length' "$f")
            echo "$f OK. Entradas: $count"
            echo "Primeras 3 entradas:"
            jq -c '.[0:3]' "$f" || true
            echo "::endgroup::"
          done

      - name: "Validar fusión: superset, sin duplicados y orden por fecha"
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const core = require('@actions/core');
            const base = 'workspace/astro/public';
            const files = {
              py: `${base}/articles_py.json`,
              js: `${base}/articles_js.json`,
              merged: `${base}/articles.json`,
            };
            const dateField = 'date';
            const read = (p) => JSON.parse(fs.readFileSync(p, 'utf8'));
            const id = (it) => String((it.id||it.ID||it.doi||it.DOI||it.url||it.link||'').trim().toLowerCase().replace(/[\s?#]+/g,''));
            const t  = (it) => { const d = it[dateField]||it.published||it.publishedAt||it.datePublished||''; const tt = Date.parse(d); return Number.isFinite(tt)?tt:0; };
            const py = read(files.py);
            const js = read(files.js);
            const merged = read(files.merged);
            core.info(`PY: ${py.length} | JS: ${js.length} | MERGED: ${merged.length}`);
            const mergedIds = new Set(merged.map(id));
            const missPy = py.filter(x=>!mergedIds.has(id(x)));
            const missJs = js.filter(x=>!mergedIds.has(id(x)));
            if (missPy.length||missJs.length){
              if(missPy.length) core.error('- Faltan de PY (ids): ' + missPy.map(id).slice(0,20).join(', '));
              if(missJs.length) core.error('- Faltan de JS (ids): ' + missJs.map(id).slice(0,20).join(', '));
              core.setFailed('articles.json no contiene todo el superset PY+JS');
              return;
            }
            core.info('articles.json contiene todas las entradas de PY y JS.');
            const seen = new Set(); const dups = [];
            for (const it of merged){ const k = id(it); if(seen.has(k)) dups.push(k); seen.add(k);} 
            if (dups.length){
              core.setFailed('Duplicados en articles.json (ej.: ' + dups.slice(0,20).join(', ') + ')');
              return;
            }
            core.info('Sin duplicados en articles.json.');
            let inOrder = true;
            for (let i=1;i<merged.length;i++){ if (t(merged[i])>t(merged[i-1])) { inOrder=false; break; } }
            if (!inOrder){
              core.setFailed('articles.json no está ordenado por fecha descendente.');
              return;
            }
            core.info('Orden correcto por fecha descendente.');

      - name: "Proteger histórico frente a regresiones (>20% menos que el commit previo)"
        run: |
          set -euo pipefail
          CUR=$(jq 'length' "$FINAL_JSON")
          PREV=$(git show HEAD:"$FINAL_JSON" 2>/dev/null | jq 'length' || echo 0)
          echo "Anterior: $PREV | Actual: $CUR"
          if [ "$PREV" -gt 0 ]; then
            LIMITE=$(( PREV * 80 / 100 ))
            if [ "$CUR" -lt "$LIMITE" ]; then
              echo "El total actual ($CUR) es >20% menor que el anterior ($PREV)." && exit 1
            fi
          fi

      - name: "Build Astro (opcional, si existe)"
        if: ${{ hashFiles('workspace/astro/package.json') != '' }}
        working-directory: workspace/astro
        run: npm run build

      - name: "Subir artefactos (JSON intermedios y final)"
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: articles-jsons
          path: |
            ${{ env.PY_JSON }}
            ${{ env.JS_JSON }}
            ${{ env.FINAL_JSON }}

      - name: "Commit & Push de artículos"
        run: |
          set -euo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "$PY_JSON" "$JS_JSON" "$FINAL_JSON"
          if git diff --cached --quiet; then
            echo "Sin cambios que commitear."
          else
            git commit -m "chore: daily articles update [skip ci]"
            git push
          fi
