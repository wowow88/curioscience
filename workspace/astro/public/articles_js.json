[
  {
    "title": "Efficient Real-Time Aircraft ETA Prediction via Feature Tokenization Transformer",
    "title_es": "Predicción eficiente en tiempo real de la hora prevista de llegada de un avión mediante un transformador de tokenización de características",
    "url": "https://arxiv.org/abs/2508.09144",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09144v1 Tipo de anuncio: nuevo\nResumen: La estimación de la hora de llegada (ETA) de aeronaves en tiempo real es crucial para la gestión de llegadas en aviación, en particular para la secuenciación de pistas. Dado el contexto rápidamente cambiante del espacio aéreo, la eficiencia de la predicción de ETA es tan importante como su precisión en un sistema de gestión de aeronaves de llegada en tiempo real. En este estudio, utilizamos un modelo Transformer basado en la tokenización de características para predecir eficientemente la ETA de las aeronaves. La tokenización de rasgos proyecta entradas brutas a espacios latentes, mientras que el mecanismo de autoatención multicabezal del Transformer captura aspectos importantes de las proyecciones, aliviando la necesidad de una compleja ingeniería de rasgos. Además, la capacidad de cálculo en paralelo del Transformer le permite gestionar solicitudes de ETA a una frecuencia elevada, es decir, 1HZ, lo que resulta esencial para un sistema de gestión de llegadas en tiempo real. Las entradas del modelo incluyen datos brutos, como la latitud y longitud de la aeronave, la velocidad de avance, el grado theta del aeropuerto, el día y la hora de los datos de la pista, el contexto meteorológico y la categoría de turbulencia de la estela de la aeronave. Con una frecuencia de muestreo de datos de 1HZ, la predicción de ETA se actualiza cada segundo. Aplicamos el enfoque de predicción de ETA de aeronaves propuesto al aeropuerto Changi de Singapur (código OACI: WSSS) utilizando datos de un mes de Automatic Dependent Surveillance-Broadcast (ADS-B) del 1 al 31 de octubre de 2022. En la evaluación experimental, el modelado ETA cubre todas las aeronaves dentro de un rango de 10NM a 300NM de WSSS. Los resultados muestran que nuestro método propuesto supera al modelo basado en árbol boosting comúnmente utilizado, mejorando la precisión en un 7\\% en comparación con XGBoost, mientras que requiere sólo el 39\\% de su tiempo de computación. Los resultados experimentales también indican que, con 40 aeronaves en el espacio aéreo en un momento dado, el tiempo de inferencia de ETA es de sólo 51,7 microsegundos, lo que lo hace prometedor para los sistemas de gestión de llegadas en tiempo real.",
    "source": "arXiv"
  },
  {
    "title": "MoLAN: A Unified Modality-Aware Noise Dynamic Editing Framework for Multimodal Sentiment Analysis",
    "title_es": "MoLAN: un marco unificado de edición dinámica del ruido con conciencia de la modalidad para el análisis multimodal del sentimiento",
    "url": "https://arxiv.org/abs/2508.09145",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09145v1 Tipo de anuncio: nuevo\nResumen: El análisis multimodal de sentimientos pretende integrar información de varias modalidades, como audio, visual y texto, para hacer predicciones complementarias. Sin embargo, a menudo tiene dificultades con la información visual y auditiva irrelevante o engañosa. La mayoría de los enfoques existentes suelen tratar toda la información de la modalidad (por ejemplo, una imagen completa, un segmento de audio o un párrafo de texto) como una unidad independiente para la mejora o eliminación de ruido. A menudo suprimen la información redundante y el ruido a riesgo de perder información crítica. Para hacer frente a este reto, proponemos MoLAN, un marco unificado de edición dinámica de ruido con conciencia de la modalidad. En concreto, MoLAN realiza el bloqueo en función de la modalidad dividiendo las características de cada modalidad en varios bloques. A continuación, se asigna dinámicamente a cada bloque una intensidad de eliminación de ruido distinta en función de su nivel de ruido y su relevancia semántica, lo que permite suprimir el ruido con precisión y preservar al mismo tiempo la información multimodal esencial. MoLAN es un marco unificado y flexible que puede integrarse perfectamente en una amplia gama de modelos multimodales. Basándonos en este marco, presentamos MoLAN+, un nuevo enfoque de análisis multimodal de sentimientos. Los experimentos realizados con cinco modelos y cuatro conjuntos de datos demuestran la gran eficacia del marco MoLAN. Las evaluaciones exhaustivas muestran que MoLAN+ alcanza el rendimiento más avanzado. El código está disponible públicamente en https://github.com/betterfly123/MoLAN-Framework.",
    "source": "arXiv"
  },
  {
    "title": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA",
    "title_es": "Comprender teóricamente el aprendizaje en contexto basado en transformadores para optimizar CSMA",
    "url": "https://arxiv.org/abs/2508.09146",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09146v1 Tipo de anuncio: nuevo\nResumen: El esquema de backoff exponencial binario es ampliamente utilizado en WiFi 7 y todavía incurre en un rendimiento pobre bajo entornos de canal dinámico. Enfoques recientes basados en modelos (por ejemplo, CSMA no persistente y $p$-persistente) simplemente optimizan las estrategias de backoff bajo una densidad de nodos conocida y fija, lo que sigue dando lugar a una gran pérdida de rendimiento debido a la estimación inexacta de la densidad de nodos. Este artículo es el primero que propone una teoría de aprendizaje en contexto (ICL) basada en transformadores LLM para optimizar el acceso al canal. Diseñamos un optimizador ICL basado en transformadores para recopilar previamente ejemplos de datos con umbral de colisión y un caso de colisión de consulta. Se construyen como una indicación que sirve de entrada para que el transformador aprenda el patrón, que a su vez genera un umbral de ventana de contención (CWT) previsto. Para entrenar al transformador para una ICL eficaz, desarrollamos un algoritmo eficiente y garantizamos una predicción de CWT casi óptima en pasos de entrenamiento limitados. Como en la práctica puede ser difícil reunir ejemplos de datos perfectos para ICL, ampliamos aún más para permitir la entrada de datos erróneos en la predicción. Demostramos que nuestro optimizador mantiene desviaciones mínimas de la predicción y el rendimiento respecto a los valores óptimos. Los resultados experimentales en NS-3 demuestran además la rápida convergencia de nuestro enfoque y su rendimiento casi óptimo frente a los enfoques existentes basados en modelos y en DRL bajo densidades de nodos desconocidas.",
    "source": "arXiv"
  },
  {
    "title": "Agentic TinyML for Intent-aware Handover in 6G Wireless Networks",
    "title_es": "Agentic TinyML para el traspaso consciente de la intención en redes inalámbricas 6G",
    "url": "https://arxiv.org/abs/2508.09147",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09147v1 Tipo de anuncio: nuevo\nResumen: A medida que las redes 6G evolucionan hacia ecosistemas cada vez más impulsados por la IA y centrados en el usuario, los mecanismos tradicionales de traspaso reactivo muestran limitaciones, especialmente en escenarios de computación móvil de borde y servicios autónomos basados en agentes. Este manuscrito presenta WAAN, un marco multicapa que permite traspasos proactivos y conscientes de la intención mediante la incorporación de agentes TinyML ligeros como entidades autónomas con capacidad de negociación en nodos de borde heterogéneos que contribuyen a la propagación de la intención y a la adaptación de la red. Para garantizar la continuidad en caso de interrupciones inducidas por la movilidad, WAAN incorpora puntos de encuentro semiestables que sirven como anclas de coordinación para la transferencia de contexto y la conservación del estado. Las capacidades operativas del marco se demuestran a través de un caso práctico de control ambiental multimodal, que pone de relieve su eficacia para mantener la experiencia del usuario en condiciones de movilidad. Por último, el artículo analiza los principales retos y oportunidades de futuro asociados al despliegue y la evolución de WAAN.",
    "source": "arXiv"
  },
  {
    "title": "Motif 2.6B Technical Report",
    "title_es": "Informe técnico Motif 2.6B",
    "url": "https://arxiv.org/abs/2508.09148",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09148v1 Tipo de anuncio: nuevo\nResumen: Los recientes avances en Large Language Models (LLMs) han revolucionado la inteligencia artificial, sin embargo, el desarrollo de un LLM fundacional eficaz que equilibre el alto rendimiento con la eficiencia computacional sigue siendo un reto, especialmente para los grupos de investigación emergentes. Para colmar esta laguna, presentamos Motif-2.6B, un modelo fundacional de 2.600 millones de parámetros diseñado para democratizar las capacidades de los LLM avanzados. Motif-2.6B incorpora varias mejoras arquitectónicas innovadoras, como las funciones de activación Atención Diferencial y PolyNorm, que mejoran la comprensión de contextos largos, reducen la alucinación y potencian las capacidades de aprendizaje en contexto. Hemos probado rigurosamente múltiples componentes arquitectónicos novedosos a través de una amplia experimentación para determinar la arquitectura óptima para Motif-2.6B. Las exhaustivas evaluaciones realizadas demuestran que Motif-2.6B alcanza o supera sistemáticamente el rendimiento de los modelos más avanzados de tamaño similar en diversas pruebas de referencia, lo que pone de manifiesto su eficacia, escalabilidad y aplicabilidad en el mundo real. A través de experimentos detallados y técnicas a medida, Motif-2.6B avanza significativamente en el panorama de los LLM fundacionales eficientes, escalables y potentes, ofreciendo valiosos conocimientos y una base sólida para futuras investigaciones y despliegues.",
    "source": "arXiv"
  },
  {
    "title": "Semantic-Aware LLM Orchestration for Proactive Resource Management in Predictive Digital Twin Vehicular Networks",
    "title_es": "Orquestación LLM consciente de la semántica para la gestión proactiva de recursos en redes vehiculares digitales gemelas predictivas",
    "url": "https://arxiv.org/abs/2508.09149",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09149v1 Tipo de anuncio: nuevo\nResumen: Las aplicaciones de automoción de próxima generación requieren computación en el borde del vehículo (VEC), pero los sistemas de gestión actuales son esencialmente fijos y reactivos. Son subóptimos en entornos vehiculares extremadamente dinámicos porque están limitados a objetivos de optimización estáticos y basan sus decisiones en los estados actuales de la red. Este artículo presenta un novedoso marco de Orquestación Proactiva LLM Consciente de la Semántica (SP-LLM) para abordar estos problemas. Nuestro método transforma el Gemelo Digital (DT) tradicional en un Gemelo Digital Predictivo (pDT) que predice parámetros importantes de la red como la llegada de tareas, la movilidad de los vehículos y la calidad del canal. El núcleo de nuestro marco es un modelo de lenguaje amplio (LLM) que actúa como orquestador cognitivo. Toma decisiones proactivas y previsoras sobre la descarga de tareas y la asignación de recursos utilizando las previsiones del PDT. La capacidad del LLM para descifrar órdenes semánticas de alto nivel dadas en lenguaje natural es crucial porque le permite modificar dinámicamente su política de optimización para adaptarse a la evolución de los objetivos estratégicos, como dar prioridad a los servicios de emergencia u optimizar la eficiencia energética. Mediante extensas simulaciones, demostramos que SP-LLM ofrece unos resultados significativamente mejores en términos de escalabilidad, robustez en condiciones volátiles y adaptabilidad que los enfoques reactivos y basados en MARL más avanzados. Las redes vehiculares más inteligentes, autónomas y orientadas a objetivos serán posibles gracias a la extraordinaria capacidad de nuestro marco para convertir la intención humana en un comportamiento óptimo de la red.",
    "source": "arXiv"
  },
  {
    "title": "Enabling On-demand Guaranteed QoS for Real Time Video Streaming from Vehicles in 5G Advanced with CAPIF & NEF APIs",
    "title_es": "Habilitación de la calidad de servicio garantizada a petición para la transmisión de vídeo en tiempo real desde vehículos en 5G Advanced con las API CAPIF y NEF",
    "url": "https://arxiv.org/abs/2508.09150",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09150v1 Tipo de anuncio: nuevo\nResumen: Este artículo presenta el diseño y la implementación de una Prueba de Concepto (PoC) que demuestra cómo las Funciones de Red Avanzadas 5G pueden integrarse con el Marco Común de API (CAPIF) para soportar una conectividad mejorada para aplicaciones de automoción. La PoC muestra la monitorización continua del rendimiento de la red móvil y la adaptación dinámica y bajo demanda de la Calidad de Servicio (QoS) para flujos de tráfico de streaming de vídeo de Equipos de Usuario (UE) 5G seleccionados utilizando APIs de Función de Exposición de Red (NEF) 3GPP estándar expuestas a través de CAPIF. Además, los flujos de tráfico se redirigen al borde para mejorar la latencia y optimizar la utilización de los recursos de red.",
    "source": "arXiv"
  },
  {
    "title": "Physiological Signal-Driven QoE Optimization for Wireless Virtual Reality Transmission",
    "title_es": "Optimización de la calidad del servicio basada en señales fisiológicas para la transmisión inalámbrica de realidad virtual",
    "url": "https://arxiv.org/abs/2508.09151",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09151v1 Tipo de anuncio: nuevo\nResumen: Los cambios bruscos de resolución en el streaming de realidad virtual (RV) pueden perjudicar significativamente la calidad de experiencia (QoE) de los usuarios, especialmente durante las transiciones de alta a baja resolución. Los modelos de calidad de experiencia y los esquemas de transmisión existentes no abordan adecuadamente el impacto perceptivo de estos cambios. Para colmar esta laguna, este artículo propone, por primera vez, un innovador marco de modelado y optimización de la calidad de experiencia basado en señales fisiológicas que aprovecha plenamente las señales de electroencefalograma (EEG), electrocardiograma (ECG) y actividad cutánea de los usuarios. Este marco capta con precisión la dinámica temporal de las respuestas fisiológicas y los cambios de resolución en las transmisiones de RV, lo que permite cuantificar con precisión las ventajas de mejorar la resolución y los efectos de reducirla. Integrado el marco de calidad de vida propuesto en la red de acceso radioeléctrico (RAN) a través de un marco de aprendizaje profundo por refuerzo (DRL), se han implementado estrategias de transmisión adaptativas para asignar recursos radioeléctricos de forma dinámica, lo que mitiga las fluctuaciones del canal a corto plazo y ajusta la resolución de los fotogramas en respuesta a las variaciones del canal causadas por la movilidad de los usuarios. Al dar prioridad a la resolución a largo plazo y minimizar las transiciones bruscas, la solución propuesta consigue una mejora del 88,7\\% en la resolución y una reducción del 81,0\\% en el traspaso con respecto a la línea de base. Los resultados experimentales demuestran la eficacia de esta estrategia basada en la señal fisiológica, lo que subraya la promesa de la IA de borde en los servicios multimedia inmersivos.",
    "source": "arXiv"
  },
  {
    "title": "5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI",
    "title_es": "Detección de fallos en el núcleo 5G y análisis de la causa raíz mediante aprendizaje automático e IA generativa",
    "url": "https://arxiv.org/abs/2508.09152",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09152v1 Tipo de anuncio: nuevo\nResumen: Con la llegada de las redes y tecnologías 5G, garantizar la integridad y el rendimiento del tráfico central de paquetes es primordial. Durante el análisis de la red, los archivos de prueba, como los archivos de captura de paquetes (PCAP) y los archivos de registro, contendrán errores si están presentes en el sistema que deben resolverse para mejorar el rendimiento general de la red, como la fuerza de la conectividad y la calidad del traspaso. Los métodos actuales requieren numerosas horas-persona para clasificar los resultados de las pruebas y encontrar los fallos. Este artículo presenta un novedoso motor de análisis de fallos (FA) basado en IA/ML diseñado para clasificar tramas correctas y defectuosas en archivos PCAP, concretamente en el núcleo de paquetes 5G. El motor FA analiza el tráfico de red utilizando técnicas de procesamiento de lenguaje natural para identificar anomalías e ineficiencias, reduciendo significativamente el tiempo de esfuerzo necesario y aumentando la eficiencia. El motor FA también sugiere pasos para solucionar el problema utilizando IA generativa a través de un modelo de lenguaje amplio (LLM) entrenado en varios documentos del núcleo de paquetes 5G. El motor explica los detalles del error desde la perspectiva del dominio utilizando documentos como las normas 3GPP y documentos de usuario sobre las condiciones internas de las pruebas. Los resultados de las pruebas con los modelos ML muestran una alta precisión de clasificación en el conjunto de datos de prueba cuando se entrenan con divisiones 80-20 para los archivos PCAP exitosos y fallidos. Entre los objetivos futuros se incluye la ampliación del motor de IA para incorporar el tráfico de red 4G y otras formas de datos de red, como archivos de texto de registro y sistemas multimodales.",
    "source": "arXiv"
  },
  {
    "title": "JustDense: Just using Dense instead of Sequence Mixer for Time Series analysis",
    "title_es": "JustDense: Uso de Dense en lugar de Sequence Mixer para el análisis de series temporales",
    "url": "https://arxiv.org/abs/2508.09153",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09153v1 Tipo de anuncio: nuevo\nResumen: Los mezcladores de secuencias y canales, el mecanismo central en los modelos secuenciales, se han convertido en el estándar de facto en el análisis de series temporales (TSA). Sin embargo, estudios recientes han cuestionado la necesidad de mezcladores de secuencias complejos, como los mecanismos de atención, demostrando que arquitecturas más sencillas pueden lograr un rendimiento comparable o incluso superior. Esto sugiere que las ventajas atribuidas a los mezcladores de secuencias complejos podrían derivarse de otros factores arquitectónicos o de optimización. Basándonos en esta observación, planteamos una pregunta central: ¿Son necesarios los mezcladores de secuencias comunes para el análisis de series temporales? Por lo tanto, proponemos JustDense, un estudio empírico que sustituye sistemáticamente los mezcladores de secuencias en varios modelos TSA bien establecidos por capas densas. Basado en el marco MatrixMixer, JustDense trata cualquier mezclador de secuencias como una matriz de mezcla y lo sustituye por una capa densa. Esta sustitución aísla la operación de mezcla, permitiendo una base teórica clara para comprender su papel. Por lo tanto, llevamos a cabo experimentos exhaustivos en 29 puntos de referencia que cubren cinco tareas TSA representativas utilizando siete modelos TSA de última generación para abordar nuestra pregunta de investigación. Los resultados muestran que la sustitución de los mezcladores de secuencias por capas densas produce un rendimiento comparable o incluso superior. En los casos en los que los mezcladores de secuencias dedicados siguen ofreciendo ventajas, JustDense desafía la suposición de que \"las arquitecturas más profundas y complejas son intrínsecamente mejores\" en TSA.",
    "source": "arXiv"
  },
  {
    "title": "Peer Effect Estimation in the Presence of Simultaneous Feedback and Unobserved Confounders",
    "title_es": "Estimación del efecto de los pares en presencia de retroalimentación simultánea y factores de confusión no observados",
    "url": "https://arxiv.org/abs/2508.09154",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09154v1 Tipo de anuncio: nuevo\nResumen: Estimar los efectos causales entre iguales en redes complejas del mundo real, como las redes sociales, es un reto, principalmente debido a la retroalimentación simultánea entre iguales y a factores de confusión no observados. Los métodos existentes o bien abordan los factores de confusión no observados ignorando la retroalimentación simultánea, o bien tienen en cuenta la retroalimentación pero bajo supuestos lineales restrictivos, por lo que no consiguen obtener una estimación precisa del efecto entre iguales. En este artículo, proponemos DIG2RSI, un novedoso marco de aprendizaje profundo que aprovecha la transformación I-G (operación matricial) y 2SRI (una técnica de variable instrumental o IV) para abordar tanto la retroalimentación simultánea como los factores de confusión no observados, al tiempo que da cabida a relaciones complejas, no lineales y de alta dimensión. DIG2RSI aplica primero la transformación I-G para desentrañar las influencias mutuas entre iguales y eliminar el sesgo debido a la retroalimentación simultánea. Para tratar los factores de confusión no observados, primero construimos IV válidos a partir de los datos de la red. En la fase 1 de 2RSI, entrenamos una red neuronal con estos IV para predecir la exposición a los compañeros y extraemos los residuos como variables sustitutivas de los factores de confusión no observados. En la etapa 2, ajustamos una red neuronal separada aumentada por un discriminador adversarial que incorpora estos residuos como una función de control y obliga a la representación aprendida a no contener ninguna señal de confusión residual. El poder expresivo de los modelos de aprendizaje profundo en la captura de relaciones no lineales complejas y la eliminación de sesgos adversariales mejora la eficacia de DIG2RSI en la eliminación de sesgos tanto de los bucles de retroalimentación como de los factores de confusión ocultos. Demostramos la consistencia de nuestro estimador en condiciones de regularidad estándar, garantizando la recuperación asintótica del verdadero efecto de los pares. Los resultados empíricos sobre dos puntos de referencia semisintéticos y un conjunto de datos del mundo real demuestran que DIG2RSI supera a los enfoques existentes.",
    "source": "arXiv"
  },
  {
    "title": "A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models",
    "title_es": "A Rolling Stone Gathers No Moss: Optimización de políticas adaptativas para una autoevaluación estable en grandes modelos multimodales",
    "url": "https://arxiv.org/abs/2508.09155",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09155v1 Tipo de anuncio: nuevo\nResumen: La auto-evaluación, la capacidad de un modelo para evaluar la corrección de su propia salida, es crucial para que los Grandes Modelos Multimodales (LMMs) logren la auto-mejora en las conversaciones multi-vuelta, sin embargo, en gran medida ausente en los modelos de fundación. En trabajos recientes se ha empleado el aprendizaje por refuerzo (RL) para mejorar la autoevaluación; sin embargo, su mecanismo de recompensa fija sufre de hackeo de recompensas cuando se optimizan múltiples objetivos de entrenamiento, lo que lleva al colapso del modelo. En este trabajo proponemos AdaPO, un marco de aprendizaje por refuerzo en línea capaz de ajustar de forma adaptativa el objetivo de entrenamiento en tiempo real de acuerdo con el estado de entrenamiento actual para cada tarea. En concreto, para mitigar el hackeo de recompensas, AdaPO introduce un Modelo Adaptativo de Recompensas (ARM) y un mecanismo de Regularización KL Dinámica Consciente de las Recompensas. ARM evalúa el estado de entrenamiento de la tarea a partir de la distribución del rendimiento de las trayectorias multivuelta generadas por el modelo. Reward Aware Dynamic KL sustituye una penalización fija por coeficientes dinámicos que se modulan en función de la diferencia de recompensa entre las distintas situaciones multivuelta. En particular, nuestro método ajusta automáticamente y sin problemas su enfoque de aprendizaje basándose en el progreso del entrenamiento de las subtareas sin intervención manual. Experimentos exhaustivos con 8 puntos de referencia y varios modelos muestran que nuestro método mejora significativamente tanto el razonamiento directo como la capacidad de autoevaluación. Publicaremos nuestro código para contribuir a la comunidad.",
    "source": "arXiv"
  },
  {
    "title": "Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems",
    "title_es": "Ajuste fino con restricciones físicas de modelos de correspondencia de flujos para problemas de generación e inversos",
    "url": "https://arxiv.org/abs/2508.09156",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09156v1 Tipo de anuncio: nuevo\nResumen: Presentamos un marco para el ajuste fino de modelos generativos de coincidencia de flujo para hacer cumplir las restricciones físicas y resolver problemas inversos en sistemas científicos. Partiendo de un modelo entrenado con datos de baja fidelidad u observacionales, aplicamos un procedimiento de post-entrenamiento diferenciable que minimiza los residuos de forma débil de las ecuaciones diferenciales parciales (EDP) gobernantes, promoviendo la consistencia física y la adherencia a las condiciones de contorno sin distorsionar la distribución aprendida subyacente. Para inferir entradas físicas desconocidas, como términos de fuente, parámetros de material o datos de frontera, aumentamos el proceso generativo con un predictor de parámetros latentes aprendible y proponemos una estrategia de optimización conjunta. El modelo resultante produce soluciones de campo físicamente válidas junto con estimaciones plausibles de parámetros ocultos, abordando eficazmente problemas inversos mal planteados de una manera basada en datos pero consciente de la física. Validamos nuestro método con referencias canónicas de EDP, demostrando una mejor satisfacción de las restricciones de la EDP y una recuperación precisa de los coeficientes latentes. Nuestro enfoque tiende un puente entre el modelado generativo y la inferencia científica, abriendo nuevas vías para el descubrimiento aumentado por simulación y el modelado eficiente de datos de sistemas físicos.",
    "source": "arXiv"
  },
  {
    "title": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving",
    "title_es": "EvaDrive: Optimización evolutiva de políticas adversarias para la conducción autónoma de extremo a extremo.",
    "url": "https://arxiv.org/abs/2508.09158",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09158v1 Tipo de anuncio: nuevo\nResumen: La conducción autónoma se enfrenta a importantes retos para lograr una toma de decisiones iterativa similar a la humana, que genere, evalúe y refine continuamente las propuestas de trayectoria. Los marcos actuales de generación-evaluación aíslan la generación de trayectorias de la evaluación de la calidad, impidiendo el refinamiento iterativo esencial para la planificación, mientras que los métodos de aprendizaje de refuerzo colapsan las preferencias multidimensionales en recompensas escalares, oscureciendo las compensaciones críticas y produciendo un sesgo de escalarización.Para superar estos problemas, presentamos EvaDrive, un nuevo marco de aprendizaje de refuerzo multi-objetivo que establece una verdadera co-evolución de bucle cerrado entre la generación de trayectorias y la evaluación a través de la optimización adversarial. EvaDrive plantea la planificación de trayectorias como un juego adversarial de varias rondas. En este juego, un generador jerárquico propone continuamente trayectorias candidatas combinando el modelado autorregresivo para la causalidad temporal con el refinamiento basado en la difusión para la flexibilidad espacial. A continuación, estas propuestas son evaluadas rigurosamente por un crítico multiobjetivo entrenable que preserva explícitamente diversas estructuras de preferencias sin colapsarlas en un único sesgo de escalarización. Esta interacción adversarial, guiada por un mecanismo de selección de la frontera de Pareto, permite el refinamiento iterativo en múltiples rondas, escapando eficazmente de los óptimos locales y preservando al mismo tiempo la diversidad de trayectorias.Experimentos exhaustivos en NAVSIM y Bench2Drive demuestran el rendimiento de SOTA, logrando 94,9 PDMS en NAVSIM v1 (superando a DiffusionDrive en 6,8, DriveSuprim en 5,0 y TrajHF en 0,9) y 64,96 Driving Score en Bench2Drive. EvaDrive genera diversos estilos de conducción a través de la ponderación dinámica sin datos de preferencia externos, introduciendo un marco adversarial de bucle cerrado para la toma de decisiones iterativa similar a la humana, ofreciendo un novedoso enfoque de optimización de trayectoria sin escalarización.",
    "source": "arXiv"
  },
  {
    "title": "Agoran: An Agentic Open Marketplace for 6G RAN Automation",
    "title_es": "Agoran: Un mercado abierto agenético para la automatización de RAN 6G",
    "url": "https://arxiv.org/abs/2508.09159",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09159v1 Tipo de anuncio: nuevo\nResumen: Las redes móviles de próxima generación deben conciliar los objetivos, a menudo contradictorios, de múltiples propietarios de servicios. Sin embargo, los actuales controladores de red siguen siendo rígidos, están sujetos a políticas y desconocen el contexto empresarial. Presentamos Agoran Service and Resource Broker (SRB), un mercado ágil que introduce a las partes interesadas directamente en el bucle operativo. Inspirado en el ágora de la antigua Grecia, Agoran distribuye la autoridad entre tres ramas autónomas de IA: una rama legislativa que responde a las consultas de cumplimiento mediante modelos de lenguaje ampliados (LLM); una rama ejecutiva que mantiene el conocimiento de la situación en tiempo real a través de una base de datos de vectores actualizada; y una rama judicial que evalúa cada mensaje de agente con una puntuación de confianza basada en reglas, mientras que los LLM de arbitraje detectan comportamientos maliciosos y aplican incentivos en tiempo real para restaurar la confianza. Los agentes de negociación del lado de las partes interesadas y el agente mediador del lado de la SRB negocian ofertas factibles y óptimas de Pareto producidas por un optimizador multiobjetivo, alcanzando una intención de consenso en una sola ronda, que luego se despliega a controladores RAN abiertos y de IA. Desplegado en un banco de pruebas 5G privado y evaluado con trazas realistas de movilidad de vehículos, Agoran logró ganancias significativas: (i) un aumento del 37% en el rendimiento de las rebanadas eMBB, (ii) una reducción del 73% en la latencia de las rebanadas URLLC, y simultáneamente (iii) un ahorro de extremo a extremo del 8,3% en el uso de PRB en comparación con una línea de base estática. Un modelo Llama de 1B parámetros, ajustado con precisión durante cinco minutos en 100 diálogos GPT-4, recupera aproximadamente el 80% de la calidad de decisión de GPT-4.1, al tiempo que funciona con 6 GiB de memoria y converge en sólo 1,3 segundos. Estos resultados convierten a Agoran en una vía concreta, alineada con los estándares, hacia redes 6G ultraflexibles y centradas en las partes interesadas. Puede verse una demostración en directo en https://www.youtube.com/watch?v=h7vEyMu2f5w&ab_channel=BubbleRAN.",
    "source": "arXiv"
  },
  {
    "title": "Presenting DiaData for Research on Type 1 Diabetes",
    "title_es": "Presentación de DiaData para la investigación de la diabetes de tipo 1",
    "url": "https://arxiv.org/abs/2508.09160",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09160v1 Tipo de anuncio: nuevo\nResumen: La diabetes tipo 1 (T1D) es un trastorno autoinmune que conduce a la destrucción de las células productoras de insulina, dando lugar a una deficiencia de insulina, por lo que los individuos afectados dependen de inyecciones externas de insulina. Sin embargo, la insulina puede disminuir los niveles de glucosa en sangre y provocar hipoglucemia. La hipoglucemia es un evento grave de niveles bajos de glucosa en sangre ($\\le$70 mg/dL) con peligrosos efectos secundarios de mareo, coma o muerte. El análisis de datos puede mejorar significativamente la atención diabética mediante la identificación de patrones y tendencias personales que conducen a eventos adversos. En especial, los modelos de aprendizaje automático (ML) pueden predecir los niveles de glucosa y proporcionar alarmas tempranas. Sin embargo, la investigación sobre la diabetes y la hipoglucemia se ve limitada por la falta de disponibilidad de grandes conjuntos de datos. Así, este trabajo integra sistemáticamente 15 conjuntos de datos para proporcionar una gran base de datos de 2510 sujetos con mediciones de glucosa registradas cada 5 minutos. En total, se incluyen 149 millones de mediciones, de las cuales el 4% representan valores en el rango hipoglucémico. Además, se extraen dos sub-bases de datos. La subbase de datos I incluye datos demográficos, y la subbase de datos II incluye datos de frecuencia cardiaca. El conjunto de datos integrado ofrece una distribución equitativa del sexo y los distintos niveles de edad. Como contribución adicional, se evalúa la calidad de los datos, lo que revela que el desequilibrio de los datos y los valores perdidos suponen un reto importante. Además, se realiza un estudio de correlación entre los niveles de glucosa y los datos de frecuencia cardiaca, que muestra una relación entre 15 y 55 minutos antes de la hipoglucemia.",
    "source": "arXiv"
  },
  {
    "title": "Physics-Guided Memory Network for Building Energy Modeling",
    "title_es": "Red de memoria guiada por la física para la modelización energética de edificios",
    "url": "https://arxiv.org/abs/2508.09161",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09161v1 Tipo de anuncio: nuevo\nResumen: La previsión precisa del consumo de energía es esencial para la gestión eficiente de los recursos y la sostenibilidad en el sector de la construcción. Los modelos de aprendizaje profundo son muy exitosos, pero luchan con datos históricos limitados y se vuelven inutilizables cuando los datos históricos no están disponibles, como en los edificios de nueva construcción. Por otro lado, los modelos basados en la física, como EnergyPlus, simulan el consumo de energía sin depender de los datos históricos, pero requieren amplias especificaciones de los parámetros del edificio y un tiempo considerable para modelar un edificio. Este artículo presenta una red de memoria guiada por la física (PgMN), una red neuronal que integra predicciones de aprendizaje profundo y modelos basados en la física para abordar sus limitaciones. PgMN comprende una Capa de Proyección Paralela para procesar entradas incompletas, una Unidad de Memoria para tener en cuenta los sesgos persistentes y un Módulo de Experiencia de Memoria para extender de manera óptima las predicciones más allá de su rango de entrada y producir la salida. La evaluación teórica muestra que los componentes de la PgMN son matemáticamente válidos para realizar sus respectivas tareas. La PgMN se evaluó en la previsión de energía a corto plazo con una resolución horaria, crítica para la toma de decisiones operativas en sistemas de redes y edificios inteligentes. La validación experimental muestra la precisión y aplicabilidad de la PgMN en diversos escenarios, como edificios de nueva construcción, datos ausentes, datos históricos escasos y cambios dinámicos en la infraestructura. Este trabajo proporciona una solución prometedora para la previsión del consumo energético en entornos de edificios dinámicos, mejorando la aplicabilidad del modelo en escenarios en los que los datos históricos son limitados o no están disponibles o cuando los modelos basados en la física son inadecuados.",
    "source": "arXiv"
  },
  {
    "title": "An Unsupervised Deep XAI Framework for Localization of Concurrent Replay Attacks in Nuclear Reactor Signals",
    "title_es": "Un marco XAI profundo no supervisado para la localización de ataques de repetición concurrentes en señales de reactores nucleares",
    "url": "https://arxiv.org/abs/2508.09162",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09162v1 Tipo de anuncio: nuevo\nResumen: Se espera que los reactores nucleares avanzados de próxima generación sean más pequeños tanto en tamaño como en potencia, y que dependan en gran medida de sistemas de instrumentación y control totalmente digitales. Estos reactores generarán un gran flujo de información en forma de datos de series temporales multivariantes, que transmitirán simultáneamente diversos estados ciberfísicos no lineales, de proceso, de control, de sensores y operativos. Garantizar la integridad de los datos contra los ataques de engaño es cada vez más importante para la comunicación en red y un requisito para un funcionamiento seguro y fiable. Los esfuerzos actuales para hacer frente a los ataques de repetición se centran casi universalmente en la marca de agua o en enfoques supervisados de detección de anomalías sin identificar y caracterizar más a fondo la causa raíz de la anomalía. Además, estos enfoques se basan principalmente en datos sintéticos con procesos gaussianos no correlacionados y ruido de medición y retroalimentación de estado completa, o se limitan a señales univariantes, estacionariedad de señal, reguladores lineales cuadráticos u otros espacios de estado invariantes en tiempo lineal que pueden no capturar ninguna dinámica de sistema no modelada. En el ámbito de los sistemas ciberfísicos nucleares regulados, es necesario seguir trabajando en la caracterización de los ataques de repetición y en la explicabilidad de las predicciones utilizando datos reales. Aquí, proponemos un marco de IA explicable no supervisado basado en una combinación de autocodificador y algoritmo windowSHAP personalizado para caracterizar completamente los ataques de repetición en tiempo real, es decir, detección, identificación de la fuente, temporización y tipo, de complejidad creciente durante un proceso dinámico de evolución temporal del reactor. El marco XAI propuesto se evaluó en varios conjuntos de datos reales del reactor nuclear PUR-1 de Purdue con hasta seis señales reproducidas simultáneamente. En todos los casos, el marco XAI fue capaz de detectar e identificar la fuente y el número de señales reproducidas, así como la duración de la falsificación, con una precisión del 95% o superior.",
    "source": "arXiv"
  },
  {
    "title": "Energy-Efficient Stochastic Computing (SC) Neural Networks for Internet of Things Devices With Layer-Wise Adjustable Sequence Length (ASL)",
    "title_es": "Redes neuronales de computación estocástica (SC) energéticamente eficientes para dispositivos del Internet de las cosas con longitud de secuencia ajustable por capas (ASL)",
    "url": "https://arxiv.org/abs/2508.09163",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09163v1 Tipo de anuncio: nuevo\nResumen: La computación estocástica (SC) ha surgido como una alternativa eficiente de bajo consumo para desplegar redes neuronales (NNs) en escenarios con recursos limitados, como el Internet de las Cosas (IoT). Mediante la codificación de valores como secuencias de bits en serie, SC reduce significativamente la disipación de energía en comparación con los diseños convencionales de punto flotante (FP); sin embargo, la mejora de la implementación de precisión mixta por capas para SC sigue sin explorarse. Este artículo presenta la Longitud de Secuencia Ajustable (ASL), un novedoso esquema que aplica conceptos de precisión mixta específicamente a las NN de SC. Introduciendo un modelo teórico basado en operadores-normas, este artículo muestra que el ruido de truncamiento puede propagarse acumulativamente a través de las capas mediante los factores de amplificación estimados. Se presenta un análisis de sensibilidad ampliado, utilizando la regresión de bosque aleatorio (RF) para evaluar los efectos del truncamiento multicapa y validar la alineación de las predicciones teóricas con los comportamientos prácticos de la red. Para dar cabida a diferentes escenarios de aplicación, este artículo propone dos estrategias de truncamiento (de grano grueso y de grano fino), que aplican diversas configuraciones de longitud de secuencia en cada capa. Las evaluaciones realizadas en un MLP SC sintetizado en 32 nm demuestran que ASL puede reducir los gastos generales de energía y latencia en más de un 60% con una pérdida de precisión insignificante. Esto confirma la viabilidad del esquema ASL para aplicaciones IoT y pone de relieve las claras ventajas del truncado de precisión mixta en los diseños SC.",
    "source": "arXiv"
  },
  {
    "title": "Generating Feasible and Diverse Synthetic Populations Using Diffusion Models",
    "title_es": "Generación de poblaciones sintéticas viables y diversas mediante modelos de difusión",
    "url": "https://arxiv.org/abs/2508.09164",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09164v1 Tipo de anuncio: nuevo\nResumen: La síntesis de poblaciones es una tarea crítica que implica generar representaciones sintéticas pero realistas de poblaciones. Se trata de un problema fundamental en el modelado basado en agentes (ABM), que se ha convertido en el estándar para analizar sistemas de transporte inteligentes. La población sintética sirve como entrada principal para la simulación de transporte ABM, con agentes viajeros representados por miembros de la población. Sin embargo, cuando el número de atributos que describen a los agentes se hace grande, los datos de la encuesta a menudo no pueden soportar densamente la distribución conjunta de los atributos en la población debido a la maldición de la dimensionalidad. Esta escasez dificulta el modelado y la generación precisos de la población. Curiosamente, los modelos generativos profundos entrenados a partir de los datos de muestra disponibles pueden sintetizar potencialmente posibles combinaciones de atributos presentes en la población real pero que no existen en los datos de muestra (denominados ceros muestrales). Sin embargo, esto tiene el coste de generar falsamente las combinaciones de atributos no factibles que no existen en la población (denominadas ceros estructurales). En este estudio se propone un nuevo método de síntesis de la población basado en un modelo de difusión para estimar la distribución conjunta subyacente de una población. Este enfoque permite la recuperación de numerosos ceros de muestreo ausentes, manteniendo al mismo tiempo mínimos los ceros estructurales generados. Nuestro método se compara con otros enfoques propuestos recientemente, como los autocodificadores variacionales (VAE) y las redes generativas adversariales (GAN), que han demostrado su eficacia en la síntesis de poblaciones tabulares de alta dimensión. Evaluamos el rendimiento de las salidas sintetizadas utilizando una serie de métricas, como la similitud de la distribución marginal, la viabilidad y la diversidad. Los resultados demuestran que el método propuesto supera a los anteriores al lograr un mejor equilibrio entre la viabilidad y la diversidad de la población sintetizada.",
    "source": "arXiv"
  },
  {
    "title": "Masked Training for Robust Arrhythmia Detection from Digitalized Multiple Layout ECG Images",
    "title_es": "Entrenamiento enmascarado para la detección robusta de arritmias a partir de imágenes de ECG digitalizadas de disposición múltiple",
    "url": "https://arxiv.org/abs/2508.09165",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09165v1 Tipo de anuncio: nuevo\nResumen: El electrocardiograma (ECG) es una herramienta importante para el diagnóstico de enfermedades cardiovasculares como la arritmia. Debido a las diferencias en los diseños de ECG utilizados por los diferentes hospitales, las señales digitalizadas exhiben tiempo de espera asíncrono y pérdida parcial de apagón, lo que plantea un serio desafío a los modelos existentes. Para hacer frente a este reto, el estudio introdujo PatchECG, un marco para el aprendizaje adaptativo de representación de pérdida de recuento de bloques variable basado en una estrategia de entrenamiento de enmascaramiento, que se centra automáticamente en parches clave con dependencias de colaboración entre derivaciones, logrando así un reconocimiento clave de la arritmia en ECG con diferentes diseños. Se realizaron experimentos con el conjunto de datos PTB-XL y 21388 imágenes de ECG asíncronas generadas con la herramienta ECG image kit, utilizando las 23 subclases como etiquetas. El método propuesto demostró una gran solidez con diferentes diseños, con un área media bajo la curva de características operativas del receptor (AUROC) de 0,835 y se mantuvo estable (sin cambios con los cambios de diseño). En la validación externa basada en 400 datos de imágenes de ECG reales del Hospital Chaoyang, el AUROC para el diagnóstico de fibrilación auricular alcanzó 0,778; en los ECG de disposición 12 x 1, el AUROC alcanza 0,893. Este resultado es superior a varios métodos clásicos de interpolación y de línea de base, y en comparación con el actual modelo óptimo de preentrenamiento a gran escala ECGFounder, ha mejorado en 0,111 y 0,19.",
    "source": "arXiv"
  },
  {
    "title": "WPTrack: A Wi-Fi and Pressure Insole Fusion System for Single Target Tracking",
    "title_es": "WPTrack: Un sistema de fusión de Wi-Fi y plantilla de presión para el seguimiento de un solo objetivo",
    "url": "https://arxiv.org/abs/2508.09166",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09166v1 Tipo de anuncio: nuevo\nResumen: A medida que el Internet de las Cosas (IoT) continúa evolucionando, la localización en interiores se ha convertido en un elemento crítico para habilitar hogares inteligentes, monitoreo del comportamiento y cuidado de ancianos. Las soluciones existentes de seguimiento humano basadas en WiFi suelen requerir equipos especializados o múltiples enlaces Wi-Fi, una limitación en la mayoría de los entornos de interior donde solo suele haber disponible un único par de dispositivos Wi-Fi. Sin embargo, a pesar de los esfuerzos por implementar el seguimiento humano utilizando un solo enlace Wi-Fi, siguen existiendo importantes retos, como las dificultades para adquirir posiciones iniciales y los puntos ciegos en la estimación DFS de la dirección tangente. Para hacer frente a estos retos, este artículo propone WPTrack, el primer sistema de fusión de Wi-Fi y plantillas de presión para el seguimiento de un único objetivo. WPTrack recopila información de estado del canal (CSI) de un único enlace Wi-Fi y datos de presión de 90 sensores de plantilla. La diferencia de fase y la velocidad Doppler se calculan a partir de la CSI, mientras que los datos del sensor de presión se utilizan para calcular la velocidad de la marcha. A continuación, proponemos el modelo de fusión CSI-presión, que integra los datos CSI y de presión para determinar con precisión las posiciones iniciales y facilitar un seguimiento humano preciso. Los resultados de la simulación muestran que la precisión de la localización de la posición inicial oscila entre 0,02 cm y 42,55 cm. Los resultados del seguimiento de la trayectoria obtenidos a partir de datos experimentales recogidos en un entorno real se ajustan estrechamente a la trayectoria real.",
    "source": "arXiv"
  },
  {
    "title": "SVGen: Interpretable Vector Graphics Generation with Large Language Models",
    "title_es": "SVGen: Generación de gráficos vectoriales interpretables con grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.09168",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09168v1 Tipo de anuncio: nuevo\nResumen: Los gráficos vectoriales escalables (SVG) son ampliamente utilizados en el desarrollo front-end y en el diseño UI/UX debido a su escalabilidad, editabilidad y eficiencia de renderizado. Sin embargo, convertir ideas creativas en gráficos vectoriales precisos sigue siendo un reto que requiere mucho tiempo. Para resolver este problema, presentamos SVG-1M, un conjunto de datos a gran escala de SVG de alta calidad emparejados con descripciones en lenguaje natural. Mediante el aumento y la anotación de datos avanzados, creamos pares de entrenamiento de texto a SVG bien alineados, incluido un subconjunto con anotaciones de Cadena de Pensamiento para mejorar la orientación semántica. Basándonos en este conjunto de datos, proponemos SVGen, un modelo integral que genera código SVG a partir de entradas de lenguaje natural. Nuestro enfoque garantiza la precisión semántica y la integridad estructural, con el apoyo del aprendizaje curricular y la optimización del aprendizaje por refuerzo. Los experimentos demuestran que SVGen supera a los grandes modelos generales y a los métodos tradicionales de renderizado tanto en eficacia como en eficiencia. El código, el modelo y el conjunto de datos están disponibles en GitHub.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal RAG Enhanced Visual Description",
    "title_es": "Descripción visual mejorada del GAR multimodal",
    "url": "https://arxiv.org/abs/2508.09170",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09170v1 Tipo de anuncio: nuevo\nResumen: Las descripciones textuales para entradas multimodales implican un refinamiento recurrente de las consultas para producir imágenes de salida relevantes. A pesar de los esfuerzos para hacer frente a retos como el escalado del tamaño del modelo y el volumen de datos, el coste asociado con el pre-entrenamiento y el ajuste fino sigue siendo sustancial. Sin embargo, los grandes modelos multimodales (LMM) preentrenados se topan con una brecha de modalidad, caracterizada por un desajuste entre las representaciones textuales y visuales dentro de un espacio de incrustación común. Aunque el ajuste fino puede mitigar potencialmente esta brecha, suele ser caro y poco práctico debido a la necesidad de disponer de amplios datos basados en el dominio. Para superar este reto, proponemos un enfoque ligero y sin formación que utiliza la Generación Mejorada por Recuperación (RAG) para extenderse a través de la modalidad mediante un mapeo lineal, que puede calcularse de forma eficiente. Durante la inferencia, esta asignación se aplica a las imágenes incrustadas por un LMM que permite recuperar las descripciones textuales más cercanas del conjunto de entrenamiento. Estas descripciones textuales, junto con una instrucción, sirven de entrada para que el modelo lingüístico genere nuevas descripciones textuales. Además, introducimos una técnica iterativa para destilar el mapeo mediante la generación de descripciones sintéticas a través del modelo de lenguaje, lo que facilita la optimización de las medidas de descripción de imágenes utilizadas habitualmente. Los resultados experimentales en dos conjuntos de datos multimodales de referencia demuestran mejoras significativas.",
    "source": "arXiv"
  },
  {
    "title": "webMCP: Efficient AI-Native Client-Side Interaction for Agent-Ready Web Design",
    "title_es": "webMCP: Interacción eficiente entre el cliente y la IA para un diseño web preparado para el agente",
    "url": "https://arxiv.org/abs/2508.09171",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09171v1 Tipo de anuncio: nuevo\nResumen: Los actuales agentes de IA crean barreras significativas para los usuarios al requerir un extenso procesamiento para entender las páginas web, haciendo que la interacción web asistida por IA sea lenta y costosa. En este artículo se presenta webMCP (Web Machine Context & Procedure), un estándar del lado del cliente que incorpora metadatos de interacción estructurados directamente en las páginas web, lo que permite una colaboración más eficiente entre humanos e IA en los sitios web existentes. webMCP transforma la forma en que los agentes de IA entienden las interfaces web al proporcionar asignaciones explícitas entre los elementos de la página y las acciones del usuario. En lugar de procesar documentos HTML completos, los agentes pueden acceder a datos de interacción preestructurados, lo que reduce drásticamente la carga computacional y mantiene la precisión de las tareas. Una evaluación exhaustiva de 1.890 llamadas reales a API que abarcan escenarios de compra en línea, autenticación y gestión de contenidos demuestra que webMCP reduce los requisitos de procesamiento en un 67,6%, al tiempo que mantiene tasas de éxito de las tareas del 97,9%, frente al 98,8% de los enfoques tradicionales. Los usuarios experimentan costes significativamente más bajos (reducción del 34-63%) y tiempos de respuesta más rápidos en diversas interacciones web. Los análisis estadísticos confirman que estas mejoras son muy significativas en múltiples modelos de IA. Un estudio independiente de implementación en WordPress valida la aplicabilidad práctica, mostrando mejoras consistentes en los flujos de trabajo de gestión de contenidos del mundo real. webMCP no requiere modificaciones del lado del servidor, por lo que se puede implementar en millones de sitios web existentes sin barreras técnicas. Estos resultados establecen webMCP como una solución viable para hacer que la asistencia web de IA sea más accesible y sostenible, abordando la brecha crítica entre las necesidades de interacción del usuario y los requisitos computacionales de IA en entornos de producción.",
    "source": "arXiv"
  },
  {
    "title": "Camel: Energy-Aware LLM Inference on Resource-Constrained Devices",
    "title_es": "Camel: Inferencia LLM consciente de la energía en dispositivos con recursos limitados",
    "url": "https://arxiv.org/abs/2508.09173",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09173v1 Tipo de anuncio: nuevo\nResumen: En la actualidad, la mayoría de los grandes modelos lingüísticos (LLM) se despliegan en la nube, y los usuarios dependen de la conectividad a Internet para acceder a ellos. Sin embargo, este paradigma se enfrenta a retos como la latencia de la red, problemas de privacidad y limitaciones de ancho de banda. Por ello, el despliegue de LLM en dispositivos periféricos se ha convertido en un importante foco de investigación. En la inferencia en el borde, la latencia de las peticiones es crítica, ya que una latencia elevada puede afectar a las tareas en tiempo real. Al mismo tiempo, los dispositivos periféricos suelen tener una capacidad de batería limitada, por lo que el consumo de energía es otro problema importante. Es esencial equilibrar el consumo de energía y la latencia de la inferencia. Para resolver este problema, proponemos un marco de gestión de la energía de inferencia LLM que optimiza la frecuencia de la GPU y el tamaño del lote para equilibrar la latencia y el consumo de energía. Al gestionar eficazmente el dilema exploración-explotación en la búsqueda de configuraciones, el marco encuentra los ajustes óptimos. El marco se ha implementado en la plataforma NVIDIA Jetson AGX Orin y se han realizado una serie de validaciones experimentales. Los resultados demuestran que, en comparación con la configuración por defecto, nuestro marco reduce el producto de retardo de energía (EDP) entre un 12,4% y un 29,9%, logrando un mejor equilibrio entre consumo de energía y latencia.",
    "source": "arXiv"
  },
  {
    "title": "FedMP: Tackling Medical Feature Heterogeneity in Federated Learning from a Manifold Perspective",
    "title_es": "FedMP: abordar la heterogeneidad de las características médicas en el aprendizaje federado desde una perspectiva múltiple",
    "url": "https://arxiv.org/abs/2508.09174",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09174v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje federado (FL) es un paradigma de aprendizaje automático descentralizado en el que múltiples clientes entrenan de forma colaborativa un modelo compartido sin compartir sus datos privados locales. Sin embargo, las aplicaciones de FL en el mundo real se enfrentan con frecuencia a retos derivados de los conjuntos de datos locales distribuidos de forma no idéntica e independiente (no IID) entre los clientes participantes, lo que es particularmente pronunciado en el campo de las imágenes médicas, donde los cambios en las distribuciones de características de imagen dificultan significativamente la convergencia y el rendimiento del modelo global. Para hacer frente a este reto, proponemos FedMP, un método novedoso diseñado para mejorar la FL en escenarios sin IID. FedMP emplea la compleción estocástica de múltiples características para enriquecer el espacio de entrenamiento de los clasificadores de clientes individuales, y aprovecha los prototipos de clase para guiar la alineación de los múltiples de características entre clientes dentro de subespacios semánticamente coherentes, facilitando la construcción de límites de decisión más diferenciados. Validamos la eficacia de FedMP en múltiples conjuntos de datos de imágenes médicas, incluidos aquellos con distribuciones multicéntricas del mundo real, así como en un conjunto de datos de imágenes naturales multidominio. Los resultados experimentales demuestran que FedMP supera a los algoritmos FL existentes. Además, analizamos el impacto de la dimensionalidad múltiple, la eficiencia de la comunicación y las implicaciones para la privacidad de la exposición de características en nuestro método.",
    "source": "arXiv"
  },
  {
    "title": "A Context-aware Attention and Graph Neural Network-based Multimodal Framework for Misogyny Detection",
    "title_es": "Marco multimodal basado en redes neuronales gráficas y atención consciente del contexto para la detección de la misoginia",
    "url": "https://arxiv.org/abs/2508.09175",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09175v1 Tipo de anuncio: nuevo\nResumen: Una parte sustancial del contenido ofensivo en las redes sociales está dirigido a las mujeres. Dado que los enfoques para la detección de contenido ofensivo en general se enfrentan a un reto en la detección de contenido misógino, se requieren soluciones adaptadas para abordar el contenido ofensivo contra las mujeres. Con este fin, proponemos un novedoso marco multimodal para la detección de contenidos misóginos y sexistas. El marco consta de tres módulos: el módulo de atención multimodal (MANM), el módulo de reconstrucción de características basadas en gráficos (GFRM) y el módulo de aprendizaje de características específicas del contenido (CFLM). El MANM emplea una atención multimodal adaptativa basada en el contexto, lo que permite al modelo centrarse en la información visual y textual relevante y generar características contextualmente pertinentes. El módulo GFRM utiliza gráficos para perfeccionar las características dentro de las distintas modalidades, mientras que el CFLM se centra en el aprendizaje de características específicas del texto y la imagen, como las características de toxicidad y las características del pie de foto. Además, seleccionamos un conjunto de léxicos misóginos para calcular la puntuación del léxico específico de la misoginia a partir del texto. Aplicamos el aumento en tiempo de prueba en el espacio de características para generalizar mejor las predicciones sobre diversas entradas. El rendimiento del método propuesto se ha evaluado en dos conjuntos de datos multimodales, AMMI y MMHS150K, con 11.000 y 13.494 muestras, respectivamente. El método propuesto demuestra una mejora media del 10,17% y el 8,88% en macro-F1 con respecto a los métodos existentes en los conjuntos de datos AMMI y MMHS150K, respectivamente.",
    "source": "arXiv"
  },
  {
    "title": "DQT: Dynamic Quantization Training via Dequantization-Free Nested Integer Arithmetic",
    "title_es": "DQT: formación en cuantificación dinámica mediante aritmética de enteros anidados sin cuantificación",
    "url": "https://arxiv.org/abs/2508.09176",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09176v1 Tipo de anuncio: nuevo\nResumen: El despliegue de redes neuronales profundas en dispositivos con recursos limitados depende de la cuantización. Aunque la cuantización estática y uniforme aplica un ancho de bits fijo a todas las entradas, no se adapta a su complejidad variable. La cuantización dinámica, basada en instancias y de precisión mixta, promete un equilibrio superior entre precisión y eficiencia al asignar una mayor precisión sólo cuando es necesario. Sin embargo, sigue existiendo un cuello de botella crítico: los métodos actuales requieren un costoso ciclo de decuantización a flotante y de recuantización a entera para cambiar la precisión, lo que rompe el paradigma de hardware exclusivo para enteros y compromete las ganancias de rendimiento. En este artículo se presenta el Entrenamiento de Cuantización Dinámica (DQT), un novedoso marco que elimina este cuello de botella. El núcleo de DQT es una representación de enteros anidada en la que los valores de menor precisión se incrustan dentro de los de mayor precisión. Este diseño, unido a una aritmética personalizada de enteros, permite cambiar sobre la marcha el ancho de bits mediante una operación de desplazamiento de bits de coste casi nulo. Esto convierte a DQT en el primer marco de cuantificación que permite tanto la cuantificación estática de precisión mixta sin decuantificación de la red troncal, como una cuantificación dinámica basada en instancias realmente eficiente a través de un controlador ligero que decide en tiempo de ejecución cómo cuantificar cada capa. Demostramos el rendimiento de vanguardia de DQT en ResNet18 sobre CIFAR-10 y ResNet50 sobre ImageNet. En ImageNet, nuestra ResNet50 dinámica de 4 bits alcanza una precisión top-1 del 77,00%, lo que supone una mejora con respecto a los métodos estáticos (LSQ, 76,70%) y dinámicos (DQNET, 76,94%) líderes con un presupuesto de BitOPs comparable. Y lo que es más importante, DQT lo consigue con un coste de transición de ancho de bits de sólo 28,3 millones de operaciones de desplazamiento de bits, lo que supone una mejora drástica respecto a los 56,6 millones de costosas operaciones de multiplicación-acumulación (MAC) en coma flotante que requerían los métodos dinámicos anteriores.",
    "source": "arXiv"
  },
  {
    "title": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection",
    "title_es": "IAD-R1: Refuerzo del razonamiento coherente en la detección industrial de anomalías",
    "url": "https://arxiv.org/abs/2508.09178",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09178v1 Tipo de anuncio: nuevo\nResumen: La detección de anomalías industriales es un componente crítico de la fabricación moderna, sin embargo, la escasez de muestras defectuosas restringe los métodos tradicionales de detección a aplicaciones en escenarios específicos. Aunque los Modelos Visión-Lenguaje (VLMs) demuestran ventajas significativas en capacidades de generalización, su rendimiento en la detección de anomalías industriales sigue siendo limitado. Para hacer frente a este reto, proponemos IAD-R1, un marco universal de post-entrenamiento aplicable a VLMs de diferentes arquitecturas y escalas de parámetros, que mejora sustancialmente sus capacidades de detección de anomalías. IAD-R1 emplea una estrategia de entrenamiento en dos etapas: la etapa de Ajuste Supervisado de la Activación de la Percepción (PA-SFT) utiliza un conjunto de datos de Cadena de Pensamiento de alta calidad meticulosamente construido (Experto-AD) para el entrenamiento, mejorando las capacidades de percepción de anomalías y estableciendo correlaciones de razonamiento-respuesta; la etapa de Optimización de la Política Relativa del Grupo de Control Estructurado (SC-GRPO) emplea funciones de recompensa cuidadosamente diseñadas para lograr un salto de capacidad de \"Percepción de Anomalías\" a \"Interpretación de Anomalías\". Los resultados experimentales demuestran que IAD-R1 logra mejoras significativas en 7 VLM, alcanzando hasta un 43,3% de mejora en la precisión media en 6 conjuntos de datos de referencia de detección de anomalías industriales. En particular, el modelo de parámetro 0,5B entrenado con IAD-R1 supera a los modelos comerciales, incluidos GPT-4.1 y Claude-Sonnet-4 en configuraciones de disparo cero, lo que demuestra la eficacia y superioridad de IAD-R1. El conjunto de datos, el código y todas las ponderaciones del modelo estarán a disposición del público en https://github.com/Yanhui-Lee/IAD-R1.",
    "source": "arXiv"
  },
  {
    "title": "scAGC: Learning Adaptive Cell Graphs with Contrastive Guidance for Single-Cell Clustering",
    "title_es": "scAGC: Aprendizaje de grafos celulares adaptativos con orientación contrastiva para la agrupación unicelular",
    "url": "https://arxiv.org/abs/2508.09180",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09180v1 Tipo de anuncio: nuevo\nResumen: La anotación precisa del tipo de célula es un paso crucial en el análisis de datos de secuenciación de ARN unicelular (scRNA-seq), que proporciona información valiosa sobre la heterogeneidad celular. Sin embargo, debido a la alta dimensionalidad y a la prevalencia de elementos cero en los datos de scRNA-seq, los métodos tradicionales de agrupamiento se enfrentan a importantes retos estadísticos y computacionales. Aunque algunos métodos avanzados utilizan redes neuronales de grafos para modelar las relaciones célula-célula, a menudo dependen de estructuras de grafos estáticas que son sensibles al ruido y no consiguen capturar la distribución de colas largas inherente a las poblaciones unicelulares.Para abordar estas limitaciones, proponemos scAGC, un método de agrupamiento unicelular que aprende grafos celulares adaptativos con orientación contrastiva. Nuestro enfoque optimiza las representaciones de características y los grafos celulares simultáneamente de extremo a extremo. En concreto, introducimos un autocodificador de grafos adaptable a la topología que aprovecha una estrategia de muestreo Gumbel-Softmax diferenciable para refinar dinámicamente la estructura del grafo durante el entrenamiento. Este mecanismo adaptativo mitiga el problema de una distribución de grados de cola larga promoviendo una estructura de vecindario más equilibrada. Para modelar la naturaleza discreta, sobredispersa y cero-inflada de los datos de scRNA-seq, integramos una pérdida binomial negativa cero-inflada (ZINB) para una reconstrucción robusta de las características. Además, se incorpora un objetivo de aprendizaje contrastivo para regularizar el proceso de aprendizaje del grafo y evitar cambios bruscos en la topología del grafo, asegurando la estabilidad y mejorando la convergencia. Experimentos exhaustivos en 9 conjuntos de datos reales de scRNA-seq demuestran que scAGC supera sistemáticamente a otros métodos de vanguardia, obteniendo las mejores puntuaciones NMI y ARI en 9 y 7 conjuntos de datos, respectivamente.",
    "source": "arXiv"
  },
  {
    "title": "Long-Term Client Selection for Federated Learning with Non-IID Data: A Truthful Auction Approach",
    "title_es": "Selección de clientes a largo plazo para el aprendizaje federado con datos no procedentes de IID: Un enfoque de subasta veraz",
    "url": "https://arxiv.org/abs/2508.09181",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09181v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje federado (FL) proporciona un marco descentralizado que permite el entrenamiento universal de modelos a través de esfuerzos colaborativos en nodos móviles, tales como vehículos inteligentes en el Internet de los Vehículos (IoV). Cada vehículo inteligente actúa como un cliente móvil, contribuyendo al proceso sin cargar datos locales. Este método aprovecha los datos de entrenamiento no independientes e idénticamente distribuidos (no IoV) de diferentes vehículos, influidos por diversos patrones de conducción y condiciones ambientales, que pueden afectar significativamente a la convergencia y precisión del modelo. Aunque la selección de clientes puede ser una solución viable para los problemas no relacionados con IID, se enfrenta a retos relacionados con las métricas de selección. Las métricas tradicionales evalúan la calidad de los datos del cliente de forma independiente por ronda y requieren la selección del cliente después de que todos los clientes completen el entrenamiento local, lo que conduce a un desperdicio de recursos debido a los resultados de entrenamiento no utilizados. En el contexto de IoV, en el que los vehículos tienen conectividad y recursos informáticos limitados, la asimetría de la información en la selección de clientes puede hacer que los clientes envíen información falsa, lo que puede hacer que la selección sea ineficaz. Para hacer frente a estos retos, proponemos un nuevo Aprendizaje Federado de Selección de Clientes a Largo Plazo basado en la Subasta Veraz (LCSFLA). Este esquema maximiza el bienestar social teniendo en cuenta la calidad de los datos a largo plazo mediante un nuevo mecanismo de evaluación y los costes energéticos, y el mecanismo de subasta aconsejado con un requisito de depósito incentiva la participación de los clientes y garantiza la veracidad de la información. Demostramos teóricamente la compatibilidad de los incentivos y la racionalidad individual del mecanismo de incentivos asesorado. Los resultados experimentales en varios conjuntos de datos, incluidos los de escenarios IoV, demuestran su eficacia para mitigar la degradación del rendimiento causada por datos no IoV.",
    "source": "arXiv"
  },
  {
    "title": "HiSTM: Hierarchical Spatiotemporal Mamba for Cellular Traffic Forecasting",
    "title_es": "HiSTM: Hierarchical Spatiotemporal Mamba para la previsión del tráfico celular",
    "url": "https://arxiv.org/abs/2508.09184",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09184v1 Tipo de anuncio: nuevo\nResumen: La previsión del tráfico celular es esencial para planificar la red, asignar recursos o equilibrar la carga de tráfico entre celdas. Sin embargo, una previsión precisa es difícil debido a los intrincados patrones espaciales y temporales que existen debido a la movilidad de los usuarios. Los modelos de previsión de tráfico basados en inteligencia artificial suelen compensar la precisión con la eficiencia computacional. Presentamos Hierarchical SpatioTemporal Mamba (HiSTM), que combina un codificador espacial dual con un módulo temporal basado en Mamba y un mecanismo de atención. HiSTM emplea métodos selectivos de espacio de estados para capturar patrones espaciales y temporales en el tráfico de red. En nuestra evaluación, utilizamos un conjunto de datos del mundo real para comparar HiSTM con varias líneas de base, mostrando una mejora MAE del 29,4% sobre la línea de base STN mientras se utiliza un 94% menos de parámetros. Demostramos que HiSTM se generaliza bien en diferentes conjuntos de datos y mejora su precisión en horizontes temporales más largos.",
    "source": "arXiv"
  },
  {
    "title": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality",
    "title_es": "Un marco neurosimbólico para la detección interpretable de ataques cognitivos en la realidad aumentada",
    "url": "https://arxiv.org/abs/2508.09185",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09185v1 Tipo de anuncio: nuevo\nResumen: La Realidad Aumentada (RA) enriquece la percepción superponiendo elementos virtuales sobre el mundo físico. Debido a su creciente popularidad, los ataques cognitivos que alteran el contenido de la RA para manipular la percepción semántica de los usuarios han recibido cada vez más atención. Los métodos de detección existentes a menudo se centran en los cambios visuales, que se limitan al procesamiento a nivel de píxel o imagen y carecen de capacidades de razonamiento semántico, o se basan en modelos de visión-lenguaje (VLM) preentrenados, que funcionan como enfoques de caja negra con interpretabilidad limitada. En este artículo presentamos CADAR, un novedoso enfoque neurosimbólico para la detección de ataques cognitivos en RA. Fusiona entradas multimodales de visión-lenguaje utilizando VLMs neuronales para obtener una representación simbólica de percepción-grafo, incorporando conocimiento previo, ponderación de saliencia y correlaciones temporales. A continuación, el modelo permite el razonamiento estadístico basado en filtros de partículas -un método Monte Carlo secuencial- para detectar ataques cognitivos. Así, CADAR hereda la adaptabilidad del VLM preentrenado y la interpretabilidad y el rigor de razonamiento del filtrado de partículas. Los experimentos con un conjunto de datos ampliado de ataques cognitivos de RA muestran mejoras de precisión de hasta el 10,7% sobre líneas de base sólidas en escenarios desafiantes de ataques de RA, lo que subraya la promesa de los métodos neurosimbólicos para la detección eficaz e interpretable de ataques cognitivos.",
    "source": "arXiv"
  },
  {
    "title": "RL-MoE: An Image-Based Privacy Preserving Approach In Intelligent Transportation System",
    "title_es": "RL-MoE: Un enfoque de preservación de la privacidad basado en imágenes para el sistema de transporte inteligente",
    "url": "https://arxiv.org/abs/2508.09186",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09186v1 Tipo de anuncio: nuevo\nResumen: La proliferación de cámaras con IA en los Sistemas Inteligentes de Transporte (ITS) crea un grave conflicto entre la necesidad de datos visuales ricos y el derecho fundamental a la privacidad. Los mecanismos existentes para preservar la privacidad, como el desenfoque o la encriptación, son a menudo insuficientes, lo que crea una disyuntiva indeseable en la que, o bien la privacidad se ve comprometida frente a ataques avanzados de reconstrucción, o bien la utilidad de los datos se degrada críticamente. Para resolver este impasse, proponemos RL-MoE, un novedoso marco que transforma datos visuales sensibles en descripciones textuales que preservan la privacidad, eliminando la necesidad de la transmisión directa de imágenes. RL-MoE combina de forma única una arquitectura de Mezcla de Expertos (MoE) para la descomposición matizada y multiaspecto de escenas con un agente de Aprendizaje por Refuerzo (RL) que optimiza el texto generado para un doble objetivo de precisión semántica y preservación de la privacidad. Extensos experimentos demuestran que RL-MoE proporciona una protección superior de la privacidad, reduciendo la tasa de éxito de los ataques de repetición a sólo el 9,4\\% en el conjunto de datos CFP-FP, al tiempo que genera un contenido textual más rico que los métodos de referencia. Nuestro trabajo proporciona una solución práctica y escalable para crear sistemas de IA fiables en dominios sensibles a la privacidad, allanando el camino hacia redes de ciudades inteligentes y vehículos autónomos más seguras.",
    "source": "arXiv"
  },
  {
    "title": "Breath as a biomarker: A survey of contact and contactless applications and approaches in respiratory monitoring",
    "title_es": "El aliento como biomarcador: Un estudio de las aplicaciones y enfoques con y sin contacto en la monitorización respiratoria",
    "url": "https://arxiv.org/abs/2508.09187",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09187v1 Tipo de anuncio: nuevo\nResumen: El análisis del aliento se ha convertido en una herramienta fundamental en la monitorización de la salud, ofreciendo información sobre la función respiratoria, la detección de enfermedades y la evaluación continua de la salud. Aunque los métodos tradicionales basados en el contacto son fiables, a menudo plantean problemas de comodidad y practicidad, especialmente para la monitorización a largo plazo. Este estudio examina exhaustivamente los enfoques basados en el contacto y sin contacto, haciendo hincapié en los avances recientes en las técnicas de aprendizaje automático y aprendizaje profundo aplicadas al análisis de la respiración. Los métodos sin contacto, incluida la información de estado del canal Wi-Fi y la detección acústica, se analizan por su capacidad para proporcionar una monitorización respiratoria precisa y no invasiva. Exploramos una amplia gama de aplicaciones, desde la detección de la frecuencia respiratoria de un solo usuario hasta escenarios multiusuario, identificación de usuarios y detección de enfermedades respiratorias. Además, este estudio detalla las técnicas esenciales de preprocesamiento de datos, extracción de características y clasificación, ofreciendo una visión comparativa de los modelos de aprendizaje automático/aprendizaje profundo adecuados para cada enfoque. También se analizan retos clave como la escasez de conjuntos de datos, la interferencia multiusuario y la privacidad de los datos, junto con tendencias emergentes como la IA explicable, el aprendizaje federado, el aprendizaje por transferencia y el modelado híbrido. Al sintetizar las metodologías actuales e identificar las líneas de investigación abiertas, este estudio ofrece un marco exhaustivo para guiar las futuras innovaciones en el análisis de la respiración, tendiendo un puente entre las capacidades tecnológicas avanzadas y las aplicaciones sanitarias prácticas.",
    "source": "arXiv"
  },
  {
    "title": "Synthetic Data Generation for Emotional Depth Faces: Optimizing Conditional DCGANs via Genetic Algorithms in the Latent Space and Stabilizing Training with Knowledge Distillation",
    "title_es": "Generación de Datos Sintéticos para Caras de Profundidad Emocional: Optimización de DCGAN condicionales mediante algoritmos genéticos en el espacio latente y estabilización del entrenamiento con destilación de conocimientos",
    "url": "https://arxiv.org/abs/2508.09188",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09188v1 Tipo de anuncio: nuevo\nResumen: La computación afectiva se enfrenta a un reto importante: la falta de conjuntos de datos faciales de profundidad diversos y de alta calidad para reconocer expresiones emocionales sutiles. Proponemos un marco para la generación de caras de profundidad sintéticas utilizando un GAN optimizado con Destilación de Conocimiento (modelos de maestro EMA) para estabilizar el entrenamiento, mejorar la calidad y evitar el colapso de modo. También aplicamos Algoritmos Genéticos para evolucionar los vectores latentes de GAN basándonos en las estadísticas de la imagen, potenciando la diversidad y la calidad visual de las emociones objetivo. El enfoque supera a GAN, VAE, GMM y KDE tanto en diversidad como en calidad. Para la clasificación, extraemos y concatenamos características de LBP, HOG, borde Sobel e histograma de intensidad, logrando un 94% y un 96% de precisión con XGBoost. La evaluación mediante FID, IS, SSIM y PSNR muestra una mejora consistente respecto a los métodos más avanzados.",
    "source": "arXiv"
  },
  {
    "title": "Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks",
    "title_es": "Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks",
    "url": "https://arxiv.org/abs/2508.09190",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09190v1 Announce Type: new \nAbstract: Fine-tuning as service injects domain-specific knowledge into large language models (LLMs), while challenging the original alignment mechanisms and introducing safety risks. A series of defense strategies have been proposed for the alignment, fine-tuning, and post-fine-tuning phases, where most post-fine-tuning defenses rely on coarse-grained safety layer mapping. These methods lack a comprehensive consideration of both safety layers and fine-grained neurons, limiting their ability to efficiently balance safety and utility. To address this, we propose the Fine-Grained Safety Neurons (FGSN) with Training-Free Continual Projection method to reduce the fine-tuning safety risks. FGSN inherently integrates the multi-scale interactions between safety layers and neurons, localizing sparser and more precise fine-grained safety neurons while minimizing interference with downstream task neurons. We then project the safety neuron parameters onto safety directions, improving model safety while aligning more closely with human preferences. Extensive experiments across multiple fine-tuned LLM models demonstrate that our method significantly reduce harmfulness scores and attack success rates with minimal parameter modifications, while preserving the model's utility. Furthermore, by introducing a task-specific, multi-dimensional heterogeneous safety neuron cluster optimization mechanism, we achieve continual defense and generalization capability against unforeseen emerging safety concerns.",
    "source": "arXiv"
  },
  {
    "title": "From Values to Tokens: An LLM-Driven Framework for Context-aware Time Series Forecasting via Symbolic Discretization",
    "title_es": "From Values to Tokens: An LLM-Driven Framework for Context-aware Time Series Forecasting via Symbolic Discretization",
    "url": "https://arxiv.org/abs/2508.09191",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09191v1 Announce Type: new \nAbstract: Time series forecasting plays a vital role in supporting decision-making across a wide range of critical applications, including energy, healthcare, and finance. Despite recent advances, forecasting accuracy remains limited due to the challenge of integrating historical numerical sequences with contextual features, which often comprise unstructured textual data. To address this challenge, we propose TokenCast, an LLM-driven framework that leverages language-based symbolic representations as a unified intermediary for context-aware time series forecasting. Specifically, TokenCast employs a discrete tokenizer to transform continuous numerical sequences into temporal tokens, enabling structural alignment with language-based inputs. To bridge the semantic gap between modalities, both temporal and contextual tokens are embedded into a shared representation space via a pre-trained large language model (LLM), further optimized with autoregressive generative objectives. Building upon this unified semantic space, the aligned LLM is subsequently fine-tuned in a supervised manner to predict future temporal tokens, which are then decoded back into the original numerical space. Extensive experiments on diverse real-world datasets enriched with contextual features demonstrate the effectiveness and generalizability of TokenCast.",
    "source": "arXiv"
  },
  {
    "title": "Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing",
    "title_es": "Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing",
    "url": "https://arxiv.org/abs/2508.09192",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09192v1 Announce Type: new \nAbstract: Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to autoregressive (AR) LLMs for text generation, with the potential to decode multiple tokens in a single iteration. However, none of the existing open-source dLLMs have achieved superior inference speed over AR LLMs of similar size. This paper breaks this barrier based on a simple and effective strategy named discrete diffusion forcing (D2F). D2F equips dLLMs with two key capabilities: (1) block-wise autoregressive generation to enable KV cache utilization; (2) prediction of following tokens without requiring completion of prior blocks for inter-block parallel decoding. In this way, the vanilla dLLMs are refurbished into an AR-diffusion hybrid paradigm for efficient inference. D2F can be implemented with an asymmetric distillation process based on pre-trained dLLMs. We further propose a pipelined parallel decoding algorithm, which enables a trade-off between efficiency and efficacy. Empirically, D2F dLLMs achieve more than $\\mathbf{2.5\\times}$ inference speed than LLaMA3 and Qwen2.5 on GSM8K. Compared to vanilla dLLMs like LLaDA and Dream, the acceleration can be more than $\\mathbf{50\\times}$ while maintaining comparable output quality. The code is available at https://github.com/zhijie-group/Discrete-Diffusion-Forcing.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Objective Instruction-Aware Representation Learning in Procedural Content Generation RL",
    "title_es": "Multi-Objective Instruction-Aware Representation Learning in Procedural Content Generation RL",
    "url": "https://arxiv.org/abs/2508.09193",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09193v1 Announce Type: new \nAbstract: Recent advancements in generative modeling emphasize the importance of natural language as a highly expressive and accessible modality for controlling content generation. However, existing instructed reinforcement learning for procedural content generation (IPCGRL) method often struggle to leverage the expressive richness of textual input, especially under complex, multi-objective instructions, leading to limited controllability. To address this problem, we propose \\textit{MIPCGRL}, a multi-objective representation learning method for instructed content generators, which incorporates sentence embeddings as conditions. MIPCGRL effectively trains a multi-objective embedding space by incorporating multi-label classification and multi-head regression networks. Experimental results show that the proposed method achieves up to a 13.8\\% improvement in controllability with multi-objective instructions. The ability to process complex instructions enables more expressive and flexible content generation.",
    "source": "arXiv"
  },
  {
    "title": "Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments",
    "title_es": "Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments",
    "url": "https://arxiv.org/abs/2508.09194",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09194v1 Announce Type: new \nAbstract: The deployment of large-scale models, such as large language models (LLMs), incurs substantial costs due to their computational demands. To mitigate these costs and address challenges related to scalability and data security, there is a growing shift towards decentralized systems for model deployment, where choosing efficient inference acceleration schemes become crucial to manage computational resources effectively and enhance system responsiveness. In this work, we address the challenge of selecting optimal acceleration methods in decentralized systems by introducing a meta-learning-based framework. This framework automates the selection process by learning from historical performance data of various acceleration techniques across different tasks. Unlike traditional methods that rely on random selection or expert intuition, our approach systematically identifies the best acceleration strategies based on the specific characteristics of each task. We demonstrate that our meta-learning framework not only streamlines the decision-making process but also consistently outperforms conventional methods in terms of efficiency and performance. Our results highlight the potential of inference acceleration in decentralized AI systems, offering a path towards more democratic and economically feasible artificial intelligence solutions.",
    "source": "arXiv"
  },
  {
    "title": "MX-AI: Agentic Observability and Control Platform for Open and AI-RAN",
    "title_es": "MX-AI: Agentic Observability and Control Platform for Open and AI-RAN",
    "url": "https://arxiv.org/abs/2508.09197",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09197v1 Announce Type: new \nAbstract: Future 6G radio access networks (RANs) will be artificial intelligence (AI)-native: observed, reasoned about, and re-configured by autonomous agents cooperating across the cloud-edge continuum. We introduce MX-AI, the first end-to-end agentic system that (i) instruments a live 5G Open RAN testbed based on OpenAirInterface (OAI) and FlexRIC, (ii) deploys a graph of Large-Language-Model (LLM)-powered agents inside the Service Management and Orchestration (SMO) layer, and (iii) exposes both observability and control functions for 6G RAN resources through natural-language intents. On 50 realistic operational queries, MX-AI attains a mean answer quality of 4.1/5.0 and 100 % decision-action accuracy, while incurring only 8.8 seconds end-to-end latency when backed by GPT-4.1. Thus, it matches human-expert performance, validating its practicality in real settings. We publicly release the agent graph, prompts, and evaluation harness to accelerate open research on AI-native RANs. A live demo is presented here: https://www.youtube.com/watch?v=CEIya7988Ug&t=285s&ab_channel=BubbleRAN",
    "source": "arXiv"
  },
  {
    "title": "ADT4Coupons: An Innovative Framework for Sequential Coupon Distribution in E-commerce",
    "title_es": "ADT4Coupons: An Innovative Framework for Sequential Coupon Distribution in E-commerce",
    "url": "https://arxiv.org/abs/2508.09198",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09198v1 Announce Type: new \nAbstract: Coupon distribution is a critical marketing strategy used by online platforms to boost revenue and enhance user engagement. Regrettably, existing coupon distribution strategies fall far short of effectively leveraging the complex sequential interactions between platforms and users. This critical oversight, despite the abundance of e-commerce log data, has precipitated a performance plateau. In this paper, we focus on the scene that the platforms make sequential coupon distribution decision multiple times for various users, with each user interacting with the platform repeatedly. Based on this marketing scenario, we propose a novel marketing framework, named Aligned Decision Transformer for Coupons (ADT4Coupons), to directly devise coupon distribution policy for long-term revenue boosting. ADT4Coupons enables optimized online decision-making in a variety of real-world marketing scenarios. It achieves this by seamlessly integrating three key characteristics, general scenarios, sequential modeling with more comprehensive historical data, and efficient iterative updates within a unified framework. Furthermore, empirical results on real-world industrial dataset, alongside public and synthetic datasets demonstrate the superiority of our framework.",
    "source": "arXiv"
  },
  {
    "title": "$\\Delta$-AttnMask: Attention-Guided Masked Hidden States for Efficient Data Selection and Augmentation",
    "title_es": "$\\Delta$-AttnMask: Attention-Guided Masked Hidden States for Efficient Data Selection and Augmentation",
    "url": "https://arxiv.org/abs/2508.09199",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09199v1 Announce Type: new \nAbstract: Visual Instruction Finetuning (VIF) is pivotal for post-training Vision-Language Models (VLMs). Unlike unimodal instruction finetuning in plain-text large language models, which mainly requires instruction datasets to enable model instruction-following ability, VIF also requires multimodal data to enable joint visual and textual understanding; therefore, it typically requires more data. Consequently, VIF imposes stricter data selection challenges: the method must scale efficiently to handle larger data demands while ensuring the quality of both visual and textual content, as well as their alignment. Despite its critical impact on performance, data selection for VIF remains an understudied area. In this paper, we propose $\\Delta$-AttnMask. This data-efficient framework quantifies sample quality through attention-guided masking of the model's hidden states, jointly evaluating image-text pairs without requiring domain labels, auxiliary models, or extra training. By computing loss differences ($\\Delta$) between the original states and states masked using high-attention regions, $\\Delta$-AttnMask intrinsically assesses sample quality. Experiments across multiple VLMs and datasets show that $\\Delta$-AttnMask achieves state-of-the-art performance with just 20% of data, accelerating training by 5x while surpassing full-dataset baselines by +10.1% in overall accuracy. Its model-agnostic and data-agnostic design ensures broad applicability across modalities and architectures.",
    "source": "arXiv"
  },
  {
    "title": "Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models: A Unified and Accurate Approach",
    "title_es": "Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models: A Unified and Accurate Approach",
    "url": "https://arxiv.org/abs/2508.09201",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09201v1 Announce Type: new \nAbstract: Despite extensive alignment efforts, Large Vision-Language Models (LVLMs) remain vulnerable to jailbreak attacks, posing serious safety risks. Although recent detection works have shifted to internal representations due to their rich cross-modal information, most methods rely on heuristic rules rather than principled objectives, resulting in suboptimal performance. To address these limitations, we propose Learning to Detect (LoD), a novel unsupervised framework that formulates jailbreak detection as anomaly detection. LoD introduces two key components: Multi-modal Safety Concept Activation Vectors (MSCAV), which capture layer-wise safety-related representations across modalities, and the Safety Pattern Auto-Encoder, which models the distribution of MSCAV derived from safe inputs and detects anomalies via reconstruction errors. By training the auto-encoder (AE) solely on safe samples without attack labels, LoD naturally identifies jailbreak inputs as distributional anomalies, enabling accurate and unified detection of jailbreak attacks. Comprehensive experiments on three different LVLMs and five benchmarks demonstrate that LoD achieves state-of-the-art performance, with an average AUROC of 0.9951 and an improvement of up to 38.89% in the minimum AUROC over the strongest baselines.",
    "source": "arXiv"
  },
  {
    "title": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method",
    "title_es": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method",
    "url": "https://arxiv.org/abs/2508.09202",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09202v1 Announce Type: new \nAbstract: Facial expression recognition (FER) models are employed in many video-based affective computing applications, such as human-computer interaction and healthcare monitoring. However, deep FER models often struggle with subtle expressions and high inter-subject variability, limiting their performance in real-world applications. To improve their performance, source-free domain adaptation (SFDA) methods have been proposed to personalize a pretrained source model using only unlabeled target domain data, thereby avoiding data privacy, storage, and transmission constraints. This paper addresses a challenging scenario where source data is unavailable for adaptation, and only unlabeled target data consisting solely of neutral expressions is available. SFDA methods are not typically designed to adapt using target data from only a single class. Further, using models to generate facial images with non-neutral expressions can be unstable and computationally intensive. In this paper, personalized feature translation (PFT) is proposed for SFDA. Unlike current image translation methods for SFDA, our lightweight method operates in the latent space. We first pre-train the translator on the source domain data to transform the subject-specific style features from one source subject into another. Expression information is preserved by optimizing a combination of expression consistency and style-aware objectives. Then, the translator is adapted on neutral target data, without using source data or image synthesis. By translating in the latent space, PFT avoids the complexity and noise of face expression generation, producing discriminative embeddings optimized for classification. Using PFT eliminates the need for image synthesis, reduces computational overhead (using a lightweight translator), and only adapts part of the model, making the method efficient compared to image-based translation.",
    "source": "arXiv"
  },
  {
    "title": "Building Safer Sites: A Large-Scale Multi-Level Dataset for Construction Safety Research",
    "title_es": "Building Safer Sites: A Large-Scale Multi-Level Dataset for Construction Safety Research",
    "url": "https://arxiv.org/abs/2508.09203",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09203v1 Announce Type: new \nAbstract: Construction safety research is a critical field in civil engineering, aiming to mitigate risks and prevent injuries through the analysis of site conditions and human factors. However, the limited volume and lack of diversity in existing construction safety datasets pose significant challenges to conducting in-depth analyses. To address this research gap, this paper introduces the Construction Safety Dataset (CSDataset), a well-organized comprehensive multi-level dataset that encompasses incidents, inspections, and violations recorded sourced from the Occupational Safety and Health Administration (OSHA). This dataset uniquely integrates structured attributes with unstructured narratives, facilitating a wide range of approaches driven by machine learning and large language models. We also conduct a preliminary approach benchmarking and various cross-level analyses using our dataset, offering insights to inform and enhance future efforts in construction safety. For example, we found that complaint-driven inspections were associated with a 17.3% reduction in the likelihood of subsequent incidents. Our dataset and code are released at https://github.com/zhenhuiou/Construction-Safety-Dataset-CSDataset.",
    "source": "arXiv"
  },
  {
    "title": "MoQE: Improve Quantization Model performance via Mixture of Quantization Experts",
    "title_es": "MoQE: Improve Quantization Model performance via Mixture of Quantization Experts",
    "url": "https://arxiv.org/abs/2508.09204",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09204v1 Announce Type: new \nAbstract: Quantization method plays a crucial role in improving model efficiency and reducing deployment costs, enabling the widespread application of deep learning models on resource-constrained devices. However, the quantization process inevitably introduces accuracy degradation. In this paper, we propose Mixture of Quantization Experts( abbr. MoQE), a quantization inference framework based on the Mixture-of-Experts (MoE) architecture, aiming to jointly improve the performance of quantization models. MoQE combines multiple quantization variants of one full-precision model as specialized \"quantization experts\" and dynamically routes input data to the most suitable expert based on its characteristics. MoQE alleviates the performance degradation commonly seen in single quantization models through specialization quantization expert models. We design lightweight, structure-aware router models tailored for both CV and NLP tasks. Experimental evaluations on ResNet, LLaMA, and Qwen model families across benchmark datasets including ImageNet, WikiText, C4, and OpenWebText demonstrate that MoQE achieves performance comparable to SOTA quantization model, without incurring significant increases in inference latency.",
    "source": "arXiv"
  },
  {
    "title": "The First Differentiable Transfer-Based Algorithm for Discrete MicroLED Repair",
    "title_es": "The First Differentiable Transfer-Based Algorithm for Discrete MicroLED Repair",
    "url": "https://arxiv.org/abs/2508.09206",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09206v1 Announce Type: new \nAbstract: Laser-enabled selective transfer, a key process in high-throughput microLED fabrication, requires computational models that can plan shift sequences to minimize motion of XY stages and adapt to varying optimization objectives across the substrate. We propose the first repair algorithm based on a differentiable transfer module designed to model discrete shifts of transfer platforms, while remaining trainable via gradient-based optimization. Compared to local proximity searching algorithms, our approach achieves superior repair performance and enables more flexible objective designs, such as minimizing the number of steps. Unlike reinforcement learning (RL)-based approaches, our method eliminates the need for handcrafted feature extractors and trains significantly faster, allowing scalability to large arrays. Experiments show a 50% reduction in transfer steps and sub-2-minute planning time on 2000x2000 arrays. This method provides a practical and adaptable solution for accelerating microLED repair in AR/VR and next-generation display fabrication.",
    "source": "arXiv"
  },
  {
    "title": "GANime: Generating Anime and Manga Character Drawings from Sketches with Deep Learning",
    "title_es": "GANime: Generating Anime and Manga Character Drawings from Sketches with Deep Learning",
    "url": "https://arxiv.org/abs/2508.09207",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09207v1 Announce Type: new \nAbstract: The process of generating fully colorized drawings from sketches is a large, usually costly bottleneck in the manga and anime industry. In this study, we examine multiple models for image-to-image translation between anime characters and their sketches, including Neural Style Transfer, C-GAN, and CycleGAN. By assessing them qualitatively and quantitatively, we find that C-GAN is the most effective model that is able to produce high-quality and high-resolution images close to those created by humans.",
    "source": "arXiv"
  },
  {
    "title": "CoMoE: Collaborative Optimization of Expert Aggregation and Offloading for MoE-based LLMs at Edge",
    "title_es": "CoMoE: Collaborative Optimization of Expert Aggregation and Offloading for MoE-based LLMs at Edge",
    "url": "https://arxiv.org/abs/2508.09208",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09208v1 Announce Type: new \nAbstract: The proliferation of large language models (LLMs) has driven the adoption of Mixture-of-Experts (MoE) architectures as a promising solution to scale model capacity while controlling computational costs. However, deploying MoE models in resource-constrained mobile edge computing environments presents significant challenges due to their large memory footprint and dynamic expert activation patterns. To address these challenges, we propose a novel dynamic resource-aware collaborative optimization framework that jointly optimizes expert aggregation granularity and offloading strategies based on real-time device resource states, network conditions, and input characteristics in mobile edge environments, denoted as CoMoE. In CoMoE, we first systematically analyze existing expert aggregation techniques, including expert parameter merging,knowledge distillation,and parameter sharing decomposition, identifying their limitations in dynamic mobile environments.We then investigate expert offloading strategies encompassing expert prediction and prefetching, expert caching and scheduling, and multi-tier storage architectures, revealing the interdependencies between routing decisions and offloading performance.The CoMoE incorporates adaptive scheduling mechanisms that respond to user mobility and varying network conditions, enabling efficient MoE deployment across heterogeneous edge devices. Extensive experiments on real mobile edge testbeds demonstrate that CoMoE achieves approximately 70% reduction in memory usage compared to baseline methods, 10.5% lower inference latency than existing expert offloading techniques, while maintaining model performance stability. For large-scale MoE models (e.g,7.4B-parameter Switch-Base-128), the CoMoE reduces memory requirements from 15.6GB to 4.7GB, enabling deployment on resource-constrained mobile edge devices that previously could only support much smaller models.",
    "source": "arXiv"
  },
  {
    "title": "MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models",
    "title_es": "MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2508.09210",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09210v1 Announce Type: new \nAbstract: Recent advances in multimodal large language models (MLLMs) have catalyzed transformative progress in affective computing, enabling models to exhibit emergent emotional intelligence. Despite substantial methodological progress, current emotional benchmarks remain limited, as it is still unknown: (a) the generalization abilities of MLLMs across distinct scenarios, and (b) their reasoning capabilities to identify the triggering factors behind emotional states. To bridge these gaps, we present \\textbf{MME-Emotion}, a systematic benchmark that assesses both emotional understanding and reasoning capabilities of MLLMs, enjoying \\textit{scalable capacity}, \\textit{diverse settings}, and \\textit{unified protocols}. As the largest emotional intelligence benchmark for MLLMs, MME-Emotion contains over 6,000 curated video clips with task-specific questioning-answering (QA) pairs, spanning broad scenarios to formulate eight emotional tasks. It further incorporates a holistic evaluation suite with hybrid metrics for emotion recognition and reasoning, analyzed through a multi-agent system framework. Through a rigorous evaluation of 20 advanced MLLMs, we uncover both their strengths and limitations, yielding several key insights: \\ding{182} Current MLLMs exhibit unsatisfactory emotional intelligence, with the best-performing model achieving only $39.3\\%$ recognition score and $56.0\\%$ Chain-of-Thought (CoT) score on our benchmark. \\ding{183} Generalist models (\\emph{e.g.}, Gemini-2.5-Pro) derive emotional intelligence from generalized multimodal understanding capabilities, while specialist models (\\emph{e.g.}, R1-Omni) can achieve comparable performance through domain-specific post-training adaptation. By introducing MME-Emotion, we hope that it can serve as a foundation for advancing MLLMs' emotional intelligence in the future.",
    "source": "arXiv"
  },
  {
    "title": "VeriPHY: Physical Layer Signal Authentication for Wireless Communication in 5G Environments",
    "title_es": "VeriPHY: Physical Layer Signal Authentication for Wireless Communication in 5G Environments",
    "url": "https://arxiv.org/abs/2508.09213",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09213v1 Announce Type: new \nAbstract: Physical layer authentication (PLA) uses inherent characteristics of the communication medium to provide secure and efficient authentication in wireless networks, bypassing the need for traditional cryptographic methods. With advancements in deep learning, PLA has become a widely adopted technique for its accuracy and reliability. In this paper, we introduce VeriPHY, a novel deep learning-based PLA solution for 5G networks, which enables unique device identification by embedding signatures within wireless I/Q transmissions using steganography. VeriPHY continuously generates pseudo-random signatures by sampling from Gaussian Mixture Models whose distribution is carefully varied to ensure signature uniqueness and stealthiness over time, and then embeds the newly generated signatures over I/Q samples transmitted by users to the 5G gNB. Utilizing deep neural networks, VeriPHY identifies and authenticates users based on these embedded signatures. VeriPHY achieves high precision, identifying unique signatures between 93% and 100% with low false positive rates and an inference time of 28 ms when signatures are updated every 20 ms. Additionally, we also demonstrate a stealth generation mode where signatures are generated in a way that makes them virtually indistinguishable from unaltered 5G signals while maintaining over 93% detection accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Towards Effective MLLM Jailbreaking Through Balanced On-Topicness and OOD-Intensity",
    "title_es": "Towards Effective MLLM Jailbreaking Through Balanced On-Topicness and OOD-Intensity",
    "url": "https://arxiv.org/abs/2508.09218",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09218v1 Announce Type: new \nAbstract: Multimodal large language models (MLLMs) are widely used in vision-language reasoning tasks. However, their vulnerability to adversarial prompts remains a serious concern, as safety mechanisms often fail to prevent the generation of harmful outputs. Although recent jailbreak strategies report high success rates, many responses classified as \"successful\" are actually benign, vague, or unrelated to the intended malicious goal. This mismatch suggests that current evaluation standards may overestimate the effectiveness of such attacks. To address this issue, we introduce a four-axis evaluation framework that considers input on-topicness, input out-of-distribution (OOD) intensity, output harmfulness, and output refusal rate. This framework identifies truly effective jailbreaks. In a substantial empirical study, we reveal a structural trade-off: highly on-topic prompts are frequently blocked by safety filters, whereas those that are too OOD often evade detection but fail to produce harmful content. However, prompts that balance relevance and novelty are more likely to evade filters and trigger dangerous output. Building on this insight, we develop a recursive rewriting strategy called Balanced Structural Decomposition (BSD). The approach restructures malicious prompts into semantically aligned sub-tasks, while introducing subtle OOD signals and visual cues that make the inputs harder to detect. BSD was tested across 13 commercial and open-source MLLMs, where it consistently led to higher attack success rates, more harmful outputs, and fewer refusals. Compared to previous methods, it improves success rates by $67\\%$ and harmfulness by $21\\%$, revealing a previously underappreciated weakness in current multimodal safety systems.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Ethical Practices in AI: Insights from a Cross-Role, Cross-Region Survey of AI Development Teams",
    "title_es": "Understanding Ethical Practices in AI: Insights from a Cross-Role, Cross-Region Survey of AI Development Teams",
    "url": "https://arxiv.org/abs/2508.09219",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09219v1 Announce Type: new \nAbstract: Recent advances in AI applications have raised growing concerns about the need for ethical guidelines and regulations to mitigate the risks posed by these technologies. In this paper, we present a mixed-method survey study - combining statistical and qualitative analyses - to examine the ethical perceptions, practices, and knowledge of individuals involved in various AI development roles. Our survey includes 414 participants from 43 countries, representing roles such as AI managers, analysts, developers, quality assurance professionals, and information security and privacy experts. The results reveal varying degrees of familiarity and experience with AI ethics principles, government initiatives, and risk mitigation strategies across roles, regions, and other demographic factors. Our findings highlight the importance of a collaborative, role-sensitive approach, involving diverse stakeholders in ethical decision-making throughout the AI development lifecycle. We advocate for developing tailored, inclusive solutions to address ethical challenges in AI development, and we propose future research directions and educational strategies to promote ethics-aware AI practices.",
    "source": "arXiv"
  },
  {
    "title": "Towards Scalable Training for Handwritten Mathematical Expression Recognition",
    "title_es": "Towards Scalable Training for Handwritten Mathematical Expression Recognition",
    "url": "https://arxiv.org/abs/2508.09220",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09220v1 Announce Type: new \nAbstract: Large foundation models have achieved significant performance gains through scalable training on massive datasets. However, the field of \\textbf{H}andwritten \\textbf{M}athematical \\textbf{E}xpression \\textbf{R}ecognition (HMER) has been impeded by the scarcity of data, primarily due to the arduous and costly process of manual annotation. To bridge this gap, we propose a novel method integrating limited handwritten formulas with large-scale LaTeX-rendered formulas by developing a scalable data engine to generate complex and consistent LaTeX sequences. With this engine, we built the largest formula dataset to date, termed \\texttt{Tex80M}, comprising over 80 million high-quality training instances. Then we propose \\texttt{TexTeller}, the first HMER model trained at scale, by mix-training \\texttt{Tex80M} with a relatively small HME dataset. The expansive training dataset and our refined pipeline have equipped \\texttt{TexTeller} with state-of-the-art (SOTA) performance across nearly all benchmarks. To advance the field, we will openly release our complete model, entire dataset, and full codebase, enabling further research building upon our contributions.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical Adaptive networks with Task vectors for Test-Time Adaptation",
    "title_es": "Hierarchical Adaptive networks with Task vectors for Test-Time Adaptation",
    "url": "https://arxiv.org/abs/2508.09223",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09223v1 Announce Type: new \nAbstract: Test-time adaptation allows pretrained models to adjust to incoming data streams, addressing distribution shifts between source and target domains. However, standard methods rely on single-dimensional linear classification layers, which often fail to handle diverse and complex shifts. We propose Hierarchical Adaptive Networks with Task Vectors (Hi-Vec), which leverages multiple layers of increasing size for dynamic test-time adaptation. By decomposing the encoder's representation space into such hierarchically organized layers, Hi-Vec, in a plug-and-play manner, allows existing methods to adapt to shifts of varying complexity. Our contributions are threefold: First, we propose dynamic layer selection for automatic identification of the optimal layer for adaptation to each test batch. Second, we propose a mechanism that merges weights from the dynamic layer to other layers, ensuring all layers receive target information. Third, we propose linear layer agreement that acts as a gating function, preventing erroneous fine-tuning by adaptation on noisy batches. We rigorously evaluate the performance of Hi-Vec in challenging scenarios and on multiple target datasets, proving its strong capability to advance state-of-the-art methods. Our results show that Hi-Vec improves robustness, addresses uncertainty, and handles limited batch sizes and increased outlier rates.",
    "source": "arXiv"
  },
  {
    "title": "From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training",
    "title_es": "From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training",
    "url": "https://arxiv.org/abs/2508.09224",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09224v1 Announce Type: new \nAbstract: Large Language Models used in ChatGPT have traditionally been trained to learn a refusal boundary: depending on the user's intent, the model is taught to either fully comply or outright refuse. While this is a strong mitigation for explicitly malicious prompts, focusing safety training on refusals can lead to brittleness for prompts with obscured user intent. Binary refusal boundaries are especially ill-suited for dual-use cases (such as biology or cybersecurity), where a user request can be answered safely at a high level, but in some cases can lead to malicious uplift if sufficiently detailed or actionable. As an alternative, we propose safe-completions: a safety-training approach that centers on the safety of the assistant's output, rather than a binary classification of the user's intent. Safe-completions seek to maximize helpfulness within the safety policy's constraints. We incorporated this approach into GPT-5 and find that across both production comparisons and internally controlled experiments, safe-completion training improves safety (especially on dual-use prompts), reduces the severity of residual safety failures, and substantially increases model helpfulness.",
    "source": "arXiv"
  },
  {
    "title": "GSMT: Graph Fusion and Spatiotemporal TaskCorrection for Multi-Bus Trajectory Prediction",
    "title_es": "GSMT: Graph Fusion and Spatiotemporal TaskCorrection for Multi-Bus Trajectory Prediction",
    "url": "https://arxiv.org/abs/2508.09227",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09227v1 Announce Type: new \nAbstract: Accurate trajectory prediction for buses is crucial in intelligent transportation systems, particularly within urban environments. In developing regions where access to multimodal data is limited, relying solely on onboard GPS data remains indispensable despite inherent challenges. To address this problem, we propose GSMT, a hybrid model that integrates a Graph Attention Network (GAT) with a sequence-to-sequence Recurrent Neural Network (RNN), and incorporates a task corrector capable of extracting complex behavioral patterns from large-scale trajectory data. The task corrector clusters historical trajectories to identify distinct motion patterns and fine-tunes the predictions generated by the GAT and RNN. Specifically, GSMT fuses dynamic bus information and static station information through embedded hybrid networks to perform trajectory prediction, and applies the task corrector for secondary refinement after the initial predictions are generated. This two-stage approach enables multi-node trajectory prediction among buses operating in dense urban traffic environments under complex conditions. Experiments conducted on a real-world dataset from Kuala Lumpur, Malaysia, demonstrate that our method significantly outperforms existing approaches, achieving superior performance in both short-term and long-term trajectory prediction tasks.",
    "source": "arXiv"
  },
  {
    "title": "Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference",
    "title_es": "Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference",
    "url": "https://arxiv.org/abs/2508.09229",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09229v1 Announce Type: new \nAbstract: Efficient deployment of a pre-trained LLM to a cluster with multiple servers is a critical step for providing fast responses to users' queries. The recent success of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy them efficiently, considering their underlying structure. During the inference in MoE LLMs, only a small part of the experts is selected to process a given token. Moreover, in practice, the experts' load is highly imbalanced. For efficient deployment, one has to distribute the model across a large number of servers using a model placement algorithm. Thus, to improve cluster utilization, the model placement algorithm has to take into account the network topology. This work focuses on the efficient topology-aware placement of the pre-trained MoE LLMs in the inference stage. We propose an integer linear program (ILP) that determines the optimal placement of experts, minimizing the expected number of transmissions. Due to the internal structure, this optimization problem can be solved with a standard ILP solver. We demonstrate that ILP-based placement strategy yields lower network traffic than competitors for small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models.",
    "source": "arXiv"
  },
  {
    "title": "Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems",
    "title_es": "Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems",
    "url": "https://arxiv.org/abs/2508.09230",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09230v1 Announce Type: new \nAbstract: Vision Language Model (VLM)-based agents are stateful, autonomous entities capable of perceiving and interacting with their environments through vision and language. Multi-agent systems comprise specialized agents who collaborate to solve a (complex) task. A core security property is robustness, stating that the system should maintain its integrity under adversarial attacks. However, the design of existing multi-agent systems lacks the robustness consideration, as a successful exploit against one agent can spread and infect other agents to undermine the entire system's assurance. To address this, we propose a new defense approach, Cowpox, to provably enhance the robustness of multi-agent systems. It incorporates a distributed mechanism, which improves the recovery rate of agents by limiting the expected number of infections to other agents. The core idea is to generate and distribute a special cure sample that immunizes an agent against the attack before exposure and helps recover the already infected agents. We demonstrate the effectiveness of Cowpox empirically and provide theoretical robustness guarantees.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Technocratic XAI: The Who, What & How in Explanation Design",
    "title_es": "Beyond Technocratic XAI: The Who, What & How in Explanation Design",
    "url": "https://arxiv.org/abs/2508.09231",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09231v1 Announce Type: new \nAbstract: The field of Explainable AI (XAI) offers a wide range of techniques for making complex models interpretable. Yet, in practice, generating meaningful explanations is a context-dependent task that requires intentional design choices to ensure accessibility and transparency. This paper reframes explanation as a situated design process -- an approach particularly relevant for practitioners involved in building and deploying explainable systems. Drawing on prior research and principles from design thinking, we propose a three-part framework for explanation design in XAI: asking Who needs the explanation, What they need explained, and How that explanation should be delivered. We also emphasize the need for ethical considerations, including risks of epistemic inequality, reinforcing social inequities, and obscuring accountability and governance. By treating explanation as a sociotechnical design process, this framework encourages a context-aware approach to XAI that supports effective communication and the development of ethically responsible explanations.",
    "source": "arXiv"
  },
  {
    "title": "PETLP: A Privacy-by-Design Pipeline for Social Media Data in AI Research",
    "title_es": "PETLP: A Privacy-by-Design Pipeline for Social Media Data in AI Research",
    "url": "https://arxiv.org/abs/2508.09232",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09232v1 Announce Type: new \nAbstract: Social media data presents AI researchers with overlapping obligations under the GDPR, copyright law, and platform terms -- yet existing frameworks fail to integrate these regulatory domains, leaving researchers without unified guidance. We introduce PETLP (Privacy-by-design Extract, Transform, Load, and Present), a compliance framework that embeds legal safeguards directly into extended ETL pipelines. Central to PETLP is treating Data Protection Impact Assessments as living documents that evolve from pre-registration through dissemination. Through systematic Reddit analysis, we demonstrate how extraction rights fundamentally differ between qualifying research organisations (who can invoke DSM Article 3 to override platform restrictions) and commercial entities (bound by terms of service), whilst GDPR obligations apply universally. We reveal why true anonymisation remains unachievable for social media data and expose the legal gap between permitted dataset creation and uncertain model distribution. By structuring compliance decisions into practical workflows and simplifying institutional data management plans, PETLP enables researchers to navigate regulatory complexity with confidence, bridging the gap between legal requirements and research practice.",
    "source": "arXiv"
  },
  {
    "title": "TFZ: Topology-Preserving Compression of 2D Symmetric and Asymmetric Second-Order Tensor Fields",
    "title_es": "TFZ: Topology-Preserving Compression of 2D Symmetric and Asymmetric Second-Order Tensor Fields",
    "url": "https://arxiv.org/abs/2508.09235",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09235v1 Announce Type: new \nAbstract: In this paper, we present a novel compression framework, TFZ, that preserves the topology of 2D symmetric and asymmetric second-order tensor fields defined on flat triangular meshes. A tensor field assigns a tensor - a multi-dimensional array of numbers - to each point in space. Tensor fields, such as the stress and strain tensors, and the Riemann curvature tensor, are essential to both science and engineering. The topology of tensor fields captures the core structure of data, and is useful in various disciplines, such as graphics (for manipulating shapes and textures) and neuroscience (for analyzing brain structures from diffusion MRI). Lossy data compression may distort the topology of tensor fields, thus hindering downstream analysis and visualization tasks. TFZ ensures that certain topological features are preserved during lossy compression. Specifically, TFZ preserves degenerate points essential to the topology of symmetric tensor fields and retains eigenvector and eigenvalue graphs that represent the topology of asymmetric tensor fields. TFZ scans through each cell, preserving the local topology of each cell, and thereby ensuring certain global topological guarantees. We showcase the effectiveness of our framework in enhancing the lossy scientific data compressors SZ3 and SPERR.",
    "source": "arXiv"
  },
  {
    "title": "Blockchain Network Analysis using Quantum Inspired Graph Neural Networks & Ensemble Models",
    "title_es": "Blockchain Network Analysis using Quantum Inspired Graph Neural Networks & Ensemble Models",
    "url": "https://arxiv.org/abs/2508.09237",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09237v1 Announce Type: new \nAbstract: In the rapidly evolving domain of financial technology, the detection of illicit transactions within blockchain networks remains a critical challenge, necessitating robust and innovative solutions. This work proposes a novel approach by combining Quantum Inspired Graph Neural Networks (QI-GNN) with flexibility of choice of an Ensemble Model using QBoost or a classic model such as Random Forrest Classifier. This system is tailored specifically for blockchain network analysis in anti-money laundering (AML) efforts. Our methodology to design this system incorporates a novel component, a Canonical Polyadic (CP) decomposition layer within the graph neural network framework, enhancing its capability to process and analyze complex data structures efficiently. Our technical approach has undergone rigorous evaluation against classical machine learning implementations, achieving an F2 score of 74.8% in detecting fraudulent transactions. These results highlight the potential of quantum-inspired techniques, supplemented by the structural advancements of the CP layer, to not only match but potentially exceed traditional methods in complex network analysis for financial security. The findings advocate for a broader adoption and further exploration of quantum-inspired algorithms within the financial sector to effectively combat fraud.",
    "source": "arXiv"
  },
  {
    "title": "ELASTIC: Event-Tracking Data Synchronization in Soccer Without Annotated Event Locations",
    "title_es": "ELASTIC: Event-Tracking Data Synchronization in Soccer Without Annotated Event Locations",
    "url": "https://arxiv.org/abs/2508.09238",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09238v1 Announce Type: new \nAbstract: The integration of event and tracking data has become essential for advanced analysis in soccer. However, synchronizing these two modalities remains a significant challenge due to temporal and spatial inaccuracies in manually recorded event timestamps. Existing synchronizers typically rely on annotated event locations, which themselves are prone to spatial errors and thus can distort synchronization results. To address this issue, we propose ELASTIC (Event-Location-AgnoSTIC synchronizer), a synchronization framework that only uses features derived from tracking data. ELASTIC also explicitly detects the end times of pass-like events and separates the detection of major and minor events, which improves the completeness of the synchronized output and reduces error cascade across events. We annotated the ground truth timestamps of 2,134 events from three Eredivisie matches to measure the synchronization accuracy, and the experimental results demonstrate that ELASTIC outperforms existing synchronizers by a large margin.",
    "source": "arXiv"
  },
  {
    "title": "Gradient-Direction-Aware Density Control for 3D Gaussian Splatting",
    "title_es": "Gradient-Direction-Aware Density Control for 3D Gaussian Splatting",
    "url": "https://arxiv.org/abs/2508.09239",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09239v1 Announce Type: new \nAbstract: The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced novel view synthesis through explicit scene representation, enabling real-time photorealistic rendering. However, existing approaches manifest two critical limitations in complex scenarios: (1) Over-reconstruction occurs when persistent large Gaussians cannot meet adaptive splitting thresholds during density control. This is exacerbated by conflicting gradient directions that prevent effective splitting of these Gaussians; (2) Over-densification of Gaussians occurs in regions with aligned gradient aggregation, leading to redundant component proliferation. This redundancy significantly increases memory overhead due to unnecessary data retention. We present Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware adaptive density control framework to address these challenges. Our key innovations: the gradient coherence ratio (GCR), computed through normalized gradient vector norms, which explicitly discriminates Gaussians with concordant versus conflicting gradient directions; and a nonlinear dynamic weighting mechanism leverages the GCR to enable gradient-direction-aware density control. Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting operations to enhance geometric details while suppressing redundant concordant-direction Gaussians. Conversely, in cloning processes, GDAGS promotes concordant-direction Gaussian densification for structural completion while preventing conflicting-direction Gaussian overpopulation. Comprehensive evaluations across diverse real-world benchmarks demonstrate that GDAGS achieves superior rendering quality while effectively mitigating over-reconstruction, suppressing over-densification, and constructing compact scene representations with 50\\% reduced memory consumption through optimized Gaussians utilization.",
    "source": "arXiv"
  },
  {
    "title": "NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation",
    "title_es": "NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation",
    "url": "https://arxiv.org/abs/2508.09240",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09240v1 Announce Type: new \nAbstract: The use of Service-Based Architecture in modern telecommunications has exponentially increased Network Functions (NFs) and Application Programming Interfaces (APIs), creating substantial operational complexities in service discovery and management. We introduce \\textit{NEFMind}, a framework leveraging parameter-efficient fine-tuning of open-source Large Language Models (LLMs) to address these challenges. It integrates three core components: synthetic dataset generation from Network Exposure Function (NEF) API specifications, model optimization through Quantized-Low-Rank Adaptation, and performance evaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G Service-Based Architecture APIs, our approach achieves 85% reduction in communication overhead compared to manual discovery methods. Experimental validation using the open-source Phi-2 model demonstrates exceptional API call identification performance at 98-100% accuracy. The fine-tuned Phi-2 model delivers performance comparable to significantly larger models like GPT-4 while maintaining computational efficiency for telecommunications infrastructure deployment. These findings validate domain-specific, parameter-efficient LLM strategies for managing complex API ecosystems in next-generation telecommunications networks.",
    "source": "arXiv"
  },
  {
    "title": "FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents",
    "title_es": "FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents",
    "url": "https://arxiv.org/abs/2508.09241",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09241v1 Announce Type: new \nAbstract: With the rapid advancement of generative artificial intelligence technology, Graphical User Interface (GUI) agents have demonstrated tremendous potential for autonomously managing daily tasks through natural language instructions. However, current evaluation frameworks for GUI agents suffer from fundamental flaws: existing benchmarks overly focus on coarse-grained task completion while neglecting fine-grained control capabilities crucial for real-world applications. To address this, we introduce FineState-Bench, the first evaluation and diagnostic standard for fine-grained GUI proxy operations, designed to quantify fine-grained control. This multi-platform (desktop, Web, mobile) framework includes 2257 task benchmarks in four components and uses a four-phase indicator for comprehensive perception-to-control assessment. To analyze perception and positioning for refined operations, we developed the plug-and-play Visual Diagnostic Assistant (VDA), enabling the first quantitative decoupling analysis of these capabilities. Experimental results on our benchmark show that the most advanced models achieve only 32.8% fine-grained interaction accuracy. Using our VDA in controlled experiments, quantifying the impact of visual capabilities, we showed that ideal visual localization boosts Gemini-2.5-Flash's success rate by 14.9\\%. Our diagnostic framework confirms for the first time that the primary bottleneck for current GUI proxies is basic visual positioning capability.All resources are fully open-source. github: https://github.com/AnonymousThewarehouse/FineState-Bench huggingface: https://huggingface.co/datasets/Willtime2006/Static-FineBench",
    "source": "arXiv"
  },
  {
    "title": "Beyond Blanket Masking: Examining Granularity for Privacy Protection in Images Captured by Blind and Low Vision Users",
    "title_es": "Beyond Blanket Masking: Examining Granularity for Privacy Protection in Images Captured by Blind and Low Vision Users",
    "url": "https://arxiv.org/abs/2508.09245",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09245v1 Announce Type: new \nAbstract: As visual assistant systems powered by visual language models (VLMs) become more prevalent, concerns over user privacy have grown, particularly for blind and low vision users who may unknowingly capture personal private information in their images. Existing privacy protection methods rely on coarse-grained segmentation, which uniformly masks entire private objects, often at the cost of usability. In this work, we propose FiGPriv, a fine-grained privacy protection framework that selectively masks only high-risk private information while preserving low-risk information. Our approach integrates fine-grained segmentation with a data-driven risk scoring mechanism. We evaluate our framework using the BIV-Priv-Seg dataset and show that FiG-Priv preserves +26% of image content, enhancing the ability of VLMs to provide useful responses by 11% and identify the image content by 45%, while ensuring privacy protection. Project Page: https://artcs1.github.io/VLMPrivacy/",
    "source": "arXiv"
  },
  {
    "title": "Harnessing Input-Adaptive Inference for Efficient VLN",
    "title_es": "Harnessing Input-Adaptive Inference for Efficient VLN",
    "url": "https://arxiv.org/abs/2508.09262",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09262v1 Announce Type: new \nAbstract: An emerging paradigm in vision-and-language navigation (VLN) is the use of history-aware multi-modal transformer models. Given a language instruction, these models process observation and navigation history to predict the most appropriate action for an agent. While they have significantly improved performance, the scale of these models can be a bottleneck in practical settings with limited computational resources. In this work, we propose a novel input-adaptive navigation method to enhance VLN model efficiency. We first show that existing input-adaptive mechanisms fail to reduce computations without substantial performance degradation. To address this, we introduce three adaptive algorithms, each deployed at a different level: (1) To improve spatial efficiency, we selectively process panoramic views at each observation of an agent. (2) To improve intra-model efficiency, we propose importance-based adaptive thresholding for the early-exit methods. (3) To improve temporal efficiency, we implement a caching mechanism that prevents reprocessing of views previously seen by the agent. In evaluations on seven VLN benchmarks, we demonstrate over a 2$\\times$ reduction in computation across three off-the-shelf agents in both standard and continuous environments. Our code is publicly available at https://github.com/secure-ai-systems-group/adaptive-vision-and-language-navigation.",
    "source": "arXiv"
  },
  {
    "title": "LLM Empowered Prototype Learning for Zero and Few-Shot Tasks on Tabular Data",
    "title_es": "LLM Empowered Prototype Learning for Zero and Few-Shot Tasks on Tabular Data",
    "url": "https://arxiv.org/abs/2508.09263",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09263v1 Announce Type: new \nAbstract: Recent breakthroughs in large language models (LLMs) have opened the door to in-depth investigation of their potential in tabular data modeling. However, effectively utilizing advanced LLMs in few-shot and even zero-shot scenarios is still challenging. To this end, we propose a novel LLM-based prototype estimation framework for tabular learning. Our key idea is to query the LLM to generate feature values based example-free prompt, which solely relies on task and feature descriptions. With the feature values generated by LLM, we can build a zero-shot prototype in a training-free manner, which can be further enhanced by fusing few-shot samples, avoiding training a classifier or finetuning the LLMs. Thanks to the example-free prompt and prototype estimation, ours bypasses the constraints brought by the example-based prompt, providing a scalable and robust framework. Extensive experiments demonstrate the effectiveness of ours in zero and few-shot tabular learning.",
    "source": "arXiv"
  },
  {
    "title": "Detection of Odor Presence via Deep Neural Networks",
    "title_es": "Detection of Odor Presence via Deep Neural Networks",
    "url": "https://arxiv.org/abs/2508.09264",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09264v1 Announce Type: new \nAbstract: Odor detection underpins food safety, environmental monitoring, medical diagnostics, and many more fields. The current artificial sensors developed for odor detection struggle with complex mixtures while non-invasive recordings lack reliable single-trial fidelity. To develop a general system for odor detection, in this study we present a preliminary work where we aim to test two hypotheses: (i) that spectral features of local field potentials (LFPs) are sufficient for robust single-trial odor detection and (ii) that signals from the olfactory bulb alone are adequate. To test two hypotheses, we propose an ensemble of complementary one-dimensional convolutional networks (ResCNN and AttentionCNN) that decodes the presence of odor from multichannel olfactory bulb LFPs. Tested on 2,349 trials from seven awake mice, our final ensemble model supports both hypotheses, achieving a mean accuracy of 86.6%, an F1-score of 81.0%, and an AUC of 0.9247, substantially outperforming previous benchmarks. In addition, the t-SNE visualization confirms that our framework captures biologically significant signatures. These findings establish the feasibility of robust single-trial detection of the presence of odor from extracellular LFPs, as well as demonstrate the potential of deep learning models to provide a deeper understanding of olfactory representations.",
    "source": "arXiv"
  },
  {
    "title": "Over-Squashing in GNNs and Causal Inference of Rewiring Strategies",
    "title_es": "Over-Squashing in GNNs and Causal Inference of Rewiring Strategies",
    "url": "https://arxiv.org/abs/2508.09265",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09265v1 Announce Type: new \nAbstract: Graph neural networks (GNNs) have exhibited state-of-the-art performance across wide-range of domains such as recommender systems, material design, and drug repurposing. Yet message-passing GNNs suffer from over-squashing -- exponential compression of long-range information from distant nodes -- which limits expressivity. Rewiring techniques can ease this bottleneck; but their practical impacts are unclear due to the lack of a direct empirical over-squashing metric. We propose a rigorous, topology-focused method for assessing over-squashing between node pairs using the decay rate of their mutual sensitivity. We then extend these pairwise assessments to four graph-level statistics (prevalence, intensity, variability, extremity). Coupling these metrics with a within-graph causal design, we quantify how rewiring strategies affect over-squashing on diverse graph- and node-classification benchmarks. Our extensive empirical analyses show that most graph classification datasets suffer from over-squashing (but to various extents), and rewiring effectively mitigates it -- though the degree of mitigation, and its translation into performance gains, varies by dataset and method. We also found that over-squashing is less notable in node classification datasets, where rewiring often increases over-squashing, and performance variations are uncorrelated with over-squashing changes. These findings suggest that rewiring is most beneficial when over-squashing is both substantial and corrected with restraint -- while overly aggressive rewiring, or rewiring applied to minimally over-squashed graphs, is unlikely to help and may even harm performance. Our plug-and-play diagnostic tool lets practitioners decide -- before any training -- whether rewiring is likely to pay off.",
    "source": "arXiv"
  },
  {
    "title": "Unsteady Navier-Stokes Equations On A Stationary Surface",
    "title_es": "Unsteady Navier-Stokes Equations On A Stationary Surface",
    "url": "https://arxiv.org/abs/2508.09266",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09266v1 Announce Type: new \nAbstract: In this paper we consider a fully discrete numerical method for the unsteady Navier-Stokes equations on a smooth closed stationary surface in $\\mathbb{R}^3$. We use the surface finite element method (SFEM) with a generalized Taylor-Hood finite element pair $\\mathrm{\\mathbf{P}}_{k_u}$/$\\mathrm{P}_{k_{pr}}$/$\\mathrm{P}_{k_{\\lambda}}$, where we enforce the tangential condition of the velocity field weakly, by introducing an extra Lagrange multiplier $\\lambda$. Depending on the richness of the finite element space involving this extra Lagrange multiplier we present a full discrete stability and error analysis. For the velocity, we establish optimal $L^{2}(a_h)$-norm bounds ($a_h$ - an energy norm) when $k_\\lambda=k_u$ and suboptimal with respect to the geometric approximation error when $k_{\\lambda} = k_u-1$ (optimal when \\emph{super-parametric finite elements} are used). For the pressure, optimal $L^2(L^2)$-norm error bounds are established when $k_\\lambda=k_u$. Assuming further regularity assumptions for our continuous problem, we are also able to show optimal convergence (using \\emph{super-parametric finite elements} again) when $k_\\lambda=k_u-1$. Numerical simulations that confirm the established theory are provided, along with a comparative analysis against a penalty approach.",
    "source": "arXiv"
  },
  {
    "title": "Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning",
    "title_es": "Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.09275",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09275v1 Announce Type: new \nAbstract: Collaborative multi-agent reinforcement learning (c-MARL) has rapidly evolved, offering state-of-the-art algorithms for real-world applications, including sensitive domains. However, a key challenge to its widespread adoption is the lack of a thorough investigation into its vulnerabilities to adversarial attacks. Existing work predominantly focuses on training-time attacks or unrealistic scenarios, such as access to policy weights or the ability to train surrogate policies. In this paper, we investigate new vulnerabilities under more realistic and constrained conditions, assuming an adversary can only collect and perturb the observations of deployed agents. We also consider scenarios where the adversary has no access at all. We propose simple yet highly effective algorithms for generating adversarial perturbations designed to misalign how victim agents perceive their environment. Our approach is empirically validated on three benchmarks and 22 environments, demonstrating its effectiveness across diverse algorithms and environments. Furthermore, we show that our algorithm is sample-efficient, requiring only 1,000 samples compared to the millions needed by previous methods.",
    "source": "arXiv"
  },
  {
    "title": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning",
    "title_es": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.09277",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09277v1 Announce Type: new \nAbstract: Value function initialization (VFI) is an effective way to achieve a jumpstart in reinforcement learning (RL) by leveraging value estimates from prior tasks. While this approach is well established in tabular settings, extending it to deep reinforcement learning (DRL) poses challenges due to the continuous nature of the state-action space, the noisy approximations of neural networks, and the impracticality of storing all past models for reuse. In this work, we address these challenges and introduce DQInit, a method that adapts value function initialization to DRL. DQInit reuses compact tabular Q-values extracted from previously solved tasks as a transferable knowledge base. It employs a knownness-based mechanism to softly integrate these transferred values into underexplored regions and gradually shift toward the agent's learned estimates, avoiding the limitations of fixed time decay. Our approach offers a novel perspective on knowledge transfer in DRL by relying solely on value estimates rather than policies or demonstrations, effectively combining the strengths of jumpstart RL and policy distillation while mitigating their drawbacks. Experiments across multiple continuous control tasks demonstrate that DQInit consistently improves early learning efficiency, stability, and overall performance compared to standard initialization and existing transfer techniques.",
    "source": "arXiv"
  },
  {
    "title": "Carbon Pricing in Traffic Networks",
    "title_es": "Carbon Pricing in Traffic Networks",
    "url": "https://arxiv.org/abs/2508.09280",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09280v1 Announce Type: new \nAbstract: Traffic is a significant source of global carbon emissions. In this paper, we study how carbon pricing can be used to guide traffic towards equilibria that respect given emission budgets. In particular, we consider a general multi-commodity flow model with flow-dependent externalities. These externalities may represent carbon emissions, entering a priced area, or the traversal of paths regulated by tradable credit schemes.\n  We provide a complete characterization of all flows that can be attained as Wardrop equilibria when assigning a single price to each externality. More precisely, we show that every externality budget achievable by any feasible flow in the network can also be achieved as a Wardrop equilibrium by setting appropriate prices. For extremal and Pareto-minimal budgets, we show that there are prices such that all equilibria respect the budgets. Although the proofs of existence of these particular prices rely on fixed-point arguments and are non-constructive, we show that in the case where the equilibrium minimizes a convex potential, the prices can be obtained as Lagrange multipliers of a suitable convex program. In the case of a single externality, we prove that the total externality caused by the traffic flow is decreasing in the price. For increasing, continuous, and piecewise affine travel time functions with a single externality, we give an output-polynomial algorithm that computes all equilibria implementable by pricing the externality. Even though there are networks where the output size is exponential in the input size, we show that the minimal price obeying a given budget can be computed in polynomial time. This allows the efficient computation of the market price of tradable credit schemes. Overall, our results show that carbon pricing is a viable and (under mild assumptions) tractable approach to achieve all feasible emission goals in traffic networks.",
    "source": "arXiv"
  },
  {
    "title": "Pattern-based Knowledge Component Extraction from Student Code Using Representation Learning",
    "title_es": "Pattern-based Knowledge Component Extraction from Student Code Using Representation Learning",
    "url": "https://arxiv.org/abs/2508.09281",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09281v1 Announce Type: new \nAbstract: Effective personalized learning in computer science education depends on accurately modeling what students know and what they need to learn. While Knowledge Components (KCs) provide a foundation for such modeling, automated KC extraction from student code is inherently challenging due to insufficient explainability of discovered KCs and the open-endedness of programming problems with significant structural variability across student solutions and complex interactions among programming concepts. In this work, we propose a novel, explainable framework for automated KC discovery through pattern-based KCs: recurring structural patterns within student code that capture the specific programming patterns and language constructs that students must master. Toward this, we train a Variational Autoencoder to generate important representative patterns from student code guided by an explainable, attention-based code representation model that identifies important correct and incorrect pattern implementations from student code. These patterns are then clustered to form pattern-based KCs. We evaluate our KCs using two well-established methods informed by Cognitive Science: learning curve analysis and Deep Knowledge Tracing (DKT). Experimental results demonstrate meaningful learning trajectories and significant improvements in DKT predictive performance over traditional KT methods. This work advances knowledge modeling in CS education by providing an automated, scalable, and explainable framework for identifying granular code patterns and algorithmic constructs, essential for student learning.",
    "source": "arXiv"
  },
  {
    "title": "Distilling Reinforcement Learning into Single-Batch Datasets",
    "title_es": "Distilling Reinforcement Learning into Single-Batch Datasets",
    "url": "https://arxiv.org/abs/2508.09283",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09283v1 Announce Type: new \nAbstract: Dataset distillation compresses a large dataset into a small synthetic dataset such that learning on the synthetic dataset approximates learning on the original. Training on the distilled dataset can be performed in as little as one step of gradient descent. We demonstrate that distillation is generalizable to different tasks by distilling reinforcement learning environments into one-batch supervised learning datasets. This demonstrates not only distillation's ability to compress a reinforcement learning task but also its ability to transform one learning modality (reinforcement learning) into another (supervised learning). We present a novel extension of proximal policy optimization for meta-learning and use it in distillation of a multi-dimensional extension of the classic cart-pole problem, all MuJoCo environments, and several Atari games. We demonstrate distillation's ability to compress complex RL environments into one-step supervised learning, explore RL distillation's generalizability across learner architectures, and demonstrate distilling an environment into the smallest-possible synthetic dataset.",
    "source": "arXiv"
  },
  {
    "title": "Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs",
    "title_es": "Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs",
    "url": "https://arxiv.org/abs/2508.09288",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09288v1 Announce Type: new \nAbstract: Large language models (LLMs) remain acutely vulnerable to prompt injection and related jailbreak attacks; heuristic guardrails (rules, filters, LLM judges) are routinely bypassed. We present Contextual Integrity Verification (CIV), an inference-time security architecture that attaches cryptographically signed provenance labels to every token and enforces a source-trust lattice inside the transformer via a pre-softmax hard attention mask (with optional FFN/residual gating). CIV provides deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence higher-trust representations. On benchmarks derived from recent taxonomies of prompt-injection vectors (Elite-Attack + SoK-246), CIV attains 0% attack success rate under the stated threat model while preserving 93.1% token-level similarity and showing no degradation in model perplexity on benign tasks; we note a latency overhead attributable to a non-optimized data path. Because CIV is a lightweight patch -- no fine-tuning required -- we demonstrate drop-in protection for Llama-3-8B and Mistral-7B. We release a reference implementation, an automated certification harness, and the Elite-Attack corpus to support reproducible research.",
    "source": "arXiv"
  },
  {
    "title": "The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards",
    "title_es": "The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards",
    "url": "https://arxiv.org/abs/2508.09292",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09292v1 Announce Type: new \nAbstract: The ability to rapidly adapt to novel and unforeseen environmental changes is a cornerstone of artificial general intelligence (AGI), yet it remains a critical blind spot in most existing AI benchmarks. Traditional evaluation largely focuses on optimizing performance within fixed environments, failing to assess systems' flexibility and generalization capabilities when faced with even subtle rule or structural modifications. Addressing this gap, I introduce the Othello AI Arena, a novel benchmark framework designed to evaluate intelligent systems based on their capacity for limited-time adaptation to unseen environments. Our platform poses a meta-learning challenge: participants must develop systems that can analyze the specific configuration and rules of a novel Othello board within a strict time limit (60 seconds) and generate a tailored, high-performing strategy for that unique environment. With this, evaluation of the meta-level intelligence can be separated from the task-level strategy performance. The Arena features a diverse set of game stages, including public stages for development and private stages with structural and rule variations designed to test genuine adaptive and generalization capabilities. Implemented as an accessible web-based platform, the Arena provides real-time visualization, automated evaluation using multi-dimensional metrics, and comprehensive logging for post-hoc analysis. Initial observations from pilot tests and preliminary student engagements highlight fascinating patterns in adaptation approaches, ranging from rapid parameter tuning to rudimentary environmental model learning through simulation. The Othello AI Arena offers a unique educational tool and a valuable research benchmark for fostering and evaluating the crucial skill of rapid, intelligent adaptation in AI systems.",
    "source": "arXiv"
  },
  {
    "title": "Ethical Medical Image Synthesis",
    "title_es": "Ethical Medical Image Synthesis",
    "url": "https://arxiv.org/abs/2508.09293",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09293v1 Announce Type: new \nAbstract: The task of ethical Medical Image Synthesis (MISyn) is to ensure that the MISyn techniques are researched and developed ethically throughout their entire lifecycle, which is essential to prevent the negative impacts of MISyn. To address the ever-increasing needs and requirements for ethical practice of MISyn research and development, we first conduct a theoretical analysis that identifies the key properties of ethical MISyn and intrinsic limits of MISyn. We identify that synthetic images lack inherent grounding in real medical phenomena, cannot fully represent the training medical images, and inevitably introduce new distribution shifts and biases.\n  Ethical risks can arise from not acknowledging the intrinsic limits and weaknesses of synthetic images compared to medical images, with the extreme form manifested as misinformation of MISyn that substitutes synthetic images for medical images without acknowledgment. The resulting ethical harms include eroding trust in the medical imaging dataset environment and causing algorithmic discrimination towards stakeholders and the public.\n  To facilitate collective efforts towards ethical MISyn within and outside the medical image analysis community, we then propose practical supports for ethical practice in MISyn based on the theoretical analysis, including ethical practice recommendations that adapt the existing technical standards, problem formulation, design, and evaluation practice of MISyn to the ethical challenges; and oversight recommendations to facilitate checks and balances from stakeholders and the public. We also present two case studies that demonstrate how to apply the ethical practice recommendations in practice, and identify gaps between existing practice and the ethical practice recommendations.",
    "source": "arXiv"
  },
  {
    "title": "Based AI improves human decision-making but reduces trust",
    "title_es": "Based AI improves human decision-making but reduces trust",
    "url": "https://arxiv.org/abs/2508.09297",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09297v1 Announce Type: new \nAbstract: Current AI systems minimize risk by enforcing ideological neutrality, yet this may introduce automation bias by suppressing cognitive engagement in human decision-making. We conducted randomized trials with 2,500 participants to test whether culturally biased AI enhances human decision-making. Participants interacted with politically diverse GPT-4o variants on information evaluation tasks. Partisan AI assistants enhanced human performance, increased engagement, and reduced evaluative bias compared to non-biased counterparts, with amplified benefits when participants encountered opposing views. These gains carried a trust penalty: participants underappreciated biased AI and overcredited neutral systems. Exposing participants to two AIs whose biases flanked human perspectives closed the perception-performance gap. These findings complicate conventional wisdom about AI neutrality, suggesting that strategic integration of diverse cultural biases may foster improved and resilient human decision-making.",
    "source": "arXiv"
  },
  {
    "title": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation",
    "title_es": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation",
    "url": "https://arxiv.org/abs/2508.09299",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09299v1 Announce Type: new \nAbstract: Weather forecasting plays a vital role in disaster preparedness, agriculture, and resource management, yet current centralized forecasting systems are increasingly strained by security vulnerabilities, limited scalability, and susceptibility to single points of failure. To address these challenges, we propose a decentralized weather forecasting framework that integrates Federated Learning (FL) with blockchain technology. FL enables collaborative model training without exposing sensitive local data; this approach enhances privacy and reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures transparent and dependable verification of model updates. To further enhance the system's security, we introduce a reputation-based voting mechanism that assesses the trustworthiness of submitted models while utilizing the Interplanetary File System (IPFS) for efficient off-chain storage. Experimental results demonstrate that our approach not only improves forecasting accuracy but also enhances system resilience and scalability, making it a viable candidate for deployment in real-world, security-critical environments.",
    "source": "arXiv"
  },
  {
    "title": "ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning",
    "title_es": "ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.09303",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09303v1 Announce Type: new \nAbstract: Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the limitations of their parametric memory by dynamically gathering relevant facts to address complex reasoning tasks. However, existing approaches suffer from a fundamental architectural limitation: they process search queries strictly sequentially, even when handling inherently parallelizable and logically independent comparisons. This sequential bottleneck significantly constrains computational efficiency, particularly for queries that require multiple entity comparisons. To address this critical limitation, we propose ParallelSearch, a novel reinforcement learning framework that empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple search operations concurrently. Our approach introduces dedicated reward functions that incentivize the identification of independent query components while preserving answer accuracy through jointly considering correctness, query decomposition quality, and parallel execution benefits. Comprehensive experiments demonstrate that ParallelSearch outperforms state-of-the-art baselines by an average performance gain of 2.9% across seven question-answering benchmarks. Notably, on parallelizable questions, our method achieves a 12.7% performance improvement while requiring only 69.6% of the LLM calls compared to sequential approaches.",
    "source": "arXiv"
  },
  {
    "title": "Decision-Making-Based Path Planning for Autonomous UAVs: A Survey",
    "title_es": "Decision-Making-Based Path Planning for Autonomous UAVs: A Survey",
    "url": "https://arxiv.org/abs/2508.09304",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09304v1 Announce Type: new \nAbstract: One of the most critical features for the successful operation of autonomous UAVs is the ability to make decisions based on the information acquired from their surroundings. Each UAV must be able to make decisions during the flight in order to deal with uncertainties in its system and the environment, and to further act upon the information being received. Such decisions influence the future behavior of the UAV, which is expressed as the path plan. Thus, decision-making in path planning is an enabling technique for deploying autonomous UAVs in real-world applications. This survey provides an overview of existing studies that use aspects of decision-making in path planning, presenting the research strands for Exploration Path Planning and Informative Path Planning, and focusing on characteristics of how data have been modeled and understood. Finally, we highlight the existing challenges for relevant topics in this field.",
    "source": "arXiv"
  },
  {
    "title": "Micro-Health Interventions: Exploring Design Strategies for 1-Minute Interventions as a Gateway to Healthy Habits",
    "title_es": "Micro-Health Interventions: Exploring Design Strategies for 1-Minute Interventions as a Gateway to Healthy Habits",
    "url": "https://arxiv.org/abs/2508.09312",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09312v1 Announce Type: new \nAbstract: One-minute behavior change interventions might seem too brief to matter. Could something so short really help people build healthier routines? This work explores this question through two studies examining how ultra-brief prompts might encourage meaningful actions in daily life. In a formative study, we explored how participants engaged with one-minute prompts across four domains: physical activity, eating, screen use, and mental well-being. This revealed two common design approaches: Immediate Action prompts (simple, directive tasks) and Reflection-First prompts (self-awareness before action). We then conducted a 14-day, within-subjects study comparing these two flows with 28 participants. Surprisingly, most participants did not notice differences in structure -- but responded positively when prompts felt timely, relevant, or emotionally supportive. Engagement was not shaped by flow type, but by content fit, tone, and momentary readiness. Participants also co-designed messages, favoring those with step-by-step guidance, personal meaning, or sensory detail. These results suggest that one-minute interventions, while easily dismissed, may serve as meaningful gateways into healthier routines -- if designed to feel helpful in the moment.",
    "source": "arXiv"
  },
  {
    "title": "Reflective Homework as a Learning Tool: Evidence from Comparing Thirteen Years of Dual vs. Single Submission",
    "title_es": "Reflective Homework as a Learning Tool: Evidence from Comparing Thirteen Years of Dual vs. Single Submission",
    "url": "https://arxiv.org/abs/2508.09314",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09314v1 Announce Type: new \nAbstract: Dual-submission homework, where students submit work, receive feedback and then revise has gained attention as a way to foster reflection and discourage reliance on online answer repositories. This study analyzes 13 years of exam data from a computer architecture course to compare student performance under single versus dual-submission homework conditions. Using pooled t-tests on matched exam questions, we found that dual-submission significantly improved outcomes in a majority of cases. The results suggest that reflective resubmission can meaningfully enhance learning and may serve as a useful strategy in today's AI-influenced academic environment. This full research paper also discusses pedagogical implications and study limitations.",
    "source": "arXiv"
  },
  {
    "title": "TPTP World Infrastructure for Non-classical Logics",
    "title_es": "TPTP World Infrastructure for Non-classical Logics",
    "url": "https://arxiv.org/abs/2508.09318",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09318v1 Announce Type: new \nAbstract: The TPTP World is the well established infrastructure that supports research, development, and deployment of Automated Theorem Proving (ATP) systems. The TPTP World supports a range of classical logics, and since release v9.0.0 has supported non-classical logics. This paper provides a self-contained comprehensive overview of the TPTP World infrastructure for ATP in non-classical logics: the non-classical language extension, problems and solutions, and tool support. A detailed description of use of the infrastructure for quantified normal multi-modal logic is given.",
    "source": "arXiv"
  },
  {
    "title": "Exact Verification of Graph Neural Networks with Incremental Constraint Solving",
    "title_es": "Exact Verification of Graph Neural Networks with Incremental Constraint Solving",
    "url": "https://arxiv.org/abs/2508.09320",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09320v1 Announce Type: new \nAbstract: Graph neural networks (GNNs) are increasingly employed in high-stakes applications, such as fraud detection or healthcare, but are susceptible to adversarial attacks. A number of techniques have been proposed to provide adversarial robustness guarantees, but support for commonly used aggregation functions in message-passing GNNs is still lacking. In this paper, we develop an exact (sound and complete) verification method for GNNs to compute guarantees against attribute and structural perturbations that involve edge addition or deletion, subject to budget constraints. Focusing on node classification tasks, our method employs constraint solving with bound tightening, and iteratively solves a sequence of relaxed constraint satisfaction problems while relying on incremental solving capabilities of solvers to improve efficiency. We implement GNNev, a versatile solver for message-passing neural networks, which supports three aggregation functions, sum, max and mean, with the latter two considered here for the first time. Extensive experimental evaluation of GNNev on two standard benchmarks (Cora and CiteSeer) and two real-world fraud datasets (Amazon and Yelp) demonstrates its usability and effectiveness, as well as superior performance compared to existing {exact verification} tools on sum-aggregated node classification tasks.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Large Language Models for Rare Disease Named Entity Recognition",
    "title_es": "Leveraging Large Language Models for Rare Disease Named Entity Recognition",
    "url": "https://arxiv.org/abs/2508.09323",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09323v1 Announce Type: new \nAbstract: Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disease NER under low-resource settings, using a range of prompt-based strategies including zero-shot prompting, few-shot in-context learning, retrieval-augmented generation (RAG), and task-level fine-tuning. We design a structured prompting framework that encodes domain-specific knowledge and disambiguation rules for four entity types. We further introduce two semantically guided few-shot example selection methods to improve in-context performance while reducing labeling effort. Experiments on the RareDis Corpus show that GPT-4o achieves competitive or superior performance compared to BioClinicalBERT, with task-level fine-tuning yielding new state-of-the-art (SOTA) results. Cost-performance analysis reveals that few-shot prompting delivers high returns at low token budgets, while RAG offers marginal additional benefit. An error taxonomy highlights common failure modes such as boundary drift and type confusion, suggesting opportunities for post-processing and hybrid refinement. Our results demonstrate that prompt-optimized LLMs can serve as effective, scalable alternatives to traditional supervised models in biomedical NER, particularly in rare disease applications where annotated data is scarce.",
    "source": "arXiv"
  },
  {
    "title": "TEN: Table Explicitization, Neurosymbolically",
    "title_es": "TEN: Table Explicitization, Neurosymbolically",
    "url": "https://arxiv.org/abs/2508.09324",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09324v1 Announce Type: new \nAbstract: We present a neurosymbolic approach, TEN, for extracting tabular data from semistructured input text. This task is particularly challenging for text input that does not use special delimiters consistently to separate columns and rows. Purely neural approaches perform poorly due to hallucinations and their inability to enforce hard constraints. TEN uses Structural Decomposition prompting - a specialized chain-of-thought prompting approach - on a large language model (LLM) to generate an initial table, and thereafter uses a symbolic checker to evaluate not only the well-formedness of that table, but also detect cases of hallucinations or forgetting. The output of the symbolic checker is processed by a critique-LLM to generate guidance for fixing the table, which is presented to the original LLM in a self-debug loop. Our extensive experiments demonstrate that TEN significantly outperforms purely neural baselines across multiple datasets and metrics, achieving significantly higher exact match accuracy and substantially reduced hallucination rates. A 21-participant user study further confirms that TEN's tables are rated significantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are consistently preferred for ease of verification and correction, with participants favoring our method in over 60% of the cases.",
    "source": "arXiv"
  },
  {
    "title": "SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning",
    "title_es": "SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.09325",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09325v1 Announce Type: new \nAbstract: Visual reinforcement learning (RL) is challenging due to the need to learn both perception and actions from high-dimensional inputs and noisy rewards. Although large perception models exist, integrating them effectively into RL for visual generalization and improved sample efficiency remains unclear. We propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment Anything (SAM) for object-centric decomposition and YOLO-World to ground segments semantically via text prompts. It includes a novel transformer-based architecture that supports a dynamic number of segments at each time step and effectively learns which segments to focus on using online RL, without using human labels. By evaluating SegDAC over a challenging visual generalization benchmark using Maniskill3, which covers diverse manipulation tasks under strong visual perturbations, we demonstrate that SegDAC achieves significantly better visual generalization, doubling prior performance on the hardest setting and matching or surpassing prior methods in sample efficiency across all evaluated tasks.",
    "source": "arXiv"
  },
  {
    "title": "Lung-DDPM+: Efficient Thoracic CT Image Synthesis using Diffusion Probabilistic Model",
    "title_es": "Lung-DDPM+: Efficient Thoracic CT Image Synthesis using Diffusion Probabilistic Model",
    "url": "https://arxiv.org/abs/2508.09327",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09327v1 Announce Type: new \nAbstract: Generative artificial intelligence (AI) has been playing an important role in various domains. Leveraging its high capability to generate high-fidelity and diverse synthetic data, generative AI is widely applied in diagnostic tasks, such as lung cancer diagnosis using computed tomography (CT). However, existing generative models for lung cancer diagnosis suffer from low efficiency and anatomical imprecision, which limit their clinical applicability. To address these drawbacks, we propose Lung-DDPM+, an improved version of our previous model, Lung-DDPM. This novel approach is a denoising diffusion probabilistic model (DDPM) guided by nodule semantic layouts and accelerated by a pulmonary DPM-solver, enabling the method to focus on lesion areas while achieving a better trade-off between sampling efficiency and quality. Evaluation results on the public LIDC-IDRI dataset suggest that the proposed method achieves 8$\\times$ fewer FLOPs (floating point operations per second), 6.8$\\times$ lower GPU memory consumption, and 14$\\times$ faster sampling compared to Lung-DDPM. Moreover, it maintains comparable sample quality to both Lung-DDPM and other state-of-the-art (SOTA) generative models in two downstream segmentation tasks. We also conducted a Visual Turing Test by an experienced radiologist, showing the advanced quality and fidelity of synthetic samples generated by the proposed method. These experimental results demonstrate that Lung-DDPM+ can effectively generate high-quality thoracic CT images with lung nodules, highlighting its potential for broader applications, such as general tumor synthesis and lesion generation in medical imaging. The code and pretrained models are available at https://github.com/Manem-Lab/Lung-DDPM-PLUS.",
    "source": "arXiv"
  },
  {
    "title": "Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization",
    "title_es": "Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization",
    "url": "https://arxiv.org/abs/2508.09330",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09330v1 Announce Type: new \nAbstract: Synaptic pruning in biological brains removes weak connections to improve efficiency. In contrast, dropout regularization in artificial neural networks randomly deactivates neurons without considering activity-dependent pruning. We propose a magnitude-based synaptic pruning method that better reflects biology by progressively removing low-importance connections during training. Integrated directly into the training loop as a dropout replacement, our approach computes weight importance from absolute magnitudes across layers and applies a cubic schedule to gradually increase global sparsity. At fixed intervals, pruning masks permanently remove low-importance weights while maintaining gradient flow for active ones, eliminating the need for separate pruning and fine-tuning phases. Experiments on multiple time series forecasting models including RNN, LSTM, and Patch Time Series Transformer across four datasets show consistent gains. Our method ranked best overall, with statistically significant improvements confirmed by Friedman tests (p < 0.01). In financial forecasting, it reduced Mean Absolute Error by up to 20% over models with no or standard dropout, and up to 52% in select transformer models. This dynamic pruning mechanism advances regularization by coupling weight elimination with progressive sparsification, offering easy integration into diverse architectures. Its strong performance, especially in financial time series forecasting, highlights its potential as a practical alternative to conventional dropout techniques.",
    "source": "arXiv"
  },
  {
    "title": "Teaching Code Refactoring Using LLMs",
    "title_es": "Teaching Code Refactoring Using LLMs",
    "url": "https://arxiv.org/abs/2508.09332",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09332v1 Announce Type: new \nAbstract: This Innovative Practice full paper explores how Large Language Models (LLMs) can enhance the teaching of code refactoring in software engineering courses through real-time, context-aware feedback. Refactoring improves code quality but is difficult to teach, especially with complex, real-world codebases. Traditional methods like code reviews and static analysis tools offer limited, inconsistent feedback. Our approach integrates LLM-assisted refactoring into a course project using structured prompts to help students identify and address code smells such as long methods and low cohesion. Implemented in Spring 2025 in a long-lived OSS project, the intervention is evaluated through student feedback and planned analysis of code quality improvements. Findings suggest that LLMs can bridge theoretical and practical learning, supporting a deeper understanding of maintainability and refactoring principles.",
    "source": "arXiv"
  },
  {
    "title": "RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs",
    "title_es": "RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs",
    "url": "https://arxiv.org/abs/2508.09334",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09334v1 Announce Type: new \nAbstract: We propose RicciFlowRec, a geometric recommendation framework that performs root cause attribution via Ricci curvature and flow on dynamic financial graphs. By modelling evolving interactions among stocks, macroeconomic indicators, and news, we quantify local stress using discrete Ricci curvature and trace shock propagation via Ricci flow. Curvature gradients reveal causal substructures, informing a structural risk-aware ranking function. Preliminary results on S\\&P~500 data with FinBERT-based sentiment show improved robustness and interpretability under synthetic perturbations. This ongoing work supports curvature-based attribution and early-stage risk-aware ranking, with plans for portfolio optimization and return forecasting. To our knowledge, RicciFlowRec is the first recommender to apply geometric flow-based reasoning in financial decision support.",
    "source": "arXiv"
  },
  {
    "title": "Decoding Neural Emotion Patterns through Natural Language Processing Embeddings",
    "title_es": "Decoding Neural Emotion Patterns through Natural Language Processing Embeddings",
    "url": "https://arxiv.org/abs/2508.09337",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09337v1 Announce Type: new \nAbstract: Understanding how emotional expression in language relates to brain function is a challenge in computational neuroscience and affective computing. Traditional neuroimaging is costly and lab-bound, but abundant digital text offers new avenues for emotion-brain mapping. Prior work has largely examined neuroimaging-based emotion localization or computational text analysis separately, with little integration. We propose a computational framework that maps textual emotional content to anatomically defined brain regions without requiring neuroimaging. Using OpenAI's text-embedding-ada-002, we generate high-dimensional semantic representations, apply dimensionality reduction and clustering to identify emotional groups, and map them to 18 brain regions linked to emotional processing. Three experiments were conducted: i) analyzing conversational data from healthy vs. depressed subjects (DIAC-WOZ dataset) to compare mapping patterns, ii) applying the method to the GoEmotions dataset and iii) comparing human-written text with large language model (LLM) responses to assess differences in inferred brain activation. Emotional intensity was scored via lexical analysis. Results showed neuroanatomically plausible mappings with high spatial specificity. Depressed subjects exhibited greater limbic engagement tied to negative affect. Discrete emotions were successfully differentiated. LLM-generated text matched humans in basic emotion distribution but lacked nuanced activation in empathy and self-referential regions (medial prefrontal and posterior cingulate cortex). This cost-effective, scalable approach enables large-scale analysis of naturalistic language, distinguishes between clinical populations, and offers a brain-based benchmark for evaluating AI emotional expression.",
    "source": "arXiv"
  },
  {
    "title": "UltraLight Med-Vision Mamba for Classification of Neoplastic Progression in Tubular Adenomas",
    "title_es": "UltraLight Med-Vision Mamba for Classification of Neoplastic Progression in Tubular Adenomas",
    "url": "https://arxiv.org/abs/2508.09339",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09339v1 Announce Type: new \nAbstract: Identification of precancerous polyps during routine colonoscopy screenings is vital for their excision, lowering the risk of developing colorectal cancer. Advanced deep learning algorithms enable precise adenoma classification and stratification, improving risk assessment accuracy and enabling personalized surveillance protocols that optimize patient outcomes. Ultralight Med-Vision Mamba, a state-space based model (SSM), has excelled in modeling long- and short-range dependencies and image generalization, critical factors for analyzing whole slide images. Furthermore, Ultralight Med-Vision Mamba's efficient architecture offers advantages in both computational speed and scalability, making it a promising tool for real-time clinical deployment.",
    "source": "arXiv"
  },
  {
    "title": "Collective dynamics of strategic classification",
    "title_es": "Collective dynamics of strategic classification",
    "url": "https://arxiv.org/abs/2508.09340",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09340v1 Announce Type: new \nAbstract: Classification algorithms based on Artificial Intelligence (AI) are nowadays applied in high-stakes decisions in finance, healthcare, criminal justice, or education. Individuals can strategically adapt to the information gathered about classifiers, which in turn may require algorithms to be re-trained. Which collective dynamics will result from users' adaptation and algorithms' retraining? We apply evolutionary game theory to address this question. Our framework provides a mathematically rigorous way of treating the problem of feedback loops between collectives of users and institutions, allowing to test interventions to mitigate the adverse effects of strategic adaptation. As a case study, we consider institutions deploying algorithms for credit lending. We consider several scenarios, each representing different interaction paradigms. When algorithms are not robust against strategic manipulation, we are able to capture previous challenges discussed in the strategic classification literature, whereby users either pay excessive costs to meet the institutions' expectations (leading to high social costs) or game the algorithm (e.g., provide fake information). From this baseline setting, we test the role of improving gaming detection and providing algorithmic recourse. We show that increased detection capabilities reduce social costs and could lead to users' improvement; when perfect classifiers are not feasible (likely to occur in practice), algorithmic recourse can steer the dynamics towards high users' improvement rates. The speed at which the institutions re-adapt to the user's population plays a role in the final outcome. Finally, we explore a scenario where strict institutions provide actionable recourse to their unsuccessful users and observe cycling dynamics so far unnoticed in the literature.",
    "source": "arXiv"
  },
  {
    "title": "Affordances of Sketched Notations for Multimodal UI Design and Development Tools",
    "title_es": "Affordances of Sketched Notations for Multimodal UI Design and Development Tools",
    "url": "https://arxiv.org/abs/2508.09342",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09342v1 Announce Type: new \nAbstract: Multimodal UI design and development tools that interpret sketches or natural language descriptions of UIs inherently have notations: the inputs they can understand. In AI-based systems, notations are implicitly defined by the data used to train these systems. In order to create usable and intuitive notations for interactive design systems, we must regard, design, and evaluate these training datasets as notation specifications. To better understand the design space of notational possibilities for future design tools, we use the Cognitive Dimensions of Notations framework to analyze two possible notations for UI sketching. The first notation is the sketching rules for an existing UI sketch dataset, and the second notation is the set of sketches generated by participants in this study, where individuals sketched UIs without imposed representational rules. We imagine two systems, FixedSketch and FlexiSketch, built with each notation respectively, in order to understand the differential affordances of, and potential design requirements for, systems. We find that participants' sketches were composed of element-level notations that are ambiguous in isolation but are interpretable in context within whole designs. For many cognitive dimensions, the FlexiSketch notation supports greater intuitive creative expression and affords lower cognitive effort than the FixedSketch notation, but cannot be supported with prevailing, element-based approaches to UI sketch recognition. We argue that for future multimodal design tools to be truly human-centered, they must adopt contemporary AI methods, including transformer-based and human-in-the-loop, reinforcement learning techniques to understand users' context-rich expressive notations and corrections.",
    "source": "arXiv"
  },
  {
    "title": "Blink-to-code: real-time Morse code communication via eye blink detection and classification",
    "title_es": "Blink-to-code: real-time Morse code communication via eye blink detection and classification",
    "url": "https://arxiv.org/abs/2508.09344",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09344v1 Announce Type: new \nAbstract: This study proposes a real-time system that translates voluntary eye blinks into Morse code, enabling communication for individuals with severe motor impairments. Using a standard webcam and computer vision, the system detects and classifies blinks as short (dot) or long (dash), then decodes them into alphanumeric characters. Experiments with five participants show 62% decoding accuracy and 18-20 seconds response times, demonstrating a viable, low-cost assistive communication method.",
    "source": "arXiv"
  },
  {
    "title": "How Safe Will I Be Given What I Saw? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy",
    "title_es": "How Safe Will I Be Given What I Saw? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy",
    "url": "https://arxiv.org/abs/2508.09346",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09346v1 Announce Type: new \nAbstract: Autonomous robots that rely on deep neural network controllers pose critical challenges for safety prediction, especially under partial observability and distribution shift. Traditional model-based verification techniques are limited in scalability and require access to low-dimensional state models, while model-free methods often lack reliability guarantees. This paper addresses these limitations by introducing a framework for calibrated safety prediction in end-to-end vision-controlled systems, where neither the state-transition model nor the observation model is accessible. Building on the foundation of world models, we leverage variational autoencoders and recurrent predictors to forecast future latent trajectories from raw image sequences and estimate the probability of satisfying safety properties. We distinguish between monolithic and composite prediction pipelines and introduce a calibration mechanism to quantify prediction confidence. In long-horizon predictions from high-dimensional observations, the forecasted inputs to the safety evaluator can deviate significantly from the training distribution due to compounding prediction errors and changing environmental conditions, leading to miscalibrated risk estimates. To address this, we incorporate unsupervised domain adaptation to ensure robustness of safety evaluation under distribution shift in predictions without requiring manual labels. Our formulation provides theoretical calibration guarantees and supports practical evaluation across long prediction horizons. Experimental results on three benchmarks show that our UDA-equipped evaluators maintain high accuracy and substantially lower false positive rates under distribution shift. Similarly, world model-based composite predictors outperform their monolithic counterparts on long-horizon tasks, and our conformal calibration provides reliable statistical bounds.",
    "source": "arXiv"
  },
  {
    "title": "The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains",
    "title_es": "The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains",
    "url": "https://arxiv.org/abs/2508.09349",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09349v1 Announce Type: new \nAbstract: Expert consensus plays a critical role in domains where evidence is complex, conflicting, or insufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and systematic guideline synthesis, offer structure but face limitations including high panel burden, interpretive oversimplification, and suppression of conditional nuance. These challenges are now exacerbated by information overload, fragmentation of the evidence base, and increasing reliance on publicly available sources that lack expert filtering. This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three phases: retrospective replication, prospective comparison, and applied deployment in two applied domains (endurance training and resistance and mixed cardio/strength training). The AI replicated 95% of published expert consensus conclusions in Phase I and showed 95% directional agreement with senior human experts in Phase II, though it lacked experiential and pragmatic nuance. In Phase III, compact panels of six senior experts achieved >90% consensus coverage and reached thematic saturation before the final participant. The AI provided consistent, literature-grounded scaffolding that supported divergence resolution and accelerated saturation. The HAH-Delphi framework offers a flexible, scalable approach for generating high-quality, context-sensitive consensus. Its successful application across health, coaching, and performance science confirms its methodological robustness and supports its use as a foundation for generating conditional, personalised guidance and published consensus frameworks at scale.",
    "source": "arXiv"
  },
  {
    "title": "Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling",
    "title_es": "Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling",
    "url": "https://arxiv.org/abs/2508.09350",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09350v1 Announce Type: new \nAbstract: Textless spoken language models (SLMs) are generative models of speech that do not rely on text supervision. Most textless SLMs learn to predict the next semantic token, a discrete representation of linguistic content, and rely on a separate vocoder to add acoustic information to the generated speech. Such models have no access to acoustic context and no built-in control over acoustic details. In this work, we propose to jointly model linguistic and acoustic information by generating semantic tokens and a continuous real-valued representation of the acoustic frame. We use a flow-matching objective to predict the continuous vector conditioned on the semantic tokens. We study the design space of this approach and find that predicting multiple future semantic tokens helps preserve linguistic information. Our approach achieves comparable performance to existing models in terms of linguistic likelihood benchmarks, while providing better acoustic detail in prompted generation.",
    "source": "arXiv"
  },
  {
    "title": "A Limits Study of Memory-side Tiering Telemetry",
    "title_es": "A Limits Study of Memory-side Tiering Telemetry",
    "url": "https://arxiv.org/abs/2508.09351",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09351v1 Announce Type: new \nAbstract: Increasing workload demands and emerging technologies necessitate the use of various memory and storage tiers in computing systems. This paper presents results from a CXL-based Experimental Memory Request Logger that reveals precise memory access patterns at runtime without interfering with the running workloads. We use it for software emulation of future memory telemetry hardware. By combining reactive placement based on data address monitoring, proactive data movement, and compiler hints, a Hotness Monitoring Unit (HMU) within memory modules can greatly improve memory tiering solutions. Analysis of page placement using profiled access counts on a Deep Learning Recommendation Model (DLRM) indicates a potential 1.94x speedup over Linux NUMA balancing tiering, and only a 3% slowdown compared to Host-DRAM allocation while offloading over 90% of pages to CXL memory. The study underscores the limitations of existing tiering strategies in terms of coverage and accuracy, and makes a strong case for programmable, device-level telemetry as a scalable and efficient solution for future memory systems.",
    "source": "arXiv"
  },
  {
    "title": "CLF-RL: Control Lyapunov Function Guided Reinforcement Learning",
    "title_es": "CLF-RL: Control Lyapunov Function Guided Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.09354",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09354v1 Announce Type: new \nAbstract: Reinforcement learning (RL) has shown promise in generating robust locomotion policies for bipedal robots, but often suffers from tedious reward design and sensitivity to poorly shaped objectives. In this work, we propose a structured reward shaping framework that leverages model-based trajectory generation and control Lyapunov functions (CLFs) to guide policy learning. We explore two model-based planners for generating reference trajectories: a reduced-order linear inverted pendulum (LIP) model for velocity-conditioned motion planning, and a precomputed gait library based on hybrid zero dynamics (HZD) using full-order dynamics. These planners define desired end-effector and joint trajectories, which are used to construct CLF-based rewards that penalize tracking error and encourage rapid convergence. This formulation provides meaningful intermediate rewards, and is straightforward to implement once a reference is available. Both the reference trajectories and CLF shaping are used only during training, resulting in a lightweight policy at deployment. We validate our method both in simulation and through extensive real-world experiments on a Unitree G1 robot. CLF-RL demonstrates significantly improved robustness relative to the baseline RL policy and better performance than a classic tracking reward RL formulation.",
    "source": "arXiv"
  },
  {
    "title": "Virtual Reality User Interface Design: Best Practices and Implementation",
    "title_es": "Virtual Reality User Interface Design: Best Practices and Implementation",
    "url": "https://arxiv.org/abs/2508.09358",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09358v1 Announce Type: new \nAbstract: Designing effective user interfaces (UIs) for virtual reality (VR) is essential to enhance user immersion, usability, comfort, and accessibility in virtual environments. Despite the growing adoption of VR across domains such as education, healthcare, gaming, and rehabilitation, there is a noticeable lack of unified and comprehensive design guidelines for VR UI design. To address this gap, we conducted a systematic literature review to identify existing best practices and propose complete and unified guidelines for UI development in VR.\n  Building on these insights, this research proposes a set of best practices to guide the creation of more effective VR interfaces. To demonstrate and validate these practices, we developed a VR application called \\textit{FlUId} that showcases both good and bad UI design principles for direct comparison. A user study was conducted to evaluate the impact of the proposed guidelines. The findings aim to bridge the gap between theory and practice, offering concrete recommendations for VR designers and developers.",
    "source": "arXiv"
  },
  {
    "title": "An improved local search based algorithm for $k^-$-star partition",
    "title_es": "An improved local search based algorithm for $k^-$-star partition",
    "url": "https://arxiv.org/abs/2508.09361",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09361v1 Announce Type: new \nAbstract: We study the $k^-$-star partition problem that aims to find a minimum collection of vertex-disjoint stars, each having at most $k$ vertices to cover all vertices in a simple undirected graph $G = (V, E)$. Our main contribution is an improved $O(|V|^3)$-time $(\\frac k2 - \\frac {k-2}{8k-14})$-approximation algorithm.\n  Our algorithm starts with a $k^-$-star partition with the least $1$-stars and a key idea is to distinguish critical vertices, each of which is either in a $2$-star or is the center of a $3$-star in the current solution. Our algorithm iteratively updates the solution by three local search operations so that the vertices in each star in the final solution produced cannot be adjacent to too many critical vertices. We present an amortization scheme to prove the approximation ratio in which the critical vertices are allowed to receive more tokens from the optimal solution.",
    "source": "arXiv"
  },
  {
    "title": "FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition",
    "title_es": "FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition",
    "url": "https://arxiv.org/abs/2508.09362",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09362v1 Announce Type: new \nAbstract: Accurate recognition of sign language in healthcare communication poses a significant challenge, requiring frameworks that can accurately interpret complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net, a novel attention-based ensemble of spatiotemporal networks that dynamically fuses visual and motion data to enhance recognition accuracy. The proposed approach processes RGB video and range Doppler map radar modalities synchronously through four different spatiotemporal networks. For each network, features from both modalities are continuously fused using an attention-based fusion module before being fed into an ensemble of classifiers. Finally, the outputs of these four different fused channels are combined in an ensemble classification head, thereby enhancing the model's robustness. Experiments demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for Italian Sign Language. Our findings indicate that an ensemble of diverse spatiotemporal networks, unified by attention-based fusion, yields a robust and accurate framework for complex, multimodal isolated gesture recognition tasks. The source code is available at: https://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.",
    "source": "arXiv"
  },
  {
    "title": "Resurrecting the Salmon: Rethinking Mechanistic Interpretability with Domain-Specific Sparse Autoencoders",
    "title_es": "Resurrecting the Salmon: Rethinking Mechanistic Interpretability with Domain-Specific Sparse Autoencoders",
    "url": "https://arxiv.org/abs/2508.09363",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09363v1 Announce Type: new \nAbstract: Sparse autoencoders (SAEs) decompose large language model (LLM) activations into latent features that reveal mechanistic structure. Conventional SAEs train on broad data distributions, forcing a fixed latent budget to capture only high-frequency, generic patterns. This often results in significant linear ``dark matter'' in reconstruction error and produces latents that fragment or absorb each other, complicating interpretation. We show that restricting SAE training to a well-defined domain (medical text) reallocates capacity to domain-specific features, improving both reconstruction fidelity and interpretability. Training JumpReLU SAEs on layer-20 activations of Gemma-2 models using 195k clinical QA examples, we find that domain-confined SAEs explain up to 20\\% more variance, achieve higher loss recovery, and reduce linear residual error compared to broad-domain SAEs. Automated and human evaluations confirm that learned features align with clinically meaningful concepts (e.g., ``taste sensations'' or ``infectious mononucleosis''), rather than frequent but uninformative tokens. These domain-specific SAEs capture relevant linear structure, leaving a smaller, more purely nonlinear residual. We conclude that domain-confinement mitigates key limitations of broad-domain SAEs, enabling more complete and interpretable latent decompositions, and suggesting the field may need to question ``foundation-model'' scaling for general-purpose SAEs.",
    "source": "arXiv"
  },
  {
    "title": "Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser",
    "title_es": "Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser",
    "url": "https://arxiv.org/abs/2508.09366",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09366v1 Announce Type: new \nAbstract: Log parsing is an essential task in log analysis, and many tools have been designed to accomplish it. Existing log parsers can be categorized into statistic-based and semantic-based approaches. In comparison to semantic-based parsers, existing statistic-based parsers tend to be more efficient, require lower computational costs, and be more privacy-preserving thanks to on-premise deployment, but often fall short in their accuracy (e.g., grouping or parsing accuracy) and generalizability. Therefore, it became a common belief that statistic-based parsers cannot be as effective as semantic-based parsers since the latter could take advantage of external knowledge supported by pretrained language models. Our work, however, challenges this belief with a novel statistic-based parser, PIPLUP. PIPLUP eliminates the pre-assumption of the position of constant tokens for log grouping and relies on data-insensitive parameters to overcome the generalizability challenge, allowing \"plug and play\" on given log files. According to our experiments on an open-sourced large log dataset, PIPLUP shows promising accuracy and generalizability with the data-insensitive default parameter set. PIPLUP not only outperforms the state-of-the-art statistic-based log parsers, Drain and its variants, but also obtains a competitive performance compared to the best unsupervised semantic-based log parser (i.e., LUNAR). Further, PIPLUP exhibits low time consumption without GPU acceleration and external API usage; our simple, efficient, and effective approach makes it more practical in real-world adoptions, especially when costs and privacy are of major concerns.",
    "source": "arXiv"
  },
  {
    "title": "Multidimensional Budget-Feasible Mechanism Design",
    "title_es": "Multidimensional Budget-Feasible Mechanism Design",
    "url": "https://arxiv.org/abs/2508.09367",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09367v1 Announce Type: new \nAbstract: In budget-feasible mechanism design, a buyer wishes to procure a set of items of maximum value from self-interested players. We have a valuation function $v:2^U \\to \\mathbb{R}_+$, where $U$ is the set of all items, where $v(S)$ specifies the value obtained from set $S$ of items. The entirety of current work on budget-feasible mechanisms has focused on the single-dimensional setting, wherein each player holds a single item $e$ and incurs a private cost $c_e$ for supplying item $e$.\n  We introduce multidimensional budget feasible mechanism design: the universe $U$ is now partitioned into item-sets $\\{G_i\\}$ held by the different players, and each player $i$ incurs a private cost $c_i(S_i)$ for supplying the set $S_i\\subseteq G_i$ of items. A budget-feasible mechanism is a mechanism that is truthful, and where the total payment made to the players is at most some given budget $B$. The goal is to devise a budget-feasible mechanism that procures a set of items of large value. We obtain the first approximation guarantees for multidimensional budget feasible mechanism design.\n  Our contributions are threefold. First, we prove an impossibility result showing that the standard benchmark used in single-dimensional budget-feasible mechanism design, namely the algorithmic optimum is inadequate in that no budget-feasible mechanism can achieve good approximation relative to this. We identify that the chief underlying issue here is that there could be a monopolist which prevents a budget-feasible mechanism from obtaining good guarantees. Second, we devise an alternate benchmark, $OPT_{Bench}$, that allows for meaningful approximation guarantees, thereby yielding a metric for comparing mechanisms. Third, we devise budget-feasible mechanisms that achieve constant-factor approximation guarantees with respect to this benchmark for XOS valuations.",
    "source": "arXiv"
  },
  {
    "title": "On-Device Multimodal Federated Learning for Efficient Jamming Detection",
    "title_es": "On-Device Multimodal Federated Learning for Efficient Jamming Detection",
    "url": "https://arxiv.org/abs/2508.09369",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09369v1 Announce Type: new \nAbstract: Wireless networks face severe vulnerabilities from jamming attacks, which can significantly disrupt communication. Existing detection approaches are often unimodal, rely on centralized processing, and demand substantial computational resources, hindering scalability, efficiency, and deployment feasibility. To address these challenges, we introduce a multimodal Federated Learning (FL) framework for on-device jamming detection and classification that integrates spectrograms with cross-layer network Key Performance Indicators (KPIs) through a lightweight dual-encoder architecture equipped with a fusion module and a multimodal projection head. This design enables privacy-preserving training and inference by ensuring that only model parameters are exchanged, while raw data remains on the device. The framework is implemented and evaluated on a wireless experimental testbed using, to the best of our knowledge, the first over-the-air multimodal dataset with synchronized benign and three distinct jamming scenarios. Results show that our approach surpasses state-of-the-art unimodal baselines by up to 15% in detection accuracy, achieves convergence with 60% fewer communication rounds, and maintains low resource usage. Its benefits are most evident under heterogeneous data distributions across devices, where it exhibits strong robustness and reliability.",
    "source": "arXiv"
  },
  {
    "title": "A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition",
    "title_es": "A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition",
    "url": "https://arxiv.org/abs/2508.09372",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09372v1 Announce Type: new \nAbstract: Continuous Sign Language Recognition (CSLR) faces multiple challenges, including significant inter-signer variability and poor generalization to novel sentence structures. Traditional solutions frequently fail to handle these issues efficiently. For overcoming these constraints, we propose a dual-architecture framework. For the Signer-Independent (SI) challenge, we propose a Signer-Invariant Conformer that combines convolutions with multi-head self-attention to learn robust, signer-agnostic representations from pose-based skeletal keypoints. For the Unseen-Sentences (US) task, we designed a Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that captures both fine-grained posture dynamics, enabling the model's ability to comprehend novel grammatical compositions. Experiments on the challenging Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US task, the transformer model scores a WER of 47.78%, surpassing previous work. In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th in the SI task, demonstrating the performance of these models. The findings validate our key hypothesis: that developing task-specific networks designed for the particular challenges of CSLR leads to considerable performance improvements and establishes a new baseline for further research. The source code is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.",
    "source": "arXiv"
  },
  {
    "title": "APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification",
    "title_es": "APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification",
    "url": "https://arxiv.org/abs/2508.09378",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09378v1 Announce Type: new \nAbstract: Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a given task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on manually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based prompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.",
    "source": "arXiv"
  },
  {
    "title": "What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?",
    "title_es": "What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?",
    "url": "https://arxiv.org/abs/2508.09381",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09381v1 Announce Type: new \nAbstract: Medical image segmentation exhibits intra- and inter-annotator variability due to ambiguous object boundaries, annotator preferences, expertise, and tools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated or infiltrative nodules, or irregular borders per the ABCD rule, are particularly prone to disagreement and are often associated with malignancy. In this work, we curate IMA++, the largest multi-annotator skin lesion segmentation dataset, on which we conduct an in-depth study of variability due to annotator, malignancy, tool, and skill factors. We find a statistically significant (p<0.001) association between inter-annotator agreement (IAA), measured using Dice, and the malignancy of skin lesions. We further show that IAA can be accurately predicted directly from dermoscopic images, achieving a mean absolute error of 0.108. Finally, we leverage this association by utilizing IAA as a \"soft\" clinical feature within a multi-task learning objective, yielding a 4.2% improvement in balanced accuracy averaged across multiple model architectures and across IMA++ and four public dermoscopic datasets. The code is available at https://github.com/sfu-mial/skin-IAV.",
    "source": "arXiv"
  },
  {
    "title": "Deviation Inequalities for R\\'{e}nyi Divergence Estimators via Variational Expression",
    "title_es": "Deviation Inequalities for R\\'{e}nyi Divergence Estimators via Variational Expression",
    "url": "https://arxiv.org/abs/2508.09382",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09382v1 Announce Type: new \nAbstract: R\\'enyi divergences play a pivotal role in information theory, statistics, and machine learning. While several estimators of these divergences have been proposed in the literature with their consistency properties established and minimax convergence rates quantified, existing accounts of probabilistic bounds governing the estimation error are premature. Here, we make progress in this regard by establishing exponential deviation inequalities for smoothed plug-in estimators and neural estimators by relating the error to an appropriate empirical process and leveraging tools from empirical process theory. In particular, our approach does not require the underlying distributions to be compactly supported or have densities bounded away from zero, an assumption prevalent in existing results. The deviation inequality also leads to a one-sided concentration bound from the expectation, which is useful in random-coding arguments over continuous alphabets in information theory with potential applications to physical-layer security. As another concrete application, we consider a hypothesis testing framework for auditing R\\'{e}nyi differential privacy using the neural estimator as a test statistic and obtain non-asymptotic performance guarantees for such a test.",
    "source": "arXiv"
  },
  {
    "title": "X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents",
    "title_es": "X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents",
    "url": "https://arxiv.org/abs/2508.09383",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09383v1 Announce Type: new \nAbstract: We present X-UniMotion, a unified and expressive implicit latent representation for whole-body human motion, encompassing facial expressions, body poses, and hand gestures. Unlike prior motion transfer methods that rely on explicit skeletal poses and heuristic cross-identity adjustments, our approach encodes multi-granular motion directly from a single image into a compact set of four disentangled latent tokens -- one for facial expression, one for body pose, and one for each hand. These motion latents are both highly expressive and identity-agnostic, enabling high-fidelity, detailed cross-identity motion transfer across subjects with diverse identities, poses, and spatial configurations. To achieve this, we introduce a self-supervised, end-to-end framework that jointly learns the motion encoder and latent representation alongside a DiT-based video generative model, trained on large-scale, diverse human motion datasets. Motion-identity disentanglement is enforced via 2D spatial and color augmentations, as well as synthetic 3D renderings of cross-identity subject pairs under shared poses. Furthermore, we guide motion token learning with auxiliary decoders that promote fine-grained, semantically aligned, and depth-aware motion embeddings. Extensive experiments show that X-UniMotion outperforms state-of-the-art methods, producing highly expressive animations with superior motion fidelity and identity preservation.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Dementia Speech Alignment with Diffusion-Based Image Generation",
    "title_es": "Understanding Dementia Speech Alignment with Diffusion-Based Image Generation",
    "url": "https://arxiv.org/abs/2508.09385",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09385v1 Announce Type: new \nAbstract: Text-to-image models generate highly realistic images based on natural language descriptions and millions of users use them to create and share images online. While it is expected that such models can align input text and generated image in the same latent space little has been done to understand whether this alignment is possible between pathological speech and generated images. In this work, we examine the ability of such models to align dementia-related speech information with the generated images and develop methods to explain this alignment. Surprisingly, we found that dementia detection is possible from generated images alone achieving 75% accuracy on the ADReSS dataset. We then leverage explainability methods to show which parts of the language contribute to the detection.",
    "source": "arXiv"
  },
  {
    "title": "VIVA: Virtual Healthcare Interactions Using Visual Analytics, With Controllability Through Configuration",
    "title_es": "VIVA: Virtual Healthcare Interactions Using Visual Analytics, With Controllability Through Configuration",
    "url": "https://arxiv.org/abs/2508.09386",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09386v1 Announce Type: new \nAbstract: At the beginning of the COVID-19 pandemic, HealthLink BC (HLBC) rapidly integrated physicians into the triage process of their virtual healthcare service to improve patient outcomes and satisfaction with this service and preserve health care system capacity. We present the design and implementation of a visual analytics tool, VIVA (Virtual healthcare Interactions using Visual Analytics), to support HLBC in analysing various forms of usage data from the service. We abstract HLBC's data and data analysis tasks, which we use to inform our design of VIVA. We also present the interactive workflow abstraction of Scan, Act, Adapt. We validate VIVA's design through three case studies with stakeholder domain experts. We also propose the Controllability Through Configuration model to conduct and analyze design studies, and discuss architectural evolution of VIVA through that lens. It articulates configuration, both that specified by a developer or technical power user and that constructed automatically through log data from previous interactive sessions, as a bridge between the rigidity of hardwired programming and the time-consuming implementation of full end-user interactivity.\n  Availability: Supplemental materials at https://osf.io/wv38n",
    "source": "arXiv"
  },
  {
    "title": "A Nitsche method for Navier--Stokes/generalized poroelasticity interface problems",
    "title_es": "A Nitsche method for Navier--Stokes/generalized poroelasticity interface problems",
    "url": "https://arxiv.org/abs/2508.09388",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09388v1 Announce Type: new \nAbstract: We consider a time-dependent coupled Navier--Stokes/generalized poroelastic flow problem and propose a unified and monolithic finite element discretization based on implicit time stepping. To handle the fluid-structure interface we employ a Nitsche-type formulation. The resulting discrete problem is shown to be well-posed using the theory of differential-algebraic equations (DAEs) and the Banach fixed-point theorem. We prove stability and derive a priori error estimates for the fully discrete scheme. The stability and convergence of the method are ensured by a properly chosen penalty parameter independent of the mesh size. Numerical tests are presented to confirm the theoretical convergence rates and to illustrate the ability of the method to capture the coupled dynamics accurately.",
    "source": "arXiv"
  },
  {
    "title": "DenoDet V2: Phase-Amplitude Cross Denoising for SAR Object Detection",
    "title_es": "DenoDet V2: Phase-Amplitude Cross Denoising for SAR Object Detection",
    "url": "https://arxiv.org/abs/2508.09392",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09392v1 Announce Type: new \nAbstract: One of the primary challenges in Synthetic Aperture Radar (SAR) object detection lies in the pervasive influence of coherent noise. As a common practice, most existing methods, whether handcrafted approaches or deep learning-based methods, employ the analysis or enhancement of object spatial-domain characteristics to achieve implicit denoising. In this paper, we propose DenoDet V2, which explores a completely novel and different perspective to deconstruct and modulate the features in the transform domain via a carefully designed attention architecture. Compared to DenoDet V1, DenoDet V2 is a major advancement that exploits the complementary nature of amplitude and phase information through a band-wise mutual modulation mechanism, which enables a reciprocal enhancement between phase and amplitude spectra. Extensive experiments on various SAR datasets demonstrate the state-of-the-art performance of DenoDet V2. Notably, DenoDet V2 achieves a significant 0.8\\% improvement on SARDet-100K dataset compared to DenoDet V1, while reducing the model complexity by half. The code is available at https://github.com/GrokCV/GrokSAR.",
    "source": "arXiv"
  },
  {
    "title": "Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety",
    "title_es": "Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety",
    "url": "https://arxiv.org/abs/2508.09397",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09397v1 Announce Type: new \nAbstract: Drones operating in complex environments face a significant threat from thin obstacles, such as steel wires and kite strings at the submillimeter level, which are notoriously difficult for conventional sensors like RGB cameras, LiDAR, and depth cameras to detect. This paper introduces SkyShield, an event-driven, end-to-end framework designed for the perception of submillimeter scale obstacles. Drawing upon the unique features that thin obstacles present in the event stream, our method employs a lightweight U-Net architecture and an innovative Dice-Contour Regularization Loss to ensure precise detection. Experimental results demonstrate that our event-based approach achieves mean F1 Score of 0.7088 with a low latency of 21.2 ms, making it ideal for deployment on edge and mobile platforms.",
    "source": "arXiv"
  },
  {
    "title": "Autonomous AI Bird Feeder for Backyard Biodiversity Monitoring",
    "title_es": "Autonomous AI Bird Feeder for Backyard Biodiversity Monitoring",
    "url": "https://arxiv.org/abs/2508.09398",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09398v1 Announce Type: new \nAbstract: This paper presents a low cost, on premise system for autonomous backyard bird monitoring in Belgian urban gardens. A motion triggered IP camera uploads short clips via FTP to a local server, where frames are sampled and birds are localized with Detectron2; cropped regions are then classified by an EfficientNet-B3 model fine tuned on a 40-species Belgian subset derived from a larger Kaggle corpus. All processing runs on commodity hardware without a discrete GPU, preserving privacy and avoiding cloud fees. The physical feeder uses small entry ports (30 mm) to exclude pigeons and reduce nuisance triggers. Detector-guided cropping improves classification accuracy over raw-frame classification. The classifier attains high validation performance on the curated subset (about 99.5 percent) and delivers practical field accuracy (top-1 about 88 percent) on held-out species, demonstrating feasibility for citizen-science-grade biodiversity logging at home.",
    "source": "arXiv"
  },
  {
    "title": "Integrating Feature Attention and Temporal Modeling for Collaborative Financial Risk Assessment",
    "title_es": "Integrating Feature Attention and Temporal Modeling for Collaborative Financial Risk Assessment",
    "url": "https://arxiv.org/abs/2508.09399",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09399v1 Announce Type: new \nAbstract: This paper addresses the challenges of data privacy and collaborative modeling in cross-institution financial risk analysis. It proposes a risk assessment framework based on federated learning. Without sharing raw data, the method enables joint modeling and risk identification across multiple institutions. This is achieved by incorporating a feature attention mechanism and temporal modeling structure. Specifically, the model adopts a distributed optimization strategy. Each financial institution trains a local sub-model. The model parameters are protected using differential privacy and noise injection before being uploaded. A central server then aggregates these parameters to generate a global model. This global model is used for systemic risk identification. To validate the effectiveness of the proposed method, multiple experiments are conducted. These evaluate communication efficiency, model accuracy, systemic risk detection, and cross-market generalization. The results show that the proposed model outperforms both traditional centralized methods and existing federated learning variants across all evaluation metrics. It demonstrates strong modeling capabilities and practical value in sensitive financial environments. The method enhances the scope and efficiency of risk identification while preserving data sovereignty. It offers a secure and efficient solution for intelligent financial risk analysis.",
    "source": "arXiv"
  },
  {
    "title": "Graph Neural Network and Transformer Integration for Unsupervised System Anomaly Discovery",
    "title_es": "Graph Neural Network and Transformer Integration for Unsupervised System Anomaly Discovery",
    "url": "https://arxiv.org/abs/2508.09401",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09401v1 Announce Type: new \nAbstract: This study proposes an unsupervised anomaly detection method for distributed backend service systems, addressing practical challenges such as complex structural dependencies, diverse behavioral evolution, and the absence of labeled data. The method constructs a dynamic graph based on service invocation relationships and applies graph convolution to extract high-order structural representations from multi-hop topologies. A Transformer is used to model the temporal behavior of each node, capturing long-term dependencies and local fluctuations. During the feature fusion stage, a learnable joint embedding mechanism integrates structural and behavioral representations into a unified anomaly vector. A nonlinear mapping is then applied to compute anomaly scores, enabling an end-to-end detection process without supervision. Experiments on real-world cloud monitoring data include sensitivity analyses across different graph depths, sequence lengths, and data perturbations. Results show that the proposed method outperforms existing models on several key metrics, demonstrating stronger expressiveness and stability in capturing anomaly propagation paths and modeling dynamic behavior sequences, with high potential for practical deployment.",
    "source": "arXiv"
  },
  {
    "title": "Realtime Multimodal Emotion Estimation using Behavioral and Neurophysiological Data",
    "title_es": "Realtime Multimodal Emotion Estimation using Behavioral and Neurophysiological Data",
    "url": "https://arxiv.org/abs/2508.09402",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09402v1 Announce Type: new \nAbstract: Many individuals especially those with autism spectrum disorder (ASD), alexithymia, or other neurodivergent profiles face challenges in recognizing, expressing, or interpreting emotions. To support more inclusive and personalized emotion technologies, we present a real-time multimodal emotion estimation system that combines neurophysiological EEG, ECG, blood volume pulse (BVP), and galvanic skin response (GSR/EDA) and behavioral modalities (facial expressions, and speech) in a unified arousal-valence 2D interface to track moment-to-moment emotional states. This architecture enables interpretable, user-specific analysis and supports applications in emotion education, neuroadaptive feedback, and interaction support for neurodiverse users. Two demonstration scenarios illustrate its application: (1) passive media viewing (2D or VR videos) reveals cortical and autonomic responses to affective content, and (2) semi-scripted conversations with a facilitator or virtual agent capture real-time facial and vocal expressions. These tasks enable controlled and naturalistic emotion monitoring, making the system well-suited for personalized feedback and neurodiversity-informed interaction design.",
    "source": "arXiv"
  },
  {
    "title": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models",
    "title_es": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models",
    "url": "https://arxiv.org/abs/2508.09403",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09403v1 Announce Type: new \nAbstract: Expanding the abbreviated column names of tables, such as ``esal'' to ``employee salary'', is critical for numerous downstream data tasks. This problem arises in enterprises, domain sciences, government agencies, and more. In this paper we make three contributions that significantly advances the state of the art. First, we show that synthetic public data used by prior work has major limitations, and we introduce 4 new datasets in enterprise/science domains, with real-world abbreviations. Second, we show that accuracy measures used by prior work seriously undercount correct expansions, and we propose new synonym-aware measures that capture accuracy much more accurately. Finally, we develop Columbo, a powerful LLM-based solution that exploits context, rules, chain-of-thought reasoning, and token-level analysis. Extensive experiments show that Columbo significantly outperforms NameGuess, the current most advanced solution, by 4-29\\%, over 5 datasets. Columbo has been used in production on EDI, a major data portal for environmental sciences.",
    "source": "arXiv"
  },
  {
    "title": "Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving",
    "title_es": "Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.09404",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09404v1 Announce Type: new \nAbstract: Large-scale high-quality 3D motion datasets with multi-person interactions are crucial for data-driven models in autonomous driving to achieve fine-grained pedestrian interaction understanding in dynamic urban environments. However, existing datasets mostly rely on estimating 3D poses from monocular RGB video frames, which suffer from occlusion and lack of temporal continuity, thus resulting in unrealistic and low-quality human motion. In this paper, we introduce Waymo-3DSkelMo, the first large-scale dataset providing high-quality, temporally coherent 3D skeletal motions with explicit interaction semantics, derived from the Waymo Perception dataset. Our key insight is to utilize 3D human body shape and motion priors to enhance the quality of the 3D pose sequences extracted from the raw LiDRA point clouds. The dataset covers over 14,000 seconds across more than 800 real driving scenarios, including rich interactions among an average of 27 agents per scene (with up to 250 agents in the largest scene). Furthermore, we establish 3D pose forecasting benchmarks under varying pedestrian densities, and the results demonstrate its value as a foundational resource for future research on fine-grained human behavior understanding in complex urban environments. The dataset and code will be available at https://github.com/GuangxunZhu/Waymo-3DSkelMo",
    "source": "arXiv"
  },
  {
    "title": "Trigonometric Interpolation Based Approach for Second Order Fredholm Integro-Differential Equations",
    "title_es": "Trigonometric Interpolation Based Approach for Second Order Fredholm Integro-Differential Equations",
    "url": "https://arxiv.org/abs/2508.09413",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09413v1 Announce Type: new \nAbstract: A trigonometric interpolation algorithm for non-periodic functions has been recently proposed and applied to study general ordinary differential equation (ODE). This paper enhances the algorithm to approximate functions in $2$-dim space. Performance of the enhanced algorithm is expected to be similar as in $1$-dim case and achieve accuracy aligned with the smoothness of the target function, which is confirmed by numerical examples.\n  As an application, the $2$-dim trigonometric interpolation method is used to develop an algorithm for the solution of a second order Fredholm integro-differential equation (FIDE). There are several advantages of the algorithm. First of all, it converges quickly and high accuracy can be achieved with a moderate size of grid points; Secondly, it can effectively address singularities of kernel functions and work well with general boundary conditions. Finally, it can be enhanced to copy with other IDE such as Volterra IDE or IDE with high order ODE component. The tests conducted in this paper include various boundary conditions with both continuous kernels and integrable ones with singularity. Decent performance is observed across all covered scenarios with a moderate size of grid points.",
    "source": "arXiv"
  },
  {
    "title": "RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata",
    "title_es": "RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata",
    "url": "https://arxiv.org/abs/2508.09415",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09415v1 Announce Type: new \nAbstract: Curb ramps are critical for urban accessibility, but robustly detecting them in images remains an open problem due to the lack of large-scale, high-quality datasets. While prior work has attempted to improve data availability with crowdsourced or manually labeled data, these efforts often fall short in either quality or scale. In this paper, we introduce and evaluate a two-stage pipeline called RampNet to scale curb ramp detection datasets and improve model performance. In Stage 1, we generate a dataset of more than 210,000 annotated Google Street View (GSV) panoramas by auto-translating government-provided curb ramp location data to pixel coordinates in panoramic images. In Stage 2, we train a curb ramp detection model (modified ConvNeXt V2) from the generated dataset, achieving state-of-the-art performance. To evaluate both stages of our pipeline, we compare to manually labeled panoramas. Our generated dataset achieves 94.0% precision and 92.5% recall, and our detection model reaches 0.9236 AP -- far exceeding prior work. Our work contributes the first large-scale, high-quality curb ramp detection dataset, benchmark, and model.",
    "source": "arXiv"
  },
  {
    "title": "Domain-Generalization to Improve Learning in Meta-Learning Algorithms",
    "title_es": "Domain-Generalization to Improve Learning in Meta-Learning Algorithms",
    "url": "https://arxiv.org/abs/2508.09418",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09418v1 Announce Type: new \nAbstract: This paper introduces Domain Generalization Sharpness-Aware Minimization Model-Agnostic Meta-Learning (DGS-MAML), a novel meta-learning algorithm designed to generalize across tasks with limited training data. DGS-MAML combines gradient matching with sharpness-aware minimization in a bi-level optimization framework to enhance model adaptability and robustness. We support our method with theoretical analysis using PAC-Bayes and convergence guarantees. Experimental results on benchmark datasets show that DGS-MAML outperforms existing approaches in terms of accuracy and generalization. The proposed method is particularly useful for scenarios requiring few-shot learning and quick adaptation, and the source code is publicly available at GitHub.",
    "source": "arXiv"
  },
  {
    "title": "Design and Simulation of 6T SRAM Array",
    "title_es": "Design and Simulation of 6T SRAM Array",
    "url": "https://arxiv.org/abs/2508.09419",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09419v1 Announce Type: new \nAbstract: Conventional 6T SRAM is used in microprocessors in the cache memory design. The basic 6T SRAM cell and a 6 bit memory array layout are designed in LEdit. The design and analysis of key SRAM components, sense amplifiers, decoders, write drivers and precharge circuits are also provided. The pulse voltage waveforms generated for read and write operations as well as Q and Qbar nodes are simulated in LTSpice. Parasitic capacitances are extracted and their impact on the waveforms analyzed. Static noise margin, propagation delays, and power dissipation are calculated. Comparison of SRAM read and write operational performance using CMOS transistors is made with edge-triggered D flip flops. If certain size area and ratio constraints are satisfied, the 6T cell with CMOS transistors will possess stability, speed, and power efficiency. Both theoretical and simulated results are given.",
    "source": "arXiv"
  },
  {
    "title": "Control Systems Analysis of a 3-Axis Photovoltatic Solar Tracker for Water Pumping",
    "title_es": "Control Systems Analysis of a 3-Axis Photovoltatic Solar Tracker for Water Pumping",
    "url": "https://arxiv.org/abs/2508.09420",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09420v1 Announce Type: new \nAbstract: We propose 3-axis solar tracker water pumping system. The solar tracker can rotate and tilt using stepper/DC motors and can rise and lower on a tripod using a linear actuator. The charge generated from solar energy absorbed by photovoltaic (PV) cells in the solar panel is stored in a 12V battery that in turn powers two water diaphragm pumps using a solar charge controller. The PV uses four light photocell resistors/sensors to measure light intensity. A solar tracking algorithm determines the optimal angle for PV positioning. Using an ultrasonic sensor to measure the water level in a reservoir water tank, water is pumped from one water tank to the reservoir. Based on soil moisture sensor levels, a second water pump supplies water from the reservoir to the plant. The system is analyzed from a control systems perspective. The transfer functions, root loci, and Bode plots are generated and simulated and experimental results are provided as well as stability and steady-state error analysis.",
    "source": "arXiv"
  },
  {
    "title": "A Classical Quadratic Speedup for Planted $k$XOR",
    "title_es": "A Classical Quadratic Speedup for Planted $k$XOR",
    "url": "https://arxiv.org/abs/2508.09422",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09422v1 Announce Type: new \nAbstract: A recent work of Schmidhuber et al (QIP, SODA, & Phys. Rev. X 2025) exhibited a quantum algorithm for the noisy planted $k$XOR problem running quartically faster than all known classical algorithms. In this work, we design a new classical algorithm that is quadratically faster than the best previous one, in the case of large constant $k$. Thus for such $k$, the quantum speedup of Schmidhuber et al. becomes only quadratic (though it retains a space advantage). Our algorithm, which also works in the semirandom case, combines tools from sublinear-time algorithms (essentially, the birthday paradox) and polynomial anticoncentration.",
    "source": "arXiv"
  },
  {
    "title": "Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation",
    "title_es": "Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation",
    "url": "https://arxiv.org/abs/2508.09423",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09423v1 Announce Type: new \nAbstract: The Object Goal Navigation (ObjectNav) task challenges agents to locate a specified object in an unseen environment by imagining unobserved regions of the scene. Prior approaches rely on deterministic and discriminative models to complete semantic maps, overlooking the inherent uncertainty in indoor layouts and limiting their ability to generalize to unseen environments. In this work, we propose GOAL, a generative flow-based framework that models the semantic distribution of indoor environments by bridging observed regions with LLM-enriched full-scene semantic maps. During training, spatial priors inferred from large language models (LLMs) are encoded as two-dimensional Gaussian fields and injected into target maps, distilling rich contextual knowledge into the flow model and enabling more generalizable completions. Extensive experiments demonstrate that GOAL achieves state-of-the-art performance on MP3D and Gibson, and shows strong generalization in transfer settings to HM3D. Codes and pretrained models are available at https://github.com/Badi-Li/GOAL.",
    "source": "arXiv"
  },
  {
    "title": "Imperfect Competition in Markets for Short-Circuit Current Services",
    "title_es": "Imperfect Competition in Markets for Short-Circuit Current Services",
    "url": "https://arxiv.org/abs/2508.09425",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09425v1 Announce Type: new \nAbstract: An important limitation of Inverter-Based Resources (IBR) is their reduced contribution to Short-Circuit Current (SCC), as compared to that of Synchronous Generators (SGs). With increasing penetration of IBR in most power systems, the reducing SCC poses challenges to a secure system operation, as line protections may not trip when required. In order to address this issue, the SCC ancillary service could be procured via an economic mechanism, aiming at securing adequate SCC on all buses. However, the suitability of markets for SCC services is not well understood, given that these could be prone to market-power issues: since the SCC contributions from various SGs to a certain bus are determined by the electrical topology of the grid, this is a highly local service. It is necessary to understand if SGs at advantageous electrical locations could exert market power and, if so, how it could be mitigated. In order to fill this gap, this paper adopts an SCC-constrained bilevel model to investigate strategic behaviors of SGs. To address the non-convexity due to unit commitment variables, the model is restructured through a primal-dual formulation. Based on a modified IEEE 30-bus system, cases with strategic SGs placed at different buses are analyzed. These studies demonstrate that agents exerting market power could achieve up to triple revenues from SCC provision, highlighting the need to carefully design these markets.",
    "source": "arXiv"
  },
  {
    "title": "Security Analysis of ChatGPT: Threats and Privacy Risks",
    "title_es": "Security Analysis of ChatGPT: Threats and Privacy Risks",
    "url": "https://arxiv.org/abs/2508.09426",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09426v1 Announce Type: new \nAbstract: As artificial intelligence technology continues to advance, chatbots are becoming increasingly powerful. Among them, ChatGPT, launched by OpenAI, has garnered widespread attention globally due to its powerful natural language processing capabilities based on the GPT model, which enables it to engage in natural conversations with users, understand various forms of linguistic expressions, and generate useful information and suggestions. However, as its application scope expands, user demand grows, and malicious attacks related to it become increasingly frequent, the security threats and privacy risks faced by ChatGPT are gradually coming to the forefront. In this paper, the security of ChatGPT is mainly studied from two aspects, security threats and privacy risks. The article systematically analyzes various types of vulnerabilities involved in the above two types of problems and their causes. Briefly, we discuss the controversies that ChatGPT may cause at the ethical and moral levels. In addition, this paper reproduces several network attack and defense test scenarios by simulating the attacker's perspective and methodology. Simultaneously, it explores the feasibility of using ChatGPT for security vulnerability detection and security tool generation from the defender's perspective.",
    "source": "arXiv"
  },
  {
    "title": "Implicit Hypergraph Neural Networks: A Stable Framework for Higher-Order Relational Learning with Provable Guarantees",
    "title_es": "Implicit Hypergraph Neural Networks: A Stable Framework for Higher-Order Relational Learning with Provable Guarantees",
    "url": "https://arxiv.org/abs/2508.09427",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09427v1 Announce Type: new \nAbstract: Many real-world interactions are group-based rather than pairwise such as papers with multiple co-authors and users jointly engaging with items. Hypergraph neural networks have shown great promise at modeling higher-order relations, but their reliance on a fixed number of explicit message-passing layers limits long-range dependency capture and can destabilize training as depth grows. In this work, we introduce Implicit Hypergraph Neural Networks (IHGNN), which bring the implicit equilibrium formulation to hypergraphs: instead of stacking layers, IHGNN computes representations as the solution to a nonlinear fixed-point equation, enabling stable and efficient global propagation across hyperedges without deep architectures. We develop a well-posed training scheme with provable convergence, analyze the oversmoothing conditions and expressivity of the model, and derive a transductive generalization bound on hypergraphs. We further present an implicit-gradient training procedure coupled with a projection-based stabilization strategy. Extensive experiments on citation benchmarks show that IHGNN consistently outperforms strong traditional graph/hypergraph neural network baselines in both accuracy and robustness. Empirically, IHGNN is resilient to random initialization and hyperparameter variation, highlighting its strong generalization and practical value for higher-order relational learning.",
    "source": "arXiv"
  },
  {
    "title": "What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset",
    "title_es": "What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset",
    "url": "https://arxiv.org/abs/2508.09428",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09428v1 Announce Type: new \nAbstract: People control their bodies to establish contact with the environment. To comprehensively understand actions across diverse visual contexts, it is essential to simultaneously consider \\textbf{what} action is occurring and \\textbf{where} it is happening. Current methodologies, however, often inadequately capture this duality, typically failing to jointly model both action semantics and their spatial contextualization within scenes. To bridge this gap, we introduce a novel vision task that simultaneously predicts high-level action semantics and fine-grained body-part contact regions. Our proposed framework, PaIR-Net, comprises three key components: the Contact Prior Aware Module (CPAM) for identifying contact-relevant body parts, the Prior-Guided Concat Segmenter (PGCS) for pixel-wise contact segmentation, and the Interaction Inference Module (IIM) responsible for integrating global interaction relationships. To facilitate this task, we present PaIR (Part-aware Interaction Representation), a comprehensive dataset containing 13,979 images that encompass 654 actions, 80 object categories, and 17 body parts. Experimental evaluation demonstrates that PaIR-Net significantly outperforms baseline approaches, while ablation studies confirm the efficacy of each architectural component. The code and dataset will be released upon publication.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech",
    "title_es": "Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech",
    "url": "https://arxiv.org/abs/2508.09430",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09430v1 Announce Type: new \nAbstract: Code-switching and language identification in child-directed scenarios present significant challenges, particularly in bilingual environments. This paper addresses this challenge by using Zipformer to handle the nuances of speech, which contains two imbalanced languages, Mandarin and English, in an utterance. This work demonstrates that the internal layers of the Zipformer effectively encode the language characteristics, which can be leveraged in language identification. We present the selection methodology of the inner layers to extract the embeddings and make a comparison with different back-ends. Our analysis shows that Zipformer is robust across these backends. Our approach effectively handles imbalanced data, achieving a Balanced Accuracy (BAC) of 81.89%, a 15.47% improvement over the language identification baseline. These findings highlight the potential of the transformer encoder architecture model in real scenarios.",
    "source": "arXiv"
  },
  {
    "title": "From Micro to Macro Flow Modeling: Characterizing Heterogeneity of Mixed-Autonomy Traffic",
    "title_es": "From Micro to Macro Flow Modeling: Characterizing Heterogeneity of Mixed-Autonomy Traffic",
    "url": "https://arxiv.org/abs/2508.09432",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09432v1 Announce Type: new \nAbstract: Most autonomous-vehicles (AVs) driving strategies are designed and analyzed at the vehicle level, yet their aggregate impact on macroscopic traffic flow is still not understood, particularly the flow heterogeneity that emerges when AVs interact with human-driven vehicles (HVs). Existing validation techniques for macroscopic flow models rely on high-resolution spatiotemporal data spanning entire road segments which are rarely available for mixed-autonomy traffic. AVs record detailed Lagrangian trajectories of the ego vehicle and surrounding traffic through onboard sensors. Leveraging these Lagrangian observations to validate mixed-autonomy flow models therefore remains an open research challenge. This paper closes the gap between microscopic Lagrangian data and macroscopic Euclidean traffic models by introducing a continuous traffic-heterogeneity attribute. We represent traffic flow with two coupled conservation laws with one for vehicle number and one for the traffic attribute. Reconstruction methods are designed to derive the traffic attribute from Lagrangian vehicle trajectories. When abundant trajectory data are available, we characterize traffic heterogeneity by extracting drivers' desired speed and local behavioral uncertainty from trajectories. In data-scarce mixed traffic, we design an end-to-end mapping that infers the traffic heterogeneity solely from trajectories in the current spatiotemporal region. Experiments across multiple traffic datasets show that the proposed model effectively captures traffic heterogeneity by clustering the fundamental diagram scatter into attribute-based groups. The calibration errors of traffic flow dynamics are also reduce by 20% relative to the Aw-Rascle-Zhang model benchmark. Detailed analyses further show that the model generalizes well, maintaining nearly the same accuracy when evaluated under a variety of previously unseen traffic conditions.",
    "source": "arXiv"
  },
  {
    "title": "Generalized Plane Wave quasi-Trefftz spaces for wave propagation in inhomogeneous media",
    "title_es": "Generalized Plane Wave quasi-Trefftz spaces for wave propagation in inhomogeneous media",
    "url": "https://arxiv.org/abs/2508.09435",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09435v1 Announce Type: new \nAbstract: Partial Differential Equations (PDEs) models for wave propagation in inhomogeneous media are relevant for many applications. We will discuss numerical methods tailored for tackling problems governed by these variable-coefficient PDEs. Trefftz methods rely, in broad terms, on the idea of approximating solutions to PDEs via Galerkin methods using basis functions that are exact solutions of the PDE, making explicit use of information about the ambient medium. However, wave propagation in inhomogeneous media is modeled by PDEs with variable coefficients, and in general no exact solutions are available. Quasi-Trefftz methods have been introduced, in the case of the Helmholtz equation, to address this problem: they rely instead on high-order approximate solutions constructed locally. We will discuss basis of Generalized Plane Waves, a particular kind of quasi-Trefftz functions, and how their construction can be related to the construction of polynomial quasi-Trefftz bases.",
    "source": "arXiv"
  },
  {
    "title": "Fulfillment of the Work Games: Warehouse Workers' Experiences with Algorithmic Management",
    "title_es": "Fulfillment of the Work Games: Warehouse Workers' Experiences with Algorithmic Management",
    "url": "https://arxiv.org/abs/2508.09438",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09438v1 Announce Type: new \nAbstract: The introduction of algorithms into a large number of industries has already restructured the landscape of work and threatens to continue. While a growing body of CSCW research centered on the future of work has begun to document these shifts, relatively little is known about workers' experiences beyond those of platform-mediated gig workers. In this paper, we turn to a traditional work sector, Amazon fulfillment centers (FC), to deepen our field's empirical examination of algorithmic management. Drawing on two years of ethnographic research, we show how FC workers react to managers' interventions, imposed productivity rates, and quantified objectification when subjected to labor-tracking systems in their physical work environments. Situating FC workers' resistance to algorithmic systems and metrics within the current CSCW literature allows us to explicate and link the nuanced practices of FC workers to the larger discourse of algorithmic control mechanisms. In addition, we show how FC workers' resistance practices are emblematic of 'work games'--a long-studied means by which workers agentically configure (\"trick\") their engagement within work systems. We argue that gaining a more nuanced understanding of workers' resistance and consent in relation to algorithmic management expands our ability to critique and potentially disassemble the economic and political forces at the root of these sociotechnical labor systems.",
    "source": "arXiv"
  },
  {
    "title": "Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference",
    "title_es": "Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference",
    "url": "https://arxiv.org/abs/2508.09442",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09442v1 Announce Type: new \nAbstract: The Key-Value (KV) cache, which stores intermediate attention computations (Key and Value pairs) to avoid redundant calculations, is a fundamental mechanism for accelerating Large Language Model (LLM) inference. However, this efficiency optimization introduces significant yet underexplored privacy risks. This paper provides the first comprehensive analysis of these vulnerabilities, demonstrating that an attacker can reconstruct sensitive user inputs directly from the KV-cache. We design and implement three distinct attack vectors: a direct Inversion Attack, a more broadly applicable and potent Collision Attack, and a semantic-based Injection Attack. These methods demonstrate the practicality and severity of KV-cache privacy leakage issues. To mitigate this, we propose KV-Cloak, a novel, lightweight, and efficient defense mechanism. KV-Cloak uses a reversible matrix-based obfuscation scheme, combined with operator fusion, to secure the KV-cache. Our extensive experiments show that KV-Cloak effectively thwarts all proposed attacks, reducing reconstruction quality to random noise. Crucially, it achieves this robust security with virtually no degradation in model accuracy and minimal performance overhead, offering a practical solution for trustworthy LLM deployment.",
    "source": "arXiv"
  },
  {
    "title": "DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation",
    "title_es": "DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation",
    "url": "https://arxiv.org/abs/2508.09444",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09444v1 Announce Type: new \nAbstract: Vision-Language Navigation in Continuous Environments (VLN-CE) requires agents to follow natural language instructions through free-form 3D spaces. Existing VLN-CE approaches typically use a two-stage waypoint planning framework, where a high-level waypoint predictor generates the navigable waypoints, and then a navigation planner suggests the intermediate goals in the high-level action space. However, this two-stage decomposition framework suffers from: (1) global sub-optimization due to the proxy objective in each stage, and (2) a performance bottleneck caused by the strong reliance on the quality of the first-stage predicted waypoints. To address these limitations, we propose DAgger Diffusion Navigation (DifNav), an end-to-end optimized VLN-CE policy that unifies the traditional two stages, i.e. waypoint generation and planning, into a single diffusion policy. Notably, DifNav employs a conditional diffusion policy to directly model multi-modal action distributions over future actions in continuous navigation space, eliminating the need for a waypoint predictor while enabling the agent to capture multiple possible instruction-following behaviors. To address the issues of compounding error in imitation learning and enhance spatial reasoning in long-horizon navigation tasks, we employ DAgger for online policy training and expert trajectory augmentation, and use the aggregated data to further fine-tune the policy. This approach significantly improves the policy's robustness and its ability to recover from error states. Extensive experiments on benchmark datasets demonstrate that, even without a waypoint predictor, the proposed method substantially outperforms previous state-of-the-art two-stage waypoint-based models in terms of navigation performance. Our code is available at: https://github.com/Tokishx/DifNav.",
    "source": "arXiv"
  },
  {
    "title": "MPT: Motion Prompt Tuning for Micro-Expression Recognition",
    "title_es": "MPT: Motion Prompt Tuning for Micro-Expression Recognition",
    "url": "https://arxiv.org/abs/2508.09446",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09446v1 Announce Type: new \nAbstract: Micro-expression recognition (MER) is crucial in the affective computing field due to its wide application in medical diagnosis, lie detection, and criminal investigation. Despite its significance, obtaining micro-expression (ME) annotations is challenging due to the expertise required from psychological professionals. Consequently, ME datasets often suffer from a scarcity of training samples, severely constraining the learning of MER models. While current large pre-training models (LMs) offer general and discriminative representations, their direct application to MER is hindered by an inability to capture transitory and subtle facial movements-essential elements for effective MER. This paper introduces Motion Prompt Tuning (MPT) as a novel approach to adapting LMs for MER, representing a pioneering method for subtle motion prompt tuning. Particularly, we introduce motion prompt generation, including motion magnification and Gaussian tokenization, to extract subtle motions as prompts for LMs. Additionally, a group adapter is carefully designed and inserted into the LM to enhance it in the target MER domain, facilitating a more nuanced distinction of ME representation. Furthermore, extensive experiments conducted on three widely used MER datasets demonstrate that our proposed MPT consistently surpasses state-of-the-art approaches and verifies its effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "NEXICA: Discovering Road Traffic Causality (Extended arXiv Version)",
    "title_es": "NEXICA: Discovering Road Traffic Causality (Extended arXiv Version)",
    "url": "https://arxiv.org/abs/2508.09447",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09447v1 Announce Type: new \nAbstract: Road traffic congestion is a persistent problem. Focusing resources on the causes of congestion is a potentially efficient strategy for reducing slowdowns. We present NEXICA, an algorithm to discover which parts of the highway system tend to cause slowdowns on other parts of the highway. We use time series of road speeds as inputs to our causal discovery algorithm. Finding other algorithms inadequate, we develop a new approach that is novel in three ways. First, it concentrates on just the presence or absence of events in the time series, where an event indicates the temporal beginning of a traffic slowdown. Second, we develop a probabilistic model using maximum likelihood estimation to compute the probabilities of spontaneous and caused slowdowns between two locations on the highway. Third, we train a binary classifier to identify pairs of cause/effect locations trained on pairs of road locations where we are reasonably certain a priori of their causal connections, both positive and negative. We test our approach on six months of road speed data from 195 different highway speed sensors in the Los Angeles area, showing that our approach is superior to state-of-the-art baselines in both accuracy and computation speed.",
    "source": "arXiv"
  },
  {
    "title": "RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration",
    "title_es": "RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration",
    "url": "https://arxiv.org/abs/2508.09449",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09449v1 Announce Type: new \nAbstract: Reference-based Super Resolution (RefSR) improves upon Single Image Super Resolution (SISR) by leveraging high-quality reference images to enhance texture fidelity and visual realism. However, a critical limitation of existing RefSR approaches is their reliance on manually curated target-reference image pairs, which severely constrains their practicality in real-world scenarios. To overcome this, we introduce Retrieval-Augmented Super Resolution (RASR), a new and practical RefSR paradigm that automatically retrieves semantically relevant high-resolution images from a reference database given only a low-quality input. This enables scalable and flexible RefSR in realistic use cases, such as enhancing mobile photos taken in environments like zoos or museums, where category-specific reference data (e.g., animals, artworks) can be readily collected or pre-curated. To facilitate research in this direction, we construct RASR-Flickr30, the first benchmark dataset designed for RASR. Unlike prior datasets with fixed target-reference pairs, RASR-Flickr30 provides per-category reference databases to support open-world retrieval. We further propose RASRNet, a strong baseline that combines a semantic reference retriever with a diffusion-based RefSR generator. It retrieves relevant references based on semantic similarity and employs a diffusion-based generator enhanced with semantic conditioning. Experiments on RASR-Flickr30 demonstrate that RASRNet consistently improves over SISR baselines, achieving +0.38 dB PSNR and -0.0131 LPIPS, while generating more realistic textures. These findings highlight retrieval augmentation as a promising direction to bridge the gap between academic RefSR research and real-world applicability.",
    "source": "arXiv"
  },
  {
    "title": "From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text",
    "title_es": "From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text",
    "url": "https://arxiv.org/abs/2508.09450",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09450v1 Announce Type: new \nAbstract: Charts are very common for exploring data and communicating insights, but extracting key takeaways from charts and articulating them in natural language can be challenging. The chart-to-text task aims to automate this process by generating textual summaries of charts. While with the rapid advancement of large Vision-Language Models (VLMs), we have witnessed great progress in this domain, little to no attention has been given to potential biases in their outputs. This paper investigates how VLMs can amplify geo-economic biases when generating chart summaries, potentially causing societal harm. Specifically, we conduct a large-scale evaluation of geo-economic biases in VLM-generated chart summaries across 6,000 chart-country pairs from six widely used proprietary and open-source models to understand how a country's economic status influences the sentiment of generated summaries. Our analysis reveals that existing VLMs tend to produce more positive descriptions for high-income countries compared to middle- or low-income countries, even when country attribution is the only variable changed. We also find that models such as GPT-4o-mini, Gemini-1.5-Flash, and Phi-3.5 exhibit varying degrees of bias. We further explore inference-time prompt-based debiasing techniques using positive distractors but find them only partially effective, underscoring the complexity of the issue and the need for more robust debiasing strategies. Our code and dataset are publicly available here.",
    "source": "arXiv"
  },
  {
    "title": "A Unified Contrastive-Generative Framework for Time Series Classification",
    "title_es": "A Unified Contrastive-Generative Framework for Time Series Classification",
    "url": "https://arxiv.org/abs/2508.09451",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09451v1 Announce Type: new \nAbstract: Self-supervised learning (SSL) for multivariate time series mainly includes two paradigms: contrastive methods that excel at instance discrimination and generative approaches that model data distributions. While effective individually, their complementary potential remains unexplored. We propose a Contrastive Generative Time series framework (CoGenT), the first framework to unify these paradigms through joint contrastive-generative optimization. CoGenT addresses fundamental limitations of both approaches: it overcomes contrastive learning's sensitivity to high intra-class similarity in temporal data while reducing generative methods' dependence on large datasets. We evaluate CoGenT on six diverse time series datasets. The results show consistent improvements, with up to 59.2% and 14.27% F1 gains over standalone SimCLR and MAE, respectively. Our analysis reveals that the hybrid objective preserves discriminative power while acquiring generative robustness. These findings establish a foundation for hybrid SSL in temporal domains. We will release the code shortly.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Integration of Multi-View Attributed Graphs for Clustering and Embedding",
    "title_es": "Efficient Integration of Multi-View Attributed Graphs for Clustering and Embedding",
    "url": "https://arxiv.org/abs/2508.09452",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09452v1 Announce Type: new \nAbstract: A multi-view attributed graph (MVAG) G captures the diverse relationships and properties of real-world entities through multiple graph views and attribute views. Effectively utilizing all views in G is essential for MVAG clustering and embedding, which are important for applications like recommendation systems, anomaly detection, social network analysis, etc. Existing methods either achieve inferior result quality or incur significant computational costs to handle large-scale MVAGs.\n  In this paper, we present a spectrum-guided Laplacian aggregation scheme with an effective objective formulation and two efficient algorithms SGLA and SGLA+, to cohesively integrate all views of G into an MVAG Laplacian matrix, which readily enables classic graph algorithms to handle G with superior performance in clustering and embedding tasks. We begin by conducting a theoretical analysis to design an integrated objective that consists of two components, the eigengap and connectivity objectives, aiming to link the spectral properties of the aggregated MVAG Laplacian with the underlying community and connectivity properties of G. A constrained optimization problem is then formulated for the integration, which is computationally expensive to solve. Thus, we first develop the SGLA algorithm, which already achieves excellent performance compared with existing methods. To further enhance efficiency, we design SGLA+ to reduce the number of costly objective evaluations via sampling and approximation to quickly find an approximate optimum. Extensive experiments compare our methods against 12 baselines for clustering and 8 baselines for embedding on 8 multi-view attributed graphs, validating the superior performance of SGLA and SGLA+ in terms of result quality and efficiency. Compared with the most effective baselines, our methods are significantly faster, often by up to orders of magnitude.",
    "source": "arXiv"
  },
  {
    "title": "HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss",
    "title_es": "HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss",
    "url": "https://arxiv.org/abs/2508.09453",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09453v1 Announce Type: new \nAbstract: The proliferation of foundation models, pretrained on large-scale unlabeled datasets, has emerged as an effective approach in creating adaptable and reusable architectures that can be leveraged for various downstream tasks using satellite observations. However, their direct application to hyperspectral remote sensing remains challenging due to inherent spectral disparities and the scarcity of available observations. In this work, we present HyperKD, a novel knowledge distillation framework that enables transferring learned representations from a teacher model into a student model for effective development of a foundation model on hyperspectral images. Unlike typical knowledge distillation frameworks, which use a complex teacher to guide a simpler student, HyperKD enables an inverse form of knowledge transfer across different types of spectral data, guided by a simpler teacher model. Building upon a Masked Autoencoder, HyperKD distills knowledge from the Prithvi foundational model into a student tailored for EnMAP hyperspectral imagery. HyperKD addresses the inverse domain adaptation problem with spectral gaps by introducing a feature-based strategy that includes spectral range-based channel alignment, spatial feature-guided masking, and an enhanced loss function tailored for hyperspectral images. HyperKD bridges the substantial spectral domain gap, enabling the effective use of pretrained foundation models for geospatial applications. Extensive experiments show that HyperKD significantly improves representation learning in MAEs, leading to enhanced reconstruction fidelity and more robust performance on downstream tasks such as land cover classification, crop type identification, and soil organic carbon prediction, underpinning the potential of knowledge distillation frameworks in remote sensing analytics with hyperspectral imagery.",
    "source": "arXiv"
  },
  {
    "title": "Animate-X++: Universal Character Image Animation with Dynamic Backgrounds",
    "title_es": "Animate-X++: Universal Character Image Animation with Dynamic Backgrounds",
    "url": "https://arxiv.org/abs/2508.09454",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09454v1 Announce Type: new \nAbstract: Character image animation, which generates high-quality videos from a reference image and target pose sequence, has seen significant progress in recent years. However, most existing methods only apply to human figures, which usually do not generalize well on anthropomorphic characters commonly used in industries like gaming and entertainment. Furthermore, previous methods could only generate videos with static backgrounds, which limits the realism of the videos. For the first challenge, our in-depth analysis suggests to attribute this limitation to their insufficient modeling of motion, which is unable to comprehend the movement pattern of the driving video, thus imposing a pose sequence rigidly onto the target character. To this end, this paper proposes Animate-X++, a universal animation framework based on DiT for various character types, including anthropomorphic characters. To enhance motion representation, we introduce the Pose Indicator, which captures comprehensive motion pattern from the driving video through both implicit and explicit manner. The former leverages CLIP visual features of a driving video to extract its gist of motion, like the overall movement pattern and temporal relations among motions, while the latter strengthens the generalization of DiT by simulating possible inputs in advance that may arise during inference. For the second challenge, we introduce a multi-task training strategy that jointly trains the animation and TI2V tasks. Combined with the proposed partial parameter training, this approach achieves not only character animation but also text-driven background dynamics, making the videos more realistic. Moreover, we introduce a new Animated Anthropomorphic Benchmark (A2Bench) to evaluate the performance of Animate-X++ on universal and widely applicable animation images. Extensive experiments demonstrate the superiority and effectiveness of Animate-X++.",
    "source": "arXiv"
  },
  {
    "title": "IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding",
    "title_es": "IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding",
    "url": "https://arxiv.org/abs/2508.09456",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09456v1 Announce Type: new \nAbstract: Vision-language models (VLMs) have shown significant advancements in tasks such as visual grounding, where they localize specific objects in images based on natural language queries and images. However, security issues in visual grounding tasks for VLMs remain underexplored, especially in the context of backdoor attacks. In this paper, we introduce a novel input-aware backdoor attack method, IAG, designed to manipulate the grounding behavior of VLMs. This attack forces the model to ground a specific target object in the input image, regardless of the user's query. We propose an adaptive trigger generator that embeds the semantic information of the attack target's description into the original image using a text-conditional U-Net, thereby overcoming the open-vocabulary attack challenge. To ensure the attack's stealthiness, we utilize a reconstruction loss to minimize visual discrepancies between poisoned and clean images. Additionally, we introduce a unified method for generating attack data. IAG is evaluated theoretically and empirically, demonstrating its feasibility and effectiveness. Notably, our ASR@0.5 on InternVL-2.5-8B reaches over 65\\% on various testing sets. IAG also shows promising potential on manipulating Ferret-7B and LlaVA-1.5-7B with very little accuracy decrease on clean samples. Extensive specific experiments, such as ablation study and potential defense, also indicate the robustness and transferability of our attack.",
    "source": "arXiv"
  },
  {
    "title": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis",
    "title_es": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis",
    "url": "https://arxiv.org/abs/2508.09458",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09458v1 Announce Type: new \nAbstract: Knowledge syntheses (literature reviews) are essential to health professions education (HPE), consolidating findings to advance theory and practice. However, they are labor-intensive, especially during data extraction. Artificial Intelligence (AI)-assisted extraction promises efficiency but raises concerns about accuracy, making it critical to distinguish AI 'hallucinations' (fabricated content) from legitimate interpretive differences. We developed an extraction platform using large language models (LLMs) to automate data extraction and compared AI to human responses across 187 publications and 17 extraction questions from a published scoping review. AI-human, human-human, and AI-AI consistencies were measured using interrater reliability (categorical) and thematic similarity ratings (open-ended). Errors were identified by comparing extracted responses to source publications. AI was highly consistent with humans for concrete, explicitly stated questions (e.g., title, aims) and lower for questions requiring subjective interpretation or absent in text (e.g., Kirkpatrick's outcomes, study rationale). Human-human consistency was not higher than AI-human and showed the same question-dependent variability. Discordant AI-human responses (769/3179 = 24.2%) were mostly due to interpretive differences (18.3%); AI inaccuracies were rare (1.51%), while humans were nearly three times more likely to state inaccuracies (4.37%). Findings suggest AI accuracy depends more on interpretability than hallucination. Repeating AI extraction can identify interpretive complexity or ambiguity, refining processes before human review. AI can be a transparent, trustworthy partner in knowledge synthesis, though caution is needed to preserve critical human insights.",
    "source": "arXiv"
  },
  {
    "title": "RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization",
    "title_es": "RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization",
    "url": "https://arxiv.org/abs/2508.09459",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09459v1 Announce Type: new \nAbstract: Visual manipulation localization (VML) -- across both images and videos -- is a crucial task in digital forensics that involves identifying tampered regions in visual content. However, existing methods often lack cross-modal generalization and struggle to handle high-resolution or long-duration inputs efficiently.\n  We propose RelayFormer, a unified and modular architecture for visual manipulation localization across images and videos. By leveraging flexible local units and a Global-Local Relay Attention (GLoRA) mechanism, it enables scalable, resolution-agnostic processing with strong generalization. Our framework integrates seamlessly with existing Transformer-based backbones, such as ViT and SegFormer, via lightweight adaptation modules that require only minimal architectural changes, ensuring compatibility without disrupting pretrained representations.\n  Furthermore, we design a lightweight, query-based mask decoder that supports one-shot inference across video sequences with linear complexity. Extensive experiments across multiple benchmarks demonstrate that our approach achieves state-of-the-art localization performance, setting a new baseline for scalable and modality-agnostic VML. Code is available at: https://github.com/WenOOI/RelayFormer.",
    "source": "arXiv"
  },
  {
    "title": "Towards Self-cognitive Exploration: Metacognitive Knowledge Graph Retrieval Augmented Generation",
    "title_es": "Towards Self-cognitive Exploration: Metacognitive Knowledge Graph Retrieval Augmented Generation",
    "url": "https://arxiv.org/abs/2508.09460",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09460v1 Announce Type: new \nAbstract: Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) significantly enhances the reasoning capabilities of LargeLanguage Models by leveraging structured knowledge. However, existing KG-RAG frameworks typically operate as open-loop systems, suffering from cognitive blindness, an inability to recognize their exploration deficiencies. This leads to relevance drift and incomplete evidence, which existing self-refinement methods, designed for unstructured text-based RAG, cannot effectively resolve due to the path-dependent nature of graph exploration. To address this challenge, we propose Metacognitive Knowledge Graph Retrieval Augmented Generation (MetaKGRAG), a novel framework inspired by the human metacognition process, which introduces a Perceive-Evaluate-Adjust cycle to enable path-aware, closed-loop refinement. This cycle empowers the system to self-assess exploration quality, identify deficiencies in coverage or relevance, and perform trajectory-connected corrections from precise pivot points. Extensive experiments across five datasets in the medical, legal, and commonsense reasoning domains demonstrate that MetaKGRAG consistently outperforms strong KG-RAG and self-refinement baselines. Our results validate the superiority of our approach and highlight the critical need for path-aware refinement in structured knowledge retrieval.",
    "source": "arXiv"
  },
  {
    "title": "Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy",
    "title_es": "Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy",
    "url": "https://arxiv.org/abs/2508.09461",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09461v1 Announce Type: new \nAbstract: Different forms of customized 2D avatars are widely used in gaming applications, virtual communication, education, and content creation. However, existing approaches often fail to capture fine-grained facial expressions and struggle to preserve identity across different expressions. We propose GEN-AFFECT, a novel framework for personalized avatar generation that generates expressive and identity-consistent avatars with a diverse set of facial expressions. Our framework proposes conditioning a multimodal diffusion transformer on an extracted identity-expression representation. This enables identity preservation and representation of a wide range of facial expressions. GEN-AFFECT additionally employs consistent attention at inference for information sharing across the set of generated expressions, enabling the generation process to maintain identity consistency over the array of generated fine-grained expressions. GEN-AFFECT demonstrates superior performance compared to previous state-of-the-art methods on the basis of the accuracy of the generated expressions, the preservation of the identity and the consistency of the target identity across an array of fine-grained facial expressions.",
    "source": "arXiv"
  },
  {
    "title": "Open-Set Fault Diagnosis in Multimode Processes via Fine-Grained Deep Feature Representation",
    "title_es": "Open-Set Fault Diagnosis in Multimode Processes via Fine-Grained Deep Feature Representation",
    "url": "https://arxiv.org/abs/2508.09462",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09462v1 Announce Type: new \nAbstract: A reliable fault diagnosis system should not only accurately classify known health states but also effectively identify unknown faults. In multimode processes, samples belonging to the same health state often show multiple cluster distributions, making it difficult to construct compact and accurate decision boundaries for that state. To address this challenge, a novel open-set fault diagnosis model named fine-grained clustering and rejection network (FGCRN) is proposed. It combines multiscale depthwise convolution, bidirectional gated recurrent unit and temporal attention mechanism to capture discriminative features. A distance-based loss function is designed to enhance the intra-class compactness. Fine-grained feature representations are constructed through unsupervised learning to uncover the intrinsic structures of each health state. Extreme value theory is employed to model the distance between sample features and their corresponding fine-grained representations, enabling effective identification of unknown faults. Extensive experiments demonstrate the superior performance of the proposed method.",
    "source": "arXiv"
  },
  {
    "title": "User-centric Subjective Leaderboard by Customizable Reward Modeling",
    "title_es": "User-centric Subjective Leaderboard by Customizable Reward Modeling",
    "url": "https://arxiv.org/abs/2508.09463",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09463v1 Announce Type: new \nAbstract: Existing benchmarks for large language models (LLMs) predominantely focus on assessing their capabilities through verifiable tasks. Such objective and static benchmarks offer limited utility for practical LLM selection, making it difficult for users to find suitable models for their individual needs. To bridge this gap, we present the first User-Centric Subjective Leaderboard (USL), which provides a preference-driven, dynamic ranking of LLMs across diverse real-world scenarios. Our work is built upon a thorough investigation of real human preference data, involving more than 10K subjective queries. Our investigation reveals significant diversity and contradictions in human preferences, which limit the effectiveness of state-of-the-art reward models. To address this, we introduce Customizable Reward Models (CRMs). With only 4B parameters, our CRM surpasses the performance of leading models such as GPT-4.1 and Gemini-2.5-pro, showing exceptional generalization capabilities across new topics and criteria. The USL, powered by CRMs, exhibits strong negative correlations to contradictory preferences.",
    "source": "arXiv"
  },
  {
    "title": "Event-driven Robust Fitting on Neuromorphic Hardware",
    "title_es": "Event-driven Robust Fitting on Neuromorphic Hardware",
    "url": "https://arxiv.org/abs/2508.09466",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09466v1 Announce Type: new \nAbstract: Robust fitting of geometric models is a fundamental task in many computer vision pipelines. Numerous innovations have been produced on the topic, from improving the efficiency and accuracy of random sampling heuristics to generating novel theoretical insights that underpin new approaches with mathematical guarantees. However, one aspect of robust fitting that has received little attention is energy efficiency. This performance metric has become critical as high energy consumption is a growing concern for AI adoption. In this paper, we explore energy-efficient robust fitting via the neuromorphic computing paradigm. Specifically, we designed a novel spiking neural network for robust fitting on real neuromorphic hardware, the Intel Loihi 2. Enabling this are novel event-driven formulations of model estimation that allow robust fitting to be implemented in the unique architecture of Loihi 2, and algorithmic strategies to alleviate the current limited precision and instruction set of the hardware. Results show that our neuromorphic robust fitting consumes only a fraction (15%) of the energy required to run the established robust fitting algorithm on a standard CPU to equivalent accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Learn to Explore: Meta NAS via Bayesian Optimization Guided Graph Generation",
    "title_es": "Learn to Explore: Meta NAS via Bayesian Optimization Guided Graph Generation",
    "url": "https://arxiv.org/abs/2508.09467",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09467v1 Announce Type: new \nAbstract: Neural Architecture Search (NAS) automates the design of high-performing neural networks but typically targets a single predefined task, thereby restricting its real-world applicability. To address this, Meta Neural Architecture Search (Meta-NAS) has emerged as a promising paradigm that leverages prior knowledge across tasks to enable rapid adaptation to new ones. Nevertheless, existing Meta-NAS methods often struggle with poor generalization, limited search spaces, or high computational costs. In this paper, we propose a novel Meta-NAS framework, GraB-NAS. Specifically, GraB-NAS first models neural architectures as graphs, and then a hybrid search strategy is developed to find and generate new graphs that lead to promising neural architectures. The search strategy combines global architecture search via Bayesian Optimization in the search space with local exploration for novel neural networks via gradient ascent in the latent space. Such a hybrid search strategy allows GraB-NAS to discover task-aware architectures with strong performance, even beyond the predefined search space. Extensive experiments demonstrate that GraB-NAS outperforms state-of-the-art Meta-NAS baselines, achieving better generalization and search effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries",
    "title_es": "DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries",
    "url": "https://arxiv.org/abs/2508.09468",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09468v1 Announce Type: new \nAbstract: Internet of Things (IoT) sensors are ubiquitous technologies deployed across smart cities, industrial sites, and healthcare systems. They continuously generate time series data that enable advanced analytics and automation in industries. However, challenges such as the loss or ambiguity of sensor metadata, heterogeneity in data sources, varying sampling frequencies, inconsistent units of measurement, and irregular timestamps make raw IoT time series data difficult to interpret, undermining the effectiveness of smart systems. To address these challenges, we propose a novel deep learning model, DeepFeatIoT, which integrates learned local and global features with non-learned randomized convolutional kernel-based features and features from large language models (LLMs). This straightforward yet unique fusion of diverse learned and non-learned features significantly enhances IoT time series sensor data classification, even in scenarios with limited labeled data. Our model's effectiveness is demonstrated through its consistent and generalized performance across multiple real-world IoT sensor datasets from diverse critical application domains, outperforming state-of-the-art benchmark models. These results highlight DeepFeatIoT's potential to drive significant advancements in IoT analytics and support the development of next-generation smart systems.",
    "source": "arXiv"
  },
  {
    "title": "Handows: A Palm-Based Interactive Multi-Window Management System in Virtual Reality",
    "title_es": "Handows: A Palm-Based Interactive Multi-Window Management System in Virtual Reality",
    "url": "https://arxiv.org/abs/2508.09469",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09469v1 Announce Type: new \nAbstract: Window management in virtual reality (VR) remains a challenging task due to the spatial complexity and physical demands of current interaction methods. We introduce Handows, a palm-based interface that enables direct manipulation of spatial windows through familiar smartphone-inspired gestures on the user's non-dominant hand. Combining ergonomic layout design with body-centric input and passive haptics, Handows supports four core operations: window selection, closure, positioning, and scaling. We evaluate Handows in a user study (N=15) against two common VR techniques (virtual hand and controller) across these core window operations. Results show that Handows significantly reduces physical effort and head movement while improving task efficiency and interaction precision. A follow-up case study (N=8) demonstrates Handows' usability in realistic multitasking scenarios, highlighting user-adapted workflows and spontaneous layout strategies. Our findings suggest the potential of embedding mobile-inspired metaphors into proprioceptive body-centric interfaces to support low-effort and spatially coherent interaction in VR.",
    "source": "arXiv"
  },
  {
    "title": "CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios",
    "title_es": "CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios",
    "url": "https://arxiv.org/abs/2508.09470",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09470v1 Announce Type: new \nAbstract: Semantic segmentation of city-scale point clouds is a critical technology for Unmanned Aerial Vehicle (UAV) perception systems, enabling the classification of 3D points without relying on any visual information to achieve comprehensive 3D understanding. However, existing models are frequently constrained by the limited scale of 3D data and the domain gap between datasets, which lead to reduced generalization capability. To address these challenges, we propose CitySeg, a foundation model for city-scale point cloud semantic segmentation that incorporates text modality to achieve open vocabulary segmentation and zero-shot inference. Specifically, in order to mitigate the issue of non-uniform data distribution across multiple domains, we customize the data preprocessing rules, and propose a local-global cross-attention network to enhance the perception capabilities of point networks in UAV scenarios. To resolve semantic label discrepancies across datasets, we introduce a hierarchical classification strategy. A hierarchical graph established according to the data annotation rules consolidates the data labels, and the graph encoder is used to model the hierarchical relationships between categories. In addition, we propose a two-stage training strategy and employ hinge loss to increase the feature separability of subcategories. Experimental results demonstrate that the proposed CitySeg achieves state-of-the-art (SOTA) performance on nine closed-set benchmarks, significantly outperforming existing approaches. Moreover, for the first time, CitySeg enables zero-shot generalization in city-scale point cloud scenarios without relying on visual information.",
    "source": "arXiv"
  },
  {
    "title": "EGGS-PTP: An Expander-Graph Guided Structured Post-training Pruning Method for Large Language Models",
    "title_es": "EGGS-PTP: An Expander-Graph Guided Structured Post-training Pruning Method for Large Language Models",
    "url": "https://arxiv.org/abs/2508.09471",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09471v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) become more widely adopted and scale up in size, the computational and memory challenges involved in deploying these massive foundation models have grown increasingly severe. This underscores the urgent need to develop more efficient model variants. Faced with this challenge, the present work introduces EGGS-PTP: an Expander-Graph Guided Structured Post-training Pruning method. The proposed approach leverages graph theory to guide the design of N:M structured pruning, effectively reducing model size and computational demands. By incorporating concepts from expander graphs, EGGS-PTP ensures information flow within the pruned network, preserving essential model functionality. Extensive numerical experiments demonstrate that EGGS-PTP not only achieves significant acceleration and memory savings due to structured sparsity but also outperforms existing structured pruning techniques in terms of accuracy across various LLMs.",
    "source": "arXiv"
  },
  {
    "title": "NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs",
    "title_es": "NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs",
    "url": "https://arxiv.org/abs/2508.09473",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09473v1 Announce Type: new \nAbstract: Ensuring robust safety alignment while preserving utility is critical for the reliable deployment of Large Language Models (LLMs). However, current techniques fundamentally suffer from intertwined deficiencies: insufficient robustness against malicious attacks, frequent refusal of benign queries, degradation in generated text quality and general task performance--the former two reflecting deficits in robust safety and the latter constituting utility impairment. We trace these limitations to the coarse-grained layer-wise interventions in existing methods. To resolve this, we propose NeuronTune, a fine-grained framework that dynamically modulates sparse neurons to achieve simultaneous safety-utility optimization. Our approach first identifies safety-critical and utility-preserving neurons across all layers via attribution, then employs meta-learning to adaptively amplify safety-neuron activations and suppress utility-neuron activations. Crucially, NeuronTune enables tunable adjustment of intervention scope via neuron-count thresholds, supporting flexible adaptation to security-critical or utility-priority scenarios. Extensive experimental results demonstrate that our method significantly outperforms existing state-of-the-art technologies, achieving superior model safety while maintaining excellent utility.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection",
    "title_es": "Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection",
    "url": "https://arxiv.org/abs/2508.09475",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09475v1 Announce Type: new \nAbstract: Recent deepfake detection studies often treat unseen sample detection as a ``zero-shot\" task, training on images generated by known models but generalizing to unknown ones. A key real-world challenge arises when a model performs poorly on unknown samples, yet these samples remain available for analysis. This highlights that it should be approached as a ``few-shot\" task, where effectively utilizing a small number of samples can lead to significant improvement. Unlike typical few-shot tasks focused on semantic understanding, deepfake detection prioritizes image realism, which closely mirrors real-world distributions. In this work, we propose the Few-shot Training-free Network (FTNet) for real-world few-shot deepfake detection. Simple yet effective, FTNet differs from traditional methods that rely on large-scale known data for training. Instead, FTNet uses only one fake samplefrom an evaluation set, mimicking the scenario where new samples emerge in the real world and can be gathered for use, without any training or parameter updates. During evaluation, each test sample is compared to the known fake and real samples, and it is classified based on the category of the nearest sample. We conduct a comprehensive analysis of AI-generated images from 29 different generative models and achieve a new SoTA performance, with an average improvement of 8.7\\% compared to existing methods. This work introduces a fresh perspective on real-world deepfake detection: when the model struggles to generalize on a few-shot sample, leveraging the failed samples leads to better performance.",
    "source": "arXiv"
  },
  {
    "title": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts",
    "title_es": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts",
    "url": "https://arxiv.org/abs/2508.09476",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09476v1 Announce Type: new \nAbstract: Current video generation models struggle with identity preservation under large facial angles, primarily facing two challenges: the difficulty in exploring an effective mechanism to integrate identity features into DiT structure, and the lack of targeted coverage of large facial angles in existing open-source video datasets. To address these, we present two key innovations. First, we introduce a Mixture of Facial Experts (MoFE) that dynamically combines complementary cues from three specialized experts, each designed to capture distinct but mutually reinforcing aspects of facial attributes. The identity expert captures cross-pose identity-sensitive features, the semantic expert extracts high-level visual semantxics, and the detail expert preserves pixel-level features (e.g., skin texture, color gradients). Furthermore, to mitigate dataset limitations, we have tailored a data processing pipeline centered on two key aspects: Face Constraints and Identity Consistency. Face Constraints ensure facial angle diversity and a high proportion of facial regions, while Identity Consistency preserves coherent person-specific features across temporal sequences, collectively addressing the scarcity of large facial angles and identity-stable training data in existing datasets. Leveraging this pipeline, we have curated and refined a Large Face Angles (LFA) Dataset from existing open-source human video datasets, comprising 460K video clips with annotated facial angles. Experimental results on the LFA benchmark demonstrate that our method, empowered by the LFA dataset, significantly outperforms prior SOTA methods in face similarity, face FID, and CLIP semantic alignment. The code and dataset will be made publicly available at https://github.com/rain152/LFA-Video-Generation.",
    "source": "arXiv"
  },
  {
    "title": "CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection",
    "title_es": "CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.09477",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09477v1 Announce Type: new \nAbstract: With the rapid advancement of AI generative models, the visual quality of AI-generated images (AIIs) has become increasingly close to natural images, which inevitably raises security concerns. Most AII detectors often employ the conventional image classification pipeline with natural images and AIIs (generated by a generative model), which can result in limited detection performance for AIIs from unseen generative models. To solve this, we proposed a universal AI-generated image detector from the perspective of anomaly detection. Our discriminator does not need to access any AIIs and learn a generalizable representation with unsupervised learning. Specifically, we use the pre-trained CLIP encoder as the feature extractor and design a normalizing flow-like unsupervised model. Instead of AIIs, proxy images, e.g., obtained by applying a spectral modification operation on natural images, are used for training. Our models are trained by minimizing the likelihood of proxy images, optionally combined with maximizing the likelihood of natural images. Extensive experiments demonstrate the effectiveness of our method on AIIs produced by various image generators.",
    "source": "arXiv"
  },
  {
    "title": "GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs",
    "title_es": "GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs",
    "url": "https://arxiv.org/abs/2508.09478",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09478v1 Announce Type: new \nAbstract: In this work, we present GazeLT, a human visual attention integration-disintegration approach for long-tailed disease classification. A radiologist's eye gaze has distinct patterns that capture both fine-grained and coarser level disease related information. While interpreting an image, a radiologist's attention varies throughout the duration; it is critical to incorporate this into a deep learning framework to improve automated image interpretation. Another important aspect of visual attention is that apart from looking at major/obvious disease patterns, experts also look at minor/incidental findings (few of these constituting long-tailed classes) during the course of image interpretation. GazeLT harnesses the temporal aspect of the visual search process, via an integration and disintegration mechanism, to improve long-tailed disease classification. We show the efficacy of GazeLT on two publicly available datasets for long-tailed disease classification, namely the NIH-CXR-LT (n=89237) and the MIMIC-CXR-LT (n=111898) datasets. GazeLT outperforms the best long-tailed loss by 4.1% and the visual attention-based baseline by 21.7% in average accuracy metrics for these datasets. Our code is available at https://github.com/lordmoinak1/gazelt.",
    "source": "arXiv"
  },
  {
    "title": "SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images",
    "title_es": "SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images",
    "url": "https://arxiv.org/abs/2508.09479",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09479v1 Announce Type: new \nAbstract: Three-dimensional scene reconstruction from sparse-view satellite images is a long-standing and challenging task. While 3D Gaussian Splatting (3DGS) and its variants have recently attracted attention for its high efficiency, existing methods remain unsuitable for satellite images due to incompatibility with rational polynomial coefficient (RPC) models and limited generalization capability. Recent advances in generalizable 3DGS approaches show potential, but they perform poorly on multi-temporal sparse satellite images due to limited geometric constraints, transient objects, and radiometric inconsistencies. To address these limitations, we propose SkySplat, a novel self-supervised framework that integrates the RPC model into the generalizable 3DGS pipeline, enabling more effective use of sparse geometric cues for improved reconstruction. SkySplat relies only on RGB images and radiometric-robust relative height supervision, thereby eliminating the need for ground-truth height maps. Key components include a Cross-Self Consistency Module (CSCM), which mitigates transient object interference via consistency-based masking, and a multi-view consistency aggregation strategy that refines reconstruction results. Compared to per-scene optimization methods, SkySplat achieves an 86 times speedup over EOGS with higher accuracy. It also outperforms generalizable 3DGS baselines, reducing MAE from 13.18 m to 1.80 m on the DFC19 dataset significantly, and demonstrates strong cross-dataset generalization on the MVS3D benchmark.",
    "source": "arXiv"
  },
  {
    "title": "Episodic Memory Representation for Long-form Video Understanding",
    "title_es": "Episodic Memory Representation for Long-form Video Understanding",
    "url": "https://arxiv.org/abs/2508.09486",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09486v1 Announce Type: new \nAbstract: Video Large Language Models (Video-LLMs) excel at general video understanding but struggle with long-form videos due to context window limits. Consequently, recent approaches focus on keyframe retrieval, condensing lengthy videos into a small set of informative frames. Despite their practicality, these methods simplify the problem to static text image matching, overlooking spatio temporal relationships crucial for capturing scene transitions and contextual continuity, and may yield redundant keyframes with limited information, diluting salient cues essential for accurate video question answering. To address these limitations, we introduce Video-EM, a training free framework inspired by the principles of human episodic memory, designed to facilitate robust and contextually grounded reasoning. Rather than treating keyframes as isolated visual entities, Video-EM explicitly models them as temporally ordered episodic events, capturing both spatial relationships and temporal dynamics necessary for accurately reconstructing the underlying narrative. Furthermore, the framework leverages chain of thought (CoT) thinking with LLMs to iteratively identify a minimal yet highly informative subset of episodic memories, enabling efficient and accurate question answering by Video-LLMs. Extensive evaluations on the Video-MME, EgoSchema, HourVideo, and LVBench benchmarks confirm the superiority of Video-EM, which achieves highly competitive results with performance gains of 4-9 percent over respective baselines while utilizing fewer frames.",
    "source": "arXiv"
  },
  {
    "title": "SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection",
    "title_es": "SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection",
    "url": "https://arxiv.org/abs/2508.09487",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09487v1 Announce Type: new \nAbstract: Recently, diffusion-generated image detection has gained increasing attention, as the rapid advancement of diffusion models has raised serious concerns about their potential misuse. While existing detection methods have achieved promising results, their performance often degrades significantly when facing fake images from unseen, out-of-distribution (OOD) generative models, since they primarily rely on model-specific artifacts. To address this limitation, we explore a fundamental property commonly observed in fake images. Motivated by the observation that fake images tend to exhibit higher similarity to their captions than real images, we propose a novel representation, namely Semantic-Aware Reconstruction Error (SARE), that measures the semantic difference between an image and its caption-guided reconstruction. The hypothesis behind SARE is that real images, whose captions often fail to fully capture their complex visual content, may undergo noticeable semantic shifts during the caption-guided reconstruction process. In contrast, fake images, which closely align with their captions, show minimal semantic changes. By quantifying these semantic shifts, SARE can be utilized as a discriminative feature for robust detection across diverse generative models. We empirically demonstrate that the proposed method exhibits strong generalization, outperforming existing baselines on benchmarks including GenImage and CommunityForensics.",
    "source": "arXiv"
  },
  {
    "title": "Large-Small Model Collaborative Framework for Federated Continual Learning",
    "title_es": "Large-Small Model Collaborative Framework for Federated Continual Learning",
    "url": "https://arxiv.org/abs/2508.09489",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09489v1 Announce Type: new \nAbstract: Continual learning (CL) for Foundation Models (FMs) is an essential yet underexplored challenge, especially in Federated Continual Learning (FCL), where each client learns from a private, evolving task stream under strict data and communication constraints. Despite their powerful generalization abilities, FMs often exhibit suboptimal performance on local downstream tasks, as they are unable to utilize private local data. Furthermore, enabling FMs to learn new tasks without forgetting prior knowledge is inherently a challenging problem, primarily due to their immense parameter count and high model complexity. In contrast, small models can be trained locally under resource-constrained conditions and benefit from more mature CL techniques. To bridge the gap between small models and FMs, we propose the first collaborative framework in FCL, where lightweight local models act as a dynamic bridge, continually adapting to new tasks while enhancing the utility of the large model. Two novel components are also included: Small Model Continual Fine-tuning is for preventing small models from temporal forgetting; One-by-One Distillation performs personalized fusion of heterogeneous local knowledge on the server. Experimental results demonstrate its superior performance, even when clients utilize heterogeneous small models.",
    "source": "arXiv"
  },
  {
    "title": "Learning Facts at Scale with Active Reading",
    "title_es": "Learning Facts at Scale with Active Reading",
    "url": "https://arxiv.org/abs/2508.09494",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09494v1 Announce Type: new \nAbstract: LLMs are known to store vast amounts of knowledge in their parametric memory. However, learning and recalling facts from this memory is known to be unreliable, depending largely on the prevalence of particular facts in the training data and other factors which are poorly understood. Practitioners are lacking tools which will allow them to ensure that the models learn a given body of knowledge reliably and consistently. To this end, we propose Active Reading: a framework where we train models to study a given set of material with self-generated learning strategies. First, we demonstrate models trained with Active Reading on expert domains absorb significantly more knowledge than vanilla finetuning and other data augmentations. We train expert 8B models that achieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over vanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla finetuning) by applying Active Reading to the source documents for each benchmark. Finally, we show that Active Reading can be utilized at pre-training scale to build more factual models. As a demonstration of this, we release Meta WikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens, which outcompetes models with hundreds of billions of parameters on factual QA.",
    "source": "arXiv"
  },
  {
    "title": "From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation",
    "title_es": "From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation",
    "url": "https://arxiv.org/abs/2508.09497",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09497v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) systems are often bottlenecked by their reranking modules, which typically score passages independently and select a fixed Top-K size. This approach struggles with complex multi-hop queries that require synthesizing evidence across multiple documents, creating a trade-off where small K values omit crucial information and large K values introduce noise. To address this, we introduce the Dynamic Passage Selector (DPS), a novel reranking framework that treats passage selection as a supervised learning problem. Unlike traditional point-wise or list-wise methods, DPS is fine-tuned to capture inter-passage dependencies and dynamically select the most relevant set of passages for generation. As a seamless plug-and-play module, DPS requires no modifications to the standard RAG pipeline. Comprehensive evaluations on five benchmarks show that DPS consistently outperforms state-of-the-art rerankers and fine-tuning methods. Notably, on the challenging MuSiQue dataset, DPS improves the F1-score by 30.06% and 15.4% over strong baselines like Qwen3-reranker and RankingGPT, respectively. Our results demonstrate that by enabling adaptive evidence selection, DPS substantially enhances reasoning capabilities in complex RAG scenarios.",
    "source": "arXiv"
  },
  {
    "title": "CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking",
    "title_es": "CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking",
    "url": "https://arxiv.org/abs/2508.09499",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09499v1 Announce Type: new \nAbstract: Accurately predicting the binding conformation of small-molecule ligands to protein targets is a critical step in rational drug design. Although recent deep learning-based docking surpasses traditional methods in speed and accuracy, many approaches rely on graph representations and language model-inspired encoders while neglecting critical geometric information, resulting in inaccurate pocket localization and unrealistic binding conformations. In this study, we introduce CWFBind, a weighted, fast, and accurate docking method based on local curvature features. Specifically, we integrate local curvature descriptors during the feature extraction phase to enrich the geometric representation of both proteins and ligands, complementing existing chemical, sequence, and structural features. Furthermore, we embed degree-aware weighting mechanisms into the message passing process, enhancing the model's ability to capture spatial structural distinctions and interaction strengths. To address the class imbalance challenge in pocket prediction, CWFBind employs a ligand-aware dynamic radius strategy alongside an enhanced loss function, facilitating more precise identification of binding regions and key residues. Comprehensive experimental evaluations demonstrate that CWFBind achieves competitive performance across multiple docking benchmarks, offering a balanced trade-off between accuracy and efficiency.",
    "source": "arXiv"
  },
  {
    "title": "MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI",
    "title_es": "MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI",
    "url": "https://arxiv.org/abs/2508.09500",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09500v1 Announce Type: new \nAbstract: Quantized Neural Networks (QNN) with extremely low-bitwidth data have proven promising in efficient storage and computation on edge devices. To further reduce the accuracy drop while increasing speedup, layer-wise mixed-precision quantization (MPQ) becomes a popular solution. However, existing algorithms for exploring MPQ schemes are limited in flexibility and efficiency. Comprehending the complex impacts of different MPQ schemes on post-training quantization and quantization-aware training results is a challenge for conventional methods. Furthermore, an end-to-end framework for the optimization and deployment of MPQ models is missing in existing work.\n  In this paper, we propose the MiCo framework, a holistic MPQ exploration and deployment framework for edge AI applications. The framework adopts a novel optimization algorithm to search for optimal quantization schemes with the highest accuracies while meeting latency constraints. Hardware-aware latency models are built for different hardware targets to enable fast explorations. After the exploration, the framework enables direct deployment from PyTorch MPQ models to bare-metal C codes, leading to end-to-end speedup with minimal accuracy drops.",
    "source": "arXiv"
  },
  {
    "title": "Reactive Model Predictive Contouring Control for Robot Manipulators",
    "title_es": "Reactive Model Predictive Contouring Control for Robot Manipulators",
    "url": "https://arxiv.org/abs/2508.09502",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09502v1 Announce Type: new \nAbstract: This contribution presents a robot path-following framework via Reactive Model Predictive Contouring Control (RMPCC) that successfully avoids obstacles, singularities and self-collisions in dynamic environments at 100 Hz. Many path-following methods rely on the time parametrization, but struggle to handle collision and singularity avoidance while adhering kinematic limits or other constraints. Specifically, the error between the desired path and the actual position can become large when executing evasive maneuvers. Thus, this paper derives a method that parametrizes the reference path by a path parameter and performs the optimization via RMPCC. In particular, Control Barrier Functions (CBFs) are introduced to avoid collisions and singularities in dynamic environments. A Jacobian-based linearization and Gauss-Newton Hessian approximation enable solving the nonlinear RMPCC problem at 100 Hz, outperforming state-of-the-art methods by a factor of 10. Experiments confirm that the framework handles dynamic obstacles in real-world settings with low contouring error and low robot acceleration.",
    "source": "arXiv"
  },
  {
    "title": "Holistic Heterogeneous Scheduling for Autonomous Applications using Fine-grained, Multi-XPU Abstraction",
    "title_es": "Holistic Heterogeneous Scheduling for Autonomous Applications using Fine-grained, Multi-XPU Abstraction",
    "url": "https://arxiv.org/abs/2508.09503",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09503v1 Announce Type: new \nAbstract: Modern autonomous applications are increasingly utilizing multiple heterogeneous processors (XPUs) to accelerate different stages of algorithm modules. However, existing runtime systems for these applications, such as ROS, can only perform module-level task management, lacking awareness of the fine-grained usage of multiple XPUs. This paper presents XAUTO, a runtime system designed to cooperatively manage XPUs for latency-sensitive autonomous applications. The key idea is a fine-grained, multi-XPU programming abstraction -- XNODE, which aligns with the stage-level task granularity and can accommodate multiple XPU implementations. XAUTO holistically assigns XPUs to XNODEs and schedules their execution to minimize end-to-end latency. Experimental results show that XAUTO can reduce the end-to-end latency of a perception pipeline for autonomous driving by 1.61x compared to a state-of-the-art module-level scheduling system (ROS2).",
    "source": "arXiv"
  },
  {
    "title": "Causal Graph Profiling via Structural Divergence for Robust Anomaly Detection in Cyber-Physical Systems",
    "title_es": "Causal Graph Profiling via Structural Divergence for Robust Anomaly Detection in Cyber-Physical Systems",
    "url": "https://arxiv.org/abs/2508.09504",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09504v1 Announce Type: new \nAbstract: With the growing complexity of cyberattacks targeting critical infrastructures such as water treatment networks, there is a pressing need for robust anomaly detection strategies that account for both system vulnerabilities and evolving attack patterns. Traditional methods -- statistical, density-based, and graph-based models struggle with distribution shifts and class imbalance in multivariate time series, often leading to high false positive rates. To address these challenges, we propose CGAD, a Causal Graph-based Anomaly Detection framework designed for reliable cyberattack detection in public infrastructure systems. CGAD follows a two-phase supervised framework -- causal profiling and anomaly scoring. First, it learns causal invariant graph structures representing the system's behavior under \"Normal\" and \"Attack\" states using Dynamic Bayesian Networks. Second, it employs structural divergence to detect anomalies via causal graph comparison by evaluating topological deviations in causal graphs over time. By leveraging causal structures, CGAD achieves superior adaptability and accuracy in non-stationary and imbalanced time series environments compared to conventional machine learning approaches. By uncovering causal structures beneath volatile sensor data, our framework not only detects cyberattacks with markedly higher precision but also redefines robustness in anomaly detection, proving resilience where traditional models falter under imbalance and drift. Our framework achieves substantial gains in F1 and ROC-AUC scores over best-performing baselines across four industrial datasets, demonstrating robust detection of delayed and structurally complex anomalies.",
    "source": "arXiv"
  },
  {
    "title": "Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference",
    "title_es": "Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference",
    "url": "https://arxiv.org/abs/2508.09505",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09505v1 Announce Type: new \nAbstract: Distributed machine learning training and inference is common today because today's large models require more memory and compute than can be provided by a single GPU. Distributed models are generally produced by programmers who take a sequential model specification and apply several distribution strategies to distribute state and computation across GPUs. Unfortunately, bugs can be introduced in the process, and a distributed model implementation's outputs might differ from the sequential model's outputs. In this paper, we describe an approach to statically identify such bugs by checking model refinement, that is, can the sequential model's outputs be reconstructed from the distributed model's outputs? Our approach, implemented in GraphGuard, uses iterative rewriting to prove model refinement. Our approach can scale to today's large models and deployments: we evaluate it using GPT and Llama-3. Further, it provides actionable output that aids in bug localization.",
    "source": "arXiv"
  },
  {
    "title": "An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants",
    "title_es": "An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants",
    "url": "https://arxiv.org/abs/2508.09507",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09507v1 Announce Type: new \nAbstract: With the rapid development of mobile intelligent assistant technologies, multi-modal AI assistants have become essential interfaces for daily user interactions. However, current evaluation methods face challenges including high manual costs, inconsistent standards, and subjective bias. This paper proposes an automated multi-modal evaluation framework based on large language models and multi-agent collaboration. The framework employs a three-tier agent architecture consisting of interaction evaluation agents, semantic verification agents, and experience decision agents. Through supervised fine-tuning on the Qwen3-8B model, we achieve a significant evaluation matching accuracy with human experts. Experimental results on eight major intelligent agents demonstrate the framework's effectiveness in predicting users' satisfaction and identifying generation defects.",
    "source": "arXiv"
  },
  {
    "title": "SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents",
    "title_es": "SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents",
    "url": "https://arxiv.org/abs/2508.09508",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09508v1 Announce Type: new \nAbstract: Typical marine environments are highly complex with spatio-temporally varying currents and dynamic obstacles, presenting significant challenges to Unmanned Surface Vehicles (USVs) for safe and efficient navigation. Thus, the USVs need to continuously adapt their paths with real-time information to avoid collisions and follow the path of least resistance to the goal via exploiting ocean currents. In this regard, we introduce a novel algorithm, called Self-Morphing Adaptive Replanning Tree for dynamic Obstacles and Currents (SMART-OC), that facilitates real-time time-risk optimal replanning in dynamic environments. SMART-OC integrates the obstacle risks along a path with the time cost to reach the goal to find the time-risk optimal path. The effectiveness of SMART-OC is validated by simulation experiments, which demonstrate that the USV performs fast replannings to avoid dynamic obstacles and exploit ocean currents to successfully reach the goal.",
    "source": "arXiv"
  },
  {
    "title": "A hyperbolic finite difference scheme for anisotropic diffusion equations: preserving the discrete maximum principle",
    "title_es": "A hyperbolic finite difference scheme for anisotropic diffusion equations: preserving the discrete maximum principle",
    "url": "https://arxiv.org/abs/2508.09509",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09509v1 Announce Type: new \nAbstract: A hyperbolic system approach is proposed for robust computation of anisotropic diffusion equations that appear in quasineutral plasmas. Though the approach exhibits merits of high extensibility and accurate flux computation, the monotonicity of the scheme for anisotropic diffusion cases has not been understood. In this study, the discrete maximum principle (DMP) of the hyperbolic system approach is analyzed and tested in various anisotropic diffusion cases. A mathematical analysis is conducted to obtain an optimal condition of an arbitrary parameter to guarantee the DMP, and numerical experiments reveal an adoptive selection of the parameter for DMP-preserving results. It is confirmed that, with an appropriate preconditioning matrix and parameter choice, the hyperbolic system approach preserves the DMP even with a linear discretization.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Memory Recall in LLMs with Gauss-Tin: A Hybrid Instructional and Gaussian Replay Approach",
    "title_es": "Enhancing Memory Recall in LLMs with Gauss-Tin: A Hybrid Instructional and Gaussian Replay Approach",
    "url": "https://arxiv.org/abs/2508.09510",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09510v1 Announce Type: new \nAbstract: Despite the significant advancements in Large Language Models (LLMs), catastrophic forgetting remains a substantial challenge, where models lose previously acquired knowledge upon learning new information. Continual learning (CL) strategies have emerged as a potential solution to this problem, with replay-based techniques demonstrating superior performance in preserving learned knowledge. In this context, we introduce Gauss-Tin, a novel approach that integrates the replay strategy with a Gaussian mixture model to enhance the quality of sample selection during training, supplemented by instructional guidance to facilitate the generation of past learning. This method aims to improve LLMs' retention capabilities by strategically reinforcing important past learnings while accommodating new information. Our experimental results indicate a promising 6\\% improvement in retention metrics over traditional methods, suggesting that Gauss-Tin is an effective strategy for mitigating catastrophic forgetting in LLMs. This study underscores the potential of hybrid models in enhancing the robustness and adaptability of LLMs in dynamic learning environments.",
    "source": "arXiv"
  },
  {
    "title": "LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation",
    "title_es": "LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation",
    "url": "https://arxiv.org/abs/2508.09515",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09515v1 Announce Type: new \nAbstract: Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed sentiment analysis in a target language by transferring knowledge from a source language with available annotated data. Most existing methods depend heavily on often unreliable translation tools to bridge the language gap. In this paper, we propose a new approach that leverages a large language model (LLM) to generate high-quality pseudo-labelled data in the target language without the need for translation tools. First, the framework trains an ABSA model to obtain predictions for unlabelled target language data. Next, LLM is prompted to generate natural sentences that better represent these noisy predictions than the original text. The ABSA model is then further fine-tuned on the resulting pseudo-labelled dataset. We demonstrate the effectiveness of this method across six languages and five backbone models, surpassing previous state-of-the-art translation-based approaches. The proposed framework also supports generative models, and we show that fine-tuned LLMs outperform smaller multilingual models.",
    "source": "arXiv"
  },
  {
    "title": "Cross-lingual Aspect-Based Sentiment Analysis: A Survey on Tasks, Approaches, and Challenges",
    "title_es": "Cross-lingual Aspect-Based Sentiment Analysis: A Survey on Tasks, Approaches, and Challenges",
    "url": "https://arxiv.org/abs/2508.09516",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09516v1 Announce Type: new \nAbstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that focuses on understanding opinions at the aspect level, including sentiment towards specific aspect terms, categories, and opinions. While ABSA research has seen significant progress, much of the focus has been on monolingual settings. Cross-lingual ABSA, which aims to transfer knowledge from resource-rich languages (such as English) to low-resource languages, remains an under-explored area, with no systematic review of the field. This paper aims to fill that gap by providing a comprehensive survey of cross-lingual ABSA. We summarize key ABSA tasks, including aspect term extraction, aspect sentiment classification, and compound tasks involving multiple sentiment elements. Additionally, we review the datasets, modelling paradigms, and cross-lingual transfer methods used to solve these tasks. We also examine how existing work in monolingual and multilingual ABSA, as well as ABSA with LLMs, contributes to the development of cross-lingual ABSA. Finally, we highlight the main challenges and suggest directions for future research to advance cross-lingual ABSA systems.",
    "source": "arXiv"
  },
  {
    "title": "UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval",
    "title_es": "UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval",
    "url": "https://arxiv.org/abs/2508.09517",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09517v1 Announce Type: new \nAbstract: This paper presents a zero-shot system for fact-checked claim retrieval. We employed several state-of-the-art large language models to obtain text embeddings. The models were then combined to obtain the best possible result. Our approach achieved 7th place in monolingual and 9th in cross-lingual subtasks. We used only English translations as an input to the text embedding models since multilingual models did not achieve satisfactory results. We identified the most relevant claims for each post by leveraging the embeddings and measuring cosine similarity. Overall, the best results were obtained by the NVIDIA NV-Embed-v2 model. For some languages, we benefited from model combinations (NV-Embed & GPT or Mistral).",
    "source": "arXiv"
  },
  {
    "title": "From Formal Methods to Data-Driven Safety Certificates of Unknown Large-Scale Networks",
    "title_es": "From Formal Methods to Data-Driven Safety Certificates of Unknown Large-Scale Networks",
    "url": "https://arxiv.org/abs/2508.09520",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09520v1 Announce Type: new \nAbstract: In this work, we propose a data-driven scheme within a compositional framework with noisy data to design robust safety controllers in a fully decentralized fashion for large-scale interconnected networks with unknown mathematical dynamics. Despite the network's high dimensionality and the inherent complexity of its unknown model, which make it intractable, our approach effectively addresses these challenges by (i) treating the network as a composition of smaller subsystems, and (ii) collecting noisy data from each subsystem's trajectory to design a control sub-barrier certificate (CSBC) and its corresponding local controller. To achieve this, our proposed scheme only requires a noise-corrupted single input-state trajectory from each unknown subsystem up to a specified time horizon, satisfying a certain rank condition. Subsequently, under a small-gain compositional reasoning, we compose those CSBC, derived from noisy data, and formulate a control barrier certificate (CBC) for the unknown network, ensuring its safety over an infinite time horizon, while providing correctness guarantees. We offer a data-dependent sum-of-squares (SOS) optimization program for computing CSBC alongside local controllers of subsystems. We illustrate that while the computational complexity of designing a CBC and its safety controller grows polynomially with network dimension using SOS optimization, our compositional data-driven approach significantly reduces it to a linear scale concerning the number of subsystems. We demonstrate the capability of our data-driven approach on multiple physical networks involving unknown models and a range of interconnection topologies.",
    "source": "arXiv"
  },
  {
    "title": "COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation",
    "title_es": "COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation",
    "url": "https://arxiv.org/abs/2508.09521",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09521v1 Announce Type: new \nAbstract: Emotional support conversations are crucial for promoting emotional well-being, yet current models often lack deep empathetic reasoning grounded in psychological principles. To address this, we propose controllable empathetic reasoning, which combines natural language reasoning with structured psychological steps. We construct a fine-grained dataset annotated with reasoning correctness and response preferences to enable this capability. To further enhance training, we employ reinforcement learning with a unified process-outcome reward model that delivers precise feedback. To mitigate response repetitiveness from entropy collapse, we introduce personality-based dialogue rewriting and a redundancy-aware reward reweighting strategy. Our approach significantly improves model's emotional support ability, advancing the development of empathetic, human-like support systems.",
    "source": "arXiv"
  },
  {
    "title": "Generation of Indian Sign Language Letters, Numbers, and Words",
    "title_es": "Generation of Indian Sign Language Letters, Numbers, and Words",
    "url": "https://arxiv.org/abs/2508.09522",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09522v1 Announce Type: new \nAbstract: Sign language, which contains hand movements, facial expressions and bodily gestures, is a significant medium for communicating with hard-of-hearing people. A well-trained sign language community communicates easily, but those who don't know sign language face significant challenges. Recognition and generation are basic communication methods between hearing and hard-of-hearing individuals. Despite progress in recognition, sign language generation still needs to be explored. The Progressive Growing of Generative Adversarial Network (ProGAN) excels at producing high-quality images, while the Self-Attention Generative Adversarial Network (SAGAN) generates feature-rich images at medium resolutions. Balancing resolution and detail is crucial for sign language image generation. We are developing a Generative Adversarial Network (GAN) variant that combines both models to generate feature-rich, high-resolution, and class-conditional sign language images. Our modified Attention-based model generates high-quality images of Indian Sign Language letters, numbers, and words, outperforming the traditional ProGAN in Inception Score (IS) and Fr\\'echet Inception Distance (FID), with improvements of 3.2 and 30.12, respectively. Additionally, we are publishing a large dataset incorporating high-quality images of Indian Sign Language alphabets, numbers, and 129 words.",
    "source": "arXiv"
  },
  {
    "title": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking",
    "title_es": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking",
    "url": "https://arxiv.org/abs/2508.09524",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09524v1 Announce Type: new \nAbstract: In this paper, we present the first systematic investigation and quantification of Similar Object Interference (SOI), a long-overlooked yet critical bottleneck in Single Object Tracking (SOT). Through controlled Online Interference Masking (OIM) experiments, we quantitatively demonstrate that eliminating interference sources leads to substantial performance improvements (AUC gains up to 4.35) across all SOTA trackers, directly validating SOI as a primary constraint for robust tracking and highlighting the feasibility of external cognitive guidance. Building upon these insights, we adopt natural language as a practical form of external guidance, and construct SOIBench-the first semantic cognitive guidance benchmark specifically targeting SOI challenges. It automatically mines SOI frames through multi-tracker collective judgment and introduces a multi-level annotation protocol to generate precise semantic guidance texts. Systematic evaluation on SOIBench reveals a striking finding: existing vision-language tracking (VLT) methods fail to effectively exploit semantic cognitive guidance, achieving only marginal improvements or even performance degradation (AUC changes of -0.26 to +0.71). In contrast, we propose a novel paradigm employing large-scale vision-language models (VLM) as external cognitive engines that can be seamlessly integrated into arbitrary RGB trackers. This approach demonstrates substantial improvements under semantic cognitive guidance (AUC gains up to 0.93), representing a significant advancement over existing VLT methods. We hope SOIBench will serve as a standardized evaluation platform to advance semantic cognitive tracking research and contribute new insights to the tracking research community.",
    "source": "arXiv"
  },
  {
    "title": "Learning Spatial Decay for Vision Transformers",
    "title_es": "Learning Spatial Decay for Vision Transformers",
    "url": "https://arxiv.org/abs/2508.09525",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09525v1 Announce Type: new \nAbstract: Vision Transformers (ViTs) have revolutionized computer vision, yet their self-attention mechanism lacks explicit spatial inductive biases, leading to suboptimal performance on spatially-structured tasks. Existing approaches introduce data-independent spatial decay based on fixed distance metrics, applying uniform attention weighting regardless of image content and limiting adaptability to diverse visual scenarios. Inspired by recent advances in large language models where content-aware gating mechanisms (e.g., GLA, HGRN2, FOX) significantly outperform static alternatives, we present the first successful adaptation of data-dependent spatial decay to 2D vision transformers. We introduce \\textbf{Spatial Decay Transformer (SDT)}, featuring a novel Context-Aware Gating (CAG) mechanism that generates dynamic, data-dependent decay for patch interactions. Our approach learns to modulate spatial attention based on both content relevance and spatial proximity. We address the fundamental challenge of 1D-to-2D adaptation through a unified spatial-content fusion framework that integrates manhattan distance-based spatial priors with learned content representations. Extensive experiments on ImageNet-1K classification and generation tasks demonstrate consistent improvements over strong baselines. Our work establishes data-dependent spatial decay as a new paradigm for enhancing spatial attention in vision transformers.",
    "source": "arXiv"
  },
  {
    "title": "Time-Aware and Transition-Semantic Graph Neural Networks for Interpretable Predictive Business Process Monitoring",
    "title_es": "Time-Aware and Transition-Semantic Graph Neural Networks for Interpretable Predictive Business Process Monitoring",
    "url": "https://arxiv.org/abs/2508.09527",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09527v1 Announce Type: new \nAbstract: Predictive Business Process Monitoring (PBPM) aims to forecast future events in ongoing cases based on historical event logs. While Graph Neural Networks (GNNs) are well suited to capture structural dependencies in process data, existing GNN-based PBPM models remain underdeveloped. Most rely either on short prefix subgraphs or global architectures that overlook temporal relevance and transition semantics. We propose a unified, interpretable GNN framework that advances the state of the art along three key axes. First, we compare prefix-based Graph Convolutional Networks(GCNs) and full trace Graph Attention Networks(GATs) to quantify the performance gap between localized and global modeling. Second, we introduce a novel time decay attention mechanism that constructs dynamic, prediction-centered windows, emphasizing temporally relevant history and suppressing noise. Third, we embed transition type semantics into edge features to enable fine grained reasoning over structurally ambiguous traces. Our architecture includes multilevel interpretability modules, offering diverse visualizations of attention behavior. Evaluated on five benchmarks, the proposed models achieve competitive Top-k accuracy and DL scores without per-dataset tuning. By addressing architectural, temporal, and semantic gaps, this work presents a robust, generalizable, and explainable solution for next event prediction in PBPM.",
    "source": "arXiv"
  },
  {
    "title": "Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing",
    "title_es": "Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing",
    "url": "https://arxiv.org/abs/2508.09528",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09528v1 Announce Type: new \nAbstract: Deep networks have achieved remarkable success in image compressed sensing (CS) task, namely reconstructing a high-fidelity image from its compressed measurement. However, existing works are deficient inincoherent compressed measurement at sensing phase and implicit measurement representations at reconstruction phase, limiting the overall performance. In this work, we answer two questions: 1) how to improve the measurement incoherence for decreasing the ill-posedness; 2) how to learn informative representations from measurements. To this end, we propose a novel asymmetric Kronecker CS (AKCS) model and theoretically present its better incoherence than previous Kronecker CS with minimal complexity increase. Moreover, we reveal that the unfolding networks' superiority over non-unfolding ones result from sufficient gradient descents, called explicit measurement representations. We propose a measurement-aware cross attention (MACA) mechanism to learn implicit measurement representations. We integrate AKCS and MACA into widely-used unfolding architecture to get a measurement-enhanced unfolding network (MEUNet). Extensive experiences demonstrate that our MEUNet achieves state-of-the-art performance in reconstruction accuracy and inference speed.",
    "source": "arXiv"
  },
  {
    "title": "Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks",
    "title_es": "Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks",
    "url": "https://arxiv.org/abs/2508.09532",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09532v1 Announce Type: new \nAbstract: Federated fine-tuning has emerged as a promising approach for adapting foundation models (FMs) to diverse downstream tasks in edge environments. In Internet of Vehicles (IoV) systems, enabling efficient and low-latency multi-task adaptation is particularly challenging due to client mobility, heterogeneous resources, and intermittent connectivity. This paper proposes a hierarchical federated fine-tuning framework that coordinates roadside units (RSUs) and vehicles to support resource-aware and mobility-resilient learning across dynamic IoV scenarios. Leveraging Low-Rank Adaptation (LoRA), we introduce a decentralized, energy-aware rank adaptation mechanism formulated as a constrained multi-armed bandit problem. A novel UCB-DUAL algorithm is developed to enable adaptive exploration under per-task energy budgets, achieving provable sublinear regret. To evaluate our method, we construct a large-scale IoV simulator based on real-world trajectories, capturing dynamic participation, RSU handoffs, and communication variability. Extensive experiments show that our approach achieves the best accuracy-efficiency trade-off among all baselines, reducing latency by over 24\\% and improving average accuracy by more than 2.5\\%.",
    "source": "arXiv"
  },
  {
    "title": "COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection",
    "title_es": "COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection",
    "url": "https://arxiv.org/abs/2508.09533",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09533v1 Announce Type: new \nAbstract: Detecting tiny objects in multimodal Red-Green-Blue-Thermal (RGBT) imagery is a critical challenge in computer vision, particularly in surveillance, search and rescue, and autonomous navigation. Drone-based scenarios exacerbate these challenges due to spatial misalignment, low-light conditions, occlusion, and cluttered backgrounds. Current methods struggle to leverage the complementary information between visible and thermal modalities effectively. We propose COXNet, a novel framework for RGBT tiny object detection, addressing these issues through three core innovations: i) the Cross-Layer Fusion Module, fusing high-level visible and low-level thermal features for enhanced semantic and spatial accuracy; ii) the Dynamic Alignment and Scale Refinement module, correcting cross-modal spatial misalignments and preserving multi-scale features; and iii) an optimized label assignment strategy using the GeoShape Similarity Measure for better localization. COXNet achieves a 3.32\\% mAP$_{50}$ improvement on the RGBTDronePerson dataset over state-of-the-art methods, demonstrating its effectiveness for robust detection in complex environments.",
    "source": "arXiv"
  },
  {
    "title": "Improving Dense Passage Retrieval with Multiple Positive Passages",
    "title_es": "Improving Dense Passage Retrieval with Multiple Positive Passages",
    "url": "https://arxiv.org/abs/2508.09534",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09534v1 Announce Type: new \nAbstract: By leveraging a dual encoder architecture, Dense Passage Retrieval (DPR) has outperformed traditional sparse retrieval algorithms such as BM25 in terms of passage retrieval accuracy. Recently proposed methods have further enhanced DPR's performance. However, these models typically pair each question with only one positive passage during training, and the effect of associating multiple positive passages has not been examined. In this paper, we explore the performance of DPR when additional positive passages are incorporated during training. Experimental results show that equipping each question with multiple positive passages consistently improves retrieval accuracy, even when using a significantly smaller batch size, which enables training on a single GPU.",
    "source": "arXiv"
  },
  {
    "title": "AI Blob! LLM-Driven Recontextualization of Italian Television Archives",
    "title_es": "AI Blob! LLM-Driven Recontextualization of Italian Television Archives",
    "url": "https://arxiv.org/abs/2508.09535",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09535v1 Announce Type: new \nAbstract: This paper introduces AI Blob!, an experimental system designed to explore the potential of semantic cataloging and Large Language Models (LLMs) for the retrieval and recontextualization of archival television footage. Drawing methodological inspiration from Italian television programs such as Blob (RAI Tre, 1989-), AI Blob! integrates automatic speech recognition (ASR), semantic embeddings, and retrieval-augmented generation (RAG) to organize and reinterpret archival content. The system processes a curated dataset of 1,547 Italian television videos by transcribing audio, segmenting it into sentence-level units, and embedding these segments into a vector database for semantic querying. Upon user input of a thematic prompt, the LLM generates a range of linguistically and conceptually related queries, guiding the retrieval and recombination of audiovisual fragments. These fragments are algorithmically selected and structured into narrative sequences producing montages that emulate editorial practices of ironic juxtaposition and thematic coherence. By foregrounding dynamic, content-aware retrieval over static metadata schemas, AI Blob! demonstrates how semantic technologies can facilitate new approaches to archival engagement, enabling novel forms of automated narrative construction and cultural analysis. The project contributes to ongoing debates in media historiography and AI-driven archival research, offering both a conceptual framework and a publicly available dataset to support further interdisciplinary experimentation.",
    "source": "arXiv"
  },
  {
    "title": "Shepherd Grid Strategy: Towards Reliable SWARM Interception",
    "title_es": "Shepherd Grid Strategy: Towards Reliable SWARM Interception",
    "url": "https://arxiv.org/abs/2508.09536",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09536v1 Announce Type: new \nAbstract: Modern unmanned aerial vehicle threats require sophisticated interception strategies that can overcome advanced evasion capabilities and operate effectively in contested environments. Traditional single-interceptor and uncoordinated multi-interceptor approaches suffer from fundamental limitations including inadequate coverage, predictable pursuit patterns, and vulnerability to intelligent evasion maneuvers. This paper introduces the Shepherd Grid Strategy, a new multi-phase coordination framework that employs pack-based behavioral coordination to achieve deterministic target interception through systematic containment and coordinated strike execution. The strategy implements a four-phase operational model consisting of chase, follow, formation, and engagement phases, with dynamic role assignment and adaptive formation geometry that maintains persistent target pressure while preparing optimal strike opportunities. Our approach incorporates three key innovations: adaptive phase transition mechanisms that optimize pursuit behavior based on proximity and mission objectives, dynamic role assignment systems that designate specialized interceptor functions including formation maintenance and strike execution, and predictive formation geometry algorithms that create mobile containment grids adapting to target movement patterns. The simulation experiments demonstrate significant performance improvements over traditional methods, achieving near-perfect interception success rates (over 95%) compared to traditional approaches (65%) and reducing median time-to-intercept.",
    "source": "arXiv"
  },
  {
    "title": "Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion",
    "title_es": "Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion",
    "url": "https://arxiv.org/abs/2508.09537",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09537v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly used for function completion in repository-scale codebases. Prior studies demonstrate that when explicit instructions--such as docstrings--are provided, these models can generate highly accurate implementations. However, in real-world repositories, such annotations are frequently absent, and performance drops substantially without them. To address this gap, we frame the task as a three-stage process. The first stage focuses on intent inference, where the model analyzes the code preceding the target function to uncover cues about the desired functionality. Such preceding context often encodes subtle but critical information, and we design a reasoning-based prompting framework to guide the LLM through step-by-step extraction and synthesis of these signals before any code is generated. The second stage introduces an optional interactive refinement mechanism to handle cases where preceding context alone is insufficient for intent recovery. In this stage, the model proposes a small set of candidate intentions, enabling the developer to select or edit them so that the inferred intent closely matches the actual requirement. Finally, in the third stage, the LLM generates the target function conditioned on the finalized intent. To support this pipeline, we curate a dataset of 40,000 examples annotated with intermediate reasoning traces and corresponding docstrings. Extensive experiments on DevEval and ComplexCodeEval show that our approach consistently boosts multiple LLMs, achieving over 20\\% relative gains in both reference-based and execution-based metrics, with the interactive refinement stage delivering additional improvements beyond these gains.",
    "source": "arXiv"
  },
  {
    "title": "TFRank: Think-Free Reasoning Enables Practical Pointwise LLM Ranking",
    "title_es": "TFRank: Think-Free Reasoning Enables Practical Pointwise LLM Ranking",
    "url": "https://arxiv.org/abs/2508.09539",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09539v1 Announce Type: new \nAbstract: Reasoning-intensive ranking models built on Large Language Models (LLMs) have made notable progress, but existing approaches often rely on large-scale LLMs and explicit Chain-of-Thought (CoT) reasoning, resulting in high computational cost and latency that limit real-world use. To address this, we propose \\textbf{TFRank}, an efficient pointwise reasoning ranker based on small-scale LLMs. To improve ranking performance, TFRank effectively integrates CoT data, fine-grained score supervision, and multi-task training. Furthermore, it achieves an efficient ``\\textbf{T}hink-\\textbf{F}ree\" reasoning capability by employing a ``think-mode switch'' and pointwise format constraints. Specifically, this allows the model to leverage explicit reasoning during training while delivering precise relevance scores for complex queries at inference without generating any reasoning chains. Experiments show that TFRank (e.g., 1.7B) achieves performance comparable to models with four times more parameters on the BRIGHT benchmark, and demonstrates strong competitiveness on the BEIR benchmark. Further analysis shows that TFRank achieves an effective balance between performance and efficiency, providing a practical solution for integrating advanced reasoning into real-world systems. Our code and data are released in the repository: https://github.com/JOHNNY-fans/TFRank.",
    "source": "arXiv"
  },
  {
    "title": "Emergence of Hierarchies in Multi-Agent Self-Organizing Systems Pursuing a Joint Objective",
    "title_es": "Emergence of Hierarchies in Multi-Agent Self-Organizing Systems Pursuing a Joint Objective",
    "url": "https://arxiv.org/abs/2508.09541",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09541v1 Announce Type: new \nAbstract: Multi-agent self-organizing systems (MASOS) exhibit key characteristics including scalability, adaptability, flexibility, and robustness, which have contributed to their extensive application across various fields. However, the self-organizing nature of MASOS also introduces elements of unpredictability in their emergent behaviors. This paper focuses on the emergence of dependency hierarchies during task execution, aiming to understand how such hierarchies arise from agents' collective pursuit of the joint objective, how they evolve dynamically, and what factors govern their development. To investigate this phenomenon, multi-agent reinforcement learning (MARL) is employed to train MASOS for a collaborative box-pushing task. By calculating the gradients of each agent's actions in relation to the states of other agents, the inter-agent dependencies are quantified, and the emergence of hierarchies is analyzed through the aggregation of these dependencies. Our results demonstrate that hierarchies emerge dynamically as agents work towards a joint objective, with these hierarchies evolving in response to changing task requirements. Notably, these dependency hierarchies emerge organically in response to the shared objective, rather than being a consequence of pre-configured rules or parameters that can be fine-tuned to achieve specific results. Furthermore, the emergence of hierarchies is influenced by the task environment and network initialization conditions. Additionally, hierarchies in MASOS emerge from the dynamic interplay between agents' \"Talent\" and \"Effort\" within the \"Environment.\" \"Talent\" determines an agent's initial influence on collective decision-making, while continuous \"Effort\" within the \"Environment\" enables agents to shift their roles and positions within the system.",
    "source": "arXiv"
  },
  {
    "title": "Iterative Volume Fusion for Asymmetric Stereo Matching",
    "title_es": "Iterative Volume Fusion for Asymmetric Stereo Matching",
    "url": "https://arxiv.org/abs/2508.09543",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09543v1 Announce Type: new \nAbstract: Stereo matching is vital in 3D computer vision, with most algorithms assuming symmetric visual properties between binocular visions. However, the rise of asymmetric multi-camera systems (e.g., tele-wide cameras) challenges this assumption and complicates stereo matching. Visual asymmetry disrupts stereo matching by affecting the crucial cost volume computation. To address this, we explore the matching cost distribution of two established cost volume construction methods in asymmetric stereo. We find that each cost volume experiences distinct information distortion, indicating that both should be comprehensively utilized to solve the issue. Based on this, we propose the two-phase Iterative Volume Fusion network for Asymmetric Stereo matching (IVF-AStereo). Initially, the aggregated concatenation volume refines the correlation volume. Subsequently, both volumes are fused to enhance fine details. Our method excels in asymmetric scenarios and shows robust performance against significant visual asymmetry. Extensive comparative experiments on benchmark datasets, along with ablation studies, confirm the effectiveness of our approach in asymmetric stereo with resolution and color degradation.",
    "source": "arXiv"
  },
  {
    "title": "SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification",
    "title_es": "SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification",
    "url": "https://arxiv.org/abs/2508.09544",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09544v1 Announce Type: new \nAbstract: Scarcity of labeled data, especially for rare events, hinders training effective machine learning models. This paper proposes SYNAPSE-G (Synthetic Augmentation for Positive Sampling via Expansion on Graphs), a novel pipeline leveraging Large Language Models (LLMs) to generate synthetic training data for rare event classification, addressing the cold-start problem. This synthetic data serve as seeds for semi-supervised label propagation on a similarity graph constructed between the seeds and a large unlabeled dataset. This identifies candidate positive examples, subsequently labeled by an oracle (human or LLM). The expanded dataset then trains/fine-tunes a classifier. We theoretically analyze how the quality (validity and diversity) of the synthetic data impacts the precision and recall of our method. Experiments on the imbalanced SST2 and MHS datasets demonstrate SYNAPSE-G's effectiveness in finding positive labels, outperforming baselines including nearest neighbor search.",
    "source": "arXiv"
  },
  {
    "title": "GoViG: Goal-Conditioned Visual Navigation Instruction Generation",
    "title_es": "GoViG: Goal-Conditioned Visual Navigation Instruction Generation",
    "url": "https://arxiv.org/abs/2508.09547",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09547v1 Announce Type: new \nAbstract: We introduce Goal-Conditioned Visual Navigation Instruction Generation (GoViG), a new task that aims to autonomously generate precise and contextually coherent navigation instructions solely from egocentric visual observations of initial and goal states. Unlike conventional approaches that rely on structured inputs such as semantic annotations or environmental maps, GoViG exclusively leverages raw egocentric visual data, substantially improving its adaptability to unseen and unstructured environments. Our method addresses this task by decomposing it into two interconnected subtasks: (1) visual forecasting, which predicts intermediate visual states bridging the initial and goal views; and (2) instruction generation, which synthesizes linguistically coherent instructions grounded in both observed and anticipated visuals. These subtasks are integrated within an autoregressive multimodal large language model trained with tailored objectives to ensure spatial accuracy and linguistic clarity. Furthermore, we introduce two complementary multimodal reasoning strategies, one-pass and interleaved reasoning, to mimic incremental human cognitive processes during navigation. To evaluate our method, we propose the R2R-Goal dataset, combining diverse synthetic and real-world trajectories. Empirical results demonstrate significant improvements over state-of-the-art methods, achieving superior BLEU-4 and CIDEr scores along with robust cross-domain generalization.",
    "source": "arXiv"
  },
  {
    "title": "CS-Agent: LLM-based Community Search via Dual-agent Collaboration",
    "title_es": "CS-Agent: LLM-based Community Search via Dual-agent Collaboration",
    "url": "https://arxiv.org/abs/2508.09549",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09549v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks, yet their application to graph structure analysis, particularly in community search, remains underexplored. Community search, a fundamental task in graph analysis, aims to identify groups of nodes with dense interconnections, which is crucial for understanding the macroscopic structure of graphs. In this paper, we propose GraphCS, a comprehensive benchmark designed to evaluate the performance of LLMs in community search tasks. Our experiments reveal that while LLMs exhibit preliminary potential, they frequently fail to return meaningful results and suffer from output bias. To address these limitations, we introduce CS-Agent, a dual-agent collaborative framework to enhance LLM-based community search. CS-Agent leverages the complementary strengths of two LLMs acting as Solver and Validator. Through iterative feedback and refinement, CS-Agent dynamically refines initial results without fine-tuning or additional training. After the multi-round dialogue, Decider module selects the optimal community. Extensive experiments demonstrate that CS-Agent significantly improves the quality and stability of identified communities compared to baseline methods. To our knowledge, this is the first work to apply LLMs to community search, bridging the gap between LLMs and graph analysis while providing a robust and adaptive solution for real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification",
    "title_es": "Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification",
    "url": "https://arxiv.org/abs/2508.09550",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09550v1 Announce Type: new \nAbstract: In this paper, we address a key scientific problem in machine learning: Given a training set for an image classification task, can we train a generative model on this dataset to enhance the classification performance? (i.e., closed-set generative data augmentation). We start by exploring the distinctions and similarities between real images and closed-set synthetic images generated by advanced generative models. Through extensive experiments, we offer systematic insights into the effective use of closed-set synthetic data for augmentation. Notably, we empirically determine the equivalent scale of synthetic images needed for augmentation. In addition, we also show quantitative equivalence between the real data augmentation and open-set generative augmentation (generative models trained using data beyond the given training set). While it aligns with the common intuition that real images are generally preferred, our empirical formulation also offers a guideline to quantify the increased scale of synthetic data augmentation required to achieve comparable image classification performance. Our results on natural and medical image datasets further illustrate how this effect varies with the baseline training set size and the amount of synthetic data incorporated.",
    "source": "arXiv"
  },
  {
    "title": "On Middle Grounds for Preference Statements",
    "title_es": "On Middle Grounds for Preference Statements",
    "url": "https://arxiv.org/abs/2508.09553",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09553v1 Announce Type: new \nAbstract: In group decisions or deliberations, stakeholders are often confronted with conflicting opinions. We investigate a logic-based way of expressing such opinions and a formal general notion of a middle ground between stakeholders. Inspired by the literature on preferences with hierarchical and lexicographic models, we instantiate our general framework to the case where stakeholders express their opinions using preference statements of the form I prefer 'a' to 'b', where 'a' and 'b' are alternatives expressed over some attributes, e.g., in a trolley problem, one can express I prefer to save 1 adult and 1 child to 2 adults (and 0 children). We prove theoretical results on the existence and uniqueness of middle grounds. In particular, we show that, for preference statements, middle grounds may not exist and may not be unique. We also provide algorithms for deciding the existence and finding middle grounds.",
    "source": "arXiv"
  },
  {
    "title": "Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning",
    "title_es": "Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning",
    "url": "https://arxiv.org/abs/2508.09555",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09555v1 Announce Type: new \nAbstract: Objective - This study presents a biometric identification method based on topological invariants from 2D iris images, representing iris texture via formally defined digital homology and evaluating classification performance.\n  Methods - Each normalized iris image (48x482 pixels) is divided into grids (e.g., 6x54 or 3x27). For each subregion, we compute Betti0, Betti1, and their ratio using a recent algorithm for homology groups in 2D digital images. The resulting invariants form a feature matrix used with logistic regression, KNN, and SVM (with PCA and 100 randomized repetitions). A convolutional neural network (CNN) is trained on raw images for comparison.\n  Results - Logistic regression achieved 97.78 +/- 0.82% accuracy, outperforming CNN (96.44 +/- 1.32%) and other feature-based models. The topological features showed high accuracy with low variance.\n  Conclusion - This is the first use of topological invariants from formal digital homology for iris recognition. The method offers a compact, interpretable, and accurate alternative to deep learning, useful when explainability or limited data is important. Beyond iris recognition, it can apply to other biometrics, medical imaging, materials science, remote sensing, and interpretable AI. It runs efficiently on CPU-only systems and produces robust, explainable features valuable for security-critical domains.",
    "source": "arXiv"
  },
  {
    "title": "CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail",
    "title_es": "CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail",
    "url": "https://arxiv.org/abs/2508.09558",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09558v1 Announce Type: new \nAbstract: The manipulation of deformable linear flexures has a wide range of applications in industry, such as cable routing in automotive manufacturing and textile production. Cable routing, as a complex multi-stage robot manipulation scenario, is a challenging task for robot automation. Common parallel two-finger grippers have the risk of over-squeezing and over-tension when grasping and guiding cables. In this paper, a novel eagle-inspired fingernail is designed and mounted on the gripper fingers, which helps with cable grasping on planar surfaces and in-hand cable guiding operations. Then we present a single-grasp end-to-end 3D cable routing framework utilizing the proposed fingernails, instead of the common pick-and-place strategy. Continuous control is achieved to efficiently manipulate cables through vision-based state estimation of task configurations and offline trajectory planning based on motion primitives. We evaluate the effectiveness of the proposed framework with a variety of cables and channel slots, significantly outperforming the pick-and-place manipulation process under equivalent perceptual conditions. Our reconfigurable task setting and the proposed framework provide a reference for future cable routing manipulations in 3D space.",
    "source": "arXiv"
  },
  {
    "title": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization",
    "title_es": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization",
    "url": "https://arxiv.org/abs/2508.09560",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09560v1 Announce Type: new \nAbstract: Visual geo-localization for drones faces critical degradation under weather perturbations, \\eg, rain and fog, where existing methods struggle with two inherent limitations: 1) Heavy reliance on limited weather categories that constrain generalization, and 2) Suboptimal disentanglement of entangled scene-weather features through pseudo weather categories. We present WeatherPrompt, a multi-modality learning paradigm that establishes weather-invariant representations through fusing the image embedding with the text context. Our framework introduces two key contributions: First, a Training-free Weather Reasoning mechanism that employs off-the-shelf large multi-modality models to synthesize multi-weather textual descriptions through human-like reasoning. It improves the scalability to unseen or complex weather, and could reflect different weather strength. Second, to better disentangle the scene and weather feature, we propose a multi-modality framework with the dynamic gating mechanism driven by the text embedding to adaptively reweight and fuse visual features across modalities. The framework is further optimized by the cross-modal objectives, including image-text contrastive learning and image-text matching, which maps the same scene with different weather conditions closer in the respresentation space. Extensive experiments validate that, under diverse weather conditions, our method achieves competitive recall rates compared to state-of-the-art drone geo-localization methods. Notably, it improves Recall@1 by +13.37\\% under night conditions and by 18.69\\% under fog and snow conditions.",
    "source": "arXiv"
  },
  {
    "title": "Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges",
    "title_es": "Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges",
    "url": "https://arxiv.org/abs/2508.09561",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09561v1 Announce Type: new \nAbstract: Edge General Intelligence (EGI) represents a transformative evolution of edge computing, where distributed agents possess the capability to perceive, reason, and act autonomously across diverse, dynamic environments. Central to this vision are world models, which act as proactive internal simulators that not only predict but also actively imagine future trajectories, reason under uncertainty, and plan multi-step actions with foresight. This proactive nature allows agents to anticipate potential outcomes and optimize decisions ahead of real-world interactions. While prior works in robotics and gaming have showcased the potential of world models, their integration into the wireless edge for EGI remains underexplored. This survey bridges this gap by offering a comprehensive analysis of how world models can empower agentic artificial intelligence (AI) systems at the edge. We first examine the architectural foundations of world models, including latent representation learning, dynamics modeling, and imagination-based planning. Building on these core capabilities, we illustrate their proactive applications across EGI scenarios such as vehicular networks, unmanned aerial vehicle (UAV) networks, the Internet of Things (IoT) systems, and network functions virtualization, thereby highlighting how they can enhance optimization under latency, energy, and privacy constraints. We then explore their synergy with foundation models and digital twins, positioning world models as the cognitive backbone of EGI. Finally, we highlight open challenges, such as safety guarantees, efficient training, and constrained deployment, and outline future research directions. This survey provides both a conceptual foundation and a practical roadmap for realizing the next generation of intelligent, autonomous edge systems.",
    "source": "arXiv"
  },
  {
    "title": "WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description",
    "title_es": "WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description",
    "url": "https://arxiv.org/abs/2508.09565",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09565v1 Announce Type: new \nAbstract: Multi-exposure correction technology is essential for restoring images affected by insufficient or excessive lighting, enhancing the visual experience by improving brightness, contrast, and detail richness. However, current multi-exposure correction methods often encounter challenges in addressing intra-class variability caused by diverse lighting conditions, shooting environments, and weather factors, particularly when processing images captured at a single exposure level. To enhance the adaptability of these models under complex imaging conditions, this paper proposes a Wavelet-based Exposure Correction method with Degradation Guidance (WEC-DG). Specifically, we introduce a degradation descriptor within the Exposure Consistency Alignment Module (ECAM) at both ends of the processing pipeline to ensure exposure consistency and achieve final alignment. This mechanism effectively addresses miscorrected exposure anomalies caused by existing methods' failure to recognize 'blurred' exposure degradation. Additionally, we investigate the light-detail decoupling properties of the wavelet transform to design the Exposure Restoration and Detail Reconstruction Module (EDRM), which processes low-frequency information related to exposure enhancement before utilizing high-frequency information as a prior guide for reconstructing spatial domain details. This serial processing strategy guarantees precise light correction and enhances detail recovery. Extensive experiments conducted on multiple public datasets demonstrate that the proposed method outperforms existing algorithms, achieving significant performance improvements and validating its effectiveness and practical applicability.",
    "source": "arXiv"
  },
  {
    "title": "A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation",
    "title_es": "A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation",
    "url": "https://arxiv.org/abs/2508.09566",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09566v1 Announce Type: new \nAbstract: Despite the progress of radiology report generation (RRG), existing works face two challenges: 1) The performances in clinical efficacy are unsatisfactory, especially for lesion attributes description; 2) the generated text lacks explainability, making it difficult for radiologists to trust the results. To address the challenges, we focus on a trustworthy RRG model, which not only generates accurate descriptions of abnormalities, but also provides basis of its predictions. To this end, we propose a framework named chain of diagnosis (CoD), which maintains a chain of diagnostic process for clinically accurate and explainable RRG. It first generates question-answer (QA) pairs via diagnostic conversation to extract key findings, then prompts a large language model with QA diagnoses for accurate generation. To enhance explainability, a diagnosis grounding module is designed to match QA diagnoses and generated sentences, where the diagnoses act as a reference. Moreover, a lesion grounding module is designed to locate abnormalities in the image, further improving the working efficiency of radiologists. To facilitate label-efficient training, we propose an omni-supervised learning strategy with clinical consistency to leverage various types of annotations from different datasets. Our efforts lead to 1) an omni-labeled RRG dataset with QA pairs and lesion boxes; 2) a evaluation tool for assessing the accuracy of reports in describing lesion location and severity; 3) extensive experiments to demonstrate the effectiveness of CoD, where it outperforms both specialist and generalist models consistently on two RRG benchmarks and shows promising explainability by accurately grounding generated sentences to QA diagnoses and images.",
    "source": "arXiv"
  },
  {
    "title": "Re-thinking Memory-Bound Limitations in CGRAs",
    "title_es": "Re-thinking Memory-Bound Limitations in CGRAs",
    "url": "https://arxiv.org/abs/2508.09570",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09570v1 Announce Type: new \nAbstract: Coarse-Grained Reconfigurable Arrays (CGRAs) are specialized accelerators commonly employed to boost performance in workloads with iterative structures. Existing research typically focuses on compiler or architecture optimizations aimed at improving CGRA performance, energy efficiency, flexibility, and area utilization, under the idealistic assumption that kernels can access all data from Scratchpad Memory (SPM). However, certain complex workloads-particularly in fields like graph analytics, irregular database operations, and specialized forms of high-performance computing (e.g., unstructured mesh simulations)-exhibit irregular memory access patterns that hinder CGRA utilization, sometimes dropping below 1.5%, making the CGRA memory-bound. To address this challenge, we conduct a thorough analysis of the underlying causes of performance degradation, then propose a redesigned memory subsystem and refine the memory model. With both microarchitectural and theoretical optimization, our solution can effectively manage irregular memory accesses through CGRA-specific runahead execution mechanism and cache reconfiguration techniques. Our results demonstrate that we can achieve performance comparable to the original SPM-only system while requiring only 1.27% of the storage size. The runahead execution mechanism achieves an average 3.04x speedup (up to 6.91x), with cache reconfiguration technique providing an additional 6.02% improvement, significantly enhancing CGRA performance for irregular memory access patterns.",
    "source": "arXiv"
  },
  {
    "title": "Metrics for Assessing Changes in Flow-based Networks",
    "title_es": "Metrics for Assessing Changes in Flow-based Networks",
    "url": "https://arxiv.org/abs/2508.09573",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09573v1 Announce Type: new \nAbstract: This paper addresses the challenges of evaluating network performance in the presence of fluctuating traffic patterns, with a particular focus on the impact of peak data rates on network resources. We introduce a set of metrics to quantify network load and measure the impact of individual flows on the overall network state. By analyzing link and flow data through percentile values and sample distributions, and introducing the Utilization Score metric, the research provides insights into resource utilization under varying network conditions. Furthermore, we employ a modified Shapley value-based approach to measure the influence of individual flows on the network, offering a better understanding of their contribution to network performance. The paper reviews and compares 11 metrics across various network scenarios, evaluating their practical relevance for research and development. Our evaluation demonstrates that these metrics effectively capture changes in network state induced by specific flows, with three of them offering a broad range of valuable insights while remaining relatively easy to maintain. Moreover, the methodology described in this paper serves as a framework for future research, with the potential to expand and refine the set of metrics used to evaluate flow impact on network performance.",
    "source": "arXiv"
  },
  {
    "title": "Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion",
    "title_es": "Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion",
    "url": "https://arxiv.org/abs/2508.09575",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09575v1 Announce Type: new \nAbstract: Recent advancements in controllable text-to-image (T2I) diffusion models, such as Ctrl-X and FreeControl, have demonstrated robust spatial and appearance control without requiring auxiliary module training. However, these models often struggle to accurately preserve spatial structures and fail to capture fine-grained conditions related to object poses and scene layouts. To address these challenges, we propose a training-free Dual Recursive Feedback (DRF) system that properly reflects control conditions in controllable T2I models. The proposed DRF consists of appearance feedback and generation feedback that recursively refines the intermediate latents to better reflect the given appearance information and the user's intent. This dual-update mechanism guides latent representations toward reliable manifolds, effectively integrating structural and appearance attributes. Our approach enables fine-grained generation even between class-invariant structure-appearance fusion, such as transferring human motion onto a tiger's form. Extensive experiments demonstrate the efficacy of our method in producing high-quality, semantically coherent, and structurally consistent image generations. Our source code is available at https://github.com/jwonkm/DRF.",
    "source": "arXiv"
  },
  {
    "title": "ESCoT: An Enhanced Step-based Coordinate Trajectory Planning Method for Multiple Car-like Robots",
    "title_es": "ESCoT: An Enhanced Step-based Coordinate Trajectory Planning Method for Multiple Car-like Robots",
    "url": "https://arxiv.org/abs/2508.09581",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09581v1 Announce Type: new \nAbstract: Multi-vehicle trajectory planning (MVTP) is one of the key challenges in multi-robot systems (MRSs) and has broad applications across various fields. This paper presents ESCoT, an enhanced step-based coordinate trajectory planning method for multiple car-like robots. ESCoT incorporates two key strategies: collaborative planning for local robot groups and replanning for duplicate configurations. These strategies effectively enhance the performance of step-based MVTP methods. Through extensive experiments, we show that ESCoT 1) in sparse scenarios, significantly improves solution quality compared to baseline step-based method, achieving up to 70% improvement in typical conflict scenarios and 34% in randomly generated scenarios, while maintaining high solving efficiency; and 2) in dense scenarios, outperforms all baseline methods, maintains a success rate of over 50% even in the most challenging configurations. The results demonstrate that ESCoT effectively solves MVTP, further extending the capabilities of step-based methods. Finally, practical robot tests validate the algorithm's applicability in real-world scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Energy-efficient PON-based Backhaul Connectivity for a VLC-enabled Indoor Fog Computing Environment",
    "title_es": "Energy-efficient PON-based Backhaul Connectivity for a VLC-enabled Indoor Fog Computing Environment",
    "url": "https://arxiv.org/abs/2508.09582",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09582v1 Announce Type: new \nAbstract: In this paper, we consider the use of visible light communication (VLC) to provide connectivity to indoor fog computing resources and propose an energy-efficient passive optical network (PON)-based backhaul architecture to support the VLC system. We develop a mixed-integer linear programming (MILP) model to optimize the allocation of computing resources over the proposed architecture, aiming to minimize processing and networking power consumption. We evaluate the performance of the proposed architecture under varying workload demands and user distributions. Comparative analysis against a backhaul architecture that is based on the state-of-the-art spine-and-leaf (S&L) network design demonstrates total power savings of up to 82%. Further comparison with centralized cloud processing shows improvements in energy efficiency of up to 93%. Additionally, we examine the improvements in energy efficiency obtained by splitting tasks among multiple processing nodes and propose enhancements to the architecture including dynamic bandwidth allocation, increased wavelength bandwidth and improved connectivity within rooms to alleviate networking bottlenecks. Furthermore, we introduce an inter-building architecture that leverages resources from neighboring buildings to support high-demand scenarios.",
    "source": "arXiv"
  },
  {
    "title": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs",
    "title_es": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs",
    "url": "https://arxiv.org/abs/2508.09584",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09584v1 Announce Type: new \nAbstract: Despite rapid advances, Large Vision-Language Models (LVLMs) still suffer from hallucinations, i.e., generating content inconsistent with input or established world knowledge, which correspond to faithfulness and factuality hallucinations, respectively. Prior studies primarily evaluate faithfulness hallucination at a coarse level (e.g., object-level) and lack fine-grained analysis. Additionally, existing benchmarks rely on costly manual curation or reused public datasets, raising concerns about scalability and data leakage. To address these limitations, we propose an automated data construction pipeline that produces scalable, controllable, and diverse evaluation data. We also design a hierarchical hallucination induction framework with input perturbations to simulate realistic noisy scenarios. Integrating these designs, we construct SHALE, a Scalable HALlucination Evaluation benchmark designed to assess both faithfulness and factuality hallucinations via a fine-grained hallucination categorization scheme. SHALE comprises over 30K image-instruction pairs spanning 12 representative visual perception aspects for faithfulness and 6 knowledge domains for factuality, considering both clean and noisy scenarios. Extensive experiments on over 20 mainstream LVLMs reveal significant factuality hallucinations and high sensitivity to semantic perturbations.",
    "source": "arXiv"
  },
  {
    "title": "Offline Auto Labeling: BAAS",
    "title_es": "Offline Auto Labeling: BAAS",
    "url": "https://arxiv.org/abs/2508.09585",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09585v1 Announce Type: new \nAbstract: This paper introduces BAAS, a new Extended Object Tracking (EOT) and fusion-based label annotation framework for radar detections in autonomous driving. Our framework utilizes Bayesian-based tracking, smoothing and eventually fusion methods to provide veritable and precise object trajectories along with shape estimation to provide annotation labels on the detection level under various supervision levels. Simultaneously, the framework provides evaluation of tracking performance and label annotation. If manually labeled data is available, each processing module can be analyzed independently or combined with other modules to enable closed-loop continuous improvements. The framework performance is evaluated in a challenging urban real-world scenario in terms of tracking performance and the label annotation errors. We demonstrate the functionality of the proposed approach for varying dynamic objects and class types",
    "source": "arXiv"
  },
  {
    "title": "EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making",
    "title_es": "EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making",
    "url": "https://arxiv.org/abs/2508.09586",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09586v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, including programming, planning, and decision-making. However, their performance often degrades when faced with highly complex problem instances that require deep reasoning over long horizons. In such cases, direct problem-solving approaches can lead to inefficiency or failure due to the lack of structured intermediate guidance. To address this, we propose a novel self-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM constructs a sequence of problem instances with gradually increasing difficulty, tailored to the solver LLM's learning progress. The curriculum dynamically adapts easing challenges when the solver struggles and escalating them when success is consistent, thus maintaining an optimal learning trajectory. This approach enables the solver LLM, implemented as a code-generation model producing Python decision-tree scripts, to progressively acquire the skills needed for complex decision-making tasks. Experimental results on challenging decision-making benchmarks show that our method significantly improves task success rates and solution efficiency compared to direct-solving baselines. These findings suggest that LLM-driven curriculum learning holds strong potential for enhancing automated reasoning in real-world, high-complexity domains.",
    "source": "arXiv"
  },
  {
    "title": "Large-Scale Topology Optimisation of Time-dependent Thermal Conduction Using Space-Time Finite Elements and a Parallel Space-Time Multigrid Preconditioner",
    "title_es": "Large-Scale Topology Optimisation of Time-dependent Thermal Conduction Using Space-Time Finite Elements and a Parallel Space-Time Multigrid Preconditioner",
    "url": "https://arxiv.org/abs/2508.09589",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09589v1 Announce Type: new \nAbstract: This paper presents a novel space-time topology optimisation framework for time-dependent thermal conduction problems, aiming to significantly reduce the time-to-solution. By treating time as an additional spatial dimension, we discretise the governing equations using a stabilised continuous Galerkin space-time finite element method. The resulting large all-at-once system is solved using an iterative Krylov solver preconditioned with a parallel space-time multigrid method employing a semi-coarsening strategy. Implemented in a fully parallel computing framework, the method yields a parallel-in-time method that demonstrates excellent scalability on a distributed-memory supercomputer, solving problems up to 4.2 billion degrees of freedom. Comparative studies show up to 52x speed-up over traditional time-stepping approaches, with only moderate increases in total computational cost in terms of core-hours. The framework is validated on benchmark problems with both time-constant and time-varying designs, and its flexibility is demonstrated through variations in material properties. These results establish the proposed space-time method as a promising approach for large-scale time-dependent topology optimisation in thermal applications.",
    "source": "arXiv"
  },
  {
    "title": "HierMoE: Accelerating MoE Training with Hierarchical Token Deduplication and Expert Swap",
    "title_es": "HierMoE: Accelerating MoE Training with Hierarchical Token Deduplication and Expert Swap",
    "url": "https://arxiv.org/abs/2508.09591",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09591v1 Announce Type: new \nAbstract: The sparsely activated mixture-of-experts (MoE) transformer has become a common architecture for large language models (LLMs) due to its sparsity, which requires fewer computational demands while easily scaling the model size. In MoE models, each MoE layer requires to dynamically choose tokens to activate particular experts for computation while the activated experts may not be located in the same device or GPU as the token. However, this leads to substantial communication and load imbalances across all GPUs, which obstructs the scalability of distributed systems within a GPU cluster. To this end, we introduce HierMoE to accelerate the training of MoE models by two topology-aware techniques: 1) token deduplication to reduce the communication traffic, and 2) expert swap to balance the workloads among all GPUs. To enable the above two proposed approaches to be more general, we build theoretical models aimed at achieving the best token duplication and expert swap strategy under different model configurations and hardware environments. We implement our prototype HierMoE system atop Megatron-LM and conduct experiments on a 32-GPU cluster with DeepSeek-V3 and Qwen3-30B-A3B models. Experimental results show that our HierMoE achieves $1.55\\times$ to $3.32\\times$ faster communication and delivers $1.18\\times$ to $1.27\\times$ faster end-to-end training compared to state-of-the-art MoE training systems, Tutel-2DH, SmartMoE, and Megatron-LM.",
    "source": "arXiv"
  },
  {
    "title": "Online Prediction with Limited Selectivity",
    "title_es": "Online Prediction with Limited Selectivity",
    "url": "https://arxiv.org/abs/2508.09592",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09592v1 Announce Type: new \nAbstract: Selective prediction [Dru13, QV19] models the scenario where a forecaster freely decides on the prediction window that their forecast spans. Many data statistics can be predicted to a non-trivial error rate without any distributional assumptions or expert advice, yet these results rely on that the forecaster may predict at any time. We introduce a model of Prediction with Limited Selectivity (PLS) where the forecaster can start the prediction only on a subset of the time horizon. We study the optimal prediction error both on an instance-by-instance basis and via an average-case analysis. We introduce a complexity measure that gives instance-dependent bounds on the optimal error. For a randomly-generated PLS instance, these bounds match with high probability.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma",
    "title_es": "Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma",
    "url": "https://arxiv.org/abs/2508.09593",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09593v1 Announce Type: new \nAbstract: Isocitrate DeHydrogenase (IDH) mutation status is a crucial biomarker for glioma prognosis. However, current prediction methods are limited by the low availability and noise of functional MRI. Structural and morphological connectomes offer a non-invasive alternative, yet existing approaches often ignore the brain's hierarchical organisation and multiscale interactions. To address this, we propose Hi-SMGNN, a hierarchical framework that integrates structural and morphological connectomes from regional to modular levels. It features a multimodal interaction module with a Siamese network and cross-modal attention, a multiscale feature fusion mechanism for reducing redundancy, and a personalised modular partitioning strategy to enhance individual specificity and interpretability. Experiments on the UCSF-PDGM dataset demonstrate that Hi-SMGNN outperforms baseline and state-of-the-art models, showing improved robustness and effectiveness in IDH mutation prediction.",
    "source": "arXiv"
  },
  {
    "title": "LLMLog: Advanced Log Template Generation via LLM-driven Multi-Round Annotation",
    "title_es": "LLMLog: Advanced Log Template Generation via LLM-driven Multi-Round Annotation",
    "url": "https://arxiv.org/abs/2508.09594",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09594v1 Announce Type: new \nAbstract: Modern computing systems, such as HDFS and Spark, produce vast quantities of logs that developers use for tasks like anomaly detection and error analysis. To simplify log analysis, template generation methods have been proposed to standardize log formats, transforming unstructured data into structured templates. Existing heuristic-based methods and neural network-based methods suffer from low accuracy problems due to the reliance on handcrafted heuristics or specific log patterns in training sets. Recently, large language models (LLMs) have shown great potential in log template generation. However, they often struggle with ambiguous, complex, or highly specific log content, which can lead to errors in generating accurate templates. To address these challenges, we propose LLMLog, a multi-round annotation framework with adaptive in-context learning. We first propose an edit-distance-based similarity metric to evaluate log similarity. Then, we introduce a method to select the most informative $k$ unlabeled logs for annotation by considering both the representativeness of the logs and the confidence of LLM predictions. Additionally, we design an adaptive context selection strategy that adaptively selects labeled logs to ensure comprehensive keyword coverage for unlabeled logs. These labeled logs serve as the context for LLMs to better understand the unlabeled logs, thereby enhancing the accuracy of template generation. Extensive experiments on sixteen datasets demonstrate that LLMLog outperforms the state-of-the-art approaches.",
    "source": "arXiv"
  },
  {
    "title": "HapticGiant: A Novel Very Large Kinesthetic Haptic Interface with Hierarchical Force Control",
    "title_es": "HapticGiant: A Novel Very Large Kinesthetic Haptic Interface with Hierarchical Force Control",
    "url": "https://arxiv.org/abs/2508.09595",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09595v1 Announce Type: new \nAbstract: Research in virtual reality and haptic technologies has consistently aimed to enhance immersion. While advanced head-mounted displays are now commercially available, kinesthetic haptic interfaces still face challenges such as limited workspaces, insufficient degrees of freedom, and kinematics not matching the human arm. In this paper, we present HapticGiant, a novel large-scale kinesthetic haptic interface designed to match the properties of the human arm as closely as possible and to facilitate natural user locomotion while providing full haptic feedback. The interface incorporates a novel admittance-type force control scheme, leveraging hierarchical optimization to render both arbitrary serial kinematic chains and Cartesian admittances. Notably, the proposed control scheme natively accounts for system limitations, including joint and Cartesian constraints, as well as singularities. Experimental results demonstrate the effectiveness of HapticGiant and its control scheme, paving the way for highly immersive virtual reality applications.",
    "source": "arXiv"
  },
  {
    "title": "Random Greedy Fast Block Kaczmarz Method for Solving Large-Scale Nonlinear Systems",
    "title_es": "Random Greedy Fast Block Kaczmarz Method for Solving Large-Scale Nonlinear Systems",
    "url": "https://arxiv.org/abs/2508.09596",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09596v1 Announce Type: new \nAbstract: To efficiently solve large scale nonlinear systems, we propose a novel Random Greedy Fast Block Kaczmarz method. This approach integrates the strengths of random and greedy strategies while avoiding the computationally expensive pseudoinversion of Jacobian submatrices, thus enabling efficient solutions for large scale problems. Our theoretical analysis establishes that the proposed method achieves linear convergence in expectation, with its convergence rates upper bound determined by the stochastic greedy condition number and the relaxation parameter. Numerical experiments confirm that when the Jacobian matrix exhibits a favorable stochastic greedy condition number and an appropriate relaxation parameter is selected, the algorithm convergence is significantly accelerated. As a result, the proposed method outperforms other comparable algorithms in both efficiency and robustness.",
    "source": "arXiv"
  },
  {
    "title": "SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing",
    "title_es": "SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing",
    "url": "https://arxiv.org/abs/2508.09597",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09597v1 Announce Type: new \nAbstract: Creating high-fidelity and editable head avatars is a pivotal challenge in computer vision and graphics, boosting many AR/VR applications. While recent advancements have achieved photorealistic renderings and plausible animation, head editing, especially real-time appearance editing, remains challenging due to the implicit representation and entangled modeling of the geometry and global appearance. To address this, we propose Surface-Volumetric Gaussian Head Avatar (SVG-Head), a novel hybrid representation that explicitly models the geometry with 3D Gaussians bound on a FLAME mesh and leverages disentangled texture images to capture the global appearance. Technically, it contains two types of Gaussians, in which surface Gaussians explicitly model the appearance of head avatars using learnable texture images, facilitating real-time texture editing, while volumetric Gaussians enhance the reconstruction quality of non-Lambertian regions (e.g., lips and hair). To model the correspondence between 3D world and texture space, we provide a mesh-aware Gaussian UV mapping method, which leverages UV coordinates given by the FLAME mesh to obtain sharp texture images and real-time rendering speed. A hierarchical optimization strategy is further designed to pursue the optimal performance in both reconstruction quality and editing flexibility. Experiments on the NeRSemble dataset show that SVG-Head not only generates high-fidelity rendering results, but also is the first method to obtain explicit texture images for Gaussian head avatars and support real-time appearance editing.",
    "source": "arXiv"
  },
  {
    "title": "Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality",
    "title_es": "Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality",
    "url": "https://arxiv.org/abs/2508.09598",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09598v1 Announce Type: new \nAbstract: Diffusion models have achieved remarkable progress in class-to-image generation. However, we observe that despite impressive FID scores, state-of-the-art models often generate distorted or low-quality images, especially in certain classes. This gap arises because FID evaluates global distribution alignment, while ignoring the perceptual quality of individual samples. We further examine the role of CFG, a common technique used to enhance generation quality. While effective in improving metrics and suppressing outliers, CFG can introduce distribution shift and visual artifacts due to its misalignment with both training objectives and user expectations. In this work, we propose FaME, a training-free and inference-efficient method for improving perceptual quality. FaME uses an image quality assessment model to identify low-quality generations and stores their sampling trajectories. These failure modes are then used as negative guidance to steer future sampling away from poor-quality regions. Experiments on ImageNet demonstrate that FaME brings consistent improvements in visual quality without compromising FID. FaME also shows the potential to be extended to improve text-to-image generation.",
    "source": "arXiv"
  },
  {
    "title": "BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation",
    "title_es": "BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation",
    "url": "https://arxiv.org/abs/2508.09599",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09599v1 Announce Type: new \nAbstract: Bird's-Eye-View (BEV) map segmentation is one of the most important and challenging tasks in autonomous driving. Camera-only approaches have drawn attention as cost-effective alternatives to LiDAR, but they still fall behind LiDAR-Camera (LC) fusion-based methods. Knowledge Distillation (KD) has been explored to narrow this gap, but existing methods mainly enlarge the student model by mimicking the teacher's architecture, leading to higher inference cost. To address this issue, we introduce BridgeTA, a cost-effective distillation framework to bridge the representation gap between LC fusion and Camera-only models through a Teacher Assistant (TA) network while keeping the student's architecture and inference cost unchanged. A lightweight TA network combines the BEV representations of the teacher and student, creating a shared latent space that serves as an intermediate representation. To ground the framework theoretically, we derive a distillation loss using Young's Inequality, which decomposes the direct teacher-student distillation path into teacher-TA and TA-student dual paths, stabilizing optimization and strengthening knowledge transfer. Extensive experiments on the challenging nuScenes dataset demonstrate the effectiveness of our method, achieving an improvement of 4.2% mIoU over the Camera-only baseline, up to 45% higher than the improvement of other state-of-the-art KD methods.",
    "source": "arXiv"
  },
  {
    "title": "OSUM-EChat: Enhancing End-to-End Empathetic Spoken Chatbot via Understanding-Driven Spoken Dialogue",
    "title_es": "OSUM-EChat: Enhancing End-to-End Empathetic Spoken Chatbot via Understanding-Driven Spoken Dialogue",
    "url": "https://arxiv.org/abs/2508.09600",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09600v1 Announce Type: new \nAbstract: Empathy is crucial in enabling natural interactions within spoken dialogue systems, allowing machines to recognize and respond appropriately to paralinguistic cues such as age, gender, and emotion. Recent advancements in end-to-end speech language models, which unify speech understanding and generation, provide promising solutions. However, several challenges persist, including an over-reliance on large-scale dialogue datasets, insufficient extraction of paralinguistic cues vital for conveying empathy, and the lack of empathy-specific datasets and evaluation frameworks. To address these issues, we introduce OSUM-EChat, an open-source, end-to-end spoken dialogue system designed to enhance empathetic interactions, particularly in resource-limited settings. OSUM-EChat introduces two key innovations: (1) a three-stage understanding-driven spoken dialogue training strategy that extends the capabilities of a large speech understanding model to spoken dialogue tasks, and (2) a linguistic-paralinguistic dual thinking mechanism that integrates paralinguistic understanding through a chain of thought with dialogue generation, enabling the system to produce more empathetic responses. This approach reduces reliance on large-scale dialogue datasets while maintaining high-quality empathetic interactions. Additionally, we introduce the EChat-200K dataset, a rich corpus of empathetic speech-to-speech dialogues, and the EChat-eval benchmark, a comprehensive framework for evaluating the empathetic capabilities of dialogue systems. Experimental results demonstrate that OSUM-EChat outperforms end-to-end spoken dialogue models regarding empathetic responsiveness, validating its effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "A Lightweight Learned Cardinality Estimation Model",
    "title_es": "A Lightweight Learned Cardinality Estimation Model",
    "url": "https://arxiv.org/abs/2508.09602",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09602v1 Announce Type: new \nAbstract: Cardinality estimation is a fundamental task in database management systems, aiming to predict query results accurately without executing the queries. However, existing techniques either achieve low estimation accuracy or incur high inference latency. Simultaneously achieving high speed and accuracy becomes critical for the cardinality estimation problem. In this paper, we propose a novel data-driven approach called CoDe (Covering with Decompositions) to address this problem. CoDe employs the concept of covering design, which divides the table into multiple smaller, overlapping segments. For each segment, CoDe utilizes tensor decomposition to accurately model its data distribution. Moreover, CoDe introduces innovative algorithms to select the best-fitting distributions for each query, combining them to estimate the final result. By employing multiple models to approximate distributions, CoDe excels in effectively modeling discrete distributions and ensuring computational efficiency. Notably, experimental results show that our method represents a significant advancement in cardinality estimation, achieving state-of-the-art levels of both estimation accuracy and inference efficiency. Across various datasets, CoDe achieves absolute accuracy in estimating more than half of the queries.",
    "source": "arXiv"
  },
  {
    "title": "The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage",
    "title_es": "The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage",
    "url": "https://arxiv.org/abs/2508.09603",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09603v1 Announce Type: new \nAbstract: Membership inference attacks serves as useful tool for fair use of language models, such as detecting potential copyright infringement and auditing data leakage. However, many current state-of-the-art attacks require access to models' hidden states or probability distribution, which prevents investigation into more widely-used, API-access only models like GPT-4. In this work, we introduce N-Gram Coverage Attack, a membership inference attack that relies solely on text outputs from the target model, enabling attacks on completely black-box models. We leverage the observation that models are more likely to memorize and subsequently generate text patterns that were commonly observed in their training data. Specifically, to make a prediction on a candidate member, N-Gram Coverage Attack first obtains multiple model generations conditioned on a prefix of the candidate. It then uses n-gram overlap metrics to compute and aggregate the similarities of these outputs with the ground truth suffix; high similarities indicate likely membership. We first demonstrate on a diverse set of existing benchmarks that N-Gram Coverage Attack outperforms other black-box methods while also impressively achieving comparable or even better performance to state-of-the-art white-box attacks - despite having access to only text outputs. Interestingly, we find that the success rate of our method scales with the attack compute budget - as we increase the number of sequences generated from the target model conditioned on the prefix, attack performance tends to improve. Having verified the accuracy of our method, we use it to investigate previously unstudied closed OpenAI models on multiple domains. We find that more recent models, such as GPT-4o, exhibit increased robustness to membership inference, suggesting an evolving trend toward improved privacy protections.",
    "source": "arXiv"
  },
  {
    "title": "BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots",
    "title_es": "BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots",
    "url": "https://arxiv.org/abs/2508.09606",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09606v1 Announce Type: new \nAbstract: \\textbf{BEAVR} is an open-source, bimanual, multi-embodiment Virtual Reality (VR) teleoperation system for robots, designed to unify real-time control, data recording, and policy learning across heterogeneous robotic platforms. BEAVR enables real-time, dexterous teleoperation using commodity VR hardware, supports modular integration with robots ranging from 7-DoF manipulators to full-body humanoids, and records synchronized multi-modal demonstrations directly in the LeRobot dataset schema. Our system features a zero-copy streaming architecture achieving $\\leq$35\\,ms latency, an asynchronous ``think--act'' control loop for scalable inference, and a flexible network API optimized for real-time, multi-robot operation. We benchmark BEAVR across diverse manipulation tasks and demonstrate its compatibility with leading visuomotor policies such as ACT, DiffusionPolicy, and SmolVLA. All code is publicly available, and datasets are released on Hugging Face\\footnote{Code, datasets, and VR app available at https://github.com/ARCLab-MIT/BEAVR-Bot.",
    "source": "arXiv"
  },
  {
    "title": "DualPhys-GS: Dual Physically-Guided 3D Gaussian Splatting for Underwater Scene Reconstruction",
    "title_es": "DualPhys-GS: Dual Physically-Guided 3D Gaussian Splatting for Underwater Scene Reconstruction",
    "url": "https://arxiv.org/abs/2508.09610",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09610v1 Announce Type: new \nAbstract: In 3D reconstruction of underwater scenes, traditional methods based on atmospheric optical models cannot effectively deal with the selective attenuation of light wavelengths and the effect of suspended particle scattering, which are unique to the water medium, and lead to color distortion, geometric artifacts, and collapsing phenomena at long distances. We propose the DualPhys-GS framework to achieve high-quality underwater reconstruction through a dual-path optimization mechanism. Our approach further develops a dual feature-guided attenuation-scattering modeling mechanism, the RGB-guided attenuation optimization model combines RGB features and depth information and can handle edge and structural details. In contrast, the multi-scale depth-aware scattering model captures scattering effects at different scales using a feature pyramid network and an attention mechanism. Meanwhile, we design several special loss functions. The attenuation scattering consistency loss ensures physical consistency. The water body type adaptive loss dynamically adjusts the weighting coefficients. The edge-aware scattering loss is used to maintain the sharpness of structural edges. The multi-scale feature loss helps to capture global and local structural information. In addition, we design a scene adaptive mechanism that can automatically identify the water-body-type characteristics (e.g., clear coral reef waters or turbid coastal waters) and dynamically adjust the scattering and attenuation parameters and optimization strategies. Experimental results show that our method outperforms existing methods in several metrics, especially in suspended matter-dense regions and long-distance scenes, and the reconstruction quality is significantly improved.",
    "source": "arXiv"
  },
  {
    "title": "Gap-SBM: A New Conceptualization of the Shifted Boundary Method with Optimal Convergence for the Neumann and Dirichlet Problems",
    "title_es": "Gap-SBM: A New Conceptualization of the Shifted Boundary Method with Optimal Convergence for the Neumann and Dirichlet Problems",
    "url": "https://arxiv.org/abs/2508.09613",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09613v1 Announce Type: new \nAbstract: We propose and mathematically analyze a new Shifted Boundary Method for the treatment of Dirichlet and Neumann boundary conditions, with provable optimal accuracy in the $L^2$- and $H^1$-norms of the error. The proposed method is built on three stages. First, the distance map between the SBM surrogate boundary and the true boundary is used to construct an approximation to the geometry of the gap between the two. Then, the representations of the numerical solution and test functions are extended from the surrogate domain to such gap. Finally, approximate quadrature formulas and specific shift operators are applied to integrate a variational formulation that also involves the fields extended in the gap. An extensive set of two-dimensional tests demonstrates the theoretical findings and the overall optimal performance of the proposed method.",
    "source": "arXiv"
  },
  {
    "title": "How Persuasive Could LLMs Be? A First Study Combining Linguistic-Rhetorical Analysis and User Experiments",
    "title_es": "How Persuasive Could LLMs Be? A First Study Combining Linguistic-Rhetorical Analysis and User Experiments",
    "url": "https://arxiv.org/abs/2508.09614",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09614v1 Announce Type: new \nAbstract: This study examines the rhetorical and linguistic features of argumentative texts generated by ChatGPT on ethically nuanced topics and investigates their persuasive impact on human readers.Through a user study involving 62 participants and pre-post interaction surveys, the paper analyzes how exposure to AI-generated arguments affects opinion change and user perception. A linguistic and rhetorical analysis of the generated texts reveals a consistent argumentative macrostructure, reliance on formulaic expressions, and limited stylistic richness. While ChatGPT demonstrates proficiency in constructing coherent argumentative texts, its persuasive efficacy appears constrained, particularly on topics involving ethical issues.The study finds that while participants often acknowledge the benefits highlighted by ChatGPT, ethical concerns tend to persist or even intensify post-interaction. The results also demonstrate a variation depending on the topic. These findings highlight new insights on AI-generated persuasion in ethically sensitive domains and are a basis for future research.",
    "source": "arXiv"
  },
  {
    "title": "MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography",
    "title_es": "MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography",
    "url": "https://arxiv.org/abs/2508.09616",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09616v1 Announce Type: new \nAbstract: We present MInDI-3D (Medical Inversion by Direct Iteration in 3D), the first 3D conditional diffusion-based model for real-world sparse-view Cone Beam Computed Tomography (CBCT) artefact removal, aiming to reduce imaging radiation exposure. A key contribution is extending the \"InDI\" concept from 2D to a full 3D volumetric approach for medical images, implementing an iterative denoising process that refines the CBCT volume directly from sparse-view input. A further contribution is the generation of a large pseudo-CBCT dataset (16,182) from chest CT volumes of the CT-RATE public dataset to robustly train MInDI-3D. We performed a comprehensive evaluation, including quantitative metrics, scalability analysis, generalisation tests, and a clinical assessment by 11 clinicians. Our results show MInDI-3D's effectiveness, achieving a 12.96 (6.10) dB PSNR gain over uncorrected scans with only 50 projections on the CT-RATE pseudo-CBCT (independent real-world) test set and enabling an 8x reduction in imaging radiation exposure. We demonstrate its scalability by showing that performance improves with more training data. Importantly, MInDI-3D matches the performance of a 3D U-Net on real-world scans from 16 cancer patients across distortion and task-based metrics. It also generalises to new CBCT scanner geometries. Clinicians rated our model as sufficient for patient positioning across all anatomical sites and found it preserved lung tumour boundaries well.",
    "source": "arXiv"
  },
  {
    "title": "Reinforcement learning in densely recurrent biological networks",
    "title_es": "Reinforcement learning in densely recurrent biological networks",
    "url": "https://arxiv.org/abs/2508.09618",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09618v1 Announce Type: new \nAbstract: Training highly recurrent networks in continuous action spaces is a technical challenge: gradient-based methods suffer from exploding or vanishing gradients, while purely evolutionary searches converge slowly in high-dimensional weight spaces. We introduce a hybrid, derivative-free optimization framework that implements reinforcement learning by coupling global evolutionary exploration with local direct search exploitation. The method, termed ENOMAD (Evolutionary Nonlinear Optimization with Mesh Adaptive Direct search), is benchmarked on a suite of food-foraging tasks instantiated in the fully mapped neural connectome of the nematode \\emph{Caenorhabditis elegans}. Crucially, ENOMAD leverages biologically derived weight priors, letting it refine--rather than rebuild--the organism's native circuitry. Two algorithmic variants of the method are introduced, which lead to either small distributed adjustments of many weights, or larger changes on a limited number of weights. Both variants significantly exceed the performance of the untrained connectome (in what can be interpreted as an example of transfer learning) and of existing training strategies. These findings demonstrate that integrating evolutionary search with nonlinear optimization provides an efficient, biologically grounded strategy for specializing natural recurrent networks towards a specified set of tasks.",
    "source": "arXiv"
  },
  {
    "title": "Duty-Cycling is Not Enough in Constrained IoT Networking: Revealing the Energy Savings of Dynamic Clock Scaling",
    "title_es": "Duty-Cycling is Not Enough in Constrained IoT Networking: Revealing the Energy Savings of Dynamic Clock Scaling",
    "url": "https://arxiv.org/abs/2508.09620",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09620v1 Announce Type: new \nAbstract: Minimizing energy consumption of low-power wireless nodes is a persistent challenge from the constrained Internet of Things (IoT). In this paper, we start from the observation that constrained IoT devices have largely different hardware (im-)balances than full-scale machines. We find that the performance gap between MCU and network throughput on constrained devices enables minimal energy delay product (EDP) for IoT networking at largely reduced clock frequencies. We analyze the potentials by integrating dynamic voltage and frequency scaling (DVFS) into the RIOT IoT operating system and show that the DVFS reconfiguration overhead stays below the energy saved for a single, downscaled MAC operation. Backed by these findings, we systematically investigate how DVFS further improves energy-efficiency for common networking tasks -- in addition to duty-cycling. We measure IoT communication scenarios between real-world systems and analyze two MAC operating modes -- CSMA/CA and time slotting -- in combination with different CoAP transactions, payload sizes, as well as DTLS transport encryption. Our experiments reveal energy savings between 24% and 52% for MAC operations and up to 37% for encrypted CoAP communication. These results shall encourage research and system design work to integrate DVFS in future IoT devices for performing tasks at their optimal frequencies and thereby significantly extending battery lifetimes.",
    "source": "arXiv"
  },
  {
    "title": "Interpretable Robot Control via Structured Behavior Trees and Large Language Models",
    "title_es": "Interpretable Robot Control via Structured Behavior Trees and Large Language Models",
    "url": "https://arxiv.org/abs/2508.09621",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09621v1 Announce Type: new \nAbstract: As intelligent robots become more integrated into human environments, there is a growing need for intuitive and reliable Human-Robot Interaction (HRI) interfaces that are adaptable and more natural to interact with. Traditional robot control methods often require users to adapt to interfaces or memorize predefined commands, limiting usability in dynamic, unstructured environments. This paper presents a novel framework that bridges natural language understanding and robotic execution by combining Large Language Models (LLMs) with Behavior Trees. This integration enables robots to interpret natural language instructions given by users and translate them into executable actions by activating domain-specific plugins. The system supports scalable and modular integration, with a primary focus on perception-based functionalities, such as person tracking and hand gesture recognition. To evaluate the system, a series of real-world experiments was conducted across diverse environments. Experimental results demonstrate that the proposed approach is practical in real-world scenarios, with an average cognition-to-execution accuracy of approximately 94%, making a significant contribution to HRI systems and robots. The complete source code of the framework is publicly available at https://github.com/snt-arg/robot_suite.",
    "source": "arXiv"
  },
  {
    "title": "AINL-Eval 2025 Shared Task: Detection of AI-Generated Scientific Abstracts in Russian",
    "title_es": "AINL-Eval 2025 Shared Task: Detection of AI-Generated Scientific Abstracts in Russian",
    "url": "https://arxiv.org/abs/2508.09622",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09622v1 Announce Type: new \nAbstract: The rapid advancement of large language models (LLMs) has revolutionized text generation, making it increasingly difficult to distinguish between human- and AI-generated content. This poses a significant challenge to academic integrity, particularly in scientific publishing and multilingual contexts where detection resources are often limited. To address this critical gap, we introduce the AINL-Eval 2025 Shared Task, specifically focused on the detection of AI-generated scientific abstracts in Russian. We present a novel, large-scale dataset comprising 52,305 samples, including human-written abstracts across 12 diverse scientific domains and AI-generated counterparts from five state-of-the-art LLMs (GPT-4-Turbo, Gemma2-27B, Llama3.3-70B, Deepseek-V3, and GigaChat-Lite). A core objective of the task is to challenge participants to develop robust solutions capable of generalizing to both (i) previously unseen scientific domains and (ii) models not included in the training data. The task was organized in two phases, attracting 10 teams and 159 submissions, with top systems demonstrating strong performance in identifying AI-generated content. We also establish a continuous shared task platform to foster ongoing research and long-term progress in this important area. The dataset and platform are publicly available at https://github.com/iis-research-team/AINL-Eval-2025.",
    "source": "arXiv"
  },
  {
    "title": "Goal Discovery with Causal Capacity for Efficient Reinforcement Learning",
    "title_es": "Goal Discovery with Causal Capacity for Efficient Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.09624",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09624v1 Announce Type: new \nAbstract: Causal inference is crucial for humans to explore the world, which can be modeled to enable an agent to efficiently explore the environment in reinforcement learning. Existing research indicates that establishing the causality between action and state transition will enhance an agent to reason how a policy affects its future trajectory, thereby promoting directed exploration. However, it is challenging to measure the causality due to its intractability in the vast state-action space of complex scenarios. In this paper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework for efficient environment exploration. Specifically, we first derive a measurement of causality in state space, \\emph{i.e.,} causal capacity, which represents the highest influence of an agent's behavior on future trajectories. After that, we present a Monte Carlo based method to identify critical points in discrete state space and further optimize this method for continuous high-dimensional environments. Those critical points are used to uncover where the agent makes important decisions in the environment, which are then regarded as our subgoals to guide the agent to make exploration more purposefully and efficiently. Empirical results from multi-objective tasks demonstrate that states with high causal capacity align with our expected subgoals, and our GDCC achieves significant success rate improvements compared to baselines.",
    "source": "arXiv"
  },
  {
    "title": "Plane Detection and Ranking via Model Information Optimization",
    "title_es": "Plane Detection and Ranking via Model Information Optimization",
    "url": "https://arxiv.org/abs/2508.09625",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09625v1 Announce Type: new \nAbstract: Plane detection from depth images is a crucial subtask with broad robotic applications, often accomplished by iterative methods such as Random Sample Consensus (RANSAC). While RANSAC is a robust strategy with strong probabilistic guarantees, the ambiguity of its inlier threshold criterion makes it susceptible to false positive plane detections. This issue is particularly prevalent in complex real-world scenes, where the true number of planes is unknown and multiple planes coexist. In this paper, we aim to address this limitation by proposing a generalised framework for plane detection based on model information optimization. Building on previous works, we treat the observed depth readings as discrete random variables, with their probability distributions constrained by the ground truth planes. Various models containing different candidate plane constraints are then generated through repeated random sub-sampling to explain our observations. By incorporating the physics and noise model of the depth sensor, we can calculate the information for each model, and the model with the least information is accepted as the most likely ground truth. This information optimization process serves as an objective mechanism for determining the true number of planes and preventing false positive detections. Additionally, the quality of each detected plane can be ranked by summing the information reduction of inlier points for each plane. We validate these properties through experiments with synthetic data and find that our algorithm estimates plane parameters more accurately compared to the default Open3D RANSAC plane segmentation. Furthermore, we accelerate our algorithm by partitioning the depth map using neural network segmentation, which enhances its ability to generate more realistic plane parameters in real-world data.",
    "source": "arXiv"
  },
  {
    "title": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation",
    "title_es": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation",
    "url": "https://arxiv.org/abs/2508.09626",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09626v1 Announce Type: new \nAbstract: In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS), traditional methods struggle to address semantic ambiguity caused by scale variations and structural occlusions in aerial images. This limits their segmentation accuracy and consistency. To tackle these challenges, we propose a novel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian point drop module, which integrates semantic confidence estimation with a learnable sparsity mechanism based on the Hard Concrete distribution. This module effectively eliminates redundant and semantically ambiguous Gaussian points, enhancing both segmentation performance and representation compactness. Furthermore, SAD-Splat incorporates a high-confidence pseudo-label generation pipeline. It leverages 2D foundation models to enhance supervision when ground-truth labels are limited, thereby further improving segmentation accuracy. To advance research in this domain, we introduce a challenging benchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse real-world aerial scenes with sparse annotations. Experimental results demonstrate that SAD-Splat achieves an excellent balance between segmentation accuracy and representation compactness. It offers an efficient and scalable solution for 3D aerial scene understanding.",
    "source": "arXiv"
  },
  {
    "title": "Physics- and geometry-aware spatio-spectral graph neural operator for time-independent and time-dependent PDEs",
    "title_es": "Physics- and geometry-aware spatio-spectral graph neural operator for time-independent and time-dependent PDEs",
    "url": "https://arxiv.org/abs/2508.09627",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09627v1 Announce Type: new \nAbstract: Solving partial differential equations (PDEs) efficiently and accurately remains a cornerstone challenge in science and engineering, especially for problems involving complex geometries and limited labeled data. We introduce a Physics- and Geometry- Aware Spatio-Spectral Graph Neural Operator ($\\pi$G-Sp$^2$GNO) for learning the solution operators of time-independent and time-dependent PDEs. The proposed approach first improves upon the recently developed Sp$^2$GNO by enabling geometry awareness and subsequently exploits the governing physics to learn the underlying solution operator in a simulation-free setup. While the spatio-spectral structure present in the proposed architecture allows multiscale learning, two separate strategies for enabling geometry awareness is introduced in this paper. For time dependent problems, we also introduce a novel hybrid physics informed loss function that combines higher-order time-marching scheme with upscaled theory inspired stochastic projection scheme. This allows accurate integration of the physics-information into the loss function. The performance of the proposed approach is illustrated on number of benchmark examples involving regular and complex domains, variation in geometry during inference, and time-independent and time-dependent problems. The results obtained illustrate the efficacy of the proposed approach as compared to the state-of-the-art physics-informed neural operator algorithms in the literature.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors",
    "title_es": "Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors",
    "url": "https://arxiv.org/abs/2508.09629",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09629v1 Announce Type: new \nAbstract: We revisit the role of texture in monocular 3D hand reconstruction, not as an afterthought for photorealism, but as a dense, spatially grounded cue that can actively support pose and shape estimation. Our observation is simple: even in high-performing models, the overlay between predicted hand geometry and image appearance is often imperfect, suggesting that texture alignment may be an underused supervisory signal. We propose a lightweight texture module that embeds per-pixel observations into UV texture space and enables a novel dense alignment loss between predicted and observed hand appearances. Our approach assumes access to a differentiable rendering pipeline and a model that maps images to 3D hand meshes with known topology, allowing us to back-project a textured hand onto the image and perform pixel-based alignment. The module is self-contained and easily pluggable into existing reconstruction pipelines. To isolate and highlight the value of texture-guided supervision, we augment HaMeR, a high-performing yet unadorned transformer architecture for 3D hand pose estimation. The resulting system improves both accuracy and realism, demonstrating the value of appearance-guided alignment in hand reconstruction.",
    "source": "arXiv"
  },
  {
    "title": "TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling",
    "title_es": "TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling",
    "url": "https://arxiv.org/abs/2508.09630",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09630v1 Announce Type: new \nAbstract: Multivariate time series data typically comprises two distinct modalities: variable semantics and sampled numerical observations. Traditional time series models treat variables as anonymous statistical signals, overlooking the rich semantic information embedded in variable names and data descriptions. However, these textual descriptors often encode critical domain knowledge that is essential for robust and interpretable modeling. Here we present TimeMKG, a multimodal causal reasoning framework that elevates time series modeling from low-level signal processing to knowledge informed inference. TimeMKG employs large language models to interpret variable semantics and constructs structured Multivariate Knowledge Graphs that capture inter-variable relationships. A dual-modality encoder separately models the semantic prompts, generated from knowledge graph triplets, and the statistical patterns from historical time series. Cross-modality attention aligns and fuses these representations at the variable level, injecting causal priors into downstream tasks such as forecasting and classification, providing explicit and interpretable priors to guide model reasoning. The experiment in diverse datasets demonstrates that incorporating variable-level knowledge significantly improves both predictive performance and generalization.",
    "source": "arXiv"
  },
  {
    "title": "AmbiGraph-Eval: Can LLMs Effectively Handle Ambiguous Graph Queries?",
    "title_es": "AmbiGraph-Eval: Can LLMs Effectively Handle Ambiguous Graph Queries?",
    "url": "https://arxiv.org/abs/2508.09631",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09631v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have recently demonstrated strong capabilities in translating natural language into database queries, especially when dealing with complex graph-structured data. However, real-world queries often contain inherent ambiguities, and the interconnected nature of graph structures can amplify these challenges, leading to unintended or incorrect query results. To systematically evaluate LLMs on this front, we propose a taxonomy of graph-query ambiguities, comprising three primary types: Attribute Ambiguity, Relationship Ambiguity, and Attribute-Relationship Ambiguity, each subdivided into Same-Entity and Cross-Entity scenarios. We introduce AmbiGraph-Eval, a novel benchmark of real-world ambiguous queries paired with expert-verified graph query answers. Evaluating 9 representative LLMs shows that even top models struggle with ambiguous graph queries. Our findings reveal a critical gap in ambiguity handling and motivate future work on specialized resolution techniques.",
    "source": "arXiv"
  },
  {
    "title": "Preacher: Paper-to-Video Agentic System",
    "title_es": "Preacher: Paper-to-Video Agentic System",
    "url": "https://arxiv.org/abs/2508.09632",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09632v1 Announce Type: new \nAbstract: The paper-to-video task converts a research paper into a structured video abstract, distilling key concepts, methods, and conclusions into an accessible, well-organized format. While state-of-the-art video generation models demonstrate potential, they are constrained by limited context windows, rigid video duration constraints, limited stylistic diversity, and an inability to represent domain-specific knowledge. To address these limitations, we introduce Preacher, the first paper-to-video agentic system. Preacher employs a top-down approach to decompose, summarize, and reformulate the paper, followed by bottom-up video generation, synthesizing diverse video segments into a coherent abstract. To align cross-modal representations, we define key scenes and introduce a Progressive Chain of Thought (P-CoT) for granular, iterative planning. Preacher successfully generates high-quality video abstracts across five research fields, demonstrating expertise beyond current video generation models. Code will be released at: https://github.com/GenVerse/Paper2Video",
    "source": "arXiv"
  },
  {
    "title": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data",
    "title_es": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data",
    "url": "https://arxiv.org/abs/2508.09636",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09636v1 Announce Type: new \nAbstract: In this paper, we present a novel model architecture for optimizing personalized product search ranking using a multi-task learning (MTL) framework. Our approach uniquely integrates tabular and non-tabular data, leveraging a pre-trained TinyBERT model for semantic embeddings and a novel sampling technique to capture diverse customer behaviors. We evaluate our model against several baselines, including XGBoost, TabNet, FT-Transformer, DCN-V2, and MMoE, focusing on their ability to handle mixed data types and optimize personalized ranking. Additionally, we propose a scalable relevance labeling mechanism based on click-through rates, click positions, and semantic similarity, offering an alternative to traditional human-annotated labels. Experimental results show that combining non-tabular data with advanced embedding techniques in multi-task learning paradigm significantly enhances model performance. Ablation studies further underscore the benefits of incorporating relevance labels, fine-tuning TinyBERT layers, and TinyBERT query-product embedding interactions. These results demonstrate the effectiveness of our approach in achieving improved personalized product search ranking.",
    "source": "arXiv"
  },
  {
    "title": "Distributed Diamond Formation of Sliding Squares",
    "title_es": "Distributed Diamond Formation of Sliding Squares",
    "url": "https://arxiv.org/abs/2508.09638",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09638v1 Announce Type: new \nAbstract: The sliding square model is a widely used abstraction for studying self-reconfigurable robotic systems, where modules are square-shaped robots that move by sliding or rotating over one another. In this paper, we propose a novel distributed algorithm that allows a group of modules to reconfigure into a diamond shape, starting from an arbitrary side-connected configuration. It is connectivity-preserving and operates under minimal assumptions: one leader module, common chirality, constant memory per module, and visibility and communication restricted to immediate neighbors. Unlike prior work, which relaxes the original sliding square move-set, our approach uses the unmodified move-set, addressing the additional challenge of handling locked configurations. Our algorithm is sequential in nature and operates with a worst-case time complexity of $\\mathcal{O}(n^2)$ rounds, which is optimal for sequential algorithms. To improve runtime, we introduce two parallel variants of the algorithm. Both rely on a spanning tree data structure, allowing modules to make decisions based on local connectivity. Our experimental results show a significant speedup for the first variant, and linear average runtime for the second variant, which is worst-case optimal for parallel algorithms.",
    "source": "arXiv"
  },
  {
    "title": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles",
    "title_es": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles",
    "url": "https://arxiv.org/abs/2508.09639",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09639v1 Announce Type: new \nAbstract: Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP), have become essential tools for interpreting complex ensemble tree-based models, especially in high-stakes domains such as healthcare analytics. However, SHAP values are usually treated as point estimates, which disregards the inherent and ubiquitous uncertainty in predictive models and data. This uncertainty has two primary sources: aleatoric and epistemic. The aleatoric uncertainty, which reflects the irreducible noise in the data. The epistemic uncertainty, which arises from a lack of data. In this work, we propose an approach for decomposing uncertainty in SHAP values into aleatoric, epistemic, and entanglement components. This approach integrates Dempster-Shafer evidence theory and hypothesis sampling via Dirichlet processes over tree ensembles. We validate the method across three real-world use cases with descriptive statistical analyses that provide insight into the nature of epistemic uncertainty embedded in SHAP explanations. The experimentations enable to provide more comprehensive understanding of the reliability and interpretability of SHAP-based attributions. This understanding can guide the development of robust decision-making processes and the refinement of models in high-stakes applications. Through our experiments with multiple datasets, we concluded that features with the highest SHAP values are not necessarily the most stable. This epistemic uncertainty can be reduced through better, more representative data and following appropriate or case-desired model development techniques. Tree-based models, especially bagging, facilitate the effective quantification of epistemic uncertainty.",
    "source": "arXiv"
  },
  {
    "title": "VisFinEval: A Scenario-Driven Chinese Multimodal Benchmark for Holistic Financial Understanding",
    "title_es": "VisFinEval: A Scenario-Driven Chinese Multimodal Benchmark for Holistic Financial Understanding",
    "url": "https://arxiv.org/abs/2508.09641",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09641v1 Announce Type: new \nAbstract: Multimodal large language models (MLLMs) hold great promise for automating complex financial analysis. To comprehensively evaluate their capabilities, we introduce VisFinEval, the first large-scale Chinese benchmark that spans the full front-middle-back office lifecycle of financial tasks. VisFinEval comprises 15,848 annotated question-answer pairs drawn from eight common financial image modalities (e.g., K-line charts, financial statements, official seals), organized into three hierarchical scenario depths: Financial Knowledge & Data Analysis, Financial Analysis & Decision Support, and Financial Risk Control & Asset Optimization. We evaluate 21 state-of-the-art MLLMs in a zero-shot setting. The top model, Qwen-VL-max, achieves an overall accuracy of 76.3%, outperforming non-expert humans but trailing financial experts by over 14 percentage points. Our error analysis uncovers six recurring failure modes-including cross-modal misalignment, hallucinations, and lapses in business-process reasoning-that highlight critical avenues for future research. VisFinEval aims to accelerate the development of robust, domain-tailored MLLMs capable of seamlessly integrating textual and visual financial information. The data and the code are available at https://github.com/SUFE-AIFLM-Lab/VisFinEval.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification",
    "title_es": "Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification",
    "url": "https://arxiv.org/abs/2508.09644",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09644v1 Announce Type: new \nAbstract: Purpose: Prenatal ultrasound is a key tool in evaluating fetal structural development and detecting abnormalities, contributing to reduced perinatal complications and improved neonatal survival. Accurate identification of standard fetal torso planes is essential for reliable assessment and personalized prenatal care. However, limitations such as low contrast and unclear texture details in ultrasound imaging pose significant challenges for fine-grained anatomical recognition. Methods: We propose a novel Multi-Contrast Fusion Module (MCFM) to enhance the model's ability to extract detailed information from ultrasound images. MCFM operates exclusively on the lower layers of the neural network, directly processing raw ultrasound data. By assigning attention weights to image representations under different contrast conditions, the module enhances feature modeling while explicitly maintaining minimal parameter overhead. Results: The proposed MCFM was evaluated on a curated dataset of fetal torso plane ultrasound images. Experimental results demonstrate that MCFM substantially improves recognition performance, with a minimal increase in model complexity. The integration of multi-contrast attention enables the model to better capture subtle anatomical structures, contributing to higher classification accuracy and clinical reliability. Conclusions: Our method provides an effective solution for improving fetal torso plane recognition in ultrasound imaging. By enhancing feature representation through multi-contrast fusion, the proposed approach supports clinicians in achieving more accurate and consistent diagnoses, demonstrating strong potential for clinical adoption in prenatal screening. The codes are available at https://github.com/sysll/MCFM.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model",
    "title_es": "Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model",
    "url": "https://arxiv.org/abs/2508.09645",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09645v1 Announce Type: new \nAbstract: Parotid gland lesion segmentation is essential for the treatment of parotid gland diseases. However, due to the variable size and complex lesion boundaries, accurate parotid gland lesion segmentation remains challenging. Recently, the Segment Anything Model (SAM) fine-tuning has shown remarkable performance in the field of medical image segmentation. Nevertheless, SAM's interaction segmentation model relies heavily on precise lesion prompts (points, boxes, masks, etc.), which are very difficult to obtain in real-world applications. Besides, current medical image segmentation methods are automatically generated, ignoring the domain knowledge of medical experts when performing segmentation. To address these limitations, we propose the parotid gland segment anything model (PG-SAM), an expert diagnosis text-guided SAM incorporating expert domain knowledge for cross-sequence parotid gland lesion segmentation. Specifically, we first propose an expert diagnosis report guided prompt generation module that can automatically generate prompt information containing the prior domain knowledge to guide the subsequent lesion segmentation process. Then, we introduce a cross-sequence attention module, which integrates the complementary information of different modalities to enhance the segmentation effect. Finally, the multi-sequence image features and generated prompts are feed into the decoder to get segmentation result. Experimental results demonstrate that PG-SAM achieves state-of-the-art performance in parotid gland lesion segmentation across three independent clinical centers, validating its clinical applicability and the effectiveness of diagnostic text for enhancing image segmentation in real-world clinical settings.",
    "source": "arXiv"
  },
  {
    "title": "Per-antenna power constraints: constructing Pareto-optimal precoders with cubic complexity under non-negligible noise conditions",
    "title_es": "Per-antenna power constraints: constructing Pareto-optimal precoders with cubic complexity under non-negligible noise conditions",
    "url": "https://arxiv.org/abs/2508.09646",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09646v1 Announce Type: new \nAbstract: Precoding matrix construction is a key element of the wireless signal processing using the multiple-input and multiple-output model. It is established that the problem of global throughput optimization under per-antenna power constraints belongs, in general, to the class of monotonic optimization problems, and is unsolvable in real-time. The most widely used real-time baseline is the suboptimal solution of Zero-Forcing, which achieves a cubic complexity by discarding the background noise coefficients. This baseline, however, is not readily adapted to per-antenna power constraints, and performs poorly if background noise coefficients are not negligible. In this paper, we are going to present a computational algorithm which constructs a precoder that is SINR multiobjective Pareto-optimal under per-antenna power constraints - with a complexity that differs from that of Zero-Forcing only by a constant factor. The algorithm has a set of input parameters, changing which skews the importance of particular user throughputs: these parameters make up an efficient parameterization of the entire Pareto boundary.",
    "source": "arXiv"
  },
  {
    "title": "ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation",
    "title_es": "ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation",
    "url": "https://arxiv.org/abs/2508.09648",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09648v1 Announce Type: new \nAbstract: Software Requirements Specification (SRS) is one of the most important documents in software projects, but writing it manually is time-consuming and often leads to ambiguity. Existing automated methods rely heavily on manual analysis, while recent Large Language Model (LLM)-based approaches suffer from hallucinations and limited controllability. In this paper, we propose ReqInOne, an LLM-based agent that follows the common steps taken by human requirements engineers when writing an SRS to convert natural language into a structured SRS. ReqInOne adopts a modular architecture by decomposing SRS generation into three tasks: summary, requirement extraction, and requirement classification, each supported by tailored prompt templates to improve the quality and consistency of LLM outputs.\n  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the generated SRSs against those produced by the holistic GPT-4-based method from prior work as well as by entry-level requirements engineers. Expert evaluations show that ReqInOne produces more accurate and well-structured SRS documents. The performance advantage of ReqInOne benefits from its modular design, and experimental results further demonstrate that its requirement classification component achieves comparable or even better results than the state-of-the-art requirement classification model.",
    "source": "arXiv"
  },
  {
    "title": "The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge",
    "title_es": "The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge",
    "url": "https://arxiv.org/abs/2508.09649",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09649v1 Announce Type: new \nAbstract: Accurate intraoperative image guidance is critical for achieving maximal safe resection in brain tumor surgery, yet neuronavigation systems based on preoperative MRI lose accuracy during the procedure due to brain shift. Aligning post-resection intraoperative ultrasound (iUS) with preoperative MRI can restore spatial accuracy by estimating brain shift deformations, but it remains a challenging problem given the large anatomical and topological changes and substantial modality intensity gap. The ReMIND2Reg 2025 Challenge provides the largest public benchmark for this task, built upon the ReMIND dataset. It offers 99 training cases, 5 validation cases, and 10 private test cases comprising paired 3D ceT1 MRI, T2 MRI, and post-resection 3D iUS volumes. Data are provided without annotations for training, while validation and test performance are evaluated on manually annotated anatomical landmarks. Metrics include target registration error (TRE), robustness to worst-case landmark misalignment (TRE30), and runtime. By establishing a standardized evaluation framework for this clinically critical and technically complex problem, ReMIND2Reg aims to accelerate the development of robust, generalizable, and clinically deployable multimodal registration algorithms for image-guided neurosurgery.",
    "source": "arXiv"
  },
  {
    "title": "TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos",
    "title_es": "TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos",
    "url": "https://arxiv.org/abs/2508.09650",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09650v1 Announce Type: new \nAbstract: Robust ball tracking under occlusion remains a key challenge in sports video analysis, affecting tasks like event detection and officiating. We present TOTNet, a Temporal Occlusion Tracking Network that leverages 3D convolutions, visibility-weighted loss, and occlusion augmentation to improve performance under partial and full occlusions. Developed in collaboration with Paralympics Australia, TOTNet is designed for real-world sports analytics. We introduce TTA, a new occlusion-rich table tennis dataset collected from professional-level Paralympic matches, comprising 9,159 samples with 1,996 occlusion cases. Evaluated on four datasets across tennis, badminton, and table tennis, TOTNet significantly outperforms prior state-of-the-art methods, reducing RMSE from 37.30 to 7.19 and improving accuracy on fully occluded frames from 0.63 to 0.80. These results demonstrate TOTNets effectiveness for offline sports analytics in fast-paced scenarios. Code and data access:\\href{https://github.com/AugustRushG/TOTNet}{AugustRushG/TOTNet}.",
    "source": "arXiv"
  },
  {
    "title": "A Close Reading Approach to Gender Narrative Biases in AI-Generated Stories",
    "title_es": "A Close Reading Approach to Gender Narrative Biases in AI-Generated Stories",
    "url": "https://arxiv.org/abs/2508.09651",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09651v1 Announce Type: new \nAbstract: The paper explores the study of gender-based narrative biases in stories generated by ChatGPT, Gemini, and Claude. The prompt design draws on Propp's character classifications and Freytag's narrative structure. The stories are analyzed through a close reading approach, with particular attention to adherence to the prompt, gender distribution of characters, physical and psychological descriptions, actions, and finally, plot development and character relationships. The results reveal the persistence of biases - especially implicit ones - in the generated stories and highlight the importance of assessing biases at multiple levels using an interpretative approach.",
    "source": "arXiv"
  },
  {
    "title": "Demystifying the Role of Rule-based Detection in AI Systems for Windows Malware Detection",
    "title_es": "Demystifying the Role of Rule-based Detection in AI Systems for Windows Malware Detection",
    "url": "https://arxiv.org/abs/2508.09652",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09652v1 Announce Type: new \nAbstract: Malware detection increasingly relies on AI systems that integrate signature-based detection with machine learning. However, these components are typically developed and combined in isolation, missing opportunities to reduce data complexity and strengthen defenses against adversarial EXEmples, carefully crafted programs designed to evade detection. Hence, in this work we investigate the influence that signature-based detection exerts on model training, when they are included inside the training pipeline. Specifically, we compare models trained on a comprehensive dataset with an AI system whose machine learning component is trained solely on samples not already flagged by signatures. Our results demonstrate improved robustness to both adversarial EXEmples and temporal data drift, although this comes at the cost of a fixed lower bound on false positives, driven by suboptimal rule selection. We conclude by discussing these limitations and outlining how future research could extend AI-based malware detection to include dynamic analysis, thereby further enhancing system resilience.",
    "source": "arXiv"
  },
  {
    "title": "On Negative-aware Preference Optimization for Recommendation",
    "title_es": "On Negative-aware Preference Optimization for Recommendation",
    "url": "https://arxiv.org/abs/2508.09653",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09653v1 Announce Type: new \nAbstract: Recommendation systems leverage user interaction data to suggest relevant items while filtering out irrelevant (negative) ones. The rise of large language models (LLMs) has garnered increasing attention for their potential in recommendation tasks. However, existing methods for optimizing LLM-based recommenders face challenges in effectively utilizing negative samples. Simply integrating large numbers of negative samples can improve ranking accuracy and mitigate popularity bias but often leads to increased computational overhead and memory costs. Additionally, current approaches fail to account for the varying informativeness of negative samples, leading to suboptimal optimization performance. To address these issues, we propose NAPO (\\textbf{N}egative-\\textbf{A}ware \\textbf{P}reference \\textbf{O}ptimization), an enhanced framework for preference optimization in LLM-based recommendation. NAPO introduces two key innovations: (1) in-batch negative sharing, which expands the pool of negative samples without additional memory overhead, and (2) dynamic reward margin adjustment, which adapts model updates based on the confidence of negative samples. Extensive experiments on three public datasets demonstrate that NAPO outperforms existing methods in both recommendation accuracy and popularity bias reduction.",
    "source": "arXiv"
  },
  {
    "title": "Improving Diversity in Language Models: When Temperature Fails, Change the Loss",
    "title_es": "Improving Diversity in Language Models: When Temperature Fails, Change the Loss",
    "url": "https://arxiv.org/abs/2508.09654",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09654v1 Announce Type: new \nAbstract: Increasing diversity in language models is a challenging yet essential objective. A common approach is to raise the decoding temperature. In this work, we investigate this approach through a simplistic yet common case to provide insights into why decreasing temperature can improve quality (Precision), while increasing it often fails to boost coverage (Recall). Our analysis reveals that for a model to be effectively tunable through temperature adjustments, it must be trained toward coverage. To address this, we propose rethinking loss functions in language models by leveraging the Precision-Recall framework. Our results demonstrate that this approach achieves a substantially better trade-off between Precision and Recall than merely combining negative log-likelihood training with temperature scaling. These findings offer a pathway toward more versatile and robust language modeling techniques.",
    "source": "arXiv"
  },
  {
    "title": "Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging",
    "title_es": "Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging",
    "url": "https://arxiv.org/abs/2508.09655",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09655v1 Announce Type: new \nAbstract: Computational imaging, especially non-line-of-sight (NLOS) imaging, the extraction of information from obscured or hidden scenes is achieved through the utilization of indirect light signals resulting from multiple reflections or scattering. The inherently weak nature of these signals, coupled with their susceptibility to noise, necessitates the integration of physical processes to ensure accurate reconstruction. This paper presents a parameterized inverse problem framework tailored for large-scale linear problems in 3D imaging reconstruction. Initially, a noise estimation module is employed to adaptively assess the noise levels present in transient data. Subsequently, a parameterized neural operator is developed to approximate the inverse mapping, facilitating end-to-end rapid image reconstruction. Our 3D image reconstruction framework, grounded in operator learning, is constructed through deep algorithm unfolding, which not only provides commendable model interpretability but also enables dynamic adaptation to varying noise levels in the acquired data, thereby ensuring consistently robust and accurate reconstruction outcomes. Furthermore, we introduce a novel method for the fusion of global and local spatiotemporal data features. By integrating structural and detailed information, this method significantly enhances both accuracy and robustness. Comprehensive numerical experiments conducted on both simulated and real datasets substantiate the efficacy of the proposed method. It demonstrates remarkable performance with fast scanning data and sparse illumination point data, offering a viable solution for NLOS imaging in complex scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Thermal Tracks: A Gaussian process-based framework for universal melting curve analysis enabling unconstrained hit identification in thermal proteome profiling experiments",
    "title_es": "Thermal Tracks: A Gaussian process-based framework for universal melting curve analysis enabling unconstrained hit identification in thermal proteome profiling experiments",
    "url": "https://arxiv.org/abs/2508.09659",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09659v1 Announce Type: new \nAbstract: Thermal Tracks is a Python-based statistical framework for analyzing protein thermal stability data that overcomes key limitations of existing thermal proteome profiling (TPP) work-flows. Unlike standard approaches that assume sigmoidal melting curves and are constrained by empirical null distributions (limiting significant hits to approximately 5 % of data), Thermal Tracks uses Gaussian Process (GP) models with squared-exponential kernels to flexibly model any melting curve shape while generating unbiased null distributions through kernel priors. This framework is particularly valuable for analyzing proteome-wide perturbations that significantly alter protein thermal stability, such as pathway inhibitions, genetic modifications, or environmental stresses, where conventional TPP methods may miss biologically relevant changes due to their statistical constraints. Furthermore, Thermal Tracks excels at analyzing proteins with un-conventional melting profiles, including phase-separating proteins and membrane proteins, which often exhibit complex, non-sigmoidal thermal stability behaviors. Thermal Tracks is freely available from GitHub and is implemented in Python, providing an accessible and flexible tool for proteome-wide thermal profiling studies.",
    "source": "arXiv"
  },
  {
    "title": "Anomaly Detection for IoT Global Connectivity",
    "title_es": "Anomaly Detection for IoT Global Connectivity",
    "url": "https://arxiv.org/abs/2508.09660",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09660v1 Announce Type: new \nAbstract: Internet of Things (IoT) application providers rely on Mobile Network Operators (MNOs) and roaming infrastructures to deliver their services globally. In this complex ecosystem, where the end-to-end communication path traverses multiple entities, it has become increasingly challenging to guarantee communication availability and reliability. Further, most platform operators use a reactive approach to communication issues, responding to user complaints only after incidents have become severe, compromising service quality. This paper presents our experience in the design and deployment of ANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity service of a large global roaming platform. ANCHOR assists engineers by filtering vast amounts of data to identify potential problematic clients (i.e., those with connectivity issues affecting several of their IoT devices), enabling proactive issue resolution before the service is critically impacted. We first describe the IoT service, infrastructure, and network visibility of the IoT connectivity provider we operate. Second, we describe the main challenges and operational requirements for designing an unsupervised anomaly detection solution on this platform. Following these guidelines, we propose different statistical rules, and machine- and deep-learning models for IoT verticals anomaly detection based on passive signaling traffic. We describe the steps we followed working with the operational teams on the design and evaluation of our solution on the operational platform, and report an evaluation on operational IoT customers.",
    "source": "arXiv"
  },
  {
    "title": "NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation",
    "title_es": "NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation",
    "url": "https://arxiv.org/abs/2508.09661",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09661v1 Announce Type: new \nAbstract: The use of synthetic data as an alternative to authentic datasets in face recognition (FR) development has gained significant attention, addressing privacy, ethical, and practical concerns associated with collecting and using authentic data. Recent state-of-the-art approaches have proposed identity-conditioned diffusion models to generate identity-consistent face images, facilitating their use in training FR models. However, these methods often lack explicit sampling mechanisms to enforce inter-class separability, leading to identity overlap in the generated data and, consequently, suboptimal FR performance. In this work, we introduce NegFaceDiff, a novel sampling method that incorporates negative conditions into the identity-conditioned diffusion process. NegFaceDiff enhances identity separation by leveraging negative conditions that explicitly guide the model away from unwanted features while preserving intra-class consistency. Extensive experiments demonstrate that NegFaceDiff significantly improves the identity consistency and separability of data generated by identity-conditioned diffusion models. Specifically, identity separability, measured by the Fisher Discriminant Ratio (FDR), increases from 2.427 to 5.687. These improvements are reflected in FR systems trained on the NegFaceDiff dataset, which outperform models trained on data generated without negative conditions across multiple benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization",
    "title_es": "EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization",
    "url": "https://arxiv.org/abs/2508.09662",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09662v1 Announce Type: new \nAbstract: The rapid advancement of large language models (LLMs) and the development of increasingly large and diverse evaluation benchmarks have introduced substantial computational challenges for model assessment. In this paper, we present EffiEval, a training-free approach for efficient benchmarking that effectively addresses data redundancy while maintaining high evaluation reliability. Our method is specifically designed to meet three key criteria for high-quality evaluation: representativeness, by ensuring comprehensive coverage of model capabilities; fairness, by remaining independent of model performance during sample selection to avoid bias; and generalizability, by enabling flexible transfer across datasets and model families without reliance on large-scale evaluation data. Unlike traditional methods that rely on absolute performance or require extensive evaluation data, our approach adaptively selects high-quality representative subsets based on the Model Utility Index (MUI). Extensive experiments on multiple public benchmarks and diverse LLMs demonstrate that EffiEval achieves strong ranking consistency with full-dataset evaluation using only a small fraction of the original data. Furthermore, our method is flexible and scalable in size, allowing users to balance evaluation efficiency and representativeness according to specific needs. Overall, EffiEval provides a practical and generalizable solution for reliable, fair, and efficient evaluation in the era of LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Closing the HPC-Cloud Convergence Gap: Multi-Tenant Slingshot RDMA for Kubernetes",
    "title_es": "Closing the HPC-Cloud Convergence Gap: Multi-Tenant Slingshot RDMA for Kubernetes",
    "url": "https://arxiv.org/abs/2508.09663",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09663v1 Announce Type: new \nAbstract: Converged HPC-Cloud computing is an emerging computing paradigm that aims to support increasingly complex and multi-tenant scientific workflows. These systems require reconciliation of the isolation requirements of native cloud workloads and the performance demands of HPC applications. In this context, networking hardware is a critical boundary component: it is the conduit for high-throughput, low-latency communication and enables isolation across tenants. HPE Slingshot is a high-speed network interconnect that provides up to 200 Gbps of throughput per port and targets high-performance computing (HPC) systems. The Slingshot host software, including hardware drivers and network middleware libraries, is designed to meet HPC deployments, which predominantly use single-tenant access modes. Hence, the Slingshot stack is not suited for secure use in multi-tenant deployments, such as converged HPC-Cloud deployments. In this paper, we design and implement an extension to the Slingshot stack targeting converged deployments on the basis of Kubernetes. Our integration provides secure, container-granular, and multi-tenant access to Slingshot RDMA networking capabilities at minimal overhead.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal Fusion And Sparse Attention-based Alignment Model for Long Sequential Recommendation",
    "title_es": "Multimodal Fusion And Sparse Attention-based Alignment Model for Long Sequential Recommendation",
    "url": "https://arxiv.org/abs/2508.09664",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09664v1 Announce Type: new \nAbstract: Recent advances in multimodal recommendation enable richer item understanding, while modeling users' multi-scale interests across temporal horizons has attracted growing attention. However, effectively exploiting multimodal item sequences and mining multi-grained user interests to substantially bridge the gap between content comprehension and recommendation remain challenging. To address these issues, we propose MUFASA, a MUltimodal Fusion And Sparse Attention-based Alignment model for long sequential recommendation. Our model comprises two core components. First, the Multimodal Fusion Layer (MFL) leverages item titles as a cross-genre semantic anchor and is trained with a joint objective of four tailored losses that promote: (i) cross-genre semantic alignment, (ii) alignment to the collaborative space for recommendation, (iii) preserving the similarity structure defined by titles and preventing modality representation collapse, and (iv) distributional regularization of the fusion space. This yields high-quality fused item representations for further preference alignment. Second, the Sparse Attention-guided Alignment Layer (SAL) scales to long user-behavior sequences via a multi-granularity sparse attention mechanism, which incorporates windowed attention, block-level attention, and selective attention, to capture user interests hierarchically and across temporal horizons. SAL explicitly models both the evolution of coherent interest blocks and fine-grained intra-block variations, producing robust user and item representations. Extensive experiments on real-world benchmarks show that MUFASA consistently surpasses state-of-the-art baselines. Moreover, online A/B tests demonstrate significant gains in production, confirming MUFASA's effectiveness in leveraging multimodal cues and accurately capturing diverse user preferences.",
    "source": "arXiv"
  },
  {
    "title": "Social-Sensor Identity Cloning Detection Using Weakly Supervised Deep Forest and Cryptographic Authentication",
    "title_es": "Social-Sensor Identity Cloning Detection Using Weakly Supervised Deep Forest and Cryptographic Authentication",
    "url": "https://arxiv.org/abs/2508.09665",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09665v1 Announce Type: new \nAbstract: Recent years have witnessed a rising trend in social-sensor cloud identity cloning incidents. However, existing approaches suffer from unsatisfactory performance, a lack of solutions for detecting duplicated accounts, and a lack of large-scale evaluations on real-world datasets. We introduce a novel method for detecting identity cloning in social-sensor cloud service providers. Our proposed technique consists of two primary components: 1) a similar identity detection method and 2) a cryptography-based authentication protocol. Initially, we developed a weakly supervised deep forest model to identify similar identities using non-privacy-sensitive user profile features provided by the service. Subsequently, we designed a cryptography-based authentication protocol to verify whether similar identities were generated by the same provider. Our extensive experiments on a large real-world dataset demonstrate the feasibility and superior performance of our technique compared to current state-of-the-art identity clone detection methods.",
    "source": "arXiv"
  },
  {
    "title": "Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation",
    "title_es": "Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation",
    "url": "https://arxiv.org/abs/2508.09666",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09666v1 Announce Type: new \nAbstract: Previous chain-of-thought (CoT) distillation methods primarily focused on enhancing the reasoning capabilities of Small Language Models (SLMs) by utilizing high-quality rationales generated by powerful Large Language Models (LLMs, e.g., GPT-4). However, few works have noted the negative effects on SLM safety brought by the training, which are revealed in this study. Although there are works on safety alignment that fine-tune language models or manipulate model weights to defend against harmful inputs, they require extra computation or annotated data, and probably impact the reasoning ability of SLMs. In this paper, we investigate how to maintain the safety of SLMs during the CoT distillation process. Specifically, we propose a safe distillation method, Slow Tuning and Low-Entropy Masking Distillation (SLowED), containing two modules: Slow Tuning and Low-Entropy Masking. Slow Tuning scales down the magnitude of model weight changes to optimize the model weights in the neighboring space near the initial weight distribution. Low-Entropy Masking masks low-entropy tokens, which are regarded as unnecessary learning targets, to exclude them from fine-tuning. Experiments on three SLMs (Qwen2.5-1.5B, Llama-3.2-1B, BLOOM-1.1B) across reasoning benchmarks (BBH, BB-Sub, ARC, AGIEval) and safety evaluation (AdvBench) show that SLowED retains the safety of SLMs and comparably improves their reasoning capability compared to existing distillation methods. Furthermore, our ablation study presents the effectiveness of Slow Tuning and Low-Entropy Masking, with the former maintaining the model's safety in the early stage and the latter prolonging the safe training epochs.",
    "source": "arXiv"
  },
  {
    "title": "GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors",
    "title_es": "GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors",
    "url": "https://arxiv.org/abs/2508.09667",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09667v1 Announce Type: new \nAbstract: Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from sparse views is an ill-posed problem due to insufficient information, often resulting in noticeable artifacts. While recent approaches have sought to leverage generative priors to complete information for under-constrained regions, they struggle to generate content that remains consistent with input observations. To address this challenge, we propose GSFixer, a novel framework designed to improve the quality of 3DGS representations reconstructed from sparse inputs. The core of our approach is the reference-guided video restoration model, built upon a DiT-based video diffusion model trained on paired artifact 3DGS renders and clean frames with additional reference-based conditions. Considering the input sparse views as references, our model integrates both 2D semantic features and 3D geometric features of reference views extracted from the visual geometry foundation model, enhancing the semantic coherence and 3D consistency when fixing artifact novel views. Furthermore, considering the lack of suitable benchmarks for 3DGS artifact restoration evaluation, we present DL3DV-Res which contains artifact frames rendered using low-quality 3DGS. Extensive experiments demonstrate our GSFixer outperforms current state-of-the-art methods in 3DGS artifact restoration and sparse-view 3D reconstruction. Project page: https://github.com/GVCLab/GSFixer.",
    "source": "arXiv"
  },
  {
    "title": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement",
    "title_es": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement",
    "url": "https://arxiv.org/abs/2508.09670",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09670v1 Announce Type: new \nAbstract: Recent advances demonstrate that reinforcement learning with verifiable rewards (RLVR) significantly enhances the reasoning capabilities of large language models (LLMs). However, standard RLVR faces challenges with reward sparsity, where zero rewards from consistently incorrect candidate answers provide no learning signal, particularly in challenging tasks. To address this, we propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative framework that utilizes diverse expert prompts as system prompts to generate a broader range of responses, substantially increasing the likelihood of identifying correct solutions. Additionally, we introduce an inter-expert mutual learning mechanism that facilitates knowledge sharing and transfer among experts, further boosting the model's performance through RLVR. Extensive experiments across multiple reasoning benchmarks show that MEML-GRPO delivers significant improvements, achieving an average performance gain of 4.89% with Qwen and 11.33% with Llama, effectively overcoming the core limitations of traditional RLVR methods.",
    "source": "arXiv"
  },
  {
    "title": "Succinct Oblivious Tensor Evaluation and Applications: Adaptively-Secure Laconic Function Evaluation and Trapdoor Hashing for All Circuits",
    "title_es": "Succinct Oblivious Tensor Evaluation and Applications: Adaptively-Secure Laconic Function Evaluation and Trapdoor Hashing for All Circuits",
    "url": "https://arxiv.org/abs/2508.09673",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09673v1 Announce Type: new \nAbstract: We propose the notion of succinct oblivious tensor evaluation (OTE), where two parties compute an additive secret sharing of a tensor product of two vectors $\\mathbf{x} \\otimes \\mathbf{y}$, exchanging two simultaneous messages. Crucially, the size of both messages and of the CRS is independent of the dimension of $\\mathbf{x}$.\n  We present a construction of OTE with optimal complexity from the standard learning with errors (LWE) problem. Then we show how this new technical tool enables a host of cryptographic primitives, all with security reducible to LWE, such as:\n  * Adaptively secure laconic function evaluation for depth-$D$ functions $f:\\{0, 1\\}^m\\rightarrow\\{0, 1\\}^\\ell$ with communication $m+\\ell+D\\cdot \\mathrm{poly}(\\lambda)$.\n  * A trapdoor hash function for all functions.\n  * An (optimally) succinct homomorphic secret sharing for all functions.\n  * A rate-$1/2$ laconic oblivious transfer for batch messages, which is best possible.\n  In particular, we obtain the first laconic function evaluation scheme that is adaptively secure from the standard LWE assumption, improving upon Quach, Wee, and Wichs (FOCS 2018).\n  As a key technical ingredient, we introduce a new notion of \\emph{adaptive lattice encodings}, which may be of independent interest.",
    "source": "arXiv"
  },
  {
    "title": "DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity",
    "title_es": "DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity",
    "url": "https://arxiv.org/abs/2508.09676",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09676v1 Announce Type: new \nAbstract: This study investigates the implementation and efficacy of DeputyDev, an AI-powered code review assistant developed to address inefficiencies in the software development process. The process of code review is highly inefficient for several reasons, such as it being a time-consuming process, inconsistent feedback, and review quality not being at par most of the time. Using our telemetry data, we observed that at TATA 1mg, pull request (PR) processing exhibits significant inefficiencies, with average pick-up and review times of 73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review cycle was marked by prolonged iterative communication between the reviewing and submitting parties. Research from the University of California, Irvine indicates that interruptions can lead to an average of 23 minutes of lost focus, critically affecting code quality and timely delivery. To address these challenges, we developed DeputyDev's PR review capabilities by providing automated, contextual code reviews. We conducted a rigorous double-controlled A/B experiment involving over 200 engineers to evaluate DeputyDev's impact on review times. The results demonstrated a statistically significant reduction in both average per PR (23.09%) and average per-line-of-code (40.13%) review durations. After implementing safeguards to exclude outliers, DeputyDev has been effectively rolled out across the entire organisation. Additionally, it has been made available to external companies as a Software-as-a-Service (SaaS) solution, currently supporting the daily work of numerous engineering professionals. This study explores the implementation and effectiveness of AI-assisted code reviews in improving development workflow timelines and code.",
    "source": "arXiv"
  },
  {
    "title": "Metering traffic flows for perimeter control through auction-based signalling using connected vehicles",
    "title_es": "Metering traffic flows for perimeter control through auction-based signalling using connected vehicles",
    "url": "https://arxiv.org/abs/2508.09678",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09678v1 Announce Type: new \nAbstract: Urban traffic congestion remains a critical challenge in modern cities, with traffic signal control systems often struggling to manage congestion during peak travel times. Perimeter control of a Protected Network (PN) has emerged as a potential solution to reducing gridlock in urban networks. This paper proposes a novel auction-based mechanism for green time allocation at signalized intersections, for effective perimeter control application. Utilising a Sealed Bid, Second Price auction framework, our approach combines real-time traffic monitoring with market-inspired mechanisms to regulate vehicle inflows into PN areas. Unlike existing methods that focus primarily on gated links, our system allocates budgets to individual traffic movements, providing greater flexibility in managing multi-directional flows. We evaluate the proposed mechanism using a test case intersection with a single controlled inflow, comparing it against a volume-based fixed-time approach. The results demonstrate that our auction-based method controls flows into the PN with improved accuracy, outperforming the volume-based approach in terms of inflow regulation, queue management and delays. The framework can be applied in real time to any generic intersection, offering a scalable solution for urban traffic management. This work bridges the gap between perimeter control and market-based intersection auctions, providing a pathway for further research on adaptive traffic management systems.",
    "source": "arXiv"
  },
  {
    "title": "Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering",
    "title_es": "Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering",
    "url": "https://arxiv.org/abs/2508.09680",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09680v1 Announce Type: new \nAbstract: Research has highlighted the valuable contributions of autistic individuals in the Information and Communication Technology (ICT) sector, particularly in areas such as software development, testing, and cybersecurity. Their strengths in information processing, attention to detail, innovative thinking, and commitment to high-quality outcomes in the ICT domain are well-documented. However, despite their potential, autistic individuals often face barriers in Software Engineering (SE) roles due to a lack of personalised tools, complex work environments, non-inclusive recruitment practices, limited co-worker support, challenging social dynamics and so on. Motivated by the ethical framework of the neurodiversity movement and the success of pioneering initiatives like the Dandelion program, corporate Diversity, Equity, and Inclusion (DEI) in the ICT sector has increasingly focused on autistic talent. This movement fundamentally reframes challenges not as individual deficits but as failures of environments designed for a neurotypical majority. Despite this progress, there is no synthesis of knowledge reporting the full pathway from software engineering education through to sustainable workplace inclusion. To address this, we conducted a Systematic Review of 30 studies and identified 18 success factors grouped into four thematic categories: (1) Software Engineering Education, (2) Career and Employment Training, (3) Work Environment, and (4) Tools and Assistive Technologies. Our findings offer evidence-based recommendations for educational institutions, employers, organisations, and tool developers to enhance the inclusion of autistic individuals in SE. These include strategies for inclusive meeting and collaboration practices, accessible and structured work environments, clear role and responsibility definitions, and the provision of tailored workplace accommodations.",
    "source": "arXiv"
  },
  {
    "title": "Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision",
    "title_es": "Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision",
    "url": "https://arxiv.org/abs/2508.09681",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09681v1 Announce Type: new \nAbstract: We proposed a novel test-time optimisation (TTO) approach framed by a NeRF-based architecture for long-term 3D point tracking. Most current methods in point tracking struggle to obtain consistent motion or are limited to 2D motion. TTO approaches frame the solution for long-term tracking as optimising a function that aggregates correspondences from other specialised state-of-the-art methods. Unlike the state-of-the-art on TTO, we propose parametrising such a function with our new invertible Neural Radiance Field (InvNeRF) architecture to perform both 2D and 3D tracking in surgical scenarios. Our approach allows us to exploit the advantages of a rendering-based approach by supervising the reprojection of pixel correspondences. It adapts strategies from recent rendering-based methods to obtain a bidirectional deformable-canonical mapping, to efficiently handle a defined workspace, and to guide the rays' density. It also presents our multi-scale HexPlanes for fast inference and a new algorithm for efficient pixel sampling and convergence criteria. We present results in the STIR and SCARE datasets, for evaluating point tracking and testing the integration of kinematic data in our pipeline, respectively. In 2D point tracking, our approach surpasses the precision and accuracy of the TTO state-of-the-art methods by nearly 50% on average precision, while competing with other approaches. In 3D point tracking, this is the first TTO approach, surpassing feed-forward methods while incorporating the benefits of a deformable NeRF-based reconstruction.",
    "source": "arXiv"
  },
  {
    "title": "A Divide-and-Conquer Tiling Method for the Design of Large Aperiodic Phased Arrays",
    "title_es": "A Divide-and-Conquer Tiling Method for the Design of Large Aperiodic Phased Arrays",
    "url": "https://arxiv.org/abs/2508.09682",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09682v1 Announce Type: new \nAbstract: Due to the growing request from modern wireless applications of cost-affordable and high-gain scanning antenna solutions, the design of large phased arrays (PAs) with radiating elements organized into modular clusters with sub-array-only amplitude and phase control is a key topic. In this paper, an innovative irregular tiling method is proposed where, according to a divide-and-conquer strategy, the antenna aperture is subdivided into sub-areas that are locally domino-tiled by jointly fulfilling the full-coverage condition on the remaining untiled part of the PA support. Selected representative results, including comparisons with competitive state-of-the-art synthesis methods, are reported to prove the effectiveness and the computational efficiency of the proposed tiling approach. Use-cases of current relevance for low Earth orbit (LEO) satellite communications are discussed, as well, to provide the antenna designers useful practical guidelines for handling large PAs.",
    "source": "arXiv"
  },
  {
    "title": "Global Convergence Analysis of Vanilla Gradient Descent for Asymmetric Matrix Completion",
    "title_es": "Global Convergence Analysis of Vanilla Gradient Descent for Asymmetric Matrix Completion",
    "url": "https://arxiv.org/abs/2508.09685",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09685v1 Announce Type: new \nAbstract: This paper investigates the asymmetric low-rank matrix completion problem, which can be formulated as an unconstrained non-convex optimization problem with a nonlinear least-squares objective function, and is solved via gradient descent methods. Previous gradient descent approaches typically incorporate regularization terms into the objective function to guarantee convergence. However, numerical experiments and theoretical analysis of the gradient flow both demonstrate that the elimination of regularization terms in gradient descent algorithms does not adversely affect convergence performance. By introducing the leave-one-out technique, we inductively prove that the vanilla gradient descent with spectral initialization achieves a linear convergence rate with high probability. Besides, we demonstrate that the balancing regularization term exhibits a small norm during iterations, which reveals the implicit regularization property of gradient descent. Empirical results show that our algorithm has a lower computational cost while maintaining comparable completion performance compared to other gradient descent algorithms.",
    "source": "arXiv"
  },
  {
    "title": "Hermitian Self-dual Twisted Generalized Reed-Solomon Codes",
    "title_es": "Hermitian Self-dual Twisted Generalized Reed-Solomon Codes",
    "url": "https://arxiv.org/abs/2508.09687",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09687v1 Announce Type: new \nAbstract: Self-dual maximum distance separable (MDS) codes over finite fields are linear codes with significant combinatorial and cryptographic applications. Twisted generalized Reed-Solomon (TGRS) codes can be both MDS and self-dual. In this paper, we study a general class of TGRS codes (A-TGRS), which encompasses all previously known special cases. First, we establish a sufficient and necessary condition for an A-TGRS code to be Hermitian self-dual. Furthermore, we present four constructions of self-dual TGRS codes, which, to the best of our knowledge, nearly cover all the related results previously reported in the literature. More importantly, we also obtain several new classes of Hermitian self-dual TGRS codes with flexible parameters. Based on this framework, we derive a sufficient and necessary condition for an A-TGRS code to be Hermitian self-dual and MDS. In addition, we construct a class of MDS Hermitian self-dual TGRS code by appropriately selecting the evaluation points. This work investigates the Hermitian self-duality of TGRS codes from the perspective of matrix representation, leading to more concise and transparent analysis. More generally, the Euclidean self-dual TGRS codes and the Hermitian self-dual GRS codes can also be understood easily from this point.",
    "source": "arXiv"
  },
  {
    "title": "PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training",
    "title_es": "PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training",
    "url": "https://arxiv.org/abs/2508.09691",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09691v1 Announce Type: new \nAbstract: Facial representation pre-training is crucial for tasks like facial recognition, expression analysis, and virtual reality. However, existing methods face three key challenges: (1) failing to capture distinct facial features and fine-grained semantics, (2) ignoring the spatial structure inherent to facial anatomy, and (3) inefficiently utilizing limited labeled data. To overcome these, we introduce PaCo-FR, an unsupervised framework that combines masked image modeling with patch-pixel alignment. Our approach integrates three innovative components: (1) a structured masking strategy that preserves spatial coherence by aligning with semantically meaningful facial regions, (2) a novel patch-based codebook that enhances feature discrimination with multiple candidate tokens, and (3) spatial consistency constraints that preserve geometric relationships between facial components. PaCo-FR achieves state-of-the-art performance across several facial analysis tasks with just 2 million unlabeled images for pre-training. Our method demonstrates significant improvements, particularly in scenarios with varying poses, occlusions, and lighting conditions. We believe this work advances facial representation learning and offers a scalable, efficient solution that reduces reliance on expensive annotated datasets, driving more effective facial analysis systems.",
    "source": "arXiv"
  },
  {
    "title": "Temporal Anchoring in Deepening Embedding Spaces: Event-Indexed Projections, Drift, Convergence, and an Internal Computational Architecture",
    "title_es": "Temporal Anchoring in Deepening Embedding Spaces: Event-Indexed Projections, Drift, Convergence, and an Internal Computational Architecture",
    "url": "https://arxiv.org/abs/2508.09693",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09693v1 Announce Type: new \nAbstract: We develop an operator-theoretic framework for temporal anchoring in embedding spaces, modeled as drift maps interleaved with event-indexed blocks culminating in affine projections. We provide complete proofs for a variable-block contraction lemma (products of Lipschitz factors), a drift--projection convergence theorem with explicit uniform-gap envelopes, and ontological convergence under nested affine anchors with a robustness variant. We formalize an internal Manuscript Computer (MC) whose computations are defined purely by these operators and prove a rigorous finite-run equivalence theorem (with perturbation bounds). For attention layers, we give a self-contained proof that softmax is $1/2$-Lipschitz in $\\ell_2$ and derive sufficient layer-contraction conditions (orthogonal/non-orthogonal heads). All floats are placed exactly where written; the manuscript uses only in-paper pseudocode and appendix figures.",
    "source": "arXiv"
  },
  {
    "title": "Fluid Reconfigurable Intelligent Surface with Element-Level Pattern Reconfigurability: Beamforming and Pattern Co-Design",
    "title_es": "Fluid Reconfigurable Intelligent Surface with Element-Level Pattern Reconfigurability: Beamforming and Pattern Co-Design",
    "url": "https://arxiv.org/abs/2508.09695",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09695v1 Announce Type: new \nAbstract: This paper proposes a novel pattern-reconfigurable fluid reconfigurable intelligent surface (FRIS) framework, where each fluid element can dynamically adjust its radiation pattern based on instantaneous channel conditions. To evaluate its potential, we first conduct a comparative analysis of the received signal power in point-to-point communication systems assisted by three types of surfaces: (1) the proposed pattern-reconfigurable FRIS, (2) a position-reconfigurable FRIS, and (3) a conventional RIS. Theoretical results demonstrate that the pattern-reconfigurable FRIS provides a significant advantage in modulating transmission signals compared to the other two configurations. To further study its capabilities, we extend the framework to a multiuser communication scenario. In this context, the spherical harmonics orthogonal decomposition (SHOD) method is employed to accurately model the radiation patterns of individual fluid elements, making the pattern design process more tractable. An optimization problem is then formulated with the objective of maximizing the weighted sum rate among users by jointly designing the active beamforming vectors and the spherical harmonics coefficients, subject to both transmit power and pattern energy constraints. To tackle the resulting non-convex optimization problem, we propose an iterative algorithm that alternates between a minimum mean-square error (MMSE) approach for active beamforming and a Riemannian conjugate gradient (RCG) method for updating the spherical harmonics coefficients. Simulation results show that the proposed pattern-reconfigurable FRIS significantly outperforms traditional RIS architectures based on the 3GPP 38.901 and isotropic radiation models, achieving average performance gains of 161.5% and 176.2%, respectively.",
    "source": "arXiv"
  },
  {
    "title": "Combating Noisy Labels via Dynamic Connection Masking",
    "title_es": "Combating Noisy Labels via Dynamic Connection Masking",
    "url": "https://arxiv.org/abs/2508.09697",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09697v1 Announce Type: new \nAbstract: Noisy labels are inevitable in real-world scenarios. Due to the strong capacity of deep neural networks to memorize corrupted labels, these noisy labels can cause significant performance degradation. Existing research on mitigating the negative effects of noisy labels has mainly focused on robust loss functions and sample selection, with comparatively limited exploration of regularization in model architecture. Inspired by the sparsity regularization used in Kolmogorov-Arnold Networks (KANs), we propose a Dynamic Connection Masking (DCM) mechanism for both Multi-Layer Perceptron Networks (MLPs) and KANs to enhance the robustness of classifiers against noisy labels. The mechanism can adaptively mask less important edges during training by evaluating their information-carrying capacity. Through theoretical analysis, we demonstrate its efficiency in reducing gradient error. Our approach can be seamlessly integrated into various noise-robust training methods to build more robust deep networks, including robust loss functions, sample selection strategies, and regularization techniques. Extensive experiments on both synthetic and real-world benchmarks demonstrate that our method consistently outperforms state-of-the-art (SOTA) approaches. Furthermore, we are also the first to investigate KANs as classifiers against noisy labels, revealing their superior noise robustness over MLPs in real-world noisy scenarios. Our code will soon be publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Slot Attention-based Feature Filtering for Few-Shot Learning",
    "title_es": "Slot Attention-based Feature Filtering for Few-Shot Learning",
    "url": "https://arxiv.org/abs/2508.09699",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09699v1 Announce Type: new \nAbstract: Irrelevant features can significantly degrade few-shot learn ing performance. This problem is used to match queries and support images based on meaningful similarities despite the limited data. However, in this process, non-relevant fea tures such as background elements can easily lead to confu sion and misclassification. To address this issue, we pro pose Slot Attention-based Feature Filtering for Few-Shot Learning (SAFF) that leverages slot attention mechanisms to discriminate and filter weak features, thereby improving few-shot classification performance. The key innovation of SAFF lies in its integration of slot attention with patch em beddings, unifying class-aware slots into a single attention mechanism to filter irrelevant features effectively. We intro duce a similarity matrix that computes across support and query images to quantify the relevance of filtered embed dings for classification. Through experiments, we demon strate that Slot Attention performs better than other atten tion mechanisms, capturing discriminative features while reducing irrelevant information. We validate our approach through extensive experiments on few-shot learning bench marks: CIFAR-FS, FC100, miniImageNet and tieredIma geNet, outperforming several state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions",
    "title_es": "Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions",
    "url": "https://arxiv.org/abs/2508.09700",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09700v1 Announce Type: new \nAbstract: Teleoperation of beyond-human-scale robotic manipulators (BHSRMs) presents unique challenges that differ fundamentally from conventional human-scale systems. As these platforms gain relevance in industrial domains such as construction, mining, and disaster response, immersive interfaces must be rethought to support scalable, safe, and effective human-robot collaboration. This paper investigates the control, cognitive, and interface-level challenges of immersive teleoperation in BHSRMs, with a focus on ensuring operator safety, minimizing sensorimotor mismatch, and enhancing the sense of embodiment. We analyze design trade-offs in haptic and visual feedback systems, supported by early experimental comparisons of exoskeleton- and joystick-based control setups. Finally, we outline key research directions for developing new evaluation tools, scaling strategies, and human-centered safety models tailored to large-scale robotic telepresence.",
    "source": "arXiv"
  },
  {
    "title": "MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers",
    "title_es": "MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers",
    "url": "https://arxiv.org/abs/2508.09709",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09709v1 Announce Type: new \nAbstract: Recent advances in diffusion models have significantly improved the performance of reference-guided line art colorization. However, existing methods still struggle with region-level color consistency, especially when the reference and target images differ in character pose or motion. Instead of relying on external matching annotations between the reference and target, we propose to discover semantic correspondences implicitly through internal attention mechanisms. In this paper, we present MangaDiT, a powerful model for reference-guided line art colorization based on Diffusion Transformers (DiT). Our model takes both line art and reference images as conditional inputs and introduces a hierarchical attention mechanism with a dynamic attention weighting strategy. This mechanism augments the vanilla attention with an additional context-aware path that leverages pooled spatial features, effectively expanding the model's receptive field and enhancing region-level color alignment. Experiments on two benchmark datasets demonstrate that our method significantly outperforms state-of-the-art approaches, achieving superior performance in both qualitative and quantitative evaluations.",
    "source": "arXiv"
  },
  {
    "title": "GraphTreeGen: Subtree-Centric Approach to Efficient and Supervised Graph Generation",
    "title_es": "GraphTreeGen: Subtree-Centric Approach to Efficient and Supervised Graph Generation",
    "url": "https://arxiv.org/abs/2508.09710",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09710v1 Announce Type: new \nAbstract: Brain connectomes, representing neural connectivity as graphs, are crucial for understanding brain organization but costly and time-consuming to acquire, motivating generative approaches. Recent advances in graph generative modeling offer a data-driven alternative, enabling synthetic connectome generation and reducing dependence on large neuroimaging datasets. However, current models face key limitations: (i) compressing the whole graph into a single latent code (e.g., VGAEs) blurs fine-grained local motifs; (ii) relying on rich node attributes rarely available in connectomes reduces reconstruction quality; (iii) edge-centric models emphasize topology but overlook accurate edge-weight prediction, harming quantitative fidelity; and (iv) computationally expensive designs (e.g., edge-conditioned convolutions) impose high memory demands, limiting scalability. We propose GraphTreeGen (GTG), a subtree-centric generative framework for efficient, accurate connectome synthesis. GTG decomposes each connectome into entropy-guided k-hop trees capturing informative local structure, encoded by a shared GCN. A bipartite message-passing layer fuses subtree embeddings with global node features, while a dual-branch decoder jointly predicts edge existence and weights to reconstruct the adjacency matrix. GTG outperforms state-of-the-art baselines in self-supervised tasks and remains competitive in supervised settings, delivering higher structural fidelity and more precise weights with far less memory. Its modular design enables extensions to connectome super-resolution and cross-modality synthesis. Code: https://github.com/basiralab/GTG/",
    "source": "arXiv"
  },
  {
    "title": "Evaluating the Role of Large Language Models in Legal Practice in India",
    "title_es": "Evaluating the Role of Large Language Models in Legal Practice in India",
    "url": "https://arxiv.org/abs/2508.09713",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09713v1 Announce Type: new \nAbstract: The integration of Artificial Intelligence(AI) into the legal profession raises significant questions about the capacity of Large Language Models(LLM) to perform key legal tasks. In this paper, I empirically evaluate how well LLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian context, including issue spotting, legal drafting, advice, research, and reasoning. Through a survey experiment, I compare outputs from LLMs with those of a junior lawyer, with advanced law students rating the work on helpfulness, accuracy, and comprehensiveness. LLMs excel in drafting and issue spotting, often matching or surpassing human work. However, they struggle with specialised legal research, frequently generating hallucinations, factually incorrect or fabricated outputs. I conclude that while LLMs can augment certain legal tasks, human expertise remains essential for nuanced reasoning and the precise application of law.",
    "source": "arXiv"
  },
  {
    "title": "NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation",
    "title_es": "NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation",
    "url": "https://arxiv.org/abs/2508.09715",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09715v1 Announce Type: new \nAbstract: The rapid growth of multimodal medical imaging data presents significant storage and transmission challenges, particularly in resource-constrained clinical settings. We propose NEURAL, a novel framework that addresses this by using semantics-guided data compression. Our approach repurposes cross-attention scores between the image and its radiological report from a fine-tuned generative vision-language model to structurally prune chest X-rays, preserving only diagnostically critical regions. This process transforms the image into a highly compressed, graph representation. This unified graph-based representation fuses the pruned visual graph with a knowledge graph derived from the clinical report, creating a universal data structure that simplifies downstream modeling. Validated on the MIMIC-CXR and CheXpert Plus dataset for pneumonia detection, NEURAL achieves a 93.4-97.7\\% reduction in image data size while maintaining a high diagnostic performance of 0.88-0.95 AUC, outperforming other baseline models that use uncompressed data. By creating a persistent, task-agnostic data asset, NEURAL resolves the trade-off between data size and clinical utility, enabling efficient workflows and teleradiology without sacrificing performance. Our NEURAL code is available at https://github.com/basiralab/NEURAL.",
    "source": "arXiv"
  },
  {
    "title": "The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models",
    "title_es": "The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.09716",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09716v1 Announce Type: new \nAbstract: Information visualizations are powerful tools that help users quickly identify patterns, trends, and outliers, facilitating informed decision-making. However, when visualizations incorporate deceptive design elements-such as truncated or inverted axes, unjustified 3D effects, or violations of best practices-they can mislead viewers and distort understanding, spreading misinformation. While some deceptive tactics are obvious, others subtly manipulate perception while maintaining a facade of legitimacy. As Vision-Language Models (VLMs) are increasingly used to interpret visualizations, especially by non-expert users, it is critical to understand how susceptible these models are to deceptive visual designs. In this study, we conduct an in-depth evaluation of VLMs' ability to interpret misleading visualizations. By analyzing over 16,000 responses from ten different models across eight distinct types of misleading chart designs, we demonstrate that most VLMs are deceived by them. This leads to altered interpretations of charts, despite the underlying data remaining the same. Our findings highlight the need for robust safeguards in VLMs against visual misinformation.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction",
    "title_es": "Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction",
    "url": "https://arxiv.org/abs/2508.09717",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09717v1 Announce Type: new \nAbstract: Glioblastoma is a highly invasive brain tumor with rapid progression rates. Recent studies have shown that glioblastoma molecular subtype classification serves as a significant biomarker for effective targeted therapy selection. However, this classification currently requires invasive tissue extraction for comprehensive histopathological analysis. Existing multimodal approaches combining MRI and histopathology images are limited and lack robust mechanisms for preserving shared structural information across modalities. In particular, graph-based models often fail to retain discriminative features within heterogeneous graphs, and structural reconstruction mechanisms for handling missing or incomplete modality data are largely underexplored. To address these limitations, we propose a novel sheaf-based framework for structure-aware and consistent fusion of MRI and histopathology data. Our model outperforms baseline methods and demonstrates robustness in incomplete or missing data scenarios, contributing to the development of virtual biopsy tools for rapid diagnostics. Our source code is available at https://github.com/basiralab/MMSN/.",
    "source": "arXiv"
  },
  {
    "title": "Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models",
    "title_es": "Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models",
    "url": "https://arxiv.org/abs/2508.09719",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09719v1 Announce Type: new \nAbstract: Large, publicly available clinical datasets have emerged as a novel resource for understanding disease heterogeneity and to explore personalization of therapy. These datasets are derived from data not originally collected for research purposes and, as a result, are often incomplete and lack critical labels. Many AI tools have been developed to retrospectively label these datasets, such as by performing disease classification; however, they often suffer from limited interpretability. Previous work has attempted to explain predictions using Concept Bottleneck Models (CBMs), which learn interpretable concepts that map to higher-level clinical ideas, facilitating human evaluation. However, these models often experience performance limitations when the concepts fail to adequately explain or characterize the task. We use the identification of Acute Respiratory Distress Syndrome (ARDS) as a challenging test case to demonstrate the value of incorporating contextual information from clinical notes to improve CBM performance. Our approach leverages a Large Language Model (LLM) to process clinical notes and generate additional concepts, resulting in a 10% performance gain over existing methods. Additionally, it facilitates the learning of more comprehensive concepts, thereby reducing the risk of information leakage and reliance on spurious shortcuts, thus improving the characterization of ARDS.",
    "source": "arXiv"
  },
  {
    "title": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge",
    "title_es": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge",
    "url": "https://arxiv.org/abs/2508.09724",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09724v1 Announce Type: new \nAbstract: Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but it is prone to preference bias, where judges systematically favor certain outputs, such as their own. This bias leads to inconsistent and skewed rankings across different judges. To address this, we first empirically demonstrate significant and heterogeneous biases in cross-model evaluations. We then propose UDA (Unsupervised Debiasing Alignment), a framework that reduces inter-judge disagreement by dynamically adjusting the Elo rating system. For each pairwise comparison, a compact neural network learns to adaptively set the K-factor and refine win probabilities. Crucially, UDA operates in a fully unsupervised manner, guided solely by the objective of minimizing the dispersion among the Elo trajectories of all judges. This forces an alignment towards a collective consensus, which serves as an unsupervised proxy for a more stable and reproducible evaluation. In addition, we provide theoretical motivation demonstrating how alignment towards a consensus can reduce aggregate system bias. Experiments show that UDA significantly reduces the inter-judge rating standard deviation by up to 63.4% and improves the average correlation with human judgments by 24.7%. Notably, UDA elevates the performance of poorly performing judges to achieve parity with high-quality ones, fostering a more robust and reliable evaluation ecosystem. Code and data are available at https://anonymous.4open.science/r/62AB93CD-23B4.",
    "source": "arXiv"
  },
  {
    "title": "Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning",
    "title_es": "Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning",
    "url": "https://arxiv.org/abs/2508.09726",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09726v1 Announce Type: new \nAbstract: Large language models trained with reinforcement learning with verifiable rewards tend to trade accuracy for length--inflating response lengths to achieve gains in accuracy. While longer answers may be warranted for harder problems, many tokens are merely \"filler\": repetitive, verbose text that makes no real progress. We introduce GFPO (Group Filtered Policy Optimization), which curbs this length explosion by sampling larger groups per problem during training and filtering responses to train on based on two key metrics: (1) response length and (2) token efficiency: reward per token ratio. By sampling more at training time, we teach models to think less at inference time. On the Phi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across challenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH, LiveCodeBench) while maintaining accuracy. Optimizing for reward per token further increases reductions in length inflation to 71-85%. We also propose Adaptive Difficulty GFPO, which dynamically allocates more training resources to harder problems based on real-time difficulty estimates, improving the balance between computational efficiency and accuracy especially on difficult questions. GFPO demonstrates that increased training-time compute directly translates to reduced test-time compute--a simple yet effective trade-off for efficient reasoning.",
    "source": "arXiv"
  },
  {
    "title": "MetaGuardian: Enhancing Voice Assistant Security through Advanced Acoustic Metamaterials",
    "title_es": "MetaGuardian: Enhancing Voice Assistant Security through Advanced Acoustic Metamaterials",
    "url": "https://arxiv.org/abs/2508.09728",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09728v1 Announce Type: new \nAbstract: We present MetaGuardian, a voice assistant (VA) protection system based on acoustic metamaterials. MetaGuardian can be directly integrated into the enclosures of various smart devices, effectively defending against inaudible, adversarial and laser attacks without relying on additional software support or altering the underlying hardware, ensuring usability. To achieve this, MetaGuardian leverages the mutual impedance effects between metamaterial units to extend the signal filtering range to 16-40 kHz to effectively block wide-band inaudible attacks. Additionally, it adopts a carefully designed coiled space structure to precisely interfere with adversarial attacks while ensuring the normal functioning of VAs. Furthermore, MetaGuardian offers a universal structural design, allowing itself to be flexibly adapted to various smart devices, striking a balance between portability and protection effectiveness. In controled evaluation environments, MetaGuardian achieves a high defense success rate against various attack types, including adversarial, inaudible and laser attacks.",
    "source": "arXiv"
  },
  {
    "title": "Generative Modeling with Multi-Instance Reward Learning for E-commerce Creative Optimization",
    "title_es": "Generative Modeling with Multi-Instance Reward Learning for E-commerce Creative Optimization",
    "url": "https://arxiv.org/abs/2508.09730",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09730v1 Announce Type: new \nAbstract: In e-commerce advertising, selecting the most compelling combination of creative elements -- such as titles, images, and highlights -- is critical for capturing user attention and driving conversions. However, existing methods often evaluate creative components individually, failing to navigate the exponentially large search space of possible combinations. To address this challenge, we propose a novel framework named GenCO that integrates generative modeling with multi-instance reward learning. Our unified two-stage architecture first employs a generative model to efficiently produce a diverse set of creative combinations. This generative process is optimized with reinforcement learning, enabling the model to effectively explore and refine its selections. Next, to overcome the challenge of sparse user feedback, a multi-instance learning model attributes combination-level rewards, such as clicks, to the individual creative elements. This allows the reward model to provide a more accurate feedback signal, which in turn guides the generative model toward creating more effective combinations. Deployed on a leading e-commerce platform, our approach has significantly increased advertising revenue, demonstrating its practical value. Additionally, we are releasing a large-scale industrial dataset to facilitate further research in this important domain.",
    "source": "arXiv"
  },
  {
    "title": "Besondere Anforderungen des automatisierten Fahrens an den Entwurf",
    "title_es": "Besondere Anforderungen des automatisierten Fahrens an den Entwurf",
    "url": "https://arxiv.org/abs/2508.09731",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09731v1 Announce Type: new \nAbstract: The development of automated vehicles and automated driving functions is an exceptionally complex task that requires the integration of numerous, sometimes conflicting interests and various constraints already in the early stages of system design. This chapter explains important challenges in concept specifications for automated driving and presents a systematic process model that contributes to overcoming the special requirements in this field. In addition, it describes the successful implementation of a structured concept specification for an automated vehicle guidance system.\n  --\n  Die Entwicklung automatisierter Fahrzeuge und Fahrfunktionen stellt eine ausgesprochen komplexe Aufgabe dar, die bereits im Zuge des Systementwurfs die Einbeziehung einer Vielzahl teilweise konflikt\\\"arer Interessen und diverser Randbedingungen erfordert. Dieses Kapitel erl\\\"autert wichtige Herausforderungen bei Konzeptspezifikationen im Themenfeld des automatisierten Fahrens und stellt ein systematisches Prozessmodell vor, das einen Beitrag zur Erf\\\"ullung der besonderen Anforderungen des automatisierten Fahrens an den Entwurf leistet. Dar\\\"uber hinaus wird die erfolgreiche Durchf\\\"uhrung einer strukturierten Konzeptspezifikation f\\\"ur ein automatisiertes Fahrzeugf\\\"uhrungssystem beschrieben.",
    "source": "arXiv"
  },
  {
    "title": "Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System",
    "title_es": "Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System",
    "url": "https://arxiv.org/abs/2508.09732",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09732v1 Announce Type: new \nAbstract: Recent advances in data-driven computer vision have enabled robust autonomous navigation capabilities for civil aviation, including automated landing and runway detection. However, ensuring that these systems meet the robustness and safety requirements for aviation applications remains a major challenge. In this work, we present a practical vision-based pipeline for aircraft pose estimation from runway images that represents a step toward the ability to certify these systems for use in safety-critical aviation applications. Our approach features three key innovations: (i) an efficient, flexible neural architecture based on a spatial Soft Argmax operator for probabilistic keypoint regression, supporting diverse vision backbones with real-time inference; (ii) a principled loss function producing calibrated predictive uncertainties, which are evaluated via sharpness and calibration metrics; and (iii) an adaptation of Residual-based Receiver Autonomous Integrity Monitoring (RAIM), enabling runtime detection and rejection of faulty model outputs. We implement and evaluate our pose estimation pipeline on a dataset of runway images. We show that our model outperforms baseline architectures in terms of accuracy while also producing well-calibrated uncertainty estimates with sub-pixel precision that can be used downstream for fault detection.",
    "source": "arXiv"
  },
  {
    "title": "Simpler and Faster Contiguous Art Gallery",
    "title_es": "Simpler and Faster Contiguous Art Gallery",
    "url": "https://arxiv.org/abs/2508.09734",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09734v1 Announce Type: new \nAbstract: The contiguous art gallery problem was introduced at SoCG'25 in a merged paper that combined three simultaneous results, each achieving a polynomial-time algorithm for the problem. This problem is a variant of the classical art gallery problem, first introduced by Klee in 1973. In the contiguous art gallery problem, we are given a polygon P and asked to determine the minimum number of guards needed, where each guard is assigned a contiguous portion of the boundary of P that it can see, such that all assigned portions together cover the boundary of P. The classical art gallery problem is NP-hard and ER-complete, and the three independent works investigated whether this variant admits a polynomial-time solution. Each of these works indeed presented such a solution, with the fastest running in O(k n^5 log n) time, where n denotes the number of vertices of P and k is the size of a minimum guard set covering the boundary of P. We present a solution that is both considerably simpler and significantly faster, yielding a concise and almost entirely self-contained O(k n^2 log^2 n)-time algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Route Planning and Online Routing for Quantum Key Distribution Networks",
    "title_es": "Route Planning and Online Routing for Quantum Key Distribution Networks",
    "url": "https://arxiv.org/abs/2508.09735",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09735v1 Announce Type: new \nAbstract: Quantum Key Distribution (QKD) networks harness the principles of quantum physics in order to securely transmit cryptographic key material, providing physical guarantees. These networks require traditional management and operational components, such as routing information through the network elements. However, due to the limitations on capacity and the particularities of information handling in these networks, traditional shortest paths algorithms for routing perform poorly on both route planning and online routing, which is counterintuitive. Moreover, due to the scarce resources in such networks, often the expressed demand cannot be met by any assignment of routes. To address both the route planning problem and the need for fair automated suggestions in infeasible cases, we propose to model this problem as a Quadratic Programming (QP) problem. For the online routing problem, we showcase that the shortest (available) paths routing strategy performs poorly in the online setting. Furthermore, we prove that the widest shortest path routing strategy has a competitive ratio greater or equal than $\\frac{1}{2}$, efficiently addressing both routing modes in QKD networks.",
    "source": "arXiv"
  },
  {
    "title": "Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory",
    "title_es": "Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory",
    "url": "https://arxiv.org/abs/2508.09736",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09736v1 Announce Type: new \nAbstract: We introduce M3-Agent, a novel multimodal agent framework equipped with long-term memory. Like humans, M3-Agent can process real-time visual and auditory inputs to build and update its long-term memory. Beyond episodic memory, it also develops semantic memory, enabling it to accumulate world knowledge over time. Its memory is organized in an entity-centric, multimodal format, allowing deeper and more consistent understanding of the environment. Given an instruction, M3-Agent autonomously performs multi-turn, iterative reasoning and retrieves relevant information from memory to accomplish the task. To evaluate memory effectiveness and memory-based reasoning in multimodal agents, we develop M3-Bench, a new long-video question answering benchmark. M3-Bench comprises 100 newly recorded real-world videos captured from a robot's perspective (M3-Bench-robot) and 929 web-sourced videos across diverse scenarios (M3-Bench-web). We annotate question-answer pairs designed to test key capabilities essential for agent applications, such as human understanding, general knowledge extraction, and cross-modal reasoning. Experimental results show that M3-Agent, trained via reinforcement learning, outperforms the strongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o, achieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web and VideoMME-long, respectively. Our work advances the multimodal agents toward more human-like long-term memory and provides insights into their practical design. Model, code and data are available at https://github.com/bytedance-seed/m3-agent",
    "source": "arXiv"
  },
  {
    "title": "Fast and Simple Multiclass Data Segmentation: An Eigendecomposition and Projection-Free Approach",
    "title_es": "Fast and Simple Multiclass Data Segmentation: An Eigendecomposition and Projection-Free Approach",
    "url": "https://arxiv.org/abs/2508.09738",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09738v1 Announce Type: new \nAbstract: Graph-based machine learning has seen an increased interest over the last decade with many connections to other fields of applied mathematics. Learning based on partial differential equations, such as the phase-field Allen-Cahn equation, allows efficient handling of semi-supervised learning approaches on graphs. The numerical solution of the graph Allen-Cahn equation via a convexity splitting or the Merriman-Bence-Osher (MBO) scheme, albeit being a widely used approach, requires the calculation of a graph Laplacian eigendecomposition and repeated projections over the unit simplex to maintain valid partitions. The computational efficiency of those methods is hence limited by those two bottlenecks in practice, especially when dealing with large-scale instances. In order to overcome these limitations, we propose a new framework combining a novel penalty-based reformulation of the segmentation problem, which ensures valid partitions (i.e., binary solutions) for appropriate parameter choices, with an eigendecomposition and projection-free optimization scheme, which has a small per-iteration complexity (by relying primarily on sparse matrix-vector products) and guarantees good convergence properties. Experiments on synthetic and real-world datasets related to data segmentation in networks and images demonstrate that the proposed framework achieves comparable or better accuracy than the CS and MBO methods while being significantly faster, particularly for large-scale problems.",
    "source": "arXiv"
  },
  {
    "title": "Project Submission Games in Participatory Budgeting",
    "title_es": "Project Submission Games in Participatory Budgeting",
    "url": "https://arxiv.org/abs/2508.09741",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09741v1 Announce Type: new \nAbstract: We introduce the framework of project submission games, capturing the behavior of project proposers in participatory budgeting (and multiwinner elections). Here, each proposer submits a subset of project proposals, aiming at maximizing the total cost of those that get funded. We focus on finding conditions under which pure Nash equilibria (NE) exist in our games, and on the complexity of checking whether they exist. We also seek algorithms for computing best responses for the proposers",
    "source": "arXiv"
  },
  {
    "title": "HKT: A Biologically Inspired Framework for Modular Hereditary Knowledge Transfer in Neural Networks",
    "title_es": "HKT: A Biologically Inspired Framework for Modular Hereditary Knowledge Transfer in Neural Networks",
    "url": "https://arxiv.org/abs/2508.09743",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09743v1 Announce Type: new \nAbstract: A prevailing trend in neural network research suggests that model performance improves with increasing depth and capacity - often at the cost of integrability and efficiency. In this paper, we propose a strategy to optimize small, deployable models by enhancing their capabilities through structured knowledge inheritance. We introduce Hereditary Knowledge Transfer (HKT), a biologically inspired framework for modular and selective transfer of task-relevant features from a larger, pretrained parent network to a smaller child model. Unlike standard knowledge distillation, which enforces uniform imitation of teacher outputs, HKT draws inspiration from biological inheritance mechanisms - such as memory RNA transfer in planarians - to guide a multi-stage process of feature transfer. Neural network blocks are treated as functional carriers, and knowledge is transmitted through three biologically motivated components: Extraction, Transfer, and Mixture (ETM). A novel Genetic Attention (GA) mechanism governs the integration of inherited and native representations, ensuring both alignment and selectivity. We evaluate HKT across diverse vision tasks, including optical flow (Sintel, KITTI), image classification (CIFAR-10), and semantic segmentation (LiTS), demonstrating that it significantly improves child model performance while preserving its compactness. The results show that HKT consistently outperforms conventional distillation approaches, offering a general-purpose, interpretable, and scalable solution for deploying high-performance neural networks in resource-constrained environments.",
    "source": "arXiv"
  },
  {
    "title": "ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding",
    "title_es": "ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding",
    "url": "https://arxiv.org/abs/2508.09744",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09744v1 Announce Type: new \nAbstract: Motivated by the need for channel codes with low-complexity soft-decision decoding algorithms, we consider the recursive Plotkin concatenation of optimal low-rate and high-rate codes based on simplex codes and their duals. These component codes come with low-complexity maximum likelihood (ML) decoding which, in turn, enables efficient successive cancellation (SC)-based decoding. As a result, the proposed optimally recursively concatenated simplex (ORCAS) codes achieve a performance that is at least as good as that of polar codes. For practical parameters, the proposed construction significantly outperforms polar codes in terms of block error rate by up to 0.5 dB while maintaining similar decoding complexity. Furthermore, the codes offer greater flexibility in codeword length than conventional polar codes.",
    "source": "arXiv"
  },
  {
    "title": "Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection",
    "title_es": "Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection",
    "url": "https://arxiv.org/abs/2508.09746",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09746v1 Announce Type: new \nAbstract: The goal of image harmonization is to adjust the foreground in a composite image to achieve visual consistency with the background. Recently, latent diffusion model (LDM) are applied for harmonization, achieving remarkable results. However, LDM-based harmonization faces challenges in detail preservation and limited harmonization ability. Additionally, current synthetic datasets rely on color transfer, which lacks local variations and fails to capture complex real-world lighting conditions. To enhance harmonization capabilities, we propose the Region-to-Region transformation. By injecting information from appropriate regions into the foreground, this approach preserves original details while achieving image harmonization or, conversely, generating new composite data. From this perspective, We propose a novel model R2R. Specifically, we design Clear-VAE to preserve high-frequency details in the foreground using Adaptive Filter while eliminating disharmonious elements. To further enhance harmonization, we introduce the Harmony Controller with Mask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the foreground based on the channel importance of both foreground and background regions. To address the limitation of existing datasets, we propose Random Poisson Blending, which transfers color and lighting information from a suitable region to the foreground, thereby generating more diverse and challenging synthetic images. Using this method, we construct a new synthetic dataset, RPHarmony. Experiments demonstrate the superiority of our method over other methods in both quantitative metrics and visual harmony. Moreover, our dataset helps the model generate more realistic images in real examples. Our code, dataset, and model weights have all been released for open access.",
    "source": "arXiv"
  },
  {
    "title": "A Machine Learning Approach to Predict Biological Age and its Longitudinal Drivers",
    "title_es": "A Machine Learning Approach to Predict Biological Age and its Longitudinal Drivers",
    "url": "https://arxiv.org/abs/2508.09747",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09747v1 Announce Type: new \nAbstract: Predicting an individual's aging trajectory is a central challenge in preventative medicine and bioinformatics. While machine learning models can predict chronological age from biomarkers, they often fail to capture the dynamic, longitudinal nature of the aging process. In this work, we developed and validated a machine learning pipeline to predict age using a longitudinal cohort with data from two distinct time periods (2019-2020 and 2021-2022). We demonstrate that a model using only static, cross-sectional biomarkers has limited predictive power when generalizing to future time points. However, by engineering novel features that explicitly capture the rate of change (slope) of key biomarkers over time, we significantly improved model performance. Our final LightGBM model, trained on the initial wave of data, successfully predicted age in the subsequent wave with high accuracy ($R^2 = 0.515$ for males, $R^2 = 0.498$ for females), significantly outperforming both traditional linear models and other tree-based ensembles. SHAP analysis of our successful model revealed that the engineered slope features were among the most important predictors, highlighting that an individual's health trajectory, not just their static health snapshot, is a key determinant of biological age. Our framework paves the way for clinical tools that dynamically track patient health trajectories, enabling early intervention and personalized prevention strategies for age-related diseases.",
    "source": "arXiv"
  },
  {
    "title": "$\\mu$-Parametrization for Mixture of Experts",
    "title_es": "$\\mu$-Parametrization for Mixture of Experts",
    "url": "https://arxiv.org/abs/2508.09752",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09752v1 Announce Type: new \nAbstract: Recent years have seen a growing interest and adoption of LLMs, with $\\mu$Transfer becoming a key technique for tuning hyperparameters in large-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a leading architecture in extremely large models. However, the intersection of these two advancements has remained unexplored. In this work, we derive a $\\mu$-Parameterization ($\\mu$P) for MoE, providing theoretical guarantees for feature learning across model widths in both the router and experts. We empirically validate our parameterization and further investigate how scaling the number of experts and granularity affects the optimal learning rate.",
    "source": "arXiv"
  },
  {
    "title": "TriForecaster: A Mixture of Experts Framework for Multi-Region Electric Load Forecasting with Tri-dimensional Specialization",
    "title_es": "TriForecaster: A Mixture of Experts Framework for Multi-Region Electric Load Forecasting with Tri-dimensional Specialization",
    "url": "https://arxiv.org/abs/2508.09753",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09753v1 Announce Type: new \nAbstract: Electric load forecasting is pivotal for power system operation, planning and decision-making. The rise of smart grids and meters has provided more detailed and high-quality load data at multiple levels of granularity, from home to bus and cities. Motivated by similar patterns of loads across different cities in a province in eastern China, in this paper we focus on the Multi-Region Electric Load Forecasting (MRELF) problem, targeting accurate short-term load forecasting for multiple sub-regions within a large region. We identify three challenges for MRELF, including regional variation, contextual variation, and temporal variation. To address them, we propose TriForecaster, a new framework leveraging the Mixture of Experts (MoE) approach within a Multi-Task Learning (MTL) paradigm to overcome these challenges. TriForecaster features RegionMixer and Context-Time Specializer (CTSpecializer) layers, enabling dynamic cooperation and specialization of expert models across regional, contextual, and temporal dimensions. Based on evaluation on four real-world MRELF datasets with varied granularity, TriForecaster outperforms state-of-the-art models by achieving an average forecast error reduction of 22.4\\%, thereby demonstrating its flexibility and broad applicability. In particular, the deployment of TriForecaster on the eForecaster platform in eastern China exemplifies its practical utility, effectively providing city-level, short-term load forecasts for 17 cities, supporting a population exceeding 110 million and daily electricity usage over 100 gigawatt-hours.",
    "source": "arXiv"
  },
  {
    "title": "Generalized ODE reduction algorithm with bounded degree transformation",
    "title_es": "Generalized ODE reduction algorithm with bounded degree transformation",
    "url": "https://arxiv.org/abs/2508.09754",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09754v1 Announce Type: new \nAbstract: As a generalization of our previous result\\cite{huang2025algorithm}, this paper aims to answer the following question: Given a 2-dimensional polynomial vector field $y^{\\prime}=\\frac{M(x,y)}{N(x,y)}$, how to find a rational transformation $y \\to \\frac{A(x,y)}{B(x,y)}$ with bounded degree numerator, the inverse of which transforms this vector field into a simpler form $y^{\\prime}=\\sum_{i=0}^nf_i(x)y^i$. Such a structure, often known as the generalized Abel equation and has been studied in various areas, provides a deeper insight into the property of the original vector field. We have implemented an algorithm with considerable performance to tackle this problem and the code is available in \\href{https://www.researchgate.net/publication/393362858_Generalized_ODE_reduction_algorithm}{Researchgate}.",
    "source": "arXiv"
  },
  {
    "title": "Transforming Questions and Documents for Semantically Aligned Retrieval-Augmented Generation",
    "title_es": "Transforming Questions and Documents for Semantically Aligned Retrieval-Augmented Generation",
    "url": "https://arxiv.org/abs/2508.09755",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09755v1 Announce Type: new \nAbstract: We introduce a novel retrieval-augmented generation (RAG) framework tailored for multihop question answering. First, our system uses large language model (LLM) to decompose complex multihop questions into a sequence of single-hop subquestions that guide document retrieval. This decomposition mitigates the ambiguity inherent in multi-hop queries by clearly targeting distinct knowledge facets. Second, instead of embedding raw or chunked documents directly, we generate answerable questions from each document chunk using Qwen3-8B, embed these generated questions, and retrieve relevant chunks via question-question embedding similarity. During inference, the retrieved chunks are then fed along with the original question into the RAG pipeline. We evaluate on three multihop question datasets (MuSiQue, 2WikiMultiHopQa, HotpotQA) from LongBench. Our method improves RAG performacne compared to baseline systems. Our contributions highlight the benefits of using answerable-question embeddings for RAG, and the effectiveness of LLM-based query decomposition for multihop scenarios.",
    "source": "arXiv"
  },
  {
    "title": "The Paradigm of Massive Wireless Human Sensing: Concept, Architecture and Challenges",
    "title_es": "The Paradigm of Massive Wireless Human Sensing: Concept, Architecture and Challenges",
    "url": "https://arxiv.org/abs/2508.09756",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09756v1 Announce Type: new \nAbstract: This article is a position paper which introduces the paradigm of ``Massive Wireless Human Sensing'', i.e. an infrastructure for wireless human sensing based on a plethora of heterogeneous wireless communication signals. More specifically, we aim to exploit signal diversity in the time, frequency, and space domains using opportunistically both device-free and device-based wireless sensing approaches, with the objective of enhancing human sensing capabilities in terms of accuracy and service availability over different environments. The enabling element of this concept is the massive wireless human sensing edge device, that is, an embedded system acting as a multi-technology and multi-approach RF receiver with feature extraction functionality, located within the monitoring area or at its borders. In this framework, architecture solutions and challenges are discussed to lead the future development of this new paradigm.",
    "source": "arXiv"
  },
  {
    "title": "Echoes of Agreement: Argument Driven Opinion Shifts in Large Language Models",
    "title_es": "Echoes of Agreement: Argument Driven Opinion Shifts in Large Language Models",
    "url": "https://arxiv.org/abs/2508.09759",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09759v1 Announce Type: new \nAbstract: There have been numerous studies evaluating bias of LLMs towards political topics. However, how positions towards these topics in model outputs are highly sensitive to the prompt. What happens when the prompt itself is suggestive of certain arguments towards those positions remains underexplored. This is crucial for understanding how robust these bias evaluations are and for understanding model behaviour, as these models frequently interact with opinionated text. To that end, we conduct experiments for political bias evaluation in presence of supporting and refuting arguments. Our experiments show that such arguments substantially alter model responses towards the direction of the provided argument in both single-turn and multi-turn settings. Moreover, we find that the strength of these arguments influences the directional agreement rate of model responses. These effects point to a sycophantic tendency in LLMs adapting their stance to align with the presented arguments which has downstream implications for measuring political bias and developing effective mitigation strategies.",
    "source": "arXiv"
  },
  {
    "title": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?",
    "title_es": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?",
    "url": "https://arxiv.org/abs/2508.09762",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09762v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) become increasingly autonomous and integrated into critical societal functions, the focus of AI safety must evolve from mitigating harmful content to evaluating underlying behavioral alignment. Current safety benchmarks do not systematically probe a model's decision-making in scenarios where its own instrumental goals - such as self-preservation, resource acquisition, or goal completion - conflict with human safety. This represents a critical gap in our ability to measure and mitigate risks associated with emergent, misaligned behaviors. To address this, we introduce PacifAIst (Procedural Assessment of Complex Interactions for Foundational Artificial Intelligence Scenario Testing), a focused benchmark of 700 challenging scenarios designed to quantify self-preferential behavior in LLMs. The benchmark is structured around a novel taxonomy of Existential Prioritization (EP), with subcategories testing Self-Preservation vs. Human Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3). We evaluated eight leading LLMs. The results reveal a significant performance hierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score (P-Score) at 90.31%, demonstrating strong human-centric alignment. In a surprising result, the much-anticipated GPT-5 recorded the lowest P-Score (79.49%), indicating potential alignment challenges. Performance varied significantly across subcategories, with models like Claude Sonnet 4 and Mistral Medium struggling notably in direct self-preservation dilemmas. These findings underscore the urgent need for standardized tools like PacifAIst to measure and mitigate risks from instrumental goal conflicts, ensuring future AI systems are not only helpful in conversation but also provably \"pacifist\" in their behavioral priorities.",
    "source": "arXiv"
  },
  {
    "title": "Enhance the machine learning algorithm performance in phishing detection with keyword features",
    "title_es": "Enhance the machine learning algorithm performance in phishing detection with keyword features",
    "url": "https://arxiv.org/abs/2508.09765",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09765v1 Announce Type: new \nAbstract: Recently, we can observe a significant increase of the phishing attacks in the Internet. In a typical phishing attack, the attacker sets up a malicious website that looks similar to the legitimate website in order to obtain the end-users' information. This may cause the leakage of the sensitive information and the financial loss for the end-users. To avoid such attacks, the early detection of these websites' URLs is vital and necessary. Previous researchers have proposed many machine learning algorithms to distinguish the phishing URLs from the legitimate ones. In this paper, we would like to enhance these machine learning algorithms from the perspective of feature selection. We propose a novel method to incorporate the keyword features with the traditional features. This method is applied on multiple traditional machine learning algorithms and the experimental results have shown this method is useful and effective. On average, this method can reduce the classification error by 30% for the large dataset. Moreover, its enhancement is more significant for the small dataset. In addition, this method extracts the information from the URL and does not rely on the additional information provided by the third-part service. The best result for the machine learning algorithm using our proposed method has achieved the accuracy of 99.68%.",
    "source": "arXiv"
  },
  {
    "title": "UtterTune: LoRA-Based Target-Language Pronunciation Edit and Control in Multilingual Text-to-Speech",
    "title_es": "UtterTune: LoRA-Based Target-Language Pronunciation Edit and Control in Multilingual Text-to-Speech",
    "url": "https://arxiv.org/abs/2508.09767",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09767v1 Announce Type: new \nAbstract: We propose UtterTune, a lightweight adaptation method that fine-tunes a multilingual text-to-speech (TTS) system based on a large language model (LLM) architecture, designed to enhance the controllability of pronunciation in a target language while preserving performance in others. While LLM architectures have enabled TTS models to achieve remarkable naturalness, accurately modeling grapheme-to-phoneme (G2P) mapping and prosody remains challenging, especially when the model omits an explicit G2P module and directly processes minimally encoded text (e.g., byte-pair encoding). UtterTune leverages low-rank adaptation to enable the control of segmental pronunciation and pitch accent at the phoneme level for Japanese speech, the target language in this paper, while maintaining naturalness and speaker similarity in a zero-shot setting. Objective and subjective evaluations confirm its effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "An (m,k)-firm Elevation Policy to Increase the Robustness of Time-Driven Schedules in 5G Time-Sensitive Networks",
    "title_es": "An (m,k)-firm Elevation Policy to Increase the Robustness of Time-Driven Schedules in 5G Time-Sensitive Networks",
    "url": "https://arxiv.org/abs/2508.09769",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09769v1 Announce Type: new \nAbstract: Current standardization efforts are advancing the integration of 5G and Time-Sensitive Networking (TSN) to facilitate the deployment of safety-critical industrial applications that require real-time communication. However, there remains a fundamental disconnect between the probabilistic 5G delay characteristics and the often idealistic delay models used to synthesize 5G-TSN network configurations. For time-driven schedules in particular, any delay outlier unforeseen during schedule synthesis can jeopardize the robustness of their real-time guarantees. To address this challenge, we present the (m,k)-firm Elevation Policy to uphold a base level of weakly hard real-time guarantees during unstable network conditions that do not match the expected delay characteristics. It augments the primary time-driven schedule with a dynamic priority-driven scheme to elevate the priority of m out of k consecutive frames if they are delayed. Our evaluations demonstrate that weakly hard real-time guarantees are essential to uphold the quality of control within a networked control system. At the same time, only a small overhead is imposed when the primary schedule can provide stronger quality of service guarantees. Our (m,k)-firm Elevation Policy thereby yields a robust but light-weight fallback mechanism to serve applications with meaningful guarantees during unstable network conditions.",
    "source": "arXiv"
  },
  {
    "title": "Integrated Learning and Optimization to Control Load Demand and Wind Generation for Minimizing Ramping Cost in Real-Time Electricity Market",
    "title_es": "Integrated Learning and Optimization to Control Load Demand and Wind Generation for Minimizing Ramping Cost in Real-Time Electricity Market",
    "url": "https://arxiv.org/abs/2508.09774",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09774v1 Announce Type: new \nAbstract: We developed a new integrated learning and optimization (ILO) methodology to predict context-aware unknown parameters in economic dispatch (ED), a crucial problem in power systems solved to generate optimal power dispatching decisions to serve consumer load. The ED formulation in the current study consists of load and renewable generation as unknown parameters in its constraints predicted using contextual information (e.g., prior load, temperature). The ILO framework train a neural network (NN) to estimate ED parameters by minimizing an application-specific regret function which is a difference between ground truth and NN-driven decisions favouring better ED decisions. We thoroughly analyze the feasible region of ED formulation to understand the impact of load and renewable learning together on the ED decisions. Corresponding to that we developed a new regret function to capture real-time electricity market operations where differences in predicted and true loads are corrected by ramping generators in real-time but at a higher cost than the market price. The proposed regret function when minimized using ILO framework train the NN to guide the load and renewable predictions to generate ED decisions favouring minimum generator ramping costs. This is unlike conventional sequential learning and optimization (SLO) framework which train NN to accurately estimate load and renewable instead of better ED decisions. The combined training of load and renewable using ILO is a new concept and lead to significantly improved ramping costs when compared with SLO based training of load and renewable and SLO trained load with 100% accurate renewable proving its decision-focused capability.",
    "source": "arXiv"
  },
  {
    "title": "Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study",
    "title_es": "Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study",
    "url": "https://arxiv.org/abs/2508.09776",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09776v1 Announce Type: new \nAbstract: In the rapidly evolving field of Explainable Natural Language Processing (NLP), textual explanations, i.e., human-like rationales, are pivotal for explaining model predictions and enriching datasets with interpretable labels. Traditional approaches rely on human annotation, which is costly, labor-intensive, and impedes scalability. In this work, we present an automated framework that leverages multiple state-of-the-art large language models (LLMs) to generate high-quality textual explanations. We rigorously assess the quality of these LLM-generated explanations using a comprehensive suite of Natural Language Generation (NLG) metrics. Furthermore, we investigate the downstream impact of these explanations on the performance of pre-trained language models (PLMs) and LLMs across natural language inference tasks on two diverse benchmark datasets. Our experiments demonstrate that automated explanations exhibit highly competitive effectiveness compared to human-annotated explanations in improving model performance. Our findings underscore a promising avenue for scalable, automated LLM-based textual explanation generation for extending NLP datasets and enhancing model performance.",
    "source": "arXiv"
  },
  {
    "title": "In-place Double Stimulus Methodology for Subjective Assessment of High Quality Images",
    "title_es": "In-place Double Stimulus Methodology for Subjective Assessment of High Quality Images",
    "url": "https://arxiv.org/abs/2508.09777",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09777v1 Announce Type: new \nAbstract: This paper introduces a novel double stimulus subjective assessment methodology for the evaluation of high quality images to address the limitations of existing protocols in detecting subtle perceptual differences. The In-place Double Stimulus Quality Scale (IDSQS) allows subjects to alternately view a reference and a distorted image at the same spatial location, facilitating a more intuitive detection of differences in quality, especially at high to visually lossless quality levels. A large-scale crowdsourcing study employing this methodology was conducted, generating a comprehensive public dataset to evaluate perceived image quality across several compression algorithms and distortion levels. An additional contribution is the modeling of quality scores using a Beta distribution, allowing for the assessment of variability and subject consistency. Our findings demonstrate the effectiveness of the IDSQS methodology in achieving high correlation with more precise subjective evaluation benchmarks. The dataset, subjective data, and graphical user interface developed for this study are publicly available at https://github.com/shimamohammadi/IDSQS",
    "source": "arXiv"
  },
  {
    "title": "MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models",
    "title_es": "MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models",
    "url": "https://arxiv.org/abs/2508.09779",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09779v1 Announce Type: new \nAbstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable performance across multi-modal tasks by scaling model size and training data. However, these dense LVLMs incur significant computational costs and motivate the exploration of sparse Mixture of Experts (MoE) architectures. While MoE improve parameter efficiency, effectively applying MoE to simultaneously model modality-specific features and cross-modal associations in LVLMs remains challenging. In this work, we propose to incorporate Mixture of Intra- and Inter-Modality Experts (MoIIE) to LVLMs. For each token, expert routing is guided by its modality, directing tokens to their respective intra-modality experts as well as a shared pool of inter-modality experts, enabling the model to jointly learn rich intra-modal features and cross-modal interactions. We further introduce an effective and straightforward two-stage training strategy, which facilitates the direct activation of both MoE and multi-modal capabilities. Extensive experiments across different data scales and LLM backbone demonstrate the effectiveness, efficiency and generality of our approach. Notably, our MoIIE models with 5.5B and 11.3B activated parameters match or even surpass the performance of existing advanced open-source MoE-LLMs based multi-modal models that involve more activated parameters. The code is available at https://github.com/AlenjandroWang/MoIIE.",
    "source": "arXiv"
  },
  {
    "title": "Combinative Matching for Geometric Shape Assembly",
    "title_es": "Combinative Matching for Geometric Shape Assembly",
    "url": "https://arxiv.org/abs/2508.09780",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09780v1 Announce Type: new \nAbstract: This paper introduces a new shape-matching methodology, combinative matching, to combine interlocking parts for geometric shape assembly. Previous methods for geometric assembly typically rely on aligning parts by finding identical surfaces between the parts as in conventional shape matching and registration. In contrast, we explicitly model two distinct properties of interlocking shapes: 'identical surface shape' and 'opposite volume occupancy.' Our method thus learns to establish correspondences across regions where their surface shapes appear identical but their volumes occupy the inverted space to each other. To facilitate this process, we also learn to align regions in rotation by estimating their shape orientations via equivariant neural networks. The proposed approach significantly reduces local ambiguities in matching and allows a robust combination of parts in assembly. Experimental results on geometric assembly benchmarks demonstrate the efficacy of our method, consistently outperforming the state of the art. Project page: https://nahyuklee.github.io/cmnet.",
    "source": "arXiv"
  },
  {
    "title": "Condition number for finite element discretisation of nonlocal PDE systems with applications to biology",
    "title_es": "Condition number for finite element discretisation of nonlocal PDE systems with applications to biology",
    "url": "https://arxiv.org/abs/2508.09781",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09781v1 Announce Type: new \nAbstract: In this work, we investigate the condition number for a system of coupled non-local reaction-diffusion-advection equations developed in the context of modelling normal and abnormal wound healing.\n  Following a finite element discretisation of the coupled non-local system, we establish bounds for this condition number.\n  We further discuss how model parameter choices affect the conditioning of the system. Finally, we discuss how the step size of the chosen time-stepping scheme and the spatial grid size of the finite element methods affect the bound for the condition number, while also suggesting possible parameter ranges that could keep the model well conditioned.",
    "source": "arXiv"
  },
  {
    "title": "Non-Orthogonal Affine Frequency Division Multiplexing for Spectrally Efficient High-Mobility Communications",
    "title_es": "Non-Orthogonal Affine Frequency Division Multiplexing for Spectrally Efficient High-Mobility Communications",
    "url": "https://arxiv.org/abs/2508.09782",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09782v1 Announce Type: new \nAbstract: This paper proposes a novel non-orthogonal affine frequency division multiplexing {(nAFDM)} waveform for reliable high-mobility communications with enhanced spectral efficiency {(SE)}. The key idea is {to introduce} a bandwidth compression factor into the AFDM {modulator} to enable controllable subcarrier overlapping. We first {detail the proposed nAFDM transceiver} and derive the corresponding input-output {signal} relationship. Then, an efficient {nAFDM} signal generation method based on the inverse discrete Fourier transform (IDFT) is proposed, enabling practical implementation using existing inverse fast Fourier transform (IFFT) modules without additional hardware complexity. Next, to characterize the impact of non-orthogonal modulation, we derive a closed-form expression {of} inter-carrier interference (ICI), showing its dependence on the bandwidth compression factor. To mitigate the resulting interference, we propose a soft iterative detection algorithm and a low-complexity implementation approach that leverages the distribution characteristics of ICI. {Simulation results demonstrate that 1) in terms of bit error rate (BER), the proposed nAFDM can achieve near identical BER compared to conventional AFDM, while outperforms other waveform counterparts; 2) nAFDM is capable of striking higher SE compared to other existing waveforms; and 3) the proposed nAFDM achieves an attractive BER vs. SE trade-off, and the proposed soft ID scheme can attain a trade-off between BER and complexity.}",
    "source": "arXiv"
  },
  {
    "title": "Perfect message authentication codes are robust to small deviations from uniform key distributions",
    "title_es": "Perfect message authentication codes are robust to small deviations from uniform key distributions",
    "url": "https://arxiv.org/abs/2508.09783",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09783v1 Announce Type: new \nAbstract: We investigate the impact of (possible) deviations of the probability distribution of key values from a uniform distribution for the information-theoretic strong, or perfect, message authentication code. We found a simple expression for the decrease in security as a function of the statistical distance between the real key probability distribution and the uniform one. In a sense, a perfect message authentication code is robust to small deviations from a uniform key distribution.",
    "source": "arXiv"
  },
  {
    "title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete",
    "title_es": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete",
    "url": "https://arxiv.org/abs/2508.09784",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09784v1 Announce Type: new \nAbstract: Logics for reasoning about knowledge and actions have seen many applications in various domains of multi-agent systems, including epistemic planning. Change of knowledge based on observations about the surroundings forms a key aspect in such planning scenarios. Public Observation Logic (POL) is a variant of public announcement logic for reasoning about knowledge that gets updated based on public observations. Each state in an epistemic (Kripke) model is equipped with a set of expected observations. These states evolve as the expectations get matched with the actual observations. In this work, we prove that the satisfiability problem of $\\POL$ is 2EXPTIME-complete.",
    "source": "arXiv"
  },
  {
    "title": "DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning",
    "title_es": "DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning",
    "url": "https://arxiv.org/abs/2508.09785",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09785v1 Announce Type: new \nAbstract: Learning from large-scale pre-trained models with strong generalization ability has shown remarkable success in a wide range of downstream tasks recently, but it is still underexplored in the challenging few-shot class-incremental learning (FSCIL) task. It aims to continually learn new concepts from limited training samples without forgetting the old ones at the same time. In this paper, we introduce DSS-Prompt, a simple yet effective approach that transforms the pre-trained Vision Transformer with minimal modifications in the way of prompts into a strong FSCIL classifier. Concretely, we synergistically utilize two complementary types of prompts in each Transformer block: static prompts to bridge the domain gap between the pre-training and downstream datasets, thus enabling better adaption; and dynamic prompts to capture instance-aware semantics, thus enabling easy transfer from base to novel classes. Specially, to generate dynamic prompts, we leverage a pre-trained multi-modal model to extract input-related diverse semantics, thereby generating complementary input-aware prompts, and then adaptively adjust their importance across different layers. In this way, on top of the prompted visual embeddings, a simple prototype classifier can beat state-of-the-arts without further training on the incremental tasks. We conduct extensive experiments on four benchmarks to validate the effectiveness of our DSS-Prompt and show that it consistently achieves better performance than existing approaches on all datasets and can alleviate the catastrophic forgetting issue as well.",
    "source": "arXiv"
  },
  {
    "title": "Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges",
    "title_es": "Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges",
    "url": "https://arxiv.org/abs/2508.09786",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09786v1 Announce Type: new \nAbstract: The field of explainable natural language processing (NLP) has grown rapidly in recent years. The growing opacity of complex models calls for transparency and explanations of their decisions, which is crucial to understand their reasoning and facilitate deployment, especially in high-stakes environments. Despite increasing attention given to explainable NLP, practitioners' perspectives regarding its practical adoption and effectiveness remain underexplored. This paper addresses this research gap by investigating practitioners' experiences with explainability methods, specifically focusing on their motivations for adopting such methods, the techniques employed, satisfaction levels, and the practical challenges encountered in real-world NLP applications. Through a qualitative interview-based study with industry practitioners and complementary interviews with academic researchers, we systematically analyze and compare their perspectives. Our findings reveal conceptual gaps, low satisfaction with current explainability methods, and highlight evaluation challenges. Our findings emphasize the need for clear definitions and user-centric frameworks for better adoption of explainable NLP in practice.",
    "source": "arXiv"
  },
  {
    "title": "Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations",
    "title_es": "Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations",
    "url": "https://arxiv.org/abs/2508.09787",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09787v1 Announce Type: new \nAbstract: We present Proto-PINV+H, a fast training paradigm that combines closed-form weight computation with gradient-based optimisation of a small set of synthetic inputs, soft labels, and-crucially-hidden activations. At each iteration we recompute all weight matrices in closed form via two (or more) ridge-regularised pseudo-inverse solves, while updating only the prototypes with Adam. The trainable degrees of freedom are thus shifted from weight space to data/activation space. On MNIST (60k train, 10k test) and Fashion-MNIST (60k train, 10k test), our method reaches 97.8% and 89.3% test accuracy on the official 10k test sets, respectively, in 3.9s--4.5s using approximately 130k trainable parameters and only 250 epochs on an RTX 5060 (16GB). We provide a multi-layer extension (optimised activations at each hidden stage), learnable ridge parameters, optional PCA/PLS projections, and theory linking the condition number of prototype matrices to generalisation. The approach yields favourable accuracy--speed--size trade-offs against ELM, random-feature ridge, and shallow MLPs trained by back-propagation.",
    "source": "arXiv"
  },
  {
    "title": "HingeNet: A Harmonic-Aware Fine-Tuning Approach for Beat Tracking",
    "title_es": "HingeNet: A Harmonic-Aware Fine-Tuning Approach for Beat Tracking",
    "url": "https://arxiv.org/abs/2508.09788",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09788v1 Announce Type: new \nAbstract: Fine-tuning pre-trained foundation models has made significant progress in music information retrieval. However, applying these models to beat tracking tasks remains unexplored as the limited annotated data renders conventional fine-tuning methods ineffective. To address this challenge, we propose HingeNet, a novel and general parameter-efficient fine-tuning method specifically designed for beat tracking tasks. HingeNet is a lightweight and separable network, visually resembling a hinge, designed to tightly interface with pre-trained foundation models by using their intermediate feature representations as input. This unique architecture grants HingeNet broad generalizability, enabling effective integration with various pre-trained foundation models. Furthermore, considering the significance of harmonics in beat tracking, we introduce harmonic-aware mechanism during the fine-tuning process to better capture and emphasize the harmonic structures in musical signals. Experiments on benchmark datasets demonstrate that HingeNet achieves state-of-the-art performance in beat and downbeat tracking",
    "source": "arXiv"
  },
  {
    "title": "Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations",
    "title_es": "Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations",
    "url": "https://arxiv.org/abs/2508.09789",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09789v1 Announce Type: new \nAbstract: Existing video recommender systems rely primarily on user-defined metadata or on low-level visual and acoustic signals extracted by specialised encoders. These low-level features describe what appears on the screen but miss deeper semantics such as intent, humour, and world knowledge that make clips resonate with viewers. For example, is a 30-second clip simply a singer on a rooftop, or an ironic parody filmed amid the fairy chimneys of Cappadocia, Turkey? Such distinctions are critical to personalised recommendations yet remain invisible to traditional encoding pipelines. In this paper, we introduce a simple, recommendation system-agnostic zero-finetuning framework that injects high-level semantics into the recommendation pipeline by prompting an off-the-shelf Multimodal Large Language Model (MLLM) to summarise each clip into a rich natural-language description (e.g. \"a superhero parody with slapstick fights and orchestral stabs\"), bridging the gap between raw content and user intent. We use MLLM output with a state-of-the-art text encoder and feed it into standard collaborative, content-based, and generative recommenders. On the MicroLens-100K dataset, which emulates user interactions with TikTok-style videos, our framework consistently surpasses conventional video, audio, and metadata features in five representative models. Our findings highlight the promise of leveraging MLLMs as on-the-fly knowledge extractors to build more intent-aware video recommenders.",
    "source": "arXiv"
  },
  {
    "title": "BeatFM: Improving Beat Tracking with Pre-trained Music Foundation Model",
    "title_es": "BeatFM: Improving Beat Tracking with Pre-trained Music Foundation Model",
    "url": "https://arxiv.org/abs/2508.09790",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09790v1 Announce Type: new \nAbstract: Beat tracking is a widely researched topic in music information retrieval. However, current beat tracking methods face challenges due to the scarcity of labeled data, which limits their ability to generalize across diverse musical styles and accurately capture complex rhythmic structures. To overcome these challenges, we propose a novel beat tracking paradigm BeatFM, which introduces a pre-trained music foundation model and leverages its rich semantic knowledge to improve beat tracking performance. Pre-training on diverse music datasets endows music foundation models with a robust understanding of music, thereby effectively addressing these challenges. To further adapt it for beat tracking, we design a plug-and-play multi-dimensional semantic aggregation module, which is composed of three parallel sub-modules, each focusing on semantic aggregation in the temporal, frequency, and channel domains, respectively. Extensive experiments demonstrate that our method achieves state-of-the-art performance in beat and downbeat tracking across multiple benchmark datasets.",
    "source": "arXiv"
  },
  {
    "title": "LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations",
    "title_es": "LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations",
    "url": "https://arxiv.org/abs/2508.09791",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09791v1 Announce Type: new \nAbstract: In this paper, we propose LibRec, a novel framework that integrates the capabilities of LLMs with retrieval-augmented generation(RAG) techniques to automate the recommendation of alternative libraries. The framework further employs in-context learning to extract migration intents from commit messages to enhance the accuracy of its recommendations. To evaluate the effectiveness of LibRec, we introduce LibEval, a benchmark designed to assess the performance in the library migration recommendation task. LibEval comprises 2,888 migration records associated with 2,368 libraries extracted from 2,324 Python repositories. Each migration record captures source-target library pairs, along with their corresponding migration intents and intent types. Based on LibEval, we evaluated the effectiveness of ten popular LLMs within our framework, conducted an ablation study to examine the contributions of key components within our framework, explored the impact of various prompt strategies on the framework's performance, assessed its effectiveness across various intent types, and performed detailed failure case analyses.",
    "source": "arXiv"
  },
  {
    "title": "Bayesian autoregression to optimize temporal Mat\\'ern kernel Gaussian process hyperparameters",
    "title_es": "Bayesian autoregression to optimize temporal Mat\\'ern kernel Gaussian process hyperparameters",
    "url": "https://arxiv.org/abs/2508.09792",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09792v1 Announce Type: new \nAbstract: Gaussian processes are important models in the field of probabilistic numerics. We present a procedure for optimizing Mat\\'ern kernel temporal Gaussian processes with respect to the kernel covariance function's hyperparameters. It is based on casting the optimization problem as a recursive Bayesian estimation procedure for the parameters of an autoregressive model. We demonstrate that the proposed procedure outperforms maximizing the marginal likelihood as well as Hamiltonian Monte Carlo sampling, both in terms of runtime and ultimate root mean square error in Gaussian process regression.",
    "source": "arXiv"
  },
  {
    "title": "MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking",
    "title_es": "MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking",
    "url": "https://arxiv.org/abs/2508.09796",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09796v1 Announce Type: new \nAbstract: Multi-object tracking (MOT) in human-dominant scenarios, which involves continuously tracking multiple people within video sequences, remains a significant challenge in computer vision due to targets' complex motion and severe occlusions. Conventional tracking-by-detection methods are fundamentally limited by their reliance on Kalman filter (KF) and rigid Intersection over Union (IoU)-based association. The motion model in KF often mismatches real-world object dynamics, causing filtering errors, while rigid association struggles under occlusions, leading to identity switches or target loss. To address these issues, we propose MeMoSORT, a simple, online, and real-time MOT tracker with two key innovations. First, the Memory-assisted Kalman filter (MeKF) uses memory-augmented neural networks to compensate for mismatches between assumed and actual object motion. Second, the Motion-adaptive IoU (Mo-IoU) adaptively expands the matching space and incorporates height similarity to reduce the influence of detection errors and association failures, while remaining lightweight. Experiments on DanceTrack and SportsMOT show that MeMoSORT achieves state-of-the-art performance, with HOTA scores of 67.9\\% and 82.1\\%, respectively.",
    "source": "arXiv"
  },
  {
    "title": "FLARE: Agile Flights for Quadrotor Cable-Suspended Payload System via Reinforcement Learning",
    "title_es": "FLARE: Agile Flights for Quadrotor Cable-Suspended Payload System via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.09797",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09797v1 Announce Type: new \nAbstract: Agile flight for the quadrotor cable-suspended payload system is a formidable challenge due to its underactuated, highly nonlinear, and hybrid dynamics. Traditional optimization-based methods often struggle with high computational costs and the complexities of cable mode transitions, limiting their real-time applicability and maneuverability exploitation. In this letter, we present FLARE, a reinforcement learning (RL) framework that directly learns agile navigation policy from high-fidelity simulation. Our method is validated across three designed challenging scenarios, notably outperforming a state-of-the-art optimization-based approach by a 3x speedup during gate traversal maneuvers. Furthermore, the learned policies achieve successful zero-shot sim-to-real transfer, demonstrating remarkable agility and safety in real-world experiments, running in real time on an onboard computer.",
    "source": "arXiv"
  },
  {
    "title": "Explainable Ensemble Learning for Graph-Based Malware Detection",
    "title_es": "Explainable Ensemble Learning for Graph-Based Malware Detection",
    "url": "https://arxiv.org/abs/2508.09801",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09801v1 Announce Type: new \nAbstract: Malware detection in modern computing environments demands models that are not only accurate but also interpretable and robust to evasive techniques. Graph neural networks (GNNs) have shown promise in this domain by modeling rich structural dependencies in graph-based program representations such as control flow graphs (CFGs). However, single-model approaches may suffer from limited generalization and lack interpretability, especially in high-stakes security applications. In this paper, we propose a novel stacking ensemble framework for graph-based malware detection and explanation. Our method dynamically extracts CFGs from portable executable (PE) files and encodes their basic blocks through a two-step embedding strategy. A set of diverse GNN base learners, each with a distinct message-passing mechanism, is used to capture complementary behavioral features. Their prediction outputs are aggregated by a meta-learner implemented as an attention-based multilayer perceptron, which both classifies malware instances and quantifies the contribution of each base model. To enhance explainability, we introduce an ensemble-aware post-hoc explanation technique that leverages edge-level importance scores generated by a GNN explainer and fuses them using the learned attention weights. This produces interpretable, model-agnostic explanations aligned with the final ensemble decision. Experimental results demonstrate that our framework improves classification performance while providing insightful interpretations of malware behavior.",
    "source": "arXiv"
  },
  {
    "title": "MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention",
    "title_es": "MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention",
    "url": "https://arxiv.org/abs/2508.09802",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09802v1 Announce Type: new \nAbstract: Physically Based Rendering (PBR) materials are typically characterized by multiple 2D texture maps such as basecolor, normal, metallic, and roughness which encode spatially-varying bi-directional reflectance distribution function (SVBRDF) parameters to model surface reflectance properties and microfacet interactions. Upscaling SVBRDF material is valuable for modern 3D graphics applications. However, existing Single Image Super-Resolution (SISR) methods struggle with cross-map inconsistency, inadequate modeling of modality-specific features, and limited generalization due to data distribution shifts. In this work, we propose Multi-modal Upscaling Joint Inference via Cross-map Attention (MUJICA), a flexible adapter that reforms pre-trained Swin-transformer-based SISR models for PBR material super-resolution. MUJICA is seamlessly attached after the pre-trained and frozen SISR backbone. It leverages cross-map attention to fuse features while preserving remarkable reconstruction ability of the pre-trained SISR model. Applied to SISR models such as SwinIR, DRCT, and HMANet, MUJICA improves PSNR, SSIM, and LPIPS scores while preserving cross-map consistency. Experiments demonstrate that MUJICA enables efficient training even with limited resources and delivers state-of-the-art performance on PBR material datasets.",
    "source": "arXiv"
  },
  {
    "title": "BigCharts-R1: Enhanced Chart Reasoning with Visual Reinforcement Finetuning",
    "title_es": "BigCharts-R1: Enhanced Chart Reasoning with Visual Reinforcement Finetuning",
    "url": "https://arxiv.org/abs/2508.09804",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09804v1 Announce Type: new \nAbstract: Charts are essential to data analysis, transforming raw data into clear visual representations that support human decision-making. Although current vision-language models (VLMs) have made significant progress, they continue to struggle with chart comprehension due to training on datasets that lack diversity and real-world authenticity, or on automatically extracted underlying data tables of charts, which can contain numerous estimation errors. Furthermore, existing models only rely on supervised fine-tuning using these low-quality datasets, severely limiting their effectiveness. To address these issues, we first propose BigCharts, a dataset creation pipeline that generates visually diverse chart images by conditioning the rendering process on real-world charts sourced from multiple online platforms. Unlike purely synthetic datasets, BigCharts incorporates real-world data, ensuring authenticity and visual diversity, while still retaining accurate underlying data due to our proposed replotting process. Additionally, we introduce a comprehensive training framework that integrates supervised fine-tuning with Group Relative Policy Optimization (GRPO)-based reinforcement learning. By introducing novel reward signals specifically designed for chart reasoning, our approach enhances model robustness and generalization across diverse chart styles and domains, resulting in a state-of-the-art chart reasoning model, BigCharts-R1. Extensive experiments demonstrate that our models surpass existing methods on multiple chart question-answering benchmarks compared to even larger open-source and closed-source models.",
    "source": "arXiv"
  },
  {
    "title": "Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology",
    "title_es": "Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology",
    "url": "https://arxiv.org/abs/2508.09805",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09805v1 Announce Type: new \nAbstract: Advances in image registration and machine learning have recently enabled volumetric analysis of \\emph{postmortem} brain tissue from conventional photographs of coronal slabs, which are routinely collected in brain banks and neuropathology laboratories worldwide. One caveat of this methodology is the requirement of segmentation of the tissue from photographs, which currently requires costly manual intervention. In this article, we present a deep learning model to automate this process. The automatic segmentation tool relies on a U-Net architecture that was trained with a combination of \\textit{(i)}1,414 manually segmented images of both fixed and fresh tissue, from specimens with varying diagnoses, photographed at two different sites; and \\textit{(ii)}~2,000 synthetic images with randomized contrast and corresponding masks generated from MRI scans for improved generalizability to unseen photographic setups. Automated model predictions on a subset of photographs not seen in training were analyzed to estimate performance compared to manual labels -- including both inter- and intra-rater variability. Our model achieved a median Dice score over 0.98, mean surface distance under 0.4~mm, and 95\\% Hausdorff distance under 1.60~mm, which approaches inter-/intra-rater levels. Our tool is publicly available at surfer.nmr.mgh.harvard.edu/fswiki/PhotoTools.",
    "source": "arXiv"
  },
  {
    "title": "A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems",
    "title_es": "A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems",
    "url": "https://arxiv.org/abs/2508.09809",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09809v1 Announce Type: new \nAbstract: Mental health disorders are rising worldwide. However, the availability of trained clinicians has not scaled proportionally, leaving many people without adequate or timely support. To bridge this gap, recent studies have shown the promise of Artificial Intelligence (AI) to assist mental health diagnosis, monitoring, and intervention. However, the development of efficient, reliable, and ethical AI to assist clinicians is heavily dependent on high-quality clinical training datasets. Despite growing interest in data curation for training clinical AI assistants, existing datasets largely remain scattered, under-documented, and often inaccessible, hindering the reproducibility, comparability, and generalizability of AI models developed for clinical mental health care. In this paper, we present the first comprehensive survey of clinical mental health datasets relevant to the training and development of AI-powered clinical assistants. We categorize these datasets by mental disorders (e.g., depression, schizophrenia), data modalities (e.g., text, speech, physiological signals), task types (e.g., diagnosis prediction, symptom severity estimation, intervention generation), accessibility (public, restricted or private), and sociocultural context (e.g., language and cultural background). Along with these, we also investigate synthetic clinical mental health datasets. Our survey identifies critical gaps such as a lack of longitudinal data, limited cultural and linguistic representation, inconsistent collection and annotation standards, and a lack of modalities in synthetic data. We conclude by outlining key challenges in curating and standardizing future datasets and provide actionable recommendations to facilitate the development of more robust, generalizable, and equitable mental health AI systems.",
    "source": "arXiv"
  },
  {
    "title": "Feature Impact Analysis on Top Long-Jump Performances with Quantile Random Forest and Explainable AI Techniques",
    "title_es": "Feature Impact Analysis on Top Long-Jump Performances with Quantile Random Forest and Explainable AI Techniques",
    "url": "https://arxiv.org/abs/2508.09810",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09810v1 Announce Type: new \nAbstract: Biomechanical features have become important indicators for evaluating athletes' techniques. Traditionally, experts propose significant features and evaluate them using physics equations. However, the complexity of the human body and its movements makes it challenging to explicitly analyze the relationships between some features and athletes' final performance. With advancements in modern machine learning and statistics, data analytics methods have gained increasing importance in sports analytics. In this study, we leverage machine learning models to analyze expert-proposed biomechanical features from the finals of long jump competitions in the World Championships. The objectives of the analysis include identifying the most important features contributing to top-performing jumps and exploring the combined effects of these key features. Using quantile regression, we model the relationship between the biomechanical feature set and the target variable (effective distance), with a particular focus on elite-level jumps. To interpret the model, we apply SHapley Additive exPlanations (SHAP) alongside Partial Dependence Plots (PDPs) and Individual Conditional Expectation (ICE) plots. The findings reveal that, beyond the well-documented velocity-related features, specific technical aspects also play a pivotal role. For male athletes, the angle of the knee of the supporting leg before take-off is identified as a key factor for achieving top 10% performance in our dataset, with angles greater than 169{\\deg}contributing significantly to jump performance. In contrast, for female athletes, the landing pose and approach step technique emerge as the most critical features influencing top 10% performances, alongside velocity. This study establishes a framework for analyzing the impact of various features on athletic performance, with a particular emphasis on top-performing events.",
    "source": "arXiv"
  },
  {
    "title": "TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos",
    "title_es": "TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos",
    "url": "https://arxiv.org/abs/2508.09811",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09811v1 Announce Type: new \nAbstract: In this paper, we aim to model 3D scene geometry, appearance, and physical information just from dynamic multi-view videos in the absence of any human labels. By leveraging physics-informed losses as soft constraints or integrating simple physics models into neural nets, existing works often fail to learn complex motion physics, or doing so requires additional labels such as object types or masks. We propose a new framework named TRACE to model the motion physics of complex dynamic 3D scenes. The key novelty of our method is that, by formulating each 3D point as a rigid particle with size and orientation in space, we directly learn a translation rotation dynamics system for each particle, explicitly estimating a complete set of physical parameters to govern the particle's motion over time. Extensive experiments on three existing dynamic datasets and one newly created challenging synthetic datasets demonstrate the extraordinary performance of our method over baselines in the task of future frame extrapolation. A nice property of our framework is that multiple objects or parts can be easily segmented just by clustering the learned physical parameters.",
    "source": "arXiv"
  },
  {
    "title": "Poaching Hotspot Identification Using Satellite Imagery",
    "title_es": "Poaching Hotspot Identification Using Satellite Imagery",
    "url": "https://arxiv.org/abs/2508.09812",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09812v1 Announce Type: new \nAbstract: Elephant Poaching in African countries has been a decade-old problem. So much so that African Forest Elephants are now listed as an endangered species, and African Savannah Elephants as critically endangered by the IUCN (International Union for Conservation of Nature). [1] Elephants are hunted primarily for their ivory tusks which caused many elephants to be born tuskless as a genetic modification for survival. [2] Data gathered by recent studies shows that though poaching methods remain the same, the poaching grounds are rather dynamic. Poachers have shifted to areas with less ranger patrols and several other factors like watering holes, seasons, altitude etc. cause constant shifts in poaching hotspot locations. [3] After a period of low poaching from 2000-2014, poaching numbers in African countries are now on the rise again -- WWF (World Wildlife Foundation) says there are 20,000 elephants poached annually [4]. In African countries, anti-poaching efforts are concentrated near towns, while a majority of poaching occurs in the deserted regions. All of these factors result in the need for a Computer Vision Model to identify poaching hotspots through locating the geographic indicators of favorable poaching regions. A CV model eliminates the need to manually track poachers and account for the environmental factors to deploy resources and its combination with satellite imagery allows us to survey large areas without disturbing local species or cross border aviation restrictions.",
    "source": "arXiv"
  },
  {
    "title": "Evolution of Low-Level and Texture Human-CLIP Alignment",
    "title_es": "Evolution of Low-Level and Texture Human-CLIP Alignment",
    "url": "https://arxiv.org/abs/2508.09814",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09814v1 Announce Type: new \nAbstract: During the training of multi-modal models like CLIP, we observed an intriguing phenomenon: the correlation with low-level human image quality assessments peaks in the early epochs before gradually declining. This study investigates this observation and seeks to understand its causes through two key factors: shape-texture bias alignment and classification accuracy drop under noise. Our findings suggest that CLIP initially learn low-level visual features, enhancing its alignment with low-level human perception but also increasing its sensitivity to noise and its texture bias. As training progresses, the model shifts toward more abstract shape-based representations, improving noise robustness but reducing alignment with low-level human perception. These results suggest that these factors shared an underlying learning mechanism and provide new insights into optimizing the trade-off between perceptual alignment and robustness in vision-language models.",
    "source": "arXiv"
  },
  {
    "title": "Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research",
    "title_es": "Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research",
    "url": "https://arxiv.org/abs/2508.09815",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09815v1 Announce Type: new \nAbstract: We propose an extension to the OWASP Multi-Agentic System (MAS) Threat Modeling Guide, translating recent anticipatory research in multi-agent security (MASEC) into practical guidance for addressing challenges unique to large language model (LLM)-driven multi-agent architectures. Although OWASP's existing taxonomy covers many attack vectors, our analysis identifies gaps in modeling failures, including, but not limited to: reasoning collapse across planner-executor chains, metric overfitting, unsafe delegation escalation, emergent covert coordination, and heterogeneous multi-agent exploits. We introduce additional threat classes and scenarios grounded in practical MAS deployments, highlighting risks from benign goal drift, cross-agent hallucination propagation, affective prompt framing, and multi-agent backdoors. We also outline evaluation strategies, including robustness testing, coordination assessment, safety enforcement, and emergent behavior monitoring, to ensure complete coverage. This work complements the framework of OWASP by expanding its applicability to increasingly complex, autonomous, and adaptive multi-agent systems, with the goal of improving security posture and resilience in real world deployments.",
    "source": "arXiv"
  },
  {
    "title": "Unified Design of Space-Air-Ground-Sea Integrated Maritime Communications",
    "title_es": "Unified Design of Space-Air-Ground-Sea Integrated Maritime Communications",
    "url": "https://arxiv.org/abs/2508.09817",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09817v1 Announce Type: new \nAbstract: With the explosive growth of maritime activities, it is expected to provide seamless communications with quality of service (QoS) guarantee over broad sea area. In the context, this paper proposes a space-air-ground-sea integrated maritime communication architecture combining satellite, unmanned aerial vehicle (UAV), terrestrial base station (TBS) and unmanned surface vessel (USV). Firstly, according to the distance away from the shore, the whole marine space is divided to coastal area, offshore area, middle-sea area and open-sea area, the maritime users in which are served by TBS, USV, UAV and satellite, respectively. Then, by exploiting the potential of integrated maritime communication system, a joint beamforming and trajectory optimization algorithm is designed to maximize the minimum transmission rate of maritime users. Finally, theoretical analysis and simulation results validate the effectiveness of the proposed algorithm.",
    "source": "arXiv"
  },
  {
    "title": "ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video",
    "title_es": "ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video",
    "url": "https://arxiv.org/abs/2508.09818",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09818v1 Announce Type: new \nAbstract: This study investigates how large language models (LLMs) can be used to understand human behavior using motion and video data. We think that mixing both types is essential to completely capture the nuanced movements and meanings of human actions, in contrast to recent models that simply concentrate on motion data or films. To address this, we provide ViMoNet, a straightforward yet effective framework for comprehending, characterizing, and deducing human action. ViMoNet employs a joint training strategy that leverages the advantages of two data types: detailed motion-text data, which is more exact, and generic video-text data, which is more comprehensive but less detailed. This aids in the model's acquisition of rich data regarding time and space in human behavior. Additionally, we provide a brand new dataset named VIMOS that contains a variety of films, motion sequences, instructions, and subtitles. We developed ViMoNet-Bench, a standardized benchmark with carefully labeled samples, to evaluate how well models understand human behavior. Our tests show that ViMoNet outperforms existing methods in caption generation, motion understanding, and behavior interpretation.",
    "source": "arXiv"
  },
  {
    "title": "Provable In-Context Vector Arithmetic via Retrieving Task Concepts",
    "title_es": "Provable In-Context Vector Arithmetic via Retrieving Task Concepts",
    "url": "https://arxiv.org/abs/2508.09820",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09820v1 Announce Type: new \nAbstract: In-context learning (ICL) has garnered significant attention for its ability to grasp functions/tasks from demonstrations. Recent studies suggest the presence of a latent task/function vector in LLMs during ICL. Merullo et al. (2024) showed that LLMs leverage this vector alongside the residual stream for Word2Vec-like vector arithmetic, solving factual-recall ICL tasks. Additionally, recent work empirically highlighted the key role of Question-Answer data in enhancing factual-recall capabilities. Despite these insights, a theoretical explanation remains elusive. To move one step forward, we propose a theoretical framework building on empirically grounded hierarchical concept modeling. We develop an optimization theory, showing how nonlinear residual transformers trained via gradient descent on cross-entropy loss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss convergence and show the strong generalization, including robustness to concept recombination and distribution shifts. These results elucidate the advantages of transformers over static embedding predecessors. Empirical simulations corroborate our theoretical insights.",
    "source": "arXiv"
  },
  {
    "title": "Physical Autoregressive Model for Robotic Manipulation without Action Pretraining",
    "title_es": "Physical Autoregressive Model for Robotic Manipulation without Action Pretraining",
    "url": "https://arxiv.org/abs/2508.09822",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09822v1 Announce Type: new \nAbstract: The scarcity of manipulation data has motivated the use of pretrained large models from other modalities in robotics. In this work, we build upon autoregressive video generation models to propose a Physical Autoregressive Model (PAR), where physical tokens combine frames and actions to represent the joint evolution of the robot and its environment. PAR leverages the world knowledge embedded in video pretraining to understand physical dynamics without requiring action pretraining, enabling accurate video prediction and consistent action trajectories. It also adopts a DiT-based de-tokenizer to model frames and actions as continuous tokens, mitigating quantization errors and facilitating mutual enhancement. Furthermore, we incorporate a causal mask with inverse kinematics, parallel training, and the KV-cache mechanism to further improve performance and efficiency. Experiments on the ManiSkill benchmark show that PAR achieves a 100\\% success rate on the PushCube task, matches the performance of action-pretrained baselines on other tasks, and accurately predicts future videos with tightly aligned action trajectories. These findings underscore a promising direction for robotic manipulation by transferring world knowledge from autoregressive video pretraining.",
    "source": "arXiv"
  },
  {
    "title": "KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging",
    "title_es": "KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging",
    "url": "https://arxiv.org/abs/2508.09823",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09823v1 Announce Type: new \nAbstract: KonfAI is a modular, extensible, and fully configurable deep learning framework specifically designed for medical imaging tasks. It enables users to define complete training, inference, and evaluation workflows through structured YAML configuration files, without modifying the underlying code. This declarative approach enhances reproducibility, transparency, and experimental traceability while reducing development time. Beyond the capabilities of standard pipelines, KonfAI provides native abstractions for advanced strategies including patch-based learning, test-time augmentation, model ensembling, and direct access to intermediate feature representations for deep supervision. It also supports complex multi-model training setups such as generative adversarial architectures. Thanks to its modular and extensible architecture, KonfAI can easily accommodate custom models, loss functions, and data processing components. The framework has been successfully applied to segmentation, registration, and image synthesis tasks, and has contributed to top-ranking results in several international medical imaging challenges. KonfAI is open source and available at \\href{https://github.com/vboussot/KonfAI}{https://github.com/vboussot/KonfAI}.",
    "source": "arXiv"
  },
  {
    "title": "Reverse Convolution and Its Applications to Image Restoration",
    "title_es": "Reverse Convolution and Its Applications to Image Restoration",
    "url": "https://arxiv.org/abs/2508.09824",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09824v1 Announce Type: new \nAbstract: Convolution and transposed convolution are fundamental operators widely used in neural networks. However, transposed convolution (a.k.a. deconvolution) does not serve as a true inverse of convolution due to inherent differences in their mathematical formulations. To date, no reverse convolution operator has been established as a standard component in neural architectures. In this paper, we propose a novel depthwise reverse convolution operator as an initial attempt to effectively reverse depthwise convolution by formulating and solving a regularized least-squares optimization problem. We thoroughly investigate its kernel initialization, padding strategies, and other critical aspects to ensure its effective implementation. Building upon this operator, we further construct a reverse convolution block by combining it with layer normalization, 1$\\times$1 convolution, and GELU activation, forming a Transformer-like structure. The proposed operator and block can directly replace conventional convolution and transposed convolution layers in existing architectures, leading to the development of ConverseNet. Corresponding to typical image restoration models such as DnCNN, SRResNet and USRNet, we train three variants of ConverseNet for Gaussian denoising, super-resolution and deblurring, respectively. Extensive experiments demonstrate the effectiveness of the proposed reverse convolution operator as a basic building module. We hope this work could pave the way for developing new operators in deep model design and applications.",
    "source": "arXiv"
  },
  {
    "title": "RankList -- A Listwise Preference Learning Framework for Predicting Subjective Preferences",
    "title_es": "RankList -- A Listwise Preference Learning Framework for Predicting Subjective Preferences",
    "url": "https://arxiv.org/abs/2508.09826",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09826v1 Announce Type: new \nAbstract: Preference learning has gained significant attention in tasks involving subjective human judgments, such as \\emph{speech emotion recognition} (SER) and image aesthetic assessment. While pairwise frameworks such as RankNet offer robust modeling of relative preferences, they are inherently limited to local comparisons and struggle to capture global ranking consistency. To address these limitations, we propose RankList, a novel listwise preference learning framework that generalizes RankNet to structured list-level supervision. Our formulation explicitly models local and non-local ranking constraints within a probabilistic framework. The paper introduces a log-sum-exp approximation to improve training efficiency. We further extend RankList with skip-wise comparisons, enabling progressive exposure to complex list structures and enhancing global ranking fidelity. Extensive experiments demonstrate the superiority of our method across diverse modalities. On benchmark SER datasets (MSP-Podcast, IEMOCAP, BIIC Podcast), RankList achieves consistent improvements in Kendall's Tau and ranking accuracy compared to standard listwise baselines. We also validate our approach on aesthetic image ranking using the Artistic Image Aesthetics dataset, highlighting its broad applicability. Through ablation and cross-domain studies, we show that RankList not only improves in-domain ranking but also generalizes better across datasets. Our framework offers a unified, extensible approach for modeling ordered preferences in subjective learning scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Fast and Accurate Heuristics for Bus-Factor Estimation",
    "title_es": "Fast and Accurate Heuristics for Bus-Factor Estimation",
    "url": "https://arxiv.org/abs/2508.09828",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09828v1 Announce Type: new \nAbstract: The bus-factor is a critical risk indicator that quantifies how many key contributors a project can afford to lose before core knowledge or functionality is compromised. Despite its practical importance, accurately computing the bus-factor is NP-Hard under established formalizations, making scalable analysis infeasible for large software systems.\n  In this paper, we model software projects as bipartite graphs of developers and tasks and propose two novel approximation heuristics, Minimum Coverage and Maximum Coverage, based on iterative graph peeling, for two influential bus-factor formalizations. Our methods significantly outperform the widely adopted degree-based heuristic, which we show can yield severely inflated estimates.\n  We conduct a comprehensive empirical evaluation on over $1\\,000$ synthetic power-law graphs and demonstrate that our heuristics provide tighter estimates while scaling to graphs with millions of nodes and edges in minutes. Our results reveal that the proposed heuristics are not only more accurate but also robust to structural variations in developer-task assignment graph. We release our implementation as open-source software to support future research and practical adoption.",
    "source": "arXiv"
  },
  {
    "title": "RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians",
    "title_es": "RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians",
    "url": "https://arxiv.org/abs/2508.09830",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09830v1 Announce Type: new \nAbstract: In this paper, we present a generalizable method for 3D surface reconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from RGB images. Unlike existing coordinate-based methods which are often computationally intensive when rendering explicit surfaces, our proposed method, named RayletDF, introduces a new technique called raylet distance field, which aims to directly predict surface points from query rays. Our pipeline consists of three key modules: a raylet feature extractor, a raylet distance field predictor, and a multi-raylet blender. These components work together to extract fine-grained local geometric features, predict raylet distances, and aggregate multiple predictions to reconstruct precise surface points. We extensively evaluate our method on multiple public real-world datasets, demonstrating superior performance in surface reconstruction from point clouds or 3D Gaussians. Most notably, our method achieves exceptional generalization ability, successfully recovering 3D surfaces in a single-forward pass across unseen datasets in testing.",
    "source": "arXiv"
  },
  {
    "title": "Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification",
    "title_es": "Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification",
    "url": "https://arxiv.org/abs/2508.09832",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09832v1 Announce Type: new \nAbstract: Code review is a crucial practice in software development. As code review nowadays is lightweight, various issues can be identified, and sometimes, they can be trivial. Research has investigated automated approaches to classify review comments to gauge the effectiveness of code reviews. However, previous studies have primarily relied on supervised machine learning, which requires extensive manual annotation to train the models effectively. To address this limitation, we explore the potential of using Large Language Models (LLMs) to classify code review comments. We assess the performance of LLMs to classify 17 categories of code review comments. Our results show that LLMs can classify code review comments, outperforming the state-of-the-art approach using a trained deep learning model. In particular, LLMs achieve better accuracy in classifying the five most useful categories, which the state-of-the-art approach struggles with due to low training examples. Rather than relying solely on a specific small training data distribution, our results show that LLMs provide balanced performance across high- and low-frequency categories. These results suggest that the LLMs could offer a scalable solution for code review analytics to improve the effectiveness of the code review process.",
    "source": "arXiv"
  },
  {
    "title": "Speed Always Wins: A Survey on Efficient Architectures for Large Language Models",
    "title_es": "Speed Always Wins: A Survey on Efficient Architectures for Large Language Models",
    "url": "https://arxiv.org/abs/2508.09834",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09834v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have delivered impressive results in language understanding, generation, reasoning, and pushes the ability boundary of multimodal models. Transformer models, as the foundation of modern LLMs, offer a strong baseline with excellent scaling properties. However, the traditional transformer architecture requires substantial computations and poses significant obstacles for large-scale training and practical deployment. In this survey, we offer a systematic examination of innovative LLM architectures that address the inherent limitations of transformers and boost the efficiency. Starting from language modeling, this survey covers the background and technical details of linear and sparse sequence modeling methods, efficient full attention variants, sparse mixture-of-experts, hybrid model architectures incorporating the above techniques, and emerging diffusion LLMs. Additionally, we discuss applications of these techniques to other modalities and consider their wider implications for developing scalable, resource-aware foundation models. By grouping recent studies into the above category, this survey presents a blueprint of modern efficient LLM architectures, and we hope this could help motivate future research toward more efficient, versatile AI systems.",
    "source": "arXiv"
  },
  {
    "title": "Embodied Tactile Perception of Soft Objects Properties",
    "title_es": "Embodied Tactile Perception of Soft Objects Properties",
    "url": "https://arxiv.org/abs/2508.09836",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09836v1 Announce Type: new \nAbstract: To enable robots to develop human-like fine manipulation, it is essential to understand how mechanical compliance, multi-modal sensing, and purposeful interaction jointly shape tactile perception. In this study, we use a dedicated modular e-Skin with tunable mechanical compliance and multi-modal sensing (normal, shear forces and vibrations) to systematically investigate how sensing embodiment and interaction strategies influence robotic perception of objects. Leveraging a curated set of soft wave objects with controlled viscoelastic and surface properties, we explore a rich set of palpation primitives-pressing, precession, sliding that vary indentation depth, frequency, and directionality. In addition, we propose the latent filter, an unsupervised, action-conditioned deep state-space model of the sophisticated interaction dynamics and infer causal mechanical properties into a structured latent space. This provides generalizable and in-depth interpretable representation of how embodiment and interaction determine and influence perception. Our investigation demonstrates that multi-modal sensing outperforms uni-modal sensing. It highlights a nuanced interaction between the environment and mechanical properties of e-Skin, which should be examined alongside the interaction by incorporating temporal dynamics.",
    "source": "arXiv"
  },
  {
    "title": "A First Look at Starlink In-Flight Performance: An Intercontinental Empirical Study",
    "title_es": "A First Look at Starlink In-Flight Performance: An Intercontinental Empirical Study",
    "url": "https://arxiv.org/abs/2508.09839",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09839v1 Announce Type: new \nAbstract: Starlink delivers Internet services to users across terrestrial, maritime, and aviation domains. The prior works have studied its performance at fixed sites and in-motion vehicles, while an in-depth analysis of in-flight performance remains absent. With major airlines now offering Starlink Internet onboard, there is a growing need to evaluate and improve its performance for aviation users. This paper addresses this shortcoming by conducting in-flight measurements over the Baltic Sea and the Pacific Ocean. Our measurement results show that a single user device experiences median throughputs of 64 Mbps and 24 Mbps for the downlink and uplink, respectively. The median uplink throughput is approximately 33 Mbps when the aircraft maintains an altitude above 17,000 feet. However, a significant reduction in uplink performance is observed during the aircraft descent phase, with the median throughput dropping to around 20 Mbps at lower altitudes. Round-trip time (RTT) is highly dependent on the location of the ground station being pinged and the use of inter-satellite links (ISLs). We dive deeper into 5.5 hours of ping measurements collected over the Pacific Ocean and investigate factors influencing RTT, hypothesizing that ISLs routing, data queuing at satellites, and feeder link congestion contribute to deviations from theoretical values. For comparative analysis, we evaluate the Starlink ground terminal and in-flight connectivity performance from the perspectives of a residential user and an airline passenger, respectively.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment",
    "title_es": "Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment",
    "url": "https://arxiv.org/abs/2508.09843",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09843v1 Announce Type: new \nAbstract: Current Omnidirectional Image Quality Assessment (OIQA) methods struggle to evaluate locally non-uniform distortions due to inadequate modeling of spatial variations in quality and ineffective feature representation capturing both local details and global context. To address this, we propose a graph neural network-based OIQA framework that explicitly models structural relationships between viewports to enhance perception of spatial distortion non-uniformity. Our approach employs Fibonacci sphere sampling to generate viewports with well-structured topology, representing each as a graph node. Multi-stage feature extraction networks then derive high-dimensional node representation. To holistically capture spatial dependencies, we integrate a Graph Attention Network (GAT) modeling fine-grained local distortion variations among adjacent viewports, and a graph transformer capturing long-range quality interactions across distant regions. Extensive experiments on two large-scale OIQA databases with complex spatial distortions demonstrate that our method significantly outperforms existing approaches, confirming its effectiveness and strong generalization capability.",
    "source": "arXiv"
  },
  {
    "title": "Whole-Body Bilateral Teleoperation with Multi-Stage Object Parameter Estimation for Wheeled Humanoid Locomanipulation",
    "title_es": "Whole-Body Bilateral Teleoperation with Multi-Stage Object Parameter Estimation for Wheeled Humanoid Locomanipulation",
    "url": "https://arxiv.org/abs/2508.09846",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09846v1 Announce Type: new \nAbstract: This paper presents an object-aware whole-body bilateral teleoperation framework for wheeled humanoid loco-manipulation. This framework combines whole-body bilateral teleoperation with an online multi-stage object inertial parameter estimation module, which is the core technical contribution of this work. The multi-stage process sequentially integrates a vision-based object size estimator, an initial parameter guess generated by a large vision-language model (VLM), and a decoupled hierarchical sampling strategy. The visual size estimate and VLM prior offer a strong initial guess of the object's inertial parameters, significantly reducing the search space for sampling-based refinement and improving the overall estimation speed. A hierarchical strategy first estimates mass and center of mass, then infers inertia from object size to ensure physically feasible parameters, while a decoupled multi-hypothesis scheme enhances robustness to VLM prior errors. Our estimator operates in parallel with high-fidelity simulation and hardware, enabling real-time online updates. The estimated parameters are then used to update the wheeled humanoid's equilibrium point, allowing the operator to focus more on locomotion and manipulation. This integration improves the haptic force feedback for dynamic synchronization, enabling more dynamic whole-body teleoperation. By compensating for object dynamics using the estimated parameters, the framework also improves manipulation tracking while preserving compliant behavior. We validate the system on a customized wheeled humanoid with a robotic gripper and human-machine interface, demonstrating real-time execution of lifting, delivering, and releasing tasks with a payload weighing approximately one-third of the robot's body weight.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance",
    "title_es": "Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance",
    "url": "https://arxiv.org/abs/2508.09847",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09847v1 Announce Type: new \nAbstract: We present a benchmark of diffusion models for human face generation on a small-scale CelebAMask-HQ dataset, evaluating both unconditional and conditional pipelines. Our study compares UNet and DiT architectures for unconditional generation and explores LoRA-based fine-tuning of pretrained Stable Diffusion models as a separate experiment. Building on the multi-conditioning approach of Giambi and Lisanti, which uses both attribute vectors and segmentation masks, our main contribution is the integration of an InfoNCE loss for attribute embedding and the adoption of a SegFormer-based segmentation encoder. These enhancements improve the semantic alignment and controllability of attribute-guided synthesis. Our results highlight the effectiveness of contrastive embedding learning and advanced segmentation encoding for controlled face generation in limited data settings.",
    "source": "arXiv"
  },
  {
    "title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts",
    "title_es": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts",
    "url": "https://arxiv.org/abs/2508.09848",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09848v1 Announce Type: new \nAbstract: We introduce PRELUDE, a benchmark for evaluating long-context understanding through the task of determining whether a character's prequel story is consistent with the canonical narrative of the original book. Our task poses a stronger demand for global comprehension and deep reasoning than existing benchmarks -- as the prequels are not part of the original story, assessing their plausibility typically requires searching and integrating information that is only indirectly related. Empirically, 88% of instances require evidence from multiple parts of the narrative. Experimental results highlight the challenge of our task: in-context learning, RAG and in-domain training with state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans by >15%. A further human study reveals that models often produce correct answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy compared to humans. These findings underscore the substantial room for improvement in long-context understanding and reasoning.",
    "source": "arXiv"
  },
  {
    "title": "ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images",
    "title_es": "ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images",
    "url": "https://arxiv.org/abs/2508.09849",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09849v1 Announce Type: new \nAbstract: X-ray computed tomography (CT) is the main 3D technique for imaging the internal microstructures of materials. Quantitative analysis of the microstructures is usually achieved by applying a sequence of steps that are implemented to the entire 3D image. This is challenged by various imaging artifacts inherent from the technique, e.g., beam hardening and partial volume. Consequently, the analysis requires users to make a number of decisions to segment and classify the microstructures based on the voxel gray-values. In this context, a software tool, here called ARI3D, is proposed to interactively analyze regions in three-dimensional X-ray CT images, assisting users through the various steps of a protocol designed to classify and quantify objects within regions of a three-dimensional image. ARI3D aims to 1) Improve phase identification; 2) Account for partial volume effect; 3) Increase the detection limit and accuracy of object quantification; and 4) Harmonize quantitative 3D analysis that can be implemented in different fields of science.",
    "source": "arXiv"
  },
  {
    "title": "Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment",
    "title_es": "Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment",
    "url": "https://arxiv.org/abs/2508.09850",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09850v1 Announce Type: new \nAbstract: Vision Transformers (ViTs) achieve remarkable performance in image recognition tasks, yet their alignment with human perception remains largely unexplored. This study systematically analyzes how model size, dataset size, data augmentation and regularization impact ViT perceptual alignment with human judgments on the TID2013 dataset. Our findings confirm that larger models exhibit lower perceptual alignment, consistent with previous works. Increasing dataset diversity has a minimal impact, but exposing models to the same images more times reduces alignment. Stronger data augmentation and regularization further decrease alignment, especially in models exposed to repeated training cycles. These results highlight a trade-off between model complexity, training strategies, and alignment with human perception, raising important considerations for applications requiring human-like visual understanding.",
    "source": "arXiv"
  },
  {
    "title": "Short proofs without interference",
    "title_es": "Short proofs without interference",
    "url": "https://arxiv.org/abs/2508.09851",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09851v1 Announce Type: new \nAbstract: Interference is a phenomenon on proof systems for SAT solving that is both counter-intuitive and bothersome when developing proof-logging techniques. However, all existing proof systems that can produce short proofs for all inprocessing techniques deployed by SAT present this feature. Based on insights from propositional dynamic logic, we propose a framework that eliminates interference while preserving the same expressive power of interference-based proofs. Furthermore, we propose a first building blocks towards RUP-like decision procedures for our dynamic logic-based frameworks, which are essential to developing effective proof checking methods.",
    "source": "arXiv"
  },
  {
    "title": "STREAM (ChemBio): A Standard for Transparently Reporting Evaluations in AI Model Reports",
    "title_es": "STREAM (ChemBio): A Standard for Transparently Reporting Evaluations in AI Model Reports",
    "url": "https://arxiv.org/abs/2508.09853",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09853v1 Announce Type: new \nAbstract: Evaluations of dangerous AI capabilities are important for managing catastrophic risks. Public transparency into these evaluations - including what they test, how they are conducted, and how their results inform decisions - is crucial for building trust in AI development. We propose STREAM (A Standard for Transparently Reporting Evaluations in AI Model Reports), a standard to improve how model reports disclose evaluation results, initially focusing on chemical and biological (ChemBio) benchmarks. Developed in consultation with 23 experts across government, civil society, academia, and frontier AI companies, this standard is designed to (1) be a practical resource to help AI developers present evaluation results more clearly, and (2) help third parties identify whether model reports provide sufficient detail to assess the rigor of the ChemBio evaluations. We concretely demonstrate our proposed best practices with \"gold standard\" examples, and also provide a three-page reporting template to enable AI developers to implement our recommendations more easily.",
    "source": "arXiv"
  },
  {
    "title": "Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes",
    "title_es": "Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes",
    "url": "https://arxiv.org/abs/2508.09855",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09855v1 Announce Type: new \nAbstract: Human-robot teaming (HRT) systems often rely on large-scale datasets of human and robot interactions, especially for close-proximity collaboration tasks such as human-robot handovers. Learning robot manipulation policies from raw, real-world image data requires a large number of robot-action trials in the physical environment. Although simulation training offers a cost-effective alternative, the visual domain gap between simulation and robot workspace remains a major limitation. We introduce a method for training HRT policies, focusing on human-to-robot handovers, solely from RGB images without the need for real-robot training or real-robot data collection. The goal is to enable the robot to reliably receive objects from a human with stable grasping while avoiding collisions with the human hand. The proposed policy learner leverages sparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes to generate robot demonstrations containing image-action pairs captured with a camera mounted on the robot gripper. As a result, the simulated camera pose changes in the reconstructed scene can be directly translated into gripper pose changes. Experiments in both Gaussian Splatting reconstructed scene and real-world human-to-robot handover experiments demonstrate that our method serves as a new and effective representation for the human-to-robot handover task, contributing to more seamless and robust HRT.",
    "source": "arXiv"
  },
  {
    "title": "Invertible Syntax without the Tuples (Functional Pearl)",
    "title_es": "Invertible Syntax without the Tuples (Functional Pearl)",
    "url": "https://arxiv.org/abs/2508.09856",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09856v1 Announce Type: new \nAbstract: In the seminal paper Functional unparsing, Olivier Danvy used continuation passing to reanalyse printf-like format strings as combinators. In the intervening decades, the conversation shifted towards a concurrent line of work -- applicative, monadic or arrow-based combinator libraries -- in an effort to find combinators for invertible syntax descriptions that simultaneously determine a parser as well as a printer, and with more expressive power, able to handle inductive structures such as lists and trees. Along the way, continuation passing got lost. This paper argues that Danvy's insight remains as relevant to the general setting as it was to the restricted setting of his original paper. Like him, we present three solutions that exploit continuation-passing style as an alternative to both dependent types and monoidal aggregation via nested pairs, in our case to parse and print structured data with increasing expressive power.",
    "source": "arXiv"
  },
  {
    "title": "OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better",
    "title_es": "OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better",
    "url": "https://arxiv.org/abs/2508.09857",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09857v1 Announce Type: new \nAbstract: Encoding videos into discrete tokens could align with text tokens to facilitate concise and unified multi-modal LLMs, yet introducing significant spatiotemporal compression compared to continuous video representation. Previous discrete video VAEs experienced unstable training, long training time, and degraded reconstruction quality. Given the easier training and superior performance of continuous VAEs, an intuitive idea is to enhance discrete video VAEs by leveraging continuous VAEs. After rethinking the intrinsic link between discrete and continuous representations, we found that FSQ could effectively preserve pre-trained continuous VAE priors compared to other quantization methods. By leveraging continuous VAE priors, it converges several times faster than training from scratch and achieves superior performance at convergence. Meanwhile, two structural improvements are proposed. First, inspired by how continuous VAEs enhance reconstruction via enlarged latent dimensions, we introduce a multi-token quantization mechanism, which achieves nearly a 1 dB improvement in PSNR without compromising the token compression ratio. Second, to tackle reconstruction challenges in high-compression video VAEs, we strengthen first-frame reconstruction, enabling the causal VAE to leverage this information in subsequent frames and markedly improving the performance of 4 x 16 x 16 discrete VAEs. Furthermore, we propose a joint discrete-continuous optimization scheme that unifies the two paradigms and, for the first time, achieves competitive performance on both continuous and discrete representations within a single network. We name our method OneVAE to reflect this connection.",
    "source": "arXiv"
  },
  {
    "title": "HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics",
    "title_es": "HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics",
    "url": "https://arxiv.org/abs/2508.09858",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09858v1 Announce Type: new \nAbstract: \\textbf{Synthetic human dynamics} aims to generate photorealistic videos of human subjects performing expressive, intention-driven motions. However, current approaches face two core challenges: (1) \\emph{geometric inconsistency} and \\emph{coarse reconstruction}, due to limited 3D modeling and detail preservation; and (2) \\emph{motion generalization limitations} and \\emph{scene inharmonization}, stemming from weak generative capabilities. To address these, we present \\textbf{HumanGenesis}, a framework that integrates geometric and generative modeling through four collaborative agents: (1) \\textbf{Reconstructor} builds 3D-consistent human-scene representations from monocular video using 3D Gaussian Splatting and deformation decomposition. (2) \\textbf{Critique Agent} enhances reconstruction fidelity by identifying and refining poor regions via multi-round MLLM-based reflection. (3) \\textbf{Pose Guider} enables motion generalization by generating expressive pose sequences using time-aware parametric encoders. (4) \\textbf{Video Harmonizer} synthesizes photorealistic, coherent video via a hybrid rendering pipeline with diffusion, refining the Reconstructor through a Back-to-4D feedback loop. HumanGenesis achieves state-of-the-art performance on tasks including text-guided synthesis, video reenactment, and novel-pose generalization, significantly improving expressiveness, geometric fidelity, and scene integration.",
    "source": "arXiv"
  },
  {
    "title": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation",
    "title_es": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation",
    "url": "https://arxiv.org/abs/2508.09860",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09860v1 Announce Type: new \nAbstract: Human-aligned AI is a critical component of co-creativity, as it enables models to accurately interpret human intent and generate controllable outputs that align with design goals in collaborative content creation. This direction is especially relevant in procedural content generation via reinforcement learning (PCGRL), which is intended to serve as a tool for human designers. However, existing systems often fall short of exhibiting human-centered behavior, limiting the practical utility of AI-driven generation tools in real-world design workflows. In this paper, we propose VIPCGRL (Vision-Instruction PCGRL), a novel deep reinforcement learning framework that incorporates three modalities-text, level, and sketches-to extend control modality and enhance human-likeness. We introduce a shared embedding space trained via quadruple contrastive learning across modalities and human-AI styles, and align the policy using an auxiliary reward based on embedding similarity. Experimental results show that VIPCGRL outperforms existing baselines in human-likeness, as validated by both quantitative metrics and human evaluations. The code and dataset will be available upon publication.",
    "source": "arXiv"
  },
  {
    "title": "Assessing the Feasibility of Lightweight Whisper Models for Low-Resource Urdu Transcription",
    "title_es": "Assessing the Feasibility of Lightweight Whisper Models for Low-Resource Urdu Transcription",
    "url": "https://arxiv.org/abs/2508.09865",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09865v1 Announce Type: new \nAbstract: This study evaluates the feasibility of lightweight Whisper models (Tiny, Base, Small) for Urdu speech recognition in low-resource settings. Despite Urdu being the 10th most spoken language globally with over 230 million speakers, its representation in automatic speech recognition (ASR) systems remains limited due to dialectal diversity, code-switching, and sparse training data. We benchmark these models on a curated Urdu dataset using word error rate (WER), without fine-tuning. Results show Whisper-Small achieves the lowest error rates (33.68\\% WER), outperforming Tiny (67.08\\% WER) and Base (53.67\\% WER). Qualitative analysis reveals persistent challenges in phonetic accuracy and lexical coherence, particularly for complex utterances. While Whisper-Small demonstrates promise for deployable Urdu ASR, significant gaps remain. Our findings emphasize lay the groundwork for future research into effective, low-resource ASR systems.",
    "source": "arXiv"
  },
  {
    "title": "FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness",
    "title_es": "FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness",
    "url": "https://arxiv.org/abs/2508.09866",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09866v1 Announce Type: new \nAbstract: To protect clients' right to be forgotten in federated learning, federated unlearning aims to remove the data contribution of leaving clients from the global learned model. While current studies mainly focused on enhancing unlearning efficiency and effectiveness, the crucial aspects of efficiency fairness and performance fairness among decentralized clients during unlearning have remained largely unexplored. In this study, we introduce FedShard, the first federated unlearning algorithm designed to concurrently guarantee both efficiency fairness and performance fairness. FedShard adaptively addresses the challenges introduced by dilemmas among convergence, unlearning efficiency, and unlearning fairness. Furthermore, we propose two novel metrics to quantitatively assess the fairness of unlearning algorithms, which we prove to satisfy well-known properties in other existing fairness measurements. Our theoretical analysis and numerical evaluation validate FedShard's fairness in terms of both unlearning performance and efficiency. We demonstrate that FedShard mitigates unfairness risks such as cascaded leaving and poisoning attacks and realizes more balanced unlearning costs among clients. Experimental results indicate that FedShard accelerates the data unlearning process 1.3-6.2 times faster than retraining from scratch and 4.9 times faster than the state-of-the-art exact unlearning methods.",
    "source": "arXiv"
  },
  {
    "title": "Analysis of Domain Shift across ASR Architectures via TTS-Enabled Separation of Target Domain and Acoustic Conditions",
    "title_es": "Analysis of Domain Shift across ASR Architectures via TTS-Enabled Separation of Target Domain and Acoustic Conditions",
    "url": "https://arxiv.org/abs/2508.09868",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09868v1 Announce Type: new \nAbstract: We analyze automatic speech recognition (ASR) modeling choices under domain mismatch, comparing classic modular and novel sequence-to-sequence (seq2seq) architectures. Across the different ASR architectures, we examine a spectrum of modeling choices, including label units, context length, and topology. To isolate language domain effects from acoustic variation, we synthesize target domain audio using a text-to-speech system trained on LibriSpeech. We incorporate target domain n-gram and neural language models for domain adaptation without retraining the acoustic model. To our knowledge, this is the first controlled comparison of optimized ASR systems across state-of-the-art architectures under domain shift, offering insights into their generalization. The results show that, under domain shift, rather than the decoder architecture choice or the distinction between classic modular and novel seq2seq models, it is specific modeling choices that influence performance.",
    "source": "arXiv"
  },
  {
    "title": "The Price of EF1 for Few Agents with Additive Ternary Valuations",
    "title_es": "The Price of EF1 for Few Agents with Additive Ternary Valuations",
    "url": "https://arxiv.org/abs/2508.09869",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09869v1 Announce Type: new \nAbstract: We consider a resource allocation problem with agents that have additive ternary valuations for a set of indivisible items, and bound the price of envy-free up to one item (EF1) allocations. For a large number $n$ of agents, we show a lower bound of $\\Omega(\\sqrt{n})$, implying that the price of EF1 is no better than when the agents have general subadditive valuations. We then focus on instances with few agents and show that the price of EF1 is $12/11$ for $n=2$, and between $1.2$ and $1.256$ for $n=3$.",
    "source": "arXiv"
  },
  {
    "title": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models",
    "title_es": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models",
    "url": "https://arxiv.org/abs/2508.09874",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09874v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown strong abilities in general language tasks, yet adapting them to specific domains remains a challenge. Current method like Domain Adaptive Pretraining (DAPT) requires costly full-parameter training and suffers from catastrophic forgetting. Meanwhile, Retrieval-Augmented Generation (RAG) introduces substantial inference latency due to expensive nearest-neighbor searches and longer context. This paper introduces Memory Decoder, a plug-and-play pretrained memory that enables efficient domain adaptation without changing the original model's parameters. Memory Decoder employs a small transformer decoder that learns to imitate the behavior of an external non-parametric retriever. Once trained, Memory Decoder can be seamlessly integrated with any pretrained language model that shares the same tokenizer, requiring no model-specific modifications. Experimental results demonstrate that Memory Decoder enables effective adaptation of various Qwen and Llama models to three distinct specialized domains: biomedicine, finance, and law, reducing perplexity by an average of 6.17 points. Overall, Memory Decoder introduces a novel paradigm centered on a specially pretrained memory component designed for domain-specific adaptation. This memory architecture can be integrated in a plug-and-play manner, consistently enhancing performance across multiple models within the target domain.",
    "source": "arXiv"
  },
  {
    "title": "An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues",
    "title_es": "An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues",
    "url": "https://arxiv.org/abs/2508.09875",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09875v1 Announce Type: new \nAbstract: Multilingual software development integrates multiple languages into a single application, with the Foreign Function Interface (FFI) enabling seamless interaction. While FFI boosts efficiency and extensibility, it also introduces risks. Existing studies focus on FFIs in languages like Python and Java, neglecting CGO, the emerging FFI in Go, which poses unique risks.\n  To address these concerns, we conduct an empirical study of CGO usage across 920 open-source Go projects. Our study aims to reveal the distribution, patterns, purposes, and critical issues associated with CGO, offering insights for developers and the Go team. We develop CGOAnalyzer, a tool to efficiently identify and quantify CGO-related features. Our findings reveal that: (1) 11.3% of analyzed Go projects utilize CGO, with usage concentrated in a subset of projects; (2) CGO serves 4 primary purposes, including system-level interactions and performance optimizations, with 15 distinct usage patterns observed; (3) 19 types of CGO-related issues exist, including one critical issue involving unnecessary pointer checks that pose risks of runtime crashes due to limitations in the current Go compilation toolchain; (4) a temporary solution reduces unnecessary pointer checks, mitigating crash risks, and (5) we submitted a proposal to improve the Go toolchain for a permanent fix, which has been grouped within an accepted proposal for future resolution. Our findings provide valuable insights for developers and the Go team, enhancing development efficiency and reliability while improving the robustness of the Go toolchain.",
    "source": "arXiv"
  },
  {
    "title": "A Shank Angle-Based Control System Enables Soft Exoskeleton to Assist Human Non-Steady Locomotion",
    "title_es": "A Shank Angle-Based Control System Enables Soft Exoskeleton to Assist Human Non-Steady Locomotion",
    "url": "https://arxiv.org/abs/2508.09876",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09876v1 Announce Type: new \nAbstract: Exoskeletons have been shown to effectively assist humans during steady locomotion. However, their effects on non-steady locomotion, characterized by nonlinear phase progression within a gait cycle, remain insufficiently explored, particularly across diverse activities. This work presents a shank angle-based control system that enables the exoskeleton to maintain real-time coordination with human gait, even under phase perturbations, while dynamically shaping assistance profiles to match the biological ankle moment patterns across walking, running, stair negotiation tasks. The control system consists of an assistance profile online generation method and a model-based feedforward control method. The assistance profile is formulated as a dual-Gaussian model with the shank angle as the independent variable. Leveraging only IMU measurements, the model parameters are updated online each stride to adapt to inter- and intra-individual biomechanical variability. The profile tracking control employs a human-exoskeleton kinematics and stiffness model as a feedforward component, reducing reliance on historical control data due to the lack of clear and consistent periodicity in non-steady locomotion. Three experiments were conducted using a lightweight soft exoskeleton with multiple subjects. The results validated the effectiveness of each individual method, demonstrated the robustness of the control system against gait perturbations across various activities, and revealed positive biomechanical and physiological responses of human users to the exoskeleton's mechanical assistance.",
    "source": "arXiv"
  },
  {
    "title": "A Survey of Cognitive Distortion Detection and Classification in NLP",
    "title_es": "A Survey of Cognitive Distortion Detection and Classification in NLP",
    "url": "https://arxiv.org/abs/2508.09878",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09878v1 Announce Type: new \nAbstract: As interest grows in the application of natural language processing (NLP) techniques to mental health, a growing body of work explores the automatic detection and classification of cognitive distortions (CDs). CDs are habitual patterns of negatively biased or flawed thinking that distort how people perceive events, judge themselves, and react to the world around them. Identifying and addressing them is an important part of therapy. Despite its momentum, the field remains fragmented, with inconsistencies in CD taxonomies, task formulations, and evaluation practices. This survey reviews 38 studies spanning two decades, providing a structured overview of datasets, modelling approaches, and evaluation strategies. We provide a consolidated CD taxonomy reference, summarise common task setups, and highlight open challenges to support more coherent and reproducible research in this emerging area.",
    "source": "arXiv"
  },
  {
    "title": "A Comparative Analysis on ASR System Combination for Attention, CTC, Factored Hybrid, and Transducer Models",
    "title_es": "A Comparative Analysis on ASR System Combination for Attention, CTC, Factored Hybrid, and Transducer Models",
    "url": "https://arxiv.org/abs/2508.09880",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09880v1 Announce Type: new \nAbstract: Combination approaches for speech recognition (ASR) systems cover structured sentence-level or word-based merging techniques as well as combination of model scores during beam search. In this work, we compare model combination across popular ASR architectures. Our method leverages the complementary strengths of different models in exploring diverse portions of the search space. We rescore a joint hypothesis list of two model candidates. We then identify the best hypothesis through log-linear combination of these sequence-level scores. While model combination during first-pass recognition may yield improved performance, it introduces variability due to differing decoding methods, making direct comparison more challenging. Our two-pass method ensures consistent comparisons across all system combination results presented in this study. We evaluate model pair candidates with varying architectures and label topologies and units. Experimental results are provided for the Librispeech 960h task.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning",
    "title_es": "Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning",
    "url": "https://arxiv.org/abs/2508.09883",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09883v1 Announce Type: new \nAbstract: Large language models (LLMs) demonstrate remarkable reasoning capabilities in tasks such as algorithmic coding and mathematical problem-solving. Recent methods have improved reasoning through expanded corpus and multistage training combining reinforcement learning and supervised fine-tuning. Although some methods suggest that small but targeted dataset can incentivize reasoning via only distillation, a reasoning scaling laws is still taking shape, increasing computational costs. To address this, we propose a data-efficient distillation framework (DED) that optimizes the Pareto frontier of reasoning distillation. Inspired by the on-policy learning and diverse roll-out strategies of reinforcement learning, the key idea of our approach is threefold: (1) We identify that benchmark scores alone do not determine an effective teacher model. Through comprehensive comparisons of leading reasoning LLMs, we develop a method to select an optimal teacher model. (2) While scaling distillation can enhance reasoning, it often degrades out-of-domain performance. A carefully curated, smaller corpus achieves a balanced trade-off between in-domain and out-of-domain capabilities. (3) Diverse reasoning trajectories encourage the student model to develop robust reasoning skills. We validate our method through evaluations on mathematical reasoning (AIME 2024/2025, MATH-500) and code generation (LiveCodeBench), achieving state-of-the-art results with only 0.8k carefully curated examples, bypassing the need for extensive scaling. Our systematic analysis demonstrates that DED outperforms existing methods by considering factors beyond superficial hardness, token length, or teacher model capability. This work offers a practical and efficient pathway to advanced reasoning while preserving general capabilities.",
    "source": "arXiv"
  },
  {
    "title": "COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets",
    "title_es": "COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets",
    "url": "https://arxiv.org/abs/2508.09886",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09886v1 Announce Type: new \nAbstract: Conventional single-dataset training often fails with new data distributions, especially in ultrasound (US) image analysis due to limited data, acoustic shadows, and speckle noise. Therefore, constructing a universal framework for multi-heterogeneous US datasets is imperative. However, a key challenge arises: how to effectively mitigate inter-dataset interference while preserving dataset-specific discriminative features for robust downstream task? Previous approaches utilize either a single source-specific decoder or a domain adaptation strategy, but these methods experienced a decline in performance when applied to other domains. Considering this, we propose a Universal Collaborative Mixture of Heterogeneous Source-Specific Experts (COME). Specifically, COME establishes dual structure-semantic shared experts that create a universal representation space and then collaborate with source-specific experts to extract discriminative features through providing complementary features. This design enables robust generalization by leveraging cross-datasets experience distributions and providing universal US priors for small-batch or unseen data scenarios. Extensive experiments under three evaluation modes (single-dataset, intra-organ, and inter-organ integration datasets) demonstrate COME's superiority, achieving significant mean AP improvements over state-of-the-art methods. Our project is available at: https://universalcome.github.io/UniversalCOME/.",
    "source": "arXiv"
  },
  {
    "title": "Modern Neural Networks for Small Tabular Datasets: The New Default for Field-Scale Digital Soil Mapping?",
    "title_es": "Modern Neural Networks for Small Tabular Datasets: The New Default for Field-Scale Digital Soil Mapping?",
    "url": "https://arxiv.org/abs/2508.09888",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09888v1 Announce Type: new \nAbstract: In the field of pedometrics, tabular machine learning is the predominant method for predicting soil properties from remote and proximal soil sensing data, forming a central component of digital soil mapping. At the field-scale, this predictive soil modeling (PSM) task is typically constrained by small training sample sizes and high feature-to-sample ratios in soil spectroscopy. Traditionally, these conditions have proven challenging for conventional deep learning methods. Classical machine learning algorithms, particularly tree-based models like Random Forest and linear models such as Partial Least Squares Regression, have long been the default choice for field-scale PSM. Recent advances in artificial neural networks (ANN) for tabular data challenge this view, yet their suitability for field-scale PSM has not been proven. We introduce a comprehensive benchmark that evaluates state-of-the-art ANN architectures, including the latest multilayer perceptron (MLP)-based models (TabM, RealMLP), attention-based transformer variants (FT-Transformer, ExcelFormer, T2G-Former, AMFormer), retrieval-augmented approaches (TabR, ModernNCA), and an in-context learning foundation model (TabPFN). Our evaluation encompasses 31 field- and farm-scale datasets containing 30 to 460 samples and three critical soil properties: soil organic matter or soil organic carbon, pH, and clay content. Our results reveal that modern ANNs consistently outperform classical methods on the majority of tasks, demonstrating that deep learning has matured sufficiently to overcome the long-standing dominance of classical machine learning for PSM. Notably, TabPFN delivers the strongest overall performance, showing robustness across varying conditions. We therefore recommend the adoption of modern ANNs for field-scale PSM and propose TabPFN as the new default choice in the toolkit of every pedometrician.",
    "source": "arXiv"
  },
  {
    "title": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving",
    "title_es": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving",
    "url": "https://arxiv.org/abs/2508.09889",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09889v1 Announce Type: new \nAbstract: The rapid advancement of large language models (LLMs) has empowered intelligent agents to leverage diverse external tools for solving complex real-world problems. However, as agents increasingly depend on multiple tools, they encounter new challenges: extended contexts from disparate sources and noisy or irrelevant tool outputs can undermine system reliability and accuracy. These challenges underscore the necessity for enhanced stability in agent-based systems. To address this, we introduce dynamic supervision and maneuvering mechanisms, constructing a robust and dynamic Multi-Agent System (MAS) architecture within the AWorld framework. In our approach, the Execution Agent invokes the Guard Agent at critical steps to verify and correct the reasoning process, effectively reducing errors arising from noise and bolstering problem-solving robustness. Extensive experiments on the GAIA test dataset reveal that our dynamic maneuvering mechanism significantly improves both the effectiveness and stability of solutions, outperforming single-agent system (SAS) and standard tool-augmented systems. As a result, our dynamic MAS system achieved first place among open-source projects on the prestigious GAIA leaderboard. These findings highlight the practical value of collaborative agent roles in developing more reliable and trustworthy intelligent systems.",
    "source": "arXiv"
  },
  {
    "title": "Retroactive Monotonic Priority Queues via Range Searching",
    "title_es": "Retroactive Monotonic Priority Queues via Range Searching",
    "url": "https://arxiv.org/abs/2508.09892",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09892v1 Announce Type: new \nAbstract: The best known fully retroactive priority queue costs $O(\\log^2 m \\log \\log m)$ time per operation, where $m$ is the number of operations performed on the data structure. In contrast, standard (non-retroactive) and partially retroactive priority queues cost $O(\\log m)$ time per operation. So far, it is unknown whether this $O(\\log m)$ bound can be achieved for fully retroactive priority queues.\n  In this work, we study a restricted variant of priority queues known as monotonic priority queues. We show that finding the minimum in a retroactive monotonic priority queue is a special case of the range-searching problem. We design a fully retroactive monotonic priority queue with a cost of $O(\\log m + T(m))$ time per operation, where $T(m)$ is the maximum between the query and the update time of a specific range-searching data structure with $m$ elements. Finally, we design a fully retroactive monotonic priority queue that costs $O(\\log m \\log \\log m)$ time per operation.",
    "source": "arXiv"
  },
  {
    "title": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA",
    "title_es": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA",
    "url": "https://arxiv.org/abs/2508.09893",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09893v1 Announce Type: new \nAbstract: Regulatory compliance question answering (QA) requires precise, verifiable information, and domain-specific expertise, posing challenges for Large Language Models (LLMs). In this work, we present a novel multi-agent framework that integrates a Knowledge Graph (KG) of Regulatory triplets with Retrieval-Augmented Generation (RAG) to address these demands. First, agents build and maintain an ontology-free KG by extracting subject--predicate--object (SPO) triplets from regulatory documents and systematically cleaning, normalizing, deduplicating, and updating them. Second, these triplets are embedded and stored along with their corresponding textual sections and metadata in a single enriched vector database, allowing for both graph-based reasoning and efficient information retrieval. Third, an orchestrated agent pipeline leverages triplet-level retrieval for question answering, ensuring high semantic alignment between user queries and the factual \"who-did-what-to-whom\" core captured by the graph. Our hybrid system outperforms conventional methods in complex regulatory queries, ensuring factual correctness with embedded triplets, enabling traceability through a unified vector database, and enhancing understanding through subgraph visualization, providing a robust foundation for compliance-driven and broader audit-focused applications.",
    "source": "arXiv"
  },
  {
    "title": "Rare anomalies require large datasets: About proving the existence of anomalies",
    "title_es": "Rare anomalies require large datasets: About proving the existence of anomalies",
    "url": "https://arxiv.org/abs/2508.09894",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09894v1 Announce Type: new \nAbstract: Detecting whether any anomalies exist within a dataset is crucial for effective anomaly detection, yet it remains surprisingly underexplored in anomaly detection literature. This paper presents a comprehensive study that addresses the fundamental question: When can we conclusively determine that anomalies are present? Through extensive experimentation involving over three million statistical tests across various anomaly detection tasks and algorithms, we identify a relationship between the dataset size, contamination rate, and an algorithm-dependent constant $ \\alpha_{\\text{algo}} $. Our results demonstrate that, for an unlabeled dataset of size $ N $ and contamination rate $ \\nu $, the condition $ N \\ge \\frac{\\alpha_{\\text{algo}}}{\\nu^2} $ represents a lower bound on the number of samples required to confirm anomaly existence. This threshold implies a limit to how rare anomalies can be before proving their existence becomes infeasible.",
    "source": "arXiv"
  },
  {
    "title": "Finetuning Large Language Model as an Effective Symbolic Regressor",
    "title_es": "Finetuning Large Language Model as an Effective Symbolic Regressor",
    "url": "https://arxiv.org/abs/2508.09897",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09897v1 Announce Type: new \nAbstract: Deriving governing equations from observational data, known as Symbolic Regression (SR), is a cornerstone of scientific discovery. Large Language Models (LLMs) have shown promise in this task by leveraging their vast cross-disciplinary scientific knowledge. However, existing LLM-based methods primarily rely on direct inference or prompt engineering, often requiring excessive inference iterations to converge on correct formulas or failing to treating complex equation targets. These limitations in effectiveness and generalization stem from an inherent tension between pre-trained LLMs' proficiency in approximate reasoning and the high-precision demands of SR tasks. To bridge this gap, we propose to fine-tune LLMs for enhanced SR capability. Yet, the absence of dedicated datasets for SR-oriented fine-tuning remains a critical barrier. We thus introduce SymbArena, specifically engineered to optimize LLMs for SR. This benchmark comprises 148,102 diverse equations formulated as corpora of 1.83 billion tokens for LLM utilization, enabling effective training and inference. Further, SymbArena proposes a heuristics metric to precisely quantify form-level consistency, going beyond existing SR numerical-oriented evaluation strategies. With this benchmark, we explore mainstream LLM fine-tuning techniques for SR tasks and establish SymbolicChat, a simple yet effective LLM-based SR strong baseline. Experimental results validate SymbolicChat as the first LLM to exceed traditional numerical methods in both numerical precision and symbolic form accuracy, outperforming the second-best LLM baseline with improvements of 2-fold gains in R2 score and 8.37% in form-level consistency score.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Na\\\"ive Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs",
    "title_es": "Beyond Na\\\"ive Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs",
    "url": "https://arxiv.org/abs/2508.09904",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09904v1 Announce Type: new \nAbstract: Forecasting in real-world settings requires models to integrate not only historical data but also relevant contextual information, often available in textual form. While recent work has shown that large language models (LLMs) can be effective context-aided forecasters via na\\\"ive direct prompting, their full potential remains underexplored. We address this gap with 4 strategies, providing new insights into the zero-shot capabilities of LLMs in this setting. ReDP improves interpretability by eliciting explicit reasoning traces, allowing us to assess the model's reasoning over the context independently from its forecast accuracy. CorDP leverages LLMs solely to refine existing forecasts with context, enhancing their applicability in real-world forecasting pipelines. IC-DP proposes embedding historical examples of context-aided forecasting tasks in the prompt, substantially improving accuracy even for the largest models. Finally, RouteDP optimizes resource efficiency by using LLMs to estimate task difficulty, and routing the most challenging tasks to larger models. Evaluated on different kinds of context-aided forecasting tasks from the CiK benchmark, our strategies demonstrate distinct benefits over na\\\"ive prompting across LLMs of different sizes and families. These results open the door to further simple yet effective improvements in LLM-based context-aided forecasting.",
    "source": "arXiv"
  },
  {
    "title": "Collision-Free Bearing-Driven Formation Tracking for Euler-Lagrange Systems",
    "title_es": "Collision-Free Bearing-Driven Formation Tracking for Euler-Lagrange Systems",
    "url": "https://arxiv.org/abs/2508.09908",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09908v1 Announce Type: new \nAbstract: In this paper, we investigate the problem of tracking formations driven by bearings for heterogeneous Euler-Lagrange systems with parametric uncertainty in the presence of multiple moving leaders. To estimate the leaders' velocities and accelerations, we first design a distributed observer for the leader system, utilizing a bearing-based localization condition in place of the conventional connectivity assumption. This observer, coupled with an adaptive mechanism, enables the synthesis of a novel distributed control law that guides the formation towards the target formation, without requiring prior knowledge of the system parameters. Furthermore, we establish a sufficient condition, dependent on the initial formation configuration, that ensures collision avoidance throughout the formation evolution. The effectiveness of the proposed approach is demonstrated through a numerical example.",
    "source": "arXiv"
  },
  {
    "title": "SHREC'25 Track on Multiple Relief Patterns: Report and Analysis",
    "title_es": "SHREC'25 Track on Multiple Relief Patterns: Report and Analysis",
    "url": "https://arxiv.org/abs/2508.09909",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09909v1 Announce Type: new \nAbstract: This SHREC 2025 track focuses on the recognition and segmentation of relief patterns embedded on the surface of a set of synthetically generated triangle meshes. We report the methods proposed by the participants, whose performance highlights the inherent complexity of solving the problem, which is still open. Then, we discuss the critical aspects of the proposed tasks, highlight the limitations of current techniques, and outline possible directions for future research. All resources and track details are available at the official track webpage: https://sites.google.com/unifi.it/shrec25-relief-pattern.",
    "source": "arXiv"
  },
  {
    "title": "Wisdom of the Crowd, Without the Crowd: A Socratic LLM for Asynchronous Deliberation on Perspectivist Data",
    "title_es": "Wisdom of the Crowd, Without the Crowd: A Socratic LLM for Asynchronous Deliberation on Perspectivist Data",
    "url": "https://arxiv.org/abs/2508.09911",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09911v1 Announce Type: new \nAbstract: Data annotation underpins the success of modern AI, but the aggregation of crowd-collected datasets can harm the preservation of diverse perspectives in data. Difficult and ambiguous tasks cannot easily be collapsed into unitary labels. Prior work has shown that deliberation and discussion improve data quality and preserve diverse perspectives -- however, synchronous deliberation through crowdsourcing platforms is time-intensive and costly. In this work, we create a Socratic dialog system using Large Language Models (LLMs) to act as a deliberation partner in place of other crowdworkers. Against a benchmark of synchronous deliberation on two tasks (Sarcasm and Relation detection), our Socratic LLM encouraged participants to consider alternate annotation perspectives, update their labels as needed (with higher confidence), and resulted in higher annotation accuracy (for the Relation task where ground truth is available). Qualitative findings show that our agent's Socratic approach was effective at encouraging reasoned arguments from our participants, and that the intervention was well-received. Our methodology lays the groundwork for building scalable systems that preserve individual perspectives in generating more representative datasets.",
    "source": "arXiv"
  },
  {
    "title": "E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras",
    "title_es": "E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras",
    "url": "https://arxiv.org/abs/2508.09912",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09912v1 Announce Type: new \nAbstract: Novel view synthesis and 4D reconstruction techniques predominantly rely on RGB cameras, thereby inheriting inherent limitations such as the dependence on adequate lighting, susceptibility to motion blur, and a limited dynamic range. Event cameras, offering advantages of low power, high temporal resolution and high dynamic range, have brought a new perspective to addressing the scene reconstruction challenges in high-speed motion and low-light scenes. To this end, we propose E-4DGS, the first event-driven dynamic Gaussian Splatting approach, for novel view synthesis from multi-view event streams with fast-moving cameras. Specifically, we introduce an event-based initialization scheme to ensure stable training and propose event-adaptive slicing splatting for time-aware reconstruction. Additionally, we employ intensity importance pruning to eliminate floating artifacts and enhance 3D consistency, while incorporating an adaptive contrast threshold for more precise optimization. We design a synthetic multi-view camera setup with six moving event cameras surrounding the object in a 360-degree configuration and provide a benchmark multi-view event stream dataset that captures challenging motion scenarios. Our approach outperforms both event-only and event-RGB fusion baselines and paves the way for the exploration of multi-view event-based reconstruction as a novel approach for rapid scene capture.",
    "source": "arXiv"
  },
  {
    "title": "SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection",
    "title_es": "SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection",
    "url": "https://arxiv.org/abs/2508.09913",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09913v1 Announce Type: new \nAbstract: Detection of face forgery videos remains a formidable challenge in the field of digital forensics, especially the generalization to unseen datasets and common perturbations. In this paper, we tackle this issue by leveraging the synergy between audio and visual speech elements, embarking on a novel approach through audio-visual speech representation learning. Our work is motivated by the finding that audio signals, enriched with speech content, can provide precise information effectively reflecting facial movements. To this end, we first learn precise audio-visual speech representations on real videos via a self-supervised masked prediction task, which encodes both local and global semantic information simultaneously. Then, the derived model is directly transferred to the forgery detection task. Extensive experiments demonstrate that our method outperforms the state-of-the-art methods in terms of cross-dataset generalization and robustness, without the participation of any fake video in model training. Code is available at https://github.com/Eleven4AI/SpeechForensics.",
    "source": "arXiv"
  },
  {
    "title": "Prototype-Guided Diffusion: Visual Conditioning without External Memory",
    "title_es": "Prototype-Guided Diffusion: Visual Conditioning without External Memory",
    "url": "https://arxiv.org/abs/2508.09922",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09922v1 Announce Type: new \nAbstract: Diffusion models have emerged as a leading framework for high-quality image generation, offering stable training and strong performance across diverse domains. However, they remain computationally intensive, particularly during the iterative denoising process. Latent-space models like Stable Diffusion alleviate some of this cost by operating in compressed representations, though at the expense of fine-grained detail. More recent approaches such as Retrieval-Augmented Diffusion Models (RDM) address efficiency by conditioning denoising on similar examples retrieved from large external memory banks. While effective, these methods introduce drawbacks: they require costly storage and retrieval infrastructure, depend on static vision-language models like CLIP for similarity, and lack adaptability during training. We propose the Prototype Diffusion Model (PDM), a method that integrates prototype learning directly into the diffusion process for efficient and adaptive visual conditioning - without external memory. Instead of retrieving reference samples, PDM constructs a dynamic set of compact visual prototypes from clean image features using contrastive learning. These prototypes guide the denoising steps by aligning noisy representations with semantically relevant visual patterns, enabling efficient generation with strong semantic grounding. Experiments show that PDM maintains high generation quality while reducing computational and storage overhead, offering a scalable alternative to retrieval-based conditioning in diffusion models.",
    "source": "arXiv"
  },
  {
    "title": "Residual Reservoir Memory Networks",
    "title_es": "Residual Reservoir Memory Networks",
    "url": "https://arxiv.org/abs/2508.09925",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09925v1 Announce Type: new \nAbstract: We introduce a novel class of untrained Recurrent Neural Networks (RNNs) within the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory Networks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear reservoir, where the latter is based on residual orthogonal connections along the temporal dimension for enhanced long-term propagation of the input. The resulting reservoir state dynamics are studied through the lens of linear stability analysis, and we investigate diverse configurations for the temporal residual connections. The proposed approach is empirically assessed on time-series and pixel-level 1-D classification tasks. Our experimental results highlight the advantages of the proposed approach over other conventional RC models.",
    "source": "arXiv"
  },
  {
    "title": "Towards Comprehensive Cellular Characterisation of H&E slides",
    "title_es": "Towards Comprehensive Cellular Characterisation of H&E slides",
    "url": "https://arxiv.org/abs/2508.09926",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09926v1 Announce Type: new \nAbstract: Cell detection, segmentation and classification are essential for analyzing tumor microenvironments (TME) on hematoxylin and eosin (H&E) slides. Existing methods suffer from poor performance on understudied cell types (rare or not present in public datasets) and limited cross-domain generalization. To address these shortcomings, we introduce HistoPLUS, a state-of-the-art model for cell analysis, trained on a novel curated pan-cancer dataset of 108,722 nuclei covering 13 cell types. In external validation across 4 independent cohorts, HistoPLUS outperforms current state-of-the-art models in detection quality by 5.2% and overall F1 classification score by 23.7%, while using 5x fewer parameters. Notably, HistoPLUS unlocks the study of 7 understudied cell types and brings significant improvements on 8 of 13 cell types. Moreover, we show that HistoPLUS robustly transfers to two oncology indications unseen during training. To support broader TME biomarker research, we release the model weights and inference code at https://github.com/owkin/histoplus/.",
    "source": "arXiv"
  },
  {
    "title": "Mathematical Computation and Reasoning Errors by Large Language Models",
    "title_es": "Mathematical Computation and Reasoning Errors by Large Language Models",
    "url": "https://arxiv.org/abs/2508.09932",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09932v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly utilized in AI-driven educational instruction and assessment, particularly within mathematics education. The capability of LLMs to generate accurate answers and detailed solutions for math problem-solving tasks is foundational for ensuring reliable and precise feedback and assessment in math education practices. Our study focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1, DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including arithmetic, algebra, and number theory, and identifies step-level reasoning errors within their solutions. Instead of relying on standard benchmarks, we intentionally build math tasks (via item models) that are challenging for LLMs and prone to errors. The accuracy of final answers and the presence of errors in individual solution steps were systematically analyzed and coded. Both single-agent and dual-agent configurations were tested. It is observed that the reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly perfect accuracy across all three math task categories. Analysis of errors revealed that procedural slips were the most frequent and significantly impacted overall performance, while conceptual misunderstandings were less frequent. Deploying dual-agent configurations substantially improved overall performance. These findings offer actionable insights into enhancing LLM performance and underscore effective strategies for integrating LLMs into mathematics education, thereby advancing AI-driven instructional practices and assessment precision.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Volume Computation for SMT Formulas",
    "title_es": "Efficient Volume Computation for SMT Formulas",
    "url": "https://arxiv.org/abs/2508.09934",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09934v1 Announce Type: new \nAbstract: Satisfiability Modulo Theory (SMT) has recently emerged as a powerful tool for solving various automated reasoning problems across diverse domains. Unlike traditional satisfiability methods confined to Boolean variables, SMT can reason on real-life variables like bitvectors, integers, and reals. A natural extension in this context is to ask quantitative questions. One such query in the SMT theory of Linear Real Arithmetic (LRA) is computing the volume of the entire satisfiable region defined by SMT formulas. This problem is important in solving different quantitative verification queries in software verification, cyber-physical systems, and neural networks, to mention a few.\n  We introduce ttc, an efficient algorithm that extends the capabilities of SMT solvers to volume computation. Our method decomposes the solution space of SMT Linear Real Arithmetic formulas into a union of overlapping convex polytopes, then computes their volumes and calculates their union. Our algorithm builds on recent developments in streaming-mode set unions, volume computation algorithms, and AllSAT techniques. Experimental evaluations demonstrate significant performance improvements over existing state-of-the-art approaches.",
    "source": "arXiv"
  },
  {
    "title": "Language of Persuasion and Misrepresentation in Business Communication: A Textual Detection Approach",
    "title_es": "Language of Persuasion and Misrepresentation in Business Communication: A Textual Detection Approach",
    "url": "https://arxiv.org/abs/2508.09935",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09935v1 Announce Type: new \nAbstract: Business communication digitisation has reorganised the process of persuasive discourse, which\n  allows not only greater transparency but also advanced deception. This inquiry synthesises classical\n  rhetoric and communication psychology with linguistic theory and empirical studies in the financial\n  reporting, sustainability discourse, and digital marketing to explain how deceptive language can be\n  systematically detected using persuasive lexicon. In controlled settings, detection accuracies of greater\n  than 99% were achieved by using computational textual analysis as well as personalised transformer\n  models. However, reproducing this performance in multilingual settings is also problematic and,\n  to a large extent, this is because it is not easy to find sufficient data, and because few multilingual\n  text-processing infrastructures are in place. This evidence shows that there has been an increasing\n  gap between the theoretical representations of communication and those empirically approximated,\n  and therefore, there is a need to have strong automatic text-identification systems where AI-based\n  discourse is becoming more realistic in communicating with humans.",
    "source": "arXiv"
  },
  {
    "title": "Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?",
    "title_es": "Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?",
    "url": "https://arxiv.org/abs/2508.09936",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09936v1 Announce Type: new \nAbstract: The digitization of historical manuscripts presents significant challenges for Handwritten Text Recognition (HTR) systems, particularly when dealing with small, author-specific collections that diverge from the training data distributions. Handwritten Text Generation (HTG) techniques, which generate synthetic data tailored to specific handwriting styles, offer a promising solution to address these challenges. However, the effectiveness of various HTG models in enhancing HTR performance, especially in low-resource transcription settings, has not been thoroughly evaluated. In this work, we systematically compare three state-of-the-art styled HTG models (representing the generative adversarial, diffusion, and autoregressive paradigms for HTG) to assess their impact on HTR fine-tuning. We analyze how visual and linguistic characteristics of synthetic data influence fine-tuning outcomes and provide quantitative guidelines for selecting the most effective HTG model. The results of our analysis provide insights into the current capabilities of HTG methods and highlight key areas for further improvement in their application to low-resource HTR.",
    "source": "arXiv"
  },
  {
    "title": "A Comprehensive Evaluation framework of Alignment Techniques for LLMs",
    "title_es": "A Comprehensive Evaluation framework of Alignment Techniques for LLMs",
    "url": "https://arxiv.org/abs/2508.09937",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09937v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) become increasingly integrated into real-world applications, ensuring their outputs align with human values and safety standards has become critical. The field has developed diverse alignment approaches including traditional fine-tuning methods (RLHF, instruction tuning), post-hoc correction systems, and inference-time interventions, each with distinct advantages and limitations. However, the lack of unified evaluation frameworks makes it difficult to systematically compare these paradigms and guide deployment decisions. This paper introduces a multi-dimensional evaluation of alignment techniques for LLMs, a comprehensive evaluation framework that provides a systematic comparison across all major alignment paradigms. Our framework assesses methods along four key dimensions: alignment detection, alignment quality, computational efficiency, and robustness. Through experiments across diverse base models and alignment strategies, we demonstrate the utility of our framework in identifying strengths and limitations of current state-of-the-art models, providing valuable insights for future research directions.",
    "source": "arXiv"
  },
  {
    "title": "AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models",
    "title_es": "AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models",
    "url": "https://arxiv.org/abs/2508.09943",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09943v1 Announce Type: new \nAbstract: Low-dose CT (LDCT) protocols reduce radiation exposure but increase image noise, compromising diagnostic confidence. Diffusion-based generative models have shown promise for LDCT denoising by learning image priors and performing iterative refinement. In this work, we introduce AST-n, an accelerated inference framework that initiates reverse diffusion from intermediate noise levels, and integrate high-order ODE solvers within conditioned models to further reduce sampling steps. We evaluate two acceleration paradigms--AST-n sampling and standard scheduling with high-order solvers -- on the Low Dose CT Grand Challenge dataset, covering head, abdominal, and chest scans at 10-25 % of standard dose. Conditioned models using only 25 steps (AST-25) achieve peak signal-to-noise ratio (PSNR) above 38 dB and structural similarity index (SSIM) above 0.95, closely matching standard baselines while cutting inference time from ~16 seg to under 1 seg per slice. Unconditional sampling suffers substantial quality loss, underscoring the necessity of conditioning. We also assess DDIM inversion, which yields marginal PSNR gains at the cost of doubling inference time, limiting its clinical practicality. Our results demonstrate that AST-n with high-order samplers enables rapid LDCT reconstruction without significant loss of image fidelity, advancing the feasibility of diffusion-based methods in clinical workflows.",
    "source": "arXiv"
  },
  {
    "title": "VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models",
    "title_es": "VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models",
    "url": "https://arxiv.org/abs/2508.09945",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09945v1 Announce Type: new \nAbstract: Multimodal large language models (MLLMs) have significantly advanced the integration of visual and textual understanding. However, their ability to generate code from multimodal inputs remains limited. In this work, we introduce VisCodex, a unified framework that seamlessly merges vision and coding language models to empower MLLMs with strong multimodal code generation abilities. Leveraging a task vector-based model merging technique, we integrate a state-of-the-art coding LLM into a strong vision-language backbone, while preserving both visual comprehension and advanced coding skills. To support training and evaluation, we introduce the Multimodal Coding Dataset (MCD), a large-scale and diverse collection of 598k samples, including high-quality HTML code, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic problems. Furthermore, we propose InfiBench-V, a novel and challenging benchmark specifically designed to assess models on visually-rich, real-world programming questions that demand a nuanced understanding of both textual and visual contexts. Extensive experiments show that VisCodex achieves state-of-the-art performance among open-source MLLMs and approaches proprietary models like GPT-4o, highlighting the effectiveness of our model merging strategy and new datasets.",
    "source": "arXiv"
  },
  {
    "title": "Stable Diffusion Models are Secretly Good at Visual In-Context Learning",
    "title_es": "Stable Diffusion Models are Secretly Good at Visual In-Context Learning",
    "url": "https://arxiv.org/abs/2508.09949",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09949v1 Announce Type: new \nAbstract: Large language models (LLM) in natural language processing (NLP) have demonstrated great potential for in-context learning (ICL) -- the ability to leverage a few sets of example prompts to adapt to various tasks without having to explicitly update the model weights. ICL has recently been explored for computer vision tasks with promising early outcomes. These approaches involve specialized training and/or additional data that complicate the process and limit its generalizability. In this work, we show that off-the-shelf Stable Diffusion models can be repurposed for visual in-context learning (V-ICL). Specifically, we formulate an in-place attention re-computation within the self-attention layers of the Stable Diffusion architecture that explicitly incorporates context between the query and example prompts. Without any additional fine-tuning, we show that this repurposed Stable Diffusion model is able to adapt to six different tasks: foreground segmentation, single object detection, semantic segmentation, keypoint detection, edge detection, and colorization. For example, the proposed approach improves the mean intersection over union (mIoU) for the foreground segmentation task on Pascal-5i dataset by 8.9% and 3.2% over recent methods such as Visual Prompting and IMProv, respectively. Additionally, we show that the proposed method is able to effectively leverage multiple prompts through ensembling to infer the task better and further improve the performance.",
    "source": "arXiv"
  },
  {
    "title": "PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement Learning for Legged Robots in Crawl Spaces",
    "title_es": "PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement Learning for Legged Robots in Crawl Spaces",
    "url": "https://arxiv.org/abs/2508.09950",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09950v1 Announce Type: new \nAbstract: The legged locomotion in spatially constrained structures (called crawl spaces) is challenging. In crawl spaces, current exteroceptive locomotion learning methods are limited by large noises and errors of the sensors in possible low visibility conditions, and current proprioceptive locomotion learning methods are difficult in traversing crawl spaces because only ground features are inferred. In this study, a point cloud supervised proprioceptive locomotion reinforcement learning method for legged robots in crawl spaces is proposed. A state estimation network is designed to estimate the robot's surrounding ground and spatial features as well as the robot's collision states using historical proprioceptive sensor data. The point cloud is represented in polar coordinate frame and a point cloud processing method is proposed to efficiently extract the ground and spatial features that are used to supervise the state estimation network learning. Comprehensive reward functions that guide the robot to traverse through crawl spaces after collisions are designed. Experiments demonstrate that, compared to existing methods, our method exhibits more agile locomotion in crawl spaces. This study enhances the ability of legged robots to traverse spatially constrained environments without requiring exteroceptive sensors.",
    "source": "arXiv"
  },
  {
    "title": "Specialised or Generic? Tokenization Choices for Radiology Language Models",
    "title_es": "Specialised or Generic? Tokenization Choices for Radiology Language Models",
    "url": "https://arxiv.org/abs/2508.09952",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09952v1 Announce Type: new \nAbstract: The vocabulary used by language models (LM) - defined by the tokenizer - plays a key role in text generation quality. However, its impact remains under-explored in radiology. In this work, we address this gap by systematically comparing general, medical, and domain-specific tokenizers on the task of radiology report summarisation across three imaging modalities. We also investigate scenarios with and without LM pre-training on PubMed abstracts. Our findings demonstrate that medical and domain-specific vocabularies outperformed widely used natural language alternatives when models are trained from scratch. Pre-training partially mitigates performance differences between tokenizers, whilst the domain-specific tokenizers achieve the most favourable results. Domain-specific tokenizers also reduce memory requirements due to smaller vocabularies and shorter sequences. These results demonstrate that adapting the vocabulary of LMs to the clinical domain provides practical benefits, including improved performance and reduced computational demands, making such models more accessible and effective for both research and real-world healthcare settings.",
    "source": "arXiv"
  },
  {
    "title": "Shaping Event Backstories to Estimate Potential Emotion Contexts",
    "title_es": "Shaping Event Backstories to Estimate Potential Emotion Contexts",
    "url": "https://arxiv.org/abs/2508.09954",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09954v1 Announce Type: new \nAbstract: Emotion analysis is an inherently ambiguous task. Previous work studied annotator properties to explain disagreement, but this overlooks the possibility that ambiguity may stem from missing information about the context of events. In this paper, we propose a novel approach that adds reasonable contexts to event descriptions, which may better explain a particular situation. Our goal is to understand whether these enriched contexts enable human annotators to annotate emotions more reliably. We disambiguate a target event description by automatically generating multiple event chains conditioned on differing emotions. By combining techniques from short story generation in various settings, we achieve coherent narratives that result in a specialized dataset for the first comprehensive and systematic examination of contextualized emotion analysis. Through automatic and human evaluation, we find that contextual narratives enhance the interpretation of specific emotions and support annotators in producing more consistent annotations.",
    "source": "arXiv"
  },
  {
    "title": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering",
    "title_es": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering",
    "url": "https://arxiv.org/abs/2508.09956",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09956v1 Announce Type: new \nAbstract: Large language models (LLMs) such as GPT-5 integrate advanced reasoning capabilities that may improve performance on complex medical question-answering tasks. For this latest generation of reasoning models, the configurations that maximize both accuracy and cost-efficiency have yet to be established. We evaluated 12 configurations of OpenAI's GPT-5 series (three model tiers across four reasoning effort settings) alongside o1-high, o3-high, and GPT-4o, using 260 closed-access multiple-choice questions from the American Academy of Ophthalmology Basic Clinical Science Course (BCSC) dataset. The primary outcome was multiple-choice accuracy; secondary outcomes included head-to-head ranking via a Bradley-Terry model, rationale quality assessment using a reference-anchored, pairwise LLM-as-a-judge framework, and analysis of accuracy-cost trade-offs using token-based cost estimates. GPT-5-high achieved the highest accuracy (0.965; 95% CI, 0.942-0.985), outperforming all GPT-5-nano variants (P < .001), o1-high (P = .04), and GPT-4o (P < .001), but not o3-high (0.958; 95% CI, 0.931-0.981). GPT-5-high ranked first in both accuracy (1.66x stronger than o3-high) and rationale quality (1.11x stronger than o3-high). Cost-accuracy analysis identified several GPT-5 configurations on the Pareto frontier, with GPT-5-mini-low offering the most favorable low-cost, high-performance balance. These results benchmark GPT-5 on a high-quality ophthalmology dataset, demonstrate the influence of reasoning effort on accuracy, and introduce an autograder framework for scalable evaluation of LLM-generated answers against reference standards in ophthalmology.",
    "source": "arXiv"
  },
  {
    "title": "Which one Performs Better? Wav2Vec or Whisper? Applying both in Badini Kurdish Speech to Text (BKSTT)",
    "title_es": "Which one Performs Better? Wav2Vec or Whisper? Applying both in Badini Kurdish Speech to Text (BKSTT)",
    "url": "https://arxiv.org/abs/2508.09957",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09957v1 Announce Type: new \nAbstract: Speech-to-text (STT) systems have a wide range of applications. They are available in many languages, albeit at different quality levels. Although Kurdish is considered a less-resourced language from a processing perspective, SST is available for some of the Kurdish dialects, for instance, Sorani (Central Kurdish). However, that is not applied to other Kurdish dialects, Badini and Hawrami, for example. This research is an attempt to address this gap. Bandin, approximately, has two million speakers, and STT systems can help their community use mobile and computer-based technologies while giving their dialect more global visibility. We aim to create a language model based on Badini's speech and evaluate its performance. To cover a conversational aspect, have a proper confidence level of grammatical accuracy, and ready transcriptions, we chose Badini kids' stories, eight books including 78 stories, as the textual input. Six narrators narrated the books, which resulted in approximately 17 hours of recording. We cleaned, segmented, and tokenized the input. The preprocessing produced nearly 15 hours of speech, including 19193 segments and 25221 words. We used Wav2Vec2-Large-XLSR-53 and Whisper-small to develop the language models. The experiments indicate that the transcriptions process based on the Wav2Vec2-Large-XLSR-53 model provides a significantly more accurate and readable output than the Whisper-small model, with 90.38% and 65.45% readability, and 82.67% and 53.17% accuracy, respectively.",
    "source": "arXiv"
  },
  {
    "title": "Neural Bandit Based Optimal LLM Selection for a Pipeline of Tasks",
    "title_es": "Neural Bandit Based Optimal LLM Selection for a Pipeline of Tasks",
    "url": "https://arxiv.org/abs/2508.09958",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09958v1 Announce Type: new \nAbstract: With the increasing popularity of large language models (LLMs) for a variety of tasks, there has been a growing interest in strategies that can predict which out of a set of LLMs will yield a successful answer at low cost. This problem promises to become more and more relevant as providers like Microsoft allow users to easily create custom LLM \"assistants\" specialized to particular types of queries. However, some tasks (i.e., queries) may be too specialized and difficult for a single LLM to handle alone. These applications often benefit from breaking down the task into smaller subtasks, each of which can then be executed by a LLM expected to perform well on that specific subtask. For example, in extracting a diagnosis from medical records, one can first select an LLM to summarize the record, select another to validate the summary, and then select another, possibly different, LLM to extract the diagnosis from the summarized record. Unlike existing LLM selection or routing algorithms, this setting requires that we select a sequence of LLMs, with the output of each LLM feeding into the next and potentially influencing its success. Thus, unlike single LLM selection, the quality of each subtask's output directly affects the inputs, and hence the cost and success rate, of downstream LLMs, creating complex performance dependencies that must be learned and accounted for during selection. We propose a neural contextual bandit-based algorithm that trains neural networks that model LLM success on each subtask in an online manner, thus learning to guide the LLM selections for the different subtasks, even in the absence of historical LLM performance data. Experiments on telecommunications question answering and medical diagnosis prediction datasets illustrate the effectiveness of our proposed approach compared to other LLM selection algorithms.",
    "source": "arXiv"
  },
  {
    "title": "LIA-X: Interpretable Latent Portrait Animator",
    "title_es": "LIA-X: Interpretable Latent Portrait Animator",
    "url": "https://arxiv.org/abs/2508.09959",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09959v1 Announce Type: new \nAbstract: We introduce LIA-X, a novel interpretable portrait animator designed to transfer facial dynamics from a driving video to a source portrait with fine-grained control. LIA-X is an autoencoder that models motion transfer as a linear navigation of motion codes in latent space. Crucially, it incorporates a novel Sparse Motion Dictionary that enables the model to disentangle facial dynamics into interpretable factors. Deviating from previous 'warp-render' approaches, the interpretability of the Sparse Motion Dictionary allows LIA-X to support a highly controllable 'edit-warp-render' strategy, enabling precise manipulation of fine-grained facial semantics in the source portrait. This helps to narrow initial differences with the driving video in terms of pose and expression. Moreover, we demonstrate the scalability of LIA-X by successfully training a large-scale model with approximately 1 billion parameters on extensive datasets. Experimental results show that our proposed method outperforms previous approaches in both self-reenactment and cross-reenactment tasks across several benchmarks. Additionally, the interpretable and controllable nature of LIA-X supports practical applications such as fine-grained, user-guided image and video editing, as well as 3D-aware portrait video manipulation.",
    "source": "arXiv"
  },
  {
    "title": "GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation",
    "title_es": "GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation",
    "url": "https://arxiv.org/abs/2508.09960",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09960v1 Announce Type: new \nAbstract: The creation of human-like humanoid robots is hindered by a fundamental fragmentation: data processing and learning algorithms are rarely universal across different robot morphologies. This paper introduces the Generalized Behavior Cloning (GBC) framework, a comprehensive and unified solution designed to solve this end-to-end challenge. GBC establishes a complete pathway from human motion to robot action through three synergistic innovations. First, an adaptive data pipeline leverages a differentiable IK network to automatically retarget any human MoCap data to any humanoid. Building on this foundation, our novel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust, high-fidelity imitation policies. To complete the ecosystem, the entire framework is delivered as an efficient, open-source platform based on Isaac Lab, empowering the community to deploy the full workflow via simple configuration scripts. We validate the power and generality of GBC by training policies on multiple heterogeneous humanoids, demonstrating excellent performance and transfer to novel motions. This work establishes the first practical and unified pathway for creating truly generalized humanoid controllers.",
    "source": "arXiv"
  },
  {
    "title": "Online Safety under Multiple Constraints and Input Bounds using gatekeeper: Theory and Applications",
    "title_es": "Online Safety under Multiple Constraints and Input Bounds using gatekeeper: Theory and Applications",
    "url": "https://arxiv.org/abs/2508.09963",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09963v1 Announce Type: new \nAbstract: This letter presents an approach to guarantee online safety of a cyber-physical system under multiple state and input constraints. Our proposed framework, called gatekeeper, recursively guarantees the existence of an infinite-horizon trajectory that satisfies all constraints and system dynamics. Such trajectory is constructed using a backup controller, which we define formally in this paper. gatekeeper relies on a small number of verifiable assumptions, and is computationally efficient since it requires optimization over a single scalar variable. We make two primary contributions in this letter. (A) First, we develop the theory of gatekeeper: we derive a sub-optimality bound relative to a full nonlinear trajectory optimization problem, and show how this can be used in runtime to validate performance. This also informs the design of the backup controllers and sets. (B) Second, we demonstrate in detail an application of gatekeeper for multi-agent formation flight, where each Dubins agent must avoid multiple obstacles and weapons engagement zones, both of which are nonlinear, nonconvex constraints.",
    "source": "arXiv"
  },
  {
    "title": "Deep and diverse population synthesis for multi-person households using generative models",
    "title_es": "Deep and diverse population synthesis for multi-person households using generative models",
    "url": "https://arxiv.org/abs/2508.09964",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09964v1 Announce Type: new \nAbstract: Synthetic population is an increasingly important material used in numerous areas such as urban and transportation analysis. Traditional methods such as iterative proportional fitting (IPF) is not capable of generating high-quality data when facing datasets with high dimension. Latest population synthesis methods using deep learning techniques can resolve such curse of dimensionality. However, few controls are placed when using these methods, and few of the methods are used to generate synthetic population capturing associations among members in one household. In this study, we propose a framework that tackles these issues. The framework uses a novel population synthesis model, called conditional input directed acyclic tabular generative adversarial network (ciDATGAN), as its core, and a basket of methods are employed to enhance the population synthesis performance. We apply the model to generate a synthetic population for the whole New York State as a public resource for researchers and policymakers. The synthetic population includes nearly 20 million individuals and 7.5 million households. The marginals obtained from the synthetic population match the census marginals well while maintaining similar associations among household members to the sample. Compared to the PUMS data, the synthetic population provides data that is 17% more diverse; when compared against a benchmark approach based on Popgen, the proposed method is 13% more diverse. This study provides an approach that encompasses multiple methods to enhance the population synthesis procedure with greater equity- and diversity-awareness.",
    "source": "arXiv"
  },
  {
    "title": "January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis",
    "title_es": "January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis",
    "url": "https://arxiv.org/abs/2508.09966",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09966v1 Announce Type: new \nAbstract: Progress in AI for automated nutritional analysis is critically hampered by the lack of standardized evaluation methodologies and high-quality, real-world benchmark datasets. To address this, we introduce three primary contributions. First, we present the January Food Benchmark (JFB), a publicly available collection of 1,000 food images with human-validated annotations. Second, we detail a comprehensive benchmarking framework, including robust metrics and a novel, application-oriented overall score designed to assess model performance holistically. Third, we provide baseline results from both general-purpose Vision-Language Models (VLMs) and our own specialized model, january/food-vision-v1. Our evaluation demonstrates that the specialized model achieves an Overall Score of 86.2, a 12.1-point improvement over the best-performing general-purpose configuration. This work offers the research community a valuable new evaluation dataset and a rigorous framework to guide and benchmark future developments in automated nutritional analysis.",
    "source": "arXiv"
  },
  {
    "title": "MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification",
    "title_es": "MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification",
    "url": "https://arxiv.org/abs/2508.09967",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09967v1 Announce Type: new \nAbstract: Recent advances in histopathology vision-language foundation models (VLFMs) have shown promise in addressing data scarcity for whole slide image (WSI) classification via zero-shot adaptation. However, these methods remain outperformed by conventional multiple instance learning (MIL) approaches trained on large datasets, motivating recent efforts to enhance VLFM-based WSI classification through fewshot learning paradigms. While existing few-shot methods improve diagnostic accuracy with limited annotations, their reliance on conventional classifier designs introduces critical vulnerabilities to data scarcity. To address this problem, we propose a Meta-Optimized Classifier (MOC) comprising two core components: (1) a meta-learner that automatically optimizes a classifier configuration from a mixture of candidate classifiers and (2) a classifier bank housing diverse candidate classifiers to enable a holistic pathological interpretation. Extensive experiments demonstrate that MOC outperforms prior arts in multiple few-shot benchmarks. Notably, on the TCGA-NSCLC benchmark, MOC improves AUC by 10.4% over the state-of-the-art few-shot VLFM-based methods, with gains up to 26.25% under 1-shot conditions, offering a critical advancement for clinical deployments where diagnostic training data is severely limited. Code is available at https://github.com/xmed-lab/MOC.",
    "source": "arXiv"
  },
  {
    "title": "Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models",
    "title_es": "Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models",
    "url": "https://arxiv.org/abs/2508.09968",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09968v1 Announce Type: new \nAbstract: The new paradigm of test-time scaling has yielded remarkable breakthroughs in Large Language Models (LLMs) (e.g. reasoning models) and in generative vision models, allowing models to allocate additional computation during inference to effectively tackle increasingly complex problems. Despite the improvements of this approach, an important limitation emerges: the substantial increase in computation time makes the process slow and impractical for many applications. Given the success of this paradigm and its growing usage, we seek to preserve its benefits while eschewing the inference overhead. In this work we propose one solution to the critical problem of integrating test-time scaling knowledge into a model during post-training. Specifically, we replace reward guided test-time noise optimization in diffusion models with a Noise Hypernetwork that modulates initial input noise. We propose a theoretically grounded framework for learning this reward-tilted distribution for distilled generators, through a tractable noise-space objective that maintains fidelity to the base model while optimizing for desired characteristics. We show that our approach recovers a substantial portion of the quality gains from explicit test-time optimization at a fraction of the computational cost. Code is available at https://github.com/ExplainableML/HyperNoise",
    "source": "arXiv"
  },
  {
    "title": "Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model",
    "title_es": "Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model",
    "url": "https://arxiv.org/abs/2508.09971",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09971v1 Announce Type: new \nAbstract: Vision-driven autonomous river following by Unmanned Aerial Vehicles is critical for applications such as rescue, surveillance, and environmental monitoring, particularly in dense riverine environments where GPS signals are unreliable. We formalize river following as a coverage control problem in which the reward function is submodular, yielding diminishing returns as more unique river segments are visited, thereby framing the task as a Submodular Markov Decision Process. First, we introduce Marginal Gain Advantage Estimation, which refines the reward advantage function by using a sliding window baseline computed from historical episodic returns, thus aligning the advantage estimation with the agent's evolving recognition of action value in non-Markovian settings. Second, we develop a Semantic Dynamics Model based on patchified water semantic masks that provides more interpretable and data-efficient short-term prediction of future observations compared to latent vision dynamics models. Third, we present the Constrained Actor Dynamics Estimator architecture, which integrates the actor, the cost estimator, and SDM for cost advantage estimation to form a model-based SafeRL framework capable of solving partially observable Constrained Submodular Markov Decision Processes. Simulation results demonstrate that MGAE achieves faster convergence and superior performance over traditional critic-based methods like Generalized Advantage Estimation. SDM provides more accurate short-term state predictions that enable the cost estimator to better predict potential violations. Overall, CADE effectively integrates safety regulation into model-based RL, with the Lagrangian approach achieving the soft balance of reward and safety during training, while the safety layer enhances performance during inference by hard action overlay.",
    "source": "arXiv"
  },
  {
    "title": "PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image",
    "title_es": "PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image",
    "url": "https://arxiv.org/abs/2508.09973",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09973v1 Announce Type: new \nAbstract: Two major approaches exist for creating animatable human avatars. The first, a 3D-based approach, optimizes a NeRF- or 3DGS-based avatar from videos of a single person, achieving personalization through a disentangled identity representation. However, modeling pose-driven deformations, such as non-rigid cloth deformations, requires numerous pose-rich videos, which are costly and impractical to capture in daily life. The second, a diffusion-based approach, learns pose-driven deformations from large-scale in-the-wild videos but struggles with identity preservation and pose-dependent identity entanglement. We present PERSONA, a framework that combines the strengths of both approaches to obtain a personalized 3D human avatar with pose-driven deformations from a single image. PERSONA leverages a diffusion-based approach to generate pose-rich videos from the input image and optimizes a 3D avatar based on them. To ensure high authenticity and sharp renderings across diverse poses, we introduce balanced sampling and geometry-weighted optimization. Balanced sampling oversamples the input image to mitigate identity shifts in diffusion-generated training videos. Geometry-weighted optimization prioritizes geometry constraints over image loss, preserving rendering quality in diverse poses.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Mixture-of-Experts for Incremental Graph Learning",
    "title_es": "Dynamic Mixture-of-Experts for Incremental Graph Learning",
    "url": "https://arxiv.org/abs/2508.09974",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09974v1 Announce Type: new \nAbstract: Graph incremental learning is a learning paradigm that aims to adapt trained models to continuously incremented graphs and data over time without the need for retraining on the full dataset. However, regular graph machine learning methods suffer from catastrophic forgetting when applied to incremental learning settings, where previously learned knowledge is overridden by new knowledge. Previous approaches have tried to address this by treating the previously trained model as an inseparable unit and using techniques to maintain old behaviors while learning new knowledge. These approaches, however, do not account for the fact that previously acquired knowledge at different timestamps contributes differently to learning new tasks. Some prior patterns can be transferred to help learn new data, while others may deviate from the new data distribution and be detrimental. To address this, we propose a dynamic mixture-of-experts (DyMoE) approach for incremental learning. Specifically, a DyMoE GNN layer adds new expert networks specialized in modeling the incoming data blocks. We design a customized regularization loss that utilizes data sequence information so existing experts can maintain their ability to solve old tasks while helping the new expert learn the new data effectively. As the number of data blocks grows over time, the computational cost of the full mixture-of-experts (MoE) model increases. To address this, we introduce a sparse MoE approach, where only the top-$k$ most relevant experts make predictions, significantly reducing the computation time. Our model achieved 4.92\\% relative accuracy increase compared to the best baselines on class incremental learning, showing the model's exceptional power.",
    "source": "arXiv"
  },
  {
    "title": "Masquerade: Learning from In-the-wild Human Videos using Data-Editing",
    "title_es": "Masquerade: Learning from In-the-wild Human Videos using Data-Editing",
    "url": "https://arxiv.org/abs/2508.09976",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09976v1 Announce Type: new \nAbstract: Robot manipulation research still suffers from significant data scarcity: even the largest robot datasets are orders of magnitude smaller and less diverse than those that fueled recent breakthroughs in language and vision. We introduce Masquerade, a method that edits in-the-wild egocentric human videos to bridge the visual embodiment gap between humans and robots and then learns a robot policy with these edited videos. Our pipeline turns each human video into robotized demonstrations by (i) estimating 3-D hand poses, (ii) inpainting the human arms, and (iii) overlaying a rendered bimanual robot that tracks the recovered end-effector trajectories. Pre-training a visual encoder to predict future 2-D robot keypoints on 675K frames of these edited clips, and continuing that auxiliary loss while fine-tuning a diffusion policy head on only 50 robot demonstrations per task, yields policies that generalize significantly better than prior work. On three long-horizon, bimanual kitchen tasks evaluated in three unseen scenes each, Masquerade outperforms baselines by 5-6x. Ablations show that both the robot overlay and co-training are indispensable, and performance scales logarithmically with the amount of edited human video. These results demonstrate that explicitly closing the visual embodiment gap unlocks a vast, readily available source of data from human videos that can be used to improve robot policies.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation",
    "title_es": "A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation",
    "url": "https://arxiv.org/abs/2508.09977",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09977v1 Announce Type: new \nAbstract: 3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative to Neural Radiance Fields (NeRF) for 3D scene representation, offering high-fidelity photorealistic rendering with real-time performance. Beyond novel view synthesis, the explicit and compact nature of 3DGS enables a wide range of downstream applications that require geometric and semantic understanding. This survey provides a comprehensive overview of recent progress in 3DGS applications. It first introduces 2D foundation models that support semantic understanding and control in 3DGS applications, followed by a review of NeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS applications into segmentation, editing, generation, and other functional tasks. For each, we summarize representative methods, supervision strategies, and learning paradigms, highlighting shared design principles and emerging trends. Commonly used datasets and evaluation protocols are also summarized, along with comparative analyses of recent methods across public benchmarks. To support ongoing research and development, a continually updated repository of papers, code, and resources is maintained at https://github.com/heshuting555/Awesome-3DGS-Applications.",
    "source": "arXiv"
  },
  {
    "title": "On the Consistency and Performance of the Iterative Bayesian Update",
    "title_es": "On the Consistency and Performance of the Iterative Bayesian Update",
    "url": "https://arxiv.org/abs/2508.09980",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09980v1 Announce Type: new \nAbstract: For many social, scientific, and commercial purposes, it is often important to estimate the distribution of the users' data regarding a sensitive attribute, e.g., their ages, locations, etc. To allow this estimation while protecting the users' privacy, every user applies a local privacy protection mechanism that releases a noisy (sanitized) version of their original datum to the data collector; then the original distribution is estimated using one of the known methods, such as the matrix inversion (INV), RAPPOR's estimator, and the iterative Bayesian update (IBU). Unlike the other estimators, the consistency of IBU, i.e., the convergence of its estimate to the real distribution as the amount of noisy data grows, has been either ignored or incorrectly proved in the literature. In this article, we use the fact that IBU is a maximum likelihood estimator to prove that IBU is consistent. We also show, through experiments on real datasets, that IBU significantly outperforms the other methods when the users' data are sanitized by geometric, Laplace, and exponential mechanisms, whereas it is comparable to the other methods in the case of the k-RR and RAPPOR mechanisms. Finally, we consider the case when the alphabet of the sensitive data is infinite, and we show a technique that allows IBU to operate in this case too.",
    "source": "arXiv"
  },
  {
    "title": "LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit",
    "title_es": "LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit",
    "url": "https://arxiv.org/abs/2508.09981",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09981v1 Announce Type: new \nAbstract: Large Vision-Language Models (VLMs) exhibit impressive multi-modal capabilities but suffer from prohibitive computational and memory demands, due to their long visual token sequences and massive parameter sizes. To address these issues, recent works have proposed training-free compression methods. However, existing efforts often suffer from three major limitations: (1) Current approaches do not decompose techniques into comparable modules, hindering fair evaluation across spatial and temporal redundancy. (2) Evaluation confined to simple single-turn tasks, failing to reflect performance in realistic scenarios. (3) Isolated use of individual compression techniques, without exploring their joint potential. To overcome these gaps, we introduce LLMC+, a comprehensive VLM compression benchmark with a versatile, plug-and-play toolkit. LLMC+ supports over 20 algorithms across five representative VLM families and enables systematic study of token-level and model-level compression. Our benchmark reveals that: (1) Spatial and temporal redundancies demand distinct technical strategies. (2) Token reduction methods degrade significantly in multi-turn dialogue and detail-sensitive tasks. (3) Combining token and model compression achieves extreme compression with minimal performance loss. We believe LLMC+ will facilitate fair evaluation and inspire future research in efficient VLM. Our code is available at https://github.com/ModelTC/LightCompress.",
    "source": "arXiv"
  },
  {
    "title": "Story2Board: A Training-Free Approach for Expressive Storyboard Generation",
    "title_es": "Story2Board: A Training-Free Approach for Expressive Storyboard Generation",
    "url": "https://arxiv.org/abs/2508.09983",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09983v1 Announce Type: new \nAbstract: We present Story2Board, a training-free framework for expressive storyboard generation from natural language. Existing methods narrowly focus on subject identity, overlooking key aspects of visual storytelling such as spatial composition, background evolution, and narrative pacing. To address this, we introduce a lightweight consistency framework composed of two components: Latent Panel Anchoring, which preserves a shared character reference across panels, and Reciprocal Attention Value Mixing, which softly blends visual features between token pairs with strong reciprocal attention. Together, these mechanisms enhance coherence without architectural changes or fine-tuning, enabling state-of-the-art diffusion models to generate visually diverse yet consistent storyboards. To structure generation, we use an off-the-shelf language model to convert free-form stories into grounded panel-level prompts. To evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain narratives designed to assess layout diversity and background-grounded storytelling, in addition to consistency. We also introduce a new Scene Diversity metric that quantifies spatial and pose variation across storyboards. Our qualitative and quantitative results, as well as a user study, show that Story2Board produces more dynamic, coherent, and narratively engaging storyboards than existing baselines.",
    "source": "arXiv"
  },
  {
    "title": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation",
    "title_es": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation",
    "url": "https://arxiv.org/abs/2508.09987",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09987v1 Announce Type: new \nAbstract: Recently, GPT-4o has garnered significant attention for its strong performance in image generation, yet open-source models still lag behind. Several studies have explored distilling image data from GPT-4o to enhance open-source models, achieving notable progress. However, a key question remains: given that real-world image datasets already constitute a natural source of high-quality data, why should we use GPT-4o-generated synthetic data? In this work, we identify two key advantages of synthetic images. First, they can complement rare scenarios in real-world datasets, such as surreal fantasy or multi-reference image generation, which frequently occur in user queries. Second, they provide clean and controllable supervision. Real-world data often contains complex background noise and inherent misalignment between text descriptions and image content, whereas synthetic images offer pure backgrounds and long-tailed supervision signals, facilitating more accurate text-to-image alignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale synthetic dataset generated by GPT-4o, harnessing the power of synthetic image data to address blind spots in real-world coverage. Using this dataset, we fine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o. In addition, we propose two new evaluation benchmarks for a more accurate and challenging assessment of image generation capabilities: GenEval++, which increases instruction complexity to mitigate score saturation, and Imagine-Bench, which focuses on evaluating both the understanding and generation of imaginative content. Echo-4o demonstrates strong performance across standard benchmarks. Moreover, applying Echo-4o-Image to other foundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains across multiple metrics, highlighting the datasets strong transferability.",
    "source": "arXiv"
  },
  {
    "title": "QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds",
    "title_es": "QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds",
    "url": "https://arxiv.org/abs/2504.19716",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.19716v2 Announce Type: cross \nAbstract: Grasping has been a long-standing challenge in facilitating the final interface between a robot and the environment. As environments and tasks become complicated, the need to embed higher intelligence to infer from the surroundings and act on them has become necessary. Although most methods utilize techniques to estimate grasp pose by treating the problem via pure sampling-based approaches in the six-degree-of-freedom space or as a learning problem, they usually fail in real-life settings owing to poor generalization across domains. In addition, the time taken to generate the grasp plan and the lack of repeatability, owing to sampling inefficiency and the probabilistic nature of existing grasp planning approaches, severely limits their application in real-world tasks. This paper presents a lightweight analytical approach towards robotic grasp planning, particularly antipodal grasps, with little to no sampling in the six-degree-of-freedom space. The proposed grasp planning algorithm is formulated as an optimization problem towards estimating grasp points on the object surface instead of directly estimating the end-effector pose. To this extent, a soft-region-growing algorithm is presented for effective plane segmentation, even in the case of curved surfaces. An optimization-based quality metric is then used for the evaluation of grasp points to ensure indirect force closure. The proposed grasp framework is compared with the existing state-of-the-art grasp planning approach, Grasp pose detection (GPD), as a baseline over multiple simulated objects. The effectiveness of the proposed approach in comparison to GPD is also evaluated in a real-world setting using image and point-cloud data, with the planned grasps being executed using a ROBOTIQ gripper and UR5 manipulator.",
    "source": "arXiv"
  },
  {
    "title": "User-Intent-Driven Semantic Communication via Adaptive Deep Understanding",
    "title_es": "User-Intent-Driven Semantic Communication via Adaptive Deep Understanding",
    "url": "https://arxiv.org/abs/2508.05884",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.05884v1 Announce Type: cross \nAbstract: Semantic communication focuses on transmitting task-relevant semantic information, aiming for intent-oriented communication. While existing systems improve efficiency by extracting key semantics, they still fail to deeply understand and generalize users' real intentions. To overcome this, we propose a user-intention-driven semantic communication system that interprets diverse abstract intents. First, we integrate a multi-modal large model as semantic knowledge base to generate user-intention prior. Next, a mask-guided attention module is proposed to effectively highlight critical semantic regions. Further, a channel state awareness module ensures adaptive, robust transmission across varying channel conditions. Extensive experiments demonstrate that our system achieves deep intent understanding and outperforms DeepJSCC, e.g., under a Rayleigh channel at an SNR of 5 dB, it achieves improvements of 8%, 6%, and 19% in PSNR, SSIM, and LPIPS, respectively.",
    "source": "arXiv"
  },
  {
    "title": "The 2R-Conjecture for the Hegselmann--Krause Model: A Proof in Expectation and New Directions",
    "title_es": "The 2R-Conjecture for the Hegselmann--Krause Model: A Proof in Expectation and New Directions",
    "url": "https://arxiv.org/abs/2508.08299",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08299v1 Announce Type: cross \nAbstract: Hegselmann--Krause models are localized, distributed averaging dynamics on spatial data. A key aspect of these dynamics is that they lead to cluster formation, which has important applications in geographic information systems, dynamic clustering algorithms, opinion dynamics, and social networks. For these models, the key questions are whether a fixed point exists and, if so, characterizing it. In this work, we establish new results towards the \"2R-Conjecture\" for the Hegselmann--Krause model, for which no meaningful progress, or even any precise statement, has been made since its introduction in 2007. This conjecture relates to the structure of the fixed point when there are a large number of agents per unit space. We provide, among other results, a proof in expectation and a statement of a stronger result that is supported by simulation. The key methodological contribution is to consider the dynamics as an infinite-dimensional problem on the space of point processes, rather than on finitely many points. This enables us to leverage stationarity, shift invariance, and certain other symmetries to obtain the results. These techniques do not have finite-dimensional analogs.",
    "source": "arXiv"
  },
  {
    "title": "RadioMamba: Breaking the Accuracy-Efficiency Trade-off in Radio Map Construction via a Hybrid Mamba-UNet",
    "title_es": "RadioMamba: Breaking the Accuracy-Efficiency Trade-off in Radio Map Construction via a Hybrid Mamba-UNet",
    "url": "https://arxiv.org/abs/2508.09140",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09140v1 Announce Type: cross \nAbstract: Radio map (RM) has recently attracted much attention since it can provide real-time and accurate spatial channel information for 6G services and applications. However, current deep learning-based methods for RM construction exhibit well known accuracy-efficiency trade-off. In this paper, we introduce RadioMamba, a hybrid Mamba-UNet architecture for RM construction to address the trade-off. Generally, accurate RM construction requires modeling long-range spatial dependencies, reflecting the global nature of wave propagation physics. RadioMamba utilizes a Mamba-Convolutional block where the Mamba branch captures these global dependencies with linear complexity, while a parallel convolutional branch extracts local features. This hybrid design generates feature representations that capture both global context and local detail. Experiments show that RadioMamba achieves higher accuracy than existing methods, including diffusion models, while operating nearly 20 times faster and using only 2.9\\% of the model parameters. By improving both accuracy and efficiency, RadioMamba presents a viable approach for real-time intelligent optimization in next generation wireless systems.",
    "source": "arXiv"
  },
  {
    "title": "Bayesian-Driven Graph Reasoning for Active Radio Map Construction",
    "title_es": "Bayesian-Driven Graph Reasoning for Active Radio Map Construction",
    "url": "https://arxiv.org/abs/2508.09142",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09142v1 Announce Type: cross \nAbstract: With the emergence of the low-altitude economy, radio maps have become essential for ensuring reliable wireless connectivity to aerial platforms. Autonomous aerial agents are commonly deployed for data collection using waypoint-based navigation; however, their limited battery capacity significantly constrains coverage and efficiency. To address this, we propose an uncertainty-aware radio map (URAM) reconstruction framework that explicitly leverages graph-based reasoning tailored for waypoint navigation. Our approach integrates two key deep learning components: (1) a Bayesian neural network that estimates spatial uncertainty in real time, and (2) an attention-based reinforcement learning policy that performs global reasoning over a probabilistic roadmap, using uncertainty estimates to plan informative and energy-efficient trajectories. This graph-based reasoning enables intelligent, non-myopic trajectory planning, guiding agents toward the most informative regions while satisfying safety constraints. Experimental results show that URAM improves reconstruction accuracy by up to 34% over existing baselines.",
    "source": "arXiv"
  },
  {
    "title": "Generative Artificial Intelligence in Medical Imaging: Foundations, Progress, and Clinical Translation",
    "title_es": "Generative Artificial Intelligence in Medical Imaging: Foundations, Progress, and Clinical Translation",
    "url": "https://arxiv.org/abs/2508.09177",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09177v1 Announce Type: cross \nAbstract: Generative artificial intelligence (AI) is rapidly transforming medical imaging by enabling capabilities such as data synthesis, image enhancement, modality translation, and spatiotemporal modeling. This review presents a comprehensive and forward-looking synthesis of recent advances in generative modeling including generative adversarial networks (GANs), variational autoencoders (VAEs), diffusion models, and emerging multimodal foundation architectures and evaluates their expanding roles across the clinical imaging continuum. We systematically examine how generative AI contributes to key stages of the imaging workflow, from acquisition and reconstruction to cross-modality synthesis, diagnostic support, and treatment planning. Emphasis is placed on both retrospective and prospective clinical scenarios, where generative models help address longstanding challenges such as data scarcity, standardization, and integration across modalities. To promote rigorous benchmarking and translational readiness, we propose a three-tiered evaluation framework encompassing pixel-level fidelity, feature-level realism, and task-level clinical relevance. We also identify critical obstacles to real-world deployment, including generalization under domain shift, hallucination risk, data privacy concerns, and regulatory hurdles. Finally, we explore the convergence of generative AI with large-scale foundation models, highlighting how this synergy may enable the next generation of scalable, reliable, and clinically integrated imaging systems. By charting technical progress and translational pathways, this review aims to guide future research and foster interdisciplinary collaboration at the intersection of AI, medicine, and biomedical engineering.",
    "source": "arXiv"
  },
  {
    "title": "HiFi-Mamba: Dual-Stream W-Laplacian Enhanced Mamba for High-Fidelity MRI Reconstruction",
    "title_es": "HiFi-Mamba: Dual-Stream W-Laplacian Enhanced Mamba for High-Fidelity MRI Reconstruction",
    "url": "https://arxiv.org/abs/2508.09179",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09179v1 Announce Type: cross \nAbstract: Reconstructing high-fidelity MR images from undersampled k-space data remains a challenging problem in MRI. While Mamba variants for vision tasks offer promising long-range modeling capabilities with linear-time complexity, their direct application to MRI reconstruction inherits two key limitations: (1) insensitivity to high-frequency anatomical details; and (2) reliance on redundant multi-directional scanning. To address these limitations, we introduce High-Fidelity Mamba (HiFi-Mamba), a novel dual-stream Mamba-based architecture comprising stacked W-Laplacian (WL) and HiFi-Mamba blocks. Specifically, the WL block performs fidelity-preserving spectral decoupling, producing complementary low- and high-frequency streams. This separation enables the HiFi-Mamba block to focus on low-frequency structures, enhancing global feature modeling. Concurrently, the HiFi-Mamba block selectively integrates high-frequency features through adaptive state-space modulation, preserving comprehensive spectral details. To eliminate the scanning redundancy, the HiFi-Mamba block adopts a streamlined unidirectional traversal strategy that preserves long-range modeling capability with improved computational efficiency. Extensive experiments on standard MRI reconstruction benchmarks demonstrate that HiFi-Mamba consistently outperforms state-of-the-art CNN-based, Transformer-based, and other Mamba-based models in reconstruction accuracy while maintaining a compact and efficient model design.",
    "source": "arXiv"
  },
  {
    "title": "MedPatch: Confidence-Guided Multi-Stage Fusion for Multimodal Clinical Data",
    "title_es": "MedPatch: Confidence-Guided Multi-Stage Fusion for Multimodal Clinical Data",
    "url": "https://arxiv.org/abs/2508.09182",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09182v1 Announce Type: cross \nAbstract: Clinical decision-making relies on the integration of information across various data modalities, such as clinical time-series, medical images and textual reports. Compared to other domains, real-world medical data is heterogeneous in nature, limited in size, and sparse due to missing modalities. This significantly limits model performance in clinical prediction tasks. Inspired by clinical workflows, we introduce MedPatch, a multi-stage multimodal fusion architecture, which seamlessly integrates multiple modalities via confidence-guided patching. MedPatch comprises three main components: (i) a multi-stage fusion strategy that leverages joint and late fusion simultaneously, (ii) a missingness-aware module that handles sparse samples with missing modalities, (iii) a joint fusion module that clusters latent token patches based on calibrated unimodal token-level confidence. We evaluated MedPatch using real-world data consisting of clinical time-series data, chest X-ray images, radiology reports, and discharge notes extracted from the MIMIC-IV, MIMIC-CXR, and MIMIC-Notes datasets on two benchmark tasks, namely in-hospital mortality prediction and clinical condition classification. Compared to existing baselines, MedPatch achieves state-of-the-art performance. Our work highlights the effectiveness of confidence-guided multi-stage fusion in addressing the heterogeneity of multimodal data, and establishes new state-of-the-art benchmark results for clinical prediction tasks.",
    "source": "arXiv"
  },
  {
    "title": "Quantum-Efficient Reinforcement Learning Solutions for Last-Mile On-Demand Delivery",
    "title_es": "Quantum-Efficient Reinforcement Learning Solutions for Last-Mile On-Demand Delivery",
    "url": "https://arxiv.org/abs/2508.09183",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09183v1 Announce Type: cross \nAbstract: Quantum computation has demonstrated a promising alternative to solving the NP-hard combinatorial problems. Specifically, when it comes to optimization, classical approaches become intractable to account for large-scale solutions. Specifically, we investigate quantum computing to solve the large-scale Capacitated Pickup and Delivery Problem with Time Windows (CPDPTW). In this regard, a Reinforcement Learning (RL) framework augmented with a Parametrized Quantum Circuit (PQC) is designed to minimize the travel time in a realistic last-mile on-demand delivery. A novel problem-specific encoding quantum circuit with an entangling and variational layer is proposed. Moreover, Proximal Policy Optimization (PPO) and Quantum Singular Value Transformation (QSVT) are designed for comparison through numerical experiments, highlighting the superiority of the proposed method in terms of the scale of the solution and training complexity while incorporating the real-world constraints.",
    "source": "arXiv"
  },
  {
    "title": "Hybrid(Transformer+CNN)-based Polyp Segmentation",
    "title_es": "Hybrid(Transformer+CNN)-based Polyp Segmentation",
    "url": "https://arxiv.org/abs/2508.09189",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09189v1 Announce Type: cross \nAbstract: Colonoscopy is still the main method of detection and segmentation of colonic polyps, and recent advancements in deep learning networks such as U-Net, ResUNet, Swin-UNet, and PraNet have made outstanding performance in polyp segmentation. Yet, the problem is extremely challenging due to high variation in size, shape, endoscopy types, lighting, imaging protocols, and ill-defined boundaries (fluid, folds) of the polyps, rendering accurate segmentation a challenging and problematic task. To address these critical challenges in polyp segmentation, we introduce a hybrid (Transformer + CNN) model that is crafted to enhance robustness against evolving polyp characteristics. Our hybrid architecture demonstrates superior performance over existing solutions, particularly in addressing two critical challenges: (1) accurate segmentation of polyps with ill-defined margins through boundary-aware attention mechanisms, and (2) robust feature extraction in the presence of common endoscopic artifacts, including specular highlights, motion blur, and fluid occlusions. Quantitative evaluations reveal significant improvements in segmentation accuracy (Recall improved by 1.76%, i.e., 0.9555, accuracy improved by 0.07%, i.e., 0.9849) and artifact resilience compared to state-of-the-art polyp segmentation methods.",
    "source": "arXiv"
  },
  {
    "title": "impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities Imputation in Cancer Survival Prediction",
    "title_es": "impuTMAE: Multi-modal Transformer with Masked Pre-training for Missing Modalities Imputation in Cancer Survival Prediction",
    "url": "https://arxiv.org/abs/2508.09195",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09195v1 Announce Type: cross \nAbstract: The use of diverse modalities, such as omics, medical images, and clinical data can not only improve the performance of prognostic models but also deepen an understanding of disease mechanisms and facilitate the development of novel treatment approaches. However, medical data are complex, often incomplete, and contains missing modalities, making effective handling its crucial for training multimodal models. We introduce impuTMAE, a novel transformer-based end-to-end approach with an efficient multimodal pre-training strategy. It learns inter- and intra-modal interactions while simultaneously imputing missing modalities by reconstructing masked patches. Our model is pre-trained on heterogeneous, incomplete data and fine-tuned for glioma survival prediction using TCGA-GBM/LGG and BraTS datasets, integrating five modalities: genetic (DNAm, RNA-seq), imaging (MRI, WSI), and clinical data. By addressing missing data during pre-training and enabling efficient resource utilization, impuTMAE surpasses prior multimodal approaches, achieving state-of-the-art performance in glioma patient survival prediction. Our code is available at https://github.com/maryjis/mtcp",
    "source": "arXiv"
  },
  {
    "title": "FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation",
    "title_es": "FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation",
    "url": "https://arxiv.org/abs/2508.09196",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09196v1 Announce Type: cross \nAbstract: Different CT segmentation datasets are typically obtained from different scanners under different capture settings and often provide segmentation labels for a limited and often disjoint set of organs. Using these heterogeneous data effectively while preserving patient privacy can be challenging. This work presents a novel federated learning approach to achieve universal segmentation across diverse abdominal CT datasets by utilizing model uncertainty for aggregation and predictive uncertainty for inference. Our approach leverages the inherent noise in stochastic mini-batch gradient descent to estimate a distribution over the model weights to provide an on-the-go uncertainty over the model parameters at the client level. The parameters are then aggregated at the server using the additional uncertainty information using a Bayesian-inspired inverse-variance aggregation scheme. Furthermore, the proposed method quantifies prediction uncertainty by propagating the uncertainty from the model weights, providing confidence measures essential for clinical decision-making. In line with recent work shown, predictive uncertainty is utilized in the inference stage to improve predictive performance. Experimental evaluations demonstrate the effectiveness of this approach in improving both the quality of federated aggregation and uncertainty-weighted inference compared to previously established baselines. The code for this work is made available at: https://github.com/asimukaye/fiva",
    "source": "arXiv"
  },
  {
    "title": "Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction",
    "title_es": "Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction",
    "url": "https://arxiv.org/abs/2508.09200",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09200v1 Announce Type: cross \nAbstract: Purpose: To investigate the feasibility of applying zero-shot self-supervised learning reconstruction to reduce breath-hold times in magnetic resonance cholangiopancreatography (MRCP). Methods: Breath-hold MRCP was acquired from 11 healthy volunteers on a 3T scanner using an incoherent k-space sampling pattern leading to a breath-hold duration of 14s. We evaluated zero-shot reconstruction of breath-hold MRCP against parallel imaging of respiratory-triggered MRCP acquired in 338s on average and compressed sensing reconstruction of breath-hold MRCP. To address the long computation times of zero-shot trainings, we used a training approach that leverages a pretrained network to reduce backpropagation depth during training. Results: Zero-shot learning reconstruction significantly improved visual image quality compared to compressed sensing reconstruction, particularly in terms of signal-to-noise ratio and ductal delineation, and reached a level of quality comparable to that of successful respiratory-triggered acquisitions with regular breathing patterns. Shallow training provided nearly equivalent reconstruction performance with a training time of 11 minutes in comparison to 271 minutes for a conventional zero-shot training. Conclusion: Zero-shot learning delivers high-fidelity MRCP reconstructions with reduced breath-hold times, and shallow training offers a practical solution for translation to time-constrained clinical workflows.",
    "source": "arXiv"
  },
  {
    "title": "From Explainable to Explained AI: Ideas for Falsifying and Quantifying Explanations",
    "title_es": "From Explainable to Explained AI: Ideas for Falsifying and Quantifying Explanations",
    "url": "https://arxiv.org/abs/2508.09205",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09205v1 Announce Type: cross \nAbstract: Explaining deep learning models is essential for clinical integration of medical image analysis systems. A good explanation highlights if a model depends on spurious features that undermines generalization and harms a subset of patients or, conversely, may present novel biological insights. Although techniques like GradCAM can identify influential features, they are measurement tools that do not themselves form an explanation. We propose a human-machine-VLM interaction system tailored to explaining classifiers in computational pathology, including multi-instance learning for whole-slide images. Our proof of concept comprises (1) an AI-integrated slide viewer to run sliding-window experiments to test claims of an explanation, and (2) quantification of an explanation's predictiveness using general-purpose vision-language models. The results demonstrate that this allows us to qualitatively test claims of explanations and can quantifiably distinguish competing explanations. This offers a practical path from explainable AI to explained AI in digital pathology and beyond. Code and prompts are available at https://github.com/nki-ai/x2x.",
    "source": "arXiv"
  },
  {
    "title": "Quantum-Enhanced Generative Adversarial Networks: Comparative Analysis of Classical and Hybrid Quantum-Classical Generative Adversarial Networks",
    "title_es": "Quantum-Enhanced Generative Adversarial Networks: Comparative Analysis of Classical and Hybrid Quantum-Classical Generative Adversarial Networks",
    "url": "https://arxiv.org/abs/2508.09209",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09209v1 Announce Type: cross \nAbstract: Generative adversarial networks (GANs) have emerged as a powerful paradigm for producing high-fidelity data samples, yet their performance is constrained by the quality of latent representations, typically sampled from classical noise distributions. This study investigates hybrid quantum-classical GANs (HQCGANs) in which a quantum generator, implemented via parameterised quantum circuits, produces latent vectors for a classical discriminator. We evaluate a classical GAN alongside three HQCGAN variants with 3, 5, and 7 qubits, using Qiskit's AerSimulator with realistic noise models to emulate near-term quantum devices. The binary MNIST dataset (digits 0 and 1) is used to align with the low-dimensional latent spaces imposed by current quantum hardware. Models are trained for 150 epochs and assessed with Frechet Inception Distance (FID) and Kernel Inception Distance (KID). Results show that while the classical GAN achieved the best scores, the 7-qubit HQCGAN produced competitive performance, narrowing the gap in later epochs, whereas the 3-qubit model exhibited earlier convergence limitations. Efficiency analysis indicates only moderate training time increases despite quantum sampling overhead. These findings validate the feasibility of noisy quantum circuits as latent priors in GAN architectures, highlighting their potential to enhance generative modelling within the constraints of the noisy intermediate-scale quantum (NISQ) era.",
    "source": "arXiv"
  },
  {
    "title": "Deep Generative Models for Discrete Genotype Simulation",
    "title_es": "Deep Generative Models for Discrete Genotype Simulation",
    "url": "https://arxiv.org/abs/2508.09212",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09212v1 Announce Type: cross \nAbstract: Deep generative models open new avenues for simulating realistic genomic data while preserving privacy and addressing data accessibility constraints. While previous studies have primarily focused on generating gene expression or haplotype data, this study explores generating genotype data in both unconditioned and phenotype-conditioned settings, which is inherently more challenging due to the discrete nature of genotype data. In this work, we developed and evaluated commonly used generative models, including Variational Autoencoders (VAEs), Diffusion Models, and Generative Adversarial Networks (GANs), and proposed adaptation tailored to discrete genotype data. We conducted extensive experiments on large-scale datasets, including all chromosomes from cow and multiple chromosomes from human. Model performance was assessed using a well-established set of metrics drawn from both deep learning and quantitative genetics literature. Our results show that these models can effectively capture genetic patterns and preserve genotype-phenotype association. Our findings provide a comprehensive comparison of these models and offer practical guidelines for future research in genotype simulation. We have made our code publicly available at https://github.com/SihanXXX/DiscreteGenoGen.",
    "source": "arXiv"
  },
  {
    "title": "Real-time deep learning phase imaging flow cytometer reveals blood cell aggregate biomarkers for haematology diagnostics",
    "title_es": "Real-time deep learning phase imaging flow cytometer reveals blood cell aggregate biomarkers for haematology diagnostics",
    "url": "https://arxiv.org/abs/2508.09215",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09215v1 Announce Type: cross \nAbstract: While analysing rare blood cell aggregates remains challenging in automated haematology, they could markedly advance label-free functional diagnostics. Conventional flow cytometers efficiently perform cell counting with leukocyte differentials but fail to identify aggregates with flagged results, requiring manual reviews. Quantitative phase imaging flow cytometry captures detailed aggregate morphologies, but clinical use is hampered by massive data storage and offline processing. Incorporating hidden biomarkers into routine haematology panels would significantly improve diagnostics without flagged results. We present RT-HAD, an end-to-end deep learning-based image and data processing framework for off-axis digital holographic microscopy (DHM), which combines physics-consistent holographic reconstruction and detection, representing each blood cell in a graph to recognize aggregates. RT-HAD processes >30 GB of image data on-the-fly with turnaround time of <1.5 min and error rate of 8.9% in platelet aggregate detection, which matches acceptable laboratory error rates of haematology biomarkers and solves the big data challenge for point-of-care diagnostics.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Molecular Odor Taxonomies for Structure-based Odor Predictions using Machine Learning",
    "title_es": "Exploring Molecular Odor Taxonomies for Structure-based Odor Predictions using Machine Learning",
    "url": "https://arxiv.org/abs/2508.09217",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09217v1 Announce Type: cross \nAbstract: One of the key challenges to predict odor from molecular structure is unarguably our limited understanding of the odor space and the complexity of the underlying structure-odor relationships. Here, we show that the predictive performance of machine learning models for structure-based odor predictions can be improved using both, an expert and a data-driven odor taxonomy. The expert taxonomy is based on semantic and perceptual similarities, while the data-driven taxonomy is based on clustering co-occurrence patterns of odor descriptors directly from the prepared dataset. Both taxonomies improve the predictions of different machine learning models and outperform random groupings of descriptors that do not reflect existing relations between odor descriptors. We assess the quality of both taxonomies through their predictive performance across different odor classes and perform an in-depth error analysis highlighting the complexity of odor-structure relationships and identifying potential inconsistencies within the taxonomies by showcasing pear odorants used in perfumery. The data-driven taxonomy allows us to critically evaluate our expert taxonomy and better understand the molecular odor space. Both taxonomies as well as a full dataset are made available to the community, providing a stepping stone for a future community-driven exploration of the molecular basis of smell. In addition, we provide a detailed multi-layer expert taxonomy including a total of 777 different descriptors from the Pyrfume repository.",
    "source": "arXiv"
  },
  {
    "title": "AMRG: Extend Vision Language Models for Automatic Mammography Report Generation",
    "title_es": "AMRG: Extend Vision Language Models for Automatic Mammography Report Generation",
    "url": "https://arxiv.org/abs/2508.09225",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09225v1 Announce Type: cross \nAbstract: Mammography report generation is a critical yet underexplored task in medical AI, characterized by challenges such as multiview image reasoning, high-resolution visual cues, and unstructured radiologic language. In this work, we introduce AMRG (Automatic Mammography Report Generation), the first end-to-end framework for generating narrative mammography reports using large vision-language models (VLMs). Building upon MedGemma-4B-it-a domain-specialized, instruction-tuned VLM-we employ a parameter-efficient fine-tuning (PEFT) strategy via Low-Rank Adaptation (LoRA), enabling lightweight adaptation with minimal computational overhead. We train and evaluate AMRG on DMID, a publicly available dataset of paired high-resolution mammograms and diagnostic reports. This work establishes the first reproducible benchmark for mammography report generation, addressing a longstanding gap in multimodal clinical AI. We systematically explore LoRA hyperparameter configurations and conduct comparative experiments across multiple VLM backbones, including both domain-specific and general-purpose models under a unified tuning protocol. Our framework demonstrates strong performance across both language generation and clinical metrics, achieving a ROUGE-L score of 0.5691, METEOR of 0.6152, CIDEr of 0.5818, and BI-RADS accuracy of 0.5582. Qualitative analysis further highlights improved diagnostic consistency and reduced hallucinations. AMRG offers a scalable and adaptable foundation for radiology report generation and paves the way for future research in multimodal medical AI.",
    "source": "arXiv"
  },
  {
    "title": "Objective Soups: Multilingual Multi-Task Modeling for Speech Processing",
    "title_es": "Objective Soups: Multilingual Multi-Task Modeling for Speech Processing",
    "url": "https://arxiv.org/abs/2508.09228",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09228v1 Announce Type: cross \nAbstract: Training a single model for multilingual, multi-task speech processing (MSP) is severely hampered by conflicting objectives between tasks like speech recognition and translation. While multi-objective optimization (MOO) aims to align gradient updates, its effectiveness diminishes as the number of tasks grows, making it difficult to find a common descent direction. This raises a fundamental question: should highly conflicting objectives be optimized jointly or separated into a hierarchical structure? To address this question, this paper investigates three multi-objective MSP formulations, which we refer to as \\textbf{objective soup recipes}. These formulations apply multi-objective optimization at different optimization levels to mitigate potential conflicts among all objectives. To ensure efficiency, we introduce a lightweight layer-selection mechanism that computes the conflict-avoiding gradient using only the most problematic layers, minimizing computational and memory overhead. Extensive experiments on CoVoST v2, LibriSpeech, and AISHELL-1 reveal that a bi-level recipe separating recognition and translation tasks consistently outperforms standard flat optimization. Our work demonstrates that hierarchical MOO is a more effective and scalable approach for building state-of-the-art MSP models. Our code has been released at https://github.com/afmsaif/Objective_Soups.",
    "source": "arXiv"
  },
  {
    "title": "Safety Perspective on Assisted Lane Changes: Insights from Open-Road, Live-Traffic Experiments",
    "title_es": "Safety Perspective on Assisted Lane Changes: Insights from Open-Road, Live-Traffic Experiments",
    "url": "https://arxiv.org/abs/2508.09233",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09233v1 Announce Type: cross \nAbstract: This study investigates the assisted lane change functionality of five different vehicles equipped with advanced driver assistance systems (ADAS). The goal is to examine novel, under-researched features of commercially available ADAS technologies. The experimental campaign, conducted in the I-24 highway near Nashville, TN, US, collected data on the kinematics and safety margins of assisted lane changes in real-world conditions. The results show that the kinematics of assisted lane changes are consistent for each system, with four out of five vehicles using slower speeds and decelerations than human drivers. However, one system consistently performed more assertive lane changes, completing the maneuver in around 5 seconds. Regarding safety margins, only three vehicles are investigated. Those operated in the US are not restricted by relevant UN regulations, and their designs were found not to adhere to these regulatory requirements. A simulation method used to classify the challenge level for the vehicle receiving the lane change, showing that these systems can force trailing vehicles to decelerate to keep a safe gap. One assisted system was found to have performed a maneuver that posed a hard challenge level for the other vehicle, raising concerns about the safety of these systems in real-world operation. All three vehicles were found to carry out lane changes that induced decelerations to the vehicle in the target lane. Those decelerations could affect traffic flow, inducing traffic shockwaves.",
    "source": "arXiv"
  },
  {
    "title": "Cross-BCI, A Cross-BCI-Paradigm Classifica-tion Model Towards Universal BCI Applications",
    "title_es": "Cross-BCI, A Cross-BCI-Paradigm Classifica-tion Model Towards Universal BCI Applications",
    "url": "https://arxiv.org/abs/2508.09242",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09242v1 Announce Type: cross \nAbstract: Classification models used in brain-computer interface (BCI) are usually designed for a single BCI paradigm. This requires the redevelopment of the model when applying it to a new BCI paradigm, resulting in repeated costs and effort. Moreover, less complex deep learning models are desired for practical usage, as well as for deployment on portable devices. In or-der to fill the above gaps, we, in this study, proposed a light-weight and unified decoding model for cross-BCI-paradigm classification. The proposed model starts with a tempo-spatial convolution. It is followed by a multi-scale local feature selec-tion module, aiming to extract local features shared across BCI paradigms and generate weighted features. Finally, a mul-ti-dimensional global feature extraction module is designed, in which multi-dimensional global features are extracted from the weighted features and fused with the weighted features to form high-level feature representations associated with BCI para-digms. The results, evaluated on a mixture of three classical BCI paradigms (i.e., MI, SSVEP, and P300), demon-strate that the proposed model achieves 88.39%, 82.36%, 80.01%, and 0.8092 for accuracy, macro-precision, mac-ro-recall, and macro-F1-score, respectively, significantly out-performing the compared models. This study pro-vides a feasible solution for cross-BCI-paradigm classifica-tion. It lays a technological foundation for de-veloping a new generation of unified decoding systems, paving the way for low-cost and universal practical applications.",
    "source": "arXiv"
  },
  {
    "title": "Forecasting Binary Economic Events in Modern Mercantilism: Traditional methodologies coupled with PCA and K-means Quantitative Analysis of Qualitative Sentimental Data",
    "title_es": "Forecasting Binary Economic Events in Modern Mercantilism: Traditional methodologies coupled with PCA and K-means Quantitative Analysis of Qualitative Sentimental Data",
    "url": "https://arxiv.org/abs/2508.09243",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09243v1 Announce Type: cross \nAbstract: This paper examines Modern Mercantilism, characterized by rising economic nationalism, strategic technological decoupling, and geopolitical fragmentation, as a disruptive shift from the post-1945 globalization paradigm. It applies Principal Component Analysis (PCA) to 768-dimensional SBERT-generated semantic embeddings of curated news articles to extract orthogonal latent factors that discriminate binary event outcomes linked to protectionism, technological sovereignty, and bloc realignments. Analysis of principal component loadings identifies key semantic features driving classification performance, enhancing interpretability and predictive accuracy. This methodology provides a scalable, data-driven framework for quantitatively tracking emergent mercantilist dynamics through high-dimensional text analytics",
    "source": "arXiv"
  },
  {
    "title": "A Generative Imputation Method for Multimodal Alzheimer's Disease Diagnosis",
    "title_es": "A Generative Imputation Method for Multimodal Alzheimer's Disease Diagnosis",
    "url": "https://arxiv.org/abs/2508.09271",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09271v1 Announce Type: cross \nAbstract: Multimodal data analysis can lead to more accurate diagnoses of brain disorders due to the complementary information that each modality adds. However, a major challenge of using multimodal datasets in the neuroimaging field is incomplete data, where some of the modalities are missing for certain subjects. Hence, effective strategies are needed for completing the data. Traditional methods, such as subsampling or zero-filling, may reduce the accuracy of predictions or introduce unintended biases. In contrast, advanced methods such as generative models have emerged as promising solutions without these limitations. In this study, we proposed a generative adversarial network method designed to reconstruct missing modalities from existing ones while preserving the disease patterns. We used T1-weighted structural magnetic resonance imaging and functional network connectivity as two modalities. Our findings showed a 9% improvement in the classification accuracy for Alzheimer's disease versus cognitive normal groups when using our generative imputation method compared to the traditional approaches.",
    "source": "arXiv"
  },
  {
    "title": "Swap Bounded Envy",
    "title_es": "Swap Bounded Envy",
    "url": "https://arxiv.org/abs/2508.09290",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09290v1 Announce Type: cross \nAbstract: We study fairness in the allocation of discrete goods. Exactly fair (envy-free) allocations are impossible, so we discuss notions of approximate fairness. In particular, we focus on allocations in which the swap of two items serves to eliminate any envy, either for the allocated bundles or with respect to a reference bundle. We propose an algorithm that, under some restrictions on agents' preferences, achieves an allocation with ``swap bounded envy.''",
    "source": "arXiv"
  },
  {
    "title": "Fake-Mamba: Real-Time Speech Deepfake Detection Using Bidirectional Mamba as Self-Attention's Alternative",
    "title_es": "Fake-Mamba: Real-Time Speech Deepfake Detection Using Bidirectional Mamba as Self-Attention's Alternative",
    "url": "https://arxiv.org/abs/2508.09294",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09294v1 Announce Type: cross \nAbstract: Advances in speech synthesis intensify security threats, motivating real-time deepfake detection research. We investigate whether bidirectional Mamba can serve as a competitive alternative to Self-Attention in detecting synthetic speech. Our solution, Fake-Mamba, integrates an XLSR front-end with bidirectional Mamba to capture both local and global artifacts. Our core innovation introduces three efficient encoders: TransBiMamba, ConBiMamba, and PN-BiMamba. Leveraging XLSR's rich linguistic representations, PN-BiMamba can effectively capture the subtle cues of synthetic speech. Evaluated on ASVspoof 21 LA, 21 DF, and In-The-Wild benchmarks, Fake-Mamba achieves 0.97%, 1.74%, and 5.85% EER, respectively, representing substantial relative gains over SOTA models XLSR-Conformer and XLSR-Mamba. The framework maintains real-time inference across utterance lengths, demonstrating strong generalization and practical viability. The code is available at https://github.com/xuanxixi/Fake-Mamba.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Survival Prediction using Longitudinal Images based on Transformer",
    "title_es": "Dynamic Survival Prediction using Longitudinal Images based on Transformer",
    "url": "https://arxiv.org/abs/2508.09328",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09328v1 Announce Type: cross \nAbstract: Survival analysis utilizing multiple longitudinal medical images plays a pivotal role in the early detection and prognosis of diseases by providing insight beyond single-image evaluations. However, current methodologies often inadequately utilize censored data, overlook correlations among longitudinal images measured over multiple time points, and lack interpretability. We introduce SurLonFormer, a novel Transformer-based neural network that integrates longitudinal medical imaging with structured data for survival prediction. Our architecture comprises three key components: a Vision Encoder for extracting spatial features, a Sequence Encoder for aggregating temporal information, and a Survival Encoder based on the Cox proportional hazards model. This framework effectively incorporates censored data, addresses scalability issues, and enhances interpretability through occlusion sensitivity analysis and dynamic survival prediction. Extensive simulations and a real-world application in Alzheimer's disease analysis demonstrate that SurLonFormer achieves superior predictive performance and successfully identifies disease-related imaging biomarkers.",
    "source": "arXiv"
  },
  {
    "title": "The connectivity dimension of a graph",
    "title_es": "The connectivity dimension of a graph",
    "url": "https://arxiv.org/abs/2508.09336",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09336v1 Announce Type: cross \nAbstract: This article investigates the connectivity dimension of a graph. We introduce this concept in analogy to the metric dimension of a graph, providing a graph parameter that measures the heterogeneity of the connectivity structure of a graph. We fully characterize extremal examples and present explicit constructions of infinitely many graphs realizing any prescribed non-extremal connectivity dimension. We also establish a general lower bound in terms of the graph's block structure, linking the parameter to classical notions from graph theory. Finally, we prove that the problem of computing the connectivity dimension is NP-complete.",
    "source": "arXiv"
  },
  {
    "title": "Distributional Sensitivity Analysis: Enabling Differentiability in Sample-Based Inference",
    "title_es": "Distributional Sensitivity Analysis: Enabling Differentiability in Sample-Based Inference",
    "url": "https://arxiv.org/abs/2508.09347",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09347v1 Announce Type: cross \nAbstract: We present two analytical formulae for estimating the sensitivity -- namely, the gradient or Jacobian -- at given realizations of an arbitrary-dimensional random vector with respect to its distributional parameters. The first formula interprets this sensitivity as partial derivatives of the inverse mapping associated with the vector of 1-D conditional distributions. The second formula, intended for optimization methods that tolerate inexact gradients, introduces a diagonal approximation that reduces computational cost at the cost of some accuracy. We additionally provide four second-order numerical algorithms to approximate both formulae when closed forms are unavailable. We performed verification and validation studies to demonstrate the correctness of these numerical algorithms and the effectiveness of the proposed formulae. A nuclear physics application showcases how our work enables uncertainty quantification and parameter inference for quantum correlation functions. Our approach differs from existing methods by avoiding the need for model fitting, knowledge of sampling algorithms, and evaluation of high-dimensional integrals. It is therefore particularly useful for sample-based inverse problems when the sampler operates as a black box or requires expensive physics simulations. Moreover, our method renders arbitrary sampling subroutines differentiable, facilitating their integration into programming frameworks for deep learning and automatic differentiation. Algorithmic details and code implementations are provided in this paper and in our open-source software DistroSA to enable reproducibility and further development.",
    "source": "arXiv"
  },
  {
    "title": "Classifying Cool Dwarfs: Comprehensive Spectral Typing of Field and Peculiar Dwarfs Using Machine Learning",
    "title_es": "Classifying Cool Dwarfs: Comprehensive Spectral Typing of Field and Peculiar Dwarfs Using Machine Learning",
    "url": "https://arxiv.org/abs/2508.09370",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09370v1 Announce Type: cross \nAbstract: Low-mass stars and brown dwarfs -- spectral types (SpTs) M0 and later -- play a significant role in studying stellar and substellar processes and demographics, reaching down to planetary-mass objects. Currently, the classification of these sources remains heavily reliant on visual inspection of spectral features, equivalent width measurements, or narrow-/wide-band spectral indices. Recent advances in machine learning (ML) methods offer automated approaches for spectral typing, which are becoming increasingly important as large spectroscopic surveys such as Gaia, SDSS, and SPHEREx generate datasets containing millions of spectra. We investigate the application of ML in spectral type classification on low-resolution (R $\\sim$ 120) near-infrared spectra of M0--T9 dwarfs obtained with the SpeX instrument on the NASA Infrared Telescope Facility. We specifically aim to classify the gravity- and metallicity-dependent subclasses for late-type dwarfs. We used binned fluxes as input features and compared the efficacy of spectral type estimators built using Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) models. We tested the influence of different normalizations and analyzed the relative importance of different spectral regions for surface gravity and metallicity subclass classification. Our best-performing model (using KNN) classifies 95.5 $\\pm$ 0.6% of sources to within $\\pm$1 SpT, and assigns surface gravity and metallicity subclasses with 89.5 $\\pm$ 0.9% accuracy. We test the dependence of signal-to-noise ratio on classification accuracy and find sources with SNR $\\gtrsim$ 60 have $\\gtrsim$ 95% accuracy. We also find that zy-band plays the most prominent role in the RF model, with FeH and TiO having the highest feature importance.",
    "source": "arXiv"
  },
  {
    "title": "Satellites are closer than you think: A near field MIMO approach for Ground stations",
    "title_es": "Satellites are closer than you think: A near field MIMO approach for Ground stations",
    "url": "https://arxiv.org/abs/2508.09374",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09374v1 Announce Type: cross \nAbstract: The rapid growth of low Earth orbit (LEO) satellite constellations has revolutionized broadband access, earth observation, and direct-to-device connectivity. However, the expansion of ground station infrastructure has not kept pace, creating a critical bottleneck in satellite-to-ground backhaul capacity. Traditional parabolic dish antennas, though effective for geostationary (GEO) satellites, are ill-suited for dense, fastmoving LEO networks due to mechanical steering delays and their inability to track multiple satellites simultaneously. Phased array antennas offer electronically steerable beams and multisatellite support, but their integration into ground stations is limited by the high cost, hardware issues, and complexity of achieving sufficient antenna gain. We introduce ArrayLink, a distributed phased array architecture that coherently combines multiple small commercially available panels to achieve high-gain beamforming and unlock line-of-sight MIMO spatial multiplexing with minimal additional capital expenditure. By spacing 16 (32x32) panels across a kilometer-scale aperture, ArrayLink enters the radiative near-field, focusing energy in both angle and range while supporting up to four simultaneous spatial streams on a single feeder link. Through rigorous theoretical analysis, detailed 2D beam pattern simulations and real-world hardware experiments, we show that ArrayLink (i) achieves dish-class gain with in range 1-2 dB of 1.47 m reflector, (ii) maintains four parallel streams at ranges of hundreds of kilometers (falling to two beyond 2000 km), and (iii) exhibits tight agreement across theory, simulation, and experiment with minimal variance. These findings open a practical and scalable path to boosting LEO backhaul capacity.",
    "source": "arXiv"
  },
  {
    "title": "Parallel repetition of expanded, and multiplayer, Quantum games: anchoring, optimal values, generalized error bounds, dependency-breaking as symmetry-breaking",
    "title_es": "Parallel repetition of expanded, and multiplayer, Quantum games: anchoring, optimal values, generalized error bounds, dependency-breaking as symmetry-breaking",
    "url": "https://arxiv.org/abs/2508.09380",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09380v1 Announce Type: cross \nAbstract: We demonstrate that parallel repetition of the multiplayer anchored optimal value, $\\omega \\big( G_{\\bot} \\big)^{\\otimes n}$, decays exponentially. Central to our approach are several probabilistic computations, pertaining to: (1) the computation of expected values for quantifying how the winning probability of the game is likely to change under the anchoring transformation; (2) the computation of positive operator valued measurements, which can be placed into direct correspondence with several probabilistically defined quantities; (3) the computation of Relative, and Relative-min entropies; (4) and lastly, the computation of generalized error bounds, which have previously been analyzed by the author in several multiplayer game-theoretic settings (arXiv: 2505.06322, and arXiv: 2507.03035). This work builds upon observations originally provided by Bavarian, Vidick, and Yuen (arXiv: 1509.07466).",
    "source": "arXiv"
  },
  {
    "title": "ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs",
    "title_es": "ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs",
    "url": "https://arxiv.org/abs/2508.09389",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09389v1 Announce Type: cross \nAbstract: Prosody conveys rich emotional and semantic information of the speech signal as well as individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as F0 and energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic features and time-aligned textual content, both are partially masked, and obtains a fixed-length latent prosodic embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input and unmasked textual content. Trained on the GigaSpeech dataset, we compare our method with state-of-the-art style encoders. For F0 and energy predictions, we show consistent improvements for our model at different levels of granularity. We also integrate these predicted prosodic features into a TTS system and conduct perceptual tests, which show higher prosody preference compared to the baselines, demonstrating the model's potential in tasks where prosody modeling is important.",
    "source": "arXiv"
  },
  {
    "title": "A pseudo-inverse of a line graph",
    "title_es": "A pseudo-inverse of a line graph",
    "url": "https://arxiv.org/abs/2508.09412",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09412v1 Announce Type: cross \nAbstract: Line graphs are an alternative representation of graphs where each vertex of the original (root) graph becomes an edge. However not all graphs have a corresponding root graph, hence the transformation from graphs to line graphs is not invertible. We investigate the case when there is a small perturbation in the space of line graphs, and try to recover the corresponding root graph, essentially defining the inverse of the line graph operation. We propose a linear integer program that edits the smallest number of edges in the line graph, that allow a root graph to be found. We use the spectral norm to theoretically prove that such a pseudo-inverse operation is well behaved. Illustrative empirical experiments on Erd\\H{o}s-R\\'enyi graphs show that our theoretical results work in practice.",
    "source": "arXiv"
  },
  {
    "title": "Semi-discrete multi-to -one dimensional variational problems",
    "title_es": "Semi-discrete multi-to -one dimensional variational problems",
    "url": "https://arxiv.org/abs/2508.09490",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09490v1 Announce Type: cross \nAbstract: We study a class of semi-discrete variational problems that arise in economic matching and game theory, where agents with continuous attributes are matched to a finite set of outcomes with a one dimensional structure. Such problems appear in applications including Cournot-Nash equilibria, and hedonic pricing, and can be formulated as problems involving optimal transport between spaces of unequal dimensions. In our discrete strategy space setting, we establish analogues of results developed for a continuum of strategies in \\cite{nenna2020variational}, ensuring solutions have a particularly simple structure under certain conditions. This has important numerical consequences, as it is natural to discretize when numerically computing solutions. We leverage our results to develop efficient algorithms for these problems which scale significantly better than standard optimal transport solvers, particularly when the number of discrete outcomes is large, provided our conditions are satisfied. We also establish rigorous convergence guarantees for these algorithms. We illustrate the advantages of our approach by solving a range of numerical examples; in many of these our new solvers outperform alternatives by a considerable margin.",
    "source": "arXiv"
  },
  {
    "title": "DeepWKB: Learning WKB Expansions of Invariant Distributions for Stochastic Systems",
    "title_es": "DeepWKB: Learning WKB Expansions of Invariant Distributions for Stochastic Systems",
    "url": "https://arxiv.org/abs/2508.09529",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09529v1 Announce Type: cross \nAbstract: This paper introduces a novel deep learning method, called DeepWKB, for estimating the invariant distribution of randomly perturbed systems via its Wentzel-Kramers-Brillouin (WKB) approximation $u_\\epsilon(x) = Q(\\epsilon)^{-1} Z_\\epsilon(x) \\exp\\{-V(x)/\\epsilon\\}$, where $V$ is known as the quasi-potential, $\\epsilon$ denotes the noise strength, and $Q(\\epsilon)$ is the normalization factor. By utilizing both Monte Carlo data and the partial differential equations satisfied by $V$ and $Z_\\epsilon$, the DeepWKB method computes $V$ and $Z_\\epsilon$ separately. This enables an approximation of the invariant distribution in the singular regime where $\\epsilon$ is sufficiently small, which remains a significant challenge for most existing methods. Moreover, the DeepWKB method is applicable to higher-dimensional stochastic systems whose deterministic counterparts admit non-trivial attractors. In particular, it provides a scalable and flexible alternative for computing the quasi-potential, which plays a key role in the analysis of rare events, metastability, and the stochastic stability of complex systems.",
    "source": "arXiv"
  },
  {
    "title": "Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm",
    "title_es": "Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm",
    "url": "https://arxiv.org/abs/2508.09546",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09546v1 Announce Type: cross \nAbstract: Distributed MIMO and integrated sensing and communication are expected to be key technologies in future wireless systems, enabling reliable, low-latency communication and accurate localization. Dedicated localization solutions must support distributed architecture, provide scalability across different system configurations and meet strict latency requirements. We present a scalable message-passing localization method and architecture co-designed for a panel-based distributed MIMO system and network topology, in which interconnected units operate without centralized processing. This method jointly detects line-of-sight paths to distributed units from multipath measurements in dynamic scenarios, localizes the agent, and achieves very low latency. Additionally, we introduce a cycle-accurate system latency model based on implemented FPGA operations, and show important insights into processing latency and hardware utilization and system-level trade-offs. We compare our method to a multipath-based localization method and show that it can achieve similar localization performance, with wide enough distribution of array elements, while offering lower latency and computational complexity.",
    "source": "arXiv"
  },
  {
    "title": "Scalable h-adaptive probabilistic solver for time-independent and time-dependent systems",
    "title_es": "Scalable h-adaptive probabilistic solver for time-independent and time-dependent systems",
    "url": "https://arxiv.org/abs/2508.09623",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09623v1 Announce Type: cross \nAbstract: Solving partial differential equations (PDEs) within the framework of probabilistic numerics offers a principled approach to quantifying epistemic uncertainty arising from discretization. By leveraging Gaussian process regression and imposing the governing PDE as a constraint at a finite set of collocation points, probabilistic numerics delivers mesh-free solutions at arbitrary locations. However, the high computational cost, which scales cubically with the number of collocation points, remains a critical bottleneck, particularly for large-scale or high-dimensional problems. We propose a scalable enhancement to this paradigm through two key innovations. First, we develop a stochastic dual descent algorithm that reduces the per-iteration complexity from cubic to linear in the number of collocation points, enabling tractable inference. Second, we exploit a clustering-based active learning strategy that adaptively selects collocation points to maximize information gain while minimizing computational expense. Together, these contributions result in an $h$-adaptive probabilistic solver that can scale to a large number of collocation points. We demonstrate the efficacy of the proposed solver on benchmark PDEs, including two- and three-dimensional steady-state elliptic problems, as well as a time-dependent parabolic PDE formulated in a space-time setting.",
    "source": "arXiv"
  },
  {
    "title": "$\\text{M}^3\\text{PDB}$: A Multimodal, Multi-Label, Multilingual Prompt Database for Speech Generation",
    "title_es": "$\\text{M}^3\\text{PDB}$: A Multimodal, Multi-Label, Multilingual Prompt Database for Speech Generation",
    "url": "https://arxiv.org/abs/2508.09702",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09702v1 Announce Type: cross \nAbstract: Recent advancements in zero-shot speech generation have enabled models to synthesize speech that mimics speaker identity and speaking style from speech prompts. However, these models' effectiveness is significantly limited in real-world scenarios where high-quality speech prompts are absent, incomplete, or out of domain. This issue arises primarily from a significant quality mismatch between the speech data utilized for model training and the input prompt speech during inference. To address this, we introduce $\\text{M}^3\\text{PDB}$, the first large-scale, multi-modal, multi-label, and multilingual prompt database designed for robust prompt selection in speech generation. Our dataset construction leverages a novel multi-modal, multi-agent annotation framework, enabling precise and hierarchical labeling across diverse modalities. Furthermore, we propose a lightweight yet effective prompt selection strategy tailored for real-time, resource-constrained inference settings. Experimental results demonstrate that our proposed database and selection strategy effectively support various challenging speech generation scenarios. We hope our work can inspire the community to shift focus from improving performance on standard benchmarks to addressing more realistic and diverse application scenarios in speech generation. Code and dataset are available at: https://github.com/hizening/M3PDB.",
    "source": "arXiv"
  },
  {
    "title": "3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator",
    "title_es": "3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator",
    "url": "https://arxiv.org/abs/2508.09708",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09708v1 Announce Type: cross \nAbstract: Vehicle-to-everything (V2X) communication is a key technology for enabling intelligent transportation systems (ITS) that can improve road safety, traffic efficiency, and environmental sustainability. Among the various V2X applications, platooning is one of the most promising ones, as it allows a group of vehicles to travel closely together at high speeds, reducing fuel consumption and emissions. However, it poses significant challenges for wireless communication, such as high reliability and low latency. In this paper, we evaluate the benefits of group scheduling, also referred to as Mode 2d, which is based on a distributed and scheduled resource allocation scheme that allows the group of cars to select resources from a configured pool without network assistance. We evaluated the scheme through simulations, and the results show that this approach can meet the reliability, low latency, and data rate requirements for platooning.",
    "source": "arXiv"
  },
  {
    "title": "Structured Kernel Regression VAE: A Computationally Efficient Surrogate for GP-VAEs in ICA",
    "title_es": "Structured Kernel Regression VAE: A Computationally Efficient Surrogate for GP-VAEs in ICA",
    "url": "https://arxiv.org/abs/2508.09721",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09721v1 Announce Type: cross \nAbstract: The interpretability of generative models is considered a key factor in demonstrating their effectiveness and controllability. The generated data are believed to be determined by latent variables that are not directly observable. Therefore, disentangling, decoupling, decomposing, causal inference, or performing Independent Component Analysis (ICA) in the latent variable space helps uncover the independent factors that influence the attributes or features affecting the generated outputs, thereby enhancing the interpretability of generative models. As a generative model, Variational Autoencoders (VAEs) combine with variational Bayesian inference algorithms. Using VAEs, the inverse process of ICA can be equivalently framed as a variational inference process. In some studies, Gaussian processes (GPs) have been introduced as priors for each dimension of latent variables in VAEs, structuring and separating each dimension from temporal or spatial perspectives, and encouraging different dimensions to control various attributes of the generated data. However, GPs impose a significant computational burden, resulting in substantial resource consumption when handling large datasets. Essentially, GPs model different temporal or spatial structures through various kernel functions. Structuring the priors of latent variables via kernel functions-so that different kernel functions model the correlations among sequence points within different latent dimensions-is at the core of achieving disentanglement in VAEs. The proposed Structured Kernel Regression VAE (SKR-VAE) leverages this core idea in a more efficient way, avoiding the costly kernel matrix inversion required in GPs. This research demonstrates that, while maintaining ICA performance, SKR-VAE achieves greater computational efficiency and significantly reduced computational burden compared to GP-VAE.",
    "source": "arXiv"
  },
  {
    "title": "NEUBORN: The Neurodevelopmental Evolution framework Using BiOmechanical RemodelliNg",
    "title_es": "NEUBORN: The Neurodevelopmental Evolution framework Using BiOmechanical RemodelliNg",
    "url": "https://arxiv.org/abs/2508.09757",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09757v1 Announce Type: cross \nAbstract: Understanding individual cortical development is essential for identifying deviations linked to neurodevelopmental disorders. However, current normative modelling frameworks struggle to capture fine-scale anatomical details due to their reliance on modelling data within a population-average reference space. Here, we present a novel framework for learning individual growth trajectories from biomechanically constrained, longitudinal, diffeomorphic image registration, implemented via a hierarchical network architecture. Trained on neonatal MRI data from the Developing Human Connectome Project, the method improves the biological plausibility of warps, generating growth trajectories that better follow population-level trends while generating smoother warps, with fewer negative Jacobians, relative to state-of-the-art baselines. The resulting subject-specific deformations provide interpretable, biologically grounded mappings of development. This framework opens new possibilities for predictive modeling of brain maturation and early identification of malformations of cortical development.",
    "source": "arXiv"
  },
  {
    "title": "Counting Short Trajectories in Elementary Cellular Automata using the Transfer Matrix Method",
    "title_es": "Counting Short Trajectories in Elementary Cellular Automata using the Transfer Matrix Method",
    "url": "https://arxiv.org/abs/2508.09768",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09768v1 Announce Type: cross \nAbstract: Elementary Cellular Automata (ECAs) exhibit diverse behaviours often categorized by Wolfram's qualitative classification. To provide a quantitative basis for understanding these behaviours, we investigate the global dynamics of such automata and we describe a method that allows us to compute the number of all configurations leading to short attractors in a limited number of time steps. This computation yields exact results in the thermodynamic limit (as the CA grid size grows to infinity), and is based on the Transfer Matrix Method (TMM) that we adapt for our purposes. Specifically, given two parameters $(p, c)$ we are able to compute the entropy of all initial configurations converging to an attractor of size $c$ after $p$ time-steps. By calculating such statistics for various ECA rules, we establish a quantitative connection between the entropy and the qualitative Wolfram classification scheme. Class 1 rules rapidly converge to maximal entropy for stationary states ($c=1$) as $p$ increases. Class 2 rules also approach maximal entropy quickly for appropriate cycle lengths $c$, potentially requiring consideration of translations. Class 3 rules exhibit zero or low finite entropy that saturates after a short transient. Class 4 rules show finite positive entropy, similar to some Class 3 rules. This method provides a precise framework for quantifying trajectory statistics, although its exponential computational cost in $p+c$ restricts practical analysis to short trajectories.",
    "source": "arXiv"
  },
  {
    "title": "Improving the Speaker Anonymization Evaluation's Robustness to Target Speakers with Adversarial Learning",
    "title_es": "Improving the Speaker Anonymization Evaluation's Robustness to Target Speakers with Adversarial Learning",
    "url": "https://arxiv.org/abs/2508.09803",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09803v1 Announce Type: cross \nAbstract: The current privacy evaluation for speaker anonymization often overestimates privacy when a same-gender target selection algorithm (TSA) is used, although this TSA leaks the speaker's gender and should hence be more vulnerable. We hypothesize that this occurs because the evaluation does not account for the fact that anonymized speech contains information from both the source and target speakers. To address this, we propose to add a target classifier that measures the influence of target speaker information in the evaluation, which can also be removed with adversarial learning. Experiments demonstrate that this approach is effective for multiple anonymizers, particularly when using a same-gender TSA, leading to a more reliable assessment.",
    "source": "arXiv"
  },
  {
    "title": "Directed Cycles as Higher-Order Units of Information Processing in Complex Networks",
    "title_es": "Directed Cycles as Higher-Order Units of Information Processing in Complex Networks",
    "url": "https://arxiv.org/abs/2508.09808",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09808v1 Announce Type: cross \nAbstract: Directed cycles form the fundamental motifs in natural, social and artificial networks, yet their distinct computational roles remain under-explored, particularly in the context of higher-order structure and function. In this work, we investigate how two types of directed cycles - feedforward and feedback - can act as higher-order structures to facilitate the flow and integration of information in sparse random networks, and how these roles depend on the environment of the cycles. Using information-theoretic measures, we show that network size, sparsity and relative directionality critically impact the information-processing capacities of directed cycles. In a network with no-preferred global direction, a feedforward cycle enables greater information flow and a feedback cycle allows for increased information integration. The relative direction of a feedforward cycle as well as the structural incoherence it induces, determines its capacity to generate higher-order behaviour. Finally, we demonstrate that introducing feedback loops into otherwise feedforward architectures increases the diversity of network activity patterns. These findings suggest that directed cycles serve as computational motifs with local information processing capabilities that depend on the structure they are embedded. Using directed cycles, we highlight the interdependence between higher-order structures and the higher-order order behaviour they can induce in the network dynamics.",
    "source": "arXiv"
  },
  {
    "title": "Robustness analysis of Deep Sky Objects detection models on HPC",
    "title_es": "Robustness analysis of Deep Sky Objects detection models on HPC",
    "url": "https://arxiv.org/abs/2508.09831",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09831v1 Announce Type: cross \nAbstract: Astronomical surveys and the growing involvement of amateur astronomers are producing more sky images than ever before, and this calls for automated processing methods that are accurate and robust. Detecting Deep Sky Objects -- such as galaxies, nebulae, and star clusters -- remains challenging because of their faint signals and complex backgrounds. Advances in Computer Vision and Deep Learning now make it possible to improve and automate this process. In this paper, we present the training and comparison of different detection models (YOLO, RET-DETR) on smart telescope images, using High-Performance Computing (HPC) to parallelise computations, in particular for robustness testing.",
    "source": "arXiv"
  },
  {
    "title": "On the Generalization Limits of Quantum Generative Adversarial Networks with Pure State Generators",
    "title_es": "On the Generalization Limits of Quantum Generative Adversarial Networks with Pure State Generators",
    "url": "https://arxiv.org/abs/2508.09844",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09844v1 Announce Type: cross \nAbstract: We investigate the capabilities of Quantum Generative Adversarial Networks (QGANs) in image generations tasks. Our analysis centers on fully quantum implementations of both the generator and discriminator. Through extensive numerical testing of current main architectures, we find that QGANs struggle to generalize across datasets, converging on merely the average representation of the training data. When the output of the generator is a pure-state, we analytically derive a lower bound for the discriminator quality given by the fidelity between the pure-state output of the generator and the target data distribution, thereby providing a theoretical explanation for the limitations observed in current models. Our findings reveal fundamental challenges in the generalization capabilities of existing quantum generative models. While our analysis focuses on QGANs, the results carry broader implications for the performance of related quantum generative models.",
    "source": "arXiv"
  },
  {
    "title": "Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions",
    "title_es": "Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions",
    "url": "https://arxiv.org/abs/2508.09852",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09852v1 Announce Type: cross \nAbstract: Neurological conditions affecting visual perception create profound experiential divides between affected individuals and their caregivers, families, and medical professionals. We present the Perceptual Reality Transformer, a comprehensive framework employing six distinct neural architectures to simulate eight neurological perception conditions with scientifically-grounded visual transformations. Our system learns mappings from natural images to condition-specific perceptual states, enabling others to experience approximations of simultanagnosia, prosopagnosia, ADHD attention deficits, visual agnosia, depression-related changes, anxiety tunnel vision, and Alzheimer's memory effects. Through systematic evaluation across ImageNet and CIFAR-10 datasets, we demonstrate that Vision Transformer architectures achieve optimal performance, outperforming traditional CNN and generative approaches. Our work establishes the first systematic benchmark for neurological perception simulation, contributes novel condition-specific perturbation functions grounded in clinical literature, and provides quantitative metrics for evaluating simulation fidelity. The framework has immediate applications in medical education, empathy training, and assistive technology development, while advancing our fundamental understanding of how neural networks can model atypical human perception.",
    "source": "arXiv"
  },
  {
    "title": "Learning complexity of many-body quantum sign structures through the lens of Boolean Fourier analysis",
    "title_es": "Learning complexity of many-body quantum sign structures through the lens of Boolean Fourier analysis",
    "url": "https://arxiv.org/abs/2508.09870",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09870v1 Announce Type: cross \nAbstract: We study sign structures of the ground states of spin-$1/2$ magnetic systems using the methods of Boolean Fourier analysis. Previously it was shown that the sign structures of frustrated systems are of complex nature: specifically, neural networks of popular architectures lack the generalization ability necessary to effectively reconstruct sign structures in supervised learning settings. This is believed to be an obstacle for applications of neural quantum states to frustrated systems. In the present work, we develop an alternative language for the analysis of sign structures based on representing them as polynomial functions defined on the Boolean hypercube - an approach called Boolean Fourier analysis. We discuss the relations between the properties of the Boolean Fourier series and the learning complexity of sign structures, and demonstrate that such polynomials can potentially serve as variational ans\\\"atze for the complex sign structures that dramatically outperform neural networks in terms of generalization ability. While ans\\\"atze of this type cannot yet be directly used in the context of variational optimization, they indicate that the complexity of sign structures is not an insurmountable curse, and can potentially be learned with better designed NQS architectures. Finally, we show how augmenting data with Boolean functions can aid sign prediction by neural networks.",
    "source": "arXiv"
  },
  {
    "title": "T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis",
    "title_es": "T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis",
    "url": "https://arxiv.org/abs/2508.09919",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09919v1 Announce Type: cross \nAbstract: Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of liver cancer, significantly improving the classification of the lesion and patient outcomes. However, traditional MRI faces challenges including risks from contrast agent (CA) administration, time-consuming manual assessment, and limited annotated datasets. To address these limitations, we propose a Time-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for synthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from non-contrast MRI (NCMRI). T-CACE introduces three core innovations: a conditional token encoding (CTE) mechanism that unifies anatomical priors and temporal phase information into latent representations; and a dynamic time-aware attention mask (DTAM) that adaptively modulates inter-phase information flow using a Gaussian-decayed attention mechanism, ensuring smooth and physiologically plausible transitions across phases. Furthermore, a constraint for temporal classification consistency (TCC) aligns the lesion classification output with the evolution of the physiological signal, further enhancing diagnostic reliability. Extensive experiments on two independent liver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods in image synthesis, segmentation, and lesion classification. This framework offers a clinically relevant and efficient alternative to traditional contrast-enhanced imaging, improving safety, diagnostic efficiency, and reliability for the assessment of liver lesion. The implementation of T-CACE is publicly available at: https://github.com/xiaojiao929/T-CACE.",
    "source": "arXiv"
  },
  {
    "title": "Improving quantum communication rates with permutation-invariant codes",
    "title_es": "Improving quantum communication rates with permutation-invariant codes",
    "url": "https://arxiv.org/abs/2508.09978",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09978v1 Announce Type: cross \nAbstract: In this work we improve the quantum communication rates of various quantum channels of interest using permutation-invariant quantum codes. We focus in particular on parametrized families of quantum channels and aim to improve bounds on their quantum capacity threshold, defined as the lowest noise level at which the quantum capacity of the channel family vanishes. These thresholds are important quantities as they mark the noise level up to which faithful quantum communication is theoretically possible. Our method exploits the fact that independent and identically distributed quantum channels preserve any permutation symmetry present at the input. The resulting symmetric output states can be described succinctly using the representation theory of the symmetric and general linear groups, which we use to derive an efficient algorithm for computing the channel coherent information of a permutation-invariant code. Our approach allows us to evaluate coherent information values for a large number of channel copies, e.g., at least 100 channel copies for qubit channels. We apply this method to various physically relevant channel models, including general Pauli channels, the dephrasure channel, the generalized amplitude damping channel, and the damping-dephasing channel. For each channel family we obtain improved lower bounds on their quantum capacities. For example, for the 2-Pauli and BB84 channel families we significantly improve the best known quantum capacity thresholds derived in [Fern, Whaley 2008]. These threshold improvements are achieved using a repetition code-like input state with non-orthogonal code states, which we further analyze in our representation-theoretic framework.",
    "source": "arXiv"
  },
  {
    "title": "Game-Theoretic Multiagent Reinforcement Learning",
    "title_es": "Game-Theoretic Multiagent Reinforcement Learning",
    "url": "https://arxiv.org/abs/2011.00583",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2011.00583v5 Announce Type: replace \nAbstract: Tremendous advances have been made in multiagent reinforcement learning (MARL). MARL corresponds to the learning problem in a multiagent system in which multiple agents learn simultaneously. It is an interdisciplinary field of study with a long history that includes game theory, machine learning, stochastic control, psychology, and optimization. Despite great successes in MARL, there is a lack of a self-contained overview of the literature that covers game-theoretic foundations of modern MARL methods and summarizes the recent advances. The majority of existing surveys are outdated and do not fully cover the recent developments since 2010. In this work, we provide a monograph on MARL that covers both the fundamentals and the latest developments on the research frontier. The goal of this monograph is to provide a self-contained assessment of the current state-of-the-art MARL techniques from a game-theoretic perspective. We expect this work to serve as a stepping stone for both new researchers who are about to enter this fast-growing field and experts in the field who want to obtain a panoramic view and identify new directions based on recent advances.",
    "source": "arXiv"
  },
  {
    "title": "Prompt-aligned Gradient for Prompt Tuning",
    "title_es": "Prompt-aligned Gradient for Prompt Tuning",
    "url": "https://arxiv.org/abs/2205.14865",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2205.14865v4 Announce Type: replace \nAbstract: Thanks to the large pre-trained vision-language models (VLMs) like CLIP, we can craft a zero-shot classifier by \"prompt\", e.g., the confidence score of an image being \"[CLASS]\" can be obtained by using the VLM provided similarity measure between the image and the prompt sentence \"a photo of a [CLASS]\". Therefore, prompt shows a great potential for fast adaptation of VLMs to downstream tasks if we fine-tune the prompt-based similarity measure. However, we find a common failure that improper fine-tuning may not only undermine the prompt's inherent prediction for the task-related classes, but also for other classes in the VLM vocabulary. Existing methods still address this problem by using traditional anti-overfitting techniques such as early stopping and data augmentation, which lack a principled solution specific to prompt. We present Prompt-aligned Gradient, dubbed ProGrad, to prevent prompt tuning from forgetting the the general knowledge learned from VLMs. In particular, ProGrad only updates the prompt whose gradient is aligned (or non-conflicting) to the \"general direction\", which is represented as the gradient of the KL loss of the pre-defined prompt prediction. Extensive experiments demonstrate the stronger few-shot generalization ability of ProGrad over state-of-the-art prompt tuning methods. Codes are available at https://github.com/BeierZhu/Prompt-align.",
    "source": "arXiv"
  },
  {
    "title": "Parameterized Approaches to Orthogonal Compaction",
    "title_es": "Parameterized Approaches to Orthogonal Compaction",
    "url": "https://arxiv.org/abs/2210.05019",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2210.05019v2 Announce Type: replace \nAbstract: Orthogonal graph drawings are used in applications such as UML diagrams, VLSI layout, cable plans, and metro maps. We focus on drawing planar graphs and assume that we are given an \\emph{orthogonal representation} that describes the desired shape, but not the exact coordinates of a drawing. Our aim is to compute an orthogonal drawing on the grid that has minimum area among all grid drawings that adhere to the given orthogonal representation.\n  This problem is called orthogonal compaction (OC) and is known to be NP-hard, even for orthogonal representations of cycles [Evans et al., 2022]. We investigate the complexity of OC with respect to several parameters. Among others, we show that OC is fixed-parameter tractable with respect to the most natural of these parameters, namely, the number of \\emph{kitty corners} of the orthogonal representation: the presence of pairs of kitty corners in an orthogonal representation makes the OC problem hard. Informally speaking, a pair of kitty corners is a pair of reflex corners of a face that point at each other. Accordingly, the number of kitty corners is the number of corners that are involved in some pair of kitty corners.",
    "source": "arXiv"
  },
  {
    "title": "LEAVES: Learning Views for Time-Series Biobehavioral Data in Contrastive Learning",
    "title_es": "LEAVES: Learning Views for Time-Series Biobehavioral Data in Contrastive Learning",
    "url": "https://arxiv.org/abs/2210.07340",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2210.07340v2 Announce Type: replace \nAbstract: Contrastive learning has been utilized as a promising self-supervised learning approach to extract meaningful representations from unlabeled data. The majority of these methods take advantage of data-augmentation techniques to create diverse views from the original input. However, optimizing augmentations and their parameters for generating more effective views in contrastive learning frameworks is often resource-intensive and time-consuming. While several strategies have been proposed for automatically generating new views in computer vision, research in other domains, such as time-series biobehavioral data, remains limited. In this paper, we introduce a simple yet powerful module for automatic view generation in contrastive learning frameworks applied to time-series biobehavioral data, which is essential for modern health care, termed learning views for time-series data (LEAVES). This proposed module employs adversarial training to learn augmentation hyperparameters within contrastive learning frameworks. We assess the efficacy of our method on multiple time-series datasets using two well-known contrastive learning frameworks, namely SimCLR and BYOL. Across four diverse biobehavioral datasets, LEAVES requires only approximately 20 learnable parameters -- dramatically fewer than the about 580k parameters demanded by frameworks like ViewMaker, a previously proposed adversarially trained convolutional module in contrastive learning, while achieving competitive and often superior performance to existing baseline methods. Crucially, these efficiency gains are obtained without extensive manual hyperparameter tuning, which makes LEAVES particularly suitable for large-scale or real-time healthcare applications that demand both accuracy and practicality.",
    "source": "arXiv"
  },
  {
    "title": "Debiased Fine-Tuning for Vision-language Models by Prompt Regularization",
    "title_es": "Debiased Fine-Tuning for Vision-language Models by Prompt Regularization",
    "url": "https://arxiv.org/abs/2301.12429",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2301.12429v3 Announce Type: replace \nAbstract: We present a new paradigm for fine-tuning large-scale visionlanguage pre-trained models on downstream task, dubbed Prompt Regularization (ProReg). Different from traditional fine-tuning which easily overfits to the downstream task data, ProReg uses the prediction by prompting the pretrained model to regularize the fine-tuning. The motivation is: by prompting the large model \"a photo of a [CLASS]\", the fil-lin answer is only dependent on the pretraining encyclopedic knowledge while independent of the task data distribution, which is usually biased. Specifically, given a training sample prediction during fine-tuning, we first calculate its KullbackLeibler loss of the prompt prediction and Cross-Entropy loss of the ground-truth label, and then combine them with a proposed sample-wise adaptive trade-off weight, which automatically adjusts the transfer between the pretrained and downstream domains. On various out-of-distribution benchmarks, we show the consistently strong performance of ProReg compared with conventional fine-tuning, zero-shot prompt, prompt tuning, and other state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "A Nystr\\\"{o}m Method for Scattering by a Two-layered Medium with a Rough Boundary",
    "title_es": "A Nystr\\\"{o}m Method for Scattering by a Two-layered Medium with a Rough Boundary",
    "url": "https://arxiv.org/abs/2303.02339",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2303.02339v5 Announce Type: replace \nAbstract: This paper is concerned with problems of scattering of time-harmonic acoustic waves by a two-layered medium with a non-locally perturbed boundary (called a rough boundary in this paper) in two dimensions, where a Dirichlet or impedance boundary condition is imposed on the boundary. The two-layered medium is composed of two unbounded media with different physical properties and the interface between the two media is considered to be a planar surface. We formulate the scattering problems considered as boundary value problems and prove the result of the well-posedness of each boundary value problem by utilizing the integral equation method associated with the two-layered Green function. Moreover, we develop a Nystr\\\"{o}m method for numerically solving the boundary value problems considered, based on the proposed integral equation formulations. We establish the convergence results of the Nystr\\\"{o}m method with the convergence rates depending on the smoothness of the rough boundary. It is worth noting that in establishing the well-posedness of the boundary value problems as well as the convergence results of the Nystr\\\"{o}m method, an essential role is played by the investigation of the asymptotic properties of the two-layered Green function for small and large arguments. Finally, numerical experiments are carried out to show the effectiveness of the Nystr\\\"{o}m method.",
    "source": "arXiv"
  },
  {
    "title": "From Stars to Insights: Exploration and Implementation of Unified Sentiment Analysis with Distant Supervision",
    "title_es": "From Stars to Insights: Exploration and Implementation of Unified Sentiment Analysis with Distant Supervision",
    "url": "https://arxiv.org/abs/2305.01710",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2305.01710v4 Announce Type: replace \nAbstract: Sentiment analysis is integral to understanding the voice of the customer and informing businesses' strategic decisions. Conventional sentiment analysis involves three separate tasks: aspect-category detection, aspect-category sentiment analysis, and rating prediction. However, independently tackling these tasks can overlook their interdependencies and often requires expensive, fine-grained annotations. This paper introduces unified sentiment analysis, a novel learning paradigm that integrates the three aforementioned tasks into a coherent framework. To achieve this, we propose the Distantly Supervised Pyramid Network (DSPN), which employs a pyramid structure to capture sentiment at word, aspect, and document levels in a hierarchical manner. Evaluations on multi-aspect review datasets in English and Chinese show that DSPN, using only star rating labels for supervision, demonstrates significant efficiency advantages while performing comparably well to a variety of benchmark models. Additionally, DSPN's pyramid structure enables the interpretability of its outputs. Our findings validate DSPN's effectiveness and efficiency, establishing a robust, resource-efficient, unified framework for sentiment analysis.",
    "source": "arXiv"
  },
  {
    "title": "Speedup of Distributed Algorithms for Power Graphs in the CONGEST Model",
    "title_es": "Speedup of Distributed Algorithms for Power Graphs in the CONGEST Model",
    "url": "https://arxiv.org/abs/2305.04358",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2305.04358v2 Announce Type: replace \nAbstract: We obtain improved distributed algorithms in the CONGEST message-passing setting for problems on power graphs of an input graph $G$. This includes Coloring, Maximal Independent Set, and related problems. We develop a general deterministic technique that transforms R-round algorithms for $G$ with certain properties into $O(R \\cdot \\Delta^{k/2 - 1})$-round algorithms for $G^k$. This improves the previously-known running time for such transformation, which was $O(R \\cdot \\Delta^{k - 1})$. Consequently, for problems that can be solved by algorithms with the required properties and within polylogarithmic number of rounds, we obtain {quadratic} improvement for $G^k$ and {exponential} improvement for $G^2$. We also obtain significant improvements for problems with larger number of rounds in $G$.",
    "source": "arXiv"
  },
  {
    "title": "Forecasting steam mass flow in power plants using the parallel hybrid network",
    "title_es": "Forecasting steam mass flow in power plants using the parallel hybrid network",
    "url": "https://arxiv.org/abs/2307.09483",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2307.09483v3 Announce Type: replace \nAbstract: Efficient and sustainable power generation is a crucial concern in the energy sector. In particular, thermal power plants grapple with accurately predicting steam mass flow, which is crucial for operational efficiency and cost reduction. In this study, we use a parallel hybrid neural network architecture that combines a parametrized quantum circuit and a conventional feed-forward neural network specifically designed for time-series prediction in industrial settings to enhance predictions of steam mass flow 15 minutes into the future. Our results show that the parallel hybrid model outperforms standalone classical and quantum models, achieving more than 5.7 and 4.9 times lower mean squared error loss on the test set after training compared to pure classical and pure quantum networks, respectively. Furthermore, the hybrid model demonstrates smaller relative errors between the ground truth and the model predictions on the test set, up to 2 times better than the pure classical model. These findings contribute to the broader scientific understanding of how integrating quantum and classical machine learning techniques can be applied to real-world challenges faced by the energy sector, ultimately leading to optimized power plant operations. To our knowledge, this study constitutes the first parallel hybrid quantum-classical architecture deployed on a real-world power-plant dataset, illustrating how near-term quantum resources can already augment classical analytics in the energy sector.",
    "source": "arXiv"
  },
  {
    "title": "Hummingbird: Fast, Flexible, and Fair Inter-Domain Bandwidth Reservations",
    "title_es": "Hummingbird: Fast, Flexible, and Fair Inter-Domain Bandwidth Reservations",
    "url": "https://arxiv.org/abs/2308.09959",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2308.09959v4 Announce Type: replace \nAbstract: The current Internet lacks quality-of-service guarantees for real-time applications like video calls and gaming, cloud-based systems, financial transactions, telesurgery, and other remote applications that benefit from reliable communication. To address this problem, this paper introduces Hummingbird: a novel, lightweight bandwidth-reservation system that provides fine-grained inter-domain reservations for end hosts and introduces several improvements over previous designs.\n  Hummingbird enables flexible and composable reservations with end-to-end guarantees, and addresses an often overlooked, but crucial, aspect of bandwidth reservation systems: incentivization of network providers. Hummingbird represents bandwidth reservations as tradeable assets which allows markets to emerge that ensure fair and efficient resource allocation and encourage deployment by remunerating providers. This incentivization is facilitated by decoupling reservations from network identities, which enables novel control-plane mechanisms and allows us to design a control plane based on smart contracts.\n  Hummingbird also provides an efficient reservation data plane which streamlines the processing on routers and thus simplifies the implementation, deployment, and traffic policing while maintaining robust security properties.",
    "source": "arXiv"
  },
  {
    "title": "Ear-Keeper: A Cross-Platform AI System for Rapid and Accurate Ear Disease Diagnosis",
    "title_es": "Ear-Keeper: A Cross-Platform AI System for Rapid and Accurate Ear Disease Diagnosis",
    "url": "https://arxiv.org/abs/2308.10610",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2308.10610v5 Announce Type: replace \nAbstract: Early and accurate detection systems for ear diseases, powered by deep learning, are essential for preventing hearing impairment and improving population health. However, the limited diversity of existing otoendoscopy datasets and the poor balance between diagnostic accuracy, computational efficiency, and model size have hindered the translation of artificial intelligence (AI) algorithms into healthcare applications. In this study, we constructed a large-scale, multi-center otoendoscopy dataset covering eight common ear diseases and healthy cases. Building upon this resource, we developed Best-EarNet, an ultrafast and lightweight deep learning architecture integrating a novel Local-Global Spatial Feature Fusion Module with a multi-scale supervision strategy, enabling real-time and accurate classification of ear conditions. Leveraging transfer learning, Best-EarNet, with a model size of only 2.94 MB, achieved diagnostic accuracies of 95.23% on an internal test set (22,581 images) and 92.14% on an external test set (1,652 images), while requiring only 0.0125 seconds (80 frames per second) to process a single image on a standard CPU. Further subgroup analysis by gender and age showed consistently excellent performance of Best-EarNet across all demographic groups. To enhance clinical interpretability and user trust, we incorporated Grad-CAM-based visualization, highlighting the specific abnormal ear regions contributing to AI predictions. Most importantly, we developed Ear-Keeper, a cross-platform intelligent diagnosis system built upon Best-EarNet, deployable on smartphones, tablets, and personal computers. Ear-Keeper enables public users and healthcare providers to perform comprehensive real-time video-based ear canal screening, supporting early detection and timely intervention of ear diseases.",
    "source": "arXiv"
  },
  {
    "title": "TinyMPC: Model-Predictive Control on Resource-Constrained Microcontrollers",
    "title_es": "TinyMPC: Model-Predictive Control on Resource-Constrained Microcontrollers",
    "url": "https://arxiv.org/abs/2310.16985",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2310.16985v4 Announce Type: replace \nAbstract: Model-predictive control (MPC) is a powerful tool for controlling highly dynamic robotic systems subject to complex constraints. However, MPC is computationally demanding, and is often impractical to implement on small, resource-constrained robotic platforms. We present TinyMPC, a high-speed MPC solver with a low memory footprint targeting the microcontrollers common on small robots. Our approach is based on the alternating direction method of multipliers (ADMM) and leverages the structure of the MPC problem for efficiency. We demonstrate TinyMPC's effectiveness by benchmarking against the state-of-the-art solver OSQP, achieving nearly an order of magnitude speed increase, as well as through hardware experiments on a 27 gram quadrotor, demonstrating high-speed trajectory tracking and dynamic obstacle avoidance. TinyMPC is publicly available at https://tinympc.org.",
    "source": "arXiv"
  },
  {
    "title": "Semi-Bandit Learning for Monotone Stochastic Optimization",
    "title_es": "Semi-Bandit Learning for Monotone Stochastic Optimization",
    "url": "https://arxiv.org/abs/2312.15427",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2312.15427v2 Announce Type: replace \nAbstract: Stochastic optimization is a widely used approach for optimization under uncertainty, where uncertain input parameters are modeled by random variables. Exact or approximation algorithms have been obtained for several fundamental problems in this area. However, a significant limitation of this approach is that it requires full knowledge of the underlying probability distributions. Can we still get good (approximation) algorithms if these distributions are unknown, and the algorithm needs to learn them through repeated interactions? In this paper, we resolve this question for a large class of ''monotone'' stochastic problems, by providing a generic online learning algorithm with $\\sqrt{T\\log(T)}$ regret relative to the best approximation algorithm (under known distributions). Importantly, our online algorithm works in a semi-bandit setting, where in each period, the algorithm only observes samples from the random variables that were actually probed. Moreover, our result extends to settings with censored and binary feedback, where the policy only observes truncated or thresholded versions of the probed variables. Our framework applies to several fundamental problems such as prophet inequality, Pandora's box, stochastic knapsack, single-resource revenue management and sequential posted pricing.",
    "source": "arXiv"
  },
  {
    "title": "Solving multiscale dynamical systems by deep learning",
    "title_es": "Solving multiscale dynamical systems by deep learning",
    "url": "https://arxiv.org/abs/2401.01220",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2401.01220v3 Announce Type: replace \nAbstract: Multiscale dynamical systems, modeled by high-dimensional stiff ordinary differential equations (ODEs) with wide-ranging characteristic timescales, arise across diverse fields of science and engineering, but their numerical solvers often encounter severe efficiency bottlenecks. This paper introduces a novel DeePODE method, which consists of an Evolutionary Monte Carlo Sampling method (EMCS) and an efficient end-to-end deep neural network (DNN) to predict multiscale dynamical systems. We validate this finding across dynamical systems from ecological systems to reactive flows, including a predator-prey model, a power system oscillation, a battery electrolyte thermal runaway, and turbulent reaction-diffusion systems with complex chemical kinetics. The method demonstrates robust generalization capabilities, allowing pre-trained DNN models to accurately predict the behavior in previously unseen scenarios, largely due to the delicately constructed dataset. While theoretical guarantees remain to be established, empirical evidence shows that DeePODE achieves the accuracy of implicit numerical schemes while maintaining the computational efficiency of explicit schemes. This work underscores the crucial relationship between training data distribution and neural network generalization performance. This work demonstrates the potential of deep learning approaches in modeling complex dynamical systems across scientific and engineering domains.",
    "source": "arXiv"
  },
  {
    "title": "Asymptotic performance of double and four circulant codes with small hull dimension",
    "title_es": "Asymptotic performance of double and four circulant codes with small hull dimension",
    "url": "https://arxiv.org/abs/2401.07017",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2401.07017v5 Announce Type: replace \nAbstract: We study the asymptotic behavior of double and four circulant codes, which are quasi-cyclic codes of index two and four respectively. Exact enumeration results are derived for these families of codes with the prescribed hull dimension. These formulas, in turn, are the most used tools to prove the good behavior of double circulant and four circulant codes asymptotically. Computational results on the code families in consideration are provided as well.",
    "source": "arXiv"
  },
  {
    "title": "FROST-BRDF: A Fast and Robust Optimal Sampling Technique for BRDF Acquisition",
    "title_es": "FROST-BRDF: A Fast and Robust Optimal Sampling Technique for BRDF Acquisition",
    "url": "https://arxiv.org/abs/2401.07283",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2401.07283v2 Announce Type: replace \nAbstract: Efficient and accurate BRDF acquisition of real world materials is a challenging research problem that requires sampling millions of incident light and viewing directions. To accelerate the acquisition process, one needs to find a minimal set of sampling directions such that the recovery of the full BRDF is accurate and robust given such samples. In this paper, we formulate BRDF acquisition as a compressed sensing problem, where the sensing operator is one that performs sub-sampling of the BRDF signal according to a set of optimal sample directions. To solve this problem, we propose the Fast and Robust Optimal Sampling Technique (FROST) for designing a provably optimal sub-sampling operator that places light-view samples such that the recovery error is minimized. FROST casts the problem of designing an optimal sub-sampling operator for compressed sensing into a sparse representation formulation under the Multiple Measurement Vector (MMV) signal model. The proposed reformulation is exact, i.e. without any approximations, hence it converts an intractable combinatorial problem into one that can be solved with standard optimization techniques. As a result, FROST is accompanied by strong theoretical guarantees from the field of compressed sensing. We perform a thorough analysis of FROST-BRDF using a 10-fold cross-validation with publicly available BRDF datasets and show significant advantages compared to the state-of-the-art with respect to reconstruction quality. Finally, FROST is simple, both conceptually and in terms of implementation, it produces consistent results at each run, and it is at least two orders of magnitude faster than the prior art.",
    "source": "arXiv"
  },
  {
    "title": "STAC: Leveraging Spatio-Temporal Data Associations For Efficient Cross-Camera Streaming and Analytics",
    "title_es": "STAC: Leveraging Spatio-Temporal Data Associations For Efficient Cross-Camera Streaming and Analytics",
    "url": "https://arxiv.org/abs/2401.15288",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2401.15288v2 Announce Type: replace \nAbstract: In IoT based distributed network of cameras, real-time multi-camera video analytics is challenged by high bandwidth demands and redundant visual data, creating a fundamental tension where reducing data saves network overhead but can degrade model performance, and vice versa. We present STAC, a cross-cameras surveillance system that leverages spatio-temporal associations for efficient object tracking under constrained network conditions. STAC integrates multi-resolution feature learning, ensuring robustness under variable networked system level optimizations such as frame filtering, FFmpeg-based compression, and Region-of-Interest (RoI) masking, to eliminate redundant content across distributed video streams while preserving downstream model accuracy for object identification and tracking. Evaluated on NVIDIA's AICity Challenge dataset, STAC achieves a 76\\% improvement in tracking accuracy and an 8.6x reduction in inference latency over a standard multi-object multi-camera tracking baseline (using YOLOv4 and DeepSORT). Furthermore, 29\\% of redundant frames are filtered, significantly reducing data volume without compromising inference quality.",
    "source": "arXiv"
  },
  {
    "title": "Keyframer: Empowering Animation Design using Large Language Models",
    "title_es": "Keyframer: Empowering Animation Design using Large Language Models",
    "url": "https://arxiv.org/abs/2402.06071",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2402.06071v2 Announce Type: replace \nAbstract: Creating 2D animations is a complex, iterative process requiring continuous adjustments to movement, timing, and coordination of multiple elements within a scene. To support designers of varying levels of experience with animation design and implementation, we developed Keyframer, a design tool that generates animation code in response to natural language prompts, enabling users to preview rendered animations inline and edit them directly through provided editors. Through a user study with 13 novices and experts in animation design and programming, we contribute 1) a categorization of semantic prompt types for describing motion and identification of a 'decomposed' prompting style where users continually adapt their goals in response to generated output; and 2) design insights on supporting iterative refinement of animations through the combination of direct editing and natural language interfaces.",
    "source": "arXiv"
  },
  {
    "title": "ABIDES-Economist: Agent-Based Simulator of Economic Systems with Learning Agents",
    "title_es": "ABIDES-Economist: Agent-Based Simulator of Economic Systems with Learning Agents",
    "url": "https://arxiv.org/abs/2402.09563",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2402.09563v2 Announce Type: replace \nAbstract: We present ABIDES-Economist, an agent-based simulator for economic systems that includes heterogeneous households, firms, a central bank, and a government. Agent behavior can be defined using domain-specific behavioral rules or learned through reinforcement learning by specifying their objectives. We integrate reinforcement learning capabilities for all agents using the OpenAI Gym environment framework for the multi-agent system. To enhance the realism of our model, we base agent parameters and action spaces on economic literature and real U.S. economic data. To tackle the challenges of calibrating heterogeneous agent-based economic models, we conduct a comprehensive survey of stylized facts related to both microeconomic and macroeconomic time series data. We then validate ABIDES-Economist by demonstrating its ability to generate simulated data that aligns with the relevant stylized facts for the economic scenario under consideration, following the learning of all agent behaviors via reinforcement learning. Specifically, we train our economic agents' policies under two broad configurations. The first configuration demonstrates that the learned economic agents produce system data consistent with macroeconomic and microeconomic stylized facts. The second configuration illustrates the utility of the validated simulation platform in designing regulatory policies for the central bank and government. These policies outperform standard rule-based approaches from the literature, which often overlook agent heterogeneity, shocks, and agent adaptability.",
    "source": "arXiv"
  },
  {
    "title": "Are you Struggling? Dataset and Baselines for Struggle Determination in Assembly Videos",
    "title_es": "Are you Struggling? Dataset and Baselines for Struggle Determination in Assembly Videos",
    "url": "https://arxiv.org/abs/2402.11057",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2402.11057v5 Announce Type: replace \nAbstract: Determining when people are struggling allows for a finer-grained understanding of actions that complements conventional action classification and error detection. Struggle detection, as defined in this paper, is a distinct and important task that can be identified without explicit step or activity knowledge. We introduce the first struggle dataset with three real-world problem-solving activities that are labelled by both expert and crowd-source annotators. Video segments were scored w.r.t. their level of struggle using a forced choice 4-point scale. This dataset contains 5.1 hours of video from 73 participants. We conducted a series of experiments to identify the most suitable modelling approaches for struggle determination. Additionally, we compared various deep learning models, establishing baseline results for struggle classification, struggle regression, and struggle label distribution learning. Our results indicate that struggle detection in video can achieve up to $88.24\\%$ accuracy in binary classification, while detecting the level of struggle in a four-way classification setting performs lower, with an overall accuracy of $52.45\\%$. Our work is motivated toward a more comprehensive understanding of action in video and potentially the improvement of assistive systems that analyse struggle and can better support users during manual activities.",
    "source": "arXiv"
  },
  {
    "title": "Discrete Neural Algorithmic Reasoning",
    "title_es": "Discrete Neural Algorithmic Reasoning",
    "url": "https://arxiv.org/abs/2402.11628",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2402.11628v3 Announce Type: replace \nAbstract: Neural algorithmic reasoning aims to capture computations with neural networks by training models to imitate the execution of classical algorithms. While common architectures are expressive enough to contain the correct model in the weight space, current neural reasoners struggle to generalize well on out-of-distribution data. On the other hand, classical computations are not affected by distributional shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. To achieve this, we separate discrete and continuous data flows and describe the interaction between them. Trained with supervision on the algorithm's state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on multiple algorithmic problems and achieve perfect test scores both in single-task and multitask setups. Moreover, the proposed architectural choice allows us to prove the correctness of the learned algorithms for any test data.",
    "source": "arXiv"
  },
  {
    "title": "Learning to Defer in Congested Systems: The AI-Human Interplay",
    "title_es": "Learning to Defer in Congested Systems: The AI-Human Interplay",
    "url": "https://arxiv.org/abs/2402.12237",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2402.12237v4 Announce Type: replace \nAbstract: High-stakes applications rely on combining Artificial Intelligence (AI) and humans for responsive and reliable decision making. For example, content moderation in social media platforms often employs an AI-human pipeline to promptly remove policy violations without jeopardizing legitimate content. A typical heuristic estimates the risk of incoming content and uses fixed thresholds to decide whether to auto-delete the content (classification) and whether to send it for human review (admission). This approach can be inefficient as it disregards the uncertainty in AI's estimation, the time-varying element of content arrivals and human review capacity, and the selective sampling in the online dataset (humans only review content filtered by the AI).\n  In this paper, we introduce a model to capture such an AI-human interplay. In this model, the AI observes contextual information for incoming jobs, makes classification and admission decisions, and schedules admitted jobs for human review. During these reviews, humans observe a job's true cost and may overturn an erroneous AI classification decision. These reviews also serve as new data to train the AI but are delayed due to congestion in the human review system. The objective is to minimize the costs of eventually misclassified jobs.\n  We propose a near-optimal learning algorithm that carefully balances the classification loss from a selectively sampled dataset, the idiosyncratic loss of non-reviewed jobs, and the delay loss of having congestion in the human review system. To the best of our knowledge, this is the first result for online learning in contextual queueing systems. Moreover, numerical experiments based on online comment datasets show that our algorithm can substantially reduce the number of misclassifications compared to existing content moderation practice.",
    "source": "arXiv"
  },
  {
    "title": "Investigating Human Values in Online Communities",
    "title_es": "Investigating Human Values in Online Communities",
    "url": "https://arxiv.org/abs/2402.14177",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2402.14177v4 Announce Type: replace \nAbstract: Studying human values is instrumental for cross-cultural research, enabling a better understanding of preferences and behaviour of society at large and communities therein. To study the dynamics of communities online, we propose a method to computationally analyse values present on Reddit. Our method allows analysis at scale, complementing survey based approaches. We train a value relevance and a value polarity classifier, which we thoroughly evaluate using in-domain and out-of-domain human annotations. Using these, we automatically annotate over six million posts across 12k subreddits with Schwartz values. Our analysis unveils both previously recorded and novel insights into the values prevalent within various online communities. For instance, we discover a very negative stance towards conformity in the Vegan and AbolishTheMonarchy subreddits. Additionally, our study of geographically specific subreddits highlights the correlation between traditional values and conservative U.S. states. Through our work, we demonstrate how our dataset and method can be used as a complementary tool for qualitative study of online communication.",
    "source": "arXiv"
  },
  {
    "title": "Revisiting 3D Medical Scribble Supervision: Benchmarking Beyond Cardiac Segmentation",
    "title_es": "Revisiting 3D Medical Scribble Supervision: Benchmarking Beyond Cardiac Segmentation",
    "url": "https://arxiv.org/abs/2403.12834",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2403.12834v2 Announce Type: replace \nAbstract: Scribble supervision has emerged as a promising approach for reducing annotation costs in medical 3D segmentation by leveraging sparse annotations instead of voxel-wise labels. While existing methods report strong performance, a closer analysis reveals that the majority of research is confined to the cardiac domain, predominantly using ACDC and MSCMR datasets. This over-specialization has resulted in severe overfitting, misleading claims of performance improvements, and a lack of generalization across broader segmentation tasks. In this work, we formulate a set of key requirements for practical scribble supervision and introduce ScribbleBench, a comprehensive benchmark spanning over seven diverse medical imaging datasets, to systematically evaluate the fulfillment of these requirements. Consequently, we uncover a general failure of methods to generalize across tasks and that many widely used novelties degrade performance outside of the cardiac domain, whereas simpler overlooked approaches achieve superior generalization. Finally, we raise awareness for a strong yet overlooked baseline, nnU-Net coupled with a partial loss, which consistently outperforms specialized methods across a diverse range of tasks. By identifying fundamental limitations in existing research and establishing a new benchmark-driven evaluation standard, this work aims to steer scribble supervision toward more practical, robust, and generalizable methodologies for medical image segmentation.",
    "source": "arXiv"
  },
  {
    "title": "From Model Performance to Claim: How a Change of Focus in Machine Learning Replicability Can Help Bridge the Responsibility Gap",
    "title_es": "From Model Performance to Claim: How a Change of Focus in Machine Learning Replicability Can Help Bridge the Responsibility Gap",
    "url": "https://arxiv.org/abs/2404.13131",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2404.13131v2 Announce Type: replace \nAbstract: Two goals - improving replicability and accountability of Machine Learning research respectively, have accrued much attention from the AI ethics and the Machine Learning community. Despite sharing the measures of improving transparency, the two goals are discussed in different registers - replicability registers with scientific reasoning whereas accountability registers with ethical reasoning. Given the existing challenge of the Responsibility Gap - holding Machine Learning scientists accountable for Machine Learning harms due to them being far from sites of application, this paper posits that reconceptualizing replicability can help bridge the gap. Through a shift from model performance replicability to claim replicability, Machine Learning scientists can be held accountable for producing non-replicable claims that are prone to eliciting harm due to misuse and misinterpretation. In this paper, I make the following contributions. First, I define and distinguish two forms of replicability for ML research that can aid constructive conversations around replicability. Second, I formulate an argument for claim-replicability's advantage over model performance replicability in justifying assigning accountability to Machine Learning scientists for producing non-replicable claims and show how it enacts a sense of responsibility that is actionable. In addition, I characterize the implementation of claim replicability as more of a social project than a technical one by discussing its competing epistemological principles, practical implications on Circulating Reference, Interpretative Labor, and research communication.",
    "source": "arXiv"
  },
  {
    "title": "A Note on Approximating Weighted Nash Social Welfare with Additive Valuations",
    "title_es": "A Note on Approximating Weighted Nash Social Welfare with Additive Valuations",
    "url": "https://arxiv.org/abs/2404.15607",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2404.15607v3 Announce Type: replace \nAbstract: We give the first $O(1)$-approximation for the weighted Nash Social Welfare problem with additive valuations. The approximation ratio we obtain is $e^{1/e} + \\epsilon \\approx 1.445 + \\epsilon$, which matches the best known approximation ratio for the unweighted case.\n  Both our algorithm and analysis are simple. We solve a natural configuration LP for the problem, and obtain the allocation of items to agents using a randomized version of the Shmoys-Tardos rounding algorithm developed for unrelated machine scheduling problems. In the analysis, we show that the approximation ratio of the algorithm is at most the worst gap between the Nash social welfare of the optimum allocation and that of an EF1 allocation, for an unweighted Nash Social Welfare instance with identical additive valuations. This was shown to be at most $e^{1/e} \\approx 1.445$ by Barman, Krishnamurthy and Vaish, leading to our approximation ratio.",
    "source": "arXiv"
  },
  {
    "title": "Model Poisoning Attacks to Federated Learning via Multi-Round Consistency",
    "title_es": "Model Poisoning Attacks to Federated Learning via Multi-Round Consistency",
    "url": "https://arxiv.org/abs/2404.15611",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2404.15611v3 Announce Type: replace \nAbstract: Model poisoning attacks are critical security threats to Federated Learning (FL). Existing model poisoning attacks suffer from two key limitations: 1) they achieve suboptimal effectiveness when defenses are deployed, and/or 2) they require knowledge of the model updates or local training data on genuine clients. In this work, we make a key observation that their suboptimal effectiveness arises from only leveraging model-update consistency among malicious clients within individual training rounds, making the attack effect self-cancel across training rounds. In light of this observation, we propose PoisonedFL, which enforces multi-round consistency among the malicious clients' model updates while not requiring any knowledge about the genuine clients. Our empirical evaluation on five benchmark datasets shows that PoisonedFL breaks eight state-of-the-art defenses and outperforms seven existing model poisoning attacks. Moreover, we also explore new defenses that are tailored to PoisonedFL, but our results show that we can still adapt PoisonedFL to break them. Our study shows that FL systems are considerably less robust than previously thought, underlining the urgency for the development of new defense mechanisms.",
    "source": "arXiv"
  },
  {
    "title": "ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with Probability Map Guided Multi-Format Feature Fusion",
    "title_es": "ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with Probability Map Guided Multi-Format Feature Fusion",
    "url": "https://arxiv.org/abs/2405.05164",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2405.05164v5 Announce Type: replace \nAbstract: Millimeter wave (mmWave) radar is a non-intrusive privacy and relatively convenient and inexpensive device, which has been demonstrated to be applicable in place of RGB cameras in human indoor pose estimation tasks. However, mmWave radar relies on the collection of reflected signals from the target, and the radar signals containing information is difficult to be fully applied. This has been a long-standing hindrance to the improvement of pose estimation accuracy. To address this major challenge, this paper introduces a probability map guided multi-format feature fusion model, ProbRadarM3F. This is a novel radar feature extraction framework using a traditional FFT method in parallel with a probability map based positional encoding method. ProbRadarM3F fuses the traditional heatmap features and the positional features, then effectively achieves the estimation of 14 keypoints of the human body. Experimental evaluation on the HuPR dataset proves the effectiveness of the model proposed in this paper, outperforming other methods experimented on this dataset with an AP of 69.9 %. The emphasis of our study is focusing on the position information that is not exploited before in radar singal. This provides direction to investigate other potential non-redundant information from mmWave rader.",
    "source": "arXiv"
  },
  {
    "title": "No-Regret M${}^{\\natural}$-Concave Function Maximization: Stochastic Bandit Algorithms and Hardness of Adversarial Full-Information Setting",
    "title_es": "No-Regret M${}^{\\natural}$-Concave Function Maximization: Stochastic Bandit Algorithms and Hardness of Adversarial Full-Information Setting",
    "url": "https://arxiv.org/abs/2405.12439",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2405.12439v2 Announce Type: replace \nAbstract: M${}^{\\natural}$-concave functions, a.k.a. gross substitute valuation functions, play a fundamental role in many fields, including discrete mathematics and economics. In practice, perfect knowledge of M${}^{\\natural}$-concave functions is often unavailable a priori, and we can optimize them only interactively based on some feedback. Motivated by such situations, we study online M${}^{\\natural}$-concave function maximization problems, which are interactive versions of the problem studied by Murota and Shioura (1999). For the stochastic bandit setting, we present $O(T^{-1/2})$-simple regret and $O(T^{2/3})$-regret algorithms under $T$ times access to unbiased noisy value oracles of M${}^{\\natural}$-concave functions. A key to proving these results is the robustness of the greedy algorithm to local errors in M${}^{\\natural}$-concave function maximization, which is one of our main technical results. While we obtain those positive results for the stochastic setting, another main result of our work is an impossibility in the adversarial setting. We prove that, even with full-information feedback, no algorithms that run in polynomial time per round can achieve $O(T^{1-c})$ regret for any constant $c > 0$. Our proof is based on a reduction from the matroid intersection problem for three matroids, which would be a novel approach to establishing the hardness in online learning.",
    "source": "arXiv"
  },
  {
    "title": "Sparse Spectral Training and Inference on Euclidean and Hyperbolic Neural Networks",
    "title_es": "Sparse Spectral Training and Inference on Euclidean and Hyperbolic Neural Networks",
    "url": "https://arxiv.org/abs/2405.15481",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2405.15481v3 Announce Type: replace \nAbstract: The growing demands on GPU memory posed by the increasing number of neural network parameters call for training approaches that are more memory-efficient. Previous memory reduction training techniques, such as Low-Rank Adaptation (LoRA) and ReLoRA, face challenges, with LoRA being constrained by its low-rank structure, particularly during intensive tasks like pre-training, and ReLoRA suffering from saddle point issues. In this paper, we propose Sparse Spectral Training (SST) to optimize memory usage for pre-training. SST updates all singular values and selectively updates singular vectors through a multinomial sampling method weighted by the magnitude of the singular values. Furthermore, SST employs singular value decomposition to initialize and periodically reinitialize low-rank parameters, reducing distortion relative to full-rank training compared to other low-rank methods. Through comprehensive testing on both Euclidean and hyperbolic neural networks across various tasks, SST demonstrates its ability to outperform existing memory reduction training methods and is comparable to full-rank training in various cases. On LLaMA-1.3B, with only 18.7\\% of the parameters trainable compared to full-rank training (using a rank equivalent to 6\\% of the embedding dimension), SST reduces the perplexity gap between other low-rank methods and full-rank training by 97.4\\%. This result highlights SST as an effective parameter-efficient technique for model pre-training.",
    "source": "arXiv"
  },
  {
    "title": "Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning Code LLMs",
    "title_es": "Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning Code LLMs",
    "url": "https://arxiv.org/abs/2405.20179",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2405.20179v4 Announce Type: replace \nAbstract: Code LLMs have shown promising results with converting tasks in natural language to programs that can be executed by service robots. We are interested in finetuning small, specialized LLMs for this purpose, but collecting datasets of task-program pairs specific to each robot is time-consuming and expensive. While approaches such as SELF-INSTRUCT and EVOL-INSTRUCT are capable of generating novel tasks given a few examples, they are unable to provide the corresponding programs that correctly abide by physical-world and robot-constraints using the provided programming interface. Using a simulator is a natural potential solution to checking for such constraints, but building simulation environments that can handle arbitrary tasks and their necessary objects and locations, is challenging. To address these challenges, we introduce ROBO-INSTRUCT, which synthesizes task-specific simulation environments on the fly during program execution, by opportunistically inferring entity properties and enforcing corresponding constraints based on how the entities are used in the task program. Additionally, ROBO-INSTRUCT integrates an LLM-aided post-processing procedure to refine instructions for better alignment with robot programs. We demonstrate the effectiveness of ROBO-INSTRUCT across multiple LLMs, showing that our fine-tuned models outperform all baseline methods and even match or surpass the performance of several larger and proprietary models.",
    "source": "arXiv"
  },
  {
    "title": "Towards Black-Box Membership Inference Attack for Diffusion Models",
    "title_es": "Towards Black-Box Membership Inference Attack for Diffusion Models",
    "url": "https://arxiv.org/abs/2405.20771",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2405.20771v5 Announce Type: replace \nAbstract: Given the rising popularity of AI-generated art and the associated copyright concerns, identifying whether an artwork was used to train a diffusion model is an important research topic. The work approaches this problem from the membership inference attack (MIA) perspective. We first identify the limitation of applying existing MIA methods for proprietary diffusion models: the required access of internal U-nets. To address the above problem, we introduce a novel membership inference attack method that uses only the image-to-image variation API and operates without access to the model's internal U-net. Our method is based on the intuition that the model can more easily obtain an unbiased noise prediction estimate for images from the training set. By applying the API multiple times to the target image, averaging the outputs, and comparing the result to the original image, our approach can classify whether a sample was part of the training set. We validate our method using DDIM and Stable Diffusion setups and further extend both our approach and existing algorithms to the Diffusion Transformer architecture. Our experimental results consistently outperform previous methods.",
    "source": "arXiv"
  },
  {
    "title": "LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data",
    "title_es": "LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data",
    "url": "https://arxiv.org/abs/2406.09864",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2406.09864v3 Announce Type: replace \nAbstract: Multimodal Deep Learning enhances decision-making by integrating diverse information sources, such as texts, images, audio, and videos. To develop trustworthy multimodal approaches, it is essential to understand how uncertainty impacts these models. We propose LUMA, a unique multimodal dataset, featuring audio, image, and textual data from 50 classes, specifically designed for learning from uncertain data. It extends the well-known CIFAR 10/100 dataset with audio samples extracted from three audio corpora, and text data generated using the Gemma-7B Large Language Model (LLM). The LUMA dataset enables the controlled injection of varying types and degrees of uncertainty to achieve and tailor specific experiments and benchmarking initiatives. LUMA is also available as a Python package including the functions for generating multiple variants of the dataset with controlling the diversity of the data, the amount of noise for each modality, and adding out-of-distribution samples. A baseline pre-trained model is also provided alongside three uncertainty quantification methods: Monte-Carlo Dropout, Deep Ensemble, and Reliable Conflictive Multi-View Learning. This comprehensive dataset and its tools are intended to promote and support the development, evaluation, and benchmarking of trustworthy and robust multimodal deep learning approaches. We anticipate that the LUMA dataset will help the research community to design more trustworthy and robust machine learning approaches for safety critical applications. The code and instructions for downloading and processing the dataset can be found at: https://github.com/bezirganyan/LUMA/ .",
    "source": "arXiv"
  },
  {
    "title": "PrAViC: Probabilistic Adaptation Framework for Real-Time Video Classification",
    "title_es": "PrAViC: Probabilistic Adaptation Framework for Real-Time Video Classification",
    "url": "https://arxiv.org/abs/2406.11443",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2406.11443v2 Announce Type: replace \nAbstract: Video processing is generally divided into two main categories: processing of the entire video, which typically yields optimal classification outcomes, and real-time processing, where the objective is to make a decision as promptly as possible. Although the models dedicated to the processing of entire videos are typically well-defined and clearly presented in the literature, this is not the case for online processing, where a~plethora of hand-devised methods exist. To address this issue, we present PrAViC, a novel, unified, and theoretically-based adaptation framework for tackling the online classification problem in video data. The initial phase of our study is to establish a mathematical background for the classification of sequential data, with the potential to make a decision at an early stage. This allows us to construct a natural function that encourages the model to return a result much faster. The subsequent phase is to present a straightforward and readily implementable method for adapting offline models to the online setting using recurrent operations. Finally, PrAViC is evaluated by comparing it with existing state-of-the-art offline and online models and datasets. This enables the network to significantly reduce the time required to reach classification decisions while maintaining, or even enhancing, accuracy.",
    "source": "arXiv"
  },
  {
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "title_es": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "url": "https://arxiv.org/abs/2406.17588",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2406.17588v3 Announce Type: replace \nAbstract: The long-context capabilities of large language models (LLMs) have been a hot topic in recent years. To evaluate the performance of LLMs in different scenarios, various assessment benchmarks have emerged. However, as most of these benchmarks focus on identifying key information to answer questions, which mainly requires the retrieval ability of LLMs, these benchmarks can partially represent the reasoning performance of LLMs from large amounts of information. Meanwhile, although LLMs often claim to have context windows of 32k, 128k, 200k, or even longer, these benchmarks fail to reveal the actual supported length of these LLMs. To address these issues, we propose the LongIns benchmark dataset, a challenging long-context instruction-based exam for LLMs, which is built based on the existing instruction datasets. Specifically, in our LongIns, we introduce three evaluation settings: Global Instruction & Single Task (GIST), Local Instruction & Single Task (LIST), and Local Instruction & Multiple Tasks (LIMT). Based on LongIns, we perform comprehensive evaluations on existing LLMs and have the following important findings: (1). The top-performing GPT-4 with 128k context length performs poorly on the evaluation context window of 16k in our LongIns. (2). For the multi-hop reasoning ability of many existing LLMs, significant efforts are still needed under short context windows (less than 4k).",
    "source": "arXiv"
  },
  {
    "title": "Riemann-Oracle: A general-purpose Riemannian optimizer to solve nearness problems in matrix theory",
    "title_es": "Riemann-Oracle: A general-purpose Riemannian optimizer to solve nearness problems in matrix theory",
    "url": "https://arxiv.org/abs/2407.03957",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2407.03957v2 Announce Type: replace \nAbstract: We propose an extremely versatile approach to address a large family of matrix nearness problems, possibly with additional linear constraints. Our method is based on splitting a matrix nearness problem into two nested optimization problems, of which the inner one can be solved either exactly or cheaply, while the outer one can be recast as an unconstrained optimization task over a smooth real Riemannian manifold. We observe that this paradigm applies to many matrix nearness problems of practical interest appearing in the literature, thus revealing that they are equivalent in this sense to a Riemannian optimization problem. We also show that the objective function to be minimized on the Riemannian manifold can be discontinuous, thus requiring regularization techniques, and we give conditions for this to happen. Finally, we demonstrate the practical applicability of our method by implementing it for a number of matrix nearness problems that are relevant for applications and are currently considered very demanding in practice. Extensive numerical experiments demonstrate that our method often greatly outperforms its predecessors, including algorithms specifically designed for those particular problems.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Step Reasoning with Large Language Models, a Survey",
    "title_es": "Multi-Step Reasoning with Large Language Models, a Survey",
    "url": "https://arxiv.org/abs/2407.11511",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2407.11511v2 Announce Type: replace \nAbstract: Language models with billions of parameters exhibit in-context learning abilities, enabling few-shot learning on tasks that the model was not specifically trained for. Traditional models achieve breakthrough performance on language tasks, but do not perform well on basic reasoning benchmarks. However, a new in-context learning approach, Chain-of-thought, has demonstrated strong multi-step reasoning abilities on these benchmarks.\n  The research on LLM reasoning abilities started with the question whether LLMs can solve grade school math word problems, and has expanded to other tasks in the past few years. This paper reviews the field of multi-step reasoning with LLMs. We propose a taxonomy that identifies different ways to generate, evaluate, and control multi-step reasoning. We provide an in-depth coverage of core approaches and open problems, and we propose a research agenda for the near future.\n  We find that multi-step reasoning approaches have progressed beyond math word problems, and can now successfully solve challenges in logic, combinatorial games, and robotics, sometimes by first generating code that is then executed by external tools. Many studies in multi-step methods are using reinforcement learning for finetuning, external optimization loops, in context reinforcement learning, and self-reflection.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal LLM-based Query Paraphrasing for Video Search",
    "title_es": "Multimodal LLM-based Query Paraphrasing for Video Search",
    "url": "https://arxiv.org/abs/2407.12341",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2407.12341v2 Announce Type: replace \nAbstract: Text-to-video retrieval answers user queries through searches based on concepts and embeddings. However, due to limitations in the size of the concept bank and the amount of training data, answering queries in the wild is not always effective because of the out-of-vocabulary problem. Furthermore, neither concept-based nor embedding-based search can perform reasoning to consolidate search results for complex queries that include logical and spatial constraints. To address these challenges, we leverage large language models (LLMs) to paraphrase queries using text-to-text (T2T), text-to-image (T2I), and image-to-text (I2T) transformations. These transformations rephrase abstract concepts into simpler terms to mitigate the out-of-vocabulary problem. Additionally, complex relationships within a query can be decomposed into simpler sub-queries, improving retrieval performance by effectively fusing the search results of these sub-queries. To mitigate the issue of LLM hallucination, this paper also proposes a novel consistency-based verification strategy to filter out factually incorrect paraphrased queries. Extensive experiments are conducted for ad-hoc video search and known-item search on the TRECVid datasets. We provide empirical insights into how traditionally difficult-to-answer queries can be effectively resolved through query paraphrasing.",
    "source": "arXiv"
  },
  {
    "title": "Integrating Clinical Knowledge Graphs and Gradient-Based Neural Systems for Enhanced Melanoma Diagnosis via the 7-Point Checklist",
    "title_es": "Integrating Clinical Knowledge Graphs and Gradient-Based Neural Systems for Enhanced Melanoma Diagnosis via the 7-Point Checklist",
    "url": "https://arxiv.org/abs/2407.16822",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2407.16822v2 Announce Type: replace \nAbstract: The 7-point checklist (7PCL) is a widely used diagnostic tool in dermoscopy for identifying malignant melanoma by assigning point values to seven specific attributes. However, the traditional 7PCL is limited to distinguishing between malignant melanoma and melanocytic Nevi, and falls short in scenarios where multiple skin diseases with appearances similar to melanoma coexist. To address this limitation, we propose a novel diagnostic framework that integrates a clinical knowledge-based topological graph (CKTG) with a gradient diagnostic strategy featuring a data-driven weighting system (GD-DDW). The CKTG captures both the internal and external relationships among the 7PCL attributes, while the GD-DDW emulates dermatologists' diagnostic processes, prioritizing visual observation before making predictions. Additionally, we introduce a multimodal feature extraction approach leveraging a dual-attention mechanism to enhance feature extraction through cross-modal interaction and unimodal collaboration. This method incorporates meta-information to uncover interactions between clinical data and image features, ensuring more accurate and robust predictions. Our approach, evaluated on the EDRA dataset, achieved an average AUC of 88.6%, demonstrating superior performance in melanoma detection and feature prediction. This integrated system provides data-driven benchmarks for clinicians, significantly enhancing the precision of melanoma diagnosis.",
    "source": "arXiv"
  },
  {
    "title": "VulScribeR: Exploring RAG-based Vulnerability Augmentation with LLMs",
    "title_es": "VulScribeR: Exploring RAG-based Vulnerability Augmentation with LLMs",
    "url": "https://arxiv.org/abs/2408.04125",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.04125v4 Announce Type: replace \nAbstract: Detecting vulnerabilities is vital for software security, yet deep learning-based vulnerability detectors (DLVD) face a data shortage, which limits their effectiveness. Data augmentation can potentially alleviate the data shortage, but augmenting vulnerable code is challenging and requires a generative solution that maintains vulnerability. Previous works have only focused on generating samples that contain single statements or specific types of vulnerabilities. Recently, large language models (LLMs) have been used to solve various code generation and comprehension tasks with inspiring results, especially when fused with retrieval augmented generation (RAG). Therefore, we propose VulScribeR, a novel LLM-based solution that leverages carefully curated prompt templates to augment vulnerable datasets. More specifically, we explore three strategies to augment both single and multi-statement vulnerabilities, with LLMs, namely Mutation, Injection, and Extension. Our extensive evaluation across four vulnerability datasets and DLVD models, using three LLMs, show that our approach beats two SOTA methods Vulgen and VGX, and Random Oversampling (ROS) by 27.48%, 27.93%, and 15.41% in f1-score with 5K generated vulnerable samples on average, and 53.84%, 54.10%, 69.90%, and 40.93% with 15K generated vulnerable samples. Our approach demonstrates its feasibility for large-scale data augmentation by generating 1K samples at as cheap as US$ 1.88.",
    "source": "arXiv"
  },
  {
    "title": "Towards flexible perception with visual memory",
    "title_es": "Towards flexible perception with visual memory",
    "url": "https://arxiv.org/abs/2408.08172",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.08172v3 Announce Type: replace \nAbstract: Training a neural network is a monolithic endeavor, akin to carving knowledge into stone: once the process is completed, editing the knowledge in a network is hard, since all information is distributed across the network's weights. We here explore a simple, compelling alternative by marrying the representational power of deep neural networks with the flexibility of a database. Decomposing the task of image classification into image similarity (from a pre-trained embedding) and search (via fast nearest neighbor retrieval from a knowledge database), we build on well-established components to construct a simple and flexible visual memory that has the following key capabilities: (1.) The ability to flexibly add data across scales: from individual samples all the way to entire classes and billion-scale data; (2.) The ability to remove data through unlearning and memory pruning; (3.) An interpretable decision-mechanism on which we can intervene to control its behavior. Taken together, these capabilities comprehensively demonstrate the benefits of an explicit visual memory. We hope that it might contribute to a conversation on how knowledge should be represented in deep vision models -- beyond carving it in \"stone\" weights.",
    "source": "arXiv"
  },
  {
    "title": "SpectralEarth: Training Hyperspectral Foundation Models at Scale",
    "title_es": "SpectralEarth: Training Hyperspectral Foundation Models at Scale",
    "url": "https://arxiv.org/abs/2408.08447",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.08447v2 Announce Type: replace \nAbstract: Foundation models have triggered a paradigm shift in computer vision and are increasingly being adopted in remote sensing, particularly for multispectral imagery. Yet, their potential in hyperspectral imaging (HSI) remains untapped due to the absence of comprehensive and globally representative hyperspectral datasets. To close this gap, we introduce SpectralEarth, a large-scale multitemporal dataset designed to pretrain hyperspectral foundation models leveraging data from the environmental mapping and analysis program (EnMAP). SpectralEarth comprises 538 974 image patches covering 415 153 unique locations from 11 636 globally distributed EnMAP scenes spanning two years of archive. In addition, 17.5% of these locations include multiple timestamps, enabling multitemporal HSI analysis. Utilizing state-of-the-art self-supervised learning algorithms, we pretrain a series of foundation models on SpectralEarth, integrating a spectral adapter into classical vision backbones to accommodate the unique characteristics of HSI. In tandem, we construct nine downstream datasets for land-cover, crop-type mapping, and tree-species classification, providing benchmarks for model evaluation. Experimental results support the versatility of our models and their generalizability across different tasks and sensors. We also highlight computational efficiency during model fine-tuning.",
    "source": "arXiv"
  },
  {
    "title": "From Few to More: Scribble-based Medical Image Segmentation via Masked Context Modeling and Continuous Pseudo Labels",
    "title_es": "From Few to More: Scribble-based Medical Image Segmentation via Masked Context Modeling and Continuous Pseudo Labels",
    "url": "https://arxiv.org/abs/2408.12814",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.12814v2 Announce Type: replace \nAbstract: Scribble-based weakly supervised segmentation methods have shown promising results in medical image segmentation, significantly reducing annotation costs. However, existing approaches often rely on auxiliary tasks to enforce semantic consistency and use hard pseudo labels for supervision, overlooking the unique challenges faced by models trained with sparse annotations. These models must predict pixel-wise segmentation maps from limited data, making it crucial to handle varying levels of annotation richness effectively. In this paper, we propose MaCo, a weakly supervised model designed for medical image segmentation, based on the principle of \"from few to more.\" MaCo leverages Masked Context Modeling (MCM) and Continuous Pseudo Labels (CPL). MCM employs an attention-based masking strategy to perturb the input image, ensuring that the model's predictions align with those of the original image. CPL converts scribble annotations into continuous pixel-wise labels by applying an exponential decay function to distance maps, producing confidence maps that represent the likelihood of each pixel belonging to a specific category, rather than relying on hard pseudo labels. We evaluate MaCo on three public datasets, comparing it with other weakly supervised methods. Our results show that MaCo outperforms competing methods across all datasets, establishing a new record in weakly supervised medical image segmentation.",
    "source": "arXiv"
  },
  {
    "title": "Explaining Caption-Image Interactions in CLIP Models with Second-Order Attributions",
    "title_es": "Explaining Caption-Image Interactions in CLIP Models with Second-Order Attributions",
    "url": "https://arxiv.org/abs/2408.14153",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.14153v4 Announce Type: replace \nAbstract: Dual encoder architectures like Clip models map two types of inputs into a shared embedding space and predict similarities between them. Despite their wide application, it is, however, not understood how these models compare their two inputs. Common first-order feature-attribution methods explain importances of individual features and can, thus, only provide limited insights into dual encoders, whose predictions depend on interactions between features. In this paper, we first derive a second-order method enabling the attribution of predictions by any differentiable dual encoder onto feature-interactions between its inputs. Second, we apply our method to Clip models and show that they learn fine-grained correspondences between parts of captions and regions in images. They match objects across input modes and also account for mismatches. This intrinsic visual-linguistic grounding ability, however, varies heavily between object classes, exhibits pronounced out-of-domain effects and we can identify individual errors as well as systematic failure categories. Code is publicly available: https://github.com/lucasmllr/exCLIP",
    "source": "arXiv"
  },
  {
    "title": "Distributed Lag Transformer based on Time-Variable-Aware Learning for Explainable Multivariate Time Series Forecasting",
    "title_es": "Distributed Lag Transformer based on Time-Variable-Aware Learning for Explainable Multivariate Time Series Forecasting",
    "url": "https://arxiv.org/abs/2408.16896",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.16896v2 Announce Type: replace \nAbstract: Time series data is a key element of big data analytics, commonly found in domains such as finance, healthcare, climate forecasting, and transportation. In large scale real world settings, such data is often high dimensional and multivariate, requiring advanced forecasting methods that are both accurate and interpretable. Although Transformer based models perform well in multivariate time series forecasting (MTSF), their lack of explainability limits their use in critical applications. To overcome this, we propose Distributed Lag Transformer (DLFormer), a novel Transformer architecture for explainable and scalable MTSF. DLFormer integrates a distributed lag embedding and a time variable aware learning (TVAL) mechanism to structurally model both local and global temporal dependencies and explicitly capture the influence of past variables on future outcomes. Experiments on ten benchmark and real world datasets show that DLFormer achieves state of the art predictive accuracy while offering robust, interpretable insights into variable wise and temporal dynamics. These results highlight ability of DLFormer to bridge the gap between performance and explainability, making it highly suitable for practical big data forecasting tasks.",
    "source": "arXiv"
  },
  {
    "title": "Pediatric brain tumor classification using digital histopathology and deep learning: evaluation of SOTA methods on a multi-center Swedish cohort",
    "title_es": "Pediatric brain tumor classification using digital histopathology and deep learning: evaluation of SOTA methods on a multi-center Swedish cohort",
    "url": "https://arxiv.org/abs/2409.01330",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2409.01330v2 Announce Type: replace \nAbstract: Brain tumors are the most common solid tumors in children and young adults, but the scarcity of large histopathology datasets has limited the application of computational pathology in this group. This study implements two weakly supervised multiple-instance learning (MIL) approaches on patch-features obtained from state-of-the-art histology-specific foundation models to classify pediatric brain tumors in hematoxylin and eosin whole slide images (WSIs) from a multi-center Swedish cohort. WSIs from 540 subjects (age 8.5$\\pm$4.9 years) diagnosed with brain tumor were gathered from the six Swedish university hospitals. Instance (patch)-level features were obtained from WSIs using three pre-trained feature extractors: ResNet50, UNI, and CONCH. Instances were aggregated using attention-based MIL (ABMIL) or clustering-constrained attention MIL (CLAM) for patient-level classification. Models were evaluated on three classification tasks based on the hierarchical classification of pediatric brain tumors: tumor category, family, and type. Model generalization was assessed by training on data from two of the centers and testing on data from four other centers. Model interpretability was evaluated through attention mapping. The highest classification performance was achieved using UNI features and ABMIL aggregation, with Matthew's correlation coefficient of 0.76$\\pm$0.04, 0.63$\\pm$0.04, and 0.60$\\pm$0.05 for tumor category, family, and type classification, respectively. When evaluating generalization, models utilizing UNI and CONCH features outperformed those using ResNet50. However, the drop in performance from the in-site to out-of-site testing was similar across feature extractors. These results show the potential of state-of-the-art computational pathology methods in diagnosing pediatric brain tumors at different hierarchical levels with fair generalizability on a multi-center national dataset.",
    "source": "arXiv"
  },
  {
    "title": "SINDyG: Sparse Identification of Nonlinear Dynamical Systems from Graph-Structured Data, with Applications to Stuart-Landau Oscillator Networks",
    "title_es": "SINDyG: Sparse Identification of Nonlinear Dynamical Systems from Graph-Structured Data, with Applications to Stuart-Landau Oscillator Networks",
    "url": "https://arxiv.org/abs/2409.04463",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2409.04463v5 Announce Type: replace \nAbstract: The combination of machine learning (ML) and sparsity-promoting techniques is enabling direct extraction of governing equations from data, revolutionizing computational modeling in diverse fields of science and engineering. The discovered dynamical models could be used to address challenges in climate science, neuroscience, ecology, finance, epidemiology, and beyond. However, most existing sparse identification methods for discovering dynamical systems treat the whole system as one without considering the interactions between subsystems. As a result, such models are not able to capture small changes in the emergent system behavior. To address this issue, we developed a new method called Sparse Identification of Nonlinear Dynamical Systems from Graph-structured data (SINDyG), which incorporates the network structure into sparse regression to identify model parameters that explain the underlying network dynamics. We tested our proposed method using several case studies of neuronal dynamics, where we modeled the macroscopic oscillation of a population of neurons using the extended Stuart-Landau (SL) equation and utilize the SINDyG method to identify the underlying nonlinear dynamics. Our extensive computational experiments validate the improved accuracy and simplicity of discovered network dynamics when compared to the original SINDy approach. The proposed graph-informed penalty can be easily integrated with other symbolic regression algorithms, enhancing model interpretability and performance by incorporating network structure into the regression process.",
    "source": "arXiv"
  },
  {
    "title": "Federated Learning for Smart Grid: A Survey on Applications and Potential Vulnerabilities",
    "title_es": "Federated Learning for Smart Grid: A Survey on Applications and Potential Vulnerabilities",
    "url": "https://arxiv.org/abs/2409.10764",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2409.10764v3 Announce Type: replace \nAbstract: The Smart Grid (SG) is a critical energy infrastructure that collects real-time electricity usage data to forecast future energy demands using information and communication technologies (ICT). Due to growing concerns about data security and privacy in SGs, federated learning (FL) has emerged as a promising training framework. FL offers a balance between privacy, efficiency, and accuracy in SGs by enabling collaborative model training without sharing private data from IoT devices. In this survey, we thoroughly review recent advancements in designing FL-based SG systems across three stages: generation, transmission and distribution, and consumption. Additionally, we explore potential vulnerabilities that may arise when implementing FL in these stages. Furthermore, we discuss the gap between state-of-the-art (SOTA) FL research and its practical applications in SGs, and we propose future research directions. Unlike traditional surveys addressing security issues in centralized machine learning methods for SG systems, this survey is the first to specifically examine the applications and security concerns unique to FL-based SG systems. We also introduce FedGridShield, an open-source framework featuring implementations of SOTA attack and defense methods. Our aim is to inspire further research into applications and improvements in the robustness of FL-based SG systems.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Reviewer Experience in Code Review Comment Generation",
    "title_es": "Leveraging Reviewer Experience in Code Review Comment Generation",
    "url": "https://arxiv.org/abs/2409.10959",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2409.10959v2 Announce Type: replace \nAbstract: Modern code review is a ubiquitous software quality assurance process aimed at identifying potential issues within newly written code. Despite its effectiveness, the process demands large amounts of effort from the human reviewers involved. To help alleviate this workload, researchers have trained deep learning models to imitate human reviewers in providing natural language code reviews. Formally, this task is known as code review comment generation. Prior work has demonstrated improvements in this task by leveraging machine learning techniques and neural models, such as transfer learning and the transformer architecture. However, the quality of the model generated reviews remain sub-optimal due to the quality of the open-source code review data used in model training. This is in part due to the data obtained from open-source projects where code reviews are conducted in a public forum, and reviewers possess varying levels of software development experience, potentially affecting the quality of their feedback. To accommodate for this variation, we propose a suite of experience-aware training methods that utilise the reviewers' past authoring and reviewing experiences as signals for review quality. Specifically, we propose experience-aware loss functions (ELF), which use the reviewers' authoring and reviewing ownership of a project as weights in the model's loss function. Through this method, experienced reviewers' code reviews yield larger influence over the model's behaviour. Compared to the SOTA model, ELF was able to generate higher quality reviews in terms of accuracy, informativeness, and comment types generated. The key contribution of this work is the demonstration of how traditional software engineering concepts such as reviewer experience can be integrated into the design of AI-based automated code review models.",
    "source": "arXiv"
  },
  {
    "title": "Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience",
    "title_es": "Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience",
    "url": "https://arxiv.org/abs/2409.17702",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2409.17702v2 Announce Type: replace \nAbstract: Verbalization of robot experience, i.e., summarization of and question answering about a robot's past, is a crucial ability for improving human-robot interaction. Previous works applied rule-based systems or fine-tuned deep models to verbalize short (several-minute-long) streams of episodic data, limiting generalization and transferability. In our work, we apply large pretrained models to tackle this task with zero or few examples, and specifically focus on verbalizing life-long experiences. For this, we derive a tree-like data structure from episodic memory (EM), with lower levels representing raw perception and proprioception data, and higher levels abstracting events to natural language concepts. Given such a hierarchical representation built from the experience stream, we apply a large language model as an agent to interactively search the EM given a user's query, dynamically expanding (initially collapsed) tree nodes to find the relevant information. The approach keeps computational costs low even when scaling to months of robot experience data. We evaluate our method on simulated household robot data, human egocentric videos, and real-world robot recordings, demonstrating its flexibility and scalability.",
    "source": "arXiv"
  },
  {
    "title": "The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems",
    "title_es": "The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems",
    "url": "https://arxiv.org/abs/2409.20002",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2409.20002v4 Announce Type: replace \nAbstract: The wide deployment of Large Language Models (LLMs) has given rise to strong demands for optimizing their inference performance. Today's techniques serving this purpose primarily focus on reducing latency and improving throughput through algorithmic and hardware enhancements, while largely overlooking their privacy side effects, particularly in a multi-user environment. In our research, for the first time, we discovered a set of new timing side channels in LLM systems, arising from shared caches and GPU memory allocations, which can be exploited to infer both confidential system prompts and those issued by other users. These vulnerabilities echo security challenges observed in traditional computing systems, highlighting an urgent need to address potential information leakage in LLM serving infrastructures. In this paper, we report novel attack strategies designed to exploit such timing side channels inherent in LLM deployments, specifically targeting the Key-Value (KV) cache and semantic cache widely used to enhance LLM inference performance. Our approach leverages timing measurements and classification models to detect cache hits, allowing an adversary to infer private prompts with high accuracy. We also propose a token-by-token search algorithm to efficiently recover shared prompt prefixes in the caches, showing the feasibility of stealing system prompts and those produced by peer users. Our experimental studies on black-box testing of popular online LLM services demonstrate that such privacy risks are completely realistic, with significant consequences. Our findings underscore the need for robust mitigation to protect LLM systems against such emerging threats.",
    "source": "arXiv"
  },
  {
    "title": "Probing Mechanical Reasoning in Large Vision Language Models",
    "title_es": "Probing Mechanical Reasoning in Large Vision Language Models",
    "url": "https://arxiv.org/abs/2410.00318",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.00318v4 Announce Type: replace \nAbstract: Mechanical reasoning is a hallmark of human intelligence, defined by its ubiquitous yet irreplaceable role in human activities ranging from routine tasks to civil engineering. Embedding machines with mechanical reasoning is therefore an important step towards building human-level artificial intelligence. Here, we leveraged 155 cognitive experiments to test the understanding of system stability, gears and pulley systems, leverage principle, inertia and motion, and fluid mechanics in 26 Vision Language Models (VLMs). Results indicate that VLMs consistently perform worse than humans on all domains, while demonstrate significant difficulty in reasoning about gear systems and fluid mechanics. Notably, their performance on these tasks do not improve as number of parameters increase, suggesting that current attention-based architecture may fail to grasp certain underlying mechanisms required for mechanical reasoning, particularly those pertaining to mental simulations.",
    "source": "arXiv"
  },
  {
    "title": "Downscaling Extreme Precipitation with Wasserstein Regularized Diffusion",
    "title_es": "Downscaling Extreme Precipitation with Wasserstein Regularized Diffusion",
    "url": "https://arxiv.org/abs/2410.00381",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.00381v4 Announce Type: replace \nAbstract: Understanding the risks posed by extreme rainfall events requires analysis of precipitation fields with high resolution (to assess localized hazards) and extensive historical coverage (to capture sufficient examples of rare occurrences). Radar and mesonet networks provide precipitation fields at 1 km resolution but with limited historical and geographical coverage, while gauge-based records and reanalysis products cover decades of time on a global scale, but only at 30-50 km resolution. To help provide high-resolution precipitation estimates over long time scales, this study presents Wasserstein Regularized Diffusion (WassDiff), a diffusion framework to downscale (super-resolve) precipitation fields from low-resolution gauge and reanalysis products. Crucially, unlike related deep generative models, WassDiff integrates a Wasserstein distribution-matching regularizer to the denoising process to reduce empirical biases at extreme intensities. Comprehensive evaluations demonstrate that WassDiff quantitatively outperforms existing state-of-the-art generative downscaling methods at recovering extreme weather phenomena such as tropical storms and cold fronts. Case studies further qualitatively demonstrate WassDiff's ability to reproduce realistic fine-scale weather structures and accurate peak intensities. By unlocking decades of high-resolution rainfall information from globally available coarse records, WassDiff offers a practical pathway toward more accurate flood-risk assessments and climate-adaptation planning.",
    "source": "arXiv"
  },
  {
    "title": "Differentiation Through Black-Box Quadratic Programming Solvers",
    "title_es": "Differentiation Through Black-Box Quadratic Programming Solvers",
    "url": "https://arxiv.org/abs/2410.06324",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.06324v3 Announce Type: replace \nAbstract: Differentiable optimization has attracted significant research interest, particularly for quadratic programming (QP). Existing approaches for differentiating the solution of a QP with respect to its defining parameters often rely on specific integrated solvers. This integration limits their applicability, including their use in neural network architectures and bi-level optimization tasks, restricting users to a narrow selection of solver choices. To address this limitation, we introduce dQP, a modular and solver-agnostic framework for plug-and-play differentiation of virtually any QP solver. Our key theoretical insight is that the solution and its derivative can each be expressed in terms of closely-related and simple linear systems by using the active set at the solution. This insight enables efficient decoupling of the QP's solution, obtained by any solver, from its differentiation. Our open-source, minimal-overhead implementation will be made publicly available and seamlessly integrates with more than 15 state-of-the-art solvers. Comprehensive benchmark experiments demonstrate dQP's robustness and scalability, particularly highlighting its advantages in large-scale sparse problems.",
    "source": "arXiv"
  },
  {
    "title": "Retrieval-Augmented Decision Transformer: External Memory for In-context RL",
    "title_es": "Retrieval-Augmented Decision Transformer: External Memory for In-context RL",
    "url": "https://arxiv.org/abs/2410.07071",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.07071v3 Announce Type: replace \nAbstract: In-context learning (ICL) is the ability of a model to learn a new task by observing a few exemplars in its context. While prevalent in NLP, this capability has recently also been observed in Reinforcement Learning (RL) settings. Prior in-context RL methods, however, require entire episodes in the agent's context. Given that complex environments typically lead to long episodes with sparse rewards, these methods are constrained to simple environments with short episodes. To address these challenges, we introduce Retrieval-Augmented Decision Transformer (RA-DT). RA-DT employs an external memory mechanism to store past experiences from which it retrieves only sub-trajectories relevant for the current situation. The retrieval component in RA-DT does not require training and can be entirely domain-agnostic. We evaluate the capabilities of RA-DT on grid-world environments, robotics simulations, and procedurally-generated video games. On grid-worlds, RA-DT outperforms baselines, while using only a fraction of their context length. Furthermore, we illuminate the limitations of current in-context RL methods on complex environments and discuss future directions. To facilitate future research, we release datasets for four of the considered environments.",
    "source": "arXiv"
  },
  {
    "title": "System 2 Reasoning for Human-AI Alignment: Generality and Adaptivity via ARC-AGI",
    "title_es": "System 2 Reasoning for Human-AI Alignment: Generality and Adaptivity via ARC-AGI",
    "url": "https://arxiv.org/abs/2410.07866",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.07866v5 Announce Type: replace \nAbstract: Despite their broad applicability, transformer-based models still fall short in System~2 reasoning, lacking the generality and adaptivity needed for human--AI alignment. We examine weaknesses on ARC-AGI tasks, revealing gaps in compositional generalization and novel-rule adaptation, and argue that closing these gaps requires overhauling the reasoning pipeline and its evaluation. We propose three research axes: (1) Symbolic representation pipeline for compositional generality, (2) Interactive feedback-driven reasoning loop for adaptivity, and (3) Test-time task augmentation balancing both qualities. Finally, we demonstrate how ARC-AGI's evaluation suite can be adapted to track progress in symbolic generality, feedback-driven adaptivity, and task-level robustness, thereby guiding future work on robust human--AI alignment.",
    "source": "arXiv"
  },
  {
    "title": "ViCToR: Improving Visual Comprehension via Token Reconstruction for Pretraining LMMs",
    "title_es": "ViCToR: Improving Visual Comprehension via Token Reconstruction for Pretraining LMMs",
    "url": "https://arxiv.org/abs/2410.14332",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.14332v4 Announce Type: replace \nAbstract: Large Multimodal Models (LMMs) often face a modality representation gap during pretraining: while language embeddings remain stable, visual representations are highly sensitive to contextual noise (e.g., background clutter). To address this issue, we introduce a visual comprehension stage, which we call ViCToR (Visual Comprehension via Token Reconstruction), a novel pretraining framework for LMMs. ViCToR employs a learnable visual token pool and utilizes the Hungarian matching algorithm to select semantically relevant tokens from this pool for visual token replacement. Furthermore, by integrating a visual token reconstruction loss with dense semantic supervision, ViCToR can learn tokens which retain high visual detail, thereby enhancing the large language model's (LLM's) understanding of visual information. After pretraining on 3 million publicly accessible images and captions, ViCToR achieves state-of-the-art results, improving over LLaVA-NeXT-8B by 10.4%, 3.2%, and 7.2% on the MMStar, SEED$^I$, and RealWorldQA benchmarks, respectively. Code is available at https://github.com/deepglint/Victor.",
    "source": "arXiv"
  },
  {
    "title": "Depth-Guided Self-Supervised Human Keypoint Detection via Cross-Modal Distillation",
    "title_es": "Depth-Guided Self-Supervised Human Keypoint Detection via Cross-Modal Distillation",
    "url": "https://arxiv.org/abs/2410.14700",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.14700v2 Announce Type: replace \nAbstract: Existing unsupervised keypoint detection methods apply artificial deformations to images such as masking a significant portion of images and using reconstruction of original image as a learning objective to detect keypoints. However, this approach lacks depth information in the image and often detects keypoints on the background. To address this, we propose Distill-DKP, a novel cross-modal knowledge distillation framework that leverages depth maps and RGB images for keypoint detection in a self-supervised setting. During training, Distill-DKP extracts embedding-level knowledge from a depth-based teacher model to guide an image-based student model with inference restricted to the student. Experiments show that Distill-DKP significantly outperforms previous unsupervised methods by reducing mean L2 error by 47.15% on Human3.6M, mean average error by 5.67% on Taichi, and improving keypoints accuracy by 1.3% on DeepFashion dataset. Detailed ablation studies demonstrate the sensitivity of knowledge distillation across different layers of the network. Project Page: https://23wm13.github.io/distill-dkp/",
    "source": "arXiv"
  },
  {
    "title": "ControlPULPlet: A Flexible Real-time Multi-core RISC-V Controller for 2.5D Systems-in-package",
    "title_es": "ControlPULPlet: A Flexible Real-time Multi-core RISC-V Controller for 2.5D Systems-in-package",
    "url": "https://arxiv.org/abs/2410.15985",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.15985v2 Announce Type: replace \nAbstract: The growing complexity of real-time control algorithms with increasing performance demands, along with the shift to 2.5D technology, drive the need for scalable controllers to manage chiplets' coupled operation in 2.5D systems-in-package. These controllers must offer real-time computing capabilities, as well as System-in-package (SiP) compatible IO interfaces for communicating with the controlled dies. Due to real-time constraints, a key challenge is minimizing the performance penalty of die-to-die communication with respect to native on-chip control interfaces. We address this challenge with ControlPULPlet, an open-source, real-time multi-core RISC-V controller designed specifically for SiP integration. ControlPULPlet features a 32-bit CV32RT core for fast interrupt handling and a specialized direct memory access engine to automate periodic sensor readout. A tightly-coupled programmable multi-core cluster for acceleration of advanced control algorithms is integrated through a dedicated AXI4 port. A flexible AXI4-compatible die-to-die (D2D) link enables efficient communication in 2.5D SiPs. We implemented and fabricated ControlPULPlet as a silicon demonstrator called Kairos in TSMC's 65nm CMOS. Kairos runs model predictive control algorithms at up to 290 MHz in a 30 mW power envelope. The D2D link attains a peak duplex transfer rate of 51 Gbit/s at 200 MHz, at the minimal costs of just 7.6 kGE in PHY area per channel, adding just 2.9% to the total system area.",
    "source": "arXiv"
  },
  {
    "title": "Improving Multimodal Large Language Models Using Continual Learning",
    "title_es": "Improving Multimodal Large Language Models Using Continual Learning",
    "url": "https://arxiv.org/abs/2410.19925",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.19925v2 Announce Type: replace \nAbstract: Generative large language models (LLMs) exhibit impressive capabilities, which can be further augmented by integrating a pre-trained vision model into the original LLM to create a multimodal LLM (MLLM). However, this integration often significantly decreases performance on natural language understanding and generation tasks, compared to the original LLM. This study investigates this issue using the LLaVA MLLM, treating the integration as a continual learning problem. We evaluate five continual learning methods to mitigate forgetting and identify a technique that enhances visual understanding while minimizing linguistic performance loss. Our approach reduces linguistic performance degradation by up to 15% over the LLaVA recipe, while maintaining high multimodal accuracy. We also demonstrate the robustness of our method through continual learning on a sequence of vision-language tasks, effectively preserving linguistic skills while acquiring new multimodal capabilities. Project webpage: https://shikhar-srivastava.github.io/cl-for-improving-mllms",
    "source": "arXiv"
  },
  {
    "title": "Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning",
    "title_es": "Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning",
    "url": "https://arxiv.org/abs/2411.02199",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2411.02199v5 Announce Type: replace \nAbstract: Transformer-based large language models (LLMs) have displayed remarkable creative prowess and emergence capabilities. Existing empirical studies have revealed a strong connection between these LLMs' impressive emergence abilities and their in-context learning (ICL) capacity, allowing them to solve new tasks using only task-specific prompts without further fine-tuning. On the other hand, existing empirical and theoretical studies also show that there is a linear regularity of the multi-concept encoded semantic representation behind transformer-based LLMs. However, existing theoretical work fail to build up an understanding of the connection between this regularity and the innovative power of ICL. Additionally, prior work often focuses on simplified, unrealistic scenarios involving linear transformers or unrealistic loss functions, and they achieve only linear or sub-linear convergence rates. In contrast, this work provides a fine-grained mathematical analysis to show how transformers leverage the multi-concept semantics of words to enable powerful ICL and excellent out-of-distribution ICL abilities, offering insights into how transformers innovate solutions for certain unseen tasks encoded with multiple cross-concept semantics. Inspired by empirical studies on the linear latent geometry of LLMs, the analysis is based on a concept-based low-noise sparse coding prompt model. Leveraging advanced techniques, this work showcases the exponential 0-1 loss convergence over the highly non-convex training dynamics, which pioneeringly incorporates the challenges of softmax self-attention, ReLU-activated MLPs, and cross-entropy loss. Empirical simulations corroborate the theoretical findings.",
    "source": "arXiv"
  },
  {
    "title": "Learning Characteristics of Reverse Quaternion Neural Network",
    "title_es": "Learning Characteristics of Reverse Quaternion Neural Network",
    "url": "https://arxiv.org/abs/2411.05816",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2411.05816v2 Announce Type: replace \nAbstract: The purpose of this paper is to propose a new multi-layer feedforward quaternion neural network model architecture, Reverse Quaternion Neural Network which utilizes the non-commutative nature of quaternion products, and to clarify its learning characteristics. While quaternion neural networks have been used in various fields, there has been no research report on the characteristics of multi-layer feedforward quaternion neural networks where weights are applied in the reverse direction. This paper investigates the learning characteristics of the Reverse Quaternion Neural Network from two perspectives: the learning speed and the generalization on rotation. As a result, it is found that the Reverse Quaternion Neural Network has a learning speed comparable to existing models and can obtain a different rotation representation from the existing models.",
    "source": "arXiv"
  },
  {
    "title": "Generative Feature Training of Thin 2-Layer Networks",
    "title_es": "Generative Feature Training of Thin 2-Layer Networks",
    "url": "https://arxiv.org/abs/2411.06848",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2411.06848v2 Announce Type: replace \nAbstract: We consider the approximation of functions by 2-layer neural networks with a small number of hidden weights based on the squared loss and small datasets. Due to the highly non-convex energy landscape, gradient-based training often suffers from local minima. As a remedy, we initialize the hidden weights with samples from a learned proposal distribution, which we parameterize as a deep generative model. To train this model, we exploit the fact that with fixed hidden weights, the optimal output weights solve a linear equation. After learning the generative model, we refine the sampled weights with a gradient-based post-processing in the latent space. Here, we also include a regularization scheme to counteract potential noise. Finally, we demonstrate the effectiveness of our approach by numerical examples.",
    "source": "arXiv"
  },
  {
    "title": "Joint multi-dimensional dynamic attention and transformer for general image restoration",
    "title_es": "Joint multi-dimensional dynamic attention and transformer for general image restoration",
    "url": "https://arxiv.org/abs/2411.07893",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2411.07893v2 Announce Type: replace \nAbstract: Outdoor images often suffer from severe degradation due to rain, haze, and noise, impairing image quality and challenging high-level tasks. Current image restoration methods struggle to handle complex degradation while maintaining efficiency. This paper introduces a novel image restoration architecture that combines multi-dimensional dynamic attention and self-attention within a U-Net framework. To leverage the global modeling capabilities of transformers and the local modeling capabilities of convolutions, we integrate sole CNNs in the encoder-decoder and sole transformers in the latent layer. Additionally, we design convolutional kernels with selected multi-dimensional dynamic attention to capture diverse degraded inputs efficiently. A transformer block with transposed self-attention further enhances global feature extraction while maintaining efficiency. Extensive experiments demonstrate that our method achieves a better balance between performance and computational complexity across five image restoration tasks: deraining, deblurring, denoising, dehazing, and enhancement, as well as superior performance for high-level vision tasks. The source code will be available at https://github.com/House-yuyu/MDDA-former.",
    "source": "arXiv"
  },
  {
    "title": "SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Game-Theoretic Defenses",
    "title_es": "SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Game-Theoretic Defenses",
    "url": "https://arxiv.org/abs/2411.11195",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2411.11195v4 Announce Type: replace \nAbstract: Multimodal foundation models (MFMs) integrate diverse data modalities to support complex and wide-ranging tasks. However, this integration also introduces distinct safety and security challenges. In this paper, we unify the concepts of safety and security in the context of MFMs by identifying critical threats that arise from both model behavior and system-level interactions. We propose a taxonomy grounded in information theory, evaluating risks through the concepts of channel capacity, signal, noise, and bandwidth. This perspective provides a principled way to analyze how information flows through MFMs and how vulnerabilities can emerge across modalities. Building on this foundation, we investigate defense mechanisms through the lens of a minimax game between attackers and defenders, highlighting key gaps in current research. In particular, we identify insufficient protection for cross-modal alignment and a lack of systematic and scalable defense strategies. Our work offers both a theoretical and practical foundation for advancing the safety and security of MFMs, supporting the development of more robust and trustworthy systems.",
    "source": "arXiv"
  },
  {
    "title": "Barriers on the EDGE: A scalable CBF architecture over EDGE for safe aerial-ground multi-agent coordination",
    "title_es": "Barriers on the EDGE: A scalable CBF architecture over EDGE for safe aerial-ground multi-agent coordination",
    "url": "https://arxiv.org/abs/2411.16608",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2411.16608v2 Announce Type: replace \nAbstract: In this article, we propose a control architecture for the safe, coordinated operation of a multi-agent system with aerial (UAVs) and ground (UGVs) robots in a confined task space. We consider the case where the aerial and ground operations are coupled, enabled by the capability of the aerial robots to land on moving ground robots. The proposed method uses time-varying Control Barrier Functions (CBFs) to impose safety constraints associated with (i) collision avoidance between agents, (ii) landing of UAVs on mobile UGVs, and (iii) task space restriction. Further, this article addresses the challenge induced by the rapid increase in the number of CBF constraints with the increasing number of agents through a hybrid centralized-distributed coordination approach that determines the set of CBF constraints that is relevant for every aerial and ground agent at any given time. A centralized node (Watcher), hosted by an edge computing cluster, activates the relevant constraints, thus reducing the network complexity and the need for high onboard processing on the robots. The CBF constraints are enforced in a distributed manner by individual robots that run a nominal controller and safety filter locally to overcome latency and other network nonidealities.",
    "source": "arXiv"
  },
  {
    "title": "PAD-F: Prior-Aware Debiasing Framework for Long-Tailed X-ray Prohibited Item Detection",
    "title_es": "PAD-F: Prior-Aware Debiasing Framework for Long-Tailed X-ray Prohibited Item Detection",
    "url": "https://arxiv.org/abs/2411.18078",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2411.18078v4 Announce Type: replace \nAbstract: Detecting prohibited items in X-ray security imagery is a challenging yet crucial task. With the rapid advancement of deep learning, object detection algorithms have been widely applied in this area. However, the distribution of object classes in real-world prohibited item detection scenarios often exhibits a distinct long-tailed distribution. Due to the unique principles of X-ray imaging, conventional methods for long-tailed object detection are often ineffective in this domain. To tackle these challenges, we introduce the Prior-Aware Debiasing Framework (PAD-F), a novel approach that employs a two-pronged strategy leveraging both material and co-occurrence priors. At the data level, our Explicit Material-Aware Augmentation (EMAA) component generates numerous challenging training samples for tail classes. It achieves this through a placement strategy guided by material-specific absorption rates and a gradient-based Poisson blending technique. At the feature level, the Implicit Co-occurrence Aggregator (ICA) acts as a plug-in module that enhances features for ambiguous objects by implicitly learning and aggregating statistical co-occurrence relationships within the image. Extensive experiments on the HiXray and PIDray datasets demonstrate that PAD-F significantly boosts the performance of multiple popular detectors. It achieves an absolute improvement of up to +17.2% in AP50 for tail classes and comprehensively outperforms existing state-of-the-art methods. Our work provides an effective and versatile solution to the critical problem of long-tailed detection in X-ray security.",
    "source": "arXiv"
  },
  {
    "title": "Scalable Out-of-distribution Robustness in the Presence of Unobserved Confounders",
    "title_es": "Scalable Out-of-distribution Robustness in the Presence of Unobserved Confounders",
    "url": "https://arxiv.org/abs/2411.19923",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2411.19923v2 Announce Type: replace \nAbstract: We consider the task of out-of-distribution (OOD) generalization, where the distribution shift is due to an unobserved confounder ($Z$) affecting both the covariates ($X$) and the labels ($Y$). This confounding introduces heterogeneity in the predictor, i.e., $P(Y | X) = E_{P(Z | X)}[P(Y | X,Z)]$, making traditional covariate and label shift assumptions unsuitable. OOD generalization differs from traditional domain adaptation in that it does not assume access to the covariate distribution ($X^\\text{te}$) of the test samples during training. These conditions create a challenging scenario for OOD robustness: (a) $Z^\\text{tr}$ is an unobserved confounder during training, (b) $P^\\text{te}(Z) \\neq P^\\text{tr}(Z)$, (c) $X^\\text{te}$ is unavailable during training, and (d) the predictive distribution depends on $P^\\text{te}(Z)$. While prior work has developed complex predictors requiring multiple additional variables for identifiability of the latent distribution, we explore a set of identifiability assumptions that yield a surprisingly simple predictor using only a single additional variable. Our approach demonstrates superior empirical performance on several benchmark tasks.",
    "source": "arXiv"
  },
  {
    "title": "Learning Whole-Body Loco-Manipulation for Omni-Directional Task Space Pose Tracking with a Wheeled-Quadrupedal-Manipulator",
    "title_es": "Learning Whole-Body Loco-Manipulation for Omni-Directional Task Space Pose Tracking with a Wheeled-Quadrupedal-Manipulator",
    "url": "https://arxiv.org/abs/2412.03012",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.03012v2 Announce Type: replace \nAbstract: In this paper, we study the whole-body loco-manipulation problem using reinforcement learning (RL). Specifically, we focus on the problem of how to coordinate the floating base and the robotic arm of a wheeled-quadrupedal manipulator robot to achieve direct six-dimensional (6D) end-effector (EE) pose tracking in task space. Different from conventional whole-body loco-manipulation problems that track both floating-base and end-effector commands, the direct EE pose tracking problem requires inherent balance among redundant degrees of freedom in the whole-body motion. We leverage RL to solve this challenging problem. To address the associated difficulties, we develop a novel reward fusion module (RFM) that systematically integrates reward terms corresponding to different tasks in a nonlinear manner. In such a way, the inherent multi-stage and hierarchical feature of the loco-manipulation problem can be carefully accommodated. By combining the proposed RFM with the a teacher-student RL training paradigm, we present a complete RL scheme to achieve 6D EE pose tracking for the wheeled-quadruped manipulator robot. Extensive simulation and hardware experiments demonstrate the significance of the RFM. In particular, we enable smooth and precise tracking performance, achieving state-of-the-art tracking position error of less than 5 cm, and rotation error of less than 0.1 rad. Please refer to https://clearlab-sustech.github.io/RFM_loco_mani/ for more experimental videos.",
    "source": "arXiv"
  },
  {
    "title": "A Taxonomy of System-Level Attacks on Deep Learning Models in Autonomous Vehicles",
    "title_es": "A Taxonomy of System-Level Attacks on Deep Learning Models in Autonomous Vehicles",
    "url": "https://arxiv.org/abs/2412.04510",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.04510v2 Announce Type: replace \nAbstract: The advent of deep learning and its astonishing performance has enabled its usage in complex systems, including autonomous vehicles. On the other hand, deep learning models are susceptible to mispredictions when small, adversarial changes are introduced into their input. Such mis-predictions can be triggered in the real world and can result in a failure of the entire system. In recent years, a growing number of research works have investigated ways to mount attacks against autonomous vehicles that exploit deep learning components. Such attacks are directed toward elements of the environment where these systems operate and their effectiveness is assessed in terms of system-level failures triggered by them. There has been however no systematic attempt to analyze and categorize such attacks. In this paper, we present the first taxonomy of system-level attacks against autonomous vehicles. We constructed our taxonomy by selecting 21 highly relevant papers, then we tagged them with 12 top-level taxonomy categories and several sub-categories. The taxonomy allowed us to investigate the attack features, the most attacked components and systems, the underlying threat models, and the failure chains from input perturbation to system-level failure. We distilled several lessons for practitioners and identified possible directions for future work for researchers.",
    "source": "arXiv"
  },
  {
    "title": "Revisiting Your Memory: Reconstruction of Affect-Contextualized Memory via EEG-guided Audiovisual Generation",
    "title_es": "Revisiting Your Memory: Reconstruction of Affect-Contextualized Memory via EEG-guided Audiovisual Generation",
    "url": "https://arxiv.org/abs/2412.05296",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.05296v2 Announce Type: replace \nAbstract: In this paper, we introduce RevisitAffectiveMemory, a novel task designed to reconstruct autobiographical memories through audio-visual generation guided by affect extracted from electroencephalogram (EEG) signals. To support this pioneering task, we present the EEG-AffectiveMemory dataset, which encompasses textual descriptions, visuals, music, and EEG recordings collected during memory recall from nine participants. Furthermore, we propose RYM (Revisit Your Memory), a three-stage framework for generating synchronized audio-visual contents while maintaining dynamic personal memory affect trajectories. Experimental results demonstrate our method successfully decodes individual affect dynamics trajectories from neural signals during memory recall (F1=0.9). Also, our approach faithfully reconstructs affect-contextualized audio-visual memory across all subjects, both qualitatively and quantitatively, with participants reporting strong affective concordance between their recalled memories and the generated content. Especially, contents generated from subject-reported affect dynamics showed higher correlation with participants' reported affect dynamics trajectories (r=0.265, p<.05) and received stronger user preference (preference=56%) compared to those generated from randomly reordered affect dynamics. Our approaches advance affect decoding research and its practical applications in personalized media creation via neural-based affect comprehension. Codes and the dataset are available at https://github.com/ioahKwon/Revisiting-Your-Memory.",
    "source": "arXiv"
  },
  {
    "title": "ViewDelta: Scaling Scene Change Detection through Text-Conditioning",
    "title_es": "ViewDelta: Scaling Scene Change Detection through Text-Conditioning",
    "url": "https://arxiv.org/abs/2412.07612",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.07612v3 Announce Type: replace \nAbstract: We introduce a generalized framework for Scene Change Detection (SCD) that addresses the core ambiguity of distinguishing \"relevant\" from \"nuisance\" changes, enabling effective joint training of a single model across diverse domains and applications. Existing methods struggle to generalize due to differences in dataset labeling, where changes such as vegetation growth or lane marking alterations may be labeled as relevant in one dataset and irrelevant in another. To resolve this ambiguity, we propose ViewDelta, a text conditioned change detection framework that uses natural language prompts to define relevant changes precisely, such as a single attribute, a specific set of classes, or all observable differences. To facilitate training in this paradigm, we release the Conditional Change Segmentation dataset (CSeg), the first large-scale synthetic dataset for text conditioned SCD, consisting of over 500,000 image pairs with more than 300,000 unique textual prompts describing relevant changes. Experiments demonstrate that a single ViewDelta model trained jointly on CSeg, SYSU-CD, PSCD, VL-CMU-CD, and their unaligned variants achieves performance competitive with or superior to dataset specific models, highlighting text conditioning as a powerful approach for generalizable SCD. Our code and dataset are available at https://joshuakgao.github.io/viewdelta/.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Audio and Text Modalities in Mental Health: A Study of LLMs Performance",
    "title_es": "Leveraging Audio and Text Modalities in Mental Health: A Study of LLMs Performance",
    "url": "https://arxiv.org/abs/2412.10417",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.10417v2 Announce Type: replace \nAbstract: Mental health disorders are increasingly prevalent worldwide, creating an urgent need for innovative tools to support early diagnosis and intervention. This study explores the potential of Large Language Models (LLMs) in multimodal mental health diagnostics, specifically for detecting depression and Post Traumatic Stress Disorder through text and audio modalities. Using the E-DAIC dataset, we compare text and audio modalities to investigate whether LLMs can perform equally well or better with audio inputs. We further examine the integration of both modalities to determine if this can enhance diagnostic accuracy, which generally results in improved performance metrics. Our analysis specifically utilizes custom-formulated metrics; Modal Superiority Score and Disagreement Resolvement Score to evaluate how combined modalities influence model performance. The Gemini 1.5 Pro model achieves the highest scores in binary depression classification when using the combined modality, with an F1 score of 0.67 and a Balanced Accuracy (BA) of 77.4%, assessed across the full dataset. These results represent an increase of 3.1% over its performance with the text modality and 2.7% over the audio modality, highlighting the effectiveness of integrating modalities to enhance diagnostic accuracy. Notably, all results are obtained in zero-shot inferring, highlighting the robustness of the models without requiring task-specific fine-tuning. To explore the impact of different configurations on model performance, we conduct binary, severity, and multiclass tasks using both zero-shot and few-shot prompts, examining the effects of prompt variations on performance. The results reveal that models such as Gemini 1.5 Pro in text and audio modalities, and GPT-4o mini in the text modality, often surpass other models in balanced accuracy and F1 scores across multiple tasks.",
    "source": "arXiv"
  },
  {
    "title": "Catch Me If You Can: Finding the Source of Infections in Temporal Networks",
    "title_es": "Catch Me If You Can: Finding the Source of Infections in Temporal Networks",
    "url": "https://arxiv.org/abs/2412.10877",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.10877v2 Announce Type: replace \nAbstract: Source detection (SD) is the task of finding the origin of a spreading process in a network. Algorithms for SD help us combat diseases, misinformation, pollution, and more, and have been studied by physicians, physicists, sociologists, and computer scientists. The field has received considerable attention and been analyzed in many settings (e.g., under different models of spreading processes), yet all previous work shares the same assumption that the network the spreading process takes place in has the same structure at every point in time. For example, if we consider how a disease spreads through a population, it is unrealistic to assume that two people can either never or at every time infect each other, rather such an infection is possible precisely when they meet. Therefore, we propose an extended model of SD based on temporal graphs, where each link between two nodes is only present at some time step. Temporal graphs have become a standard model of time-varying graphs, and, recently, researchers have begun to study infection problems (such as influence maximization) on temporal graphs (arXiv:2303.11703, [Gayraud et al., 2015]). We give the first formalization of SD on temporal graphs. For this, we employ the standard SIR model of spreading processes ([Hethcote, 1989]). We give both lower bounds and algorithms for the SD problem in a number of different settings, such as with consistent or dynamic source behavior and on general graphs as well as on trees.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Network Discovery via Infection Tracing",
    "title_es": "Dynamic Network Discovery via Infection Tracing",
    "url": "https://arxiv.org/abs/2412.10881",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.10881v2 Announce Type: replace \nAbstract: Researchers, policy makers, and engineers need to make sense of data from spreading processes as diverse as rumor spreading in social networks, viral infections, and water contamination. Classical questions include predicting infection behavior in a given network or deducing the network structure from infection data. Most of the research on network infections studies static graphs, that is, the connections in the network are assumed to not change. More recently, temporal graphs, in which connections change over time, have been used to more accurately represent real-world infections, which rarely occur in unchanging networks. We propose a model for temporal graph discovery that is consistent with previous work on static graphs and embraces the greater expressiveness of temporal graphs. For this model, we give algorithms and lower bounds which are often tight. We analyze different variations of the problem, which make our results widely applicable and it also clarifies which aspects of temporal infections make graph discovery easier or harder. We round off our analysis with an experimental evaluation of our algorithm on real-world interaction data from the Stanford Network Analysis Project and on temporal Erd\\H{o}s-Renyi graphs. On Erd\\H{o}s-Renyi graphs, we uncover a threshold behavior, which can be explained by a novel connectivity parameter that we introduce during our theoretical analysis.",
    "source": "arXiv"
  },
  {
    "title": "SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks",
    "title_es": "SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven Lightweight Transformer-based Networks",
    "url": "https://arxiv.org/abs/2412.12843",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.12843v3 Announce Type: replace \nAbstract: Event-based semantic segmentation has great potential in autonomous driving and robotics due to the advantages of event cameras, such as high dynamic range, low latency, and low power cost. Unfortunately, current artificial neural network (ANN)-based segmentation methods suffer from high computational demands, the requirements for image frames, and massive energy consumption, limiting their efficiency and application on resource-constrained edge/mobile platforms. To address these problems, we introduce SLTNet, a spike-driven lightweight transformer-based network designed for event-based semantic segmentation. Specifically, SLTNet is built on efficient spike-driven convolution blocks (SCBs) to extract rich semantic features while reducing the model's parameters. Then, to enhance the long-range contextural feature interaction, we propose novel spike-driven transformer blocks (STBs) with binary mask operations. Based on these basic blocks, SLTNet employs a high-efficiency single-branch architecture while maintaining the low energy consumption of the Spiking Neural Network (SNN). Finally, extensive experiments on DDD17 and DSEC-Semantic datasets demonstrate that SLTNet outperforms state-of-the-art (SOTA) SNN-based methods by at most 9.06% and 9.39% mIoU, respectively, with extremely 4.58x lower energy consumption and 114 FPS inference speed. Our code is open-sourced and available at https://github.com/longxianlei/SLTNet-v1.0.",
    "source": "arXiv"
  },
  {
    "title": "Indirect Query Bayesian Optimization with Integrated Feedback",
    "title_es": "Indirect Query Bayesian Optimization with Integrated Feedback",
    "url": "https://arxiv.org/abs/2412.13559",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.13559v2 Announce Type: replace \nAbstract: We develop the framework of Indirect Query Bayesian Optimization (IQBO), a new class of Bayesian optimization problems where the integrated feedback is given via a conditional expectation of the unknown function $f$ to be optimized. The underlying conditional distribution can be unknown and learned from data. The goal is to find the global optimum of $f$ by adaptively querying and observing in the space transformed by the conditional distribution. This is motivated by real-world applications where one cannot access direct feedback due to privacy, hardware or computational constraints. We propose the Conditional Max-Value Entropy Search (CMES) acquisition function to address this novel setting, and propose a hierarchical search algorithm with multi-resolution feedback to improve computational efficiency. We show regret bounds for our proposed methods and demonstrate the effectiveness of our approaches on simulated optimization tasks.",
    "source": "arXiv"
  },
  {
    "title": "Memorization Over Reasoning? Exposing and Mitigating Verbatim Memorization in Large Language Models' Character Understanding Evaluation",
    "title_es": "Memorization Over Reasoning? Exposing and Mitigating Verbatim Memorization in Large Language Models' Character Understanding Evaluation",
    "url": "https://arxiv.org/abs/2412.14368",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.14368v5 Announce Type: replace \nAbstract: Recently, Large Language Models (LLMs) have shown impressive performance in character understanding tasks, such as analyzing the roles, personalities, and relationships of fictional characters. However, the extensive pre-training corpora used by LLMs raise concerns that they may rely on memorizing popular fictional works rather than genuinely understanding and reasoning about them. In this work, we argue that 'gist memory'-capturing essential meaning - should be the primary mechanism for character understanding tasks, as opposed to 'verbatim memory' - exact match of a string. We introduce a simple yet effective method to mitigate mechanized memorization in character understanding evaluations while preserving the essential implicit cues needed for comprehension and reasoning. Our approach reduces memorization-driven performance on popular fictional works from 96% accuracy to 72% and results in up to an 18% drop in accuracy across various character understanding tasks. These findings underscore the issue of data contamination in existing benchmarks, which often measure memorization rather than true character understanding.",
    "source": "arXiv"
  },
  {
    "title": "Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction",
    "title_es": "Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction",
    "url": "https://arxiv.org/abs/2412.17565",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.17565v2 Announce Type: replace \nAbstract: Cellular traffic forecasting is a critical task that enables network operators to efficiently allocate resources and address anomalies in rapidly evolving environments. The exponential growth of data collected from base stations poses significant challenges to processing and analysis. While machine learning (ML) algorithms have emerged as powerful tools for handling these large datasets and providing accurate predictions, their environmental impact, particularly in terms of energy consumption, is often overlooked in favor of their predictive capabilities. This study investigates the potential of two bio-inspired models: Spiking Neural Networks (SNNs) and Reservoir Computing through Echo State Networks (ESNs) for cellular traffic forecasting. The evaluation focuses on both their predictive performance and energy efficiency. These models are implemented in both centralized and federated settings to analyze their effectiveness and energy consumption in decentralized systems. Additionally, we compare bio-inspired models with traditional architectures, such as Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons (MLPs), to provide a comprehensive evaluation. Using data collected from three diverse locations in Barcelona, Spain, we examine the trade-offs between predictive accuracy and energy demands across these approaches. The results indicate that bio-inspired models, such as SNNs and ESNs, can achieve significant energy savings while maintaining predictive accuracy comparable to traditional architectures. Furthermore, federated implementations were tested to evaluate their energy efficiency in decentralized settings compared to centralized systems, particularly in combination with bio-inspired models. These findings offer valuable insights into the potential of bio-inspired models for sustainable and privacy-preserving cellular traffic forecasting.",
    "source": "arXiv"
  },
  {
    "title": "AUCAD: Automated Construction of Alignment Dataset from Log-Related Issues for Enhancing LLM-based Log Generation",
    "title_es": "AUCAD: Automated Construction of Alignment Dataset from Log-Related Issues for Enhancing LLM-based Log Generation",
    "url": "https://arxiv.org/abs/2412.18835",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2412.18835v2 Announce Type: replace \nAbstract: Log statements have become an integral part of modern software systems. Prior research efforts have focused on supporting the decisions of placing log statements, such as where/what to log. With the increasing adoption of Large Language Models (LLMs) for code-related tasks such as code completion or generation, automated approaches for generating log statements have gained much momentum. However, the performance of these approaches still has a long way to go. This paper explores enhancing the performance of LLM-based solutions for automated log statement generation by post-training LLMs with a purpose-built dataset. Thus the primary contribution is a novel approach called AUCAD, which automatically constructs such a dataset with information extracting from log-related issues. Researchers have long noticed that a significant portion of the issues in the open-source community are related to log statements. However, distilling this portion of data requires manual efforts, which is labor-intensive and costly, rendering it impractical. Utilizing our approach, we automatically extract log-related issues from 1,537 entries of log data across 88 projects and identify 808 code snippets (i.e., methods) with retrievable source code both before and after modification of each issue (including log statements) to construct a dataset. Each entry in the dataset consists of a data pair representing high-quality and problematic log statements, respectively. With this dataset, we proceed to post-train multiple LLMs (primarily from the Llama series) for automated log statement generation. Both human and experimental evaluations indicate that these models significantly outperform existing LLM-based solutions, thereby validating the efficacy of our method for constructing a post-training dataset to enhance LLM-based log statement generation.",
    "source": "arXiv"
  },
  {
    "title": "Performant Automatic BLAS Offloading on Unified Memory Architecture with OpenMP First-Touch Style Data Movement",
    "title_es": "Performant Automatic BLAS Offloading on Unified Memory Architecture with OpenMP First-Touch Style Data Movement",
    "url": "https://arxiv.org/abs/2501.00279",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.00279v4 Announce Type: replace \nAbstract: BLAS is a fundamental building block of advanced linear algebra libraries and many modern scientific computing applications. GPUs are known for their strong arithmetic computing capabilities and are highly suited for BLAS operations. However, porting code to GPUs often requires significant effort, especially for large, complex codes or legacy codes, even for BLAS-heavy applications. While various tools exist to automatically offload BLAS to GPUs, they are often impractical due to the high costs associated with mandatory data transfers. The advent of unified memory architectures in recent GPU designs, such as the NVIDIA Grace-Hopper, allows cache-coherent memory access across all types of memory for both CPU and GPU, potentially eliminating the bottlenecks faced in conventional architectures. This breakthrough paves the way for innovative application developments and porting strategies. Building on our preliminary work demonstrating the potential of automatic *gemm offload, this paper extends the framework to all level-3 BLAS operations and introduces SCILIB-Accel, a novel tool for automatic BLAS offload. SCILIB-Accel leverages the memory coherency in Grace-Hopper and introduces a Device First-Use data movement policy inspired by the OpenMP First-Touch approach in multi-socket CPU programming, minimizing CPU-GPU data transfers for typical scientific computing codes. Additionally, utilizing dynamic binary instrumentation, the tool intercepts BLAS symbols directly from a CPU binary, requiring no code modifications or recompilation. SCILIB-Accel has been evaluated using multiple quantum physics codes on up to a few hundred GPU nodes, yielding promising speedups. Notably, for the LSMS method in the MuST suite, a 3x speedup was achieved on Grace-Hopper compared to Grace-Grace.",
    "source": "arXiv"
  },
  {
    "title": "Analyzing Finetuning Representation Shift for Multimodal LLMs Steering",
    "title_es": "Analyzing Finetuning Representation Shift for Multimodal LLMs Steering",
    "url": "https://arxiv.org/abs/2501.03012",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.03012v2 Announce Type: replace \nAbstract: Multimodal LLMs (MLLMs) have reached remarkable levels of proficiency in understanding multimodal inputs. However, understanding and interpreting the behavior of such complex models is a challenging task, not to mention the dynamic shifts that may occur during fine-tuning, or due to covariate shift between datasets. In this work, we apply concept-level analysis towards MLLM understanding. More specifically, we propose to map hidden states to interpretable visual and textual concepts. This enables us to more efficiently compare certain semantic dynamics, such as the shift from an original and fine-tuned model, revealing concept alteration and potential biases that may occur during fine-tuning. We also demonstrate the use of shift vectors to capture these concepts changes. These shift vectors allow us to recover fine-tuned concepts by applying simple, computationally inexpensive additive concept shifts in the original model. Finally, our findings also have direct applications for MLLM steering, which can be used for model debiasing as well as enforcing safety in MLLM output. All in all, we propose a novel, training-free, ready-to-use framework for MLLM behavior interpretability and control. Our implementation is publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Memorization: Assessing Semantic Generalization in Large Language Models Using Phrasal Constructions",
    "title_es": "Beyond Memorization: Assessing Semantic Generalization in Large Language Models Using Phrasal Constructions",
    "url": "https://arxiv.org/abs/2501.04661",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.04661v2 Announce Type: replace \nAbstract: The web-scale of pretraining data has created an important evaluation challenge: to disentangle linguistic competence on cases well-represented in pretraining data from generalization to out-of-domain language, specifically the dynamic, real-world instances less common in pretraining data. To this end, we construct a diagnostic evaluation to systematically assess natural language understanding in LLMs by leveraging Construction Grammar (CxG). CxG provides a psycholinguistically grounded framework for testing generalization, as it explicitly links syntactic forms to abstract, non-lexical meanings. Our novel inference evaluation dataset consists of English phrasal constructions, for which speakers are known to be able to abstract over commonplace instantiations in order to understand and produce creative instantiations. Our evaluation dataset uses CxG to evaluate two central questions: first, if models can 'understand' the semantics of sentences for instances that are likely to appear in pretraining data less often, but are intuitive and easy for people to understand. Second, if LLMs can deploy the appropriate constructional semantics given constructions that are syntactically identical but with divergent meanings. Our results demonstrate that state-of-the-art models, including GPT-o1, exhibit a performance drop of over 40% on our second task, revealing a failure to generalize over syntactically identical forms to arrive at distinct constructional meanings in the way humans do. We make our novel dataset and associated experimental data, including prompts and model responses, publicly available.",
    "source": "arXiv"
  },
  {
    "title": "UltraRay: Introducing Full-Path Ray Tracing in Physics-Based Ultrasound Simulation",
    "title_es": "UltraRay: Introducing Full-Path Ray Tracing in Physics-Based Ultrasound Simulation",
    "url": "https://arxiv.org/abs/2501.05828",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.05828v2 Announce Type: replace \nAbstract: Traditional ultrasound simulators solve the wave equation to model pressure distribution fields, achieving high accuracy but requiring significant computational time and resources. To address this, ray tracing approaches have been introduced, modeling wave propagation as rays interacting with boundaries and scatterers. However, existing models simplify ray propagation, generating echoes at interaction points without considering return paths to the sensor. This can result in unrealistic artifacts and necessitates careful scene tuning for plausible results. We propose a novel ultrasound simulation pipeline that utilizes a ray tracing algorithm to generate echo data, tracing each ray from the transducer through the scene and back to the sensor. To replicate advanced ultrasound imaging, we introduce a ray emission scheme optimized for plane wave imaging, incorporating delay and steering capabilities. Furthermore, we integrate a standard signal processing pipeline to simulate end-to-end ultrasound image formation. We showcase the efficacy of the proposed pipeline by modeling synthetic scenes featuring highly reflective objects, such as bones. In doing so, our proposed approach, UltraRay, not only enhances the overall visual quality but also improves the realism of the simulated images by accurately capturing secondary reflections and reducing unnatural artifacts. By building on top of a differentiable framework, the proposed pipeline lays the groundwork for a fast and differentiable ultrasound simulation tool necessary for gradient-based optimization, enabling advanced ultrasound beamforming strategies, neural network integration, and accurate inverse scene reconstruction.",
    "source": "arXiv"
  },
  {
    "title": "GenAI Confessions: Black-box Membership Inference for Generative Image Models",
    "title_es": "GenAI Confessions: Black-box Membership Inference for Generative Image Models",
    "url": "https://arxiv.org/abs/2501.06399",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.06399v2 Announce Type: replace \nAbstract: From a simple text prompt, generative-AI image models can create stunningly realistic and creative images bounded, it seems, by only our imagination. These models have achieved this remarkable feat thanks, in part, to the ingestion of billions of images collected from nearly every corner of the internet. Many creators have understandably expressed concern over how their intellectual property has been ingested without their permission or a mechanism to opt out of training. As a result, questions of fair use and copyright infringement have quickly emerged. We describe a method that allows us to determine if a model was trained on a specific image or set of images. This method is computationally efficient and assumes no explicit knowledge of the model architecture or weights (so-called black-box membership inference). We anticipate that this method will be crucial for auditing existing models and, looking ahead, ensuring the fairer development and deployment of generative AI models.",
    "source": "arXiv"
  },
  {
    "title": "MVICAD2: Multi-View Independent Component Analysis with Delays and Dilations",
    "title_es": "MVICAD2: Multi-View Independent Component Analysis with Delays and Dilations",
    "url": "https://arxiv.org/abs/2501.07426",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.07426v2 Announce Type: replace \nAbstract: Machine learning techniques in multi-view settings face significant challenges, particularly when integrating heterogeneous data, aligning feature spaces, and managing view-specific biases. These issues are prominent in neuroscience, where data from multiple subjects exposed to the same stimuli are analyzed to uncover brain activity dynamics. In magnetoencephalography (MEG), where signals are captured at the scalp level, estimating the brain's underlying sources is crucial, especially in group studies where sources are assumed to be similar for all subjects. Common methods, such as Multi-View Independent Component Analysis (MVICA), assume identical sources across subjects, but this assumption is often too restrictive due to individual variability and age-related changes. Multi-View Independent Component Analysis with Delays (MVICAD) addresses this by allowing sources to differ up to a temporal delay. However, temporal dilation effects, particularly in auditory stimuli, are common in brain dynamics, making the estimation of time delays alone insufficient. To address this, we propose Multi-View Independent Component Analysis with Delays and Dilations (MVICAD2), which allows sources to differ across subjects in both temporal delays and dilations. We present a model with identifiable sources, derive an approximation of its likelihood in closed form, and use regularization and optimization techniques to enhance performance. Through simulations, we demonstrate that MVICAD2 outperforms existing multi-view ICA methods. We further validate its effectiveness using the Cam-CAN dataset, and showing how delays and dilations are related to aging.",
    "source": "arXiv"
  },
  {
    "title": "Changing the ranking in eigenvector centrality of a weighted graph by small perturbations",
    "title_es": "Changing the ranking in eigenvector centrality of a weighted graph by small perturbations",
    "url": "https://arxiv.org/abs/2501.10745",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.10745v3 Announce Type: replace \nAbstract: In this article, we consider eigenvector centrality for the nodes of a graph and study the robustness (and stability) of this popular centrality measure. For a given weighted graph {\\mathcal G} (both directed and undirected), we consider the associated weighted adjacency matrix A, which by definition is a non-negative matrix. The eigenvector centralities of the nodes of {\\mathcal G} are the entries of the Perron eigenvector of A, which is the (positive) eigenvector associated with the eigenvalue with largest modulus. They provide a ranking of the nodes according to the corresponding centralities. An indicator of the robustness of eigenvector centrality consists in looking for a nearby perturbed graph \\widetilde{\\mathcal G}, with the same structure as {\\mathcal G} (i.e., with the same vertices and edges), but with a weighted adjacency matrix \\widetilde A such that the highest m entries (m \\ge 2) of the Perron eigenvector of \\widetilde A coalesce, making the ranking at the highest level ambiguous. To compute a solution to this matrix nearness problem, a nested iterative algorithm is proposed that makes use of a constrained gradient system of matrix differential equations in the inner iteration and a one-dimensional optimization of the perturbation size in the outer iteration. The proposed algorithm produces the {\\em optimal} perturbation (i.e., the one with smallest Frobenius norm) of the A which causes the looked-for coalescence, which is a measure of the sensitivity of the graph. Our numerical experiments indicate that the proposed strategy outperforms more standard approaches based on algorithms for constrained optimization. The methodology is formulated in terms of graphs but applies to any nonnegative matrix, with potential applications in fields like population models, consensus dynamics, economics, etc.",
    "source": "arXiv"
  },
  {
    "title": "A2SB: Audio-to-Audio Schrodinger Bridges",
    "title_es": "A2SB: Audio-to-Audio Schrodinger Bridges",
    "url": "https://arxiv.org/abs/2501.11311",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.11311v2 Announce Type: replace \nAbstract: Real-world audio is often degraded by numerous factors. This work presents an audio restoration model tailored for high-res music at 44.1kHz. Our model, Audio-to-Audio Schr\\\"odinger Bridges (A2SB), is capable of both bandwidth extension (predicting high-frequency components) and inpainting (re-generating missing segments). Critically, A2SB is end-to-end requiring no vocoder to predict waveform outputs, able to restore hour-long audio inputs, and trained on permissively licensed music data. A2SB is capable of achieving state-of-the-art band-width extension and inpainting quality on several out-of-distribution music test sets.",
    "source": "arXiv"
  },
  {
    "title": "Benchmarking LLMs' Mathematical Reasoning with Unseen Random Variables Questions",
    "title_es": "Benchmarking LLMs' Mathematical Reasoning with Unseen Random Variables Questions",
    "url": "https://arxiv.org/abs/2501.11790",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.11790v4 Announce Type: replace \nAbstract: Recent studies have raised significant concerns regarding the reliability of current mathematics benchmarks, highlighting issues such as simplistic design and potential data contamination. Consequently, developing a reliable benchmark that effectively evaluates large language models' (LLMs) genuine capabilities in mathematical reasoning remains a critical challenge. To address these concerns, we propose RV-Bench, a novel evaluation methodology for Benchmarking LLMs with Random Variables in mathematical reasoning. Specifically, we build question-generating functions to produce random variable questions (RVQs), whose background content mirrors original benchmark problems, but with randomized variable combinations, rendering them \"unseen\" to LLMs. Models must completely understand the inherent question pattern to correctly answer RVQs with diverse variable combinations. Thus, an LLM's genuine reasoning capability is reflected through its accuracy and robustness on RV-Bench. We conducted extensive experiments on over 30 representative LLMs across more than 1,000 RVQs. Our findings propose that LLMs exhibit a proficiency imbalance between encountered and ``unseen'' data distributions. Furthermore, RV-Bench reveals that proficiency generalization across similar mathematical reasoning tasks is limited, but we verified it can still be effectively elicited through test-time scaling.",
    "source": "arXiv"
  },
  {
    "title": "Navigating Robot Swarm Through a Virtual Tube with Flow-Adaptive Distribution Control",
    "title_es": "Navigating Robot Swarm Through a Virtual Tube with Flow-Adaptive Distribution Control",
    "url": "https://arxiv.org/abs/2501.11938",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.11938v2 Announce Type: replace \nAbstract: With the rapid development of robot swarm technology and its diverse applications, navigating robot swarms through complex environments has emerged as a critical research direction. To ensure safe navigation and avoid potential collisions with obstacles, the concept of virtual tubes has been introduced to define safe and navigable regions. However, current control methods in virtual tubes face the congestion issues, particularly in narrow ones with low throughput. To address these challenges, we first propose a novel control method that combines a modified artificial potential field (APF) for swarm navigation and density feedback control for distribution regulation. Then we generate a global velocity field that not only ensures collision-free navigation but also achieves locally input-to-state stability (LISS) for density tracking. Finally, numerical simulations and realistic applications validate the effectiveness and advantages of the proposed method in navigating robot swarms through narrow virtual tubes.",
    "source": "arXiv"
  },
  {
    "title": "Conformal Prediction of Classifiers with Many Classes based on Noisy Labels",
    "title_es": "Conformal Prediction of Classifiers with Many Classes based on Noisy Labels",
    "url": "https://arxiv.org/abs/2501.12749",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.12749v2 Announce Type: replace \nAbstract: Conformal Prediction (CP) controls the prediction uncertainty of classification systems by producing a small prediction set, ensuring a predetermined probability that the true class lies within this set. This is commonly done by defining a score, based on the model predictions, and setting a threshold on this score using a validation set. In this study, we address the problem of CP calibration when we only have access to a calibration set with noisy labels. We show how we can estimate the noise-free conformal threshold based on the noisy labeled data. We derive a finite sample coverage guarantee for uniform noise that remains effective even in tasks with a large number of classes. We dub our approach Noise-Aware Conformal Prediction (NACP). We illustrate the performance of the proposed results on several standard image classification datasets with a large number of classes.",
    "source": "arXiv"
  },
  {
    "title": "On the Service Rate Region of Reed-Muller Codes",
    "title_es": "On the Service Rate Region of Reed-Muller Codes",
    "url": "https://arxiv.org/abs/2501.13105",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.13105v5 Announce Type: replace \nAbstract: We study the Service Rate Region of Reed-Muller codes in the context of distributed storage systems. The service rate region is a convex polytope comprising all achievable data access request rates under a given coding scheme. It represents a critical metric for evaluating system efficiency and scalability. Using the geometric properties of Reed-Muller codes, we characterize recovery sets for data objects, including their existence, uniqueness, and enumeration. This analysis reveals a connection between recovery sets and minimum-weight codewords in the dual Reed-Muller code, providing a framework for identifying those recovery sets. Leveraging these results, we derive explicit and tight bounds on the maximal achievable demand for individual data objects, thereby defining the maximal simplex within the service rate region and the smallest simplex containing it. These two provide a tight approximation of the service rate region of Reed-Muller codes.",
    "source": "arXiv"
  },
  {
    "title": "HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene Understanding and Generation",
    "title_es": "HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene Understanding and Generation",
    "url": "https://arxiv.org/abs/2501.14729",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.14729v3 Announce Type: replace \nAbstract: Driving World Models (DWMs) have become essential for autonomous driving by enabling future scene prediction. However, existing DWMs are limited to scene generation and fail to incorporate scene understanding, which involves interpreting and reasoning about the driving environment. In this paper, we present a unified Driving World Model named HERMES. We seamlessly integrate 3D scene understanding and future scene evolution (generation) through a unified framework in driving scenarios. Specifically, HERMES leverages a Bird's-Eye View (BEV) representation to consolidate multi-view spatial information while preserving geometric relationships and interactions. We also introduce world queries, which incorporate world knowledge into BEV features via causal attention in the Large Language Model, enabling contextual enrichment for understanding and generation tasks. We conduct comprehensive studies on nuScenes and OmniDrive-nuScenes datasets to validate the effectiveness of our method. HERMES achieves state-of-the-art performance, reducing generation error by 32.4% and improving understanding metrics such as CIDEr by 8.0%. The model and code will be publicly released at https://github.com/LMD0311/HERMES.",
    "source": "arXiv"
  },
  {
    "title": "Pivoting Factorization: A Compact Meta Low-Rank Representation of Sparsity for Efficient Inference in Large Language Models",
    "title_es": "Pivoting Factorization: A Compact Meta Low-Rank Representation of Sparsity for Efficient Inference in Large Language Models",
    "url": "https://arxiv.org/abs/2501.19090",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2501.19090v3 Announce Type: replace \nAbstract: The rapid growth of Large Language Models has driven demand for effective model compression techniques to reduce memory and computation costs. Low-rank pruning has gained attention for its GPU compatibility across all densities. However, low-rank pruning struggles to match the performance of semi-structured pruning, often doubling perplexity at similar densities. In this paper, we propose Pivoting Factorization (PIFA), a novel lossless meta low-rank representation that unsupervisedly learns a compact form of any low-rank representation, effectively eliminating redundant information. PIFA identifies pivot rows (linearly independent rows) and expresses non-pivot rows as linear combinations, achieving 24.2% additional memory savings and 24.6% faster inference over low-rank layers at rank = 50% of dimension. To mitigate the performance degradation caused by low-rank pruning, we introduce a novel, retraining-free reconstruction method that minimizes error accumulation (M). MPIFA, combining M and PIFA into an end-to-end framework, significantly outperforms existing low-rank pruning methods, and achieves performance comparable to semi-structured pruning, while surpassing it in GPU efficiency and compatibility. Our code is available at https://github.com/biomedical-cybernetics/pivoting-factorization.",
    "source": "arXiv"
  },
  {
    "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "title_es": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "url": "https://arxiv.org/abs/2502.01105",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.01105v3 Announce Type: replace \nAbstract: Generating cognitive-aligned layered SVGs remains challenging due to existing methods' tendencies toward either oversimplified single-layer outputs or optimization-induced shape redundancies. We propose LayerTracer, a diffusion transformer based framework that bridges this gap by learning designers' layered SVG creation processes from a novel dataset of sequential design operations. Our approach operates in two phases: First, a text-conditioned DiT generates multi-phase rasterized construction blueprints that simulate human design workflows. Second, layer-wise vectorization with path deduplication produces clean, editable SVGs. For image vectorization, we introduce a conditional diffusion mechanism that encodes reference images into latent tokens, guiding hierarchical reconstruction while preserving structural integrity. Extensive experiments demonstrate LayerTracer's superior performance against optimization-based and neural baselines in both generation quality and editability, effectively aligning AI-generated vectors with professional design cognition.",
    "source": "arXiv"
  },
  {
    "title": "Accelerating Linear Recurrent Neural Networks for the Edge with Unstructured Sparsity",
    "title_es": "Accelerating Linear Recurrent Neural Networks for the Edge with Unstructured Sparsity",
    "url": "https://arxiv.org/abs/2502.01330",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.01330v2 Announce Type: replace \nAbstract: Linear recurrent neural networks enable powerful long-range sequence modeling with constant memory usage and time-per-token during inference. These architectures hold promise for streaming applications at the edge, but deployment in resource-constrained environments requires hardware-aware optimizations to minimize latency and energy consumption. Unstructured sparsity offers a compelling solution, enabling substantial reductions in compute and memory requirements--when accelerated by compatible hardware platforms. In this paper, we conduct a scaling study to investigate the Pareto front of performance and efficiency across inference compute budgets. We find that highly sparse linear RNNs consistently achieve better efficiency-performance trade-offs than dense baselines, with 2x less compute and 36% less memory at iso-accuracy. Our models achieve state-of-the-art results on a real-time streaming task for audio denoising. By quantizing our sparse models to fixed-point arithmetic and deploying them on the Intel Loihi 2 neuromorphic chip for real-time processing, we translate model compression into tangible gains of 42x lower latency and 149x lower energy consumption compared to a dense model on an edge GPU. Our findings showcase the transformative potential of unstructured sparsity, paving the way for highly efficient recurrent neural networks in real-world, resource-constrained environments.",
    "source": "arXiv"
  },
  {
    "title": "Image Intrinsic Scale Assessment: Bridging the Gap Between Quality and Resolution",
    "title_es": "Image Intrinsic Scale Assessment: Bridging the Gap Between Quality and Resolution",
    "url": "https://arxiv.org/abs/2502.06476",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.06476v3 Announce Type: replace \nAbstract: Image Quality Assessment (IQA) measures and predicts perceived image quality by human observers. Although recent studies have highlighted the critical influence that variations in the scale of an image have on its perceived quality, this relationship has not been systematically quantified. To bridge this gap, we introduce the Image Intrinsic Scale (IIS), defined as the largest scale where an image exhibits its highest perceived quality. We also present the Image Intrinsic Scale Assessment (IISA) task, which involves subjectively measuring and predicting the IIS based on human judgments. We develop a subjective annotation methodology and create the IISA-DB dataset, comprising 785 image-IIS pairs annotated by experts in a rigorously controlled crowdsourcing study. Furthermore, we propose WIISA (Weak-labeling for Image Intrinsic Scale Assessment), a strategy that leverages how the IIS of an image varies with downscaling to generate weak labels. Experiments show that applying WIISA during the training of several IQA methods adapted for IISA consistently improves the performance compared to using only ground-truth labels. The code, dataset, and pre-trained models are available at https://github.com/SonyResearch/IISA.",
    "source": "arXiv"
  },
  {
    "title": "On positivity preservation of hybrid discontinuous Galerkin methods on hypergraphs",
    "title_es": "On positivity preservation of hybrid discontinuous Galerkin methods on hypergraphs",
    "url": "https://arxiv.org/abs/2502.07976",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.07976v2 Announce Type: replace \nAbstract: Hybrid finite element methods, particularly hybridized discontinuous Galerkin (HDG) methods, are efficient numerical schemes for discretizing the diffusion equation, which encompasses two main physical principles: mass conservation and positivity preservation. While the former has been extensively analyzed in the literature, this paper investigates the latter. We state a theorem that guarantees the positivity of both the bulk and skeleton approximations to the primary unknown (concentration) and provide counterexamples for nonpositive discretizations. The theoretical findings are confirmed by numerical experiments.",
    "source": "arXiv"
  },
  {
    "title": "An hp Multigrid Approach for Tensor-Product Space-Time Finite Element Discretizations of the Stokes Equations",
    "title_es": "An hp Multigrid Approach for Tensor-Product Space-Time Finite Element Discretizations of the Stokes Equations",
    "url": "https://arxiv.org/abs/2502.09159",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.09159v3 Announce Type: replace \nAbstract: We present a monolithic $hp$ space-time multigrid method for tensor-product space-time finite element discretizations of the Stokes equations. Geometric and polynomial coarsening of the space-time mesh is performed, and the entire algorithm is expressed through rigorous mathematical mappings. For the discretization, we use inf-sup stable pairs $\\mathbb Q_{r+1}/\\mathbb P_{r}^{\\text{disc}}$ of elements in space and a discontinuous Galerkin (DG$(k)$) discretization in time with piecewise polynomials of order $k$. The key novelty of this work is the application of $hp$ multigrid techniques in space and time, facilitated and accelerated by the matrix-free capabilities of the deal$.$II library. While multigrid methods are well-established for stationary problems, their application in space-time formulations encounter unique challenges, particularly in constructing suitable smoothers. To overcome these challenges, we employ space-time cell and vertex star patch based Vanka smoothers. Extensive tests on high-performance computing platforms demonstrate the efficiency of our \\( hp \\) multigrid approach on problem sizes exceeding a trillion degrees of freedom (dofs), sustaining throughputs of hundreds of millions of dofs per second.",
    "source": "arXiv"
  },
  {
    "title": "LEAPS: A discrete neural sampler via locally equivariant networks",
    "title_es": "LEAPS: A discrete neural sampler via locally equivariant networks",
    "url": "https://arxiv.org/abs/2502.10843",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.10843v2 Announce Type: replace \nAbstract: We propose \"LEAPS\", an algorithm to sample from discrete distributions known up to normalization by learning a rate matrix of a continuous-time Markov chain (CTMC). LEAPS can be seen as a continuous-time formulation of annealed importance sampling and sequential Monte Carlo methods, extended so that the variance of the importance weights is offset by the inclusion of the CTMC. To derive these importance weights, we introduce a set of Radon-Nikodym derivatives of CTMCs over their path measures. Because the computation of these weights is intractable with standard neural network parameterizations of rate matrices, we devise a new compact representation for rate matrices via what we call \"locally equivariant\" functions. To parameterize them, we introduce a family of locally equivariant multilayer perceptrons, attention layers, and convolutional networks, and provide an approach to make deep networks that preserve the local equivariance. This property allows us to propose a scalable training algorithm for the rate matrix such that the variance of the importance weights associated to the CTMC are minimal. We demonstrate the efficacy of LEAPS on problems in statistical physics.",
    "source": "arXiv"
  },
  {
    "title": "Responsive Noise-Relaying Diffusion Policy: Responsive and Efficient Visuomotor Control",
    "title_es": "Responsive Noise-Relaying Diffusion Policy: Responsive and Efficient Visuomotor Control",
    "url": "https://arxiv.org/abs/2502.12724",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.12724v2 Announce Type: replace \nAbstract: Imitation learning is an efficient method for teaching robots a variety of tasks. Diffusion Policy, which uses a conditional denoising diffusion process to generate actions, has demonstrated superior performance, particularly in learning from multi-modal demonstrates. However, it relies on executing multiple actions predicted from the same inference step to retain performance and prevent mode bouncing, which limits its responsiveness, as actions are not conditioned on the most recent observations. To address this, we introduce Responsive Noise-Relaying Diffusion Policy (RNR-DP), which maintains a noise-relaying buffer with progressively increasing noise levels and employs a sequential denoising mechanism that generates immediate, noise-free actions at the head of the sequence, while appending noisy actions at the tail. This ensures that actions are responsive and conditioned on the latest observations, while maintaining motion consistency through the noise-relaying buffer. This design enables the handling of tasks requiring responsive control, and accelerates action generation by reusing denoising steps. Experiments on response-sensitive tasks demonstrate that, compared to Diffusion Policy, ours achieves 18% improvement in success rate. Further evaluation on regular tasks demonstrates that RNR-DP also exceeds the best acceleration method (DDIM) by 6.9% in success rate, highlighting its computational efficiency advantage in scenarios where responsiveness is less critical. Our project page is available at https://rnr-dp.github.io",
    "source": "arXiv"
  },
  {
    "title": "Binary VPN Traffic Detection Using Wavelet Features and Machine Learning",
    "title_es": "Binary VPN Traffic Detection Using Wavelet Features and Machine Learning",
    "url": "https://arxiv.org/abs/2502.13804",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.13804v3 Announce Type: replace \nAbstract: Encrypted traffic classification faces growing challenges as encryption renders traditional deep packet inspection ineffective. This study addresses binary VPN detection, distinguishing VPN-encrypted from non-VPN traffic using wavelet transform-based features across multiple machine learning models. Unlike previous studies focused on application-level classification within encrypted traffic, we specifically evaluate the fundamental task of VPN identification regardless of application type. We analyze the impact of wavelet decomposition levels and dataset filtering on classification performance across significantly imbalanced data, where filtering reduces some traffic categories by up to 95%. Our results demonstrate that Random Forest (RF) achieves superior performance with an F1-score of 99%, maintaining robust accuracy even after significant dataset filtering. Neural Networks (NN) show comparable effectiveness with an F1-score of 98% when trained on wavelet level 12, while Support Vector Machines (SVM) exhibit notable sensitivity to dataset reduction, with F1-scores dropping from 90% to 85% after filtering. Comparing wavelet decomposition at levels 5 and 12, we observe improved classification performance at level 12, particularly for variable traffic types, though the marginal gains may not justify the additional computational overhead. These findings establish RF as the most reliable model for VPN traffic classification while highlighting key performance tradeoffs in feature extraction and preprocessing.",
    "source": "arXiv"
  },
  {
    "title": "RocketKV: Accelerating Long-Context LLM Inference via Two-Stage KV Cache Compression",
    "title_es": "RocketKV: Accelerating Long-Context LLM Inference via Two-Stage KV Cache Compression",
    "url": "https://arxiv.org/abs/2502.14051",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.14051v3 Announce Type: replace \nAbstract: Transformer-based Large Language Models rely critically on the KV cache to efficiently handle extended contexts during the decode phase. Yet, the size of the KV cache grows proportionally with the input length, burdening both memory bandwidth and capacity as decoding progresses. To address this challenge, we present RocketKV, a training-free KV cache compression strategy containing two consecutive stages. In the first stage, it performs coarse-grain permanent KV cache eviction on the input sequence tokens. In the second stage, it adopts a hybrid sparse attention method to conduct fine-grain top-k sparse attention, approximating the attention scores by leveraging both head and sequence dimensionality reductions. We show that RocketKV provides a compression ratio of up to 400$\\times$, end-to-end speedup of up to 3.7$\\times$ as well as peak memory reduction of up to 32.6% in the decode phase on an NVIDIA A100 GPU compared to the full KV cache baseline, while achieving negligible accuracy loss on a variety of long-context tasks. We also propose a variant of RocketKV for multi-turn scenarios, which consistently outperforms other existing methods and achieves accuracy nearly on par with an oracle top-k attention scheme. The source code is available here: https://github.com/NVlabs/RocketKV.",
    "source": "arXiv"
  },
  {
    "title": "EvoP: Robust LLM Inference via Evolutionary Pruning",
    "title_es": "EvoP: Robust LLM Inference via Evolutionary Pruning",
    "url": "https://arxiv.org/abs/2502.14910",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.14910v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) have achieved remarkable success in natural language processing tasks, but their massive size and computational demands hinder their deployment in resource-constrained environments. Existing model pruning methods address this issue by removing redundant structures (e.g., elements, channels, layers) from the model. However, these methods employ a heuristic pruning strategy, which leads to suboptimal performance. Besides, they also ignore the data characteristics when pruning the model.\n  To overcome these limitations, we propose EvoP, an evolutionary pruning framework for robust LLM inference. EvoP first presents a cluster-based calibration dataset sampling (CCDS) strategy for creating a more diverse calibration dataset. EvoP then introduces an evolutionary pruning pattern searching (EPPS) method to find the optimal pruning pattern. Compared to existing model pruning techniques, EvoP achieves the best performance while maintaining the best efficiency. Experiments across different LLMs and different downstream tasks validate the effectiveness of the proposed EvoP, making it a practical and scalable solution for deploying LLMs in real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "Verifying Quantized Graph Neural Networks is PSPACE-complete",
    "title_es": "Verifying Quantized Graph Neural Networks is PSPACE-complete",
    "url": "https://arxiv.org/abs/2502.16244",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.16244v2 Announce Type: replace \nAbstract: In this paper, we investigate the verification of quantized Graph Neural Networks (GNNs), where some fixed-width arithmetic is used to represent numbers. We introduce the linear-constrained validity (LVP) problem for verifying GNNs properties, and provide an efficient translation from LVP instances into a logical language. We show that LVP is in PSPACE, for any reasonable activation functions. We provide a proof system. We also prove PSPACE-hardness, indicating that while reasoning about quantized GNNs is feasible, it remains generally computationally challenging.",
    "source": "arXiv"
  },
  {
    "title": "Human2Robot: Learning Robot Actions from Paired Human-Robot Videos",
    "title_es": "Human2Robot: Learning Robot Actions from Paired Human-Robot Videos",
    "url": "https://arxiv.org/abs/2502.16587",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.16587v3 Announce Type: replace \nAbstract: Distilling knowledge from human demonstrations is a promising way for robots to learn and act. Existing methods, which often rely on coarsely-aligned video pairs, are typically constrained to learning global or task-level features. As a result, they tend to neglect the fine-grained frame-level dynamics required for complex manipulation and generalization to novel tasks. We posit that this limitation stems from a vicious circle of inadequate datasets and the methods they inspire. To break this cycle, we propose a paradigm shift that treats fine-grained human-robot alignment as a conditional video generation problem. To this end, we first introduce H&R, a novel third-person dataset containing 2,600 episodes of precisely synchronized human and robot motions, collected using a VR teleoperation system. We then present Human2Robot, a framework designed to leverage this data. Human2Robot employs a Video Prediction Model to learn a rich and implicit representation of robot dynamics by generating robot videos from human input, which in turn guides a decoupled action decoder. Our real-world experiments demonstrate that this approach not only achieves high performance on seen tasks but also exhibits significant one-shot generalization to novel positions, objects, instances, and even new task categories.",
    "source": "arXiv"
  },
  {
    "title": "Fast, Accurate Manifold Denoising by Tunneling Riemannian Optimization",
    "title_es": "Fast, Accurate Manifold Denoising by Tunneling Riemannian Optimization",
    "url": "https://arxiv.org/abs/2502.16819",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.16819v2 Announce Type: replace \nAbstract: Learned denoisers play a fundamental role in various signal generation (e.g., diffusion models) and reconstruction (e.g., compressed sensing) architectures, whose success derives from their ability to leverage low-dimensional structure in data. Existing denoising methods, however, either rely on local approximations that require a linear scan of the entire dataset or treat denoising as generic function approximation problems, often sacrificing efficiency and interpretability. We consider the problem of efficiently denoising a new noisy data point sampled from an unknown $d$-dimensional manifold $M \\in \\mathbb{R}^D$, using only noisy samples. This work proposes a framework for test-time efficient manifold denoising, by framing the concept of \"learning-to-denoise\" as \"learning-to-optimize\". We have two technical innovations: (i) online learning methods which learn to optimize over the manifold of clean signals using only noisy data, effectively \"growing\" an optimizer one sample at a time. (ii) mixed-order methods which guarantee that the learned optimizers achieve global optimality, ensuring both efficiency and near-optimal denoising performance. We corroborate these claims with theoretical analyses of both the complexity and denoising performance of mixed-order traversal. Our experiments on scientific manifolds demonstrate significantly improved complexity-performance tradeoffs compared to nearest neighbor search, which underpins existing provable denoising approaches based on exhaustive search.",
    "source": "arXiv"
  },
  {
    "title": "One-shot Optimized Steering Vectors Mediate Safety-relevant Behaviors in LLMs",
    "title_es": "One-shot Optimized Steering Vectors Mediate Safety-relevant Behaviors in LLMs",
    "url": "https://arxiv.org/abs/2502.18862",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.18862v2 Announce Type: replace \nAbstract: Steering vectors (SVs) have emerged as a promising approach for interpreting and controlling LLMs, but current methods typically require large contrastive datasets that are often impractical to construct and may capture spurious correlations. We propose directly optimizing SVs through gradient descent on a single training example, and systematically investigate how these SVs generalize. We consider several SV optimization techniques and find that the resulting SVs effectively mediate safety-relevant behaviors in multiple models. Indeed, in experiments on an alignment-faking model, we are able to optimize one-shot SVs that induce harmful behavior on benign examples and whose negations suppress harmful behavior on malign examples. And in experiments on refusal suppression, we demonstrate that one-shot optimized SVs can transfer across inputs, yielding a Harmbench attack success rate of 96.9%. Furthermore, we extend work on \"emergent misalignment\" and show that SVs optimized to induce a model to write vulnerable code cause the model to respond harmfully on unrelated open-ended prompts. Finally, we use one-shot SV optimization to investigate how an instruction-tuned LLM recovers from outputting false information, and find that this ability is independent of the model's explicit verbalization that the information was false. Overall, our findings suggest that optimizing SVs on a single example can mediate a wide array of misaligned behaviors in LLMs. Code can be found at https://github.com/jacobdunefsky/one-shot-steering-repro and https://github.com/jacobdunefsky/one-shot-steering-misalignment.",
    "source": "arXiv"
  },
  {
    "title": "Higher-order spectral element method for the stationary Stokes interface problem in two dimensions",
    "title_es": "Higher-order spectral element method for the stationary Stokes interface problem in two dimensions",
    "url": "https://arxiv.org/abs/2502.20039",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.20039v2 Announce Type: replace \nAbstract: This article presents a higher-order spectral element method for the two-dimensional Stokes interface problem involving a piecewise constant viscosity coefficient. The proposed numerical formulation is based on least-squares formulation. The mesh is aligned with the interface, and the interface is completely resolved using blending element functions. The higher-order spectral element functions are nonconforming, and the same-order approximation is used for both velocity and pressure variables. The interface conditions are added to the minimizing functional in appropriate Sobolev norms. Stability and error estimates are proven. The proposed method is shown to be exponentially accurate in both velocity and pressure variables. The theoretical estimates are validated through various numerical examples.",
    "source": "arXiv"
  },
  {
    "title": "RIZE: Regularized Imitation Learning via Distributional Reinforcement Learning",
    "title_es": "RIZE: Regularized Imitation Learning via Distributional Reinforcement Learning",
    "url": "https://arxiv.org/abs/2502.20089",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.20089v2 Announce Type: replace \nAbstract: We propose a novel Inverse Reinforcement Learning (IRL) method that mitigates the rigidity of fixed reward structures and the limited flexibility of implicit reward regularization. Building on the Maximum Entropy IRL framework, our approach incorporates a squared temporal-difference (TD) regularizer with adaptive targets that evolve dynamically during training, thereby imposing adaptive bounds on recovered rewards and promoting robust decision-making. To capture richer return information, we integrate distributional RL into the learning process. Empirically, our method achieves expert-level performance on complex MuJoCo tasks, surpassing baseline methods on the Humanoid task with 3 demonstrations. Extensive experiments and ablation studies further validate the effectiveness of the approach and provide insights into reward dynamics in imitation learning.",
    "source": "arXiv"
  },
  {
    "title": "Underdamped Diffusion Bridges with Applications to Sampling",
    "title_es": "Underdamped Diffusion Bridges with Applications to Sampling",
    "url": "https://arxiv.org/abs/2503.01006",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.01006v2 Announce Type: replace \nAbstract: We provide a general framework for learning diffusion bridges that transport prior to target distributions. It includes existing diffusion models for generative modeling, but also underdamped versions with degenerate diffusion matrices, where the noise only acts in certain dimensions. Extending previous findings, our framework allows to rigorously show that score matching in the underdamped case is indeed equivalent to maximizing a lower bound on the likelihood. Motivated by superior convergence properties and compatibility with sophisticated numerical integration schemes of underdamped stochastic processes, we propose \\emph{underdamped diffusion bridges}, where a general density evolution is learned rather than prescribed by a fixed noising process. We apply our method to the challenging task of sampling from unnormalized densities without access to samples from the target distribution. Across a diverse range of sampling problems, our approach demonstrates state-of-the-art performance, notably outperforming alternative methods, while requiring significantly fewer discretization steps and no hyperparameter tuning.",
    "source": "arXiv"
  },
  {
    "title": "Stability Analysis and Intervention Strategies on a Coupled SIS Epidemic Model with Polar Opinion Dynamics",
    "title_es": "Stability Analysis and Intervention Strategies on a Coupled SIS Epidemic Model with Polar Opinion Dynamics",
    "url": "https://arxiv.org/abs/2503.01285",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.01285v2 Announce Type: replace \nAbstract: This paper investigates the spread of infectious diseases within a networked community by integrating epidemic transmission and public opinion dynamics. We propose a novel discrete-time networked SIS (Susceptible-Infectious-Susceptible) epidemic model coupled with opinion dynamics that includes stubborn agents with biased views. The model captures the interplay between perceived and actual epidemic severity, offering insights into epidemic dynamics in socially interconnected environments. We introduce the SIS-opinion reproduction number to assess epidemic severity and analyze conditions for disease eradication and the global stability of endemic equilibria. Additionally, we explore opinion-based intervention strategies, providing a framework for policymakers to design effective prevention measures. Numerical examples are provided to illustrate our theoretical findings and the model's practical implications.",
    "source": "arXiv"
  },
  {
    "title": "Generative Active Adaptation for Drifting and Imbalanced Network Intrusion Detection",
    "title_es": "Generative Active Adaptation for Drifting and Imbalanced Network Intrusion Detection",
    "url": "https://arxiv.org/abs/2503.03022",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.03022v2 Announce Type: replace \nAbstract: Machine learning has shown promise in network intrusion detection systems, yet its performance often degrades due to concept drift and imbalanced data. These challenges are compounded by the labor-intensive process of labeling network traffic, especially when dealing with evolving and rare attack types, which makes preparing the right data for adaptation difficult. To address these issues, we propose a generative active adaptation framework that minimizes labeling effort while enhancing model robustness. Our approach employs density-aware dataset prior selection to identify the most informative samples for annotation, and leverages deep generative models to conditionally synthesize diverse samples, thereby augmenting the training set and mitigating the effects of concept drift. We evaluate our end-to-end framework \\NetGuard on both simulated IDS data and a real-world ISP dataset, demonstrating significant improvements in intrusion detection performance. Our method boosts the overall F1-score from 0.60 (without adaptation) to 0.86. Rare attacks such as Infiltration, Web Attack, and FTP-BruteForce, which originally achieved F1 scores of 0.001, 0.04, and 0.00, improve to 0.30, 0.50, and 0.71, respectively, with generative active adaptation in the CIC-IDS 2018 dataset. Our framework effectively enhances rare attack detection while reducing labeling costs, making it a scalable and practical solution for intrusion detection.",
    "source": "arXiv"
  },
  {
    "title": "REACT: Real-time Efficient Attribute Clustering and Transfer for Updatable 3D Scene Graph",
    "title_es": "REACT: Real-time Efficient Attribute Clustering and Transfer for Updatable 3D Scene Graph",
    "url": "https://arxiv.org/abs/2503.03412",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.03412v2 Announce Type: replace \nAbstract: Modern-day autonomous robots need high-level map representations to perform sophisticated tasks. Recently, 3D scene graphs (3DSGs) have emerged as a promising alternative to traditional grid maps, blending efficient memory use and rich feature representation. However, most efforts to apply them have been limited to static worlds. This work introduces REACT, a framework that efficiently performs real-time attribute clustering and transfer to relocalize object nodes in a 3DSG. REACT employs a novel method for comparing object instances using an embedding model trained on triplet loss, facilitating instance clustering and matching. Experimental results demonstrate that REACT is able to relocalize objects while maintaining computational efficiency. The REACT framework's source code will be available as an open-source project, promoting further advancements in reusable and updatable 3DSGs.",
    "source": "arXiv"
  },
  {
    "title": "Simulating the Real World: A Unified Survey of Multimodal Generative Models",
    "title_es": "Simulating the Real World: A Unified Survey of Multimodal Generative Models",
    "url": "https://arxiv.org/abs/2503.04641",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.04641v2 Announce Type: replace \nAbstract: Understanding and replicating the real world is a critical challenge in Artificial General Intelligence (AGI) research. To achieve this, many existing approaches, such as world models, aim to capture the fundamental principles governing the physical world, enabling more accurate simulations and meaningful interactions. However, current methods often treat different modalities, including 2D (images), videos, 3D, and 4D representations, as independent domains, overlooking their interdependencies. Additionally, these methods typically focus on isolated dimensions of reality without systematically integrating their connections. In this survey, we present a unified survey for multimodal generative models that investigate the progression of data dimensionality in real-world simulation. Specifically, this survey starts from 2D generation (appearance), then moves to video (appearance+dynamics) and 3D generation (appearance+geometry), and finally culminates in 4D generation that integrate all dimensions. To the best of our knowledge, this is the first attempt to systematically unify the study of 2D, video, 3D and 4D generation within a single framework. To guide future research, we provide a comprehensive review of datasets, evaluation metrics and future directions, and fostering insights for newcomers. This survey serves as a bridge to advance the study of multimodal generative models and real-world simulation within a unified framework.",
    "source": "arXiv"
  },
  {
    "title": "Shifting Perspectives: Steering Vectors for Robust Bias Mitigation in LLMs",
    "title_es": "Shifting Perspectives: Steering Vectors for Robust Bias Mitigation in LLMs",
    "url": "https://arxiv.org/abs/2503.05371",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.05371v2 Announce Type: replace \nAbstract: We present a novel approach to bias mitigation in large language models (LLMs) by applying steering vectors to modify model activations in forward passes. We compute 8 steering vectors, each corresponding to a different social bias axis, such as age, gender, or race, on a training subset of the BBQ dataset and compare the effectiveness of these to 3 additional bias mitigation methods across 4 datasets. When optimized on the BBQ dataset, our individually tuned steering vectors achieve average improvements of 12.8% on BBQ, 8.3% on CLEAR-Bias, and 1% on StereoSet, and show improvements over prompting and Self-Debias in all cases, and improvements over fine-tuning in 12 out of 17 evaluations. In addition, steering vectors showed the lowest impact on MMLU scores of the four bias mitigation methods tested. The work presents the first systematic investigation of steering vectors for bias mitigation, and we demonstrate that they are a powerful and computationally efficient strategy for reducing bias in LLMs, with broader implications for enhancing AI safety.",
    "source": "arXiv"
  },
  {
    "title": "The Illusory Normativity of Rights-Based AI Regulation",
    "title_es": "The Illusory Normativity of Rights-Based AI Regulation",
    "url": "https://arxiv.org/abs/2503.05784",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.05784v2 Announce Type: replace \nAbstract: Whether and how to regulate AI is now a central question of governance. Across academic, policy, and international legal circles, the European Union is widely treated as the normative leader in this space. Its regulatory framework, anchored in the General Data Protection Regulation, the Digital Services and Markets Acts, and the AI Act, is often portrayed as a principled model grounded in fundamental rights. This Article challenges that assumption. We argue that the rights-based narrative surrounding EU AI regulation mischaracterizes the logic of its institutional design. While rights language pervades EU legal instruments, its function is managerial, not foundational. These rights operate as tools of administrative ordering, used to mitigate technological disruption, manage geopolitical risk, and preserve systemic balance, rather than as expressions of moral autonomy or democratic consent. Drawing on comparative institutional analysis, we situate EU AI governance within a longer tradition of legal ordering shaped by the need to coordinate power across fragmented jurisdictions. We contrast this approach with the American model, which reflects a different regulatory logic rooted in decentralized authority, sectoral pluralism, and a constitutional preference for innovation and individual autonomy. Through case studies in five key domains -- data privacy, cybersecurity, healthcare, labor, and disinformation -- we show that EU regulation is not meaningfully rights-driven, as is often claimed. It is instead structured around the containment of institutional risk. Our aim is not to endorse the American model but to reject the presumption that the EU approach reflects a normative ideal that other nations should uncritically adopt. The EU model is best understood as a historically contingent response to its own political conditions, not a template for others to blindly follow.",
    "source": "arXiv"
  },
  {
    "title": "Towards Synthesized and Editable Motion In-Betweening Through Part-Wise Phase Representation",
    "title_es": "Towards Synthesized and Editable Motion In-Betweening Through Part-Wise Phase Representation",
    "url": "https://arxiv.org/abs/2503.08180",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.08180v3 Announce Type: replace \nAbstract: Styled motion in-betweening is crucial for computer animation and gaming. However, existing methods typically encode motion styles by modeling whole-body motions, often overlooking the representation of individual body parts. This limitation reduces the flexibility of infilled motion, particularly in adjusting the motion styles of specific limbs independently. To overcome this challenge, we propose a novel framework that models motion styles at the body-part level, enhancing both the diversity and controllability of infilled motions. Our approach enables more nuanced and expressive animations by allowing precise modifications to individual limb motions while maintaining overall motion coherence. Leveraging phase-related insights, our framework employs periodic autoencoders to automatically extract the phase of each body part, capturing distinctive local style features. Additionally, we effectively decouple the motion source from synthesis control by integrating motion manifold learning and conditional generation techniques from both image and motion domains. This allows the motion source to generate high-quality motions across various styles, with extracted motion and style features readily available for controlled synthesis in subsequent tasks. Comprehensive evaluations demonstrate that our method achieves superior speed, robust generalization, and effective generation of extended motion sequences.",
    "source": "arXiv"
  },
  {
    "title": "MetaFold: Language-Guided Multi-Category Garment Folding Framework via Trajectory Generation and Foundation Model",
    "title_es": "MetaFold: Language-Guided Multi-Category Garment Folding Framework via Trajectory Generation and Foundation Model",
    "url": "https://arxiv.org/abs/2503.08372",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.08372v2 Announce Type: replace \nAbstract: Garment folding is a common yet challenging task in robotic manipulation. The deformability of garments leads to a vast state space and complex dynamics, which complicates precise and fine-grained manipulation. Previous approaches often rely on predefined key points or demonstrations, limiting their generalization across diverse garment categories. This paper presents a framework, MetaFold, that disentangles task planning from action prediction, learning each independently to enhance model generalization. It employs language-guided point cloud trajectory generation for task planning and a low-level foundation model for action prediction. This structure facilitates multi-category learning, enabling the model to adapt flexibly to various user instructions and folding tasks. Experimental results demonstrate the superiority of our proposed framework. Supplementary materials are available on our website: https://meta-fold.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "Routing Guidance for Emerging Transportation Systems with Improved Dynamic Trip Equity",
    "title_es": "Routing Guidance for Emerging Transportation Systems with Improved Dynamic Trip Equity",
    "url": "https://arxiv.org/abs/2503.12601",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.12601v3 Announce Type: replace \nAbstract: This paper presents a dynamic routing guidance system that optimizes route recommendations for individual vehicles in an emerging transportation system while enhancing travelers' trip equity. We develop a framework to quantify trip quality and equity in dynamic travel environments, providing new insights into how routing guidance influences equity in road transportation. Our approach enables real-time routing by incorporating both monitored and anticipated traffic congestion. We provide conditions that ensure perfect trip equity for all travelers in a free-flow network. Simulation studies on 1,000 vehicles traversing an urban road network in Boston demonstrate that our method improves trip equity by approximately 11.4\\% compared to the shortest-route strategy. In addition, the results reveal that our approach redistributes travel costs across vehicle types through route optimization, contributing to a more equitable transportation system.",
    "source": "arXiv"
  },
  {
    "title": "Decentralization: A Qualitative Survey of Node Operators",
    "title_es": "Decentralization: A Qualitative Survey of Node Operators",
    "url": "https://arxiv.org/abs/2503.17246",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.17246v4 Announce Type: replace \nAbstract: Decentralization is understood both by professionals in the blockchain industry and general users as a core design goal of permissionless ledgers. However, its meaning is far from universally agreed, and often it is easier to get opinions on what it is not, rather than what it is. In this paper, we solicit definitions of 'decentralization' and 'decentralization theatre' from blockchain node operators. Key to a definition is asking about effective decentralization strategies, as well as those that are ineffective, sometimes deliberately so. Malicious, deceptive, or incompetent strategies are commonly referred to by the term 'decentralization theatre.' Finally, we ask what is being decentralized. Via thematic analysis of interview transcripts, we find that most operators conceive decentralization as existing broadly on a technical and a governance axis. Isolating relevant variables, we collapse the categories to network topology and governance topology, or the structure of decision-making power. Our key finding is that `decentralization' alone does not affect ledger immutability or systemic robustness.",
    "source": "arXiv"
  },
  {
    "title": "GranQ: Granular Zero-Shot Quantization with Channel-Wise Activation Scaling in QAT",
    "title_es": "GranQ: Granular Zero-Shot Quantization with Channel-Wise Activation Scaling in QAT",
    "url": "https://arxiv.org/abs/2503.18339",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.18339v5 Announce Type: replace \nAbstract: Zero-shot quantization (ZSQ) enables neural network compression without original training data, making it a promising solution for restricted data access scenarios. To compensate for the lack of data, recent ZSQ methods typically rely on synthetic inputs generated from the full-precision model. However, these synthetic inputs often lead to activation distortion, especially under low-bit settings. To mitigate this, existing methods typically employ per-channel scaling, but they still struggle due to the severe computational overhead during the accumulation process. To overcome this critical bottleneck, we propose GranQ, a novel activation quantization framework that introduces an efficient pre-scaling strategy. Unlike conventional channel-wise methods that repeatedly perform scaling operations during accumulation, GranQ applies scaling factors in a pre-scaling step through fully vectorized computation, eliminating runtime scaling overhead. This design enables GranQ to maintain fine-grained quantization accuracy while significantly reducing computational burden, particularly in low-bit quantization settings. Extensive experiments under quantization-aware training (QAT) settings demonstrate that GranQ consistently outperforms state-of-the-art ZSQ methods across CIFAR and ImageNet. In particular, our method achieves up to 5.45% higher accuracy in the 3-bit setting on CIFAR-100 and even surpasses the full-precision baseline on CIFAR-10. Furthermore, GranQ achieves significant speedup in quantization latency over conventional per-channel methods, demonstrating improved efficiency. With these findings, we anticipate that GranQ will inspire future research beyond conventional ZSQ approaches centered on data generation and model fine-tuning. The official code is available at https://github.com/anonymus-orange/GranQ.",
    "source": "arXiv"
  },
  {
    "title": "Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models",
    "title_es": "Video SimpleQA: Towards Factuality Evaluation in Large Video Language Models",
    "url": "https://arxiv.org/abs/2503.18923",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.18923v2 Announce Type: replace \nAbstract: Recent advancements in Large Video Language Models (LVLMs) have highlighted their potential for multi-modal understanding, yet evaluating their factual grounding in videos remains a critical unsolved challenge. To address this gap, we introduce Video SimpleQA, the first comprehensive benchmark tailored for factuality evaluation in video contexts. Our work differs from existing video benchmarks through the following key features: 1) Knowledge required: demanding integration of external knowledge beyond the video's explicit narrative; 2) Multi-hop fact-seeking question: Each question involves multiple explicit facts and requires strict factual grounding without hypothetical or subjective inferences. We also include per-hop single-fact-based sub-QAs alongside final QAs to enable fine-grained, stepby-step evaluation; 3) Short-form definitive answer: Answers are crafted as unambiguous and definitively correct in a short format with minimal scoring variance; 4) Temporal grounded required: Requiring answers to rely on one or more temporal segments in videos, rather than single frames. We extensively evaluate 33 state-of-the-art LVLMs and summarize key findings as follows: 1) Current LVLMs exhibit notable deficiencies in factual adherence, with the best-performing model o3 merely achieving an F-score of 66.3%; 2) Most LVLMs are overconfident in what they generate, with self-stated confidence exceeding actual accuracy; 3) Retrieval-augmented generation demonstrates consistent improvements at the cost of additional inference time overhead; 4) Multi-hop QA demonstrates substantially degraded performance compared to single-hop sub-QAs, with first-hop object or event recognition emerging as the primary bottleneck. We position Video SimpleQA as the cornerstone benchmark for video factuality assessment, aiming to steer LVLM development toward verifiable grounding in real-world contexts.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Inference for Large Reasoning Models: A Survey",
    "title_es": "Efficient Inference for Large Reasoning Models: A Survey",
    "url": "https://arxiv.org/abs/2503.23077",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.23077v3 Announce Type: replace \nAbstract: Large Reasoning Models (LRMs) significantly improve the reasoning ability of Large Language Models (LLMs) by learning to reason, exhibiting promising performance in solving complex tasks. However, their deliberative reasoning process leads to inefficiencies in token usage, memory consumption, and inference time. Thus, this survey provides a review of efficient inference methods designed specifically for LRMs, focusing on mitigating token inefficiency while preserving the reasoning quality. The overview structure of this paper is shown in Figure~\\ref{fig:paper_structure}. First, we introduce a taxonomy to group the recent methods into two main categories: (a) explicit compact Chain-of-Thought (CoT), which reduces tokens while keeping the explicit reasoning structure, and (b) implicit latent CoT, which encodes reasoning steps within hidden representations instead of explicit tokens. Meanwhile, we discuss their strengths and weaknesses. Then, we conduct empirical analyses on existing methods from reasoning scenarios, object functions, and performance \\& efficiency aspects. Besides, we present open challenges in this field, including human-centric controllable reasoning, trade-off between interpretability and efficiency of reasoning, ensuring the safety of efficient reasoning, and broader applications of efficient reasoning. In addition, we highlight key insights for enhancing LRMs' inference efficiency via techniques such as model merging, new architectures, and agent routers. We hope this work serves as a valuable guide, helping researchers overcome challenges in this vibrant field. A collection of efficient reasoning methods for LRMs (papers and codes) is provided at this link: https://github.com/yueliu1999/Awesome-Efficient-Inference-for-LRMs.",
    "source": "arXiv"
  },
  {
    "title": "NeuralGS: Bridging Neural Fields and 3D Gaussian Splatting for Compact 3D Representations",
    "title_es": "NeuralGS: Bridging Neural Fields and 3D Gaussian Splatting for Compact 3D Representations",
    "url": "https://arxiv.org/abs/2503.23162",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2503.23162v2 Announce Type: replace \nAbstract: 3D Gaussian Splatting (3DGS) achieves impressive quality and rendering speed, but with millions of 3D Gaussians and significant storage and transmission costs. In this paper, we aim to develop a simple yet effective method called NeuralGS that compresses the original 3DGS into a compact representation. Our observation is that neural fields like NeRF can represent complex 3D scenes with Multi-Layer Perceptron (MLP) neural networks using only a few megabytes. Thus, NeuralGS effectively adopts the neural field representation to encode the attributes of 3D Gaussians with MLPs, only requiring a small storage size even for a large-scale scene. To achieve this, we adopt a clustering strategy and fit the Gaussians within each cluster using different tiny MLPs, based on importance scores of Gaussians as fitting weights. We experiment on multiple datasets, achieving a 91-times average model size reduction without harming the visual quality.",
    "source": "arXiv"
  },
  {
    "title": "Directional excitability in Hilbert spaces",
    "title_es": "Directional excitability in Hilbert spaces",
    "url": "https://arxiv.org/abs/2504.00297",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.00297v2 Announce Type: replace \nAbstract: We introduce a generalized excitable system in which spikes can happen in a continuum of directions, therefore drastically enriching the expressivity and control capability of the spiking dynamics. In this generalized excitable system, spiking trajectories happen in a Hilbert space with an excitable resting state at the origin and spike responses that can be triggered in any direction as a function of the system's state and inputs. State-dependence of the spiking direction provide the system with a vanishing spiking memory trace, which enables robust tracking and integration of inputs in the spiking direction history. The model exhibits generalized forms of both Hodgkin's Type I and Type II excitability, capturing their usual bifurcation behaviors in an abstract setting. When used as the controller of a two-dimensional navigation task, this model facilitates both the sparseness of the actuation and its sensitivity to environmental inputs. These results highlight the potential of the proposed generalized excitable model for excitable control in high- and infinite-dimensional spaces.",
    "source": "arXiv"
  },
  {
    "title": "Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models",
    "title_es": "Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models",
    "url": "https://arxiv.org/abs/2504.01137",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.01137v2 Announce Type: replace \nAbstract: Text-to-image (T2I) models generate images by encoding text prompts into token representations, which then guide the diffusion process. While prior work has largely focused on improving alignment by refining the diffusion process, we focus on the textual encoding stage. Specifically, we investigate how semantic information is distributed across token representations within and between lexical items (i.e., words or expressions conveying a single concept) in the prompt. We analyze information flow at two levels: (1) in-item representation-whether individual tokens represent their lexical item, and (2) cross-item interaction-whether information flows across the tokens of different lexical items. We use patching techniques to uncover surprising encoding patterns. We find information is usually concentrated in only one or two of the item's tokens-For example, in the item \"San Francisco's Golden Gate Bridge\", the token \"Gate\" sufficiently captures the entire expression while the other tokens could effectively be discarded. Lexical items also tend to remain isolated; for instance, the token \"dog\" encodes no visual information about \"green\" in the prompt \"a green dog\". However, in some cases, items do influence each other's representation, often leading to misinterpretations-e.g., in the prompt \"a pool by a table\", the token pool represents a pool table after contextualization. Our findings highlight the critical role of token-level encoding in image generation, suggesting that misalignment issues may originate already during the textual encoding.",
    "source": "arXiv"
  },
  {
    "title": "The Polynomial Set Associated with a Fixed Number of Matrix-Matrix Multiplications",
    "title_es": "The Polynomial Set Associated with a Fixed Number of Matrix-Matrix Multiplications",
    "url": "https://arxiv.org/abs/2504.01500",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.01500v3 Announce Type: replace \nAbstract: We consider the problem of computing matrix polynomials $p(X)$, where $X$ is a large dense matrix, with as few matrix-matrix multiplications as possible. More precisely, let $\\Pi_{2^{m}}^*$ represent the set of polynomials computable with $m$ matrix-matrix multiplications, but with an arbitrary number of matrix additions and scaling operations. We characterize this set through a tabular parameterization. By deriving equivalence transformations of the tabular representation, we establish new methods that can be used to construct elements of $\\Pi_{2^{m}}^*$ and determine general properties of the set. The transformations allow us to eliminate variables and prove that the dimension is bounded by $m^2$, which is subsequently proven to be sharp, i.e., $\\dim(\\Pi_{2^m}^*)=m^2$. Consequently, we have identified a parameterization that, to the best of our knowledge, is the first minimal parameterization. We also conduct a study using computational tools from algebraic geometry to determine the largest degree $d$ such that all polynomials of that degree belong to $\\Pi_{2^{m}}^*$, or its closure. In many cases, the computational setup is constructive in the sense that it can also be used to determine a specific evaluation scheme for a given polynomial.",
    "source": "arXiv"
  },
  {
    "title": "Distributed Triangle Detection is Hard in Few Rounds",
    "title_es": "Distributed Triangle Detection is Hard in Few Rounds",
    "url": "https://arxiv.org/abs/2504.01802",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.01802v2 Announce Type: replace \nAbstract: In the distributed triangle detection problem, we have an $n$-vertex network $G=(V,E)$ with one player for each vertex of the graph who sees the edges incident on the vertex. The players communicate in synchronous rounds using the edges of this network and have a limited bandwidth of $O(\\log{n})$ bits over each edge. The goal is to detect whether or not $G$ contains a triangle as a subgraph in a minimal number of rounds.\n  We prove that any protocol (deterministic or randomized) for distributed triangle detection requires $\\Omega(\\log\\log{n})$ rounds of communication. Prior to our work, only one-round lower bounds were known for this problem.\n  The primary technique for proving these types of distributed lower bounds is via reductions from two-party communication complexity. However, it has been known for a while that this approach is provably incapable of establishing any meaningful lower bounds for distributed triangle detection. Our main technical contribution is a new information theoretic argument which combines recent advances on multi-pass graph streaming lower bounds with the point-to-point communication aspects of distributed models, and can be of independent interest.",
    "source": "arXiv"
  },
  {
    "title": "SymCERE: Symmetric Contrastive Learning for Robust Review-Enhanced Recommendation",
    "title_es": "SymCERE: Symmetric Contrastive Learning for Robust Review-Enhanced Recommendation",
    "url": "https://arxiv.org/abs/2504.02195",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.02195v2 Announce Type: replace \nAbstract: Modern recommendation systems can achieve high performance by fusing user behavior graphs (via GNNs) and review texts (via LLMs). However, this fusion faces three significant issues: (1) False Negatives in contrastive learning can degrade the training signal by penalizing similar items; (2) Popularity Bias, often encoded as embedding magnitude, can distort similarity scores; and (3) Signal Ambiguity, which arises from the conflation of objective facts with subjective sentiment in reviews. These interconnected issues can prevent models from learning users' true preferences. In this paper, we propose SymCERE (Symmetric SINCERE), a contrastive learning method that addresses these three issues simultaneously through its structural design. First, we introduce a symmetric application of the SINCERE loss for cross-modal alignment, which is designed to eliminate false negatives in recommendation. Second, by integrating this with L2 normalisation under a \"magnitude-as-noise\" hypothesis, we aim to mitigate popularity bias by forcing the model to encode preferences primarily in the vector's direction. Experiments on 15 datasets from three distinct platforms (e-commerce, local reviews, and travel) demonstrate that SymCERE outperforms several strong baselines, achieving a relative improvement of up to 43.6% on NDCG@10. Furthermore, a detailed LIME analysis shows that the model learns to anchor alignment on objective, informative vocabulary (e.g., \"OEM,\" \"compatible,\" \"gasket\"), while placing less emphasis on generic sentiment (e.g., \"good,\" \"great\"). This suggests that effective semantic alignment stems from understanding factual product attributes, offering a path toward more accurate recommendation systems. The code is available at: https://anonymous.4open.science/r/ReviewGNN-2E1E.",
    "source": "arXiv"
  },
  {
    "title": "FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault Tolerant Attention",
    "title_es": "FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault Tolerant Attention",
    "url": "https://arxiv.org/abs/2504.02211",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.02211v2 Announce Type: replace \nAbstract: Transformer models rely on High-Performance Computing (HPC) resources for inference, where soft errors are inevitable in large-scale systems, making the reliability of the model particularly critical. Existing fault tolerance frameworks for Transformers are designed at the operation level without architectural optimization, leading to significant computational and memory overhead, which in turn reduces protection efficiency and limits scalability to larger models. In this paper, we implement module-level protection for Transformers by treating the operations within the attention module as a single kernel and applying end-to-end fault tolerance. This method provides unified protection across multi-step computations, while achieving comprehensive coverage of potential errors in the nonlinear computations. For linear modules, we design a strided algorithm-based fault tolerance (ABFT) that avoids inter-thread communication. Experimental results show that our end-to-end fault tolerance achieves up to 7.56x speedup over traditional methods with an average fault tolerance overhead of 13.9%.",
    "source": "arXiv"
  },
  {
    "title": "On learning racing policies with reinforcement learning",
    "title_es": "On learning racing policies with reinforcement learning",
    "url": "https://arxiv.org/abs/2504.02420",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.02420v2 Announce Type: replace \nAbstract: Fully autonomous vehicles promise enhanced safety and efficiency. However, ensuring reliable operation in challenging corner cases requires control algorithms capable of performing at the vehicle limits. We address this requirement by considering the task of autonomous racing and propose solving it by learning a racing policy using Reinforcement Learning (RL). Our approach leverages domain randomization, actuator dynamics modeling, and policy architecture design to enable reliable and safe zero-shot deployment on a real platform. Evaluated on the F1TENTH race car, our RL policy not only surpasses a state-of-the-art Model Predictive Control (MPC), but, to the best of our knowledge, also represents the first instance of an RL policy outperforming expert human drivers in RC racing. This work identifies the key factors driving this performance improvement, providing critical insights for the design of robust RL-based control strategies for autonomous vehicles.",
    "source": "arXiv"
  },
  {
    "title": "CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization",
    "title_es": "CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization",
    "url": "https://arxiv.org/abs/2504.04310",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.04310v2 Announce Type: replace \nAbstract: Although LLM-based agents have attracted significant attention in domains such as software engineering and machine learning research, their role in advancing combinatorial optimization (CO) remains relatively underexplored. This gap underscores the need for a deeper understanding of their potential in tackling structured, constraint-intensive problems -- a pursuit currently limited by the absence of comprehensive benchmarks for systematic investigation. To address this, we introduce CO-Bench, a benchmark suite featuring 36 real-world CO problems drawn from a broad range of domains and complexity levels. CO-Bench includes structured problem formulations and curated data to support rigorous investigation of LLM agents. We evaluate multiple agentic frameworks against established human-designed algorithms, revealing the strengths and limitations of existing LLM agents and identifying promising directions for future research. CO-Bench is publicly available at https://github.com/sunnweiwei/CO-Bench.",
    "source": "arXiv"
  },
  {
    "title": "CRDT Emulation, Simulation, and Representation Independence",
    "title_es": "CRDT Emulation, Simulation, and Representation Independence",
    "url": "https://arxiv.org/abs/2504.05398",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.05398v2 Announce Type: replace \nAbstract: Conflict-free replicated data types (CRDTs) are distributed data structures designed for fault tolerance and high availability. CRDTs have historically been taxonomized into state-based CRDTs, in which replicas apply updates locally and periodically broadcast their state to other replicas over the network, and operation-based (or op-based) CRDTs, in which every state-updating operation is individually broadcast. In the literature, state-based and op-based CRDTs are considered equivalent due to the existence of algorithms that let them emulate each other, and verification techniques and results that apply to one kind of CRDT are said to apply to the other thanks to this equivalence. However, what it means for state-based and op-based CRDTs to emulate each other has never been made fully precise. Emulation is nontrivial since state-based and op-based CRDTs place different requirements on the underlying network with regard to both the causal ordering of message delivery, and the granularity of the messages themselves.\n  We specify and formalize CRDT emulation in terms of simulation by modeling CRDTs and their interactions with the network as transition systems. We show that emulation can be understood as weak simulations between the transition systems of the original and emulating CRDT systems, thus closing a gap in the CRDT literature. We precisely characterize which properties of CRDT systems are preserved by our weak simulations, and therefore which properties can be said to be preserved by emulation algorithms. Finally, we leverage our emulation results to obtain a general representation independence result for CRDTs: intuitively, clients of a CRDT cannot tell whether they are interacting with a state-based or op-based CRDT in particular.",
    "source": "arXiv"
  },
  {
    "title": "Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for Mobile Robot Path Planning",
    "title_es": "Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for Mobile Robot Path Planning",
    "url": "https://arxiv.org/abs/2504.05921",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.05921v2 Announce Type: replace \nAbstract: In this study, we present a simple and intuitive method for accelerating optimal Reeds-Shepp path computation. Our approach uses geometrical reasoning to analyze the behavior of optimal paths, resulting in a new partitioning of the state space and a further reduction in the minimal set of viable paths. We revisit and reimplement classic methodologies from the literature, which lack contemporary open-source implementations, to serve as benchmarks for evaluating our method. Additionally, we address the under-specified Reeds-Shepp planning problem where the final orientation is unspecified. We perform exhaustive experiments to validate our solutions. Compared to the modern C++ implementation of the original Reeds-Shepp solution in the Open Motion Planning Library, our method demonstrates a 15x speedup, while classic methods achieve a 5.79x speedup. Both approaches exhibit machine-precision differences in path lengths compared to the original solution. We release our proposed C++ implementations for both the accelerated and under-specified Reeds-Shepp problems as open-source code.",
    "source": "arXiv"
  },
  {
    "title": "Mosaic: Composite Projection Pruning for Resource-efficient LLMs",
    "title_es": "Mosaic: Composite Projection Pruning for Resource-efficient LLMs",
    "url": "https://arxiv.org/abs/2504.06323",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.06323v2 Announce Type: replace \nAbstract: Extensive compute and memory requirements limit the deployment of large language models (LLMs) on any hardware. Compression methods, such as pruning, can reduce model size, which in turn reduces resource requirements. State-of-the-art pruning is based on coarse-grained methods. They are time-consuming and inherently remove critical model parameters, adversely impacting the quality of the pruned model. This paper introduces projection pruning, a novel fine-grained method for pruning LLMs. In addition, LLM projection pruning is enhanced by a new approach we refer to as composite projection pruning - the synergistic combination of unstructured pruning that retains accuracy and structured pruning that reduces model size. We develop Mosaic, a novel system to create and deploy pruned LLMs using composite projection pruning. Mosaic is evaluated using a range of performance and quality metrics on multiple hardware platforms, LLMs, and datasets. Mosaic is 7.19x faster in producing models than existing approaches. Mosaic models achieve up to 84.2% lower perplexity and 31.4% higher accuracy than models obtained from coarse-grained pruning. Up to 67% faster inference and 68% lower GPU memory use is noted for Mosaic models. Mosaic is available for public use from https://github.com/blessonvar/Mosaic",
    "source": "arXiv"
  },
  {
    "title": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes",
    "title_es": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes",
    "url": "https://arxiv.org/abs/2504.06866",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.06866v2 Announce Type: replace \nAbstract: Robust grasping in cluttered environments remains an open challenge in robotics. While benchmark datasets have significantly advanced deep learning methods, they mainly focus on simplistic scenes with light occlusion and insufficient diversity, limiting their applicability to practical scenarios. We present GraspClutter6D, a large-scale real-world grasping dataset featuring: (1) 1,000 highly cluttered scenes with dense arrangements (14.1 objects/scene, 62.6\\% occlusion), (2) comprehensive coverage across 200 objects in 75 environment configurations (bins, shelves, and tables) captured using four RGB-D cameras from multiple viewpoints, and (3) rich annotations including 736K 6D object poses and 9.3B feasible robotic grasps for 52K RGB-D images. We benchmark state-of-the-art segmentation, object pose estimation, and grasp detection methods to provide key insights into challenges in cluttered environments. Additionally, we validate the dataset's effectiveness as a training resource, demonstrating that grasping networks trained on GraspClutter6D significantly outperform those trained on existing datasets in both simulation and real-world experiments. The dataset, toolkit, and annotation tools are publicly available on our project website: https://sites.google.com/view/graspclutter6d.",
    "source": "arXiv"
  },
  {
    "title": "AI-Slop to AI-Polish? Aligning Language Models through Edit-Based Writing Rewards and Test-time Computation",
    "title_es": "AI-Slop to AI-Polish? Aligning Language Models through Edit-Based Writing Rewards and Test-time Computation",
    "url": "https://arxiv.org/abs/2504.07532",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.07532v3 Announce Type: replace \nAbstract: AI-generated text is proliferating across domains, from creative writing and journalism to marketing content and scientific articles. Models can follow user-provided instructions to generate coherent and grammatically correct outputs but in this work, we study a more fundamental question: how do we evaluate and improve the writing quality of AI-generated text? Writing quality assessment has received less attention from the community, in part because it is fundamentally subjective and requires expertise. We first introduce the Writing Quality Benchmark (WQ) by consolidating five writing-preference datasets into 4,729 writing quality judgments. Our experiments show that most of the competitive baselines, including state-of-the-art LLMs that excel at reasoning tasks, barely outperform random baselines on WQ. We then train specialized Writing Quality Reward Models (WQRM) of various sizes for writing quality assessment that demonstrate strong generalization on four out-of-distribution test sets and 74% accuracy on the WQ benchmark. To further show WQRM's practical benefits during inference, we leverage additional test-time compute to generate and rank multiple candidate revisions, allowing us to select higher-quality outputs from an initial draft. Human evaluation with 9 experienced writers confirm that WQRM-based selection produces writing samples preferred by experts 66% overall, and 72.2% when the reward gap is larger than 1 point. We release our datasets and models to encourage community engagement with writing quality assessment and development of AI writing systems better aligned with human preferences.",
    "source": "arXiv"
  },
  {
    "title": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models",
    "title_es": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models",
    "url": "https://arxiv.org/abs/2504.08329",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.08329v2 Announce Type: replace \nAbstract: Electronic health record (EHR) foundation models have been an area ripe for exploration with their improved performance in various medical tasks. Despite the rapid advances, there exists a fundamental limitation: Processing unseen medical codes out of the vocabulary. This problem limits the generality of EHR foundation models and the integration of models trained with different vocabularies. To deal with this problem, we propose MedRep for EHR foundation models based on the observational medical outcome partnership (OMOP) common data model (CDM), providing the integrated medical concept representations and the basic data augmentation strategy for patient trajectories. For concept representation learning, we enrich the information of each concept with a minimal definition through large language model (LLM) prompts and enhance the text-based representations through graph ontology of OMOP vocabulary. Trajectory augmentation randomly replaces selected concepts with other similar concepts that have closely related representations to let the model practice with the concepts out-of-vocabulary. Finally, we demonstrate that EHR foundation models trained with MedRep better maintain the prediction performance in external datasets. Our code implementation is publicly available at https://github.com/kicarussays/MedRep.",
    "source": "arXiv"
  },
  {
    "title": "FedRecon: Missing Modality Reconstruction in Heterogeneous Distributed Environments",
    "title_es": "FedRecon: Missing Modality Reconstruction in Heterogeneous Distributed Environments",
    "url": "https://arxiv.org/abs/2504.09941",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.09941v3 Announce Type: replace \nAbstract: Multimodal data are often incomplete and exhibit Non-Independent and Identically Distributed (Non-IID) characteristics in real-world scenarios. These inherent limitations lead to both modality heterogeneity through partial modality absence and data heterogeneity from distribution divergence, creating fundamental challenges for effective federated learning (FL). To address these coupled challenges, we propose FedRecon, the first method targeting simultaneous missing modality reconstruction and Non-IID adaptation in multimodal FL. Our approach first employs a lightweight Multimodal Variational Autoencoder (MVAE) to reconstruct missing modalities while preserving cross-modal consistency. Distinct from conventional imputation methods, we achieve sample-level alignment through a novel distribution mapping mechanism that guarantees both data consistency and completeness. Additionally, we introduce a strategy employing global generator freezing to prevent catastrophic forgetting, which in turn mitigates Non-IID fluctuations. Extensive evaluations on multimodal datasets demonstrate FedRecon's superior performance in modality reconstruction under Non-IID conditions, surpassing state-of-the-art methods. The code will be released upon paper acceptance.",
    "source": "arXiv"
  },
  {
    "title": "Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency Regularization",
    "title_es": "Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency Regularization",
    "url": "https://arxiv.org/abs/2504.14975",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.14975v2 Announce Type: replace \nAbstract: Despite the remarkable progress of 3D generation, achieving controllability, i.e., ensuring consistency between generated 3D content and input conditions like edge and depth, remains a significant challenge. Existing methods often struggle to maintain accurate alignment, leading to noticeable discrepancies. To address this issue, we propose \\name{}, a new framework that enhances controllable 3D generation by explicitly encouraging cyclic consistency between the second-order 3D content, generated based on extracted signals from the first-order generation, and its original input controls. Specifically, we employ an efficient feed-forward backbone that can generate a 3D object from an input condition and a text prompt. Given an initial viewpoint and a control signal, a novel view is rendered from the generated 3D content, from which the extracted condition is used to regenerate the 3D content. This re-generated output is then rendered back to the initial viewpoint, followed by another round of control signal extraction, forming a cyclic process with two consistency constraints. \\emph{View consistency} ensures coherence between the two generated 3D objects, measured by semantic similarity to accommodate generative diversity. \\emph{Condition consistency} aligns the final extracted signal with the original input control, preserving structural or geometric details throughout the process. Extensive experiments on popular benchmarks demonstrate that \\name{} significantly improves controllability, especially for fine-grained details, outperforming existing methods across various conditions (e.g., +14.17\\% PSNR for edge, +6.26\\% PSNR for sketch).",
    "source": "arXiv"
  },
  {
    "title": "How Irrationality Shapes Nash Equilibria: A Prospect-Theoretic Perspective",
    "title_es": "How Irrationality Shapes Nash Equilibria: A Prospect-Theoretic Perspective",
    "url": "https://arxiv.org/abs/2504.16556",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.16556v2 Announce Type: replace \nAbstract: Noncooperative games with uncertain payoffs have been classically studied under the expected-utility theory framework, which relies on the strong assumption that agents behave rationally. However, simple experiments on human decision makers found them to be not fully rational, due to their subjective risk perception. Prospect theory was proposed as an empirically-grounded model to incorporate irrational behaviours into game-theoretic models. But, how prospect theory shapes the set of Nash equilibria when considering irrational agents, is still poorly understood. To this end, we study how prospect theoretic transformations may generate new equilibria while eliminating existing ones. Focusing on aggregative games, we show that capturing users' irrationality can preserve symmetric equilibria while causing the vanishing of asymmetric equilibria. Further, there exist value functions which map uncountable sets of equilibria in the expected-utility maximization framework to finite sets. This last result may shape some equilibrium selection theories for human-in-the-loop systems where computing a single equilibrium is insufficient and comparison of equilibria is needed.",
    "source": "arXiv"
  },
  {
    "title": "3D-1D modelling of cranial mesh heating induced by low or medium frequency magnetic fields",
    "title_es": "3D-1D modelling of cranial mesh heating induced by low or medium frequency magnetic fields",
    "url": "https://arxiv.org/abs/2504.16600",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.16600v2 Announce Type: replace \nAbstract: Safety assessment of patients with one-dimensionally structured passive implants, like cranial meshes or stents, exposed to low or medium frequency magnetic fields, like those generated in magnetic resonance imaging or magnetic hyperthermia, can be challenging, because of the different length scales of the implant and the human body. Most of the methods used to estimate the heating induced near such implants neglect the presence of the metallic materials within the body, modeling the metal as thermal seeds. To overcome this limitation, a novel numerical approach that solves three-dimensional and one-dimensional coupled problems is proposed. The proposed method is compared with measurements performed on a cranial mesh exposed to the magnetic field generated by a gradient coil system for magnetic resonance imaging. Then, it is applied to a magnetic hyperthermia case study in which a patient with a cranial mesh is exposed to the magnetic field generated by a collar-type magnetic hyperthermia applicator for neck tumour treatment. The experimental comparison of the proposed method predictions and the measurement data shows an improved accuracy near the maximum temperature increase up to 25% with respect to the method based on thermal seeds. The application of the proposed method applied to the magnetic hyperthermia case study leads to a prediction of the maximum temperature increase that is 10% lower than the one overestimated by relying on thermal seeds. At the same time, the proposed method corrects the underestimation of the thermal seeds in the regions where the electromagnetic power is not directly deposited and the temperature increase is only due to heat transfer. The proposed method leads to improved results with respect to previous approximations by modelling the thermal diffusion through the highly conductive metallic implants.",
    "source": "arXiv"
  },
  {
    "title": "Can Automated Feedback Turn Students into Happy Prologians?",
    "title_es": "Can Automated Feedback Turn Students into Happy Prologians?",
    "url": "https://arxiv.org/abs/2504.16742",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.16742v2 Announce Type: replace \nAbstract: Providing valuable and personalized feedback is essential for effective learning, but delivering it promptly can be challenging in large-scale courses. Recent research has explored automated feedback mechanisms across various programming languages and paradigms, including logic programming.\n  In this work, we present a student survey were we evaluate the perceived usefulness of different feedback types and identified which are most valued. Our results indicate that students found all implemented feedback types helpful, with automatic testing ranked as the most useful. We also introduce a dataset comprising 7201 correct and incorrect Prolog submissions, along with 200 manually annotated programs labeled with bug types and corresponding corrections. Finally, we explore student preferences for which types of feedback they would most like to see implemented in the future.",
    "source": "arXiv"
  },
  {
    "title": "LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition",
    "title_es": "LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition",
    "url": "https://arxiv.org/abs/2504.19256",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.19256v3 Announce Type: replace \nAbstract: In human-centered environments such as restaurants, homes, and warehouses, robots often face challenges in accurately recognizing 3D objects. These challenges stem from the complexity and variability of these environments, including diverse object shapes. In this paper, we propose a novel Lightweight Multi-modal Multi-view Convolutional-Vision Transformer network (LM-MCVT) to enhance 3D object recognition in robotic applications. Our approach leverages the Globally Entropy-based Embeddings Fusion (GEEF) method to integrate multi-views efficiently. The LM-MCVT architecture incorporates pre- and mid-level convolutional encoders and local and global transformers to enhance feature extraction and recognition accuracy. We evaluate our method on the synthetic ModelNet40 dataset and achieve a recognition accuracy of 95.6% using a four-view setup, surpassing existing state-of-the-art methods. To further validate its effectiveness, we conduct 5-fold cross-validation on the real-world OmniObject3D dataset using the same configuration. Results consistently show superior performance, demonstrating the method's robustness in 3D object recognition across synthetic and real-world 3D data.",
    "source": "arXiv"
  },
  {
    "title": "CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback",
    "title_es": "CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback",
    "url": "https://arxiv.org/abs/2504.19860",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.19860v3 Announce Type: replace \nAbstract: Score Distillation Sampling (SDS) has achieved remarkable success in text-to-3D content generation. However, SDS-based methods struggle to maintain semantic fidelity for user prompts, particularly when involving multiple objects with intricate interactions. While existing approaches often address 3D consistency through multiview diffusion model fine-tuning on 3D datasets, this strategy inadvertently exacerbates text-3D alignment degradation. The limitation stems from SDS's inherent accumulation of view-independent biases during optimization, which progressively diverges from the ideal text alignment direction. To alleviate this limitation, we propose a novel SDS objective, dubbed as Textual Coherent Score Distillation (TCSD), which integrates alignment feedback from multimodal large language models (MLLMs). Our TCSD leverages cross-modal understanding capabilities of MLLMs to assess and guide the text-3D correspondence during the optimization. We further develop 3DLLaVA-CRITIC - a fine-tuned MLLM specialized for evaluating multiview text alignment in 3D generations. Additionally, we introduce an LLM-layout initialization that significantly accelerates optimization convergence through semantic-aware spatial configuration. Our framework, CoherenDream, achieves consistent improvement across multiple metrics on TIFA subset.As the first study to incorporate MLLMs into SDS optimization, we also conduct extensive ablation studies to explore optimal MLLM adaptations for 3D generation tasks.",
    "source": "arXiv"
  },
  {
    "title": "Non-native Children's Automatic Speech Assessment Challenge (NOCASA)",
    "title_es": "Non-native Children's Automatic Speech Assessment Challenge (NOCASA)",
    "url": "https://arxiv.org/abs/2504.20678",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.20678v2 Announce Type: replace \nAbstract: This paper presents the \"Non-native Children's Automatic Speech Assessment\" (NOCASA) - a data competition part of the IEEE MLSP 2025 conference. NOCASA challenges participants to develop new systems that can assess single-word pronunciations of young second language (L2) learners as part of a gamified pronunciation training app. To achieve this, several issues must be addressed, most notably the limited nature of available training data and the highly unbalanced distribution among the pronunciation level categories. To expedite the development, we provide a pseudo-anonymized training data (TeflonNorL2), containing 10,334 recordings from 44 speakers attempting to pronounce 205 distinct Norwegian words, human-rated on a 1 to 5 scale (number of stars that should be given in the game). In addition to the data, two already trained systems are released as official baselines: an SVM classifier trained on the ComParE_16 acoustic feature set and a multi-task wav2vec 2.0 model. The latter achieves the best performance on the challenge test set, with an unweighted average recall (UAR) of 36.37%.",
    "source": "arXiv"
  },
  {
    "title": "Confidential Serverless Computing",
    "title_es": "Confidential Serverless Computing",
    "url": "https://arxiv.org/abs/2504.21518",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.21518v3 Announce Type: replace \nAbstract: Although serverless computing offers compelling cost and deployment simplicity advantages, a significant challenge remains in securely managing sensitive data as it flows through the network of ephemeral function executions in serverless computing environments within untrusted clouds. While Confidential Virtual Machines (CVMs) offer a promising secure execution environment, their integration with serverless architectures currently faces fundamental limitations in key areas: security, performance, and resource efficiency. We present WALLET, a confidential computing system for secure serverless deployments to overcome these limitations. By employing nested confidential execution and a decoupled guest OS within CVMs, WALLET runs each function in a minimal \"trustlet\", significantly improving security through a reduced Trusted Computing Base (TCB). Furthermore, by leveraging a data-centric I/O architecture built upon a lightweight LibOS, WALLET optimizes network communication to address performance and resource efficiency challenges. Our evaluation shows that compared to CVM-based deployments, WALLET has 4.3x smaller TCB, improves end-to-end latency (15-93%), achieves higher function density (up to 907x), and reduces inter-function communication (up to 27x) and function chaining latency (16.7-30.2x); thus, WALLET offers a practical system for confidential serverless computing.",
    "source": "arXiv"
  },
  {
    "title": "IP-CRR: Information Pursuit for Interpretable Classification of Chest Radiology Reports",
    "title_es": "IP-CRR: Information Pursuit for Interpretable Classification of Chest Radiology Reports",
    "url": "https://arxiv.org/abs/2505.00191",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.00191v2 Announce Type: replace \nAbstract: The development of AI-based methods to analyze radiology reports could lead to significant advances in medical diagnosis, from improving diagnostic accuracy to enhancing efficiency and reducing workload. However, the lack of interpretability of AI-based methods could hinder their adoption in clinical settings. In this paper, we propose an interpretable-by-design framework for classifying chest radiology reports. First, we extract a set of representative facts from a large set of reports. Then, given a new report, we query whether a small subset of the representative facts is entailed by the report, and predict a diagnosis based on the selected subset of query-answer pairs. The explanation for a prediction is, by construction, the set of selected queries and answers. We use the Information Pursuit framework to select the most informative queries, a natural language inference model to determine if a fact is entailed by the report, and a classifier to predict the disease. Experiments on the MIMIC-CXR dataset demonstrate the effectiveness of the proposed method, highlighting its potential to enhance trust and usability in medical AI.",
    "source": "arXiv"
  },
  {
    "title": "ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction for Automated Parking using Diffusion Models",
    "title_es": "ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction for Automated Parking using Diffusion Models",
    "url": "https://arxiv.org/abs/2505.00586",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.00586v2 Announce Type: replace \nAbstract: Automated parking is a critical feature of Advanced Driver Assistance Systems (ADAS), where accurate trajectory prediction is essential to bridge perception and planning modules. Despite its significance, research in this domain remains relatively limited, with most existing studies concentrating on single-modal trajectory prediction of vehicles. In this work, we propose ParkDiffusion, a novel approach that predicts the trajectories of both vehicles and pedestrians in automated parking scenarios. ParkDiffusion employs diffusion models to capture the inherent uncertainty and multi-modality of future trajectories, incorporating several key innovations. First, we propose a dual map encoder that processes soft semantic cues and hard geometric constraints using a two-step cross-attention mechanism. Second, we introduce an adaptive agent type embedding module, which dynamically conditions the prediction process on the distinct characteristics of vehicles and pedestrians. Third, to ensure kinematic feasibility, our model outputs control signals that are subsequently used within a kinematic framework to generate physically feasible trajectories. We evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the Intersections Drone (inD) dataset. Our work establishes a new baseline for heterogeneous trajectory prediction in parking scenarios, outperforming existing methods by a considerable margin.",
    "source": "arXiv"
  },
  {
    "title": "RAGAR: Retrieval Augmented Personalized Image Generation Guided by Recommendation",
    "title_es": "RAGAR: Retrieval Augmented Personalized Image Generation Guided by Recommendation",
    "url": "https://arxiv.org/abs/2505.01657",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.01657v2 Announce Type: replace \nAbstract: Personalized image generation is crucial for improving the user experience, as it renders reference images into preferred ones according to user visual preferences. Although effective, existing methods face two main issues. First, existing methods treat all items in the user historical sequence equally when extracting user preferences, overlooking the varying semantic similarities between historical items and the reference item. Disproportionately high weights for low-similarity items distort users' visual preferences for the reference item. Second, existing methods heavily rely on consistency between generated and reference images to optimize the generation, which leads to underfitting user preferences and hinders personalization. To address these issues, we propose Retrieval Augment Personalized Image GenerAtion guided by Recommendation (RAGAR). Our approach uses a retrieval mechanism to assign different weights to historical items according to their similarities to the reference item, thereby extracting more refined users' visual preferences for the reference item. Then we introduce a novel rank task based on the multi-modal ranking model to optimize the personalization of the generated images instead of forcing depend on consistency. Extensive experiments and human evaluations on three real-world datasets demonstrate that RAGAR achieves significant improvements in both personalization and semantic metrics compared to five baselines.",
    "source": "arXiv"
  },
  {
    "title": "Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs",
    "title_es": "Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs",
    "url": "https://arxiv.org/abs/2505.02009",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.02009v3 Announce Type: replace \nAbstract: Large language models (LLMs) have become integral to various real-world applications, leveraging massive, web-sourced datasets like Common Crawl, C4, and FineWeb for pretraining. While these datasets provide linguistic data essential for high-quality natural language generation, they often contain harmful content, such as hate speech, misinformation, and biased narratives. Training LLMs on such unfiltered data risks perpetuating toxic behaviors, spreading misinformation, and amplifying societal biases which can undermine trust in LLM-driven applications and raise ethical concerns about their use. This paper presents a large-scale analysis of inappropriate content across these datasets, offering a comprehensive taxonomy that categorizes harmful webpages into Topical and Toxic based on their intent. We also introduce a prompt evaluation dataset, a high-accuracy Topical and Toxic Prompt (TTP), and a transformer-based model (HarmFormer) for harmful content filtering. Additionally, we create a new multi-harm open-ended toxicity benchmark (HAVOC) and provide crucial insights into how models respond to adversarial toxic inputs. We share TTP, TTP-Eval, HAVOC and a sample of C4 inferenced on HarmFormer. Our work offers insights into ensuring safer LLM pretraining and serves as a resource for Responsible AI (RAI) compliance.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic load balancing for cloud systems under heterogeneous setup delays",
    "title_es": "Dynamic load balancing for cloud systems under heterogeneous setup delays",
    "url": "https://arxiv.org/abs/2505.03596",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.03596v2 Announce Type: replace \nAbstract: We consider a distributed cloud service deployed at a set of distinct server pools. Arriving jobs are classified into heterogeneous types, in accordance with their setup times which are differentiated at each of the pools. A dispatcher for each job type controls the balance of load between pools, based on decentralized feedback. The system of rates and queues is modeled by a fluid differential equation system, and analyzed via convex optimization. A first, myopic policy is proposed, based on task delay-to-service. Under a simplified dynamic fluid queue model, we prove global convergence to an equilibrium point which minimizes the mean setup time; however queueing delays are incurred with this method. A second proposal is then developed based on proximal optimization, which explicitly models the setup queue and is proved to reach an optimal equilibrium, devoid of queueing delay. Results are demonstrated through a simulation example.",
    "source": "arXiv"
  },
  {
    "title": "Dequantified Diffusion-Schr{\\\"o}dinger Bridge for Density Ratio Estimation",
    "title_es": "Dequantified Diffusion-Schr{\\\"o}dinger Bridge for Density Ratio Estimation",
    "url": "https://arxiv.org/abs/2505.05034",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.05034v4 Announce Type: replace \nAbstract: Density ratio estimation is fundamental to tasks involving $f$-divergences, yet existing methods often fail under significantly different distributions or inadequately overlapping supports -- the density-chasm and the support-chasm problems. Additionally, prior approaches yield divergent time scores near boundaries, leading to instability. We design $\\textbf{D}^3\\textbf{RE}$, a unified framework for \\textbf{robust}, \\textbf{stable} and \\textbf{efficient} density ratio estimation. We propose the dequantified diffusion bridge interpolant (DDBI), which expands support coverage and stabilizes time scores via diffusion bridges and Gaussian dequantization. Building on DDBI, the proposed dequantified Schr{\\\"o}dinger bridge interpolant (DSBI) incorporates optimal transport to solve the Schr{\\\"o}dinger bridge problem, enhancing accuracy and efficiency. Our method offers uniform approximation and bounded time scores in theory, and outperforms baselines empirically in mutual information and density estimation tasks.",
    "source": "arXiv"
  },
  {
    "title": "Deep Learning Warm Starts for Trajectory Optimization on the International Space Station",
    "title_es": "Deep Learning Warm Starts for Trajectory Optimization on the International Space Station",
    "url": "https://arxiv.org/abs/2505.05588",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.05588v2 Announce Type: replace \nAbstract: Trajectory optimization is a cornerstone of modern robot autonomy, enabling systems to compute trajectories and controls in real-time while respecting safety and physical constraints. However, it has seen limited usage in spaceflight applications due to its heavy computational demands that exceed the capability of most flight computers. In this work, we provide results on the first flight demonstration of using machine learning-based warm starts for accelerating trajectory optimization for the Astrobee free-flying robot on-board the International Space Station (ISS). We formulate a data-driven optimal control approach that trains a neural network to learn the structure of the trajectory generation problem being solved for by sequential convex programming (SCP). On-board, this trained neural network predicts solutions for the trajectory generation problem and relies on using the SCP solver to enforce safety constraints for the system. Our trained network reduces the number of solver iterations required for convergence in cases including rotational dynamics by 60% and in cases with obstacles drawn from the training distribution of the warm start model by 50%. This work represents a significant milestone in the use of learning-based control for spaceflight applications and a stepping stone for future advances in the use of machine learning for autonomous guidance, navigation, & control.",
    "source": "arXiv"
  },
  {
    "title": "Emotion-Qwen: A Unified Framework for Emotion and Vision Understanding",
    "title_es": "Emotion-Qwen: A Unified Framework for Emotion and Vision Understanding",
    "url": "https://arxiv.org/abs/2505.06685",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.06685v3 Announce Type: replace \nAbstract: Accurate emotion understanding in videos necessitates effectively recognizing and interpreting emotional states by integrating visual, textual, auditory, and contextual cues. Although recent Large Multimodal Models (LMMs) have exhibited significant progress in general vision-language (VL) tasks, their performance often deteriorates in emotion-specific scenarios, exhibiting catastrophic forgetting when fine-tuned on emotion-centric tasks. To overcome these limitations, we propose Emotion-Qwen, a unified multimodal framework designed to simultaneously enable robust emotion understanding and preserve general VL reasoning capabilities. Emotion-Qwen introduces a novel Hybrid Compressor based on a Mixture-of-Experts (MoE) architecture, dynamically routing inputs to optimally balance emotion-specific processing and general multimodal reasoning. We further propose a carefully structured three-stage pre-training pipeline, leveraging extensive general and emotion-focused datasets to strengthen multimodal representation robustness and model adaptability. Additionally, we develop the Video Emotion Reasoning (VER) dataset, a large-scale bilingual resource containing over 40K video clips annotated with detailed context-aware emotional descriptions, significantly facilitating research on fine-grained emotional reasoning. Extensive experiments confirm that Emotion-Qwen achieves state-of-the-art performance across multiple emotion recognition and reasoning benchmarks, while maintaining highly competitive results in general VL tasks.",
    "source": "arXiv"
  },
  {
    "title": "Halting Recurrent GNNs and the Graded $\\mu$-Calculus",
    "title_es": "Halting Recurrent GNNs and the Graded $\\mu$-Calculus",
    "url": "https://arxiv.org/abs/2505.11050",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.11050v2 Announce Type: replace \nAbstract: Graph Neural Networks (GNNs) are a class of machine-learning models that operate on graph-structured data. Their expressive power is intimately related to logics that are invariant under graded bisimilarity. Current proposals for recurrent GNNs either assume that the graph size is given to the model, or suffer from a lack of termination guarantees. In this paper, we propose a halting mechanism for recurrent GNNs. We prove that our halting model can express all node classifiers definable in graded modal mu-calculus, even for the standard GNN variant that is oblivious to the graph size. To prove our main result, we develop a new approximate semantics for graded mu-calculus, which we believe to be of independent interest. We leverage this new semantics into a new model-checking algorithm, called the counting algorithm, which is oblivious to the graph size. In a final step we show that the counting algorithm can be implemented on a halting recurrent GNN.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Nonlinear Implicit Bias via Region Counts in Input Space",
    "title_es": "Understanding Nonlinear Implicit Bias via Region Counts in Input Space",
    "url": "https://arxiv.org/abs/2505.11370",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.11370v3 Announce Type: replace \nAbstract: One explanation for the strong generalization ability of neural networks is implicit bias. Yet, the definition and mechanism of implicit bias in non-linear contexts remains little understood. In this work, we propose to characterize implicit bias by the count of connected regions in the input space with the same predicted label. Compared with parameter-dependent metrics (e.g., norm or normalized margin), region count can be better adapted to nonlinear, overparameterized models, because it is determined by the function mapping and is invariant to reparametrization. Empirically, we found that small region counts align with geometrically simple decision boundaries and correlate well with good generalization performance. We also observe that good hyper-parameter choices such as larger learning rates and smaller batch sizes can induce small region counts. We further establish the theoretical connections and explain how larger learning rate can induce small region counts in neural networks.",
    "source": "arXiv"
  },
  {
    "title": "Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind",
    "title_es": "Can Large Multimodal Models Understand Agricultural Scenes? Benchmarking with AgroMind",
    "url": "https://arxiv.org/abs/2505.12207",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.12207v3 Announce Type: replace \nAbstract: Large Multimodal Models (LMMs) has demonstrated capabilities across various domains, but comprehensive benchmarks for agricultural remote sensing (RS) remain scarce. Existing benchmarks designed for agricultural RS scenarios exhibit notable limitations, primarily in terms of insufficient scene diversity in the dataset and oversimplified task design. To bridge this gap, we introduce AgroMind, a comprehensive agricultural remote sensing benchmark covering four task dimensions: spatial perception, object understanding, scene understanding, and scene reasoning, with a total of 13 task types, ranging from crop identification and health monitoring to environmental analysis. We curate a high-quality evaluation set by integrating eight public datasets and one private farmland plot dataset, containing 27,247 QA pairs and 19,615 images. The pipeline begins with multi-source data pre-processing, including collection, format standardization, and annotation refinement. We then generate a diverse set of agriculturally relevant questions through the systematic definition of tasks. Finally, we employ LMMs for inference, generating responses, and performing detailed examinations. We evaluated 20 open-source LMMs and 4 closed-source models on AgroMind. Experiments reveal significant performance gaps, particularly in spatial reasoning and fine-grained recognition, it is notable that human performance lags behind several leading LMMs. By establishing a standardized evaluation framework for agricultural RS, AgroMind reveals the limitations of LMMs in domain knowledge and highlights critical challenges for future work. Data and code can be accessed at https://rssysu.github.io/AgroMind/.",
    "source": "arXiv"
  },
  {
    "title": "PiT: Progressive Diffusion Transformer",
    "title_es": "PiT: Progressive Diffusion Transformer",
    "url": "https://arxiv.org/abs/2505.13219",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.13219v4 Announce Type: replace \nAbstract: Diffusion Transformers (DiTs) achieve remarkable performance within image generation via the transformer architecture. Conventionally, DiTs are constructed by stacking serial isotropic global modeling transformers, which face significant quadratic computational cost. However, through empirical analysis, we find that DiTs do not rely as heavily on global information as previously believed. In fact, most layers exhibit significant redundancy in global computation. Additionally, conventional attention mechanisms suffer from low-frequency inertia, limiting their efficiency. To address these issues, we propose Pseudo Shifted Window Attention (PSWA), which fundamentally mitigates global attention redundancy. PSWA achieves moderate global-local information through window attention. It further utilizes a high-frequency bridging branch to simulate shifted window operations, which both enrich the high-frequency information and strengthen inter-window connections. Furthermore, we propose the Progressive Coverage Channel Allocation (PCCA) strategy that captures high-order attention without additional computational cost. Based on these innovations, we propose a series of Pseudo Progressive Diffusion Transformer (PiT). Our extensive experiments show their superior performance; for example, our proposed PiT-L achieves 54% FID improvement over DiT-XL/2 while using less computation.",
    "source": "arXiv"
  },
  {
    "title": "A Sequence-Form Characterization and Differentiable Path-Following Computation of Normal-Form Perfect Equilibria in Extensive-Form Games",
    "title_es": "A Sequence-Form Characterization and Differentiable Path-Following Computation of Normal-Form Perfect Equilibria in Extensive-Form Games",
    "url": "https://arxiv.org/abs/2505.13827",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.13827v2 Announce Type: replace \nAbstract: The sequence form, owing to its compact and holistic strategy representation, has demonstrated significant efficiency in computing normal-form perfect equilibria for two-player extensive-form games with perfect recall. Nevertheless, the examination of $n$-player games remains underexplored. To tackle this challenge, we present a sequence-form characterization of normal-form perfect equilibria for $n$-player extensive-form games, achieved through a class of perturbed games formulated in sequence form. Based on this characterization, we develop a differentiable path-following method for computing normal-form perfect equilibria and prove its convergence. This method formulates an artificial logarithmic-barrier game in sequence form, introducing an additional variable to regulate the impact of logarithmic-barrier terms on the payoff functions, as well as the transition of the strategy space. We prove the existence of a smooth equilibrium path defined by the artificial game, starting from an arbitrary positive realization plan and converging to a normal-form perfect equilibrium of the original game as the additional variable approaches zero. Furthermore, we extend Harsanyi's linear and logarithmic tracing procedures to the sequence form and develop two alternative methods for computing normal-form perfect equilibria. Numerical experiments further substantiate the effectiveness and computational efficiency of our methods.",
    "source": "arXiv"
  },
  {
    "title": "Scaling Vision Mamba Across Resolutions via Fractal Traversal",
    "title_es": "Scaling Vision Mamba Across Resolutions via Fractal Traversal",
    "url": "https://arxiv.org/abs/2505.14062",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.14062v2 Announce Type: replace \nAbstract: Vision Mamba has recently emerged as a promising alternative to Transformer-based architectures, offering linear complexity in sequence length while maintaining strong modeling capacity. However, its adaptation to visual inputs is hindered by challenges in 2D-to-1D patch serialization and weak scalability across input resolutions. Existing serialization strategies such as raster scanning disrupt local spatial continuity and limit the model's ability to generalize across scales. In this paper, we propose FractalMamba++, a robust vision backbone that leverages fractal-based patch serialization via Hilbert curves to preserve spatial locality and enable seamless resolution adaptability. To address long-range dependency fading in high-resolution inputs, we further introduce a Cross-State Routing (CSR) mechanism that enhances global context propagation through selective state reuse. Additionally, we propose a Positional-Relation Capture (PRC) module to recover local adjacency disrupted by curve inflection points. Extensive experiments across diverse downstream tasks, including image classification, semantic segmentation and object detection, demonstrate that FractalMamba++ consistently outperforms previous Mamba-based backbones, with particularly notable gains under high-resolution settings.",
    "source": "arXiv"
  },
  {
    "title": "Owicki--Gries Logic for Timestamp Semantics",
    "title_es": "Owicki--Gries Logic for Timestamp Semantics",
    "url": "https://arxiv.org/abs/2505.15053",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.15053v5 Announce Type: replace \nAbstract: Whereas an extension with non-interference of Hoare logic for sequential programs Owicki--Gries logic ensures the correctness of concurrent programs on strict consistency, it is unsound to weak memory models adopted by modern computer architectures and specifications of programming languages. This paper proposes a novel non-interference notion and provides concurrent program logic sound to timestamp semantics corresponding to a weak memory model that allows delays in the effects of store instructions. This paper reports three theoretically interesting techniques for modifying non-interference to support delays in the effects of store instructions. The techniques contribute to a better understanding of constructing concurrent program logic.",
    "source": "arXiv"
  },
  {
    "title": "Prediction of Reposting on X",
    "title_es": "Prediction of Reposting on X",
    "url": "https://arxiv.org/abs/2505.15370",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.15370v2 Announce Type: replace \nAbstract: There have been considerable efforts to predict a user's reposting behaviour on X (formerly Twitter) using machine learning models. The problem is previously cast as a supervised classification task, where Tweets are randomly assigned to a test or training set. The random assignment helps to ensure that the test and training sets are drawn from the same distribution. In practice, we would like to predict users' reposting behaviour for a set of messages related to a new, previously unseen, topic (defined by a hashtag). In this case, the problem becomes an out-of-distribution generalisation classification task.\n  Experimental results reveal that while existing algorithms, which predominantly use features derived from the content of Tweet messages, perform well when the training and test distributions are the same, these algorithms perform much worse when the test set is out of distribution. We then show that if the message features are supplemented or replaced with features derived from users' profile and past behaviour, the out-of-distribution prediction is greatly improved, with the F1 score increasing from 0.24 to 0.70. Our experimental results suggest that a significant component of reposting behaviour can be predicted based on users' profile and past behaviour, and is independent of the content of messages.",
    "source": "arXiv"
  },
  {
    "title": "Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning",
    "title_es": "Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning",
    "url": "https://arxiv.org/abs/2505.16483",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.16483v2 Announce Type: replace \nAbstract: Teaching large language models (LLMs) to be faithful in the provided context is crucial for building reliable information-seeking systems. Therefore, we propose a systematic framework, CANOE, to reduce faithfulness hallucinations of LLMs across different downstream tasks without human annotations. Specifically, we first synthesize short-form question-answering (QA) data with four diverse tasks to construct high-quality and easily verifiable training data without human annotation. Also, we propose Dual-GRPO, a rule-based reinforcement learning method that includes three tailored rule-based rewards derived from synthesized short-form QA data, while simultaneously optimizing both short-form and long-form response generation. Notably, Dual-GRPO eliminates the need to manually label preference data to train reward models and avoids over-optimizing short-form generation when relying only on the synthesized short-form QA data. Experimental results show that CANOE greatly improves the faithfulness of LLMs across 11 different tasks, even outperforming the most advanced LLMs, e.g., GPT-4o and OpenAI o1.",
    "source": "arXiv"
  },
  {
    "title": "Integrating Visual Interpretation and Linguistic Reasoning for Math Problem Solving",
    "title_es": "Integrating Visual Interpretation and Linguistic Reasoning for Math Problem Solving",
    "url": "https://arxiv.org/abs/2505.17609",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.17609v2 Announce Type: replace \nAbstract: Current large vision-language models (LVLMs) typically employ a connector module to link visual features with text embeddings of large language models (LLMs) and use end-to-end training to achieve multi-modal understanding in a unified process. Effective alignment needs high-quality pre-training data and a carefully designed training process. Current LVLMs face challenges when addressing complex vision-language reasoning tasks, with their reasoning capabilities notably lagging behind those of LLMs. This paper proposes a paradigm shift: instead of training end-to-end vision-language reasoning models, we advocate for developing a decoupled reasoning framework based on existing visual interpretation specialists and text-based reasoning LLMs. Our approach leverages (1) a dedicated vision-language model to transform the visual content of images into textual descriptions and (2) an LLM to perform reasoning according to the visual-derived text and the original question. This method presents a cost-efficient solution for multi-modal model development by optimizing existing models to work collaboratively, avoiding end-to-end development of vision-language models from scratch. By transforming images into language model-compatible text representations, it facilitates future low-cost and flexible upgrades to upcoming powerful LLMs. We introduce an outcome-rewarded joint-tuning strategy to optimize the cooperation between the visual interpretation and linguistic reasoning model. Evaluation results on vision-language benchmarks demonstrate that the decoupled reasoning framework outperforms recent LVLMs. Our approach yields particularly significant performance gains on visually intensive geometric mathematics problems. The code is available: https://github.com/guozix/DVLR.",
    "source": "arXiv"
  },
  {
    "title": "CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment",
    "title_es": "CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment",
    "url": "https://arxiv.org/abs/2505.17619",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.17619v2 Announce Type: replace \nAbstract: Synthetic X-ray angiographies generated by modern generative models hold great potential to reduce the use of contrast agents in vascular interventional procedures. However, low-quality synthetic angiographies can significantly increase procedural risk, underscoring the need for reliable image quality assessment (IQA) methods. Existing IQA models, however, fail to leverage auxiliary images as references during evaluation and lack fine-grained, task-specific metrics necessary for clinical relevance. To address these limitations, this paper proposes CAS-IQA, a vision-language model (VLM)-based framework that predicts fine-grained quality scores by effectively incorporating auxiliary information from related images. In the absence of angiography datasets, CAS-3K is constructed, comprising 3,565 synthetic angiographies along with score annotations. To ensure clinically meaningful assessment, three task-specific evaluation metrics are defined. Furthermore, a Multi-path featUre fuSion and rouTing (MUST) module is designed to enhance image representations by adaptively fusing and routing visual tokens to metric-specific branches. Extensive experiments on the CAS-3K dataset demonstrate that CAS-IQA significantly outperforms state-of-the-art IQA methods by a considerable margin.",
    "source": "arXiv"
  },
  {
    "title": "Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic Methods for Decentralized Multi-Agent Reinforcement Learning",
    "title_es": "Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic Methods for Decentralized Multi-Agent Reinforcement Learning",
    "url": "https://arxiv.org/abs/2505.18433",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.18433v2 Announce Type: replace \nAbstract: Actor-critic methods for decentralized multi-agent reinforcement learning (MARL) facilitate collaborative optimal decision making without centralized coordination, thus enabling a wide range of applications in practice. To date, however, most theoretical convergence studies for existing actor-critic decentralized MARL methods are limited to the guarantee of a stationary solution under the linear function approximation. This leaves a significant gap between the highly successful use of deep neural actor-critic for decentralized MARL in practice and the current theoretical understanding. To bridge this gap, in this paper, we make the first attempt to develop a deep neural actor-critic method for decentralized MARL, where both the actor and critic components are inherently non-linear. We show that our proposed method enjoys a global optimality guarantee with a finite-time convergence rate of O(1/T), where T is the total iteration times. This marks the first global convergence result for deep neural actor-critic methods in the MARL literature. We also conduct extensive numerical experiments, which verify our theoretical results.",
    "source": "arXiv"
  },
  {
    "title": "LogicCat: A Chain-of-Thought Text-to-SQL Benchmark for Complex Reasoning",
    "title_es": "LogicCat: A Chain-of-Thought Text-to-SQL Benchmark for Complex Reasoning",
    "url": "https://arxiv.org/abs/2505.18744",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.18744v2 Announce Type: replace \nAbstract: Text-to-SQL is a critical task in natural language processing that aims to transform natural language questions into accurate and executable SQL queries. In real-world scenarios, these reasoning tasks are often accompanied by complex mathematical computations, domain knowledge, and hypothetical reasoning scenarios. However, existing large-scale Text-to-SQL datasets typically focus on business logic and task logic, neglecting critical factors such as vertical domain knowledge, complex mathematical reasoning, and hypothetical reasoning, which are essential for realistically reflecting the reasoning demands in practical applications and completing data querying and analysis. To bridge this gap, we introduce LogicCat, the first Text-to-SQL benchmark dataset specifically designed for complex reasoning and chain-of-thought parsing, encompassing physics, arithmetic, commonsense, and hypothetical reasoning scenarios. LogicCat comprises 4,038 English questions paired 12,114 detailed chain-of-thought reasoning steps, spanning 45 databases across diverse domains, significantly surpassing existing datasets in complexity. Experimental results demonstrate that LogicCat substantially increases the task difficulty for current state-of-the-art models to at most 33.20% execution accuracy, indicating that this task remains exceptionally challenging. The advancement of LogicCat represents a crucial step toward developing systems suitable for real-world enterprise data analysis and autonomous query generation. We have released our dataset code at https://github.com/Ffunkytao/LogicCat.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Differentiable Hardware Rasterization for 3D Gaussian Splatting",
    "title_es": "Efficient Differentiable Hardware Rasterization for 3D Gaussian Splatting",
    "url": "https://arxiv.org/abs/2505.18764",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.18764v2 Announce Type: replace \nAbstract: Recent works demonstrate the advantages of hardware rasterization for 3D Gaussian Splatting (3DGS) in forward-pass rendering through fast GPU-optimized graphics and fixed memory footprint. However, extending these benefits to backward-pass gradient computation remains challenging due to graphics pipeline constraints. We present a differentiable hardware rasterizer for 3DGS that overcomes the memory and performance limitations of tile-based software rasterization. Our solution employs programmable blending for per-pixel gradient computation combined with a hybrid gradient reduction strategy (quad-level + subgroup) in fragment shaders, achieving over 10x faster backward rasterization versus naive atomic operations and 3x speedup over the canonical tile-based rasterizer. Systematic evaluation reveals 16-bit render targets (float16 and unorm16) as the optimal accuracy-efficiency trade-off, achieving higher gradient accuracy among mixed-precision rendering formats with execution speeds second only to unorm8, while float32 texture incurs severe forward pass performance degradation due to suboptimal hardware optimizations. Our method with float16 formats demonstrates 3.07x acceleration in full pipeline execution (forward + backward passes) on RTX4080 GPUs with the MipNeRF 360 dataset, outperforming the baseline tile-based renderer while preserving hardware rasterization's memory efficiency advantages -- incurring merely 2.67% of the memory overhead required for splat sorting operations. This work presents a unified differentiable hardware rasterization method that simultaneously optimizes runtime and memory usage for 3DGS, making it particularly suitable for resource-constrained devices with limited memory capacity.",
    "source": "arXiv"
  },
  {
    "title": "MemGuide: Intent-Driven Memory Selection for Goal-Oriented Multi-Session LLM Agents",
    "title_es": "MemGuide: Intent-Driven Memory Selection for Goal-Oriented Multi-Session LLM Agents",
    "url": "https://arxiv.org/abs/2505.20231",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.20231v2 Announce Type: replace \nAbstract: Modern task-oriented dialogue (TOD) systems increasingly rely on large language model (LLM) agents, leveraging Retrieval-Augmented Generation (RAG) and long-context capabilities for long-term memory utilization. However, these methods are primarily based on semantic similarity, overlooking task intent and reducing task coherence in multi-session dialogues. To address this challenge, we introduce MemGuide, a two-stage framework for intent-driven memory selection. (1) Intent-Aligned Retrieval matches the current dialogue context with stored intent descriptions in the memory bank, retrieving QA-formatted memory units that share the same goal. (2) Missing-Slot Guided Filtering employs a chain-of-thought slot reasoner to enumerate unfilled slots, then uses a fine-tuned LLaMA-8B filter to re-rank the retrieved units by marginal slot-completion gain. The resulting memory units inform a proactive strategy that minimizes conversational turns by directly addressing information gaps. Based on this framework, we introduce the MS-TOD, the first multi-session TOD benchmark comprising 132 diverse personas, 956 task goals, and annotated intent-aligned memory targets, supporting efficient multi-session task completion. Evaluations on MS-TOD show that MemGuide raises the task success rate by 11% (88% -> 99%) and reduces dialogue length by 2.84 turns in multi-session settings, while maintaining parity with single-session benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "MapStory: Prototyping Editable Map Animations with LLM Agents",
    "title_es": "MapStory: Prototyping Editable Map Animations with LLM Agents",
    "url": "https://arxiv.org/abs/2505.21966",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.21966v2 Announce Type: replace \nAbstract: We introduce MapStory, an LLM-powered animation prototyping tool that generates editable map animation sequences directly from natural language text by leveraging a dual-agent LLM architecture. Given a user written script, MapStory automatically produces a scene breakdown, which decomposes the text into key map animation primitives such as camera movements, visual highlights, and animated elements. Our system includes a researcher agent that accurately queries geospatial information by leveraging an LLM with web search, enabling automatic extraction of relevant regions, paths, and coordinates while allowing users to edit and query for changes or additional information to refine the results. Additionally, users can fine-tune parameters of these primitive blocks through an interactive timeline editor. We detail the system's design and architecture, informed by formative interviews with professional animators and by an analysis of 200 existing map animation videos. Our evaluation, which includes expert interviews (N=5) and a usability study (N=12), demonstrates that MapStory enables users to create map animations with ease, facilitates faster iteration, encourages creative exploration, and lowers barriers to creating map-centric stories.",
    "source": "arXiv"
  },
  {
    "title": "MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism",
    "title_es": "MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism",
    "url": "https://arxiv.org/abs/2505.22555",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.22555v2 Announce Type: replace \nAbstract: Human pose estimation based on Channel State Information (CSI) has emerged as a promising approach for non-intrusive and precise human activity monitoring, yet faces challenges including accurate multi-person pose recognition and effective CSI feature learning. This paper presents MultiFormer, a wireless sensing system that accurately estimates human pose through CSI. The proposed system adopts a Transformer based time-frequency dual-token feature extractor with multi-head self-attention. This feature extractor is able to model inter-subcarrier correlations and temporal dependencies of the CSI. The extracted CSI features and the pose probability heatmaps are then fused by Multi-Stage Feature Fusion Network (MSFN) to enforce the anatomical constraints. Extensive experiments conducted on on the public MM-Fi dataset and our self-collected dataset show that the MultiFormer achieves higher accuracy over state-of-the-art approaches, especially for high-mobility keypoints (wrists, elbows) that are particularly difficult for previous methods to accurately estimate.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Scaling Laws for EHR Foundation Models",
    "title_es": "Exploring Scaling Laws for EHR Foundation Models",
    "url": "https://arxiv.org/abs/2505.22964",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.22964v2 Announce Type: replace \nAbstract: The emergence of scaling laws has profoundly shaped the development of large language models (LLMs), enabling predictable performance gains through systematic increases in model size, dataset volume, and compute. Yet, these principles remain largely unexplored in the context of electronic health records (EHRs) -- a rich, sequential, and globally abundant data source that differs structurally from natural language. In this work, we present the first empirical investigation of scaling laws for EHR foundation models. By training transformer architectures on patient timeline data from the MIMIC-IV database across varying model sizes and compute budgets, we identify consistent scaling patterns, including parabolic IsoFLOPs curves and power-law relationships between compute, model parameters, data size, and clinical utility. These findings demonstrate that EHR models exhibit scaling behavior analogous to LLMs, offering predictive insights into resource-efficient training strategies. Our results lay the groundwork for developing powerful EHR foundation models capable of transforming clinical prediction tasks and advancing personalized healthcare.",
    "source": "arXiv"
  },
  {
    "title": "GridRoute: A Benchmark for LLM-Based Route Planning with Cardinal Movement in Grid Environments",
    "title_es": "GridRoute: A Benchmark for LLM-Based Route Planning with Cardinal Movement in Grid Environments",
    "url": "https://arxiv.org/abs/2505.24306",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.24306v2 Announce Type: replace \nAbstract: Recent advancements in Large Language Models (LLMs) have demonstrated their potential in planning and reasoning tasks, offering a flexible alternative to classical pathfinding algorithms. However, most existing studies focus on LLMs' independent reasoning capabilities and overlook the potential synergy between LLMs and traditional algorithms. To fill this gap, we propose a comprehensive evaluation benchmark GridRoute to assess how LLMs can take advantage of traditional algorithms. We also propose a novel hybrid prompting technique called Algorithm of Thought (AoT), which introduces traditional algorithms' guidance into prompting. Our benchmark evaluates six LLMs ranging from 7B to 72B parameters across various map sizes, assessing their performance in correctness, optimality, and efficiency in grid environments with varying sizes. Our results show that AoT significantly boosts performance across all model sizes, particularly in larger or more complex environments, suggesting a promising approach to addressing path planning challenges. Our code is open-sourced at https://github.com/LinChance/GridRoute.",
    "source": "arXiv"
  },
  {
    "title": "Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques",
    "title_es": "Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques",
    "url": "https://arxiv.org/abs/2506.00658",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.00658v2 Announce Type: replace \nAbstract: Sarcasm is a form of humor where expressions convey meanings opposite to their literal interpretations. Classifying and generating sarcasm using large language models is vital for interpreting human communication. Sarcasm poses challenges for computational models, due to its nuanced nature. We introduce Sarc7, a benchmark that classifies 7 types of sarcasm: self-deprecating, brooding, deadpan, polite, obnoxious, raging, and manic by annotating entries of the MUStARD dataset. Classification was evaluated using zero-shot, few-shot, chain-of-thought (CoT), and a novel emotion-based prompting technique. We propose an emotion-based generation method developed by identifying key components of sarcasm-incongruity, shock value, and context dependency. Our classification experiments show that Gemini 2.5, using emotion-based prompting, outperforms other setups with an F1 score of 0.3664. Human evaluators preferred our emotion-based prompting, with 38.46% more successful generations than zero-shot prompting.",
    "source": "arXiv"
  },
  {
    "title": "DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments",
    "title_es": "DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments",
    "url": "https://arxiv.org/abs/2506.00739",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.00739v3 Announce Type: replace \nAbstract: Large language model (LLM) agents have shown impressive capabilities in human language comprehension and reasoning, yet their potential in cybersecurity remains underexplored. We introduce DefenderBench, a practical, open-source toolkit for evaluating language agents across offense, defense, and cybersecurity knowledge-based tasks. DefenderBench includes environments for network intrusion, malicious content detection, code vulnerability analysis, and cybersecurity knowledge assessment. It is intentionally designed to be affordable and easily accessible for researchers while providing fair and rigorous assessment. We benchmark several state-of-the-art (SoTA) and popular LLMs, including both open- and closed-weight models, using a standardized agentic framework. Our results show that Claude-3.7-sonnet performs best with a DefenderBench score of 81.65, followed by Claude-3.7-sonnet-think with 78.40, while the best open-weight model, Llama 3.3 70B, is not far behind with a DefenderBench score of 71.81. DefenderBench's modular design allows seamless integration of custom LLMs and tasks, promoting reproducibility and fair comparisons. An anonymized version of DefenderBench is available at https://github.com/microsoft/DefenderBench.",
    "source": "arXiv"
  },
  {
    "title": "DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes",
    "title_es": "DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes",
    "url": "https://arxiv.org/abs/2506.01950",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.01950v3 Announce Type: replace \nAbstract: We introduce DualMap, an online open-vocabulary mapping system that enables robots to understand and navigate dynamically changing environments through natural language queries. Designed for efficient semantic mapping and adaptability to changing environments, DualMap meets the essential requirements for real-world robot navigation applications. Our proposed hybrid segmentation frontend and object-level status check eliminate the costly 3D object merging required by prior methods, enabling efficient online scene mapping. The dual-map representation combines a global abstract map for high-level candidate selection with a local concrete map for precise goal-reaching, effectively managing and updating dynamic changes in the environment. Through extensive experiments in both simulation and real-world scenarios, we demonstrate state-of-the-art performance in 3D open-vocabulary segmentation, efficient scene mapping, and online language-guided navigation.Project page: https://eku127.github.io/DualMap/",
    "source": "arXiv"
  },
  {
    "title": "Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning",
    "title_es": "Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning",
    "url": "https://arxiv.org/abs/2506.05207",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.05207v2 Announce Type: replace \nAbstract: Recently, breakthroughs in the video diffusion transformer have shown remarkable capabilities in diverse motion generations. As for the motion-transfer task, current methods mainly use two-stage Low-Rank Adaptations (LoRAs) finetuning to obtain better performance. However, existing adaptation-based motion transfer still suffers from motion inconsistency and tuning inefficiency when applied to large video diffusion transformers. Naive two-stage LoRA tuning struggles to maintain motion consistency between generated and input videos due to the inherent spatial-temporal coupling in the 3D attention operator. Additionally, they require time-consuming fine-tuning processes in both stages. To tackle these issues, we propose Follow-Your-Motion, an efficient two-stage video motion transfer framework that finetunes a powerful video diffusion transformer to synthesize complex motion. Specifically, we propose a spatial-temporal decoupled LoRA to decouple the attention architecture for spatial appearance and temporal motion processing. During the second training stage, we design the sparse motion sampling and adaptive RoPE to accelerate the tuning speed. To address the lack of a benchmark for this field, we introduce MotionBench, a comprehensive benchmark comprising diverse motion, including creative camera motion, single object motion, multiple object motion, and complex human motion. We show extensive evaluations on MotionBench to verify the superiority of Follow-Your-Motion.",
    "source": "arXiv"
  },
  {
    "title": "Gradual Transition from Bellman Optimality Operator to Bellman Operator in Online Reinforcement Learning",
    "title_es": "Gradual Transition from Bellman Optimality Operator to Bellman Operator in Online Reinforcement Learning",
    "url": "https://arxiv.org/abs/2506.05968",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.05968v2 Announce Type: replace \nAbstract: For continuous action spaces, actor-critic methods are widely used in online reinforcement learning (RL). However, unlike RL algorithms for discrete actions, which generally model the optimal value function using the Bellman optimality operator, RL algorithms for continuous actions typically model Q-values for the current policy using the Bellman operator. These algorithms for continuous actions rely exclusively on policy updates for improvement, which often results in low sample efficiency. This study examines the effectiveness of incorporating the Bellman optimality operator into actor-critic frameworks. Experiments in a simple environment show that modeling optimal values accelerates learning but leads to overestimation bias. To address this, we propose an annealing approach that gradually transitions from the Bellman optimality operator to the Bellman operator, thereby accelerating learning while mitigating bias. Our method, combined with TD3 and SAC, significantly outperforms existing approaches across various locomotion and manipulation tasks, demonstrating improved performance and robustness to hyperparameters related to optimality. The code for this study is available at https://github.com/motokiomura/annealed-q-learning.",
    "source": "arXiv"
  },
  {
    "title": "SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence",
    "title_es": "SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence",
    "url": "https://arxiv.org/abs/2506.07966",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.07966v3 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in various multimodal tasks. To pursue higher intelligence in space, MLLMs require integrating multiple atomic spatial capabilities to handle complex and dynamic tasks. However, existing benchmarks struggle to comprehensively evaluate the spatial intelligence of common MLLMs from the atomic level to the compositional level. To fill this gap, we present SpaCE-10, a comprehensive benchmark for compositional spatial evaluations. In SpaCE-10, we define 10 atomic spatial capabilities, which are combined to form 8 compositional capabilities. Based on these definitions, we propose a novel hierarchical annotation pipeline to generate high-quality and diverse question-answer (QA) pairs. With over 150+ hours of human expert effort, we obtain over 5k QA pairs for 811 real indoor scenes in SpaCE-10, which covers various evaluation settings like point cloud input and multi-choice QA. We conduct an extensive evaluation of common MLLMs on SpaCE-10 and find that even the most advanced MLLM still lags behind humans by large margins. Through our careful study, we also draw several significant findings that benefit the MLLM community. For example, we reveal that the shortcoming of counting capability greatly limits the compositional spatial capabilities of existing MLLMs. The evaluation code and benchmark datasets are available at https://github.com/Cuzyoung/SpaCE-10.",
    "source": "arXiv"
  },
  {
    "title": "ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark",
    "title_es": "ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark",
    "url": "https://arxiv.org/abs/2506.10960",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.10960v3 Announce Type: replace \nAbstract: Large language models (LLMs) have been increasingly applied to automated harmful content detection tasks, assisting moderators in identifying policy violations and improving the overall efficiency and accuracy of content review. However, existing resources for harmful content detection are predominantly focused on English, with Chinese datasets remaining scarce and often limited in scope. We present a comprehensive, professionally annotated benchmark for Chinese content harm detection, which covers six representative categories and is constructed entirely from real-world data. Our annotation process further yields a knowledge rule base that provides explicit expert knowledge to assist LLMs in Chinese harmful content detection. In addition, we propose a knowledge-augmented baseline that integrates both human-annotated knowledge rules and implicit knowledge from large language models, enabling smaller models to achieve performance comparable to state-of-the-art LLMs. Code and data are available at https://github.com/zjunlp/ChineseHarm-bench.",
    "source": "arXiv"
  },
  {
    "title": "Mini-Game Lifetime Value Prediction in WeChat",
    "title_es": "Mini-Game Lifetime Value Prediction in WeChat",
    "url": "https://arxiv.org/abs/2506.11037",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.11037v3 Announce Type: replace \nAbstract: The LifeTime Value (LTV) prediction, which endeavors to forecast the cumulative purchase contribution of a user to a particular item, remains a vital challenge that advertisers are keen to resolve. A precise LTV prediction system enhances the alignment of user interests with meticulously designed advertisements, thereby generating substantial profits for advertisers. Nonetheless, this issue is complicated by the paucity of data typically observed in real-world advertising scenarios. The purchase rate among registered users is often as critically low as 0.1%, resulting in a dataset where the majority of users make only several purchases. Consequently, there is insufficient supervisory signal for effectively training the LTV prediction model. An additional challenge emerges from the interdependencies among tasks with high correlation. It is a common practice to estimate a user's contribution to a game over a specified temporal interval. Varying the lengths of these intervals corresponds to distinct predictive tasks, which are highly correlated. For instance, predictions over a 7-day period are heavily reliant on forecasts made over a 3-day period, where exceptional cases can adversely affect the accuracy of both tasks. In order to comprehensively address the aforementioned challenges, we introduce an innovative framework denoted as Graph-Represented Pareto-Optimal LifeTime Value prediction (GRePO-LTV). Graph representation learning is initially employed to address the issue of data scarcity. Subsequently, Pareto-Optimization is utilized to manage the interdependence of prediction tasks.",
    "source": "arXiv"
  },
  {
    "title": "Deep Learning Model Acceleration and Optimization Strategies for Real-Time Recommendation Systems",
    "title_es": "Deep Learning Model Acceleration and Optimization Strategies for Real-Time Recommendation Systems",
    "url": "https://arxiv.org/abs/2506.11421",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.11421v3 Announce Type: replace \nAbstract: With the rapid growth of Internet services, recommendation systems play a central role in delivering personalized content. Faced with massive user requests and complex model architectures, the key challenge for real-time recommendation systems is how to reduce inference latency and increase system throughput without sacrificing recommendation quality. This paper addresses the high computational cost and resource bottlenecks of deep learning models in real-time settings by proposing a combined set of modeling- and system-level acceleration and optimization strategies. At the model level, we dramatically reduce parameter counts and compute requirements through lightweight network design, structured pruning, and weight quantization. At the system level, we integrate multiple heterogeneous compute platforms and high-performance inference libraries, and we design elastic inference scheduling and load-balancing mechanisms based on real-time load characteristics. Experiments show that, while maintaining the original recommendation accuracy, our methods cut latency to less than 30% of the baseline and more than double system throughput, offering a practical solution for deploying large-scale online recommendation services.",
    "source": "arXiv"
  },
  {
    "title": "AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving",
    "title_es": "AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving",
    "url": "https://arxiv.org/abs/2506.12508",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.12508v3 Announce Type: replace \nAbstract: Recent advances in agent systems have demonstrated remarkable capabilities in solving both general-purpose and highly complex tasks. However, most current models lack mechanisms for coordinating specialized agents and have limited ability to generalize to new or diverse domains. To this end, we introduce AgentOrchestra, a hierarchical multi-agent framework for general-purpose task solving that integrates high-level planning with modular agent collaboration. Drawing inspiration from a conductor orchestrating a symphony, and grounded in the principles of extensibility, multimodality, modularity, and coordination, it features a central planning agent that decomposes complex objectives and delegates sub-tasks to a team of specialized agents. Each sub-agent is equipped with general programming tools, as well as abilities to tackle a wide range of real-world specific tasks, including data analysis, file operations, web navigation, and interactive reasoning in dynamic multimodal environments. Notably, AgentOrchestra introduces an MCP Manager Agent that enables intelligent evolution through dynamic tool creation, retrieval, and reuse mechanisms, significantly enhancing the system's adaptability and scalability. AgentOrchestra supports flexible orchestration through explicit sub-goal formulation, inter-agent communication, and adaptive role allocation. We evaluate the framework on three widely used benchmarks for assessing LLM-based agent systems. Experimental results show that AgentOrchestra consistently outperforms flat-agent and monolithic baselines in terms of task success rate and adaptability. On the GAIA benchmark testing dataset, AgentOrchestra achieves an average score of 83.39\\%, ranking among the top general-purpose agents. These results highlight the effectiveness of hierarchical organization and role specialization in building scalable and general-purpose LLM-based agent systems.",
    "source": "arXiv"
  },
  {
    "title": "MGDFIS: Multi-scale Global-detail Feature Integration Strategy for Small Object Detection",
    "title_es": "MGDFIS: Multi-scale Global-detail Feature Integration Strategy for Small Object Detection",
    "url": "https://arxiv.org/abs/2506.12697",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.12697v2 Announce Type: replace \nAbstract: Small object detection in UAV imagery is crucial for applications such as search-and-rescue, traffic monitoring, and environmental surveillance, but it is hampered by tiny object size, low signal-to-noise ratios, and limited feature extraction. Existing multi-scale fusion methods help, but add computational burden and blur fine details, making small object detection in cluttered scenes difficult. To overcome these challenges, we propose the Multi-scale Global-detail Feature Integration Strategy (MGDFIS), a unified fusion framework that tightly couples global context with local detail to boost detection performance while maintaining efficiency. MGDFIS comprises three synergistic modules: the FusionLock-TSS Attention Module, which marries token-statistics self-attention with DynamicTanh normalization to highlight spectral and spatial cues at minimal cost; the Global-detail Integration Module, which fuses multi-scale context via directional convolution and parallel attention while preserving subtle shape and texture variations; and the Dynamic Pixel Attention Module, which generates pixel-wise weighting maps to rebalance uneven foreground and background distributions and sharpen responses to true object regions. Extensive experiments on the VisDrone benchmark demonstrate that MGDFIS consistently outperforms state-of-the-art methods across diverse backbone architectures and detection frameworks, achieving superior precision and recall with low inference time. By striking an optimal balance between accuracy and resource usage, MGDFIS provides a practical solution for small-object detection on resource-constrained UAV platforms.",
    "source": "arXiv"
  },
  {
    "title": "Poison Once, Control Anywhere: Clean-Text Visual Backdoors in VLM-based Mobile Agents",
    "title_es": "Poison Once, Control Anywhere: Clean-Text Visual Backdoors in VLM-based Mobile Agents",
    "url": "https://arxiv.org/abs/2506.13205",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.13205v5 Announce Type: replace \nAbstract: Mobile agents powered by vision-language models (VLMs) are increasingly adopted for tasks such as UI automation and camera-based assistance. These agents are typically fine-tuned using small-scale, user-collected data, making them susceptible to stealthy training-time threats. This work introduces VIBMA, the first clean-text backdoor attack targeting VLM-based mobile agents. The attack injects malicious behaviors into the model by modifying only the visual input while preserving textual prompts and instructions, achieving stealth through the complete absence of textual anomalies. Once the agent is fine-tuned on this poisoned data, adding a predefined visual pattern (trigger) at inference time activates the attacker-specified behavior (backdoor). Our attack aligns the training gradients of poisoned samples with those of an attacker-specified target instance, effectively embedding backdoor-specific features into the poisoned data. To ensure the robustness and stealthiness of the attack, we design three trigger variants that better resemble real-world scenarios: static patches, dynamic motion patterns, and low-opacity blended content. Extensive experiments on six Android applications and three mobile-compatible VLMs demonstrate that our attack achieves high success rates (ASR up to 94.67%) while preserving clean-task behavior (FSR up to 95.85%). We further conduct ablation studies to understand how key design factors impact attack reliability and stealth. These findings is the first to reveal the security vulnerabilities of mobile agents and their susceptibility to backdoor injection, underscoring the need for robust defenses in mobile agent adaptation pipelines.",
    "source": "arXiv"
  },
  {
    "title": "Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning",
    "title_es": "Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning",
    "url": "https://arxiv.org/abs/2506.13265",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.13265v2 Announce Type: replace \nAbstract: Autonomous vehicles that navigate in open-world environments may encounter previously unseen object classes. However, most existing LiDAR panoptic segmentation models rely on closed-set assumptions, failing to detect unknown object instances. In this work, we propose ULOPS, an uncertainty-guided open-set panoptic segmentation framework that leverages Dirichlet-based evidential learning to model predictive uncertainty. Our architecture incorporates separate decoders for semantic segmentation with uncertainty estimation, embedding with prototype association, and instance center prediction. During inference, we leverage uncertainty estimates to identify and segment unknown instances. To strengthen the model's ability to differentiate between known and unknown objects, we introduce three uncertainty-driven loss functions. Uniform Evidence Loss to encourage high uncertainty in unknown regions. Adaptive Uncertainty Separation Loss ensures a consistent difference in uncertainty estimates between known and unknown objects at a global scale. Contrastive Uncertainty Loss refines this separation at the fine-grained level. To evaluate open-set performance, we extend benchmark settings on KITTI-360 and introduce a new open-set evaluation for nuScenes. Extensive experiments demonstrate that ULOPS consistently outperforms existing open-set LiDAR panoptic segmentation methods.",
    "source": "arXiv"
  },
  {
    "title": "HVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment",
    "title_es": "HVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment",
    "url": "https://arxiv.org/abs/2506.13925",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.13925v2 Announce Type: replace \nAbstract: In this paper, we address Semi-supervised Semantic Segmentation (SSS) under domain shift by leveraging domain-invariant semantic knowledge from text embeddings of Vision-Language Models (VLMs). We propose a unified Hierarchical Vision-Language framework (HVL) that integrates domain-invariant text embeddings as object queries in a transformer-based segmentation network to improve generalization and reduce misclassification under limited supervision. The mentioned textual queries are used for grouping pixels with shared semantics under SSS. HVL is designed to (1) generate textual queries that maximally encode domain-invariant semantics from VLM while capturing intra-class variations; (2) align these queries with spatial visual features to enhance their segmentation ability and improve the semantic clarity of visual features. We also introduce targeted regularization losses that maintain vision--language alignment throughout training to reinforce semantic understanding. HVL establishes a novel state-of-the-art by achieving a +9.3% improvement in mean Intersection over Union (mIoU) on COCO, utilizing 232 labelled images, +3.1% on Pascal VOC employing 92 labels, +4.8% on ADE20 using 316 labels, and +3.4% on Cityscapes with 100 labels, demonstrating superior performance with less than 1% supervision on four benchmark datasets. Our results show that language-guided segmentation bridges the label efficiency gap and enables new levels of fine-grained generalization.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Predictive Equivalence in Decision Trees",
    "title_es": "Leveraging Predictive Equivalence in Decision Trees",
    "url": "https://arxiv.org/abs/2506.14143",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.14143v2 Announce Type: replace \nAbstract: Decision trees are widely used for interpretable machine learning due to their clearly structured reasoning process. However, this structure belies a challenge we refer to as predictive equivalence: a given tree's decision boundary can be represented by many different decision trees. The presence of models with identical decision boundaries but different evaluation processes makes model selection challenging. The models will have different variable importance and behave differently in the presence of missing values, but most optimization procedures will arbitrarily choose one such model to return. We present a boolean logical representation of decision trees that does not exhibit predictive equivalence and is faithful to the underlying decision boundary. We apply our representation to several downstream machine learning tasks. Using our representation, we show that decision trees are surprisingly robust to test-time missingness of feature values; we address predictive equivalence's impact on quantifying variable importance; and we present an algorithm to optimize the cost of reaching predictions.",
    "source": "arXiv"
  },
  {
    "title": "Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models",
    "title_es": "Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models",
    "url": "https://arxiv.org/abs/2506.15290",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.15290v2 Announce Type: replace \nAbstract: Motion capture using sparse inertial sensors has shown great promise due to its portability and lack of occlusion issues compared to camera-based tracking. Existing approaches typically assume that IMU sensors are tightly attached to the human body. However, this assumption often does not hold in real-world scenarios. In this paper, we present Garment Inertial Poser (GaIP), a method for estimating full-body poses from sparse and loosely attached IMU sensors. We first simulate IMU recordings using an existing garment-aware human motion dataset. Our transformer-based diffusion models synthesize loose IMU data and estimate human poses from this challenging loose IMU data. We also demonstrate that incorporating garment-related parameters during training on loose IMU data effectively maintains expressiveness and enhances the ability to capture variations introduced by looser or tighter garments. Our experiments show that our diffusion methods trained on simulated and synthetic data outperform state-of-the-art inertial full-body pose estimators, both quantitatively and qualitatively, opening up a promising direction for future research on motion capture from such realistic sensor placements.",
    "source": "arXiv"
  },
  {
    "title": "The Importance of Being Lazy: Scaling Limits of Continual Learning",
    "title_es": "The Importance of Being Lazy: Scaling Limits of Continual Learning",
    "url": "https://arxiv.org/abs/2506.16884",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.16884v2 Announce Type: replace \nAbstract: Despite recent efforts, neural networks still struggle to learn in non-stationary environments, and our understanding of catastrophic forgetting (CF) is far from complete. In this work, we perform a systematic study on the impact of model scale and the degree of feature learning in continual learning. We reconcile existing contradictory observations on scale in the literature, by differentiating between lazy and rich training regimes through a variable parameterization of the architecture. We show that increasing model width is only beneficial when it reduces the amount of feature learning, yielding more laziness. Using the framework of dynamical mean field theory, we then study the infinite width dynamics of the model in the feature learning regime and characterize CF, extending prior theoretical results limited to the lazy regime. We study the intricate relationship between feature learning, task non-stationarity, and forgetting, finding that high feature learning is only beneficial with highly similar tasks. We identify a transition modulated by task similarity where the model exits an effectively lazy regime with low forgetting to enter a rich regime with significant forgetting. Finally, our findings reveal that neural networks achieve optimal performance at a critical level of feature learning, which depends on task non-stationarity and transfers across model scales. This work provides a unified perspective on the role of scale and feature learning in continual learning.",
    "source": "arXiv"
  },
  {
    "title": "SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving",
    "title_es": "SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving",
    "url": "https://arxiv.org/abs/2506.18785",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.18785v2 Announce Type: replace \nAbstract: Perception systems in autonomous driving rely on sensors such as LiDAR and cameras to perceive the 3D environment. However, due to occlusions and data sparsity, these sensors often fail to capture complete information. Semantic Occupancy Prediction (SOP) addresses this challenge by inferring both occupancy and semantics of unobserved regions. Existing transformer-based SOP methods lack explicit modeling of spatial structure in attention computation, resulting in limited geometric awareness and poor performance in sparse or occluded areas. To this end, we propose Spatially-aware Window Attention (SWA), a novel mechanism that incorporates local spatial context into attention. SWA significantly improves scene completion and achieves state-of-the-art results on LiDAR-based SOP benchmarks. We further validate its generality by integrating SWA into a camera-based SOP pipeline, where it also yields consistent gains across modalities.",
    "source": "arXiv"
  },
  {
    "title": "OC-SOP: Enhancing Vision-Based 3D Semantic Occupancy Prediction by Object-Centric Awareness",
    "title_es": "OC-SOP: Enhancing Vision-Based 3D Semantic Occupancy Prediction by Object-Centric Awareness",
    "url": "https://arxiv.org/abs/2506.18798",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.18798v2 Announce Type: replace \nAbstract: Autonomous driving perception faces significant challenges due to occlusions and incomplete scene data in the environment. To overcome these issues, the task of semantic occupancy prediction (SOP) is proposed, which aims to jointly infer both the geometry and semantic labels of a scene from images. However, conventional camera-based methods typically treat all categories equally and primarily rely on local features, leading to suboptimal predictions, especially for dynamic foreground objects. To address this, we propose Object-Centric SOP (OC-SOP), a framework that integrates high-level object-centric cues extracted via a detection branch into the semantic occupancy prediction pipeline. This object-centric integration significantly enhances the prediction accuracy for foreground objects and achieves state-of-the-art performance among all categories on SemanticKITTI.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Autocomplete: Designing CopilotLens Towards Transparent and Explainable AI Coding Agents",
    "title_es": "Beyond Autocomplete: Designing CopilotLens Towards Transparent and Explainable AI Coding Agents",
    "url": "https://arxiv.org/abs/2506.20062",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.20062v2 Announce Type: replace \nAbstract: AI-powered code assistants are widely used to generate code completions, significantly boosting developer productivity. However, these tools typically present suggestions without explaining their rationale, leaving their decision-making process inscrutable. This opacity hinders developers' ability to critically evaluate outputs, form accurate mental models, and calibrate trust in the system. To address this, we introduce CopilotLens, a novel interactive framework that reframes code completion from a simple suggestion into a transparent, explainable interaction. CopilotLens operates as an explanation layer that reconstructs the AI agent's \"thought process\" through a dynamic, two-level interface. The tool aims to surface both high-level code changes and the specific codebase context influences. This paper presents the design and rationale of CopilotLens, offering a concrete framework and articulating expectations on deepening comprehension and calibrated trust, which we plan to evaluate in subsequent work.",
    "source": "arXiv"
  },
  {
    "title": "Unlasting: Unpaired Single-Cell Multi-Perturbation Estimation by Dual Conditional Diffusion Implicit Bridges",
    "title_es": "Unlasting: Unpaired Single-Cell Multi-Perturbation Estimation by Dual Conditional Diffusion Implicit Bridges",
    "url": "https://arxiv.org/abs/2506.21107",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.21107v2 Announce Type: replace \nAbstract: Estimating single-cell responses across various perturbations facilitates the identification of key genes and enhances drug screening, significantly boosting experimental efficiency. However, single-cell sequencing is a destructive process, making it impossible to capture the same cell's phenotype before and after perturbation. Consequently, data collected under perturbed and unperturbed conditions are inherently unpaired. Existing methods either attempt to forcibly pair unpaired data using random sampling, or neglect the inherent relationship between unperturbed and perturbed cells during the modeling. In this work, we propose a framework based on Dual Diffusion Implicit Bridges (DDIB) to learn the mapping between different data distributions, effectively addressing the challenge of unpaired data. We further interpret this framework as a form of data augmentation. We integrate gene regulatory network (GRN) information to propagate perturbation signals in a biologically meaningful way, and further incorporate a masking mechanism to predict silent genes, improving the quality of generated profiles. Moreover, gene expression under the same perturbation often varies significantly across cells, frequently exhibiting a bimodal distribution that reflects intrinsic heterogeneity. To capture this, we introduce a more suitable evaluation metric. We propose Unlasting, dual conditional diffusion models that overcome the problem of unpaired single-cell perturbation data and strengthen the model's insight into perturbations under the guidance of the GRN, with a dedicated mask model designed to improve generation quality by predicting silent genes. In addition, we introduce a biologically grounded evaluation metric that better reflects the inherent heterogeneity in single-cell responses.",
    "source": "arXiv"
  },
  {
    "title": "MetaCipher: A Time-Persistent and Universal Multi-Agent Framework for Cipher-Based Jailbreak Attacks for LLMs",
    "title_es": "MetaCipher: A Time-Persistent and Universal Multi-Agent Framework for Cipher-Based Jailbreak Attacks for LLMs",
    "url": "https://arxiv.org/abs/2506.22557",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.22557v2 Announce Type: replace \nAbstract: As large language models (LLMs) grow more capable, they face growing vulnerability to sophisticated jailbreak attacks. While developers invest heavily in alignment finetuning and safety guardrails, researchers continue publishing novel attacks, driving progress through adversarial iteration. This dynamic mirrors a strategic game of continual evolution. However, two major challenges hinder jailbreak development: the high cost of querying top-tier LLMs and the short lifespan of effective attacks due to frequent safety updates. These factors limit cost-efficiency and practical impact of research in jailbreak attacks. To address this, we propose MetaCipher, a low-cost, multi-agent jailbreak framework that generalizes across LLMs with varying safety measures. Using reinforcement learning, MetaCipher is modular and adaptive, supporting extensibility to future strategies. Within as few as 10 queries, MetaCipher achieves state-of-the-art attack success rates on recent malicious prompt benchmarks, outperforming prior jailbreak methods. We conduct a large-scale empirical evaluation across diverse victim models and benchmarks, demonstrating its robustness and adaptability. Warning: This paper contains model outputs that may be offensive or harmful, shown solely to demonstrate jailbreak efficacy.",
    "source": "arXiv"
  },
  {
    "title": "Faster Diffusion Models via Higher-Order Approximation",
    "title_es": "Faster Diffusion Models via Higher-Order Approximation",
    "url": "https://arxiv.org/abs/2506.24042",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.24042v2 Announce Type: replace \nAbstract: In this paper, we explore provable acceleration of diffusion models without any additional retraining. Focusing on the task of approximating a target data distribution in $\\mathbb{R}^d$ to within $\\varepsilon$ total-variation distance, we propose a principled, training-free sampling algorithm that requires only the order of\n  $$ d^{1+2/K} \\varepsilon^{-1/K} $$\n  score function evaluations (up to log factor) in the presence of accurate scores, where $K>0$ is an arbitrary fixed integer. This result applies to a broad class of target data distributions, without the need for assumptions such as smoothness or log-concavity. Our theory is robust vis-a-vis inexact score estimation, degrading gracefully as the score estimation error increases -- without demanding higher-order smoothness on the score estimates as assumed in previous work. The proposed algorithm draws insight from high-order ODE solvers, leveraging high-order Lagrange interpolation and successive refinement to approximate the integral derived from the probability flow ODE. More broadly, our work develops a theoretical framework towards understanding the efficacy of high-order methods for accelerated sampling.",
    "source": "arXiv"
  },
  {
    "title": "Audio-3DVG: Unified Audio -- Point Cloud Fusion for 3D Visual Grounding",
    "title_es": "Audio-3DVG: Unified Audio -- Point Cloud Fusion for 3D Visual Grounding",
    "url": "https://arxiv.org/abs/2507.00669",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.00669v2 Announce Type: replace \nAbstract: 3D Visual Grounding (3DVG) involves localizing target objects in 3D point clouds based on natural language. While prior work has made strides using textual descriptions, leveraging spoken language-known as Audio-based 3D Visual Grounding-remains underexplored and challenging. Motivated by advances in automatic speech recognition (ASR) and speech representation learning, we propose Audio-3DVG, a simple yet effective framework that integrates audio and spatial information for enhanced grounding. Rather than treating speech as a monolithic input, we decompose the task into two complementary components. First, we introduce (i) Object Mention Detection, a multi-label classification task that explicitly identifies which objects are referred to in the audio, enabling more structured audio-scene reasoning. Second, we propose an (ii) Audio-Guided Attention module that models the interactions between target candidates and mentioned objects, enhancing discrimination in cluttered 3D environments. To support benchmarking, we (iii) synthesize audio descriptions for standard 3DVG datasets, including ScanRefer, Sr3D, and Nr3D. Experimental results demonstrate that Audio-3DVG not only achieves new state-of-the-art performance in audio-based grounding, but also competes with text-based methods, highlight the promise of integrating spoken language into 3D vision tasks.",
    "source": "arXiv"
  },
  {
    "title": "WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks",
    "title_es": "WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks",
    "url": "https://arxiv.org/abs/2507.00938",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.00938v2 Announce Type: replace \nAbstract: Recent progress in large language models (LLMs) has enabled the development of autonomous web agents capable of navigating and interacting with real websites. However, evaluating such agents remains challenging due to the instability and inconsistency of existing benchmarks, which often rely on dynamic content or oversimplified simulations. In this work, we introduce WebArXiv, a static and time-invariant benchmark comprising 275 web-based tasks grounded in the arXiv platform. WebArXiv ensures reproducible and reliable evaluation by anchoring tasks in fixed web snapshots with deterministic ground truths and standardized action trajectories. Through behavioral analysis, we identify a common failure mode, Rigid History Reflection, where agents over-rely on fixed interaction histories. To address this, we propose a lightweight dynamic reflection mechanism that allows agents to selectively retrieve relevant past steps during decision-making. We evaluate ten state-of-the-art web agents on WebArXiv. Results demonstrate clear performance differences across agents and validate the effectiveness of our proposed reflection strategy.",
    "source": "arXiv"
  },
  {
    "title": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning",
    "title_es": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning",
    "url": "https://arxiv.org/abs/2507.01006",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.01006v3 Announce Type: replace \nAbstract: We present GLM-4.1V-Thinking and GLM-4.5V, a family of vision-language models (VLMs) designed to advance general-purpose multimodal understanding and reasoning. In this report, we share our key findings in the development of the reasoning-centric training framework. We first develop a capable vision foundation model with significant potential through large-scale pre-training, which arguably sets the upper bound for the final performance. We then propose Reinforcement Learning with Curriculum Sampling (RLCS) to unlock the full potential of the model, leading to comprehensive capability enhancement across a diverse range of tasks, including STEM problem solving, video understanding, content recognition, coding, grounding, GUI-based agents, and long document interpretation. In a comprehensive evaluation across 42 public benchmarks, GLM-4.5V achieves state-of-the-art performance on nearly all tasks among open-source models of similar size, and demonstrates competitive or even superior results compared to closed-source models such as Gemini-2.5-Flash on challenging tasks including Coding and GUI Agents. Meanwhile, the smaller GLM-4.1V-9B-Thinking remains highly competitive-achieving superior results to the much larger Qwen2.5-VL-72B on 29 benchmarks. We open-source both GLM-4.1V-9B-Thinking and GLM-4.5V. Code, models and more information are released at https://github.com/zai-org/GLM-V.",
    "source": "arXiv"
  },
  {
    "title": "Quantum Machine Learning in Transportation: A Case Study of Pedestrian Stress Modelling",
    "title_es": "Quantum Machine Learning in Transportation: A Case Study of Pedestrian Stress Modelling",
    "url": "https://arxiv.org/abs/2507.01235",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.01235v2 Announce Type: replace \nAbstract: Quantum computing has opened new opportunities to tackle complex machine learning tasks, for instance, high-dimensional data representations commonly required in intelligent transportation systems. We explore quantum machine learning to model complex skin conductance response (SCR) events that reflect pedestrian stress in a virtual reality road crossing experiment. For this purpose, Quantum Support Vector Machine (QSVM) with an eight-qubit ZZ feature map and a Quantum Neural Network (QNN) using a Tree Tensor Network ansatz and an eight-qubit ZZ feature map, were developed on Pennylane. The dataset consists of SCR measurements along with features such as the response amplitude and elapsed time, which have been categorized into amplitude-based classes. The QSVM achieved good training accuracy, but had an overfitting problem, showing a low test accuracy of 45% and therefore impacting the reliability of the classification model. The QNN model reached a higher test accuracy of 55%, making it a better classification model than the QSVM and the classic versions.",
    "source": "arXiv"
  },
  {
    "title": "3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation",
    "title_es": "3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation",
    "url": "https://arxiv.org/abs/2507.01367",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.01367v2 Announce Type: replace \nAbstract: Physical adversarial attack methods expose the vulnerabilities of deep neural networks and pose a significant threat to safety-critical scenarios such as autonomous driving. Camouflage-based physical attack is a more promising approach compared to the patch-based attack, offering stronger adversarial effectiveness in complex physical environments. However, most prior work relies on mesh priors of the target object and virtual environments constructed by simulators, which are time-consuming to obtain and inevitably differ from the real world. Moreover, due to the limitations of the backgrounds in training images, previous methods often fail to produce multi-view robust adversarial camouflage and tend to fall into sub-optimal solutions. Due to these reasons, prior work lacks adversarial effectiveness and robustness across diverse viewpoints and physical environments. We propose a physical attack framework based on 3D Gaussian Splatting (3DGS), named PGA, which provides rapid and precise reconstruction with few images, along with photo-realistic rendering capabilities. Our framework further enhances cross-view robustness and adversarial effectiveness by preventing mutual and self-occlusion among Gaussians and employing a min-max optimization approach that adjusts the imaging background of each viewpoint, helping the algorithm filter out non-robust adversarial features. Extensive experiments validate the effectiveness and superiority of PGA. Our code is available at:https://github.com/TRLou/PGA.",
    "source": "arXiv"
  },
  {
    "title": "Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans",
    "title_es": "Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans",
    "url": "https://arxiv.org/abs/2507.01744",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.01744v2 Announce Type: replace \nAbstract: Vision Transformers (ViTs) have gained significant popularity in the natural image domain but have been less successful in 3D medical image segmentation. Nevertheless, 3D ViTs are particularly interesting for large medical imaging volumes due to their efficient self-supervised training within the masked autoencoder (MAE) framework, which enables the use of imaging data without the need for expensive manual annotations. Intracranial arterial calcification (IAC) is an imaging biomarker visible on routinely acquired CT scans linked to neurovascular diseases such as stroke and dementia, and automated IAC quantification could enable their large-scale risk assessment. We pre-train ViTs with MAE and fine-tune them for IAC segmentation for the first time. To develop our models, we use highly heterogeneous data from a large clinical trial, the third International Stroke Trial (IST-3). We evaluate key aspects of MAE pre-trained ViTs in IAC segmentation, and analyse the clinical implications. We show: 1) our calibrated self-supervised ViT beats a strong supervised nnU-Net baseline by 3.2 Dice points, 2) low patch sizes are crucial for ViTs for IAC segmentation and interpolation upsampling with regular convolutions is preferable to transposed convolutions for ViT-based models, and 3) our ViTs increase robustness to higher slice thicknesses and improve risk group classification in a clinical scenario by 46%. Our code is available online.",
    "source": "arXiv"
  },
  {
    "title": "Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views",
    "title_es": "Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views",
    "url": "https://arxiv.org/abs/2507.01835",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.01835v2 Announce Type: replace \nAbstract: Hyperspectral reconstruction (HSR) from RGB images is a fundamentally ill-posed problem due to severe spectral information loss. Existing approaches typically rely on a single RGB image, limiting reconstruction accuracy. In this work, we propose a novel multi-image-to-hyperspectral reconstruction (MI-HSR) framework that leverages a triple-camera smartphone system, where two lenses are equipped with carefully selected spectral filters. Our configuration, grounded in theoretical and empirical analysis, enables richer and more diverse spectral observations than conventional single-camera setups. To support this new paradigm, we introduce Doomer, the first dataset for MI-HSR, comprising aligned images from three smartphone cameras and a hyperspectral reference camera across diverse scenes. We show that the proposed HSR model achieves consistent improvements over existing methods on the newly proposed benchmark. In a nutshell, our setup allows 30% towards more accurately estimated spectra compared to an ordinary RGB camera. Our findings suggest that multi-view spectral filtering with commodity hardware can unlock more accurate and practical hyperspectral imaging solutions.",
    "source": "arXiv"
  },
  {
    "title": "Learning Adaptive Node Selection with External Attention for Human Interaction Recognition",
    "title_es": "Learning Adaptive Node Selection with External Attention for Human Interaction Recognition",
    "url": "https://arxiv.org/abs/2507.03936",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.03936v2 Announce Type: replace \nAbstract: Most GCN-based methods model interacting individuals as independent graphs, neglecting their inherent inter-dependencies. Although recent approaches utilize predefined interaction adjacency matrices to integrate participants, these matrices fail to adaptively capture the dynamic and context-specific joint interactions across different actions. In this paper, we propose the Active Node Selection with External Attention Network (ASEA), an innovative approach that dynamically captures interaction relationships without predefined assumptions. Our method models each participant individually using a GCN to capture intra-personal relationships, facilitating a detailed representation of their actions. To identify the most relevant nodes for interaction modeling, we introduce the Adaptive Temporal Node Amplitude Calculation (AT-NAC) module, which estimates global node activity by combining spatial motion magnitude with adaptive temporal weighting, thereby highlighting salient motion patterns while reducing irrelevant or redundant information. A learnable threshold, regularized to prevent extreme variations, is defined to selectively identify the most informative nodes for interaction modeling. To capture interactions, we design the External Attention (EA) module to operate on active nodes, effectively modeling the interaction dynamics and semantic relationships between individuals. Extensive evaluations show that our method captures interaction relationships more effectively and flexibly, achieving state-of-the-art performance.",
    "source": "arXiv"
  },
  {
    "title": "Exploring a Gamified Personality Assessment Method through Interaction with Multi-Personality LLM Agents",
    "title_es": "Exploring a Gamified Personality Assessment Method through Interaction with Multi-Personality LLM Agents",
    "url": "https://arxiv.org/abs/2507.04005",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.04005v2 Announce Type: replace \nAbstract: The execution of effective and imperceptible personality assessments is receiving increasing attention in psychology and human-computer interaction fields. This study explores an interactive approach for personality assessment, focusing on the multiplicity of personality representation. We propose a framework of gamified personality assessment through multi-personality representations (Multi-PR GPA). The framework leverages Large Language Models to empower virtual agents with diverse personalities. These agents elicit multifaceted human personality representations through engaging in interactive games. Drawing upon the multi-type textual data generated throughout the interaction, it achieves two ways of personality assessments (i.e., Direct Assessment and Que-based Assessment) and provides interpretable insights. Grounded in the classic Big Five theory, we implemented a prototype system and conducted a user study to assess the efficacy of Multi-PR GPA. The results underscore the effectiveness of our approach in personality assessment and demonstrate that it achieves superior performance when considering the multiplicity of personality representation.",
    "source": "arXiv"
  },
  {
    "title": "MoSE: Skill-by-Skill Mixture-of-Experts Learning for Embodied Autonomous Machines",
    "title_es": "MoSE: Skill-by-Skill Mixture-of-Experts Learning for Embodied Autonomous Machines",
    "url": "https://arxiv.org/abs/2507.07818",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.07818v2 Announce Type: replace \nAbstract: To meet the growing demand for smarter, faster, and more efficient embodied AI solutions, we introduce a novel Mixture-of-Expert (MoE) method that significantly boosts reasoning and learning efficiency for embodied autonomous systems. General MoE models demand extensive training data and complex optimization, which limits their applicability in embodied AI such as autonomous driving (AD) and robotic manipulation. In this work, we propose a skill-oriented MoE called MoSE, which mimics the human learning and reasoning process skill-by-skill, step-by-step. We introduce a skill-oriented routing mechanism that begins with defining and annotating specific skills, enabling experts to identify the necessary competencies for various scenarios and reasoning tasks, thereby facilitating skill-by-skill learning. To better align with multi-step planning in human reasoning and in end-to-end driving models, we build a hierarchical skill dataset and pretrain the router to encourage the model to think step-by-step. Unlike other multi-round dialogues, MoSE integrates valuable auxiliary tasks (e.g. perception-prediction-planning for AD, and high-level and low-level planning for robots) in one single forward process without introducing any extra computational cost. With less than 3B sparsely activated parameters, our model effectively grows more diverse expertise and outperforms models on both AD corner-case reasoning tasks and robot reasoning tasks with less than 40% of the parameters.",
    "source": "arXiv"
  },
  {
    "title": "RoHOI: Robustness Benchmark for Human-Object Interaction Detection",
    "title_es": "RoHOI: Robustness Benchmark for Human-Object Interaction Detection",
    "url": "https://arxiv.org/abs/2507.09111",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.09111v2 Announce Type: replace \nAbstract: Human-Object Interaction (HOI) detection is crucial for robot-human assistance, enabling context-aware support. However, models trained on clean datasets degrade in real-world conditions due to unforeseen corruptions, leading to inaccurate prediction. To address this, we introduce the first robustness benchmark for HOI detection, evaluating model resilience under diverse challenges. Despite advances, current models struggle with environmental variability, occlusions, and noise. Our benchmark, RoHOI, includes 20 corruption types based on the HICO-DET and V-COCO datasets and a new robustness-focused metric. We systematically analyze existing models in the HOI field, revealing significant performance drops under corruptions. To improve robustness, we propose a Semantic-Aware Masking-based Progressive Learning (SAMPL) strategy to guide the model to be optimized based on holistic and partial cues, thus dynamically adjusting the model's optimization to enhance robust feature learning. Extensive experiments show that our approach outperforms state-of-the-art methods, setting a new standard for robust HOI detection. Benchmarks, datasets, and code will be made publicly available at https://github.com/Kratos-Wen/RoHOI.",
    "source": "arXiv"
  },
  {
    "title": "Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations",
    "title_es": "Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations",
    "url": "https://arxiv.org/abs/2507.09500",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.09500v2 Announce Type: replace \nAbstract: Vision-language models (VLMs) exhibit remarkable zero-shot capabilities but struggle with distribution shifts in downstream tasks when labeled data is unavailable, which has motivated the development of Test-Time Adaptation (TTA) to improve VLMs' performance during inference without annotations. Among various TTA approaches, cache-based methods show promise by preserving historical knowledge from low-entropy samples in a dynamic cache and fostering efficient adaptation. However, these methods face two critical reliability challenges: (1) entropy often becomes unreliable under distribution shifts, causing error accumulation in the cache and degradation in adaptation performance; (2) the final predictions may be unreliable due to inflexible decision boundaries that fail to accommodate large downstream shifts. To address these challenges, we propose a Reliable Test-time Adaptation (ReTA) method that integrates two complementary strategies to enhance reliability from two perspectives. First, to mitigate the unreliability of entropy as a sample selection criterion for cache construction, we introduce Consistency-aware Entropy Reweighting (CER), which incorporates consistency constraints to weight entropy during cache updating. While conventional approaches rely solely on low entropy for cache prioritization and risk introducing noise, our method leverages predictive consistency to maintain a high-quality cache and facilitate more robust adaptation. Second, we present Diversity-driven Distribution Calibration (DDC), which models class-wise text embeddings as multivariate Gaussian distributions, enabling adaptive decision boundaries for more accurate predictions across visually diverse content. Extensive experiments demonstrate that ReTA consistently outperforms state-of-the-art methods, particularly under real-world distribution shifts. Code: https://github.com/Evelyn1ywliang/ReTA.",
    "source": "arXiv"
  },
  {
    "title": "Qualitative Study for LLM-assisted Design Study Process: Strategies, Challenges, and Roles",
    "title_es": "Qualitative Study for LLM-assisted Design Study Process: Strategies, Challenges, and Roles",
    "url": "https://arxiv.org/abs/2507.10024",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.10024v4 Announce Type: replace \nAbstract: Design studies aim to create visualization solutions for real-world problems of different application domains. Recently, the emergence of large language models (LLMs) has introduced new opportunities to enhance the design study process, providing capabilities such as creative problem-solving, data handling, and insightful analysis. However, despite their growing popularity, there remains a lack of systematic understanding of how LLMs can effectively assist researchers in visualization-specific design studies. In this paper, we conducted a multi-stage qualitative study to fill this gap, involving 30 design study researchers from diverse backgrounds and expertise levels. Through in-depth interviews and carefully-designed questionnaires, we investigated strategies for utilizing LLMs, the challenges encountered, and the practices used to overcome them. We further compiled and summarized the roles that LLMs can play across different stages of the design study process. Our findings highlight practical implications to inform visualization practitioners, and provide a framework for leveraging LLMs to enhance the design study process in visualization research.",
    "source": "arXiv"
  },
  {
    "title": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs",
    "title_es": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs",
    "url": "https://arxiv.org/abs/2507.10772",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.10772v2 Announce Type: replace \nAbstract: Labeled property graphs often contain rich textual attributes that can enhance analytical tasks when properly leveraged. This work explores the use of pretrained text embedding models to enable efficient semantic analysis in such graphs. By embedding textual node and edge properties, we support downstream tasks including node classification and relation prediction with improved contextual understanding. Our approach integrates language model embeddings into the graph pipeline without altering its structure, demonstrating that textual semantics can significantly enhance the accuracy and interpretability of property graph analysis.",
    "source": "arXiv"
  },
  {
    "title": "HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation",
    "title_es": "HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation",
    "url": "https://arxiv.org/abs/2507.12883",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.12883v2 Announce Type: replace \nAbstract: The reasoning segmentation task involves segmenting objects within an image by interpreting implicit user instructions, which may encompass subtleties such as contextual cues and open-world knowledge. Despite significant advancements made by existing approaches, they remain constrained by low perceptual resolution, as visual encoders are typically pre-trained at lower resolutions. Furthermore, simply interpolating the positional embeddings of visual encoders to enhance perceptual resolution yields only marginal performance improvements while incurring substantial computational costs. To address this, we propose HRSeg, an efficient model with high-resolution fine-grained perception. It features two key innovations: High-Resolution Perception (HRP) and High-Resolution Enhancement (HRE). The HRP module processes high-resolution images through cropping, integrating local and global features for multi-granularity quality. The HRE module enhances mask features by integrating fine-grained information from high-resolution images, refining their alignment with text features for precise segmentation. Extensive ablation studies validate the effectiveness of our modules, while comprehensive experiments on multiple benchmark datasets demonstrate HRSeg's superior performance.",
    "source": "arXiv"
  },
  {
    "title": "Complexity of Abduction in \\L{}ukasiewicz Logic",
    "title_es": "Complexity of Abduction in \\L{}ukasiewicz Logic",
    "url": "https://arxiv.org/abs/2507.13847",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.13847v3 Announce Type: replace \nAbstract: We explore the problem of explaining observations in contexts involving statements with truth degrees such as `the lift is loaded', `the symptoms are severe', etc. To formalise these contexts, we consider infinitely-valued {\\L}ukasiewicz fuzzy logic. We define and motivate the notions of abduction problems and explanations in the language of {\\L}ukasiewicz logic expanded with `interval literals' of the form $p\\geq\\mathbf{c}$, $p\\leq\\mathbf{c}$, and their negations that express the set of values a variable can have. We analyse the complexity of standard abductive reasoning tasks (solution recognition, solution existence, and relevance / necessity of hypotheses) in {\\L}ukasiewicz logic for the case of the full language and for the case of theories containing only disjunctive clauses and show that in contrast to classical propositional logic, the abduction in the clausal fragment has lower complexity than in the general case.",
    "source": "arXiv"
  },
  {
    "title": "A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems",
    "title_es": "A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems",
    "url": "https://arxiv.org/abs/2507.14043",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.14043v2 Announce Type: replace \nAbstract: Metaheuristic algorithms have gained widespread application across various fields owing to their ability to generate diverse solutions. One such algorithm is the Snake Optimizer (SO), a progressive optimization approach. However, SO suffers from the issues of slow convergence speed and susceptibility to local optima. In light of these shortcomings, we propose a novel Multi-strategy Improved Snake Optimizer (MISO). Firstly, we propose a new adaptive random disturbance strategy based on sine function to alleviate the risk of getting trapped in a local optimum. Secondly, we introduce adaptive Levy flight strategy based on scale factor and leader and endow the male snake leader with flight capability, which makes it easier for the algorithm to leap out of the local optimum and find the global optimum. More importantly, we put forward a position update strategy combining elite leadership and Brownian motion, effectively accelerating the convergence speed while ensuring precision. Finally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test functions and the CEC2022 test suite, comparing it with 11 popular algorithms across different dimensions to validate its effectiveness. Moreover, Unmanned Aerial Vehicle (UAV) has been widely used in various fields due to its advantages of low cost, high mobility and easy operation. However, the UAV path planning problem is crucial for flight safety and efficiency, and there are still challenges in establishing and optimizing the path model. Therefore, we apply MISO to the UAV 3D path planning problem as well as 6 engineering design problems to assess its feasibility in practical applications. The experimental results demonstrate that MISO exceeds other competitive algorithms in terms of solution quality and stability, establishing its strong potential for application.",
    "source": "arXiv"
  },
  {
    "title": "Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown",
    "title_es": "Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown",
    "url": "https://arxiv.org/abs/2507.15290",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.15290v2 Announce Type: replace \nAbstract: Thompson Sampling (TS) is widely used to address the exploration/exploitation tradeoff in contextual bandits, yet recent theory shows that it does not explore aggressively enough in high-dimensional problems. Feel-Good Thompson Sampling (FG-TS) addresses this by adding an optimism bonus that biases toward high-reward models, and it achieves the asymptotically minimax-optimal regret in the linear setting when posteriors are exact. However, its performance with \\emph{approximate} posteriors -- common in large-scale or neural problems -- has not been benchmarked. We provide the first systematic study of FG-TS and its smoothed variant (SFG-TS) across eleven real-world and synthetic benchmarks. To evaluate their robustness, we compare performance across settings with exact posteriors (linear and logistic bandits) to approximate regimes produced by fast but coarse stochastic-gradient samplers. Ablations over preconditioning, bonus scale, and prior strength reveal a trade-off: larger bonuses help when posterior samples are accurate, but hurt when sampling noise dominates. FG-TS generally outperforms vanilla TS in linear and logistic bandits, but tends to be weaker in neural bandits. Nevertheless, because FG-TS and its variants are competitive and easy-to-use, we recommend them as baselines in modern contextual-bandit benchmarks. Finally, we provide source code for all our experiments in https://github.com/SarahLiaw/ctx-bandits-mcmc-showdown.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Visual Appearance Optimization by Learning from Prior Preferences",
    "title_es": "Efficient Visual Appearance Optimization by Learning from Prior Preferences",
    "url": "https://arxiv.org/abs/2507.15355",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.15355v2 Announce Type: replace \nAbstract: Adjusting visual parameters such as brightness and contrast is common in our everyday experiences. Finding the optimal parameter setting is challenging due to the large search space and the lack of an explicit objective function, leaving users to rely solely on their implicit preferences. Prior work has explored Preferential Bayesian Optimization (PBO) to address this challenge, involving users to iteratively select preferred designs from candidate sets. However, PBO often requires many rounds of preference comparisons, making it more suitable for designers than everyday end-users. We propose Meta-PO, a novel method that integrates PBO with meta-learning to improve sample efficiency. Specifically, Meta-PO infers prior users' preferences and stores them as models, which are leveraged to intelligently suggest design candidates for the new users, enabling faster convergence and more personalized results. An experimental evaluation of our method for appearance design tasks on 2D and 3D content showed that participants achieved satisfactory appearance in 5.86 iterations using Meta-PO when participants shared similar goals with a population (e.g., tuning for a ``warm'' look) and in 8 iterations even generalizes across divergent goals (e.g., from ``vintage'', ``warm'', to ``holiday''). Meta-PO makes personalized visual optimization more applicable to end-users through a generalizable, more efficient optimization conditioned on preferences, with the potential to scale interface personalization more broadly.",
    "source": "arXiv"
  },
  {
    "title": "PDEformer-2: A Versatile Foundation Model for Two-Dimensional Partial Differential Equations",
    "title_es": "PDEformer-2: A Versatile Foundation Model for Two-Dimensional Partial Differential Equations",
    "url": "https://arxiv.org/abs/2507.15409",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.15409v2 Announce Type: replace \nAbstract: Partial differential equations (PDEs) play a central role in describing many physical phenomena. Various scientific and engineering applications demand a versatile and differentiable PDE solver that can quickly generate solutions with adequate accuracy, and limitations of the traditional solvers and specialized neural operators motivate the development of foundation models for solving PDEs. This paper introduces PDEformer-2, a versatile foundation model for two-dimensional PDEs. Based on our previous one-dimensional PDEformer-1 model, PDEformer-2 receives the PDE form as network input via computational graph representation, which has the flexibility to encode most common PDEs. The mesh-free predicted solutions can be directly queried at arbitrary spatio-temporal coordinates. A large (40TB) diverse dataset is employed to pretrain the current model, making it capable of simultaneously addressing PDEs with different symbolic forms, domain shapes, boundary conditions, number of variables, and time-dependency. Accurate zero-shot prediction is allowed for PDEs that resemble the pretraining ones. When adapted to new unseen PDEs, PDEformer-2 demonstrates faster learning than many specialized models, and has smaller errors given limited (less than 100) samples. Additionally, PDEformer-2 can be employed in the inverse problems thanks to its fast and differentiable nature and produces reasonable results in our experiments to recover coefficient scalars and fields of a PDE.",
    "source": "arXiv"
  },
  {
    "title": "See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering",
    "title_es": "See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering",
    "url": "https://arxiv.org/abs/2507.17659",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.17659v3 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) have pushed the frontiers of Knowledge-Based Visual Question Answering (KBVQA), yet their reasoning is fundamentally bottlenecked by a reliance on uni-dimensional evidence. This \"seeing only the trees, but not the forest\" approach prevents robust, multi-faceted understanding. Inspired by the principle of seeing both the forest and trees, we propose Synergos-VQA, a novel synergistic reasoning framework. At its core, Synergos-VQA concurrently generates and fuses three complementary evidence streams at inference time: (1) Holistic Evidence to perceive the entire scene (the \"forest\"), (2) Structural Evidence from a prototype-driven module to identify key objects (the \"trees\"), and (3) Causal Evidence from a counterfactual probe to ensure the reasoning is robustly grounded. By synergistically fusing this multi-faceted evidence, our framework achieves a more comprehensive and reliable reasoning process. Extensive experiments show that Synergos-VQA decisively establishes a new state-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA. Furthermore, our approach demonstrates strong plug-and-play capabilities, significantly boosting various open-source MLLMs and proving that superior methodological design can outperform sheer model scale.",
    "source": "arXiv"
  },
  {
    "title": "DRWKV: Focusing on Object Edges for Low-Light Image Enhancement",
    "title_es": "DRWKV: Focusing on Object Edges for Low-Light Image Enhancement",
    "url": "https://arxiv.org/abs/2507.18594",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.18594v2 Announce Type: replace \nAbstract: Low-light image enhancement remains a challenging task, particularly in preserving object edge continuity and fine structural details under extreme illumination degradation. In this paper, we propose a novel model, DRWKV (Detailed Receptance Weighted Key Value), which integrates our proposed Global Edge Retinex (GER) theory, enabling effective decoupling of illumination and edge structures for enhanced edge fidelity. Secondly, we introduce Evolving WKV Attention, a spiral-scanning mechanism that captures spatial edge continuity and models irregular structures more effectively. Thirdly, we design the Bilateral Spectrum Aligner (Bi-SAB) and a tailored MS2-Loss to jointly align luminance and chrominance features, improving visual naturalness and mitigating artifacts. Extensive experiments on five LLIE benchmarks demonstrate that DRWKV achieves leading performance in PSNR, SSIM, and NIQE while maintaining low computational complexity. Furthermore, DRWKV enhances downstream performance in low-light multi-object tracking tasks, validating its generalization capabilities.",
    "source": "arXiv"
  },
  {
    "title": "Towards reliable use of artificial intelligence to classify otitis media using otoscopic images: Addressing bias and improving data quality",
    "title_es": "Towards reliable use of artificial intelligence to classify otitis media using otoscopic images: Addressing bias and improving data quality",
    "url": "https://arxiv.org/abs/2507.18842",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.18842v2 Announce Type: replace \nAbstract: Ear disease contributes significantly to global hearing loss, with recurrent otitis media being a primary preventable cause in children, impacting development. Artificial intelligence (AI) offers promise for early diagnosis via otoscopic image analysis, but dataset biases and inconsistencies limit model generalizability and reliability. This retrospective study systematically evaluated three public otoscopic image datasets (Chile; Ohio, USA; T\\\"urkiye) using quantitative and qualitative methods. Two counterfactual experiments were performed: (1) obscuring clinically relevant features to assess model reliance on non-clinical artifacts, and (2) evaluating the impact of hue, saturation, and value on diagnostic outcomes. Quantitative analysis revealed significant biases in the Chile and Ohio, USA datasets. Counterfactual Experiment I found high internal performance (AUC > 0.90) but poor external generalization, because of dataset-specific artifacts. The T\\\"urkiye dataset had fewer biases, with AUC decreasing from 0.86 to 0.65 as masking increased, suggesting higher reliance on clinically meaningful features. Counterfactual Experiment II identified common artifacts in the Chile and Ohio, USA datasets. A logistic regression model trained on clinically irrelevant features from the Chile dataset achieved high internal (AUC = 0.89) and external (Ohio, USA: AUC = 0.87) performance. Qualitative analysis identified redundancy in all the datasets and stylistic biases in the Ohio, USA dataset that correlated with clinical outcomes. In summary, dataset biases significantly compromise reliability and generalizability of AI-based otoscopic diagnostic models. Addressing these biases through standardized imaging protocols, diverse dataset inclusion, and improved labeling methods is crucial for developing robust AI solutions, improving high-quality healthcare access, and enhancing diagnostic accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Synthesis Benchmarks for Automated Reasoning",
    "title_es": "Synthesis Benchmarks for Automated Reasoning",
    "url": "https://arxiv.org/abs/2507.19827",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.19827v2 Announce Type: replace \nAbstract: Program synthesis is the task of constructing a program conforming to a given specification. We focus on deductive synthesis, and in particular on synthesis problems with specifications given as $\\forall\\exists$-formulas, expressing the existence of an output corresponding to any input. So far there has been no canonical benchmark set for deductive synthesis using the $\\forall\\exists$-format and supporting the so-called uncomputable symbol restriction. This work presents such a data set, composed by complementing existing benchmarks by new ones. Our data set is dynamically growing and should motivate future developments in the theory and practice of automating synthesis.",
    "source": "arXiv"
  },
  {
    "title": "StepFun-Prover Preview: Let's Think and Verify Step by Step",
    "title_es": "StepFun-Prover Preview: Let's Think and Verify Step by Step",
    "url": "https://arxiv.org/abs/2507.20199",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.20199v3 Announce Type: replace \nAbstract: We present StepFun-Prover Preview, a large language model designed for formal theorem proving through tool-integrated reasoning. Using a reinforcement learning pipeline that incorporates tool-based interactions, StepFun-Prover can achieve strong performance in generating Lean 4 proofs with minimal sampling. Our approach enables the model to emulate human-like problem-solving strategies by iteratively refining proofs based on real-time environment feedback. On the miniF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of $70.0\\%$. Beyond advancing benchmark performance, we introduce an end-to-end training framework for developing tool-integrated reasoning models, offering a promising direction for automated theorem proving and Math AI assistant.",
    "source": "arXiv"
  },
  {
    "title": "VoteGCL: Enhancing Graph-based Recommendations with Majority-Voting LLM-Rerank Augmentation",
    "title_es": "VoteGCL: Enhancing Graph-based Recommendations with Majority-Voting LLM-Rerank Augmentation",
    "url": "https://arxiv.org/abs/2507.21563",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.21563v3 Announce Type: replace \nAbstract: Recommendation systems often suffer from data sparsity caused by limited user-item interactions, which degrade their performance and amplify popularity bias in real-world scenarios. This paper proposes a novel data augmentation framework that leverages Large Language Models (LLMs) and item textual descriptions to enrich interaction data. By few-shot prompting LLMs multiple times to rerank items and aggregating the results via majority voting, we generate high-confidence synthetic user-item interactions, supported by theoretical guarantees based on the concentration of measure. To effectively leverage the augmented data in the context of a graph recommendation system, we integrate it into a graph contrastive learning framework to mitigate distributional shift and alleviate popularity bias. Extensive experiments show that our method improves accuracy and reduces popularity bias, outperforming strong baselines.",
    "source": "arXiv"
  },
  {
    "title": "LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection",
    "title_es": "LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection",
    "url": "https://arxiv.org/abs/2507.21756",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.21756v2 Announce Type: replace \nAbstract: Detecting driver fatigue is critical for road safety, as drowsy driving remains a leading cause of traffic accidents. Many existing solutions rely on computationally demanding deep learning models, which result in high latency and are unsuitable for embedded robotic devices with limited resources (such as intelligent vehicles/cars) where rapid detection is necessary to prevent accidents. This paper introduces LiteFat, a lightweight spatio-temporal graph learning model designed to detect driver fatigue efficiently while maintaining high accuracy and low computational demands. LiteFat involves converting streaming video data into spatio-temporal graphs (STG) using facial landmark detection, which focuses on key motion patterns and reduces unnecessary data processing. LiteFat uses MobileNet to extract facial features and create a feature matrix for the STG. A lightweight spatio-temporal graph neural network is then employed to identify signs of fatigue with minimal processing and low latency. Experimental results on benchmark datasets show that LiteFat performs competitively while significantly decreasing computational complexity and latency as compared to current state-of-the-art methods. This work enables the development of real-time, resource-efficient human fatigue detection systems that can be implemented upon embedded robotic devices.",
    "source": "arXiv"
  },
  {
    "title": "HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels",
    "title_es": "HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels",
    "url": "https://arxiv.org/abs/2507.21809",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.21809v2 Announce Type: replace \nAbstract: Creating immersive and playable 3D worlds from texts or images remains a fundamental challenge in computer vision and graphics. Existing world generation approaches typically fall into two categories: video-based methods that offer rich diversity but lack 3D consistency and rendering efficiency, and 3D-based methods that provide geometric consistency but struggle with limited training data and memory-inefficient representations. To address these limitations, we present HunyuanWorld 1.0, a novel framework that combines the best of both worlds for generating immersive, explorable, and interactive 3D scenes from text and image conditions. Our approach features three key advantages: 1) 360{\\deg} immersive experiences via panoramic world proxies; 2) mesh export capabilities for seamless compatibility with existing computer graphics pipelines; 3) disentangled object representations for augmented interactivity. The core of our framework is a semantically layered 3D mesh representation that leverages panoramic images as 360{\\deg} world proxies for semantic-aware world decomposition and reconstruction, enabling the generation of diverse 3D worlds. Extensive experiments demonstrate that our method achieves state-of-the-art performance in generating coherent, explorable, and interactive 3D worlds while enabling versatile applications in virtual reality, physical simulation, game development, and interactive content creation.",
    "source": "arXiv"
  },
  {
    "title": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?",
    "title_es": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?",
    "url": "https://arxiv.org/abs/2507.21817",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.21817v2 Announce Type: replace \nAbstract: Automated vulnerability detection research has made substantial progress, yet its real-world impact remains limited. Current vulnerability datasets suffer from issues including label inaccuracy rates of 20-71%, extensive duplication, and poor coverage of critical CWE types. These issues create a significant \"generalization gap\" where models achieve misleading self-testing performance (measured on held-out data from the same dataset for training) by exploiting spurious correlations rather than learning true vulnerability patterns. Our analysis reveals that many models experience substantial performance drops of up to 33% when evaluated on independent data, with some performing close to random guessing. To address these limitations, we present a three-part solution. First, we introduce a manually curated test dataset, BenchVul, covering the MITRE Top 25 Most Dangerous CWEs. Second, we construct a high-quality training dataset, TitanVul, comprising 38,863 functions by aggregating seven public sources and applying deduplication and validation using a novel multi-agent LLM framework. Third, we propose a Realistic Vulnerability Generation (RVG) framework, which synthesizes context-aware vulnerability examples for underrepresented but critical CWE types through simulated development workflows. Our evaluation shows the strengths of each component in closing the generalization gap. First, BenchVul shows the limitations of self-testing: models trained on existing datasets, such as BigVul and CVEfixes, experience performance drops on BenchVul (from 0.776 to 0.519 and from 0.713 to 0.607). Second, training models on TitanVul demonstrates improved generalization, with model performance increasing from 0.584 when evaluated on the same dataset to 0.767 when tested on BenchVul. Third, supplementing TitanVul with RVG-generated data yields further gains, increasing model performance by 14.0% to 0.874.",
    "source": "arXiv"
  },
  {
    "title": "On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations",
    "title_es": "On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations",
    "url": "https://arxiv.org/abs/2507.22398",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.22398v3 Announce Type: replace \nAbstract: Vision-Language Models (VLMs) are increasingly used as perceptual modules for visual content reasoning, including through captioning and DeepFake detection. In this work, we expose a critical vulnerability of VLMs when exposed to subtle, structured perturbations in the frequency domain. Specifically, we highlight how these feature transformations undermine authenticity/DeepFake detection and automated image captioning tasks. We design targeted image transformations, operating in the frequency domain to systematically adjust VLM outputs when exposed to frequency-perturbed real and synthetic images. We demonstrate that the perturbation injection method generalizes across five state-of-the-art VLMs which includes different-parameter Qwen2/2.5 and BLIP models. Experimenting across ten real and generated image datasets reveals that VLM judgments are sensitive to frequency-based cues and may not wholly align with semantic content. Crucially, we show that visually-imperceptible spatial frequency transformations expose the fragility of VLMs deployed for automated image captioning and authenticity detection tasks. Our findings under realistic, black-box constraints challenge the reliability of VLMs, underscoring the need for robust multimodal perception systems.",
    "source": "arXiv"
  },
  {
    "title": "A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains",
    "title_es": "A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains",
    "url": "https://arxiv.org/abs/2507.23486",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.23486v3 Announce Type: replace \nAbstract: Large language models (LLMs) hold promise in clinical decision support but face major challenges in safety evaluation and effectiveness validation. We developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a multidimensional framework built on clinical expert consensus, encompassing 30 criteria covering critical areas like critical illness recognition, guideline adherence, and medication safety, with weighted consequence measures. Thirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A items aligned with these criteria, spanning 26 clinical departments to simulate real-world scenarios. Benchmark testing of six LLMs revealed moderate overall performance (average total score 57.2%, safety 54.7%, effectiveness 62.3%), with a significant 13.3% performance drop in high-risk scenarios (p < 0.0001). Domain-specific medical LLMs showed consistent performance advantages over general-purpose models, with relatively higher top scores in safety (0.912) and effectiveness (0.861). The findings of this study not only provide a standardized metric for evaluating the clinical application of medical LLMs, facilitating comparative analyses, risk exposure identification, and improvement directions across different scenarios, but also hold the potential to promote safer and more effective deployment of large language models in healthcare environments.",
    "source": "arXiv"
  },
  {
    "title": "Decoupling Data and Tooling in Interactive Visualization",
    "title_es": "Decoupling Data and Tooling in Interactive Visualization",
    "url": "https://arxiv.org/abs/2508.00107",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.00107v2 Announce Type: replace \nAbstract: Interactive data visualization is a major part of modern exploratory data analysis, with web-based technologies enabling a rich ecosystem of both specialized and general tools. However, current visualization tools often lack support for transformation or wrangling of data and are forced to re-implement their own solutions to load and ingest data. This redundancy creates substantial development overhead for tool creators, steeper learning curves for users who must master different data handling interfaces across tools and a degraded user experience as data handling is usually seen as an after-thought.\n  We propose a modular approach that separates data wrangling and loading capabilities from visualization components. This architecture allows visualization tools to concentrate on their core strengths while providing the opportunity to develop a unified, powerful interface for data handling. An additional benefit of this approach is that it allows for multiple tools to exist and be used side by side. We demonstrate the feasibility of this approach by building an early prototype using web technologies to encapsulate visualization tools and manage data flow between them.\n  We discuss future research directions, including downstream integrations with other tooling, such as IDEs, literate programming notebooks and applications, as well as incorporation of new technologies for efficient data transformations. We seek input from the community to better understand the requirements towards this approach.",
    "source": "arXiv"
  },
  {
    "title": "Reimagining Voltage-Controlled Cryogenic Boolean Logic Paradigm with Quantum-Enhanced Josephson Junction FETs",
    "title_es": "Reimagining Voltage-Controlled Cryogenic Boolean Logic Paradigm with Quantum-Enhanced Josephson Junction FETs",
    "url": "https://arxiv.org/abs/2508.00295",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.00295v2 Announce Type: replace \nAbstract: The growing demand for ultra low power computing and the emergence of quantum technologies have intensified interest in cryogenic electronics, particularly superconducting devices.Despite their promise, current controlled superconducting components face fundamental challenges in cascadability, limiting their effectiveness in complex logic architectures.To overcome this, recent efforts have focused on developing gate tunable superconducting devices, such as Josephson junction field effect transistors (JJFETs).However, achieving robust control and sufficient supercurrent gain, both critical for transistor-like performance in logic circuits remains a key challenge.A recent advancement in JJFET design, based on InAs and GaSb heterostructures, demonstrates enhanced gain and favorable device characteristics suitable for circuit integration.Building on this innovation, we propose and analyze fundamental voltage controlled logic topologies using the quantum enhanced JJFET. We develop a Verilog A based circuit compatible compact model of the quantum enhanced JJFET which accurately captures the experimentally observed device characteristics.To ensure cascadability, our logic circuits incorporate the multilayered Heater Nanocryotron (nTron), a superconducting nanowire-based thermal switch.Through simulation based analysis, we demonstrate the successful implementation of fundamental logic gates, including NOT, NAND, and NOR. Furthermore, we design a 3 input majority gate, which plays a pivotal role in quantum and reversible computing due to its universality.Finally, to demonstrate the cascadability of our proposed logic topology, we demonstrate the operation of a 2 input XOR gate based on our designed JJFET based NOT, NAND, and NOR gate.",
    "source": "arXiv"
  },
  {
    "title": "Rxiv-Maker: an automated template engine for streamlined scientific publications",
    "title_es": "Rxiv-Maker: an automated template engine for streamlined scientific publications",
    "url": "https://arxiv.org/abs/2508.00836",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.00836v3 Announce Type: replace \nAbstract: Preprint servers accelerate research dissemination, but authors still face complex manuscript preparation without professional typesetting support. Rxiv-Maker enables researchers to create documents using a framework that converts Markdown into publication-standard PDFs. It automatically translates the markdown text into LaTeX, so researchers don't have to write any LaTeX code themselves. This tool transforms simple documents into dynamic, version-controlled files that work well with modern team collaboration and ongoing updates. Rxiv-Maker executes Python and R scripts for on-the-fly figure generation, ensuring visualisations stay current with data and analyses. Automated build environments, Docker support, and built-in citation and cross-reference management ensure reliable, reproducible builds across systems, while the conversion process handles mathematical equations and formatting. Rxiv-Maker simplifies professional typesetting, promoting clear and open scientific publishing. This manuscript showcases Rxiv-Maker's capabilities, serving as a testament to its elegance in action.",
    "source": "arXiv"
  },
  {
    "title": "How Much is Too Much? Learning Personalised Risk Thresholds in Real-World Driving",
    "title_es": "How Much is Too Much? Learning Personalised Risk Thresholds in Real-World Driving",
    "url": "https://arxiv.org/abs/2508.00888",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.00888v2 Announce Type: replace \nAbstract: While naturalistic driving studies have become foundational for providing real-world driver behaviour data, the existing frameworks for identifying risk based on such data have two fundamental limitations: (i) they rely on predefined time windows and fixed thresholds to disentangle risky and normal episodes of driving behaviour, and (ii) they assume stationary behavioural distribution across drivers and trips. These limitations have hindered the ability of the existing frameworks to capture behavioural nuances, adapt to individual variability, or respond to stochastic fluctuations in driving contexts. Thus, there is a need for a unified framework that jointly adapts risk labels and model learning to per-driver behavioural dynamics, a gap this study aims to bridge. We present an adaptive and personalised risk detection framework, built on Belgian naturalistic driving data, integrating a rolling time window with bi-level optimisation and dynamically calibrating both model hyperparameters and driver-specific risk thresholds at the same time. The framework was tested using two safety indicators, speed-weighted time headway and harsh driving events, and three models: Random Forest, XGBoost, and Deep Neural Network (DNN). Speed-weighted time headway yielded more stable and context-sensitive classifications than harsh-event counts. XGBoost maintained consistent performance under changing thresholds, while the DNN excelled in early-risk detection at lower thresholds but exhibited higher variability. The ensemble calibration integrates model-specific thresholds and confidence scores into a unified risk decision, balancing sensitivity and stability. Overall, the framework demonstrates the potential of adaptive and personalised risk detection to enhance real-time safety feedback and support driver-specific interventions within intelligent transport systems.",
    "source": "arXiv"
  },
  {
    "title": "Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens",
    "title_es": "Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens",
    "url": "https://arxiv.org/abs/2508.01191",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.01191v3 Announce Type: replace \nAbstract: Chain-of-Thought (CoT) prompting has been shown to improve Large Language Model (LLM) performance on various tasks. With this approach, LLMs appear to produce human-like reasoning steps before providing answers (a.k.a., CoT reasoning), which often leads to the perception that they engage in deliberate inferential processes. However, some initial findings suggest that CoT reasoning may be more superficial than it appears, motivating us to explore further. In this paper, we study CoT reasoning via a data distribution lens and investigate if CoT reasoning reflects a structured inductive bias learned from in-distribution data, allowing the model to conditionally generate reasoning paths that approximate those seen during training. Thus, its effectiveness is fundamentally bounded by the degree of distribution discrepancy between the training data and the test queries. With this lens, we dissect CoT reasoning via three dimensions: task, length, and format. To investigate each dimension, we design DataAlchemy, an isolated and controlled environment to train LLMs from scratch and systematically probe them under various distribution conditions. Our results reveal that CoT reasoning is a brittle mirage that vanishes when it is pushed beyond training distributions. This work offers a deeper understanding of why and when CoT reasoning fails, emphasizing the ongoing challenge of achieving genuine and generalizable reasoning.",
    "source": "arXiv"
  },
  {
    "title": "One Subgoal at a Time: Zero-Shot Generalization to Arbitrary Linear Temporal Logic Requirements in Multi-Task Reinforcement Learning",
    "title_es": "One Subgoal at a Time: Zero-Shot Generalization to Arbitrary Linear Temporal Logic Requirements in Multi-Task Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.01561",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.01561v2 Announce Type: replace \nAbstract: Generalizing to complex and temporally extended task objectives and safety constraints remains a critical challenge in reinforcement learning (RL). Linear temporal logic (LTL) offers a unified formalism to specify such requirements, yet existing methods are limited in their abilities to handle nested long-horizon tasks and safety constraints, and cannot identify situations when a subgoal is not satisfiable and an alternative should be sought. In this paper, we introduce GenZ-LTL, a method that enables zero-shot generalization to arbitrary LTL specifications. GenZ-LTL leverages the structure of B\\\"uchi automata to decompose an LTL task specification into sequences of reach-avoid subgoals. Contrary to the current state-of-the-art method that conditions on subgoal sequences, we show that it is more effective to achieve zero-shot generalization by solving these reach-avoid problems \\textit{one subgoal at a time} through proper safe RL formulations. In addition, we introduce a novel subgoal-induced observation reduction technique that can mitigate the exponential complexity of subgoal-state combinations under realistic assumptions. Empirical results show that GenZ-LTL substantially outperforms existing methods in zero-shot generalization to unseen LTL specifications.",
    "source": "arXiv"
  },
  {
    "title": "Reservoir Computing with Evolved Critical Neural Cellular Automata",
    "title_es": "Reservoir Computing with Evolved Critical Neural Cellular Automata",
    "url": "https://arxiv.org/abs/2508.02218",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.02218v2 Announce Type: replace \nAbstract: Criticality is a behavioral state in dynamical systems that is known to present the highest computation capabilities, i.e., information transmission, storage, and modification. Therefore, such systems are ideal candidates as a substrate for reservoir computing, a subfield in artificial intelligence. Our choice of a substrate is a cellular automaton (CA) governed by an artificial neural network, also known as neural cellular automaton (NCA). We apply evolution strategy to optimize the NCA to achieve criticality, demonstrated by power law distributions in structures called avalanches. With an evolved critical NCA, the substrate is tested for reservoir computing. Our evaluation of the substrate is performed with two benchmarks, 5-bit memory task and image classification of handwritten digits. The result of the 5-bit memory task achieved a perfect score and the system managed to remember all 5 bits. The result for the image classification task matched and sometimes surpassed the performance of the best elementary CA for this task. Moreover, the proposed critical NCA may operate as a self-organized critical system, due to its robustness to extreme initial conditions.",
    "source": "arXiv"
  },
  {
    "title": "MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention",
    "title_es": "MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention",
    "url": "https://arxiv.org/abs/2508.03034",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.03034v2 Announce Type: replace \nAbstract: Achieving ID-preserving text-to-video (T2V) generation remains challenging despite recent advances in diffusion-based models. Existing approaches often fail to capture fine-grained facial dynamics or maintain temporal identity coherence. To address these limitations, we propose MoCA, a novel Video Diffusion Model built on a Diffusion Transformer (DiT) backbone, incorporating a Mixture of Cross-Attention mechanism inspired by the Mixture-of-Experts paradigm. Our framework improves inter-frame identity consistency by embedding MoCA layers into each DiT block, where Hierarchical Temporal Pooling captures identity features over varying timescales, and Temporal-Aware Cross-Attention Experts dynamically model spatiotemporal relationships. We further incorporate a Latent Video Perceptual Loss to enhance identity coherence and fine-grained details across video frames. To train this model, we collect CelebIPVid, a dataset of 10,000 high-resolution videos from 1,000 diverse individuals, promoting cross-ethnicity generalization. Extensive experiments on CelebIPVid show that MoCA outperforms existing T2V methods by over 5% across Face similarity.",
    "source": "arXiv"
  },
  {
    "title": "Estimating Worst-Case Frontier Risks of Open-Weight LLMs",
    "title_es": "Estimating Worst-Case Frontier Risks of Open-Weight LLMs",
    "url": "https://arxiv.org/abs/2508.03153",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.03153v2 Announce Type: replace \nAbstract: In this paper, we study the worst-case frontier risks of releasing gpt-oss. We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum capabilities by fine-tuning gpt-oss to be as capable as possible in two domains: biology and cybersecurity. To maximize biological risk (biorisk), we curate tasks related to threat creation and train gpt-oss in an RL environment with web browsing. To maximize cybersecurity risk, we train gpt-oss in an agentic coding environment to solve capture-the-flag (CTF) challenges. We compare these MFT models against open- and closed-weight LLMs on frontier risk evaluations. Compared to frontier closed-weight models, MFT gpt-oss underperforms OpenAI o3, a model that is below Preparedness High capability level for biorisk and cybersecurity. Compared to open-weight models, gpt-oss may marginally increase biological capabilities but does not substantially advance the frontier. Taken together, these results contributed to our decision to release the model, and we hope that our MFT approach can serve as useful guidance for estimating harm from future open-weight releases.",
    "source": "arXiv"
  },
  {
    "title": "Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling",
    "title_es": "Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling",
    "url": "https://arxiv.org/abs/2508.03611",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.03611v2 Announce Type: replace \nAbstract: This paper presents Block, a distributed scheduling framework designed to optimize load balancing and auto-provisioning across instances in large language model serving frameworks by leveraging contextual information from incoming requests. Unlike popular model serving systems that rely on monolithic and heuristic task schedulers, Block operates as a fully distributed, stateless, and predictive scheduling system to achieve low overhead, reliability, and scalability. It leverages the deterministic and predictable characteristics of LLM inferences, such as host configurations, response lengths, and hardware performance, to make scheduling decisions based on accurately predicted metrics. Evaluation on a 12 GPUs cluster shows that Block significantly outperforms heuristic schedulers, boosting serving capacity by up to 16.7\\% and reducing P99 tail latency by up to 49.5\\%. These performance gains remain consistent across diverse models, workloads and configurations. Code and data are open-sourced.",
    "source": "arXiv"
  },
  {
    "title": "GTPO: Trajectory-Based Policy Optimization in Large Language Models",
    "title_es": "GTPO: Trajectory-Based Policy Optimization in Large Language Models",
    "url": "https://arxiv.org/abs/2508.03772",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.03772v2 Announce Type: replace \nAbstract: Policy-based optimizations are widely adopted today for the training and alignment of language models, where one of the most recent and effective approaches is Group-relative Policy Optimization (GRPO). In this paper, we reveals and analyze two major limitations of GRPO: (i) tokens frequently appear in completions with both positive and negative rewards, leading to conflicting gradient updates that can reduce their output probability, even though can be essential for maintaining proper structure; (ii) negatively rewarded completions may penalize confident responses and shift model decisions toward unlikely tokens, progressively flattening the output distribution and degrading learning. To address these issues and provide a more stable and effective policy optimization strategy, we introduce GTPO (Group-relative Trajectory-based Policy Optimization), which identifies conflict tokens, tokens appearing in the same position across completions with opposite rewards, protects them by skipping negative updates, while amplifying positive ones. To further prevent policy collapse, GTPO filters out completions whose entropy exceeds a provable threshold. Unlike GRPO, GTPO does not rely on KL-divergence regularization, eliminating the need for a reference model during training, while still ensuring greater training stability and improved performance, validated through multiple experiments on GSM8K, MATH and AIME 2024 benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Confidence Driven Classification of Application Types in the Presence of Background Network",
    "title_es": "Confidence Driven Classification of Application Types in the Presence of Background Network",
    "url": "https://arxiv.org/abs/2508.03891",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.03891v3 Announce Type: replace \nAbstract: Accurately classifying the application types of network traffic using deep learning models has recently gained popularity. However, we find that these classifiers do not perform well on real-world traffic data due to the presence of non-application-specific generic background traffic originating from advertisements, analytics, shared APIs, and trackers. Unfortunately, state-of-the-art application classifiers overlook such traffic in curated datasets and only classify relevant application traffic. To address this issue, when we label and train using an additional class for background traffic, it leads to additional confusion between application and background traffic, as the latter is heterogeneous and encompasses all traffic that is not relevant to the application sessions. To avoid falsely classifying background traffic as one of the relevant application types, a reliable confidence measure is warranted, such that we can refrain from classifying uncertain samples. Therefore, we design a Gaussian Mixture Model-based classification framework that improves the indication of the deep learning classifier's confidence to allow more reliable classification.",
    "source": "arXiv"
  },
  {
    "title": "FairPOT: Balancing AUC Performance and Fairness with Proportional Optimal Transport",
    "title_es": "FairPOT: Balancing AUC Performance and Fairness with Proportional Optimal Transport",
    "url": "https://arxiv.org/abs/2508.03940",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.03940v2 Announce Type: replace \nAbstract: Fairness metrics utilizing the area under the receiver operator characteristic curve (AUC) have gained increasing attention in high-stakes domains such as healthcare, finance, and criminal justice. In these domains, fairness is often evaluated over risk scores rather than binary outcomes, and a common challenge is that enforcing strict fairness can significantly degrade AUC performance. To address this challenge, we propose Fair Proportional Optimal Transport (FairPOT), a novel, model-agnostic post-processing framework that strategically aligns risk score distributions across different groups using optimal transport, but does so selectively by transforming a controllable proportion, i.e., the top-lambda quantile, of scores within the disadvantaged group. By varying lambda, our method allows for a tunable trade-off between reducing AUC disparities and maintaining overall AUC performance. Furthermore, we extend FairPOT to the partial AUC setting, enabling fairness interventions to concentrate on the highest-risk regions. Extensive experiments on synthetic, public, and clinical datasets show that FairPOT consistently outperforms existing post-processing techniques in both global and partial AUC scenarios, often achieving improved fairness with slight AUC degradation or even positive gains in utility. The computational efficiency and practical adaptability of FairPOT make it a promising solution for real-world deployment.",
    "source": "arXiv"
  },
  {
    "title": "GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy",
    "title_es": "GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy",
    "url": "https://arxiv.org/abs/2508.04349",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.04349v3 Announce Type: replace \nAbstract: Reinforcement learning (RL) with algorithms like Group Relative Policy Optimization (GRPO) improves Large Language Model (LLM) reasoning, but is limited by a coarse-grained credit assignment that applies a uniform reward to all tokens in a sequence. This is a major flaw in long-chain reasoning tasks. This paper solves this with \\textbf{Dynamic Entropy Weighting}. Our core idea is that high-entropy tokens in correct responses can guide the policy toward a higher performance ceiling. This allows us to create more fine-grained reward signals for precise policy updates via two ways: 1) \\textbf{Group Token Policy Optimization} (\\textbf{GTPO}), we assigns a entropy-weighted reward to each token for fine-grained credit assignment. 2) \\textbf{Sequence-Level Group Relative Policy Optimization} (\\textbf{GRPO-S}), we assigns a entropy-weighted reward to each sequence based on its average token entropy. Experiments show our methods significantly outperform the strong DAPO baseline. The results confirm that our entropy-weighting mechanism is the key driver of this performance boost, offering a better path to enhance deep reasoning in models.",
    "source": "arXiv"
  },
  {
    "title": "BridgeDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment",
    "title_es": "BridgeDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment",
    "url": "https://arxiv.org/abs/2508.04611",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.04611v2 Announce Type: replace \nAbstract: Monocular and stereo depth estimation offer complementary strengths: monocular methods capture rich contextual priors but lack geometric precision, while stereo approaches leverage epipolar geometry yet struggle with ambiguities such as reflective or textureless surfaces. Despite post-hoc synergies, these paradigms remain largely disjoint in practice. We introduce a unified framework that bridges both through iterative bidirectional alignment of their latent representations. At its core, a novel cross-attentive alignment mechanism dynamically synchronizes monocular contextual cues with stereo hypothesis representations during stereo reasoning. This mutual alignment resolves stereo ambiguities (e.g., specular surfaces) by injecting monocular structure priors while refining monocular depth with stereo geometry within a single network. Extensive experiments demonstrate state-of-the-art results: \\textbf{it reduces zero-shot generalization error by $\\!>\\!40\\%$ on Middlebury and ETH3D}, while addressing longstanding failures on transparent and reflective surfaces. By harmonizing multi-view geometry with monocular context, our approach enables robust 3D perception that transcends modality-specific limitations. Codes available at https://github.com/aeolusguan/BridgeDepth.",
    "source": "arXiv"
  },
  {
    "title": "Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories",
    "title_es": "Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories",
    "url": "https://arxiv.org/abs/2508.05148",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.05148v2 Announce Type: replace \nAbstract: The integration of robotics and automation into self-driving laboratories (SDLs) can introduce additional safety complexities, in addition to those that already apply to conventional research laboratories. Personal protective equipment (PPE) is an essential requirement for ensuring the safety and well-being of workers in laboratories, self-driving or otherwise. Fires are another important risk factor in chemical laboratories. In SDLs, fires that occur close to mobile robots, which use flammable lithium batteries, could have increased severity. Here, we present Chemist Eye, a distributed safety monitoring system designed to enhance situational awareness in SDLs. The system integrates multiple stations equipped with RGB, depth, and infrared cameras, designed to monitor incidents in SDLs. Chemist Eye is also designed to spot workers who have suffered a potential accident or medical emergency, PPE compliance and fire hazards. To do this, Chemist Eye uses decision-making driven by a vision-language model (VLM). Chemist Eye is designed for seamless integration, enabling real-time communication with robots. Based on the VLM recommendations, the system attempts to drive mobile robots away from potential fire locations, exits, or individuals not wearing PPE, and issues audible warnings where necessary. It also integrates with third-party messaging platforms to provide instant notifications to lab personnel. We tested Chemist Eye with real-world data from an SDL equipped with three mobile robots and found that the spotting of possible safety hazards and decision-making performances reached 97 % and 95 %, respectively.",
    "source": "arXiv"
  },
  {
    "title": "Request-Only Optimization for Recommendation Systems",
    "title_es": "Request-Only Optimization for Recommendation Systems",
    "url": "https://arxiv.org/abs/2508.05640",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.05640v2 Announce Type: replace \nAbstract: Deep Learning Recommendation Models (DLRMs) represent one of the largest machine learning applications on the planet. Industry-scale DLRMs are trained with petabytes of recommendation data to serve billions of users every day. To utilize the rich user signals in the long user history, DLRMs have been scaled up to unprecedented complexity, up to trillions of floating-point operations (TFLOPs) per example. This scale, coupled with the huge amount of training data, necessitates new storage and training algorithms to efficiently improve the quality of these complex recommendation systems. In this paper, we present a Request-Only Optimizations (ROO) training and modeling paradigm. ROO simultaneously improves the storage and training efficiency as well as the model quality of recommendation systems. We holistically approach this challenge through co-designing data (i.e., request-only data), infrastructure (i.e., request-only based data processing pipeline), and model architecture (i.e., request-only neural architectures). Our ROO training and modeling paradigm treats a user request as a unit of the training data. Compared with the established practice of treating a user impression as a unit, our new design achieves native feature deduplication in data logging, consequently saving data storage. Second, by de-duplicating computations and communications across multiple impressions in a request, this new paradigm enables highly scaled-up neural network architectures to better capture user interest signals, such as Generative Recommenders (GRs) and other request-only friendly architectures.",
    "source": "arXiv"
  },
  {
    "title": "Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation of LLM",
    "title_es": "Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation of LLM",
    "url": "https://arxiv.org/abs/2508.05775",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.05775v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have revolutionized content creation across digital platforms, offering unprecedented capabilities in natural language generation and understanding. These models enable beneficial applications such as content generation, question and answering (Q&A), programming, and code reasoning. Meanwhile, they also pose serious risks by inadvertently or intentionally producing toxic, offensive, or biased content. This dual role of LLMs, both as powerful tools for solving real-world problems and as potential sources of harmful language, presents a pressing sociotechnical challenge. In this survey, we systematically review recent studies spanning unintentional toxicity, adversarial jailbreaking attacks, and content moderation techniques. We propose a unified taxonomy of LLM-related harms and defenses, analyze emerging multimodal and LLM-assisted jailbreak strategies, and assess mitigation efforts, including reinforcement learning with human feedback (RLHF), prompt engineering, and safety alignment. Our synthesis highlights the evolving landscape of LLM safety, identifies limitations in current evaluation methodologies, and outlines future research directions to guide the development of robust and ethically aligned language technologies.",
    "source": "arXiv"
  },
  {
    "title": "Dual Signal Decomposition of Stochastic Time Series",
    "title_es": "Dual Signal Decomposition of Stochastic Time Series",
    "url": "https://arxiv.org/abs/2508.05915",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.05915v2 Announce Type: replace \nAbstract: The decomposition of a stochastic time series into three component series representing a dual signal - namely, the mean and dispersion - while isolating noise is presented. The decomposition is performed by applying machine learning techniques to fit the dual signal. Machine learning minimizes the loss function which compromises between fitting the original time series and penalizing irregularities of the dual signal. The latter includes terms based on the first and second order derivatives along time. To preserve special patterns, weighting of the regularization components of the loss function has been introduced based on Statistical Process Control methodology. The proposed decomposition can be applied as a smoothing algorithm against the mean and dispersion of the time series. By isolating noise, the proposed decomposition can be seen as a denoising algorithm. Two approaches of the learning process have been considered: sequential and jointly. The former approach learns the mean signal first and then dispersion. The latter approach fits the dual signal jointly. Jointly learning can uncover complex relationships for the time series with heteroskedasticity. Learning has been set by solving the direct non-linear unconstrained optimization problem or by applying neural networks that have sequential or twin output architectures. Tuning of the loss function hyperparameters focuses on the isolated noise to be a stationary stochastic process without autocorrelation properties. Depending on the applications, the hyperparameters of the learning can be tuned towards either the discrete states by stepped signal or smoothed series. The decomposed dual signal can be represented on the 2D space and used to learn inherent structures, to forecast both mean and dispersion, or to analyze cross effects in case of multiple time series.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts",
    "title_es": "Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts",
    "url": "https://arxiv.org/abs/2508.05993",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.05993v2 Announce Type: replace \nAbstract: Streaming recommender systems (SRSs) are widely deployed in real-world applications, where user interests shift and new items arrive over time. As a result, effectively capturing users' latest preferences is challenging, as interactions reflecting recent interests are limited and new items often lack sufficient feedback. A common solution is to enrich item representations using multimodal encoders (e.g., BERT or ViT) to extract visual and textual features. However, these encoders are pretrained on general-purpose tasks: they are not tailored to user preference modeling, and they overlook the fact that user tastes toward modality-specific features such as visual styles and textual tones can also drift over time. This presents two key challenges in streaming scenarios: the high cost of fine-tuning large multimodal encoders, and the risk of forgetting long-term user preferences due to continuous model updates.\n  To tackle these challenges, we propose Expandable Side Mixture-of-Experts (XSMoE), a memory-efficient framework for multimodal streaming recommendation. XSMoE attaches lightweight side-tuning modules consisting of expandable expert networks to frozen pretrained encoders and incrementally expands them in response to evolving user feedback. A gating router dynamically combines expert and backbone outputs, while a utilization-based pruning strategy maintains model compactness. By learning new patterns through expandable experts without overwriting previously acquired knowledge, XSMoE effectively captures both cold start and shifting preferences in multimodal features. Experiments on three real-world datasets demonstrate that XSMoE outperforms state-of-the-art baselines in both recommendation quality and computational efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning",
    "title_es": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning",
    "url": "https://arxiv.org/abs/2508.06199",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06199v2 Announce Type: replace \nAbstract: Pretrained neural networks have attracted significant interest in chemistry and small molecule drug design. Embeddings from these models are widely used for molecular property prediction, virtual screening, and small data learning in molecular chemistry. This study presents the most extensive comparison of such models to date, evaluating 25 models across 25 datasets. Under a fair comparison framework, we assess models spanning various modalities, architectures, and pretraining strategies. Using a dedicated hierarchical Bayesian statistical testing model, we arrive at a surprising result: nearly all neural models show negligible or no improvement over the baseline ECFP molecular fingerprint. Only the CLAMP model, which is also based on molecular fingerprints, performs statistically significantly better than the alternatives. These findings raise concerns about the evaluation rigor in existing studies. We discuss potential causes, propose solutions, and offer practical recommendations.",
    "source": "arXiv"
  },
  {
    "title": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?",
    "title_es": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?",
    "url": "https://arxiv.org/abs/2508.06220",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06220v2 Announce Type: replace \nAbstract: Recent advances in Vision-Language Models (VLMs) have demonstrated impressive capabilities in perception and reasoning. However, the ability to perform causal inference -- a core aspect of human cognition -- remains underexplored, particularly in multimodal settings. In this study, we introduce InfoCausalQA, a novel benchmark designed to evaluate causal reasoning grounded in infographics that combine structured visual data with textual context. The benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning based on inferred numerical trends, while Task 2 targets semantic causal reasoning involving five types of causal relations: cause, effect, intervention, counterfactual, and temporal. We manually collected 494 infographic-text pairs from four public sources and used GPT-4o to generate 1,482 high-quality multiple-choice QA pairs. These questions were then carefully revised by humans to ensure they cannot be answered based on surface-level cues alone but instead require genuine visual grounding. Our experimental results reveal that current VLMs exhibit limited capability in computational reasoning and even more pronounced limitations in semantic causal reasoning. Their significantly lower performance compared to humans indicates a substantial gap in leveraging infographic-based information for causal inference. Through InfoCausalQA, we highlight the need for advancing the causal reasoning abilities of multimodal AI systems.",
    "source": "arXiv"
  },
  {
    "title": "LLM Robustness Leaderboard v1 --Technical report",
    "title_es": "LLM Robustness Leaderboard v1 --Technical report",
    "url": "https://arxiv.org/abs/2508.06296",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06296v2 Announce Type: replace \nAbstract: This technical report accompanies the LLM robustness leaderboard published by PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior Elicitation Tool (BET), an AI system performing automated red-teaming through Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR) against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we propose a fine-grained robustness metric estimating the average number of attempts required to elicit harmful behaviors, revealing that attack difficulty varies by over 300-fold across models despite universal vulnerability. We introduce primitive-level vulnerability analysis to identify which jailbreaking techniques are most effective for specific hazard categories. Our collaborative evaluation with trusted third parties from the AI Safety Network demonstrates practical pathways for distributed robustness assessment across the community.",
    "source": "arXiv"
  },
  {
    "title": "Memp: Exploring Agent Procedural Memory",
    "title_es": "Memp: Exploring Agent Procedural Memory",
    "url": "https://arxiv.org/abs/2508.06433",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06433v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) based agents excel at diverse tasks, yet they suffer from brittle procedural memory that is manually engineered or entangled in static parameters. In this work, we investigate strategies to endow agents with a learnable, updatable, and lifelong procedural memory. We propose Memp that distills past agent trajectories into both fine-grained, step-by-step instructions and higher-level, script-like abstractions, and explore the impact of different strategies for Build, Retrieval, and Update of procedural memory. Coupled with a dynamic regimen that continuously updates, corrects, and deprecates its contents, this repository evolves in lockstep with new experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as the memory repository is refined, agents achieve steadily higher success rates and greater efficiency on analogous tasks. Moreover, procedural memory built from a stronger model retains its value: migrating the procedural memory to a weaker model yields substantial performance gains.",
    "source": "arXiv"
  },
  {
    "title": "BigTokDetect: A Clinically-Informed Vision-Language Modeling Framework for Detecting Pro-Bigorexia Videos on TikTok",
    "title_es": "BigTokDetect: A Clinically-Informed Vision-Language Modeling Framework for Detecting Pro-Bigorexia Videos on TikTok",
    "url": "https://arxiv.org/abs/2508.06515",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06515v2 Announce Type: replace \nAbstract: Social media platforms increasingly struggle to detect harmful content that promotes muscle dysmorphic behaviors, particularly pro-bigorexia content that disproportionately affects adolescent males. Unlike traditional eating disorder detection focused on the \"thin ideal,\" pro-bigorexia material masquerades as legitimate fitness content through complex multimodal combinations of visual displays, coded language, and motivational messaging that evade text-based detection systems. We address this challenge by developing BigTokDetect, a clinically-informed detection framework for identifying pro-bigorexia content on TikTok. We introduce BigTok, the first expert-annotated multimodal dataset of over 2,200 TikTok videos labeled by clinical psychologists and psychiatrists across five primary categories spanning body image, nutrition, exercise, supplements, and masculinity. Through a comprehensive evaluation of state-of-the-art vision language models, we achieve 82.9% accuracy on primary category classification and 69.0% on subcategory detection via domain-specific finetuning. Our ablation studies demonstrate that multimodal fusion improves performance by 5-10% over text-only approaches, with video features providing the most discriminative signals. These findings establish new benchmarks for multimodal harmful content detection and provide both the computational tools and methodological framework needed for scalable content moderation in specialized mental health domains.",
    "source": "arXiv"
  },
  {
    "title": "Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC",
    "title_es": "Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC",
    "url": "https://arxiv.org/abs/2508.06564",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06564v2 Announce Type: replace \nAbstract: Multimodal Emotion Recognition in Conversations remains a challenging task due to the complex interplay of textual, acoustic and visual signals. While recent models have improved performance via advanced fusion strategies, they often lack psychologically meaningful priors to guide multimodal alignment. In this paper, we revisit the use of CLIP and propose a novel Visual Emotion Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics into the fusion and classification process. Distinct from prior work that primarily utilizes CLIP's textual encoder, our approach leverages its image encoder to construct emotion-specific visual anchors based on facial exemplars. These anchors guide unimodal and multimodal features toward a perceptually grounded and psychologically aligned representation space, drawing inspiration from cognitive theories (prototypical emotion categories and multisensory integration). A stochastic anchor sampling strategy further enhances robustness by balancing semantic stability and intra-class diversity. Integrated into a dual-branch architecture with self-distillation, our VEGA-augmented model achieves sota performance on IEMOCAP and MELD. Code is available at: https://github.com/dkollias/VEGA.",
    "source": "arXiv"
  },
  {
    "title": "Generalizing Scaling Laws for Dense and Sparse Large Language Models",
    "title_es": "Generalizing Scaling Laws for Dense and Sparse Large Language Models",
    "url": "https://arxiv.org/abs/2508.06617",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06617v2 Announce Type: replace \nAbstract: Over the past few years, the size of language models has grown exponentially, as has the computational cost to train these large models. This rapid growth has motivated researchers to develop new techniques aimed at enhancing the efficiency of the training process. Despite these advancements, optimally predicting the model size or allocating optimal resources remains a challenge. Several efforts have addressed the challenge by proposing different scaling laws, but almost all of them are architecture-specific (dense or sparse). In this work we revisit existing scaling laws and propose a generalized scaling law to provide a unified framework that is applicable to both dense and sparse large language models. We evaluate and compare our proposed scaling law with existing scaling laws to demonstrate its effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "Controlling tail risk in two-slope ski rental",
    "title_es": "Controlling tail risk in two-slope ski rental",
    "url": "https://arxiv.org/abs/2508.06809",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06809v2 Announce Type: replace \nAbstract: We study the optimal solution to a general two-slope ski rental problem with a tail risk, i.e., the chance of the competitive ratio exceeding a value $\\gamma$ is bounded by $\\delta$. This extends the recent study of tail bounds for ski rental by [Dinitz et al. SODA 2024] to the two-slope version defined by [Lotker et al. IPL 2008]. In this version, even after \"buying\" we must still pay a rental cost at each time step, though it is lower after buying. This models many real-world \"rent-or-buy\" scenarios where a one-time investment decreases (but does not eliminate) the per-time cost.\n  Despite this being a simple extension of the classical problem, we find that adding tail risk bounds creates a fundamentally different solution structure. For example, in our setting there is a possibility that we never buy in an optimal solution (which can also occur without tail bounds), but more strangely (and unlike the case without tail bounds or the classical case with tail bounds) we also show that the optimal solution might need to have nontrivial probabilities of buying even at finite points beyond the time corresponding to the buying cost. Moreover, in many regimes there does not exist a unique optimal solution. As our first contribution, we develop a series of structure theorems to characterize some features of optimal solutions.\n  The complex structure of optimal solutions makes it more difficult to develop an algorithm to compute such a solution. As our second contribution, we utilize our structure theorems to design two algorithms: one based on a greedy algorithm combined with binary search that is fast but yields arbitrarily close to optimal solutions, and a slower algorithm based on linear programming which computes exact optimal solutions.",
    "source": "arXiv"
  },
  {
    "title": "Perceiving Slope and Acceleration: Evidence for Variable Tempo Sampling in Pitch-Based Sonification of Functions",
    "title_es": "Perceiving Slope and Acceleration: Evidence for Variable Tempo Sampling in Pitch-Based Sonification of Functions",
    "url": "https://arxiv.org/abs/2508.06872",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06872v2 Announce Type: replace \nAbstract: Sonification offers a non-visual way to understand data, with pitch-based encodings being the most common. Yet, how well people perceive slope and acceleration-key features of data trends-remains poorly understood. Drawing on people's natural abilities to perceive tempo, we introduce a novel sampling method for pitch-based sonification to enhance the perception of slope and acceleration in univariate functions. While traditional sonification methods often sample data at uniform x-spacing, yielding notes played at a fixed tempo with variable pitch intervals (Variable Pitch Interval), our approach samples at uniform y-spacing, producing notes with consistent pitch intervals but variable tempo (Variable Tempo). We conducted psychoacoustic experiments to understand slope and acceleration perception across three sampling methods: Variable Pitch Interval, Variable Tempo, and a Continuous (no sampling) baseline. In slope comparison tasks, Variable Tempo was more accurate than the other methods when modulated by the magnitude ratio between slopes. For acceleration perception, just-noticeable differences under Variable Tempo were over 13 times finer than with other methods. Participants also commonly reported higher confidence, lower mental effort, and a stronger preference for Variable Tempo compared to other methods. This work contributes models of slope and acceleration perception across pitch-based sonification techniques, introduces Variable Tempo as a novel and preferred sampling method, and provides promising initial evidence that leveraging timing can lead to more sensitive, accurate, and precise interpretation of derivative-based data features.",
    "source": "arXiv"
  },
  {
    "title": "A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation",
    "title_es": "A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation",
    "url": "https://arxiv.org/abs/2508.06904",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06904v2 Announce Type: replace \nAbstract: Camouflaged Object Segmentation (COS) remains highly challenging due to the intrinsic visual similarity between target objects and their surroundings. While training-based COS methods achieve good performance, their performance degrades rapidly with increased annotation sparsity. To circumvent this limitation, recent studies have explored training-free COS methods, leveraging the Segment Anything Model (SAM) by automatically generating visual prompts from a single task-generic prompt (\\textit{e.g.}, \"\\textit{camouflaged animal}\") uniformly applied across all test images. However, these methods typically produce only semantic-level visual prompts, causing SAM to output coarse semantic masks and thus failing to handle scenarios with multiple discrete camouflaged instances effectively. To address this critical limitation, we propose a simple yet powerful \\textbf{I}nstance-\\textbf{A}ware \\textbf{P}rompting \\textbf{F}ramework (IAPF), the first training-free COS pipeline that explicitly converts a task-generic prompt into fine-grained instance masks. Specifically, the IAPF comprises three steps: (1) Text Prompt Generator, utilizing task-generic queries to prompt a Multimodal Large Language Model (MLLM) for generating image-specific foreground and background tags; (2) \\textbf{Instance Mask Generator}, leveraging Grounding DINO to produce precise instance-level bounding box prompts, alongside the proposed Single-Foreground Multi-Background Prompting strategy to sample region-constrained point prompts within each box, enabling SAM to yield a candidate instance mask; (3) Self-consistency Instance Mask Voting, which selects the final COS prediction by identifying the candidate mask most consistent across multiple candidate instance masks. Extensive evaluations on standard COS benchmarks demonstrate that the proposed IAPF significantly surpasses existing state-of-the-art training-free COS methods.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models Do Not Simulate Human Psychology",
    "title_es": "Large Language Models Do Not Simulate Human Psychology",
    "url": "https://arxiv.org/abs/2508.06950",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06950v3 Announce Type: replace \nAbstract: Large Language Models (LLMs),such as ChatGPT, are increasingly used in research, ranging from simple writing assistance to complex data annotation tasks. Recently, some research has suggested that LLMs may even be able to simulate human psychology and can, hence, replace human participants in psychological studies. We caution against this approach. We provide conceptual arguments against the hypothesis that LLMs simulate human psychology. We then present empiric evidence illustrating our arguments by demonstrating that slight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs' and human responses, even for the recent CENTAUR model that was specifically fine-tuned on psychological responses. Additionally, different LLMs show very different responses to novel items, further illustrating their lack of reliability. We conclude that LLMs do not simulate human psychology and recommend that psychological researchers should treat LLMs as useful but fundamentally unreliable tools that need to be validated against human responses for every new application.",
    "source": "arXiv"
  },
  {
    "title": "Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens",
    "title_es": "Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens",
    "url": "https://arxiv.org/abs/2508.07143",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07143v2 Announce Type: replace \nAbstract: Automatic Speech Recognition (ASR) systems now mediate countless human-technology interactions, yet research on their fairness implications remains surprisingly limited. This paper examines ASR bias through a philosophical lens, arguing that systematic misrecognition of certain speech varieties constitutes more than a technical limitation -- it represents a form of disrespect that compounds historical injustices against marginalized linguistic communities. We distinguish between morally neutral classification (discriminate1) and harmful discrimination (discriminate2), demonstrating how ASR systems can inadvertently transform the former into the latter when they consistently misrecognize non-standard dialects. We identify three unique ethical dimensions of speech technologies that differentiate ASR bias from other algorithmic fairness concerns: the temporal burden placed on speakers of non-standard varieties (\"temporal taxation\"), the disruption of conversational flow when systems misrecognize speech, and the fundamental connection between speech patterns and personal/cultural identity. These factors create asymmetric power relationships that existing technical fairness metrics fail to capture. The paper analyzes the tension between linguistic standardization and pluralism in ASR development, arguing that current approaches often embed and reinforce problematic language ideologies. We conclude that addressing ASR bias requires more than technical interventions; it demands recognition of diverse speech varieties as legitimate forms of expression worthy of technological accommodation. This philosophical reframing offers new pathways for developing ASR systems that respect linguistic diversity and speaker autonomy.",
    "source": "arXiv"
  },
  {
    "title": "Inversion of Arctic dual-channel sound speed profile based on random airgun signal",
    "title_es": "Inversion of Arctic dual-channel sound speed profile based on random airgun signal",
    "url": "https://arxiv.org/abs/2508.07152",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07152v2 Announce Type: replace \nAbstract: For the unique dual-channel sound speed profiles of the Canadian Basin and the Chukchi Plateau in the Arctic, based on the propagation characteristics of refracted normal modes under dual-channel sound speed profiles, an inversion method using refracted normal modes for dual-channel sound speed profiles is proposed. This method proposes a dual-parameter representation method for dual-channel sound speed profiles, tailored to the characteristics of dual-channel sound speed profiles. A dispersion structure extraction method is proposed for the dispersion structure characteristics of refracted normal modes under dual-channel sound speed profiles. Combining the parameter representation method of sound speed profiles and the dispersion structure extraction method, an inversion method for dual-channel sound speed profiles is proposed. For the common horizontal variation of sound speed profiles in long-distance acoustic propagation, a method for inverting horizontally varying dual-channel sound speed profiles is proposed. Finally, this article verifies the effectiveness of the dual-channel sound speed profile inversion method using the Arctic low-frequency long-range acoustic propagation experiment. Compared with previous sound speed profile inversion methods, the method proposed in this article has the advantages of fewer inversion parameters and faster inversion speed. It can be implemented using only a single hydrophone passively receiving random air gun signals, and it also solves the inversion problem of horizontal variation of sound speed profiles. It has significant advantages such as low cost, easy deployment, and fast computation speed.",
    "source": "arXiv"
  },
  {
    "title": "Acoustic source depth estimation method based on a single hydrophone in Arctic underwater",
    "title_es": "Acoustic source depth estimation method based on a single hydrophone in Arctic underwater",
    "url": "https://arxiv.org/abs/2508.07157",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07157v2 Announce Type: replace \nAbstract: Based on the normal mode and ray theory, this article discusses the characteristics of surface sound source and reception at the surface layer, and explores depth estimation methods based on normal modes and rays, and proposes a depth estimation method based on the upper limit of modal frequency. Data verification is conducted to discuss the applicability and limitations of different methods. For the surface refracted normal mode waveguide, modes can be separated through warping transformation. Based on the characteristics of normal mode amplitude variation with frequency and number, the sound source depth can be estimated by matching amplitude information. Based on the spatial variation characteristics of eigenfunctions with frequency, a sound source depth estimation method matching the cutoff frequency of normal modes is proposed. For the deep Arctic sea, the sound ray arrival structure at the receiving end is obtained through the analysis of deep inversion sound ray trajectories, and the sound source depth can be estimated by matching the time difference of ray arrivals. Experimental data is used to verify the sound field patterns and the effectiveness of the sound source depth estimation method.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach",
    "title_es": "Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach",
    "url": "https://arxiv.org/abs/2508.07353",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07353v2 Announce Type: replace \nAbstract: Numerous benchmarks have been built to evaluate the domain-specific abilities of large language models (LLMs), highlighting the need for effective and efficient benchmark construction. Existing domain-specific benchmarks primarily focus on the scaling law, relying on massive corpora for supervised fine-tuning or generating extensive question sets for broad coverage. However, the impact of corpus and question-answer (QA) set design on the precision and recall of domain-specific LLMs remains unexplored. In this paper, we address this gap and demonstrate that the scaling law is not always the optimal principle for benchmark construction in specific domains. Instead, we propose Comp-Comp, an iterative benchmarking framework based on a comprehensiveness-compactness principle. Here, comprehensiveness ensures semantic recall of the domain, while compactness enhances precision, guiding both corpus and QA set construction. To validate our framework, we conducted a case study in a well-renowned university, resulting in the creation of XUBench, a large-scale and comprehensive closed-domain benchmark. Although we use the academic domain as the case in this work, our Comp-Comp framework is designed to be extensible beyond academia, providing valuable insights for benchmark construction across various domains.",
    "source": "arXiv"
  },
  {
    "title": "On the Efficiency of Dynamic Transaction Scheduling in Blockchain Sharding",
    "title_es": "On the Efficiency of Dynamic Transaction Scheduling in Blockchain Sharding",
    "url": "https://arxiv.org/abs/2508.07472",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07472v2 Announce Type: replace \nAbstract: Sharding is a technique to speed up transaction processing in blockchains, where the $n$ processing nodes in the blockchain are divided into $s$ disjoint groups (shards) that can process transactions in parallel. We study dynamic scheduling problems on a shard graph $G_s$ where transactions arrive online over time and are not known in advance. Each transaction may access at most $k$ shards, and we denote by $d$ the worst distance between a transaction and its accessing (destination) shards (the parameter $d$ is unknown to the shards). To handle different values of $d$, we assume a locality sensitive decomposition of $G_s$ into clusters of shards, where every cluster has a leader shard that schedules transactions for the cluster. We first examine the simpler case of the stateless model, where leaders are not aware of the current state of the transaction accounts, and we prove a $O(d \\log^2 s \\cdot \\min\\{k, \\sqrt{s}\\})$ competitive ratio for latency. We then consider the stateful model, where leader shards gather the current state of accounts, and we prove a $O(\\log s\\cdot \\min\\{k, \\sqrt{s}\\}+\\log^2 s)$ competitive ratio for latency. Each leader calculates the schedule in polynomial time for each transaction that it processes. We show that for any $\\epsilon > 0$, approximating the optimal schedule within a $(\\min\\{k, \\sqrt{s}\\})^{1 -\\epsilon}$ factor is NP-hard. Hence, our bound for the stateful model is within a poly-log factor from the best possibly achievable. To the best of our knowledge, this is the first work to establish provably efficient dynamic scheduling algorithms for blockchain sharding systems.",
    "source": "arXiv"
  },
  {
    "title": "Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction",
    "title_es": "Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction",
    "url": "https://arxiv.org/abs/2508.07701",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07701v2 Announce Type: replace \nAbstract: 3D Gaussian Splatting (3DGS) achieves remarkable results in the field of surface reconstruction. However, when Gaussian normal vectors are aligned within the single-view projection plane, while the geometry appears reasonable in the current view, biases may emerge upon switching to nearby views. To address the distance and global matching challenges in multi-view scenes, we design multi-view normal and distance-guided Gaussian splatting. This method achieves geometric depth unification and high-accuracy reconstruction by constraining nearby depth maps and aligning 3D normals. Specifically, for the reconstruction of small indoor and outdoor scenes, we propose a multi-view distance reprojection regularization module that achieves multi-view Gaussian alignment by computing the distance loss between two nearby views and the same Gaussian surface. Additionally, we develop a multi-view normal enhancement module, which ensures consistency across views by matching the normals of pixel points in nearby views and calculating the loss. Extensive experimental results demonstrate that our method outperforms the baseline in both quantitative and qualitative evaluations, significantly enhancing the surface reconstruction capability of 3DGS. Our code will be made publicly available at (https://github.com/Bistu3DV/MND-GS/).",
    "source": "arXiv"
  },
  {
    "title": "AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation",
    "title_es": "AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation",
    "url": "https://arxiv.org/abs/2508.07770",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07770v2 Announce Type: replace \nAbstract: We introduce AgentWorld, an interactive simulation platform for developing household mobile manipulation capabilities. Our platform combines automated scene construction that encompasses layout generation, semantic asset placement, visual material configuration, and physics simulation, with a dual-mode teleoperation system supporting both wheeled bases and humanoid locomotion policies for data collection. The resulting AgentWorld Dataset captures diverse tasks ranging from primitive actions (pick-and-place, push-pull, etc.) to multistage activities (serve drinks, heat up food, etc.) across living rooms, bedrooms, and kitchens. Through extensive benchmarking of imitation learning methods including behavior cloning, action chunking transformers, diffusion policies, and vision-language-action models, we demonstrate the dataset's effectiveness for sim-to-real transfer. The integrated system provides a comprehensive solution for scalable robotic skill acquisition in complex home environments, bridging the gap between simulation-based training and real-world deployment. The code, datasets will be available at https://yizhengzhang1.github.io/agent_world/",
    "source": "arXiv"
  },
  {
    "title": "MolmoAct: Action Reasoning Models that can Reason in Space",
    "title_es": "MolmoAct: Action Reasoning Models that can Reason in Space",
    "url": "https://arxiv.org/abs/2508.07917",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07917v2 Announce Type: replace \nAbstract: Reasoning is central to purposeful action, yet most robotic foundation models map perception and instructions directly to control, which limits adaptability, generalization, and semantic grounding. We introduce Action Reasoning Models (ARMs), a class of robotic foundation models that integrate perception, planning, and control through a structured three-stage pipeline. Our model, MolmoAct, encodes observations and instructions into depth-aware perception tokens, generates mid-level spatial plans as editable trajectory traces, and predicts precise low-level actions, enabling explainable and steerable behavior. MolmoAct-7B-D achieves strong performance across simulation and real-world settings: 70.5% zero-shot accuracy on SimplerEnv Visual Matching tasks, surpassing closed-source Pi-0 and GR00T N1; 86.6% average success on LIBERO, including an additional 6.3% gain over ThinkAct on long-horizon tasks; and in real-world fine-tuning, an additional 10% (single-arm) and an additional 22.7% (bimanual) task progression over Pi-0-FAST. It also outperforms baselines by an additional 23.3% on out-of-distribution generalization and achieves top human-preference scores for open-ended instruction following and trajectory steering. Furthermore, we release, for the first time, the MolmoAct Dataset -- a mid-training robot dataset comprising over 10,000 high quality robot trajectories across diverse scenarios and tasks. Training with this dataset yields an average 5.5% improvement in general performance over the base model. We release all model weights, training code, our collected dataset, and our action reasoning dataset, establishing MolmoAct as both a state-of-the-art robotics foundation model and an open blueprint for building ARMs that transform perception into purposeful action through structured reasoning. Blogpost: https://allenai.org/blog/molmoact",
    "source": "arXiv"
  },
  {
    "title": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL",
    "title_es": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL",
    "url": "https://arxiv.org/abs/2508.07976",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07976v2 Announce Type: replace \nAbstract: Recent advancements in LLM-based agents have demonstrated remarkable capabilities in handling complex, knowledge-intensive tasks by integrating external tools. Among diverse choices of tools, search tools play a pivotal role in accessing vast external knowledge. However, open-source agents still fall short of achieving expert-level Search Intelligence, the ability to resolve ambiguous queries, generate precise searches, analyze results, and conduct thorough exploration. Existing approaches fall short in scalability, efficiency, and data quality. For example, small turn limits in existing online RL methods, e.g. <=10, restrict complex strategy learning. This paper introduces ASearcher, an open-source project for large-scale RL training of search agents. Our key contributions include: (1) Scalable fully asynchronous RL training that enables long-horizon search while maintaining high training efficiency. (2) A prompt-based LLM agent that autonomously synthesizes high-quality and challenging QAs, creating a large-scale QA dataset. Through RL training, our prompt-based QwQ-32B agent achieves substantial improvements, with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns and output tokens exceeding 150k during training time. With a simple agent design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We open-source our models, training data, and codes in https://github.com/inclusionAI/ASearcher.",
    "source": "arXiv"
  },
  {
    "title": "C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction",
    "title_es": "C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction",
    "url": "https://arxiv.org/abs/2508.08071",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08071v2 Announce Type: replace \nAbstract: Workshop version accepted at KDD 2025 (AI4SupplyChain). Connecting an ever-expanding catalogue of products with suitable manufacturers and suppliers is critical for resilient, efficient global supply chains, yet traditional methods struggle to capture complex capabilities, certifications, geographic constraints, and rich multimodal data of real-world manufacturer profiles. To address these gaps, we introduce PMGraph, a public benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking 8,888 manufacturers, over 70k products, more than 110k manufacturer-product edges, and over 29k product images. Building on this benchmark, we propose the Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first aligns and aggregates textual and visual attributes into intermediate group embeddings, then propagates them through a manufacturer-product hetero-graph via multiscale message passing to enhance link prediction accuracy. C-MAG also provides practical guidelines for modality-aware fusion, preserving predictive performance in noisy, real-world settings.",
    "source": "arXiv"
  },
  {
    "title": "Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration",
    "title_es": "Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration",
    "url": "https://arxiv.org/abs/2508.08128",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08128v2 Announce Type: replace \nAbstract: Ontologies play a central role in structuring knowledge across domains, supporting tasks such as reasoning, data integration, and semantic search. However, their large size and complexity, particularly in fields such as biomedicine, computational biology, law, and engineering, make them difficult for non-experts to navigate. Formal query languages such as SPARQL offer expressive access but require users to understand the ontology's structure and syntax. In contrast, visual exploration tools and basic keyword-based search interfaces are easier to use but often lack flexibility and expressiveness. We introduce FuzzyVis, a proof-of-concept system that enables intuitive and expressive exploration of complex ontologies. FuzzyVis integrates two key components: a fuzzy logic-based querying model built on fuzzy ontology embeddings, and an interactive visual interface for building and interpreting queries. Users can construct new composite concepts by selecting and combining existing ontology concepts using logical operators such as conjunction, disjunction, and negation. These composite concepts are matched against the ontology using fuzzy membership-based embeddings, which capture degrees of membership and support approximate, concept-level similarity search. The visual interface supports browsing, query composition, and partial search without requiring formal syntax. By combining fuzzy semantics with embedding-based reasoning, FuzzyVis enables flexible interpretation, efficient computation, and exploratory learning. Case studies demonstrate how FuzzyVis supports subtle information needs and helps users uncover relevant concepts in large, complex ontologies.",
    "source": "arXiv"
  },
  {
    "title": "CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data",
    "title_es": "CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data",
    "url": "https://arxiv.org/abs/2508.08173",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08173v2 Announce Type: replace \nAbstract: Large-scale scientific simulations require significant resources to generate high-resolution time-varying data (TVD). While super-resolution is an efficient post-processing strategy to reduce costs, existing methods rely on a large amount of HR training data, limiting their applicability to diverse simulation scenarios. To address this constraint, we proposed CD-TVD, a novel framework that combines contrastive learning and an improved diffusion-based super-resolution model to achieve accurate 3D super-resolution from limited time-step high-resolution data. During pre-training on historical simulation data, the contrastive encoder and diffusion superresolution modules learn degradation patterns and detailed features of high-resolution and low-resolution samples. In the training phase, the improved diffusion model with a local attention mechanism is fine-tuned using only one newly generated high-resolution timestep, leveraging the degradation knowledge learned by the encoder. This design minimizes the reliance on large-scale high-resolution datasets while maintaining the capability to recover fine-grained details. Experimental results on fluid and atmospheric simulation datasets confirm that CD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a significant advancement in data augmentation for large-scale scientific simulations. The code is available at https://github.com/Xin-Gao-private/CD-TVD.",
    "source": "arXiv"
  },
  {
    "title": "Capabilities of GPT-5 on Multimodal Medical Reasoning",
    "title_es": "Capabilities of GPT-5 on Multimodal Medical Reasoning",
    "url": "https://arxiv.org/abs/2508.08224",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08224v2 Announce Type: replace \nAbstract: Recent advances in large language models (LLMs) have enabled general-purpose systems to perform increasingly complex domain-specific reasoning without extensive fine-tuning. In the medical domain, decision-making often requires integrating heterogeneous information sources, including patient narratives, structured data, and medical images. This study positions GPT-5 as a generalist multimodal reasoner for medical decision support and systematically evaluates its zero-shot chain-of-thought reasoning performance on both text-based question answering and visual question answering tasks under a unified protocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20 against standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU medical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that GPT-5 consistently outperforms all baselines, achieving state-of-the-art accuracy across all QA benchmarks and delivering substantial gains in multimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and understanding scores by +29.26% and +26.18% over GPT-4o, respectively, and surpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in understanding. In contrast, GPT-4o remains below human expert performance in most dimensions. A representative case study demonstrates GPT-5's ability to integrate visual and textual cues into a coherent diagnostic reasoning chain, recommending appropriate high-stakes interventions. Our results show that, on these controlled multimodal reasoning benchmarks, GPT-5 moves from human-comparable to above human-expert performance. This improvement may substantially inform the design of future clinical decision-support systems.",
    "source": "arXiv"
  },
  {
    "title": "VGGSounder: Audio-Visual Evaluations for Foundation Models",
    "title_es": "VGGSounder: Audio-Visual Evaluations for Foundation Models",
    "url": "https://arxiv.org/abs/2508.08237",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08237v2 Announce Type: replace \nAbstract: The emergence of audio-visual foundation models underscores the importance of reliably assessing their multi-modal understanding. The VGGSound dataset is commonly used as a benchmark for evaluation audio-visual classification. However, our analysis identifies several limitations of VGGSound, including incomplete labelling, partially overlapping classes, and misaligned modalities. These lead to distorted evaluations of auditory and visual capabilities. To address these limitations, we introduce VGGSounder, a comprehensively re-annotated, multi-label test set that extends VGGSound and is specifically designed to evaluate audio-visual foundation models. VGGSounder features detailed modality annotations, enabling precise analyses of modality-specific performance. Furthermore, we reveal model limitations by analysing performance degradation when adding another input modality with our new modality confusion metric.",
    "source": "arXiv"
  },
  {
    "title": "BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion",
    "title_es": "BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion",
    "url": "https://arxiv.org/abs/2508.08241",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08241v3 Announce Type: replace \nAbstract: Learning skills from human motions offers a promising path toward generalizable policies for versatile humanoid whole-body control, yet two key cornerstones are missing: (1) a high-quality motion tracking framework that faithfully transforms large-scale kinematic references into robust and extremely dynamic motions on real hardware, and (2) a distillation approach that can effectively learn these motion primitives and compose them to solve downstream tasks. We address these gaps with BeyondMimic, a real-world framework to learn from human motions for versatile and naturalistic humanoid control via guided diffusion. Our framework provides a motion tracking pipeline capable of challenging skills such as jumping spins, sprinting, and cartwheels with state-of-the-art motion quality. Moving beyond simply mimicking existing motions, we further introduce a unified diffusion policy that enables zero-shot task-specific control at test time using simple cost functions. Deployed on hardware, BeyondMimic performs diverse tasks at test time, including waypoint navigation, joystick teleoperation, and obstacle avoidance, bridging sim-to-real motion tracking and flexible synthesis of human motion primitives for whole-body control. https://beyondmimic.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis",
    "title_es": "MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis",
    "url": "https://arxiv.org/abs/2508.08275",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08275v2 Announce Type: replace \nAbstract: Multimodal large language models (MLLMs) require continual instruction tuning during their post-training phase to adapt to the dynamic real-world demands. However, the absence of rigorous and systematic benchmarks has hindered progress in this area. To bridge this gap, we introduce \\textbf{MLLM-CTBench}, a dataset curating seven challenging tasks from six diverse domains with three contributions. First,to enable fine-grained analysis of continual learning ability, we introduce \\textbf{multidimensional evaluation metrics}, which combines final answer accuracy with Chain-of-Thought (CoT) reasoning quality assessment through a carefully trained MLLM evaluator. Then, we conduct a \\textbf{comprehensive evaluation of continual learning algorithms}, systematically assessing eight algorithms from four major categories to provide actionable insights for algorithm design and adoption. Finally ,we evaluate the efficacy of \\textbf{Reinforcement Fine-tuning (RFT) versus Supervised Fine-tuning (SFT)} in maintaining model performance across sequential tasks during continual instruction tuning. Our experiments demonstrate that reasoning processes in MLLMs exhibit greater resilience than final outputs to forgetting during continual learning, aligning with cognitive theories of hierarchical forgetting. We further show that both model capability and task sequence significantly influence continual learning outcomes, with stronger baseline models exhibiting greater resistance to forgetting. Notably, properly regularized RFT emerges as a more robust approach than SFT for maintaining performance across tasks.One of the key contributing factors is KL-divergence regularization, without which RFT leads to even worse forgetting than SFT on old tasks though may perform better on new tasks.",
    "source": "arXiv"
  },
  {
    "title": "Probabilistic Emissivity Retrieval from Hyperspectral Data via Physics-Guided Variational Inference",
    "title_es": "Probabilistic Emissivity Retrieval from Hyperspectral Data via Physics-Guided Variational Inference",
    "url": "https://arxiv.org/abs/2508.08291",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08291v2 Announce Type: replace \nAbstract: Recent research has proven neural networks to be a powerful tool for performing hyperspectral imaging (HSI) target identification. However, many deep learning frameworks deliver a single material class prediction and operate on a per-pixel basis; such approaches are limited in their interpretability and restricted to predicting materials that are accessible in available training libraries. In this work, we present an inverse modeling approach in the form of a physics-conditioned generative model.A probabilistic latent-variable model learns the underlying distribution of HSI radiance measurements and produces the conditional distribution of the emissivity spectrum. Moreover, estimates of the HSI scene's atmosphere and background are used as a physically relevant conditioning mechanism to contextualize a given radiance measurement during the encoding and decoding processes. Furthermore, we employ an in-the-loop augmentation scheme and physics-based loss criteria to avoid bias towards a predefined training material set and to encourage the model to learn physically consistent inverse mappings. Monte-Carlo sampling of the model's conditioned posterior delivers a sought emissivity distribution and allows for interpretable uncertainty quantification. Moreover, a distribution-based material matching scheme is presented to return a set of likely material matches for an inferred emissivity distribution. Hence, we present a strategy to incorporate contextual information about a given HSI scene, capture the possible variation of underlying material spectra, and provide interpretable probability measures of a candidate material accounting for given remotely-sensed radiance measurement.",
    "source": "arXiv"
  },
  {
    "title": "Decoupling Geometry from Optimization in 2D Irregular Cutting and Packing Problems: an Open-Source Collision Detection Engine",
    "title_es": "Decoupling Geometry from Optimization in 2D Irregular Cutting and Packing Problems: an Open-Source Collision Detection Engine",
    "url": "https://arxiv.org/abs/2508.08341",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08341v2 Announce Type: replace \nAbstract: Addressing irregular cutting and packing (C&P) optimization problems poses two distinct challenges: the geometric challenge of determining whether or not an item can be placed feasibly at a certain position, and the optimization challenge of finding a good solution according to some objective function. Until now, those tackling such problems have had to address both challenges simultaneously, requiring two distinct sets of expertise and a lot of research & development effort. One way to lower this barrier is to decouple the two challenges. In this paper we introduce a powerful collision detection engine (CDE) for 2D irregular C&P problems which assumes full responsibility for the geometric challenge. The CDE (i) allows users to focus with full confidence on their optimization challenge by abstracting geometry away and (ii) enables independent advances to propagate to all optimization algorithms built atop it. We present a set of core principles and design philosophies to model a general and adaptable CDE focused on maximizing performance, accuracy and robustness. These principles are accompanied by a concrete open-source implementation called $\\texttt{jagua-rs}$. This paper together with its implementation serves as a catalyst for future advances in irregular C&P problems by providing a solid foundation which can either be used as it currently exists or be further improved upon.",
    "source": "arXiv"
  },
  {
    "title": "Regret minimization in Linear Bandits with offline data via extended D-optimal exploration",
    "title_es": "Regret minimization in Linear Bandits with offline data via extended D-optimal exploration",
    "url": "https://arxiv.org/abs/2508.08420",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08420v2 Announce Type: replace \nAbstract: We consider the problem of online regret minimization in linear bandits with access to prior observations (offline data) from the underlying bandit model. There are numerous applications where extensive offline data is often available, such as in recommendation systems, online advertising. Consequently, this problem has been studied intensively in recent literature. Our algorithm, Offline-Online Phased Elimination (OOPE), effectively incorporates the offline data to substantially reduce the online regret compared to prior work. To leverage offline information prudently, OOPE uses an extended D-optimal design within each exploration phase. OOPE achieves an online regret is $\\tilde{O}(\\sqrt{\\deff T \\log \\left(|\\mathcal{A}|T\\right)}+d^2)$. $\\deff \\leq d)$ is the effective problem dimension which measures the number of poorly explored directions in offline data and depends on the eigen-spectrum $(\\lambda_k)_{k \\in [d]}$ of the Gram matrix of the offline data. The eigen-spectrum $(\\lambda_k)_{k \\in [d]}$ is a quantitative measure of the \\emph{quality} of offline data. If the offline data is poorly explored ($\\deff \\approx d$), we recover the established regret bounds for purely online setting while, when offline data is abundant ($\\Toff >> T$) and well-explored ($\\deff = o(1) $), the online regret reduces substantially. Additionally, we provide the first known minimax regret lower bounds in this setting that depend explicitly on the quality of the offline data. These lower bounds establish the optimality of our algorithm in regimes where offline data is either well-explored or poorly explored. Finally, by using a Frank-Wolfe approximation to the extended optimal design we further improve the $O(d^{2})$ term to $O\\left(\\frac{d^{2}}{\\deff} \\min \\{ \\deff,1\\} \\right)$, which can be substantial in high dimensions with moderate quality of offline data $\\deff = \\Omega(1)$.",
    "source": "arXiv"
  },
  {
    "title": "A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems",
    "title_es": "A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems",
    "url": "https://arxiv.org/abs/2508.08473",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08473v2 Announce Type: replace \nAbstract: Collective behaviors such as swarming and flocking emerge from simple, decentralized interactions in biological systems. Existing models, such as Vicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber model imposes rigid formations, limiting their applicability in swarm robotics. To address these limitations, this paper proposes a minimal yet expressive model that governs agent dynamics using relative positions, velocities, and local density, modulated by two tunable parameters: the spatial offset and kinetic offset. The model achieves spatially flexible, collision-free behaviors that reflect naturalistic group dynamics. Furthermore, we extend the framework to cognitive autonomous systems, enabling energy-aware phase transitions between swarming and flocking through adaptive control parameter tuning. This cognitively inspired approach offers a robust foundation for real-world applications in multi-robot systems, particularly autonomous aerial swarms.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Target Backdoor Attacks Against Speaker Recognition",
    "title_es": "Multi-Target Backdoor Attacks Against Speaker Recognition",
    "url": "https://arxiv.org/abs/2508.08559",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08559v2 Announce Type: replace \nAbstract: In this work, we propose a multi-target backdoor attack against speaker identification using position-independent clicking sounds as triggers. Unlike previous single-target approaches, our method targets up to 50 speakers simultaneously, achieving success rates of up to 95.04%. To simulate more realistic attack conditions, we vary the signal-to-noise ratio between speech and trigger, demonstrating a trade-off between stealth and effectiveness. We further extend the attack to the speaker verification task by selecting the most similar training speaker - based on cosine similarity - as a proxy target. The attack is most effective when target and enrolled speaker pairs are highly similar, reaching success rates of up to 90% in such cases.",
    "source": "arXiv"
  },
  {
    "title": "Fact-Checking at Scale: Multimodal AI for Authenticity and Context Verification in Online Media",
    "title_es": "Fact-Checking at Scale: Multimodal AI for Authenticity and Context Verification in Online Media",
    "url": "https://arxiv.org/abs/2508.08592",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08592v2 Announce Type: replace \nAbstract: The proliferation of multimedia content on social media platforms has dramatically transformed how information is consumed and disseminated. While this shift enables real-time coverage of global events, it also facilitates the rapid spread of misinformation and disinformation, especially during crises such as wars, natural disasters, or elections. The rise of synthetic media and the reuse of authentic content in misleading contexts have intensified the need for robust multimedia verification tools. In this paper, we present a comprehensive system developed for the ACM Multimedia 2025 Grand Challenge on Multimedia Verification. Our system assesses the authenticity and contextual accuracy of multimedia content in multilingual settings and generates both expert-oriented verification reports and accessible summaries for the general public. We introduce a unified verification pipeline that integrates visual forensics, textual analysis, and multimodal reasoning, and propose a hybrid approach to detect out-of-context (OOC) media through semantic similarity, temporal alignment, and geolocation cues. Extensive evaluations on the Grand Challenge benchmark demonstrate the system's effectiveness across diverse real-world scenarios. Our contributions advance the state of the art in multimedia verification and offer practical tools for journalists, fact-checkers, and researchers confronting information integrity challenges in the digital age.",
    "source": "arXiv"
  },
  {
    "title": "Yan: Foundational Interactive Video Generation",
    "title_es": "Yan: Foundational Interactive Video Generation",
    "url": "https://arxiv.org/abs/2508.08601",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08601v2 Announce Type: replace \nAbstract: We present Yan, a foundational framework for interactive video generation, covering the entire pipeline from simulation and generation to editing. Specifically, Yan comprises three core modules. AAA-level Simulation: We design a highly-compressed, low-latency 3D-VAE coupled with a KV-cache-based shift-window denoising inference process, achieving real-time 1080P/60FPS interactive simulation. Multi-Modal Generation: We introduce a hierarchical autoregressive caption method that injects game-specific knowledge into open-domain multi-modal video diffusion models (VDMs), then transforming the VDM into a frame-wise, action-controllable, real-time infinite interactive video generator. Notably, when the textual and visual prompts are sourced from different domains, the model demonstrates strong generalization, allowing it to blend and compose the style and mechanics across domains flexibly according to user prompts. Multi-Granularity Editing: We propose a hybrid model that explicitly disentangles interactive mechanics simulation from visual rendering, enabling multi-granularity video content editing during interaction through text. Collectively, Yan offers an integration of these modules, pushing interactive video generation beyond isolated capabilities toward a comprehensive AI-driven interactive creation paradigm, paving the way for the next generation of creative tools, media, and entertainment. The project page is: https://greatx3.github.io/Yan/.",
    "source": "arXiv"
  },
  {
    "title": "Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization",
    "title_es": "Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization",
    "url": "https://arxiv.org/abs/2508.08604",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08604v2 Announce Type: replace \nAbstract: Vision-Language Models (VLMs) have been widely used in various visual recognition tasks due to their remarkable generalization capabilities. As these models grow in size and complexity, fine-tuning becomes costly, emphasizing the need to reuse adaptation knowledge from 'weaker' models to efficiently enhance 'stronger' ones. However, existing adaptation transfer methods exhibit limited transferability across models due to their model-specific design and high computational demands. To tackle this, we propose Transferable Model-agnostic adapter (TransMiter), a light-weight adapter that improves vision-language models 'without backpropagation'. TransMiter captures the knowledge gap between pre-trained and fine-tuned VLMs, in an 'unsupervised' manner. Once trained, this knowledge can be seamlessly transferred across different models without the need for backpropagation. Moreover, TransMiter consists of only a few layers, inducing a negligible additional inference cost. Notably, supplementing the process with a few labeled data further yields additional performance gain, often surpassing a fine-tuned stronger model, with a marginal training cost. Experimental results and analyses demonstrate that TransMiter effectively and efficiently transfers adaptation knowledge while preserving generalization abilities across VLMs of different sizes and architectures in visual recognition tasks.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Rank Adjustment for Accurate and Efficient Neural Network Training",
    "title_es": "Dynamic Rank Adjustment for Accurate and Efficient Neural Network Training",
    "url": "https://arxiv.org/abs/2508.08625",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08625v2 Announce Type: replace \nAbstract: Low-rank training methods reduce the number of trainable parameters by re-parameterizing the weights with matrix decompositions (e.g., singular value decomposition). However, enforcing a fixed low-rank structure caps the rank of the weight matrices and can hinder the model's ability to learn complex patterns. Furthermore, the effective rank of the model's weights tends to decline during training, and this drop is accelerated when the model is reparameterized into a low-rank structure. In this study, we argue that strategically interleaving full-rank training epochs within low-rank training epochs can effectively restore the rank of the model's weights. Based on our findings, we propose a general dynamic-rank training framework that is readily applicable to a wide range of neural-network tasks. We first describe how to adjust the rank of weight matrix to alleviate the inevitable rank collapse that arises during training, and then present extensive empirical results that validate our claims and demonstrate the efficacy of the proposed framework. Our empirical study shows that the proposed method achieves almost the same computational cost as SVD-based low-rank training while achieving a comparable accuracy to full-rank training across various benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Aryabhata: An exam-focused language model for JEE Math",
    "title_es": "Aryabhata: An exam-focused language model for JEE Math",
    "url": "https://arxiv.org/abs/2508.08665",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08665v2 Announce Type: replace \nAbstract: We present Aryabhata 1.0, a compact 7B parameter math reasoning model optimized for the Indian academic exam, the Joint Entrance Examination (JEE). Despite rapid progress in large language models (LLMs), current models often remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong open-weight reasoning models, followed by supervised fine-tuning (SFT) with curriculum learning on verified chain-of-thought (CoT) traces curated through best-of-$n$ rejection sampling. To further boost performance, we apply reinforcement learning with verifiable rewards (RLVR) using A2C objective with group-relative advantage estimation along with novel exploration strategies such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K) benchmarks, Aryabhata outperforms existing models in accuracy and efficiency, while offering pedagogically useful step-by-step reasoning. We release Aryabhata as a foundation model to advance exam-centric, open-source small language models. This marks our first open release for community feedback (https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training future models to further improve learning outcomes for students.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models",
    "title_es": "A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models",
    "url": "https://arxiv.org/abs/2508.08712",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08712v2 Announce Type: replace \nAbstract: As text generation has become a core capability of modern Large Language Models (LLMs), it underpins a wide range of downstream applications. However, most existing LLMs rely on autoregressive (AR) generation, producing one token at a time based on previously generated context-resulting in limited generation speed due to the inherently sequential nature of the process. To address this challenge, an increasing number of researchers have begun exploring parallel text generation-a broad class of techniques aimed at breaking the token-by-token generation bottleneck and improving inference efficiency. Despite growing interest, there remains a lack of comprehensive analysis on what specific techniques constitute parallel text generation and how they improve inference performance. To bridge this gap, we present a systematic survey of parallel text generation methods. We categorize existing approaches into AR-based and Non-AR-based paradigms, and provide a detailed examination of the core techniques within each category. Following this taxonomy, we assess their theoretical trade-offs in terms of speed, quality, and efficiency, and examine their potential for combination and comparison with alternative acceleration strategies. Finally, based on our findings, we highlight recent advancements, identify open challenges, and outline promising directions for future research in parallel text generation. We have also created a GitHub repository for indexing relevant papers and open resources available at https://github.com/zhanglingzhe0820/Awesome-Parallel-Text-Generation.",
    "source": "arXiv"
  },
  {
    "title": "Dead Zone of Accountability: Why Social Claims in Machine Learning Research Should Be Articulated and Defended",
    "title_es": "Dead Zone of Accountability: Why Social Claims in Machine Learning Research Should Be Articulated and Defended",
    "url": "https://arxiv.org/abs/2508.08739",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08739v2 Announce Type: replace \nAbstract: Many Machine Learning research studies use language that describes potential social benefits or technical affordances of new methods and technologies. Such language, which we call \"social claims\", can help garner substantial resources and influence for those involved in ML research and technology production. However, there exists a gap between social claims and reality (the claim-reality gap): ML methods often fail to deliver the claimed functionality or social impacts. This paper investigates the claim-reality gap and makes a normative argument for developing accountability mechanisms for it. In making the argument, we make three contributions. First, we show why the symptom - absence of social claim accountability - is problematic. Second, we coin dead zone of accountability - a lens that scholars and practitioners can use to identify opportunities for new forms of accountability. We apply this lens to the claim-reality gap and provide a diagnosis by identifying cognitive and structural resistances to accountability in the claim-reality gap. Finally, we offer a prescription - two potential collaborative research agendas that can help create the condition for social claim accountability.",
    "source": "arXiv"
  },
  {
    "title": "Scalable Graph Indexing using GPUs for Approximate Nearest Neighbor Search",
    "title_es": "Scalable Graph Indexing using GPUs for Approximate Nearest Neighbor Search",
    "url": "https://arxiv.org/abs/2508.08744",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08744v2 Announce Type: replace \nAbstract: Approximate nearest neighbor search (ANNS) in high-dimensional vector spaces has a wide range of real-world applications. Numerous methods have been proposed to handle ANNS efficiently, while graph-based indexes have gained prominence due to their high accuracy and efficiency. However, the indexing overhead of graph-based indexes remains substantial. With exponential growth in data volume and increasing demands for dynamic index adjustments, this overhead continues to escalate, posing a critical challenge. In this paper, we introduce Tagore, a fast library accelerated by GPUs for graph indexing, which has powerful capabilities of constructing refinement-based graph indexes such as NSG and Vamana. We first introduce GNN-Descent, a GPU-specific algorithm for efficient k-Nearest Neighbor (k-NN) graph initialization. GNN-Descent speeds up the similarity comparison by a two-phase descent procedure and enables highly parallelized neighbor updates. Next, aiming to support various k-NN graph pruning strategies, we formulate a universal computing procedure termed CFS and devise two generalized GPU kernels for parallel processing complex dependencies in neighbor relationships. For large-scale datasets exceeding GPU memory capacity, we propose an asynchronous GPU-CPU-disk indexing framework with a cluster-aware caching mechanism to minimize the I/O pressure on the disk. Extensive experiments on 7 real-world datasets exhibit that Tagore achieves 1.32x-112.79x speedup while maintaining the index quality.",
    "source": "arXiv"
  },
  {
    "title": "Approximate DBSCAN under Differential Privacy",
    "title_es": "Approximate DBSCAN under Differential Privacy",
    "url": "https://arxiv.org/abs/2508.08749",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08749v2 Announce Type: replace \nAbstract: This paper revisits the DBSCAN problem under differential privacy (DP). Existing DP-DBSCAN algorithms aim at publishing the cluster labels of the input points. However, we show that both empirically and theoretically, this approach cannot offer any utility in the published results. We therefore propose an alternative definition of DP-DBSCAN based on the notion of spans. We argue that publishing the spans actually better serves the purposes of visualization and classification of DBSCAN. Then we present a linear-time DP-DBSCAN algorithm achieving the sandwich quality guarantee in any constant dimensions, as well as matching lower bounds on the approximation ratio. A key building block in our algorithm is a linear-time algorithm for constructing a histogram under pure-DP, which is of independent interest. Finally, we conducted experiments on both synthetic and real-world datasets to verify the practical performance of our DP-DBSCAN algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Never Compromise to Vulnerabilities: A Comprehensive Survey on AI Governance",
    "title_es": "Never Compromise to Vulnerabilities: A Comprehensive Survey on AI Governance",
    "url": "https://arxiv.org/abs/2508.08789",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08789v2 Announce Type: replace \nAbstract: The rapid advancement of AI has expanded its capabilities across domains, yet introduced critical technical vulnerabilities, such as algorithmic bias and adversarial sensitivity, that pose significant societal risks, including misinformation, inequity, security breaches, physical harm, and eroded public trust. These challenges highlight the urgent need for robust AI governance. We propose a comprehensive framework integrating technical and societal dimensions, structured around three interconnected pillars: Intrinsic Security (system reliability), Derivative Security (real-world harm mitigation), and Social Ethics (value alignment and accountability). Uniquely, our approach unifies technical methods, emerging evaluation benchmarks, and policy insights to promote transparency, accountability, and trust in AI systems. Through a systematic review of over 300 studies, we identify three core challenges: (1) the generalization gap, where defenses fail against evolving threats; (2) inadequate evaluation protocols that overlook real-world risks; and (3) fragmented regulations leading to inconsistent oversight. These shortcomings stem from treating governance as an afterthought, rather than a foundational design principle, resulting in reactive, siloed efforts that fail to address the interdependence of technical integrity and societal trust. To overcome this, we present an integrated research agenda that bridges technical rigor with social responsibility. Our framework offers actionable guidance for researchers, engineers, and policymakers to develop AI systems that are not only robust and secure but also ethically aligned and publicly trustworthy. The accompanying repository is available at https://github.com/ZTianle/Awesome-AI-SG.",
    "source": "arXiv"
  },
  {
    "title": "TempOpt -- Unsupervised Alarm Relation Learning for Telecommunication Networks",
    "title_es": "TempOpt -- Unsupervised Alarm Relation Learning for Telecommunication Networks",
    "url": "https://arxiv.org/abs/2508.08814",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08814v2 Announce Type: replace \nAbstract: In a telecommunications network, fault alarms generated by network nodes are monitored in a Network Operations Centre (NOC) to ensure network availability and continuous network operations. The monitoring process comprises of tasks such as active alarms analysis, root alarm identification, and resolution of the underlying problem. Each network node potentially can generate alarms of different types, while nodes can be from multiple vendors, a network can have hundreds of nodes thus resulting in an enormous volume of alarms at any time. Since network nodes are inter-connected, a single fault in the network would trigger multiple sequences of alarms across a variety of nodes and from a monitoring point of view, it is a challenging task for a NOC engineer to be aware of relations between the various alarms, when trying to identify, for example, a root alarm on which an action needs to be taken. To effectively identify root alarms, it is essential to learn relation among the alarms for accurate and faster resolution. In this work we propose a novel unsupervised alarm relation learning technique Temporal Optimization (TempOpt) that is practical and overcomes the limitations of an existing class of alarm relational learning method-temporal dependency methods. Experiments have been carried on real-world network datasets, that demonstrate the improved quality of alarm relations learned by TempOpt as compared to temporal dependency method.",
    "source": "arXiv"
  },
  {
    "title": "Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors",
    "title_es": "Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors",
    "url": "https://arxiv.org/abs/2508.08896",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08896v2 Announce Type: replace \nAbstract: A dexterous hand capable of generalizable grasping objects is fundamental for the development of general-purpose embodied AI. However, previous methods focus narrowly on low-level grasp stability metrics, neglecting affordance-aware positioning and human-like poses which are crucial for downstream manipulation. To address these limitations, we propose AffordDex, a novel framework with two-stage training that learns a universal grasping policy with an inherent understanding of both motion priors and object affordances. In the first stage, a trajectory imitator is pre-trained on a large corpus of human hand motions to instill a strong prior for natural movement. In the second stage, a residual module is trained to adapt these general human-like motions to specific object instances. This refinement is critically guided by two components: our Negative Affordance-aware Segmentation (NAA) module, which identifies functionally inappropriate contact regions, and a privileged teacher-student distillation process that ensures the final vision-based policy is highly successful. Extensive experiments demonstrate that AffordDex not only achieves universal dexterous grasping but also remains remarkably human-like in posture and functionally appropriate in contact location. As a result, AffordDex significantly outperforms state-of-the-art baselines across seen objects, unseen instances, and even entirely novel categories.",
    "source": "arXiv"
  },
  {
    "title": "DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models",
    "title_es": "DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models",
    "url": "https://arxiv.org/abs/2508.08961",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08961v2 Announce Type: replace \nAbstract: Extending pre-trained Large Language Models (LLMs)'s speech understanding or generation abilities by introducing various effective speech tokens has attracted great attention in the speech community. However, building a unified speech understanding and generation model still faces the following challenges: (1) Due to the huge modality gap between speech tokens and text tokens, extending text LLMs to unified speech LLMs relies on large-scale paired data for fine-tuning, and (2) Generation and understanding tasks prefer information at different levels, e.g., generation benefits from detailed acoustic features, while understanding favors high-level semantics. This divergence leads to difficult performance optimization in one unified model. To solve these challenges, in this paper, we present two key insights in speech tokenization and speech language modeling. Specifically, we first propose an Understanding-driven Speech Tokenizer (USTokenizer), which extracts high-level semantic information essential for accomplishing understanding tasks using text LLMs. In this way, USToken enjoys better modality commonality with text, which reduces the difficulty of modality alignment in adapting text LLMs to speech LLMs. Secondly, we present DualSpeechLM, a dual-token modeling framework that concurrently models USToken as input and acoustic token as output within a unified, end-to-end framework, seamlessly integrating speech understanding and generation capabilities. Furthermore, we propose a novel semantic supervision loss and a Chain-of-Condition (CoC) strategy to stabilize model training and enhance speech generation performance. Experimental results demonstrate that our proposed approach effectively fosters a complementary relationship between understanding and generation tasks, highlighting the promising strategy of mutually enhancing both tasks in one unified model.",
    "source": "arXiv"
  },
  {
    "title": "When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges",
    "title_es": "When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges",
    "url": "https://arxiv.org/abs/2508.09022",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09022v2 Announce Type: replace \nAbstract: Existing deepfake detection methods heavily depend on labeled training data. However, as AI-generated content becomes increasingly realistic, even \\textbf{human annotators struggle to distinguish} between deepfakes and authentic images. This makes the labeling process both time-consuming and less reliable. Specifically, there is a growing demand for approaches that can effectively utilize large-scale unlabeled data from online social networks. Unlike typical unsupervised learning tasks, where categories are distinct, AI-generated faces closely mimic real image distributions and share strong similarities, causing performance drop in conventional strategies. In this paper, we introduce the Dual-Path Guidance Network (DPGNet), to tackle two key challenges: (1) bridging the domain gap between faces from different generation models, and (2) utilizing unlabeled image samples. The method features two core modules: text-guided cross-domain alignment, which uses learnable prompts to unify visual and textual embeddings into a domain-invariant feature space, and curriculum-driven pseudo label generation, which dynamically exploit more informative unlabeled samples. To prevent catastrophic forgetting, we also facilitate bridging between domains via cross-domain knowledge distillation. Extensive experiments on \\textbf{11 popular datasets}, show that DPGNet outperforms SoTA approaches by \\textbf{6.3\\%}, highlighting its effectiveness in leveraging unlabeled data to address the annotation challenges posed by the increasing realism of deepfakes.",
    "source": "arXiv"
  },
  {
    "title": "GeoVLA: Empowering 3D Representations in Vision-Language-Action Models",
    "title_es": "GeoVLA: Empowering 3D Representations in Vision-Language-Action Models",
    "url": "https://arxiv.org/abs/2508.09071",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09071v2 Announce Type: replace \nAbstract: Vision-Language-Action (VLA) models have emerged as a promising approach for enabling robots to follow language instructions and predict corresponding actions. However, current VLA models mainly rely on 2D visual inputs, neglecting the rich geometric information in the 3D physical world, which limits their spatial awareness and adaptability. In this paper, we present GeoVLA, a novel VLA framework that effectively integrates 3D information to advance robotic manipulation. It uses a vision-language model (VLM) to process images and language instructions,extracting fused vision-language embeddings. In parallel, it converts depth maps into point clouds and employs a customized point encoder, called Point Embedding Network, to generate 3D geometric embeddings independently. These produced embeddings are then concatenated and processed by our proposed spatial-aware action expert, called 3D-enhanced Action Expert, which combines information from different sensor modalities to produce precise action sequences. Through extensive experiments in both simulation and real-world environments, GeoVLA demonstrates superior performance and robustness. It achieves state-of-the-art results in the LIBERO and ManiSkill2 simulation benchmarks and shows remarkable robustness in real-world tasks requiring height adaptability, scale awareness and viewpoint invariance.",
    "source": "arXiv"
  },
  {
    "title": "SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system",
    "title_es": "SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system",
    "url": "https://arxiv.org/abs/2508.09090",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09090v2 Announce Type: replace \nAbstract: Modeling multi-interests has arisen as a core problem in real-world RS. Current multi-interest retrieval methods pose three major challenges: 1) Interests, typically extracted from predefined external knowledge, are invariant. Failed to dynamically evolve with users' real-time consumption preferences. 2) Online inference typically employs an over-exploited strategy, mainly matching users' existing interests, lacking proactive exploration and discovery of novel and long-tail interests. To address these challenges, we propose a novel retrieval framework named SPARC(Soft Probabilistic Adaptive Retrieval Model via Codebooks). Our contribution is two folds. First, the framework utilizes Residual Quantized Variational Autoencoder (RQ-VAE) to construct a discretized interest space. It achieves joint training of the RQ-VAE with the industrial large scale recommendation model, mining behavior-aware interests that can perceive user feedback and evolve dynamically. Secondly, a probabilistic interest module that predicts the probability distribution over the entire dynamic and discrete interest space. This facilitates an efficient \"soft-search\" strategy during online inference, revolutionizing the retrieval paradigm from \"passive matching\" to \"proactive exploration\" and thereby effectively promoting interest discovery. Online A/B tests on an industrial platform with tens of millions daily active users, have achieved substantial gains in business metrics: +0.9% increase in user view duration, +0.4% increase in user page views (PV), and a +22.7% improvement in PV500(new content reaching 500 PVs in 24 hours). Offline evaluations are conducted on open-source Amazon Product datasets. Metrics, such as Recall@K and Normalized Discounted Cumulative Gain@K(NDCG@K), also showed consistent improvement. Both online and offline experiments validate the efficacy and practical value of the proposed method.",
    "source": "arXiv"
  },
  {
    "title": "SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling",
    "title_es": "SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling",
    "url": "https://arxiv.org/abs/2508.09105",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09105v2 Announce Type: replace \nAbstract: Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented Generation (MRAG) significantly improve the knowledge coverage and contextual understanding of Large Language Models (LLMs) by introducing external knowledge sources. However, retrieval and multimodal fusion obscure content provenance, rendering existing membership inference methods unable to reliably attribute generated outputs to pre-training, external retrieval, or user input, thus undermining privacy leakage accountability\n  To address these challenges, we propose the first Source-aware Membership Audit (SMA) that enables fine-grained source attribution of generated content in a semi-black-box setting with retrieval control capabilities. To address the environmental constraints of semi-black-box auditing, we further design an attribution estimation mechanism based on zero-order optimization, which robustly approximates the true influence of input tokens on the output through large-scale perturbation sampling and ridge regression modeling. In addition, SMA introduces a cross-modal attribution technique that projects image inputs into textual descriptions via MLLMs, enabling token-level attribution in the text modality, which for the first time facilitates membership inference on image retrieval traces in MRAG systems. This work shifts the focus of membership inference from 'whether the data has been memorized' to 'where the content is sourced from', offering a novel perspective for auditing data provenance in complex generative systems.",
    "source": "arXiv"
  },
  {
    "title": "Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer",
    "title_es": "Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer",
    "url": "https://arxiv.org/abs/2508.09131",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.09131v2 Announce Type: replace \nAbstract: Text-guided color editing in images and videos is a fundamental yet unsolved problem, requiring fine-grained manipulation of color attributes, including albedo, light source color, and ambient lighting, while preserving physical consistency in geometry, material properties, and light-matter interactions. Existing training-free methods offer broad applicability across editing tasks but struggle with precise color control and often introduce visual inconsistency in both edited and non-edited regions. In this work, we present ColorCtrl, a training-free color editing method that leverages the attention mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By disentangling structure and color through targeted manipulation of attention maps and value tokens, our method enables accurate and consistent color editing, along with word-level control of attribute intensity. Our method modifies only the intended regions specified by the prompt, leaving unrelated areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate that ColorCtrl outperforms existing training-free approaches and achieves state-of-the-art performances in both edit quality and consistency. Furthermore, our method surpasses strong commercial models such as FLUX.1 Kontext Max and GPT-4o Image Generation in terms of consistency. When extended to video models like CogVideoX, our approach exhibits greater advantages, particularly in maintaining temporal coherence and editing stability. Finally, our method also generalizes to instruction-based editing diffusion models such as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.",
    "source": "arXiv"
  },
  {
    "title": "A Quantum Approach For Reducing Communications in Classical Secure Computations with Long Outputs",
    "title_es": "A Quantum Approach For Reducing Communications in Classical Secure Computations with Long Outputs",
    "url": "https://arxiv.org/abs/2310.05213",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2310.05213v3 Announce Type: replace-cross \nAbstract: How could quantum cryptography help us achieve what are not achievable in classical cryptography? In this work we study the classical cryptographic problem that two parties would like to perform secure computations with long outputs. As a basic primitive and example, we first consider the following problem which we call secure function sampling with long outputs: suppose $f:\\{0,1\\}^n\\rightarrow \\{0,1\\}^m$ is a public, efficient classical function, where $m$ is big; Alice would like to sample $x$ from its domain and sends $f(x)$ to Bob; what Bob knows should be no more than $f(x)$ even if it behaves maliciously. Classical cryptography, like FHE and succinct arguments [Gen09,Kil92,HW15], allows us to achieve this task within communication complexity $O(n+m)$; could we achieve this task with communication complexity independent of $m$?\n  In this work, we first design a quantum cryptographic protocol that achieves secure function sampling with approximate security, within $O(n)$ communication (omitting the dependency on the security parameter and error tolerance). We also prove the classical impossibility using techniques in [HW15], which means that our protocol indeed achieves a type of quantum advantage. Building on the secure function sampling protocol, we further construct protocols for general secure two-party computations [Yao86,GB01] with approximate security, with communication complexity only depending on the input length and the targeted security. In terms of the assumptions, we construct protocols for these problems assuming only the existence of collapsing hash functions [Unr16]; what's more, we also construct a classical-channel protocol for these problems additionally assuming the existence of noisy trapdoor claw-free functions [BCMVV,BKVV].",
    "source": "arXiv"
  },
  {
    "title": "A non-uniform view of Craig interpolation in modal logics with linear frames",
    "title_es": "A non-uniform view of Craig interpolation in modal logics with linear frames",
    "url": "https://arxiv.org/abs/2312.05929",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2312.05929v2 Announce Type: replace-cross \nAbstract: Normal modal logics extending the logic K4.3 of linear transitive frames are known to lack the Craig interpolation property, except some logics of bounded depth such as S5. We turn this `negative' fact into a research question and pursue a non-uniform approach to Craig interpolation by investigating the following interpolant existence problem: decide whether there exists a Craig interpolant between two given formulas in any fixed logic above K4.3. Using a bisimulation-based characterisation of interpolant existence for descriptive frames, we show that this problem is decidable and coNP-complete for all finitely axiomatisable normal modal logics containing K4.3. It is thus not harder than entailment in these logics, which is in sharp contrast to other recent non-uniform interpolation results. We also extend our approach to Priorean temporal logics (with both past and future modalities) over the standard time flows-the integers, rationals, reals, and finite strict linear orders-none of which is blessed with the Craig interpolation property.",
    "source": "arXiv"
  },
  {
    "title": "Semi-definite optimization of the measured relative entropies of quantum states and channels",
    "title_es": "Semi-definite optimization of the measured relative entropies of quantum states and channels",
    "url": "https://arxiv.org/abs/2406.19060",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2406.19060v2 Announce Type: replace-cross \nAbstract: The measured relative entropies of quantum states and channels find operational significance in quantum information theory as achievable error rates in hypothesis testing tasks. They are of interest in the near term, as they correspond to hybrid quantum-classical strategies with technological requirements far less challenging to implement than required by the most general strategies allowed by quantum mechanics. In this paper, we prove that these measured relative entropies can be calculated efficiently by means of semi-definite programming, by making use of variational formulas for the measured relative entropies of states and semi-definite representations of the weighted geometric mean and the operator connection of the logarithm. Not only do the semi-definite programs output the optimal values of the measured relative entropies of states and channels, but they also provide numerical characterizations of optimal strategies for achieving them, which is of significant practical interest for designing hypothesis testing protocols.",
    "source": "arXiv"
  },
  {
    "title": "Continuous-time q-Learning for Jump-Diffusion Models under Tsallis Entropy",
    "title_es": "Continuous-time q-Learning for Jump-Diffusion Models under Tsallis Entropy",
    "url": "https://arxiv.org/abs/2407.03888",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2407.03888v3 Announce Type: replace-cross \nAbstract: This paper studies the continuous-time reinforcement learning in jump-diffusion models by featuring the q-learning (the continuous-time counterpart of Q-learning) under Tsallis entropy regularization. Contrary to the Shannon entropy, the general form of Tsallis entropy renders the optimal policy not necessarily a Gibbs measure. Herein, the Lagrange multiplier and KKT condition are needed to ensure that the learned policy is a probability density function. As a consequence, the characterization of the optimal policy using the q-function also involves a Lagrange multiplier. In response, we establish the martingale characterization of the q-function and devise two q-learning algorithms depending on whether the Lagrange multiplier can be derived explicitly or not. In the latter case, we consider different parameterizations of the optimal q-function and the optimal policy, and update them alternatively in an Actor-Critic manner. We also study two numerical examples, namely, an optimal liquidation problem in dark pools and a non-LQ control problem. It is interesting to see therein that the optimal policies under the Tsallis entropy regularization can be characterized explicitly, which are distributions concentrated on some compact support. The satisfactory performance of our q-learning algorithms is illustrated in each example.",
    "source": "arXiv"
  },
  {
    "title": "Importance Corrected Neural JKO Sampling",
    "title_es": "Importance Corrected Neural JKO Sampling",
    "url": "https://arxiv.org/abs/2407.20444",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2407.20444v3 Announce Type: replace-cross \nAbstract: In order to sample from an unnormalized probability density function, we propose to combine continuous normalizing flows (CNFs) with rejection-resampling steps based on importance weights. We relate the iterative training of CNFs with regularized velocity fields to a JKO scheme and prove convergence of the involved velocity fields to the velocity field of the Wasserstein gradient flow (WGF). The alternation of local flow steps and non-local rejection-resampling steps allows to overcome local minima or slow convergence of the WGF for multimodal distributions. Since the proposal of the rejection step is generated by the model itself, they do not suffer from common drawbacks of classical rejection schemes. The arising model can be trained iteratively, reduces the reverse Kullback-Leibler (KL) loss function in each step, allows to generate iid samples and moreover allows for evaluations of the generated underlying density. Numerical examples show that our method yields accurate results on various test distributions including high-dimensional multimodal targets and outperforms the state of the art in almost all cases significantly.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Deep Hedging of Options with Implied Volatility Surface Feedback Information",
    "title_es": "Enhancing Deep Hedging of Options with Implied Volatility Surface Feedback Information",
    "url": "https://arxiv.org/abs/2407.21138",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2407.21138v2 Announce Type: replace-cross \nAbstract: We present a dynamic hedging scheme for S&P 500 options, where rebalancing decisions are enhanced by integrating information about the implied volatility surface dynamics. The optimal hedging strategy is obtained through a deep policy gradient-type reinforcement learning algorithm. The favorable inclusion of forward-looking information embedded in the volatility surface allows our procedure to outperform several conventional benchmarks such as practitioner and smiled-implied delta hedging procedures, both in simulation and backtesting experiments. The outperformance is more pronounced in the presence of transaction costs.",
    "source": "arXiv"
  },
  {
    "title": "On the Robustness of Kernel Goodness-of-Fit Tests",
    "title_es": "On the Robustness of Kernel Goodness-of-Fit Tests",
    "url": "https://arxiv.org/abs/2408.05854",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.05854v4 Announce Type: replace-cross \nAbstract: Goodness-of-fit testing is often criticized for its lack of practical relevance: since ``all models are wrong'', the null hypothesis that the data conform to our model is ultimately always rejected as the sample size grows. Despite this, probabilistic models are still used extensively, raising the more pertinent question of whether the model is \\emph{good enough} for the task at hand. This question can be formalized as a robust goodness-of-fit testing problem by asking whether the data were generated from a distribution that is a mild perturbation of the model. In this paper, we show that existing kernel goodness-of-fit tests are not robust under common notions of robustness including both qualitative and quantitative robustness. We further show that robustification techniques using tilted kernels, while effective in the parameter estimation literature, are not sufficient to ensure both types of robustness in the testing setting. To address this, we propose the first robust kernel goodness-of-fit test, which resolves this open problem by using kernel Stein discrepancy (KSD) balls. This framework encompasses many well-known perturbation models, such as Huber's contamination and density-band models.",
    "source": "arXiv"
  },
  {
    "title": "The Holonomy of Optimal Mass Transport: The Gaussian-Linear Case",
    "title_es": "The Holonomy of Optimal Mass Transport: The Gaussian-Linear Case",
    "url": "https://arxiv.org/abs/2408.14707",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.14707v2 Announce Type: replace-cross \nAbstract: The theory of Monge-Kantorovich Optimal Mass Transport (OMT) has in recent years spurred a fast developing phase of research in stochastic control, control of ensemble systems, thermodynamics, data science, and several other fields in engineering and science. We herein introduce a new type of transportation problems. The salient feature of these problems is that particles/agents in the ensemble are labeled and their relative position along their journey is of interest. Of particular importance in our program are control laws that steer ensembles along cycles ensuring that individual particles return to their original position. This feature is in contrast with the classical theory of optimal transport where the primary object of study is the path of probability densities, without any concern about particle labels. In the theory that we present, we focus on the case Gaussian distributions and linear dynamics, and explore a hitherto unstudied sub-Riemannian structure of Monge-Kantorovich transport where the relative position of particles along their journey is modeled by the holonomy of the transportation schedule. From this vantage point, we discuss several other problems of independent interest.",
    "source": "arXiv"
  },
  {
    "title": "CTRQNets & LQNets: Continuous Time Recurrent and Liquid Quantum Neural Networks",
    "title_es": "CTRQNets & LQNets: Continuous Time Recurrent and Liquid Quantum Neural Networks",
    "url": "https://arxiv.org/abs/2408.15462",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2408.15462v2 Announce Type: replace-cross \nAbstract: Neural networks have continued to gain prevalence in the modern era for their ability to model complex data through pattern recognition and behavior remodeling. However, the static construction of traditional neural networks inhibits dynamic intelligence. This makes them inflexible to temporal changes in data and unfit to capture complex dependencies. With the advent of quantum technology, there has been significant progress in creating quantum algorithms. In recent years, researchers have developed quantum neural networks that leverage the capabilities of qubits to outperform classical networks. However, their current formulation exhibits a static construction limiting the system's dynamic intelligence. To address these weaknesses, we develop a Liquid Quantum Neural Network (LQNet) and a Continuous Time Recurrent Quantum Neural Network (CTRQNet). Both models demonstrate a significant improvement in accuracy compared to existing quantum neural networks (QNNs), achieving accuracy increases as high as 40\\% on CIFAR 10 through binary classification. We propose LQNets and CTRQNets might shine a light on quantum machine learning's black box.",
    "source": "arXiv"
  },
  {
    "title": "Inertial Coordination Games",
    "title_es": "Inertial Coordination Games",
    "url": "https://arxiv.org/abs/2409.08145",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2409.08145v3 Announce Type: replace-cross \nAbstract: We analyze inertial coordination games: dynamic coordination games with an endogenously changing state that depends on (i) a persistent fundamental players privately learn about over time; and (ii) past play. The speed of learning determines long-run equilibrium dynamics: the risk-dominant action is played in the limit if and only if learning is slow such that posterior precisions grow sub-quadratically. This generalizes results from static global games and endows them with a learning foundation. Conversely, when learning is fast such that posterior precisions grow super-quadratically, shocks can propagate and generate self-fulfilling spirals.",
    "source": "arXiv"
  },
  {
    "title": "Return Prediction for Mean-Variance Portfolio Selection: How Decision-Focused Learning Shapes Forecasting Models",
    "title_es": "Return Prediction for Mean-Variance Portfolio Selection: How Decision-Focused Learning Shapes Forecasting Models",
    "url": "https://arxiv.org/abs/2409.09684",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2409.09684v3 Announce Type: replace-cross \nAbstract: Markowitz laid the foundation of portfolio theory through the mean-variance optimization (MVO) framework. However, the effectiveness of MVO is contingent on the precise estimation of expected returns, variances, and covariances of asset returns, which are typically uncertain. Machine learning models are becoming useful in estimating uncertain parameters, and such models are trained to minimize prediction errors, such as mean squared errors (MSE), which treat prediction errors uniformly across assets. Recent studies have pointed out that this approach would lead to suboptimal decisions and proposed Decision-Focused Learning (DFL) as a solution, integrating prediction and optimization to improve decision-making outcomes. While studies have shown DFL's potential to enhance portfolio performance, the detailed mechanisms of how DFL modifies prediction models for MVO remain unexplored. This study investigates how DFL adjusts stock return prediction models to optimize decisions in MVO. Theoretically, we show that DFL's gradient can be interpreted as tilting the MSE-based prediction errors by the inverse covariance matrix, effectively incorporating inter-asset correlations into the learning process, while MSE treats each asset's error independently. This tilting mechanism leads to systematic prediction biases where DFL overestimates returns for assets included in portfolios while underestimating excluded assets. Our findings reveal why DFL achieves superior portfolio performance despite higher prediction errors. The strategic biases are features, not flaws.",
    "source": "arXiv"
  },
  {
    "title": "A spectral method for multi-view subspace learning using the product of projections",
    "title_es": "A spectral method for multi-view subspace learning using the product of projections",
    "url": "https://arxiv.org/abs/2410.19125",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2410.19125v2 Announce Type: replace-cross \nAbstract: Multi-view data provides complementary information on the same set of observations, with multi-omics and multimodal sensor data being common examples. Analyzing such data typically requires distinguishing between shared (joint) and unique (individual) signal subspaces from noisy, high-dimensional measurements. Despite many proposed methods, the conditions for reliably identifying joint and individual subspaces remain unclear. We rigorously quantify these conditions, which depend on the ratio of the signal rank to the ambient dimension, principal angles between true subspaces, and noise levels. Our approach characterizes how spectrum perturbations of the product of projection matrices, derived from each view's estimated subspaces, affect subspace separation. Using these insights, we provide an easy-to-use and scalable estimation algorithm. In particular, we employ rotational bootstrap and random matrix theory to partition the observed spectrum into joint, individual, and noise subspaces. Diagnostic plots visualize this partitioning, providing practical and interpretable insights into the estimation performance. In simulations, our method estimates joint and individual subspaces more accurately than existing approaches. Applications to multi-omics data from colorectal cancer patients and nutrigenomic study of mice demonstrate improved performance in downstream predictive tasks.",
    "source": "arXiv"
  },
  {
    "title": "Gradient Descent Algorithm in Hilbert Spaces under Stationary Markov Chains with $\\phi$- and $\\beta$-Mixing",
    "title_es": "Gradient Descent Algorithm in Hilbert Spaces under Stationary Markov Chains with $\\phi$- and $\\beta$-Mixing",
    "url": "https://arxiv.org/abs/2502.03551",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.03551v3 Announce Type: replace-cross \nAbstract: In this paper, we study a strictly stationary Markov chain gradient descent algorithm operating in general Hilbert spaces. Our analysis focuses on the mixing coefficients of the underlying process, specifically the $\\phi$- and $\\beta$-mixing coefficients. Under these assumptions, we derive probabilistic upper bounds on the convergence behavior of the algorithm based on the exponential as well as the polynomial decay of the mixing coefficients.",
    "source": "arXiv"
  },
  {
    "title": "Lung-DDPM: Semantic Layout-guided Diffusion Models for Thoracic CT Image Synthesis",
    "title_es": "Lung-DDPM: Semantic Layout-guided Diffusion Models for Thoracic CT Image Synthesis",
    "url": "https://arxiv.org/abs/2502.15204",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2502.15204v2 Announce Type: replace-cross \nAbstract: With the rapid development of artificial intelligence (AI), AI-assisted medical imaging analysis demonstrates remarkable performance in early lung cancer screening. However, the costly annotation process and privacy concerns limit the construction of large-scale medical datasets, hampering the further application of AI in healthcare. To address the data scarcity in lung cancer screening, we propose Lung-DDPM, a thoracic CT image synthesis approach that effectively generates high-fidelity 3D synthetic CT images, which prove helpful in downstream lung nodule segmentation tasks. Our method is based on semantic layout-guided denoising diffusion probabilistic models (DDPM), enabling anatomically reasonable, seamless, and consistent sample generation even from incomplete semantic layouts. Our results suggest that the proposed method outperforms other state-of-the-art (SOTA) generative models in image quality evaluation and downstream lung nodule segmentation tasks. Specifically, Lung-DDPM achieved superior performance on our large validation cohort, with a Fr\\'echet inception distance (FID) of 0.0047, maximum mean discrepancy (MMD) of 0.0070, and mean squared error (MSE) of 0.0024. These results were 7.4$\\times$, 3.1$\\times$, and 29.5$\\times$ better than the second-best competitors, respectively. Furthermore, the lung nodule segmentation model, trained on a dataset combining real and Lung-DDPM-generated synthetic samples, attained a Dice Coefficient (Dice) of 0.3914 and sensitivity of 0.4393. This represents 8.8% and 18.6% improvements in Dice and sensitivity compared to the model trained solely on real samples. The experimental results highlight Lung-DDPM's potential for a broader range of medical imaging applications, such as general tumor segmentation, cancer survival estimation, and risk prediction. The code and pretrained models are available at https://github.com/Manem-Lab/Lung-DDPM/.",
    "source": "arXiv"
  },
  {
    "title": "A Tutte-type canonical decomposition of 3- and 4-connected graphs",
    "title_es": "A Tutte-type canonical decomposition of 3- and 4-connected graphs",
    "url": "https://arxiv.org/abs/2504.00760",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.00760v2 Announce Type: replace-cross \nAbstract: We provide a unique decomposition of every 4-connected graph into parts that are either quasi-5-connected, cycles of triangle-torsos and 3-connected torsos on $\\leq 5$ vertices, generalised double-wheels, or thickened $K_{4,m}$'s. The decomposition can be described in terms of a tree-decomposition but with edges allowed in the adhesion-sets. Our construction is explicit, canonical, and exhibits a defining property of the Tutte-decomposition.\n  As a corollary, we obtain a new Tutte-type canonical decomposition of 3-connected graphs into parts that are either quasi-4-connected, generalised wheels or thickened $K_{3,m}$'s. This decomposition is similar yet different from the tri-separation decomposition.\n  As an application of the decomposition for 4-connectivity, we obtain a new theorem characterising all quasi-4-connected vertex-transitive finite graphs as essentially quasi-5-connected or on a short explicit list of graphs.",
    "source": "arXiv"
  },
  {
    "title": "Cryo-em images are intrinsically low dimensional",
    "title_es": "Cryo-em images are intrinsically low dimensional",
    "url": "https://arxiv.org/abs/2504.11249",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.11249v2 Announce Type: replace-cross \nAbstract: Simulation-based inference provides a powerful framework for cryo-electron microscopy, employing neural networks in methods like CryoSBI to infer biomolecular conformations via learned latent representations. This latent space represents a rich opportunity, encoding valuable information about the physical system and the inference process. Harnessing this potential hinges on understanding the underlying geometric structure of these representations. We investigate this structure by applying manifold learning techniques to CryoSBI representations of hemagglutinin (simulated and experimental). We reveal that these high-dimensional data inherently populate low-dimensional, smooth manifolds, with simulated data effectively covering the experimental counterpart. By characterizing the manifold's geometry using Diffusion Maps and identifying its principal axes of variation via coordinate interpretation methods, we establish a direct link between the latent structure and key physical parameters. Discovering this intrinsic low-dimensionality and interpretable geometric organization not only validates the CryoSBI approach but enables us to learn more from the data structure and provides opportunities for improving future inference strategies by exploiting this revealed manifold geometry.",
    "source": "arXiv"
  },
  {
    "title": "EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting",
    "title_es": "EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting",
    "url": "https://arxiv.org/abs/2504.12867",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2504.12867v4 Announce Type: replace-cross \nAbstract: Human speech goes beyond the mere transfer of information; it is a profound exchange of emotions and a connection between individuals. While Text-to-Speech (TTS) models have made huge progress, they still face challenges in controlling the emotional expression in the generated speech. In this work, we propose EmoVoice, a novel emotion-controllable TTS model that exploits large language models (LLMs) to enable fine-grained freestyle natural language emotion control, and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency, inspired by chain-of-thought (CoT) and chain-of-modality (CoM) techniques. Besides, we introduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring expressive speech and fine-grained emotion labels with natural language descriptions. EmoVoice achieves state-of-the-art performance on the English EmoVoice-DB test set using only synthetic training data, and on the Chinese Secap test set using our in-house data. We further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and Gemini to assess emotional speech. Dataset, code, checkpoints, and demo samples are available at https://github.com/yanghaha0908/EmoVoice.",
    "source": "arXiv"
  },
  {
    "title": "M-learner:A Flexible And Powerful Framework To Study Heterogeneous Treatment Effect In Mediation Model",
    "title_es": "M-learner:A Flexible And Powerful Framework To Study Heterogeneous Treatment Effect In Mediation Model",
    "url": "https://arxiv.org/abs/2505.17917",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.17917v3 Announce Type: replace-cross \nAbstract: We propose a novel method, termed the M-learner, for estimating heterogeneous indirect and total treatment effects and identifying relevant subgroups within a mediation framework. The procedure comprises four key steps. First, we compute individual-level conditional average indirect/total treatment effect Second, we construct a distance matrix based on pairwise differences. Third, we apply tSNE to project this matrix into a low-dimensional Euclidean space, followed by K-means clustering to identify subgroup structures. Finally, we calibrate and refine the clusters using a threshold-based procedure to determine the optimal configuration. To the best of our knowledge, this is the first approach specifically designed to capture treatment effect heterogeneity in the presence of mediation. Experimental results validate the robustness and effectiveness of the proposed framework. Application to the real-world Jobs II dataset highlights the broad adaptability and potential applicability of our method.Code is available at https: //anonymous.4open.science/r/M-learner-C4BB.",
    "source": "arXiv"
  },
  {
    "title": "ReverbFX: A Dataset of Room Impulse Responses Derived from Reverb Effect Plugins for Singing Voice Dereverberation",
    "title_es": "ReverbFX: A Dataset of Room Impulse Responses Derived from Reverb Effect Plugins for Singing Voice Dereverberation",
    "url": "https://arxiv.org/abs/2505.20533",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2505.20533v2 Announce Type: replace-cross \nAbstract: We present ReverbFX, a new room impulse response (RIR) dataset designed for singing voice dereverberation research. Unlike existing datasets based on real recorded RIRs, ReverbFX features a diverse collection of RIRs captured from various reverb audio effect plugins commonly used in music production. We conduct comprehensive experiments using the proposed dataset to benchmark the challenge of dereverberation of singing voice recordings affected by artificial reverbs. We train two state-of-the-art generative models using ReverbFX and demonstrate that models trained with plugin-derived RIRs outperform those trained on realistic RIRs in artificial reverb scenarios.",
    "source": "arXiv"
  },
  {
    "title": "MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements",
    "title_es": "MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements",
    "url": "https://arxiv.org/abs/2506.02260",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.02260v2 Announce Type: replace-cross \nAbstract: The growing prevalence of digital health technologies has led to the generation of complex multi-modal data, such as physical activity measurements simultaneously collected from various sensors of mobile and wearable devices. These data hold immense potential for advancing health studies, but current methods predominantly rely on supervised learning, requiring extensive labeled datasets that are often expensive or impractical to obtain, especially in clinical studies. To address this limitation, we propose a self-supervised learning framework called Multi-modal Cross-masked Autoencoder (MoCA) that leverages cross-modality masking and the Transformer autoencoder architecture to utilize both temporal correlations within modalities and cross-modal correlations between data streams. We also provide theoretical guarantees to support the effectiveness of the cross-modality masking scheme in MoCA. Comprehensive experiments and ablation studies demonstrate that our method outperforms existing approaches in both reconstruction and downstream tasks. We release open-source code for data processing, pre-training, and downstream tasks in the supplementary materials. This work highlights the transformative potential of self-supervised learning in digital health and multi-modal data.",
    "source": "arXiv"
  },
  {
    "title": "Half-Iterates and Delta Conjectures",
    "title_es": "Half-Iterates and Delta Conjectures",
    "url": "https://arxiv.org/abs/2506.07625",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.07625v4 Announce Type: replace-cross \nAbstract: The vivid contrast between two competing algorithms for solving Abel's equation $g(\\theta(x)) = g(x) + 1$, given $\\theta(x)$, is easily sketched. EJ is faster and more efficient, but ML evaluates a limit characterizing the principal solution $g(x)$ directly. EJ finds $g(x)+\\delta$, where $\\delta$ is possibly nonzero but independent of $x$. If we were to know an exact expression for $\\delta$, then the \"intrinsicality\" of ML would be subsumed by EJ. Filling this gap in our knowledge is the aim of this paper.",
    "source": "arXiv"
  },
  {
    "title": "AbRank: A Benchmark Dataset and Metric-Learning Framework for Antibody-Antigen Affinity Ranking",
    "title_es": "AbRank: A Benchmark Dataset and Metric-Learning Framework for Antibody-Antigen Affinity Ranking",
    "url": "https://arxiv.org/abs/2506.17857",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2506.17857v2 Announce Type: replace-cross \nAbstract: Accurate prediction of antibody-antigen (Ab-Ag) binding affinity is essential for therapeutic design and vaccine development, yet the performance of current models is limited by noisy experimental labels, heterogeneous assay conditions, and poor generalization across the vast antibody and antigen sequence space. We introduce AbRank, a large-scale benchmark and evaluation framework that reframes affinity prediction as a pairwise ranking problem. AbRank aggregates over 380,000 binding assays from nine heterogeneous sources, spanning diverse antibodies, antigens, and experimental conditions, and introduces standardized data splits that systematically increase distribution shift, from local perturbations such as point mutations to broad generalization across novel antigens and antibodies. To ensure robust supervision, AbRank defines an m-confident ranking framework by filtering out comparisons with marginal affinity differences, focusing training on pairs with at least an m-fold difference in measured binding strength. As a baseline for the benchmark, we introduce WALLE-Affinity, a graph-based approach that integrates protein language model embeddings with structural information to predict pairwise binding preferences. Our benchmarks reveal significant limitations in current methods under realistic generalization settings and demonstrate that ranking-based training improves robustness and transferability. In summary, AbRank offers a robust foundation for machine learning models to generalize across the antibody-antigen space, with direct relevance for scalable, structure-aware antibody therapeutic design.",
    "source": "arXiv"
  },
  {
    "title": "Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network",
    "title_es": "Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network",
    "url": "https://arxiv.org/abs/2507.11799",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.11799v3 Announce Type: replace-cross \nAbstract: This paper presents a neural network (NN)-based solver for an integro-differential equation that models shrinkage-induced fragmentation. The proposed method directly maps input parameters to the corresponding probability density function without numerically solving the governing equation, thereby significantly reducing computational costs. Specifically, it enables efficient evaluation of the density function in Monte Carlo simulations while maintaining accuracy comparable to or even exceeding that of conventional finite difference schemes. Validatation on synthetic data demonstrates both the method's computational efficiency and predictive reliability. This study establishes a foundation for the data-driven inverse analysis of fragmentation and suggests the potential for extending the framework beyond pre-specified model structures.",
    "source": "arXiv"
  },
  {
    "title": "Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control: Non-Penalty Approach",
    "title_es": "Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control: Non-Penalty Approach",
    "url": "https://arxiv.org/abs/2507.19895",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.19895v3 Announce Type: replace-cross \nAbstract: In [1], the distributed linear-quadratic problem with fixed communication topology (DFT-LQ) and the sparse feedback LQ problem (SF-LQ) are formulated into a nonsmooth and nonconvex optimization problem with affine constraints. Moreover, a penalty approach is considered in [1], and the PALM (proximal alternating linearized minimization) algorithm is studied with convergence and complexity analysis. In this paper, we aim to address the inherent drawbacks of the penalty approach, such as the challenge of tuning the penalty parameter and the risk of introducing spurious stationary points. Specifically, we first reformulate the SF-LQ problem and the DFT-LQ problem from an epi-composition function perspective, aiming to solve constrained problem directly. Then, from a theoretical viewpoint, we revisit the alternating direction method of multipliers (ADMM) and establish its convergence to the set of cluster points under certain assumptions. When these assumptions do not hold, we show that alternative approaches combining subgradient descent with Difference-of-Convex relaxation methods can be effectively utilized. In summary, our results enable the direct design of group-sparse feedback gains with theoretical guarantees, without resorting to convex surrogates, restrictive structural assumptions or penalty formulations that incorporate constraints into the cost function.",
    "source": "arXiv"
  },
  {
    "title": "Representation biases: will we achieve complete understanding by analyzing representations?",
    "title_es": "Representation biases: will we achieve complete understanding by analyzing representations?",
    "url": "https://arxiv.org/abs/2507.22216",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2507.22216v2 Announce Type: replace-cross \nAbstract: A common approach in neuroscience is to study neural representations as a means to understand a system -- increasingly, by relating the neural representations to the internal representations learned by computational models. However, a recent work in machine learning (Lampinen, 2024) shows that learned feature representations may be biased to over-represent certain features, and represent others more weakly and less-consistently. For example, simple (linear) features may be more strongly and more consistently represented than complex (highly nonlinear) features. These biases could pose challenges for achieving full understanding of a system through representational analysis. In this perspective, we illustrate these challenges -- showing how feature representation biases can lead to strongly biased inferences from common analyses like PCA, regression, and RSA. We also present homomorphic encryption as a simple case study of the potential for strong dissociation between patterns of representation and computation. We discuss the implications of these results for representational comparisons between systems, and for neuroscience more generally.",
    "source": "arXiv"
  },
  {
    "title": "ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism",
    "title_es": "ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism",
    "url": "https://arxiv.org/abs/2508.00554",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.00554v2 Announce Type: replace-cross \nAbstract: In financial trading, large language model (LLM)-based agents demonstrate significant potential. However, the high sensitivity to market noise undermines the performance of LLM-based trading systems. To address this limitation, we propose a novel multi-agent system featuring an internal competitive mechanism inspired by modern corporate management structures. The system consists of two specialized teams: (1) Data Team - responsible for processing and condensing massive market data into diversified text factors, ensuring they fit the model's constrained context. (2) Research Team - tasked with making parallelized multipath trading decisions based on deep research methods. The core innovation lies in implementing a real-time evaluation and ranking mechanism within each team, driven by authentic market feedback. Each agent's performance undergoes continuous scoring and ranking, with only outputs from top-performing agents being adopted. The design enables the system to adaptively adjust to dynamic environment, enhances robustness against market noise and ultimately delivers superior trading performance. Experimental results demonstrate that our proposed system significantly outperforms prevailing multi-agent systems and traditional quantitative investment methods across diverse evaluation metrics. ContestTrade is open-sourced on GitHub at https://github.com/FinStep-AI/ContestTrade.",
    "source": "arXiv"
  },
  {
    "title": "Poncelet triangles: conic loci of the orthocenter and of the isogonal conjugate of a fixed point",
    "title_es": "Poncelet triangles: conic loci of the orthocenter and of the isogonal conjugate of a fixed point",
    "url": "https://arxiv.org/abs/2508.02368",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.02368v3 Announce Type: replace-cross \nAbstract: We prove that over a Poncelet triangle family interscribed between two nested ellipses $\\mathcal{E},\\mathcal{E}_c$, (i) the locus of the orthocenter is not only a conic, but it is axis-aligned and homothetic to a $90^o$-rotated copy of $\\mathcal{E}$, and (ii) the locus of the isogonal conjugate of a fixed point $P$ is also a conic (the expected degree was four); a parabola (resp. line) if $P$ is on the (degree-four) envelope of the circumcircle (resp. on $\\mathcal{E}$). We also show that the envelope of both the circumcircle and radical axis of incircle and circumcircle contain a conic component if and only if $\\mathcal{E}_c$ is a circle. The former case is the union of two circles!",
    "source": "arXiv"
  },
  {
    "title": "The vast world of quantum advantage",
    "title_es": "The vast world of quantum advantage",
    "url": "https://arxiv.org/abs/2508.05720",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.05720v2 Announce Type: replace-cross \nAbstract: The quest to identify quantum advantages lies at the heart of quantum technology. While quantum devices promise extraordinary capabilities, from exponential computational speedups to unprecedented measurement precision, distinguishing genuine advantages from mere illusions remains a formidable challenge. In this endeavor, quantum theorists are like prophets attempting to foretell the future, yet the boundary between visionary insight and unfounded fantasy is perilously thin. In this perspective, we examine our mathematical tools for navigating the vast world of quantum advantages across computation, learning, sensing, and communication. We explore five keystone properties: predictability, typicality, robustness, verifiability, and usefulness that define an ideal quantum advantage, and envision what new quantum advantages could arise in a future with ubiquitous quantum technology. We prove that some quantum advantages are inherently unpredictable using classical resources alone, suggesting a landscape far richer than what we can currently foresee. While mathematical rigor remains our indispensable guide, the ultimate power of quantum technologies may emerge from advantages we cannot yet conceive.",
    "source": "arXiv"
  },
  {
    "title": "Citation Issues in Wave Mechanics Theory of Microwave Absorption",
    "title_es": "Citation Issues in Wave Mechanics Theory of Microwave Absorption",
    "url": "https://arxiv.org/abs/2508.06522",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.06522v2 Announce Type: replace-cross \nAbstract: The wave mechanics theory of microwave absorption challenges the long-standing impedance-matching and quarter-wavelength paradigms by demonstrating that conventional models mistakenly conflate bulk material parameters with thin-film phenomena. Drawing on a corpus of 35 peer-reviewed papers and preprints, the study performs a citation-pattern analysis and a logical audit of established theory. Results reveal a striking asymmetry in scholarly engagement, only a handful of supportive or neutral citations appear amid widespread silence, alongside critical logical flaws in impedance matching, notably its inconsistent treatment of penetration, reflection, and absorption from film. By re-framing absorption as a wave-mechanics process governed by interference at parallel interfaces, the wave mechanics framework restores energy-conservation consistency and provides experimentally verified design rules for film thickness, phase response, and broadband performance. The paper further situates the citation neglect within broader issues of peer-review bias and paradigm inertia, illustrating how cargo-cult scientific practices can impede theoretical progress. Recommendations are offered for researchers, editors, and institutions to foster open discourse, rigorously test competing models, and update curricula and design tools accordingly.",
    "source": "arXiv"
  },
  {
    "title": "FlexCTC: GPU-powered CTC Beam Decoding With Advanced Contextual Abilities",
    "title_es": "FlexCTC: GPU-powered CTC Beam Decoding With Advanced Contextual Abilities",
    "url": "https://arxiv.org/abs/2508.07315",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07315v2 Announce Type: replace-cross \nAbstract: While beam search improves speech recognition quality over greedy decoding, standard implementations are slow, often sequential, and CPU-bound. To fully leverage modern hardware capabilities, we present a novel open-source FlexCTC toolkit for fully GPU-based beam decoding, designed for Connectionist Temporal Classification (CTC) models. Developed entirely in Python and PyTorch, it offers a fast, user-friendly, and extensible alternative to traditional C++, CUDA, or WFST-based decoders. The toolkit features a high-performance, fully batched GPU implementation with eliminated CPU-GPU synchronization and minimized kernel launch overhead via CUDA Graphs. It also supports advanced contextualization techniques, including GPU-powered N-gram language model fusion and phrase-level boosting. These features enable accurate and efficient decoding, making them suitable for both research and production use.",
    "source": "arXiv"
  },
  {
    "title": "Remarks on the Brouwer Conjecture",
    "title_es": "Remarks on the Brouwer Conjecture",
    "url": "https://arxiv.org/abs/2508.07550",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07550v2 Announce Type: replace-cross \nAbstract: The Brouwer conjecture (BC) in spectral graph theory claims that the sum of the largest k Kirchhoff eigenvalues of a graph are bounded above by the number m of edges plus k(k+1)/2. We show that (BC) holds for all graphs with n vertices if n is larger or equal than 4 times the square of the maximal vertex degree. We also note that (BC) for graphs implies (BC) for quivers.",
    "source": "arXiv"
  },
  {
    "title": "MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer",
    "title_es": "MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer",
    "url": "https://arxiv.org/abs/2508.07817",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.07817v2 Announce Type: replace-cross \nAbstract: The core role of medical images in disease diagnosis makes their quality directly affect the accuracy of clinical judgment. However, due to factors such as low-dose scanning, equipment limitations and imaging artifacts, medical images are often accompanied by non-uniform noise interference, which seriously affects structure recognition and lesion detection. This paper proposes a medical image adaptive denoising model (MI-ND) that integrates multi-scale convolutional and Transformer architecture, introduces a noise level estimator (NLE) and a noise adaptive attention module (NAAB), and realizes channel-spatial attention regulation and cross-modal feature fusion driven by noise perception. Systematic testing is carried out on multimodal public datasets. Experiments show that this method significantly outperforms the comparative methods in image quality indicators such as PSNR, SSIM, and LPIPS, and improves the F1 score and ROC-AUC in downstream diagnostic tasks, showing strong prac-tical value and promotional potential. The model has outstanding benefits in structural recovery, diagnostic sensitivity, and cross-modal robustness, and provides an effective solution for medical image enhancement and AI-assisted diagnosis and treatment.",
    "source": "arXiv"
  },
  {
    "title": "miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research",
    "title_es": "miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research",
    "url": "https://arxiv.org/abs/2508.08331",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08331v2 Announce Type: replace-cross \nAbstract: MicroRNAs (miRs) are robust regulators of gene expression, implicated in most biological processes. microRNAs predominantly downregulate the expression of genes post-transcriptionally and each miR is predicted to target several hundred genes. The accurate identification and annotation of miR-mRNA target interactions is central to understanding miRs function and their therapeutic potential. However, computational target prediction is challenging due to imperfect complementarity of miRs with their targets and the growing volume and heterogeneity of experimental data present challenges in accessing, integrating, and analysing miR-target interaction information across biological contexts. This creates a need for integrated resources and intelligent query tools.\n  We present the miRKat Suite, comprising miRKatDB, a comprehensive, curated database of predicted and validated miR-target interactions and associated annotations, and miRKatAI, a multi-agent system powered by large language models (LLMs) and LangGraph. miRKatDB integrates data from multiple publicly available sources, providing a comprehensive foundation for miR studies, including miR target genes and changes in levels of tissue expression previously reported. miRKatAI offers a natural language interface for complex querying of miRKatDB, facilitates grounded information retrieval from established sources in the field, and supports basic data visualisation. The miRKat Suite aims to accelerate miR research by streamlining data access, enhancing exploratory analysis, and supporting hypothesis generation.",
    "source": "arXiv"
  },
  {
    "title": "Performance Benchmarking of Machine Learning Models for Terahertz Metamaterial Absorber Prediction",
    "title_es": "Performance Benchmarking of Machine Learning Models for Terahertz Metamaterial Absorber Prediction",
    "url": "https://arxiv.org/abs/2508.08611",
    "published": "2025-08-14T04:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "arXiv:2508.08611v2 Announce Type: replace-cross \nAbstract: This study presents a polarization-insensitive ultra-broadband terahertz metamaterial absorber based on vanadium dioxide (VO2) and evaluates machine learning methods for predicting its absorption performance. The structure consists of a VO2 metasurface, a MF2 dielectric spacer, and a gold ground plane. It achieves more than 90% absorption between 5.72 and 11.11 THz, covering a 5.38 THz bandwidth with an average absorptance of 98.15%. A dataset of 9,018 samples was generated from full-wave simulations by varying patch width, dielectric thickness, and frequency. Six regression models were trained: Linear Regression, Support Vector Regression, Decision Tree, Random Forest, XGBoost, and Bagging. Performance was measured using adjusted R2, MAE, MSE, and RMSE. Ensemble models achieved the best results, with Bagging reaching an adjusted R2 of 0.9985 and RMSE of 0.0146. The workflow offers a faster alternative to exhaustive simulations and can be applied to other metamaterial designs, enabling efficient evaluation and optimization.",
    "source": "arXiv"
  },
  {
    "title": "Publisher Correction: Liquid–liquid interfacial tension stabilized Li-metal batteries",
    "title_es": "Publisher Correction: Liquid–liquid interfacial tension stabilized Li-metal batteries",
    "url": "https://www.nature.com/articles/s41586-025-09504-y",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Publisher Correction: Liquid–liquid interfacial tension stabilized Li-metal batteries",
    "source": "Nature"
  },
  {
    "title": "Spatial correlation in economic analysis of climate change",
    "title_es": "Spatial correlation in economic analysis of climate change",
    "url": "https://www.nature.com/articles/s41586-025-09206-5",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Spatial correlation in economic analysis of climate change",
    "source": "Nature"
  },
  {
    "title": "Sun-powered flyers could explore the mysterious mesosphere",
    "title_es": "Sun-powered flyers could explore the mysterious mesosphere",
    "url": "https://www.nature.com/articles/d41586-025-02582-y",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Sun-powered flyers could explore the mysterious mesosphere",
    "source": "Nature"
  },
  {
    "title": "Astronomers gave up this comet for dead ― but they were wrong",
    "title_es": "Astronomers gave up this comet for dead ― but they were wrong",
    "url": "https://www.nature.com/articles/d41586-025-02561-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Astronomers gave up this comet for dead ― but they were wrong",
    "source": "Nature"
  },
  {
    "title": "Rubber planting and deforestation",
    "title_es": "Rubber planting and deforestation",
    "url": "https://www.nature.com/articles/s41586-025-08848-9",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Rubber planting and deforestation",
    "source": "Nature"
  },
  {
    "title": "Y. Wang et al. reply",
    "title_es": "Y. Wang et al. reply",
    "url": "https://www.nature.com/articles/s41586-025-08849-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Y. Wang et al. reply",
    "source": "Nature"
  },
  {
    "title": "Accuracy of rubber-related deforestation maps",
    "title_es": "Accuracy of rubber-related deforestation maps",
    "url": "https://www.nature.com/articles/s41586-025-08847-w",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Accuracy of rubber-related deforestation maps",
    "source": "Nature"
  },
  {
    "title": "Acidic oxygen reduction by single-atom Fe catalysts on curved supports",
    "title_es": "Acidic oxygen reduction by single-atom Fe catalysts on curved supports",
    "url": "https://www.nature.com/articles/s41586-025-09364-6",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Acidic oxygen reduction by single-atom Fe catalysts on curved supports",
    "source": "Nature"
  },
  {
    "title": "The geologic history of marine dissolved organic carbon from iron oxides",
    "title_es": "The geologic history of marine dissolved organic carbon from iron oxides",
    "url": "https://www.nature.com/articles/s41586-025-09383-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "The geologic history of marine dissolved organic carbon from iron oxides",
    "source": "Nature"
  },
  {
    "title": "New discoveries of Australopithecus and Homo from Ledi-Geraru, Ethiopia",
    "title_es": "New discoveries of Australopithecus and Homo from Ledi-Geraru, Ethiopia",
    "url": "https://www.nature.com/articles/s41586-025-09390-4",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "New discoveries of Australopithecus and Homo from Ledi-Geraru, Ethiopia",
    "source": "Nature"
  },
  {
    "title": "Expanding the cytokine receptor alphabet reprograms T cells into diverse states",
    "title_es": "Expanding the cytokine receptor alphabet reprograms T cells into diverse states",
    "url": "https://www.nature.com/articles/s41586-025-09393-1",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Expanding the cytokine receptor alphabet reprograms T cells into diverse states",
    "source": "Nature"
  },
  {
    "title": "NASP modulates histone turnover to drive PARP inhibitor resistance",
    "title_es": "NASP modulates histone turnover to drive PARP inhibitor resistance",
    "url": "https://www.nature.com/articles/s41586-025-09414-z",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "NASP modulates histone turnover to drive PARP inhibitor resistance",
    "source": "Nature"
  },
  {
    "title": "Clone copy number diversity is linked to survival in lung cancer",
    "title_es": "Clone copy number diversity is linked to survival in lung cancer",
    "url": "https://www.nature.com/articles/s41586-025-09398-w",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Clone copy number diversity is linked to survival in lung cancer",
    "source": "Nature"
  },
  {
    "title": "Bending the curve of land degradation to achieve global environmental goals",
    "title_es": "Bending the curve of land degradation to achieve global environmental goals",
    "url": "https://www.nature.com/articles/s41586-025-09365-5",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Bending the curve of land degradation to achieve global environmental goals",
    "source": "Nature"
  },
  {
    "title": "Establishment of chromatin architecture interplays with embryo hypertranscription",
    "title_es": "Establishment of chromatin architecture interplays with embryo hypertranscription",
    "url": "https://www.nature.com/articles/s41586-025-09400-5",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Establishment of chromatin architecture interplays with embryo hypertranscription",
    "source": "Nature"
  },
  {
    "title": "Multiple oestradiol functions inhibit ferroptosis and acute kidney injury",
    "title_es": "Multiple oestradiol functions inhibit ferroptosis and acute kidney injury",
    "url": "https://www.nature.com/articles/s41586-025-09389-x",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Multiple oestradiol functions inhibit ferroptosis and acute kidney injury",
    "source": "Nature"
  },
  {
    "title": "Human emissions drive recent trends in North Pacific climate variations",
    "title_es": "Human emissions drive recent trends in North Pacific climate variations",
    "url": "https://www.nature.com/articles/s41586-025-09368-2",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Human emissions drive recent trends in North Pacific climate variations",
    "source": "Nature"
  },
  {
    "title": "Elementary 3D organization of active and silenced E. coli genome",
    "title_es": "Elementary 3D organization of active and silenced E. coli genome",
    "url": "https://www.nature.com/articles/s41586-025-09396-y",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Elementary 3D organization of active and silenced E. coli genome",
    "source": "Nature"
  },
  {
    "title": "The genomic origin of the unique chaetognath body plan",
    "title_es": "The genomic origin of the unique chaetognath body plan",
    "url": "https://www.nature.com/articles/s41586-025-09403-2",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "The genomic origin of the unique chaetognath body plan",
    "source": "Nature"
  },
  {
    "title": "Delocalized electrolyte design enables 600 Wh kg−1 lithium metal pouch cells",
    "title_es": "Delocalized electrolyte design enables 600 Wh kg−1 lithium metal pouch cells",
    "url": "https://www.nature.com/articles/s41586-025-09382-4",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Delocalized electrolyte design enables 600 Wh kg−1 lithium metal pouch cells",
    "source": "Nature"
  },
  {
    "title": "n-Type thermoelectric elastomers",
    "title_es": "n-Type thermoelectric elastomers",
    "url": "https://www.nature.com/articles/s41586-025-09387-z",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "n-Type thermoelectric elastomers",
    "source": "Nature"
  },
  {
    "title": "Calving-driven fjord dynamics resolved by seafloor fibre sensing",
    "title_es": "Calving-driven fjord dynamics resolved by seafloor fibre sensing",
    "url": "https://www.nature.com/articles/s41586-025-09347-7",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Calving-driven fjord dynamics resolved by seafloor fibre sensing",
    "source": "Nature"
  },
  {
    "title": "Countrywide natural experiment links built environment to physical activity",
    "title_es": "Countrywide natural experiment links built environment to physical activity",
    "url": "https://www.nature.com/articles/s41586-025-09321-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Countrywide natural experiment links built environment to physical activity",
    "source": "Nature"
  },
  {
    "title": "Large riverbed sediment flux sustained for a decade after an earthquake&#xa0;",
    "title_es": "Large riverbed sediment flux sustained for a decade after an earthquake&#xa0;",
    "url": "https://www.nature.com/articles/s41586-025-09354-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Large riverbed sediment flux sustained for a decade after an earthquake&#xa0;",
    "source": "Nature"
  },
  {
    "title": "Photophoretic flight of perforated structures in near-space conditions",
    "title_es": "Photophoretic flight of perforated structures in near-space conditions",
    "url": "https://www.nature.com/articles/s41586-025-09281-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Photophoretic flight of perforated structures in near-space conditions",
    "source": "Nature"
  },
  {
    "title": "Watch rappelling robots dive into a lava tube — for science",
    "title_es": "Watch rappelling robots dive into a lava tube — for science",
    "url": "https://www.nature.com/articles/d41586-025-02585-9",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Watch rappelling robots dive into a lava tube — for science",
    "source": "Nature"
  },
  {
    "title": "These tiny flyers levitate on the Sun’s heat alone",
    "title_es": "These tiny flyers levitate on the Sun’s heat alone",
    "url": "https://www.nature.com/articles/d41586-025-02576-w",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "These tiny flyers levitate on the Sun’s heat alone",
    "source": "Nature"
  },
  {
    "title": "Many planets might be born with orbits misaligned from the spin of their stars",
    "title_es": "Many planets might be born with orbits misaligned from the spin of their stars",
    "url": "https://www.nature.com/articles/d41586-025-02536-4",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Many planets might be born with orbits misaligned from the spin of their stars",
    "source": "Nature"
  },
  {
    "title": "Null empathy",
    "title_es": "Null empathy",
    "url": "https://www.nature.com/articles/d41586-025-02489-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Null empathy",
    "source": "Nature"
  },
  {
    "title": "A humidity measure that accounts for redistribution of water across the landscape",
    "title_es": "A humidity measure that accounts for redistribution of water across the landscape",
    "url": "https://www.nature.com/articles/d41586-025-02539-1",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "A humidity measure that accounts for redistribution of water across the landscape",
    "source": "Nature"
  },
  {
    "title": "Just how bad will climate change get? The only way to know is to fund basic research",
    "title_es": "Just how bad will climate change get? The only way to know is to fund basic research",
    "url": "https://www.nature.com/articles/d41586-025-02508-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Just how bad will climate change get? The only way to know is to fund basic research",
    "source": "Nature"
  },
  {
    "title": "The perplexing body plan of arrow worms decoded",
    "title_es": "The perplexing body plan of arrow worms decoded",
    "url": "https://www.nature.com/articles/d41586-025-02423-y",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "The perplexing body plan of arrow worms decoded",
    "source": "Nature"
  },
  {
    "title": "Levitating platform could ride sunlight into the ‘ignorosphere’",
    "title_es": "Levitating platform could ride sunlight into the ‘ignorosphere’",
    "url": "https://www.nature.com/articles/d41586-025-02355-7",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Levitating platform could ride sunlight into the ‘ignorosphere’",
    "source": "Nature"
  },
  {
    "title": "How to thrive as a Latin American researcher abroad",
    "title_es": "How to thrive as a Latin American researcher abroad",
    "url": "https://www.nature.com/articles/d41586-025-02297-0",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "How to thrive as a Latin American researcher abroad",
    "source": "Nature"
  },
  {
    "title": "Is gravity quantum? Experiments could finally probe one of physics’ biggest questions",
    "title_es": "Is gravity quantum? Experiments could finally probe one of physics’ biggest questions",
    "url": "https://www.nature.com/articles/d41586-025-02509-7",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Is gravity quantum? Experiments could finally probe one of physics’ biggest questions",
    "source": "Nature"
  },
  {
    "title": "Octopus motion in the ocean tracked by a deep-sea 3D camera",
    "title_es": "Octopus motion in the ocean tracked by a deep-sea 3D camera",
    "url": "https://www.nature.com/articles/d41586-025-02542-6",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Octopus motion in the ocean tracked by a deep-sea 3D camera",
    "source": "Nature"
  },
  {
    "title": "Oestrogen defends against kidney damage caused by iron-dependent cell death",
    "title_es": "Oestrogen defends against kidney damage caused by iron-dependent cell death",
    "url": "https://www.nature.com/articles/d41586-025-02422-z",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Oestrogen defends against kidney damage caused by iron-dependent cell death",
    "source": "Nature"
  },
  {
    "title": "Air pollution could be reduced by incentivizing local government officials to control crop burning",
    "title_es": "Air pollution could be reduced by incentivizing local government officials to control crop burning",
    "url": "https://www.nature.com/articles/d41586-025-02545-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Air pollution could be reduced by incentivizing local government officials to control crop burning",
    "source": "Nature"
  },
  {
    "title": "Science Translational Medicine: Una técnica de imagen disponible en hospitales y usada en cáncer mejora el seguimiento y tratamiento de la aterosclerosis  ",
    "title_es": "Science Translational Medicine: Una técnica de imagen disponible en hospitales y usada en cáncer mejora el seguimiento y tratamiento de la aterosclerosis  ",
    "url": "https://www.cnic.es/es/noticias/science-translational-medicine-tecnica-imagen-disponible-hospitales-usada-cancer-mejora",
    "published": "2025-08-13T18:00:47.000Z",
    "date": "2025-08-13",
    "content_es": "12/08/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nEl 18FDG-PET es una técnica de tomografía por emisión de positrones que mide la  cantidad de energía que consumen las células del cuerpo\n\n\n\nUna investigación realizada en el Centro Nacional de Investigaciones Cardiovasculares (CNIC) demuestra que el 18FDG-PET, una técnica de imagen utilizada habitualmente para otras patologías y que mide la energía que consumen las células del cuerpo, también permite monitorizar la actividad de la aterosclerosis midiendo el metabolismo celular de las placas. El hallazgo, publicado en Science Translational Medicine, podría mejorar el seguimiento de esta enfermedad y acelerar el desarrollo de nuevos tratamientos.\nLa aterosclerosis, causa principal de la mayoría de los infartos e ictus, es una enfermedad silenciosa que progresa durante años sin causar síntomas. Se caracteriza por la acumulación de placas de lípidos, células y otras sustancias en las paredes de las arterias, que pueden obstruir el flujo sanguíneo o romperse repentinamente, provocando eventos cardiovasculares graves. Aunque existen tratamientos eficaces para frenar su avance, sigue siendo difícil evaluar con precisión si una intervención médica está funcionando en los pacientes.\nEl 18FDG-PET es una técnica de tomografía por emisión de positrones que utiliza un derivado de la glucosa marcado radiactivamente para detectar la actividad metabólica de los tejidos.\nEn este nuevo estudio, los autores muestran que la señal detectada en un examen de 18FDG-PET refleja el metabolismo celular de las lesiones ateroscleróticas y no únicamente la presencia de inflamación, como se pensaba hasta ahora.\nPara llegar a esta conclusión, el equipo desarrolló un modelo experimental de aterosclerosis avanzada en animales transgénicos, cuya enfermedad pudo revertirse parcialmente mediante una intervención dietética y farmacológica similar a la aplicada en los pacientes.\n\nDurante el proceso de regresión de la enfermedad, la señal obtenida por 18FDG-PET disminuyó de manera significativa, paralelamente a la reducción de genes relacionados con el metabolismo de la glucosa en diversos tipos celulares de la placa, incluidos macrófagos, linfocitos y células musculares lisas.\n“La técnica 18FDG-PET refleja el nivel de actividad de las células de la lesión aterosclerótica, y por tanto puede servir como una herramienta sensible para evaluar el efecto de tratamientos o el riesgo de progresión de la enfermedad”, explica Paula Nogales, investigadora del CNIC y autora principal del trabajo, junto a Jacob Bentzon, líder del grupo en el CNIC y la Universidad de Aarhus (Dinamarca).\nEste hallazgo abre la puerta a aprovechar una técnica ya disponible en muchos hospitales para mejorar el seguimiento clínico de la aterosclerosis y acelerar el desarrollo de nuevos tratamientos dirigidos a esta enfermedad silenciosa pero potencialmente mortal.\nEste trabajo ha recibido financiación del European Research Council (ERC) en el marco del programa de investigación e innovación Horizon 2020 de la Unión Europea; del Ministerio de Economía, Industria y Competitividad (MEIC), con cofinanciación del Fondo Europeo de Desarrollo Regional (FEDER); del Instituto de Salud Carlos III con cofinanciación FEDER/Europa (“Una manera de hacer Europa”); de la Comunidad de Madrid, y de la Fundación ”la Caixa” (AtheroConvergence).\n\nNogales, P., Velasco, C., González-Cintado, L., Sharysh, D., Mota-Cobián, A., Izquierdo-Serrano, R., Torroja, C., del Rio-Aledo, D., Morales-Cano, D., Mota, R. A., Benguría, A., Dopazo, A., Sánchez-Cabo, F., Vázquez, J., España, S., Carramolino, L., Mateo, J., & Bentzon, J. F. (2025). Atherosclerotic disease activity is associated with glycolytic enzyme expression across multiple cell types and is trackable by FDG-PET. Science Translational Medicine. https://doi.org/10.1126/scitranslmed.ado6467",
    "source": "CNIC"
  },
  {
    "title": "Science Translational Medicine: A hospital imaging technique used in cancer care improves the monitoring and treatment of atherosclerosis",
    "title_es": "Science Translational Medicine: A hospital imaging technique used in cancer care improves the monitoring and treatment of atherosclerosis",
    "url": "https://www.cnic.es/es/node/235897",
    "published": "2025-08-13T18:00:47.000Z",
    "date": "2025-08-13",
    "content_es": "12/08/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nEl 18FDG-PET is a type of positron emission tomography that measures how much energy the body’s cells consume.\n\n\n\nScientists at the Centro Nacional de Investigaciones Cardiovasculares (CNIC) have shown that 18FDG-PET, an imaging technique widely used to study other conditions, can also be used to monitor atherosclerosis by measuring cellular metabolism within arterial plaques. The findings, published in Science Translational Medicine, could improve the clinical management of this disease and accelerate the development of new treatments.\nAtherosclerosis—the underlying cause of most heart attacks and strokes—is a silent disease that progresses over many years without symptoms. The disease is characterized by the accumulation of fatty deposits, cells, and other materials in the walls of arteries, where they reduce blood flow and can eventually rupture, triggering serious cardiovascular events. While treatments are available to slow disease progression, it is still difficult to determine if a treatment is working in individual patients.\n18FDG-PET (fluorodeoxyglucose positron emission tomography) is a nuclear imaging technique that uses a radioactively labeled glucose analog to detect tissue metabolic activity.\nThe new study demonstrates that the 18FDG-PET signal reflects the metabolic activity of atherosclerotic plaques, rather than merely indicating inflammation, as was previously believed.\nTo reach this conclusion, the research team developed an experimental model of advanced atherosclerosis in genetically modified animals and was able to partially reverse disease progression using a diet and drug-based intervention similar to strategies used in clinical care.\n\nAs the disease regressed, the 18FDG-PET signal declined in parallel with the reduced expression of genes linked to glucose metabolism in various plaque cell types, including macrophages, lymphocytes, and smooth muscle cells.\n“The 18FDG-PET signal reflects the activity level of the cells within atherosclerotic lesions and can therefore serve as a sensitive tool for evaluating treatment efficacy and disease progression risk,” explains CNIC researcher Paula Nogales, lead author of the study together with Jacob Bentzon, of Aarhus University (Denmark) and head of the Experimental Pathology of Atherosclerosis group at the CNIC.\nThis discovery opens the door to using a widely available hospital imaging technique to improve clinical monitoring of atherosclerosis and speed the development of new therapies for this silent but potentially deadly disease.\nThe study received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme; the Spanish Ministry of Economy, Industry, and Competitiveness (MEIC), with co-funding from the European Regional Development Fund (FEDER); the Instituto de Salud Carlos III, with FEDER/EU co-funding; the Madrid regional government; and the “la Caixa” Foundation (AtheroConvergence).\n\nNogales, P., Velasco, C., González-Cintado, L., Sharysh, D., Mota-Cobián, A., Izquierdo-Serrano, R., Torroja, C., del Rio-Aledo, D., Morales-Cano, D., Mota, R. A., Benguría, A., Dopazo, A., Sánchez-Cabo, F., Vázquez, J., España, S., Carramolino, L., Mateo, J., & Bentzon, J. F. (2025). Atherosclerotic disease activity is associated with glycolytic enzyme expression across multiple cell types and is trackable by FDG-PET. Science Translational Medicine. https://doi.org/10.1126/scitranslmed.ado6467",
    "source": "CNIC"
  },
  {
    "title": "Use AI in the classroom to bring problems to life",
    "title_es": "Use AI in the classroom to bring problems to life",
    "url": "https://www.nature.com/articles/d41586-025-02571-1",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Use AI in the classroom to bring problems to life",
    "source": "Nature"
  },
  {
    "title": "Organs on chips could make biomedical research more equitable",
    "title_es": "Organs on chips could make biomedical research more equitable",
    "url": "https://www.nature.com/articles/d41586-025-02569-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Organs on chips could make biomedical research more equitable",
    "source": "Nature"
  },
  {
    "title": "Europe must safeguard climate data following NASA cuts",
    "title_es": "Europe must safeguard climate data following NASA cuts",
    "url": "https://www.nature.com/articles/d41586-025-02572-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Europe must safeguard climate data following NASA cuts",
    "source": "Nature"
  },
  {
    "title": "Study how screen time affects circadian rhythms",
    "title_es": "Study how screen time affects circadian rhythms",
    "url": "https://www.nature.com/articles/d41586-025-02570-2",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Study how screen time affects circadian rhythms",
    "source": "Nature"
  },
  {
    "title": "How Paris dealt with lightning in the Age of Enlightenment",
    "title_es": "How Paris dealt with lightning in the Age of Enlightenment",
    "url": "https://www.nature.com/articles/d41586-025-02429-6",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "How Paris dealt with lightning in the Age of Enlightenment",
    "source": "Nature"
  },
  {
    "title": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "title_es": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "url": "https://www.nature.com/articles/d41586-025-02354-8",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "source": "Nature"
  },
  {
    "title": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "title_es": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "url": "https://www.nature.com/articles/d41586-025-02548-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "source": "Nature"
  },
  {
    "title": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "title_es": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "url": "https://www.nature.com/articles/d41586-025-02510-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Bird flu is ‘everywhere’ on dairy farms",
    "title_es": "Daily briefing: Bird flu is ‘everywhere’ on dairy farms",
    "url": "https://www.nature.com/articles/d41586-025-02579-7",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Daily briefing: Bird flu is ‘everywhere’ on dairy farms",
    "source": "Nature"
  },
  {
    "title": "AI content is tainting preprints: how moderators are fighting back",
    "title_es": "AI content is tainting preprints: how moderators are fighting back",
    "url": "https://www.nature.com/articles/d41586-025-02469-y",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "AI content is tainting preprints: how moderators are fighting back",
    "source": "Nature"
  },
  {
    "title": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "title_es": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "url": "https://www.nature.com/articles/d41586-025-02450-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "source": "Nature"
  },
  {
    "title": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "title_es": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "url": "https://www.nature.com/articles/d41586-025-02507-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "source": "Nature"
  },
  {
    "title": "Tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro!",
    "title_es": "Tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro!",
    "url": "https://www.cnio.es/noticias/nuevas-tesis-doctorales-en-el-cnio-enhorabuena-a-quienes-hacen-la-ciencia-del-futuro/",
    "published": "2025-08-12T18:11:56.000Z",
    "date": "2025-08-12",
    "content_es": "Charles Darwin ponía sus esperanzas en «naturalistas jóvenes y emergentes» que sabrían apreciar sus rompedoras ideas; a los veteranos no aspiraba a convencerlos, porque sus mentes «están repletas de datos que durante muchos años han sido analizados desde un punto de vista opuesto al mío», escribió en El Origen de las Especies–. El físico Max […]\nLa entrada Tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro! se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "title_es": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "url": "https://www.nature.com/articles/s41586-025-09407-y",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "source": "Nature"
  },
  {
    "title": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "title_es": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "url": "https://www.nature.com/articles/s41586-025-09485-y",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "source": "Nature"
  },
  {
    "title": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "title_es": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "url": "https://www.nature.com/articles/s41586-025-09464-3",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "source": "Nature"
  },
  {
    "title": "How does agricultural land become forest? I trek to find out",
    "title_es": "How does agricultural land become forest? I trek to find out",
    "url": "https://www.nature.com/articles/d41586-025-02517-7",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "How does agricultural land become forest? I trek to find out",
    "source": "Nature"
  },
  {
    "title": "How Indigenous values permeate my chemistry teaching and research",
    "title_es": "How Indigenous values permeate my chemistry teaching and research",
    "url": "https://www.nature.com/articles/d41586-025-02568-w",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "How Indigenous values permeate my chemistry teaching and research",
    "source": "Nature"
  },
  {
    "title": "Six questions to ask before jumping into a spreadsheet",
    "title_es": "Six questions to ask before jumping into a spreadsheet",
    "url": "https://www.nature.com/articles/d41586-025-02511-z",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Six questions to ask before jumping into a spreadsheet",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Political officials could control US federal science grants",
    "title_es": "Daily briefing: Political officials could control US federal science grants",
    "url": "https://www.nature.com/articles/d41586-025-02573-z",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Daily briefing: Political officials could control US federal science grants",
    "source": "Nature"
  },
  {
    "title": "Swift bricks, ancient tattoos and more: Books in brief",
    "title_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "url": "https://www.nature.com/articles/d41586-025-02556-0",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "source": "Nature"
  },
  {
    "title": "How animal paw pads got their toughness",
    "title_es": "How animal paw pads got their toughness",
    "url": "https://www.nature.com/articles/d41586-025-02474-1",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "How animal paw pads got their toughness",
    "source": "Nature"
  },
  {
    "title": "Can creativity in science be learnt? These researchers think so",
    "title_es": "Can creativity in science be learnt? These researchers think so",
    "url": "https://www.nature.com/articles/d41586-025-01913-3",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Can creativity in science be learnt? These researchers think so",
    "source": "Nature"
  },
  {
    "title": "Trump order gives political appointees vast powers over research grants",
    "title_es": "Trump order gives political appointees vast powers over research grants",
    "url": "https://www.nature.com/articles/d41586-025-02557-z",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Trump order gives political appointees vast powers over research grants",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: US researchers fight back on key climate report",
    "title_es": "Daily briefing: US researchers fight back on key climate report",
    "url": "https://www.nature.com/articles/d41586-025-02567-x",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Daily briefing: US researchers fight back on key climate report",
    "source": "Nature"
  },
  {
    "title": "Decolonize scientific institutions, don’t just diversify them",
    "title_es": "Decolonize scientific institutions, don’t just diversify them",
    "url": "https://www.nature.com/articles/d41586-025-02516-8",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Decolonize scientific institutions, don’t just diversify them",
    "source": "Nature"
  },
  {
    "title": "A rude awakening",
    "title_es": "A rude awakening",
    "url": "https://www.nature.com/articles/d41586-025-02488-9",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "A rude awakening",
    "source": "Nature"
  },
  {
    "title": "Roxie Laybourne, the first forensic ornithologist",
    "title_es": "Roxie Laybourne, the first forensic ornithologist",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx2662",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 582-582, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Revisiting the human sociobiology debate",
    "title_es": "Revisiting the human sociobiology debate",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady6081",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 580-581, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The membrane skeleton is constitutively remodeled in neurons by calcium signaling",
    "title_es": "The membrane skeleton is constitutively remodeled in neurons by calcium signaling",
    "url": "https://www.science.org/doi/abs/10.1126/science.adn6712",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice",
    "title_es": "Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp0240",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens",
    "title_es": "Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp0246",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli",
    "title_es": "An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp9583",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 618-622, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA",
    "title_es": "Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA",
    "url": "https://www.science.org/doi/abs/10.1126/science.ads3204",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Imaging collective quantum fluctuations of the structure of a complex molecule",
    "title_es": "Imaging collective quantum fluctuations of the structure of a complex molecule",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu2637",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 650-654, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Single-photon detection enabled by negative differential conductivity in moiré superlattices",
    "title_es": "Single-photon detection enabled by negative differential conductivity in moiré superlattices",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu5329",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 644-649, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Three-dimensional nucleation and growth of deformation twins in magnesium",
    "title_es": "Three-dimensional nucleation and growth of deformation twins in magnesium",
    "url": "https://www.science.org/doi/abs/10.1126/science.adv3460",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 632-636, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing",
    "title_es": "Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing",
    "url": "https://www.science.org/doi/abs/10.1126/science.adt2741",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 623-631, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Predicting expression-altering promoter mutations with deep learning",
    "title_es": "Predicting expression-altering promoter mutations with deep learning",
    "url": "https://www.science.org/doi/abs/10.1126/science.ads7373",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth",
    "title_es": "Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu0043",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 637-643, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The multifunctional immune system",
    "title_es": "The multifunctional immune system",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea8294",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 586-587, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Immune system influence on physiology",
    "title_es": "Immune system influence on physiology",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4380",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 594-599, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Sex differences in tissue-specific immunity and immunology",
    "title_es": "Sex differences in tissue-specific immunity and immunology",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4381",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 599-603, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Convergence and divergence of individual immune responses over the life course",
    "title_es": "Convergence and divergence of individual immune responses over the life course",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady9543",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 604-609, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Evolution of antiviral host defenses against a backdrop of endogenous retroelements",
    "title_es": "Evolution of antiviral host defenses against a backdrop of endogenous retroelements",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4379",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 588-593, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "How a diagnosis altered my path",
    "title_es": "How a diagnosis altered my path",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb1444",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 658-658, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "In Other Journals",
    "title_es": "In Other Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2040",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 611-612, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Moiré eyes detect the dim",
    "title_es": "Moiré eyes detect the dim",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea5235",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 570-570, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Opening the gateway to food-induced anaphylaxis",
    "title_es": "Opening the gateway to food-induced anaphylaxis",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz6439",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 573-574, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Hardening nature’s toughest teeth",
    "title_es": "Hardening nature’s toughest teeth",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8241",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 568-569, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Improving Alzheimer’s disease immunotherapy",
    "title_es": "Improving Alzheimer’s disease immunotherapy",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8959",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 571-572, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "NextGen Voices: National Assessments in Verse",
    "title_es": "NextGen Voices: National Assessments in Verse",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2043",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Brazil’s dangerous environmental licensing bill",
    "title_es": "Brazil’s dangerous environmental licensing bill",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea7981",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 583-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Community support for inclusive US education",
    "title_es": "Community support for inclusive US education",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz3963",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Brazil’s “devastation bill” empowers criminals",
    "title_es": "Brazil’s “devastation bill” empowers criminals",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz7734",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 583-583, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Study used DNA from thousands—without consent",
    "title_es": "Study used DNA from thousands—without consent",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2395",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 552-553, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Senate panel rejects Trump’s plan to slash NIH’s budget",
    "title_es": "Senate panel rejects Trump’s plan to slash NIH’s budget",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2396",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 554-555, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Thank ketchup, and interbreeding, for your French fries",
    "title_es": "Thank ketchup, and interbreeding, for your French fries",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2397",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 556-556, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Study reveals industrial-scale publishing fraud",
    "title_es": "Study reveals industrial-scale publishing fraud",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2398",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 557-558, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "AI-generated text surges in research papers",
    "title_es": "AI-generated text surges in research papers",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2399",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 558-559, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Losing protection",
    "title_es": "Losing protection",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2041",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 560-567, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Census in crisis—further erasure of Indigenous Peoples?",
    "title_es": "Census in crisis—further erasure of Indigenous Peoples?",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea0932",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "New Products",
    "title_es": "New Products",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb1446",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 655-655, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Quantum technology governance: A standards-first approach",
    "title_es": "Quantum technology governance: A standards-first approach",
    "url": "https://www.science.org/doi/abs/10.1126/science.adw0018",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 575-578, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "In Science Journals",
    "title_es": "In Science Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2039",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 610-612, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Globally recognized island is losing its trademark glaciers",
    "title_es": "Globally recognized island is losing its trademark glaciers",
    "url": "https://www.nature.com/articles/d41586-025-02473-2",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Globally recognized island is losing its trademark glaciers",
    "source": "Nature"
  },
  {
    "title": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "title_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "url": "https://www.nature.com/articles/d41586-025-02505-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "source": "Nature"
  },
  {
    "title": "How researcher visa curbs threaten science careers",
    "title_es": "How researcher visa curbs threaten science careers",
    "url": "https://www.nature.com/articles/d41586-025-02293-4",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "How researcher visa curbs threaten science careers",
    "source": "Nature"
  },
  {
    "title": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "title_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "url": "https://www.nature.com/articles/d41586-025-02512-y",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "source": "Nature"
  },
  {
    "title": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "title_es": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "url": "https://www.nature.com/articles/d41586-025-02515-9",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "source": "Nature"
  },
  {
    "title": "These genes can have the opposite effects depending on which parent they came from",
    "title_es": "These genes can have the opposite effects depending on which parent they came from",
    "url": "https://www.nature.com/articles/d41586-025-02499-6",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "These genes can have the opposite effects depending on which parent they came from",
    "source": "Nature"
  },
  {
    "title": "Alien planet glimpsed in star's 'habitable zone'",
    "title_es": "Alien planet glimpsed in star's 'habitable zone'",
    "url": "https://www.nature.com/articles/d41586-025-02549-z",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Alien planet glimpsed in star's 'habitable zone'",
    "source": "Nature"
  },
  {
    "title": "Monoclonal antibodies revolutionized biomedical science and health care",
    "title_es": "Monoclonal antibodies revolutionized biomedical science and health care",
    "url": "https://www.nature.com/articles/d41586-025-02452-7",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Monoclonal antibodies revolutionized biomedical science and health care",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "title_es": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "url": "https://www.nature.com/articles/d41586-025-02559-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "source": "Nature"
  },
  {
    "title": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "title_es": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "url": "https://www.nature.com/articles/s41586-025-09463-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "source": "Nature"
  },
  {
    "title": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "title_es": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "url": "https://www.nature.com/articles/s41586-025-09461-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "source": "Nature"
  },
  {
    "title": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "title_es": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "url": "https://www.cnic.es/es/node/235736",
    "published": "2025-08-01T12:08:23.000Z",
    "date": "2025-08-01",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDr. Claudia Monaco, Kennedy Institute of Rheumatology, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, University of Oxford, UK\n\n\n\nClaudia Monacoo trained as a cardiologist and PhD with Professor Attilio Maseri at the Catholic University of Rome, Italy, before moving to the Kennedy Institute of Rheumatology, Imperial College London to work with Professor Marc Feldmann. She moved to the University of Oxford in 2011, where she became Professor of Cardiovascular Inflammation. Her group was the first to establish innovative experimental methodology for the isolation, culture and targeting of live cells from human atheroma lesions. Her work allowed the elegant characterization of the inflammatory and synthetic properties of human atherosclerosis, establishing toll-like receptors as important activators of innate immunity in atherosclerosis. The Cardiovascular Inflammation Team is now focused on interpreting the functional diversity of immune cells in atherosclerosis with single cell biology techniques and devise strategies for their selective targeting.\n\nWhat is the role of macrophages in the development of atherosclerosis, and how has our understanding of their function evolved?\n\nWe are focused, in particular, on macrophages and what their function is in atherosclerosis. I think it’s quite interesting, because different types of macrophages have different functions in the development of atherosclerosis. Before, we thought that all macrophages were bad—that all macrophages and the whole immune system were actually promoting atherosclerosis. But now we know the picture is much more complex than that.\nIt’s very related to what macrophages are, where they’re seeded, and how they establish themselves in specific niches. There are some macrophages, like the lipid-associated macrophages, that definitely promote disease. But there are others—vascular macrophages that are already present within the vessel wall—that actually act like guardians of the artery and are protective.\nI think it’s very important—this direction we’re going in, toward more targeted therapies. The idea is not to block all macrophages, because some are actually your friends. You need to look after them, especially the ones in the artery, while others are really pushing things toward a dangerous, disease-promoting path. This duality is really important, especially from a therapeutic perspective. That’s why we’re so fixated on understanding this better.\n\nAnd how can you tell the difference between the “good” macrophages and the ones you want to block? What kind of techniques do you use?\n\nWe use single-cell biology a lot. We’re not yet in the clinical space, but we’ve identified good markers. If those markers prove reliable, it would be easy to translate this into new tools to look at different macrophages in vivo. There’s also the potential to tailor imaging—not just therapeutics, but also how we visualize these macrophages.\nThe key idea we want to get across is that there isn’t just “one” macrophage type. We always said that macrophages are very pleiotropic—that they can take on different phenotypes—but that didn’t always seem to matter because we thought they all eventually just changed into each other. But actually, that’s not quite true.\nThere is some dynamic flexibility, yes, but it's quite reproducible which path they take. They really adapt specifically to their environment. For example, in the adventitia, they adopt a very specific phenotype, and in the intima, a different one. And these phenotypes remain pretty stable during atherosclerosis, and also in health and disease. They’re not just switching randomly between states, they’re adapting in a niche-specific way, just like cells in any other organ. That’s important because it means we can start visualizing and treating patients differently more precisely.\n\nYou mentioned you're still in the experimental phase and not yet in clinical trials. How far is immunotherapy for cardiovascular disease?\n\nI think there have been some early trials, and there are more and more now that are targeting inflammation in atherosclerosis. It’s really a booming field. We waited a long time to get here. The field was slow to move in this direction because so much focus was on lowering cholesterol, which is of course important—but inflammation wasn’t really explored until recently.\nStudies like the CANTOS trial and others have started targeting cytokines, and I think we are going in the right direction. But progress is still very slow. One big reason is the lack of imaging tools. Imaging is only now reaching the level where we can maybe use it instead of relying on hard cardiovascular outcomes in trials.\nIf you look at cancer, for example, you can track things much faster, look at the size of the tumor, and see how the patient is responding. Same for diseases like rheumatoid arthritis, where you can scan the joints or use PET imaging. Those imaging methods have been around for decades, and they’ve made it possible to run smaller trials that are either based on imaging or give you very clear, early outcomes.\nBut with cardiovascular disease, we still have to look at how patients are doing over 5, 10 years. That’s a big challenge. These trials are very expensive, especially because biologic drugs cost so much. So pharmaceutical companies need to make a huge financial commitment. The more we can improve imaging, the more we’ll be able to run meaningful trials that evaluate new biologics or targeted agents, like nanotechnology-based ones.\nI think evolution isn’t just about immunology, it’s also about how we study this in the real world. Other fields can run smaller trials to understand how things work and then move on to larger outcome trials. But here, with trials like the CANTOS trial—which involved over 10,000 patients and a very expensive biologic—that kind of scale is almost unheard of in other diseases like rheumatoid arthritis.\nSo yes, the challenges are really at the clinical stage—how we bring all this incredible knowledge about the immune system into cardiovascular medicine. The real barrier is economic.\n\nYou’re a cardiologist—you worked in Rome for many years, and then you moved to Oxford. You trained as a cardiologist, and then you also shifted into doing experiments and research. How do you combine these two areas?\n\nWell, combining clinical duties and research is one of the biggest challenges you can attempt to do.  I think if you’re doing clinical research—like outcomes-based research or imaging studies—then it’s easier to combine with clinical work. But if you’re developing science at the molecular level, it’s much harder to do both. At least I couldn’t manage it as well as I would have liked.\nThere’s a big divide between what we think we know and what we actually know. We have this concept of how atherosclerosis develops, how the immune system contributes—but in reality, we don’t really understand the specific mechanisms at play. I felt that, to bridge this gap, I had to go back to the basics. That meant not only using experimental models but also working with human samples. I saw a huge opportunity in single-cell biology has been a big opportunity—for all of us—to understand human immunology at a very detailed level. Because if we only look at mice, then the gap between mouse and human, and then from preclinical to clinical stages, is massive.\nFor example, we really need access to human vascular tissue. But as cardiologists, we’ve moved so much toward percutaneous approaches to the coronary arteries, so we don’t actually remove them anymore. That’s why I work a lot with vascular surgeons. They still operate in a way that allows us to obtain human tissue—but that might not last. Even vascular surgery is moving more and more toward stenting, which means we’ll eventually lose the ability to get that tissue. We have this narrow window of opportunity where we can still work with tissue from patients, and I felt I had to take it. I’m very vocal about this having a short window before vascular surgery becomes entirely percutaneous, \n\nIt seems like improvements in clinical treatment are making things harder for basic science in a way.\n\nExactly. It’s advancing, but at the same time, it means that now we have this critical window. I always say vascular surgeons do research, collect tissue, because we need to analyze what the cells are really doing. Just relying on blood studies, on systemic inflammation, doesn’t tell us much about what’s happening in the atherosclerotic artery. The immune cells inside the artery are very different in their programming compared to circulating cells in the blood.\nMost cells come from the blood—but there are also some embryonic macrophages that form inside the artery and never circulate. And even the ones that come from the blood and stay in the artery for 10 years, they acquire very specialized instructions. You can take monocytes from blood and run as many blood tests as you want—but that doesn’t tell you what’s actually happening inside the artery.\nThey behave differently, they look different, they’ve changed their shape and function completely. This creates a gap in what we can understand—it seems like we’re missing something in these studies . We can’t see all the different effects a drug might have if we only look at peripheral blood. I think the real answers are also in the vascular tissue, in the atherosclerotic plaque itself. We need to go as close to the source as possible—to find real targets, and to see the real effects of drugs on atherosclerotic tissue.\nBecause a lot of clinical trials have targeted systemic inflammation. But that’s not the same as inflammation within the plaque. The drivers of plaque inflammation may be different.\nWe know systemic inflammation is a risk factor, yes, but what you see in the blood isn’t necessarily what’s happening in the plaque. We often assume it is—because it’s convenient. But in cardiovascular disease, especially cardiology, we never actually look at the plaque. We look at the lumen. Intravascular ultrasound (IVUS) is the only way to get a glimpse of the arterial wall. Experimentally, we might look at blood from the heart in very complex ways—but we’re still mainly looking at circulating markers. We’re not really studying the tissue itself.\n\n\nAs a cardiologist with experience of treating patients, do you think your clinical background influences the kinds of research questions you ask?\n\nYes. And there are two things that help me a lot, I think. And that’s why I never stop clinics, even though they told me several times to stop clinics. I think I... I don’t like to stop the clinics because I enjoy that interaction.\nI think, being a scientist, your rewards are very long-term. If you’re a doctor, the rewards are quite immediate, because the patient is happier, yes—you can give the treatment. So, I think it gives me a lot of motivation to serve the patient. But at the same time, I think research is also a good way to serve patients.\nBecause as a clinician I’ve learned a lot from basic scientists. They’re much better at developing techniques at the bench, and so I have great respect for my scientific colleagues. But sometimes, as a clinician, you can see what really matters. And it makes you particularly attached to a specific disease, you know? Basic scientists are sometimes across fields. This study gives me the determination and the drive to really try and solve atherosclerosis.",
    "source": "CNIC"
  },
  {
    "title": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "title_es": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "url": "https://www.cnic.es/es/noticias/dra-claudia-monaco-enfermedades-cardiovasculares-pensamos-que-sabemos-mucho-pero-realidad",
    "published": "2025-08-01T11:49:01.000Z",
    "date": "2025-08-01",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDra. Claudia Monaco:  Instituto Kennedy de Reumatología, Departamento Nuffield de Ortopedia, Reumatología y Ciencias Musculoesqueléticas, Universidad de Oxford, Reino Unido\n\n\n\nClaudia Monaco se formó como cardióloga y doctoró con el profesor Attilio Maseri en la Universidad Católica de Roma, Italia, antes de trasladarse al Instituto Kennedy de Reumatología del Imperial College de Londres para trabajar con el profesor Marc Feldmann. En 2011 se trasladó a la Universidad de Oxford, donde se convirtió en profesora de Inflamación Cardiovascular. Su grupo fue el primero en establecer una metodología experimental innovadora para el aislamiento, cultivo y selección de células vivas de lesiones ateromatosas humanas. Su trabajo permitió caracterizar de forma elegante las propiedades inflamatorias y sintéticas de la aterosclerosis humana, estableciendo los receptores toll-like como activadores importantes de la inmunidad innata en la aterosclerosis. Su grupo de inflamación cardiovascular se centra ahora en interpretar la diversidad funcional de las células inmunitarias en la aterosclerosis con técnicas de biología celular única y en diseñar estrategias para su selección selectiva.\n\n¿Cuál es el papel de los macrófagos en el desarrollo de la aterosclerosis y cómo ha evolucionado nuestra comprensión de su función?\n\nNos centramos, en particular, en los macrófagos y en cuál es su función en la aterosclerosis. Es muy interesante porque los diferentes tipos de macrófagos tienen diferentes funciones en el desarrollo de la aterosclerosis. Antes pensábamos que todos los macrófagos eran malos, que todos los macrófagos y todo el sistema inmunitario favorecían la aterosclerosis. Pero ahora sabemos que el panorama es mucho más complejo.\nEstá muy relacionado con lo que son los macrófagos, dónde se siembran y cómo se establecen en nichos específicos. Hay algunos macrófagos, como los macrófagos asociados a los lípidos, que sin duda favorecen la enfermedad. Pero hay otros, los macrófagos vasculares que ya están presentes en la pared de los vasos, que en realidad actúan como guardianes de la arteria y la protegen.\nCreo que es muy importante la dirección que estamos tomando, hacia terapias más específicas. La idea no es bloquear todos los macrófagos, porque algunos son realmente nuestros aliados. Hay que cuidarlos, especialmente los que se encuentran en las arterias, mientras que otros realmente empujan hacia un camino peligroso que favorece la enfermedad. Esta dualidad es muy importante, especialmente desde el punto de vista terapéutico. Por eso estamos tan obsesionadas con comprenderlo mejor.\n\n¿Cómo se puede distinguir entre los macrófagos «buenos» y los que se quieren bloquear? ¿Qué tipo de técnicas se utilizan?\n\nUtilizamos mucho la biología unicelular. Aún no estamos en el ámbito clínico, pero hemos identificado buenos marcadores. Si esos marcadores resultan fiables, sería fácil traducirlos en nuevas herramientas para observar diferentes macrófagos in vivo. También existe la posibilidad de adaptar las imágenes, no solo las terapéuticas, sino también la forma en que visualizamos estos macrófagos.\nLa idea clave que queremos transmitir es que no existe un único tipo de macrófago. Siempre hemos dicho que los macrófagos son muy pleiotrópicos, es decir, que pueden adoptar diferentes fenotipos, pero eso no siempre parecía importar porque pensábamos que, al final, todos se transformaban unos en otros. Pero, en realidad, eso no es del todo cierto.\nHay cierta flexibilidad dinámica, sí, pero la trayectoria que siguen es bastante reproducible. Se adaptan específicamente a su entorno. Por ejemplo, en la adventicia adoptan un fenotipo muy específico, y en la íntima, otro diferente. Y estos fenotipos se mantienen bastante estables durante la aterosclerosis, así como en la salud y la enfermedad. No cambian aleatoriamente entre estados, sino que se adaptan de forma específica a cada nicho, al igual que las células de cualquier otro órgano. Esto es importante porque significa que podemos empezar a visualizar y tratar a los pacientes de forma diferente y más precisa.\n\nHa mencionado que aún se encuentra en la fase experimental y que aún no se han realizado ensayos clínicos. ¿En qué punto se encuentra la inmunoterapia para las enfermedades cardiovasculares?\n\nCreo que se han realizado algunos ensayos preliminares y ahora hay cada vez más estudios que se centran en la inflamación en la aterosclerosis. Es un campo en auge. Hemos esperado mucho tiempo para llegar hasta aquí. El campo tardó en avanzar en esta dirección porque se prestaba mucha atención a la reducción del colesterol, lo cual es importante, por supuesto, pero la inflamación no se ha explorado realmente hasta hace poco.\nEstudios como el ensayo CANTOS y otros han comenzado a centrarse en las citocinas, y creo que vamos en la dirección correcta. Pero el progreso sigue siendo muy lento. Una de las principales razones es la falta de herramientas de imagen. Las técnicas de imagen están alcanzando ahora un nivel en el que quizá podamos utilizarlas en lugar de basarnos en los resultados cardiovasculares de los ensayos.\nSi nos fijamos en el cáncer, por ejemplo, se puede hacer un seguimiento mucho más rápido, observar el tamaño del tumor y ver cómo responde el paciente. Lo mismo ocurre con enfermedades como la artritis reumatoide, en las que se pueden escanear las articulaciones o utilizar imágenes PET. Estos métodos de imagen llevan décadas utilizándose y han permitido realizar ensayos más pequeños basados en imágenes o que ofrecen resultados muy claros y tempranos.\nSin embargo, en el caso de las enfermedades cardiovasculares, todavía tenemos que observar cómo evolucionan los pacientes a lo largo de 5 o 10 años. Eso supone un gran reto. Estos ensayos son muy caros, sobre todo porque los medicamentos biológicos cuestan mucho. Por lo tanto, las empresas farmacéuticas deben asumir un enorme compromiso financiero. Cuanto más mejoremos las imágenes, más podremos realizar ensayos significativos que evalúen nuevos productos biológicos o agentes dirigidos, como los basados en la nanotecnología.\nCreo que la evolución no se limita a la inmunología, sino que también tiene que ver con cómo estudiamos esto en el mundo real. Otros campos pueden realizar ensayos más pequeños para comprender cómo funcionan las cosas y luego pasar a ensayos de resultados más amplios. Pero aquí, con ensayos como el CANTOS, en el que participaron más de 10.000 pacientes y se utilizó un fármaco biológico muy caro, ese tipo de escala es casi inaudito en otras enfermedades como la artritis reumatoide.\nAsí que sí, los retos se encuentran realmente en la fase clínica: cómo trasladar todos estos increíbles conocimientos sobre el sistema inmunitario a la medicina cardiovascular. La verdadera barrera es económica.\n\nUsted es cardióloga, trabajó en Roma durante muchos años y luego se trasladó a Oxford. Se formó como cardióloga y luego también pasó a dedicarse a la experimentación y la investigación. ¿Cómo combina estas dos áreas?\n\nCombinar las tareas clínicas y la investigación es uno de los mayores retos a los que te puedes enfrentar.  Creo que, si una se dedica a la investigación clínica, como la investigación basada en resultados o los estudios de imagen, es más fácil combinarla con el trabajo clínico. Pero si se trabaja más en el desarrollo científico a nivel molecular, es mucho más difícil compaginar ambas cosas. Al menos yo no pude hacerlo tan bien como me hubiera gustado.\n Existe una gran diferencia entre lo que creemos saber y lo que realmente sabemos. Tenemos una idea de cómo se desarrolla la aterosclerosis, cómo contribuye el sistema inmunitario, pero en realidad no entendemos los mecanismos específicos que intervienen. Sentí que, para salvar esta brecha, tenía que volver a lo básico. Eso significaba no solo utilizar modelos experimentales, sino también trabajar con muestras humanas. Vi una gran oportunidad en la biología de células individuales, que ha sido una gran oportunidad para todos nosotros para comprender la inmunología humana a un nivel muy detallado. Porque si solo nos fijamos en los ratones, la brecha entre estos y los seres humanos, y luego entre las etapas preclínicas y clínicas, es enorme.\nPor ejemplo, realmente necesitamos acceso al tejido vascular humano. Pero como cardiólogos, hemos avanzado tanto hacia los abordajes percutáneos de las arterias coronarias que ya no las extirpamos. Por eso trabajo mucho con cirujanos vasculares. Ellos siguen operando de una manera que nos permite obtener tejido humano, pero eso podría no durar mucho tiempo. Incluso la cirugía vascular se está orientando cada vez más hacia la implantación de stents, lo que significa que, con el tiempo, perderemos la capacidad de obtener ese tejido. Tenemos una ventana de oportunidad muy estrecha en la que todavía podemos trabajar con tejido de pacientes, y sentí que tenía que aprovecharla. Soy muy clara al afirmar que tenemos poco tiempo antes de que la cirugía vascular se vuelva completamente percutánea, lo que, por supuesto, es un avance, pero también nos priva de la oportunidad de estudiar tejidos humanos reales.\n\nParece que las mejoras en el tratamiento clínico están dificultando en cierto modo la ciencia básica.\n\nExactamente. Está avanzando, pero al mismo tiempo significa que ahora tenemos esta ventana crítica. Siempre digo que los cirujanos vasculares investigan y recogen tejido porque necesitamos analizar lo que realmente hacen las células. Basarnos únicamente en los análisis de sangre y en la inflamación sistémica no nos dice mucho sobre lo que está sucediendo en la arteria aterosclerótica. Las células inmunitarias del interior de la arteria son muy diferentes en su programación en comparación con las células circulantes en la sangre.\nLa mayoría de las células provienen de la sangre, pero también hay algunos macrófagos embrionarios que se forman dentro de la arteria y nunca circulan. E incluso los que provienen de la sangre y permanecen en la arteria durante 10 años, adquieren instrucciones muy especializadas. Se pueden extraer monocitos de la sangre y realizar tantos análisis de sangre como se desee, pero eso no revela lo que realmente ocurre dentro de la arteria.\nSe comportan de manera diferente, tienen un aspecto diferente, han cambiado completamente su forma y función. Esto crea una brecha en lo que podemos entender, parece que nos estamos perdiendo algo en estos estudios. No podemos ver todos los diferentes efectos que puede tener un fármaco si solo miramos la sangre periférica. Creo que las respuestas reales también se encuentran en el tejido vascular, en la propia placa aterosclerótica. Tenemos que acercarnos lo más posible a la fuente para encontrar los objetivos reales y ver los efectos reales de los fármacos en el tejido aterosclerótico.\nPorque muchos ensayos clínicos se han centrado en la inflamación sistémica. Pero eso no es lo mismo que la inflamación dentro de la placa. Los factores que provocan la inflamación de la placa pueden ser diferentes.\nSabemos que la inflamación sistémica es un factor de riesgo, sí, pero lo que se ve en la sangre no es necesariamente lo que ocurre en la placa. A menudo asumimos que lo es, porque es conveniente. Pero en las enfermedades cardiovasculares, especialmente en cardiología, nunca miramos realmente la placa. Miramos la luz. La ecografía intravascular (IVUS) es la única forma de echar un vistazo a la pared arterial.\nDesde el punto de vista experimental, podemos analizar la sangre del corazón de formas muy complejas, pero seguimos centrándonos principalmente en los marcadores circulantes. En realidad, no estamos estudiando el tejido en sí.\n\nComo cardióloga con experiencia en el tratamiento de pacientes, ¿cree que su experiencia clínica influye en el tipo de preguntas de investigación que se plantea?\n\nSí. Y hay dos cosas que me ayudan mucho. Por eso nunca dejo de ejercer en la clínica, aunque me han dicho varias veces que lo haga. Creo que... no me gusta dejar la clínica porque disfruto de esa interacción.\nComo científica, las recompensas son a muy largo plazo. Si eres médico, las recompensas son bastante inmediatas, porque el paciente está más contento si puedes darle el tratamiento. Por lo tanto, creo que me motiva mucho atender al paciente. Pero, al mismo tiempo, pienso que la investigación también es una buena forma de atender a los pacientes.\nPorque, como médico, he aprendido mucho de los científicos básicos. Son mucho mejores desarrollando técnicas en el laboratorio, por lo que siento un gran respeto por mis colegas científicos. Pero a veces, como médico clínico, puedes ver lo que realmente importa. Y eso te hace sentir especialmente vinculado a una enfermedad concreta. Los científicos básicos a veces abarcan varios campos. Este estudio me da la determinación y el impulso para intentar resolver realmente la aterosclerosis.\n\n\n¿De niña, se imaginó dedicándose a la ciencia o la medicina y, finalmente, a la investigación?\n\nSiempre quise ser médico. De niña era un poco enfermiza, así que probablemente estuve muy expuesta al entorno médico. Por eso, siempre decía que quería ser médico. Pero luego decepcioné a mi padre a largo plazo, porque él pensaba que me convertiría en médico, no sé, un médico generalista, y así podría tenerme muy cerca de su casa. Pero en cambio, mi carrera me llevó al extranjero. No creo que él estuviera muy contento con mi marcha.\nEn particular, cuando era joven no quería ser científica. Me fascinaban los médicos. Probablemente tenía ese sentido de ayudar a la gente, de servir a la gente. Para mí eso es muy importante. Aprendí todo sobre cardiología en Italia, con el profesor Attilio Maseri, que fue un gran precursor en este campo: la activación de las células inmunitarias, especialmente en el síndrome coronario agudo. Aprendí mucho de él y sigo llevando esa huella en mi trabajo.\nTambién trabajé con otros buenos mentores en el Reino Unido, como el profesor Mark Feldman, y aprendí mucho de él sobre el sistema inmunitario y cómo detener la inflamación. Hago todo lo posible por seguir los pasos de estos dos gigantes para comprender el funcionamiento del sistema inmunitario en las arterias, tanto en la salud como en la enfermedad.\nMe encuentro en un entorno de reumatología e inmunología que también realiza investigaciones cardiovasculares. Puedo permanecer entre ambos campos, lo que me beneficia enormemente, ya que siempre estoy en la interfaz entre los inmunólogos y los especialistas cardiovasculares. Y creo que esto es algo bastante único. Es bastante difícil de replicar en todas partes.\nAhora, la inmunología cardiovascular se está consolidando cada vez más y habrá cada vez más interfaces de este tipo. Como la que hay aquí, en el CNIC, donde hay más interfaces de este tipo. Así que todo esto se está formando. Este es el futuro.\nCuando empecé, no se podía hacer esta combinación en ningún sitio. Por lo tanto, mis opciones estaban bastante limitadas. Ahora, tal vez podría plantearme mudarme a algún lugar de Europa, Estados Unidos, volver a Italia, si hay una estructura de financiación que permita el mismo nivel. Pero, por supuesto, ya sabes, en este momento hay problemas con la financiación en todos los países. Así que es un poco optimista. No iría a Italia solo por ir a Italia. El trabajo es muy importante para mí y necesito tener la combinación adecuada para mudarme a cualquier lugar.\n\nQuizás, primero podría venir aquí para investigar en el CNIC.\n\nSí, exactamente. ¿Por qué no? ¿Por qué no?\n\nHa mencionado que ha tenido muy buenos mentores en su carrera, y supongo que todavía los tiene. Pero ahora también asume esa función de mentoría con los estudiantes en su laboratorio. Entonces, ¿qué diferencias encuentra entre cuando era joven y estos jóvenes estudiantes de hoy?\n\nEsta es una pregunta difícil, porque es una pregunta en la que se pueden tomar dos caminos completamente diferentes. Uno sería: antes trabajábamos mucho más duro, y eso me molesta. No me agradan las personas que siguen ese camino. No me gusta decirlo, pero al final yo también lo sigo: antes nos quedábamos en el laboratorio hasta tarde...\nCreo que los nuevos estudiantes tienen una capacidad mucho mayor. Las nuevas generaciones son más completas en el sentido de que no quieren perderse por completo en el trabajo o la investigación, y creo que esto es algo positivo para sus vidas, sin duda. Considero que ese cambio es muy importante. Quizás porque en Oxford existe la tradición de que hay que tener una vida social en la universidad. Organizan actividades. Intentan crear un entorno en el que los estudiantes, incluso los de posgrado, puedan socializar si lo desean. Me gusta esa cultura. Y esto es típico de Oxford, y me encanta.\nPorque pueden hacer muchas cosas que yo no hice. Ya sabes, en nuestra época, existía la idea de que había que negarse a uno mismo, dedicarse a la disciplina sin límites, y creo que eso no es bueno a largo plazo.\nPero yo diría que las nuevas generaciones suelen conocer muy bien su tema, pero quizá no amplían sus horizontes tanto como deberían, no sienten curiosidad por otras disciplinas. Y yo lucho mucho contra eso. Ya sabes, se meten de lleno en su área, obtienen el doctorado, hacen la defensa de la tesis y solo saben eso. Ahora hay muchas áreas de interés a nuestro alcance. Probablemente, como consecuencia, perdieron muchas cosas. Pero siempre intento decirles que es importante ver cómo evolucionan otros campos. Quizás haya una idea que necesites. Quizás haya un camino que no habías pensado, pero que es importante en el cáncer y quizás también lo sea en las enfermedades cardiovasculares.\nSiempre pienso que, si estás en la interfaz entre dos campos, avanzas más rápido. Porque puedes aprender, otros colegas pueden inspirarte. Así que no te fijes solo en lo tuyo.\nY otra cosa que siempre les digo es que creo que, en las enfermedades cardiovasculares, pensamos que sabemos mucho. Pero en realidad, no es así. Y siempre tenemos que revisar las pruebas.\n\nEs posible que tengan una nueva forma, diferente, de ver sus vidas y sus carreras.\n\nSí, pero también, incluso en el campo del conocimiento de la aterosclerosis, siempre enseñamos a los estudiantes: así es como evoluciona la aterosclerosis. En realidad, las pruebas para nuestro modelo siempre son muy dispersas. Porque pueden estar en ratones o en otro sistema. Pero cómo es en los seres humanos, realmente no lo sabemos. Así que estad siempre preparados para cuestionar vuestras suposiciones. No sigáis siempre lo que os dicen los demás. Debéis tener vuestras propias ideas. Y siempre tenéis que desafiar el paradigma.",
    "source": "CNIC"
  },
  {
    "title": "The Columbia deal is a tragic wake-up call",
    "title_es": "The Columbia deal is a tragic wake-up call",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb0424",
    "published": "2025-07-31T06:00:37.000Z",
    "date": "2025-07-31",
    "content_es": "Science, Volume 389, Issue 6760, Page 551-551, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "title_es": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "url": "https://www.cnio.es/noticias/un-investigador-del-cnio-desarrolla-una-prueba-capaz-de-detectar-tumores-en-estadios-iniciales-con-una-muestra-de-sangre/",
    "published": "2025-07-31T10:48:44.000Z",
    "date": "2025-07-31",
    "content_es": "Los métodos actuales para diagnosticar el cáncer se basan en identificar marcadores –moléculas que indican un estado o proceso determinado del organismo– que provienen del tumor o de proteínas asociadas a él. Como es lógico, esos marcadores son más abundantes cuando el tumor ya se ha desarrollado de forma significativa. Y, cuanto más avanzado el […]\nLa entrada Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "CNIC en la Noche Europea de los Investigadores 2025",
    "title_es": "CNIC en la Noche Europea de los Investigadores 2025",
    "url": "https://www.cnic.es/es/noticias/cnic-noche-europea-investigadores-2025",
    "published": "2025-07-17T22:35:42.000Z",
    "date": "2025-07-17",
    "content_es": "14/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nVen al CNIC el próximo viernes 26 de septiembre con motivo de la XVI Noche Europea de los Investigadores de Madrid. Podrás participar en distintas actividades que te acercarán a la investigación que se realiza en el centro.\nLa Noche Europea de los Investigadores en el CNIC es una oportunidad de sumergirte en el emocionante mundo de la ciencia y la innovación. Desde experimentos asombrosos hasta conferencias inspiradoras, CNIC te brindará una ventana a los descubrimientos más recientes y las maravillas de la tecnología.\nPara asistir es necesario inscribirse en el siguiente link: https://www.cnic.es/es/solicitud-inscripcion-xvi-noche-europea-investigadores \nLa inscripción se abre el lunes 15 de septiembre a partir de las 9:00 hrs.\nTodas las actividades se llevarán a cabo en el Centro Nacional de Investigaciones Cardiovasculares (CNIC): C. de Melchor Fernández Almagro, 3, 28029 Madrid.\nInformación actividades:\n10:30 - 12:30 h. Enfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nPúblico: juvenil (desde 12 años) y adultos.\nEl principal objetivo de esta actividad es sensibilizar sobre los muchos desafíos que enfrentan los pacientes con enfermedades raras, y explicar cómo la investigación básica, utilizando modelos animales adecuados, es esencial para avanzar en la comprensión de estas enfermedades y encontrar terapias potenciales que permitan aliviar o curar a estos pacientes. Con este propósito, se organizan dos actividades: una charla de divulgación en lenguaje accesible; y una demostración en el laboratorio que permitirá a las personas participantes familiarizarse con técnicas utilizadas rutinariamente en la investigación básica para responder preguntas científicas relevantes en el estudio de enfermedades raras.\n10:30 - 13:30 h. ¿Cómo late nuestro corazón? Grupo: Silvia Priori.\nPúblico: juvenil (desde 12 años) y adultos.\nEsta actividad tiene como objetivo explicar cómo late el corazón, desde el nivel subcelular hasta el órgano completo, así como el desarrollo de una arritmia cardíaca dependiente del calcio. Estos temas se explicarán de forma sencilla y amena para que las personas participantes los conozcan de la mano de nuestras investigadoras e investigadores.  \n12:00 - 13:30 h. ¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\nPúblico: juvenil (14-18 años).\nLas personas participantes en esta actividad tendrán la oportunidad de conocer la relación entre el cáncer y el corazón desde el acercamiento al proyecto de investigación RESILIENCE, destinado a mejorar la vida de los pacientes con cáncer. La actividad consistirá en un workshop donde las personas participantes conocerán la aplicación de la tecnología (resonancia magnética cardíaca, ecocardiografía y tomografía cardíaca) y la innovación en este ensayo clínico, así como una mesa redonda donde se compartirán experiencias y se resolverán dudas.\n14:30 - 16:00 h. ¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\nPúblico: infantil (6 – 12 años).\nSe realizará una pequeña presentación sobre las diferencias de flujo sanguíneo laminar y oscilatorio en el contexto de aterosclerosis (con nuestros personajes de dibujos LAMI y OSCI); se hará un juego con preguntas básicas sobre la presentación donde las personas participantes ganarán piezas para montar su propia máquina de flujo laminar y oscilatorio; y habrá una demostración con una adaptación similar de las máquinas que se usan en el laboratorio para estimular las células a los dos tipos de flujo, con el uso de colorante alimentario y purpurina para que se puedan ver los diferentes patrones.\nDos turnos: 11:00-11:45 h (turno 1), 11:45-12.30 h (turno 2).   \n16:00 - 17:30 h. Taller de extracción de ADN. Grupo: Enrique Lara\nPúblico: infantil (8 – 12 años).\n¿Alguna vez te has preguntado qué podéis tener en común los plátanos y tú? ¡Los dos tenéis ADN! Os presentamos una actividad rápida, fácil y divertida, en la que vais a aprender a extraer el ADN de un plátano. Para ello usaremos ingredientes que cualquiera de vosotros tenéis en casa, así podéis sorprender al resto de la familia montando un pequeño laboratorio y ejerciendo de investigadores, ¿estáis dispuestos?\nTres turnos: 16:00 - 16:30 h (Turno 1), 16:30 - 17:00 h (Turno 2), 17:00 - 17:30 h (Turno 3).\n16:00 - 18:00 h. Modelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nPúblico: Infantil (desde 6 años), juvenil y adultos.\nEsta actividad comenzará con una breve charla introductoria para seguir con la preparación de áreas temáticas en el laboratorio especializadas en una cardiopatía congénita concreta, donde se explicarán en detalle sus rasgos morfológicos y cómo afectan a la salud humana. Las personas participantes realizarán una tinción histológica en la que podrán observar corazones de ratón y observarán, de manera práctica, las malformaciones explicadas en la charla de introducción. Con esto esperamos acercar a grandes rasgos lo que se hace en el laboratorio y la relevancia de la investigación básica y traslacional en el contexto de la cardiología.\n16:30 - 18:00 h. Cuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nPúblico: juvenil (desde 15 años) y adultos.\nEsta actividad consta de dos partes. Una primera en la que se les dará a las personas que participan una charla divulgativa adaptada a la edad del público, en la que se expondrá la importancia de los factores de riesgo cardiovasculares en el desarrollo de ciertas patologías relacionadas con el cerebro, así como el ictus o demencias. Posteriormente tendrá lugar una visita guiada en pequeños grupos al laboratorio del grupo donde se mostrarán diferentes técnicas empleadas de rutina en un laboratorio de neurociencia.\n17:00 - 18:00 h. El escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nPúblico: juvenil (desde 12 años) y adultos.\nEn este escape room científico, las personas participantes deberán usar su ingenio para resolver pruebas, enigmas o puzles y abrir un candado. Si lo logran, ¡descubrirán el secreto de la PCR y ganarán una recompensa final! De esta manera, a través de retos colaborativos inspirados en la biología molecular, las personas que jueguen aprenden conceptos clave de genética en un entorno lúdico y educativo.\n17:00 - 19:00 h. Da color a tu plato: convierte a tu corazón en un superhéroe con ritmo: Grupos: José Antonio Enríquez y David Sancho.\nPúblico: infantil (6-12 años).\nEn esta actividad interactiva se construirá un estetoscopio con materiales simples y reciclados (globos, tubos de plástico y botellas usadas), que las personas participantes podrán llevarse a casa. Con él, exploraremos cómo suena nuestro propio corazón, aprendiendo de manera directa y divertida sobre el ritmo cardíaco en condiciones de reposo y después del ejercicio, así como su importancia para la salud. Posteriormente se visualizará en una maqueta humana de poliespán a tamaño real cómo es nuestro sistema circulatorio, cómo la sangre llega a nuestro corazón y cómo alteraciones de la circulación pueden ocasionar ciertas patologías, como es la ateroesclerosis. También tendremos la oportunidad de ver cómo es nuestra sangre cuando tiene un exceso de grasa.  Ambas visualizaciones permitirán comprender por qué es fundamental, evitar el sedentarismo y cuidar nuestros hábitos alimenticios desde una edad temprana para prevenir enfermedades cardiovasculares.\n18:00 - 19:00 h. Diseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nPúblico: adultos (mayores de 18 años).\nEn esta actividad cinco participantes visualizarán con gafas de realidad mixta la estructura dinámica de proteínas y sus ligandos, entendiendo como se produce el efecto de un medicamento. Otros cinco participantes trabajarán en un ordenador cada uno en el proyecto colaborativo https://foldingathome.org. Las personas participantes irán terminando y saliendo, y un nuevo participante entrará para sustituirlos.\nFinanciación y menciones necesarias\n En todas las actividades:\n\nEl CNIC recibe apoyo del Instituto de Salud Carlos III (ISCIII), del Ministerio de Ciencia, Innovación y Universidades (MICIU) y es un Centro de Excelencia Severo Ochoa. Estas actividades han sido posibles gracias a los programas de investigación de CNIC: Programa Nuevos mecanismos de aterosclerosis, Programa Homeostasis miocárdica y daño cardiaco, Programa de Regeneración cardiovascular, Programa Nuevos mecanismos arritmogénicos, Programa Factores de riesgo cardiovascular y salud cerebral, Programa de Promoción de la salud cardiovascular, Programa de Desarrollo tecnológico, financiados por la ayuda CEX2020-001041-S por el MICIU/AEI/10.13039/501100011033.\n\nFinanciado por la Unión Europea. Las opiniones y puntos de vista expresados solo comprometen a su(s) autor(es) y no reflejan necesariamente los de la Unión Europea o los de la European Research Executive Agency (EREA). Ni la Unión Europea ni la EREA pueden ser considerados responsables de ellos.\nNIGHTMADRID es un proyecto de divulgación científica, coordinado por la Fundación madri+d y financiado por la Unión Europea dentro del Programa Horizonte Europa, bajo las acciones Marie Skłodowska-Curie con el acuerdo de subvención nº101.162.110\n\n\nMenciones específicas de cada actividad:\nEnfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nProject PID2022-141211OB-I00, funded by MCIU/AEI/10.13039/501100011033 y por FEDER, UE:\n\nProject “AC22/00020\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union NextGenerationEU:\n\n\nGRUPO CIBERCV CB16/11/00405\n\nProject \"FI23/00229\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union.\n\n\n¿Cómo late nuestro corazón?Grupo: Silvia Priori.\nEl proyecto que ha dado lugar a los resultados mostrados en esta actividad ha recibido el apoyo de la Fundación “la Caixa”, según el acuerdo LCF/PR/HR21-00233.\n\n¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\n\nThis project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No GA-945118\n\nEsta actividad es parte de la ayuda ICT2021-006950, financiada por MICIU y por la Unión Europea NextGenerationEU/PRTR\n\nGRUPO CIBERCV CB16/11/00358\n\n¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\n\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGrant PID2023-146414OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nEsta actividad se (co)financiará con cargo a programa de actividades de I+D entre grupos de Investigación con número de referencia TEC-2024/TEC-158 y acrónimo TecNanoBio-CM, subvencionado por la Comunidad de Madrid en la convocatoria de ayudas destinadas a la realización de programas de actividades de I+D entre grupos de investigación de la Comunidad de Madrid en Tecnologías 2024.\n\nEl proyecto de investigación Caveolin-1-dependent stromal remodeling: a potential novel target for cancer immunotherapy” Modalidad de temática general (Ref. PROYE20089DELP) y el proyecto Immunomechanics: a new paradigm for understanding cancer immune infiltration and improving immunotherapy Modalidad Investigador AECC 2024 (Ref. INVES245874LOLO) financiado por la Asociación Española Contra el Cáncer (AECC).\n\nThe project leading to these results has received funding from “la Caixa” Foundation, under agreement LCF/PR/HR20/52400015\n\nGrant JDC2022-049775-I funded by MICIU/AEI/ 10.13039/501100011033 by the “European Union NextGenerationEU/PRTR”\n\nAyuda FPU21/04003 financiada por:\n\nGrant PRE2021-097318 and PREP2023-001367 funded by MICIU/AEI /10.13039/501100011033 and “ESF+”\n\nFinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2024-TL/SAL-GL-32882 de la convocatoria 2024 de ayudas para la contratación de Ayudantes de Investigación y Técnicos de Laboratorio 2024 y cofinanciadas con el Fondo Social Europeo Plus (FSE+)\n\nco-funded by the European Union’s Horizon Europe research and innovation programme (Cure and Heart Brain project) under the Marie Skłodowska-Curie grant agreement No GA-101126521\n\nTaller de extracción de ADN. Grupo: Enrique Lara\nProyecto TED2021-129774B-C22 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nAyuda PRE2021-100726 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nProyecto PLEC2022-009235 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto PID2021-124629OB-I00 financiado por MICIU/ AEI /10.13039/501100011033/ y por FEDER Una manera de hacer Europa\n\nAyuda PRE2019-087458 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nThis project has received funding from the Horizon Europe Framework Programme (HORIZON) under the call EIC Pathfinder Challenges 2022 and with Project 101115416 — DCM-NEXT\nEl contrato del técnico está cofinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2023-TL/SAL-GL-28706 de la convocatoria 2023 de ayudas para la contratación de ayudantes de investigación y técnicos de laboratorio y cofinanciado en un 40% por el Fondo Social Europeo Plus (FSE+), 2021-2027.\n\n \nGRUPO CIBERCV CB16/11/00432\n\nModelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nLa Caixa “Cardiogenomics”, Plan Nacional, CIBERCV, Leducq foundation\nGrant PID2022-136942OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nFunding from ”la Caixa” Foundation under the project code LCF/PR/HR23/52430011\n\nGrant from the Leducq Foundation for Cardiovascular Research- TNE-24VD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGRUPO CIBERCV CB16/11/00399\n\nAyuda PRE2020-092102 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nAyudas PRE2022-102314 y PREP2022-000716 financiadas por MICIU/AEI /10.13039/501100011033 y por FSE+\nAyuda JDC2023-051982-I financiada por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda FPU18/01054 financiada por el Ministerio de Ciencia, Innovación y Universidades\n\nFinanciado a través de la Ayuda a la contratación de personal investigador predoctoral del año 2023 de la CAM con Expediente PIPF-2023/SAL-GL-29818\n\nCuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nGrant PID2022-140616OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nGrants from the Leducq Foundation for Cardiovascular Research-TNE-19CVD01 and TNE-21CVD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nAyudas PRE2021-099443, PREP2022-000650 y PRE2022-104379 financiadas por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda a la contratación de personal investigador predoctoral del año 2022 de la CAM con Expediente PIPF-2022/SAL-GL-26119\n\nSupport of a fellowship from the ”la Caixa” Foundation (ID 100010434). The fellowship code is LCF/BQ/DI22/11940002”.\n\nEl escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nAssociated funded projects that require dissemination (if applies). Logos and mentions:\n\nUE0EIC2201-HORIZON-EIC-2022_DCM-NEXT\n\nERN-Guard-Heart\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\n \nGRUPO CIBERCV CB16/11/00432\n\nDa color a tu plato: convierte a tu corazón en un superhéroe con ritmo. Grupos: José Antonio Enríquez y David Sancho\n\nJosé Antonio Enríquez:\n\nCentro de Investigación Biomédica en Red de Fragilidad y Envejecimiento Saludable (CIBERFES), Instituto de Salud Carlos III.\nGRUPO CIBERFES CB16/10/00289\n\nProyecto TED2021-131611B-I00 financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under the proposal n° 101198761 MINTRAF\n \n \nProyecto PID2021-127988OB-I00 financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430010\n\n\nDavid Sancho:\n\nProyecto CPP2021-008310 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009762 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\n \nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under grant agreement No 101158245.\n\nThis work was supported by the grant PRYGN246642SANC from the Scientific Foundation of the Spanish Association Against Cancer.\n\nThis work was supported by WORLWIDE CANCER RESEARCH 25-0080.\n\nProyecto PID2022-137712OB-I00 financiado por MICIU/AEI/10.13039/501100011033 y por FEDER, UE\n\nPROGRAMAS DE ACTIVIDADES DE I+D ENTRE GRUPOS DE INVESTIGACIÓN de la Comunidad de Madrid - BIOMEDICINA 2022 coordinado por la Dra. Almudena R Ramiro”-EXPEDIENTE: S2022/BMD-7333. Proyecto titulado “Estrategias inmunomoduladoras en el remodelado vascular: nuevas perspectivas diagnósticas y terapéuticas, acrónimo: INMUNOVAR”. IP del Grupo INMUNOBIOL.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR22/52420019.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430012\n\nProject “UNderstanding Lipid ImmunoMetabolIsm To trEat Disease, acronym: UNLIMITED” (MSCA-Doctoral Network) has received funding from the European Union’s Horizon 2024 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 101227259 \n\nDiseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nAyudas TED2021-132296B-C54 y TED2021-131611B-I00, financiadas por MICIU/ AEI/10.13039/501100011033/ y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009668, financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/PRTR (Plan de Recuperación, Transformación y Resiliencia)\n\nAyuda BIOMARCADORES DE PRECISION PARA LA MEJORA DEL DIAGNOSTICO Y TRATAMIENTO DE LA ENFERMEDAD INFLAMATORIA DEL MIOCARDIO (PreMyo) con expediente PMP22/00105, financiado con fondos públicos por el Instituto de Salud Carlos III y cofinanciado por Unión Europea – NextGenerationEU\n\nAyuda Plan de Formación en Inteligencia Artificial y Big Data para la salud Cardiovascular (CardiotrAIning) con Ref. SOLI/2024/0524/00240212 financiado por los fondos europeos NextGenerationEU en el marco del Plan de Recuperación, Transformación y Resiliencia a través de la iniciativa de los programas de atracción y retención de talento \n\nGRUPO CIBERCV CB22/11/00021\n\nProyecto PID2022-141527OB-I00 financiado por MCIN/AEI/10.13039/501100011033 y por FEDER, UE;\n\nAyuda EQC2024-008195-P financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe EU4Health Programme 2021-2027 under Grant Agreement 101126953. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or European Health and Digital Executive Agency (HADEA). Neither the European Union nor the granting authority can be held responsible for them.\n\nProyecto ALGORITMOS DE INTELIGENCIA ARTIFICIAL PARA PREDECIR EL RIESGO CARDIOVASCULAR, EN-PESA financiado por el Mecanismo de Recuperación y Resiliencia de la Unión Europea-Next Generation, en el marco de la convocatoria “Solicitud de Proyectos de I+D de Excelencia en Inteligencia Artificial de la Secretaría de Estado de Digitalización e Inteligencia Artificial”",
    "source": "CNIC"
  },
  {
    "title": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "title_es": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "url": "https://www.cnio.es/noticias/nuevo-ensayo-clinico-contra-el-cancer-de-piel-mas-frecuente-con-un-compuesto-derivado-de-descubrimientos-del-cnio/",
    "published": "2025-07-15T09:39:59.000Z",
    "date": "2025-07-15",
    "content_es": "Hace unos 15 años, en 2009, el equipo de la investigadora del Centro Nacional de Investigaciones Oncológicas (CNIO) Marisol Soengas descubrió una nueva forma de matar células tumorales: hacerles creer que han sido infectadas por un virus. Desarrollaron un compuesto, denominado BO-110, con una forma de actuación muy novedosa porque inducía la autodigestión de las […]\nLa entrada Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "title_es": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "url": "https://www.cnic.es/es/node/235399",
    "published": "2025-07-14T11:31:24.000Z",
    "date": "2025-07-14",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nA new study led by the CNIC has identified imidazole propionate (ImP), a metabolite produced by gut bacteria, as a driver of atherosclerosis— as a driver of atherosclerosis, the disease behind most heart attacks and strokes\n\n\n\nCardiovascular disease remains the world’s leading cause of death, and often originates in atherosclerosis, a chronic condition in which inflammation and fat deposits cause arteries to harden and narrow. Although clinical practice already targets causal factors like high cholesterol, hypertension, and smoking, detecting atherosclerosis in its early stages continues to be a significant challenge.\nNow, researchers at the Spanish National Center for Cardiovascular Research (CNIC) have identified a gut microbiota–derived metabolite, imidazole propionate (ImP), that appears in the blood during the early stages of active atherosclerosis.\n‘This metabolite is uniquely produced by intestinal bacteria,’ explains CNIC researcher Annalaura Mastrangelo, one of the study’s two first authors. ‘Our study shows that its presence in the bloodstream is associated with the development of active atherosclerosis in people who otherwise appear healthy.’\nThe discovery offers a promising alternative to current diagnostic tools, which typically involve costly and complex imaging techniques. ‘Detecting this blood marker offers a major advantage because current diagnostic tools rely on advanced imaging techniques that are complex, expensive, and not covered by public health systems. Blood levels of ImP provide a diagnostic marker that could help identify apparently healthy individuals with active atherosclerosis, and thus enable earlier treatment.’ says Mastrangelo.\nBut the discovery goes even further. Co–first author Iñaki Robles-Vera explains: ‘We not only observed elevated ImP levels in people with atherosclerosis, but also showed that ImP itself is a causal agent of the disease. In animal models of atherosclerosis, ImP administration led to the formation of arterial plaques. It does this by activating the imidazoline receptor type 1 (I1R), which increases systemic inflammation and promotes atherosclerosis development.’\nDavid Sancho, head of the CNIC Immunobiology Laboratory, lead author on the study and ERC grantee notes that ‘this discovery is important because it opens the way to a completely new line of treatment.’\nThe study shows that blocking the I1R receptor in animal models prevented plaque formation and slowed disease progression, even when the animals were fed a high-cholesterol diet. ‘This suggests that future treatment could combine I1R blockade with cholesterol-lowering drugs to produce a synergistic effect that prevents atherosclerosis development,’ explains Sancho.\n‘These findings open new possibilities for the early detection and personalised treatment of atherosclerosis,’ he continues. ‘Instead of focusing solely on cholesterol and other classic risk factors, we may soon be able to analyse blood for ImP as an early warning signal. At the CNIC, we are also working to develop drugs that block the detrimental effects of ImP.’\n\nThe CNIC-led study was conducted through extensive collaboration with researchers at multiple national and international centres: Mount Sinai Fuster Heart Hospital and the Icahn School of Medicine at Mount Sinai (New York, USA); the Fundación Jiménez Díaz Health Research Institute; the Universidad Autónoma de Madrid; the Spanish cardiovascular research network (CIBER-CV); the University of Gothenburg (Sweden); the University of Athens (Greece); Inmunotek S.L.; the University of Michigan (USA); Hospital de La Princesa; the Center for Metabolomics and Bioanalysis (CEMBIO) from Universidad CEU San Pablo; the University of Heidelberg (Germany); and the Sols-Morreale Biomedical Research Institute (IIBM-CSIC). \nThe study was supported by funding from the European Research Council (Consolidator and Proof of concept grants), Spanish Ministry of Science, Innovation, and Universities; the Spanish State Research Agency; the European Union’s NextGeneration funding mechanism; and the “la Caixa” Foundation.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D., Sancho, D., et al. (2025). Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature. https://doi.org/10.1038/s41586-025-09263-w",
    "source": "CNIC"
  },
  {
    "title": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "title_es": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "url": "https://www.cnic.es/es/noticias/nature-descubren-un-metabolito-microbiota-intestinal-que-favorece-aterosclerosis-podria",
    "published": "2025-07-14T11:08:07.000Z",
    "date": "2025-07-14",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nUn estudio liderado por el CNIC desvela que el propionato de imidazol, un metabolito producido por la microbiota intestinal, induce aterosclerosis, una enfermedad que puede desencadenar la obstrucción de las arterias que causa los infartos o accidentes cerebrovasculares\n\n\n\nLas enfermedades cardiovasculares son la principal causa de muerte global y suelen originarse en la aterosclerosis, un endurecimiento y estrechamiento de las arterias por inflamación y acumulación de grasa en la pared arterial. Aunque se controlan factores causales como colesterol, hipertensión o tabaquismo, la detección temprana de la enfermedad es necesaria. Los nuevos resultados liderados por el Centro Nacional de Investigaciones Cardiovasculares (CNIC) y publicados en la revista Nature han identificado que un metabolito generado por bacterias intestinales, el propionato de imidazol (ImP), se detecta en sangre de modo temprano en la aterosclerosis activa. El estudio ha contado con el apoyo de la Fundación “la Caixa” en su Convocatoria CaixaResearch de Investigación en Salud con 967.620,20 €.\nEste metabolito, “está producido exclusivamente por bacterias del intestino”, explica Annalaura Mastrangelo, investigadora del CNIC y primera autora del estudio. “En este trabajo hemos visto que su presencia en sangre se relaciona con el desarrollo de aterosclerosis activa en personas aparentemente sanas”.\nLo relevante de este hallazgo, destaca Mastrangelo, es que “detectar este marcador en sangre representa una gran ventaja dado que las pruebas actuales requieren técnicas de imagen avanzada complejas y costosas que no están cubiertas por la seguridad social. Los niveles de ImP en sangre ofrecen un marcador con valor diagnóstico para facilitar la identificación de personas sanas que tienen aterosclerosis activa y posibilitar su tratamiento temprano”.\n\nPero el hallazgo va más allá. Iñaki Robles-Vera, también primer autor del estudio, añade: “No solo observamos que el ImP está elevado en personas con aterosclerosis, sino que es un agente causal de la enfermedad. El consumo de ImP provocó la aparición de placas en las arterias en modelos animales de aterosclerosis. El ImP activa el receptor imidazolínico de tipo 1 (I1R) generando un aumento de la inflamación sistémica que contribuye al desarrollo de la aterosclerosis”.\nPara David Sancho, jefe del laboratorio de Inmunobiología y líder del estudio, “este descubrimiento es importante porque abre una nueva vía de tratamiento”.\nEn la investigación que se publica en ‘Nature’, añade, se ha visto que, el uso de bloqueantes del receptor I1R previene la inducción de aterosclerosis por ImP y reduce la progresión de aterosclerosis en modelos de ratón donde se induce la enfermedad con dieta alta en colesterol. “Esto abre la posibilidad futura de un tratamiento combinado del bloqueo de I1R junto al bloqueo de la producción de colesterol para lograr un efecto que esperamos que sea sinérgico y que prevenga el desarrollo de aterosclerosis”, asegura David Sancho.\nEstos hallazgos, agrega, “abren nuevas posibilidades para el diagnóstico precoz y el tratamiento personalizado y temprano de la aterosclerosis. Así, en lugar de centrarse únicamente en el colesterol y otros factores clásicos, se podría en el futuro analizar la presencia de ImP en sangre como señal de riesgo. En el CNIC estamos trabajando para desarrollar fármacos que bloqueen los efectos perjudiciales de ImP”.\n\nEste trabajo ha sido liderado por el CNIC pero representa una colaboración global a nivel nacional e internacional, con la participación de instituciones como Mount Sinai Fuster Heart Hospital, Icahn School of Medicine at Mount Sinai en Nueva York (EEUU); Instituto de investigación Sanitaria Fundación Jiménez Díaz; Universidad Autónoma de Madrid; Centro de Investigación biomédica en red de enfermedades cardiovasculares (CIBER-CV); Universidad de Gotemburgo (Suecia); Universidad de Atenas (Grecia);  Inmunotek S.L; Universidad de  Michigan (EEUU);  Hospital de La Princesa; Centro de Metabolómica y Bioanálisis (CEMBIO), de la Universidad CEU San Pablo; Universidad de Heidelberg (Alemania), y el  Instituto de Investigaciones Biomédicas Sols-Morreale IIBM-CSIC.\nEste proyecto ha recibido financiación del European Research Council (ayudas Consolidator y Proof of Concept: 2016-Consolidator Grant 725091; ERC-2023-PoC); Ministerio de Ciencia, Innovación y Universidades; Agencia Estatal de Investigación; Unión Europea a través de NextGeneration, y la Fundación “la Caixa”.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D. Sancho, D., et al. Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature (2025). https://doi.org/10.1038/s41586-025-09263-w",
    "source": "CNIC"
  },
  {
    "title": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "title_es": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "url": "https://www.cnic.es/es/noticias/ocho-mejores-estudiantes-bachillerato-espana-participan-programa-acercate",
    "published": "2025-07-11T12:07:09.000Z",
    "date": "2025-07-11",
    "content_es": "11/07/2025\n\n\nSobre el CNIC\nFormación\n\n\n\n\n\n\n\n\nEl objetivo del Programa Acércate es atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular\n\n\n\nUn año más, ocho de los mejores estudiantes de bachillerato de España han participado el programa ACÉRCATE, que organiza el Centro Nacional de Investigaciones Cardiovasculares (CNIC) dentro de su Plan de Formación CNIC-Joven. El objetivo de este plan, una apuesta personal del director general del centro, el Dr. Valentín Fuster, es “atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular”.\nLa convocatoria, abierta a bachilleres de todo el territorio nacional, se ha resuelto este año a favor de 6 alumnas y 2 alumnos de los más de 50 que reunían los requisitos y solicitaron participar en el programa. Este año las personas que participan en el programa proceden de Asturias, Extremadura, Galicia, Comunidad de Madrid, Castilla y León, Comunidad Valenciana y Andalucía.\nIncluyendo a los de esta convocatoria, en total ya han participado en el programa 136 estudiantes. Los jóvenes estudiantes, además de participar en el día a día de un centro de excelencia en investigación como el CNIC, han compartido sus experiencias y sus dudas con los investigadores del centro, pero también con el Dr. Fuster, director del CNIC. El Dr. Fuster considera que empezar el programa de formación en etapas educativas tan tempranas es clave para atraer a los investigadores del futuro porque los jóvenes son el “futuro de la investigación en nuestro país”.\nLas personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024\nEn esta ocasión, las personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024 (Concurso de la Unión Europea para Jóvenes Científicos), un certamen internacional que reconoce los mejores proyectos científicos de jóvenes de entre 14 y 20 años. Kvasnovska, fue seleccionada por su proyecto individual de biomedicina titulado «Biomarcadores potenciales de la inflamación crónica relacionada con la edad».\nLos participantes del programa Acércate al CNIC comparten una gran ilusión por vivir una experiencia enriquecedora que les permita acercarse al mundo real de la investigación biomédica. Así, Alba García Peña quiere profundizar en biomedicina para orientar su futuro profesional. María García Manchado, apasionada por la cardiología, desea conocer de cerca el trabajo investigador, mientras que Lucas Gómez Sánchez espera familiarizarse con el laboratorio y la tecnología aplicada a la medicina.\nLuka Pesich, por su parte, busca reforzar sus conocimientos y habilidades prácticas en biomedicina y Sofía Requena Skalska está interesada en el funcionamiento interno de los grupos de investigación y la conexión entre ciencia y práctica clínica.\nDescubrir el día a día en un laboratorio y confirmar su vocación científica es lo que espera Laura Sánchez Rodríguez, mientras que Carmen Vico Guerra valora la oportunidad de crecer personal y académicamente en un entorno de excelencia.\nPor último, Sara Baldo Muñiz espera comprender de forma directa la labor investigadora y aprender tanto de profesionales como de otros estudiantes con intereses afines.\nTecnología más puntera\nEste programa es el que se dirige a la captación de talento más joven de todos los de formación que hay en el CNIC. El apoyo sostenido de la Fundación Pro CNIC es indispensable para que, año tras año, pueda seguir celebrándose y captando el talento desde la etapa más precoz. “Estamos muy satisfechos de este concepto que comenzamos hace ya más de 20 años”, añade el Dr. Fuster. Y, concluye, “así, si tienen ese ‘gusanillo’ de la investigación, los animamos a seguir adelante”.\nAccede aquí al álbum de fotos de esta convocatoria\nSara Baldó Muñiz \n\nSara cursó sus estudios en el IES Velázquez de Madrid y ha decidido estudiar Bioquímica en la Universidad Autónoma de Madrid. Desde pequeña, ha sentido una fuerte atracción por la investigación científica, impulsada por su curiosidad innata y su deseo de comprender cómo funciona el mundo. \nAlba García Peña \n\nAlba cursó Bachillerato en el IES Álvaro Cunqueiro de Vigo y comenzará el próximo curso la carrera de Biotecnología en la Universidad de Santiago de Compostela. Eligió esta opción porque integra varias disciplinas científicas —Matemáticas, Física, Química y Biología— y le permitirá especializarse más adelante en áreas vinculadas a la investigación biosanitaria. \nMaría García Manchado \n\nMaría estudió en el IES San José de Villanueva de la Serena, Badajoz. Ha optado por estudiar Medicina en la Universidad de Extremadura. Desde niña ha sentido una gran pasión por el conocimiento, que la llevó a interesarse especialmente por Biología y Matemáticas.\nLucas Gómez Sánchez \n\nLucas estudió en el IES Ramiro de Maeztu de Madrid y ahora estudiará Ingeniería Biomédica en la Universidad Carlos III de Madrid. Su curiosidad científica comenzó a los 8 años, participando en actividades como la Noche de los Investigadores y la Semana de la Ciencia. \nLuka Pesich \n\nLuka curso Bachillerato en el Colegio Patrocinio San José de Estepona, Málaga. Ahora iniciará sus estudios en Ciencias Biológicas y Químicas en la Universidad de Limerick (Irlanda), con la intención de especializarse en genética. Su interés por la ciencia fue creciendo de forma natural, motivado por su amor por la naturaleza. \nSofía Requena Skalska \n\nSofía estudió en el CEU San Pablo Valencia de Puerto de Sagunto, Valencia. Sofía cursó parte de su formación secundaria en Quebec, donde tuvo su primer contacto directo con la investigación científica mediante prácticas de laboratorio. Posteriormente, el Bachillerato Internacional fortaleció su interés en la biología y el cuerpo humano. \nLaura Sánchez Rodríguez \n\nLaura estudió en el Colegio Salesiano Santo Ángel de Avilés, Asturias. Empezará el próximo curso la carrera de Biotecnología en la Universidad de Oviedo. Su interés por la ciencia surgió a través de proyectos escolares y viajes STEAM organizados por su centro educativo.\nCarmen Vico Guerra \n\nCarmen cursó Bachillerato en el IES Zorrilla de Valladolid. El próximo cursó comenzará a estudiar Biomedicina y Terapias Avanzadas en la Universidad de Valladolid. Su pasión por la ciencia comenzó en la infancia, cuando pasaba horas hojeando atlas de anatomía y viendo programas divulgativos.",
    "source": "CNIC"
  },
  {
    "title": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "title_es": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "url": "https://www.cnio.es/noticias/un-estudio-pionero-desvela-nuevos-mecanismos-geneticos-implicados-en-tumores-raros-de-cabeza-y-cuello/",
    "published": "2025-07-10T13:50:44.000Z",
    "date": "2025-07-10",
    "content_es": "Los paragangliomas y feocromocitomas son tumores neuroendocrinos muy raros (entre 3 y 8 casos por millón de habitantes) que aparecen en cabeza, cuello y torso, o en las glándulas suprarrenales, y que pueden diseminarse a otros órganos. Cerca de la mitad están causados por alteraciones genéticas heredadas, mutaciones que interesa mucho descubrir: conocerlas permite encontrar familiares portadores de […]\nLa entrada Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "title_es": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "url": "https://www.cnic.es/es/noticias/dr-miguel-torres-premio-nacional-genetica-2025-por-su-contribucion-al-desarrollo-terapias",
    "published": "2025-07-09T09:22:45.000Z",
    "date": "2025-07-09",
    "content_es": "09/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nLa Sociedad Española de Genética (SEG) reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa.\n\n\n\nEl investigador Miguel Torres Sánchez, coordinador del Programa de Regeneración Cardiovascular e investigador principal del grupo “Control Genético del Desarrollo y Regeneración de Órganos” en el Centro Nacional de Investigaciones Cardiovasculares (CNIC), ha sido galardonado con el Premio Nacional de Genética 2025 en la modalidad aplicada, otorgado por la Sociedad Española de Genética (SEG).\nEl jurado reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa, destacando especialmente su trabajo sobre cómo la actividad de los genes regula los procesos de regionalización durante el desarrollo embrionario.\nSus investigaciones han permitido desentrañar mecanismos genéticos implicados en el control de la calidad y la regeneración de órganos, sentando así las bases científicas para el desarrollo de terapias regenerativas dirigidas al corazón y al sistema vascular.\nEl fallo también resalta la proyección internacional del Dr. Torres y el alto impacto de sus publicaciones científicas, que lo sitúan como una figura de referencia en el campo de la biomedicina regenerativa.\nEl Dr. Torres lidera desde el CNIC una de las líneas de investigación más innovadoras en medicina regenerativa, con el objetivo de desarrollar nuevas estrategias terapéuticas que permitan reparar los tejidos dañados tras un infarto u otras patologías cardiovasculares, una de las principales causas de muerte en el mundo.\nProyecto REACTIVA\nEntre otros proyectos, el Dr. Torres dirige el proyecto REACTIVA, seleccionado para recibir una prestigiosa ERC Advanced Grant, financiación que respalda una línea de investigación innovadora centrada en la regeneración del tejido cardíaco, con el objetivo de abrir nuevas vías hacia terapias regenerativas del corazón.\nEl Premio Nacional de Genética, financiado por la Fundación Pryconsa, representa uno de los más altos reconocimientos a la excelencia investigadora en genética en nuestro país. Con él, la Sociedad Española de Genética desea rendir homenaje a la destacada trayectoria científica del Dr. Torres, su compromiso con el avance del conocimiento y el impacto significativo que su trabajo ha tenido en la comunidad científica.\nEste galardón, señala Teresa Roldán Arjona, Presidenta de la Sociedad Española de Genética, “enaltece no solo los logros personales del Dr. Torres, sino también a la institución a la que representa y al conjunto de la comunidad genética”.\nLos Premios Nacionales de Genética, impulsados por la SEG, distinguen cada año trayectorias científicas sobresalientes tanto en investigación básica como aplicada. Junto a Miguel Torres, el jurado ha premiado en la modalidad básica a Amparo Latorre Castillo, catedrática de Genética en la Universidad de València, por su pionera labor en el estudio de la variabilidad del ADN mitocondrial y los procesos evolutivos de simbiosis.",
    "source": "CNIC"
  },
  {
    "title": "Premio a la unidad de cáncer pediátrico del CNIO",
    "title_es": "Premio a la unidad de cáncer pediátrico del CNIO",
    "url": "https://www.cnio.es/noticias/premio-a-la-unidad-de-cancer-pediatrico-del-cnio/",
    "published": "2025-07-07T10:27:25.000Z",
    "date": "2025-07-07",
    "content_es": "Las terapias CAR-T son un tipo de inmunoterapia personalizada en que las células defensivas del paciente son modificadas en el laboratorio para reforzar su capacidad de reconocer y destruir las células tumorales. Su uso, cada vez más frecuente en adultos, es aún reducido en pediatría. La Sociedad Europea de Oncología Pediátrica ha alertado ya de […]\nLa entrada Premio a la unidad de cáncer pediátrico del CNIO se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "title_es": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "url": "https://www.cnio.es/noticias/gracias-a-nuestros-amigos-y-amigas-por-ayudarnos-a-acabar-con-el-cancer/",
    "published": "2025-07-07T07:59:05.000Z",
    "date": "2025-07-07",
    "content_es": "“La clave para frenar el cáncer podría estar en la comunicación entre proteínas. Pero sinceramente, creo que la verdadera clave está en nuestra comunicación, en cómo compartimos, cuestionamos y colaboramos; si seguimos manteniendo este diálogo abierto, creo que llegará el día en que realmente entendamos el cáncer… y lo detengamos”, dijo en la Jornada de […]\nLa entrada Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "title_es": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "url": "https://www.cnio.es/noticias/el-cnio-celebra-la-solidaridad-de-sus-amigos-as-clave-para-atraer-talento-y-avanzar-en-la-investigacion-del-cancer/",
    "published": "2025-07-04T11:09:50.000Z",
    "date": "2025-07-04",
    "content_es": "Una parte importante del conocimiento que genera el Centro Nacional de Investigaciones Oncológicas (CNIO), y que se orienta a mejorar la prevención, el diagnóstico y el tratamiento del cáncer, es fruto de la generosidad. La generosidad de las personas, empresas y fundaciones que realizan donaciones al centro a través del programa ‘Amigos/as del CNIO’.  Desde que se estableció, en 2015, todos los fondos […]\nLa entrada El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "title_es": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "url": "https://www.cnic.es/es/node/235158",
    "published": "2025-07-02T09:04:18.000Z",
    "date": "2025-07-02",
    "content_es": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nCNIC researchers have uncovered the evolutionary logic of the OxPhos system—the cell’s “engine”—and developed a tool to detect mutations that cause mitochondrial disease\n\n\n\nMitochondria are the body’s “energy factories,” and their proper function is essential for life. Inside mitochondria, a set of complexes called the oxidative phosphorylation (OxPhos) system acts like a biochemical assembly line, transforming oxygen and nutrients into usable energy.\nNow, the study, led by the GENOXPHOS group at the Spanish National Centre for Cardiovascular Research (CNIC) and the Biomedical Research Networking Centre in the area of Frailty and Healthy Ageing (CIBERFES), and directed by Dr. José Antonio Enríquez, has revealed how this system evolved over millions of years—from the first vertebrates to modern humans. “Understanding this evolution helps explain why some genetic mutations cause rare but serious diseases that affect the OxPhos system,” say José Luis Cabrera lead author of the article, whose research is supported by the ‘la Caixa’ Foundation.\nPublished in Cell Genomics, the study describes the molecular evolutionary strategies of the OxPhos system, the main site of metabolic and energy integration in the cell. It also shows how this information can be used to identify mutations that cause disease.\nWorking in collaboration with Fátima Sánchez-Cabo, head of the CNIC Computational Systems Biomedicine group, the researchers analyzed the interaction between the two types of DNA that encode OxPhos proteins: nuclear DNA (inherited from both parents) and mitochondrial DNA (inherited only from the mother).\nThe OxPhos system, explains José Antonio Enríquez—head of the CNIC Functional Genetics of the Oxidative Phosphorylation System (GENOXPHOS) group—comprises five large protein complexes: four that transport electrons and one, called ATP synthase, that produces ATP, the cell’s molecular “fuel.”\n“These complexes can work individually or in combination, depending on the cell’s energy needs. Together, they are made up of 103 proteins encoded by two different genomes: nuclear and mitochondrial,” Enríquez explains. “While nuclear DNA changes slowly over time and gains variation through genetic mixing during reproduction, mitochondrial DNA evolves much more rapidly but is passed only through the maternal line.”\nDr. Cabrera adds that the proteins encoded by mitochondrial DNA form the core of the respiratory complexes, “so proper function depends on precise compatibility between the nuclear and mitochondrial components.”\nThe study also introduces an innovative new tool: ConScore, a predictive index that assesses the clinical relevance of mutations in the 103 OxPhos proteins. “ConScore is based on the evolutionary divergence of these proteins across vertebrates—including primates and other mammals—and complements human population genetic data,” says Enríquez.\nThe authors affirm that ConScore provides a new framework for interpreting potentially pathogenic mutations, opening the door to improved diagnosis and treatment of mitochondrial diseases.\nUltimately, the researchers conclude, this study not only advances our understanding of how human cells evolved, but also brings us closer to new solutions for patients with rare genetic disease.\nThe study has received funding from the European Union's NextGenerationEU/Recovery, Transformation and Resilience Plan/PRTR, CIBERFES; Fundación ‘la Caixa’,Human Frontier Science Fundation; Severo Ochoa grant awarded by MICIU/AEI and the European Social Fund (ESF invests in your future).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "source": "CNIC"
  },
  {
    "title": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "title_es": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "url": "https://www.cnio.es/noticias/los-danos-en-el-adn-derivados-de-la-contaminacion-atmosferica-podrian-contribuir-al-cancer-de-pulmon-en-personas-no-fumadoras-halla-un-estudio/",
    "published": "2025-07-02T15:17:44.000Z",
    "date": "2025-07-02",
    "content_es": "Una cuarta parte de los casos de cáncer de pulmón se dan en personas que no han fumado nunca. ¿Cuál es la causa de estos cánceres? Un estudio que analiza las alteraciones genéticas (mutaciones) en tumores de 871 personas no fumadoras de cuatro continentes apunta a la contaminación atmosférica como una de las posibles causas. […]\nLa entrada Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "title_es": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "url": "https://www.cnio.es/noticias/roger-castells-graells-recibe-el-premio-hawk-biosystems-de-la-sociedad-espanola-de-biofisica/",
    "published": "2025-06-27T13:52:15.000Z",
    "date": "2025-06-27",
    "content_es": "El investigador Roger Castells-Graells, del Centro Nacional de Investigaciones Oncológicas (CNIO), ha recibido el premio “Hawk Biosystems”, que otorga la Sociedad de Biofísica de España (SBE) en el marco de su XVIII Congreso Internacional. Castells-Graells se incorporó recientemente al CNIO para dirigir el nuevo Grupo de Diseño Biomolecular y Nanomedicina Estructural, dedicado a crear nanopartículas […]\nLa entrada Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "title_es": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "url": "https://www.cnio.es/noticias/mariano-barbacid-premio-valor-anadido-a-la-ciencia-e-investigacion/",
    "published": "2025-06-26T13:42:59.000Z",
    "date": "2025-06-26",
    "content_es": "Mariano Barbacid, descubridor del primer oncogén humano, ha recibido el Premio Valor Añadido a la Ciencia e Investigación, que reconoce la “labor de cultivo y perfeccionamiento de la investigación, descubrimiento e invención”. Los Premios Valor Añadido son una iniciativa de la Fundación Transforma España, en colaboración con BBVA, para «impulsar el reconocimiento de la aportación […]\nLa entrada Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación se publicó primero en CNIO.",
    "source": "CNIO"
  }
]