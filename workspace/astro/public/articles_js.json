[
  {
    "title": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry",
    "title_es": "Tendiendo puentes entre la innovación en IA y las necesidades sanitarias: Lecciones aprendidas de la incorporación de la PNL moderna en el Registro de Cáncer de Columbia Británica",
    "url": "https://arxiv.org/abs/2508.09991",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09991v1 Tipo de anuncio: nuevo\nResumen: La automatización de la extracción de datos de documentos clínicos ofrece un potencial significativo para mejorar la eficiencia en los entornos sanitarios, sin embargo, el despliegue de soluciones de Procesamiento del Lenguaje Natural (PLN) presenta desafíos prácticos. Basándonos en nuestra experiencia en la implementación de varios modelos de PLN para tareas de extracción y clasificación de información en el Registro de Cáncer de la Columbia Británica (BCCR), este artículo comparte las principales lecciones aprendidas a lo largo del ciclo de vida del proyecto. Enfatizamos la importancia crítica de definir los problemas basándose en objetivos empresariales claros y no únicamente en la precisión técnica, adoptando un enfoque iterativo del desarrollo y fomentando una profunda colaboración interdisciplinar y el codiseño con la participación de expertos en la materia, usuarios finales y especialistas en ML desde el principio. Otras reflexiones ponen de relieve la necesidad de una selección pragmática de modelos (que incluya enfoques híbridos y métodos más sencillos cuando proceda), una atención rigurosa a la calidad de los datos (representatividad, desviación, anotación), unas estrategias sólidas de mitigación de errores que incluyan la validación humana en el bucle y auditorías continuas, y el fomento de la alfabetización organizativa en IA. Estas consideraciones prácticas, generalizables más allá de los registros de cáncer, proporcionan orientación a las organizaciones sanitarias que buscan implementar con éxito soluciones de IA/NLP para mejorar los procesos de gestión de datos y, en última instancia, mejorar la atención al paciente y los resultados de salud pública.",
    "source": "arXiv"
  },
  {
    "title": "OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services",
    "title_es": "OpenFPL: un método de pronóstico de código abierto que rivaliza con los servicios más avanzados de la Fantasy Premier League",
    "url": "https://arxiv.org/abs/2508.09992",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09992v1 Tipo de anuncio: nuevo\nResumen: La Fantasy Premier League involucra a la comunidad futbolística en la selección de los jugadores de la Premier League que mejor rendimiento tendrán de una semana de juego a otra. El acceso a pronósticos precisos sobre el rendimiento da a los participantes una ventaja sobre sus competidores al orientar las expectativas sobre los resultados de los jugadores y reducir la incertidumbre en la selección de la plantilla. Sin embargo, los pronósticos de alta precisión se limitan actualmente a servicios comerciales cuyo funcionamiento interno no se revela y que se basan en datos patentados. Este artículo pretende democratizar el acceso a previsiones de alta precisión sobre el rendimiento de los jugadores presentando OpenFPL, un método de previsión de código abierto para la Fantasy Premier League desarrollado exclusivamente a partir de datos públicos. OpenFPL, que consta de modelos ensemble específicos para cada posición optimizados a partir de datos de la Fantasy Premier League y Understat de cuatro temporadas anteriores (2020-21 a 2023-24), alcanza una precisión comparable a la de un servicio comercial líder cuando se prueba prospectivamente con datos de la temporada 2024-25. OpenFPL también supera el punto de referencia comercial para los jugadores de alto rendimiento ($>$ 2 puntos), que son los más influyentes para las ganancias de rango. Estos resultados son válidos en horizontes de previsión de una, dos y tres semanas de juego, lo que permite planificar fichajes y estrategias a largo plazo y tomar decisiones en la última jornada.",
    "source": "arXiv"
  },
  {
    "title": "A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain",
    "title_es": "Un protocolo transparente de evaluación de la equidad para la evaluación comparativa de modelos lingüísticos de código abierto en la cadena de bloques",
    "url": "https://arxiv.org/abs/2508.09993",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09993v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos lingüísticos (LLM) se utilizan cada vez más en aplicaciones del mundo real, sin embargo, persisten las preocupaciones sobre su equidad, especialmente en dominios de alto riesgo como la justicia penal, la educación, la salud y las finanzas. Este artículo presenta un protocolo de evaluación transparente para evaluar la imparcialidad de los LLM de código abierto mediante contratos inteligentes en la cadena de bloques del Protocolo Informático de Internet (ICP) (Foundation, 2023). Nuestro método garantiza evaluaciones verificables, inmutables y reproducibles mediante la ejecución de solicitudes HTTP en la cadena a puntos finales alojados en Hugging Face y el almacenamiento de conjuntos de datos, mensajes y métricas directamente en la cadena. Comparamos los modelos Llama, DeepSeek y Mistral en el conjunto de datos PISA para la predicción del rendimiento académico (OCDE, 2018), un conjunto de datos adecuado para la evaluación de la equidad utilizando la paridad estadística y las métricas de igualdad de oportunidades (Hardt et al., 2016). También evaluamos métricas de asociación contextual estructuradas derivadas del conjunto de datos StereoSet (Nadeem et al., 2020) para medir el sesgo social en las asociaciones contextuales. Además, ampliamos nuestro análisis con una evaluación multilingüe en inglés, español y portugués utilizando el punto de referencia Kaleidoscope (Salazar et al., 2025), que revela disparidades interlingüísticas. Todo el código y los resultados son de código abierto, lo que permite auditorías comunitarias y un seguimiento longitudinal de la equidad entre las versiones del modelo.",
    "source": "arXiv"
  },
  {
    "title": "Whisper Smarter, not Harder: Adversarial Attack on Partial Suppression",
    "title_es": "Whisper Smarter, not Harder: Ataque adversario a la supresión parcial",
    "url": "https://arxiv.org/abs/2508.09994",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09994v1 Tipo de anuncio: nuevo\nResumen: Actualmente, los modelos de Reconocimiento Automático del Habla (ASR) se utilizan en una amplia gama de aplicaciones. Sin embargo, estudios recientes han demostrado la posibilidad de ataques adversarios a estos modelos que potencialmente podrían suprimir o interrumpir la salida del modelo. Investigamos y verificamos la robustez de estos ataques y exploramos si es posible aumentar su imperceptibilidad. Además, descubrimos que relajando el objetivo de optimización de la supresión completa a la supresión parcial, podemos disminuir aún más la imperceptibilidad del ataque. También exploramos posibles defensas contra estos ataques y demostramos que un filtro de paso bajo podría ser una defensa eficaz.",
    "source": "arXiv"
  },
  {
    "title": "Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling",
    "title_es": "Categorización temática y basada en tareas de los usos de GenAI K-12 con modelado temático jerárquico",
    "url": "https://arxiv.org/abs/2508.09997",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09997v1 Tipo de anuncio: nuevo\nResumen: Analizamos datos anónimos de interacción de menores en aulas que abarcan varios meses, escuelas y asignaturas empleando un novedoso y sencillo enfoque de modelado de temas. En concreto, categorizamos más de 17.000 mensajes generados por alumnos, profesores y ChatGPT en dos dimensiones: contenido (como naturaleza y personas) y tareas (como escribir y explicar). Nuestra categorización jerárquica, realizada por separado para cada dimensión, incluye mensajes ejemplares y ofrece tanto una visión general de alto nivel como perspectivas tangibles. La mayoría de los trabajos anteriores carecen de una categorización temática o de contenido. Aunque las categorizaciones de tareas son más frecuentes en la educación, la mayoría no se han apoyado en datos del mundo real para K-12. Por tanto, no es de extrañar que nuestro análisis haya dado lugar a una serie de aplicaciones novedosas. Al derivar estos conocimientos, descubrimos que muchos de los métodos computacionales clásicos y emergentes bien establecidos, es decir, el modelado de temas, para el análisis de grandes cantidades de textos tienen un rendimiento inferior, lo que nos llevó a aplicar directamente LLM de última generación con un preprocesamiento adecuado para lograr estructuras temáticas jerárquicas con una mejor alineación humana a través de instrucciones explícitas que los enfoques anteriores. Nuestros hallazgos ayudan a investigadores, profesores y estudiantes a enriquecer el uso de GenAI, mientras que nuestra discusión también pone de relieve una serie de preocupaciones y cuestiones abiertas para futuras investigaciones.",
    "source": "arXiv"
  },
  {
    "title": "INTIMA: A Benchmark for Human-AI Companionship Behavior",
    "title_es": "INTIMA: una referencia para el comportamiento de compañía entre humanos e IA",
    "url": "https://arxiv.org/abs/2508.09998",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09998v1 Tipo de anuncio: nuevo\nResumen: El compañerismo en IA, donde los usuarios desarrollan vínculos emocionales con los sistemas de IA, ha surgido como un patrón significativo con implicaciones positivas pero también preocupantes. Presentamos Interactions and Machine Attachment Benchmark (INTIMA), un punto de referencia para evaluar comportamientos de compañerismo en modelos lingüísticos. A partir de teorías psicológicas y datos de usuarios, desarrollamos una taxonomía de 31 comportamientos en cuatro categorías y 368 preguntas dirigidas. Las respuestas a estas preguntas se evalúan como reforzadoras del compañerismo, mantenedoras de los límites o neutras. La aplicación de INTIMA a Gemma-3, Phi-4, o3-mini y Claude-4 revela que las conductas de refuerzo del compañerismo siguen siendo mucho más comunes en todos los modelos, aunque se observan marcadas diferencias entre ellos. Los distintos proveedores comerciales dan prioridad a diferentes categorías dentro de las partes más sensibles del punto de referencia, lo cual es preocupante, ya que tanto el establecimiento adecuado de límites como el apoyo emocional son importantes para el bienestar del usuario. Estos resultados ponen de manifiesto la necesidad de enfoques más coherentes para gestionar las interacciones con carga emocional.",
    "source": "arXiv"
  },
  {
    "title": "XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs",
    "title_es": "XFacta: conjunto de datos contemporáneos del mundo real y evaluación para la detección multimodal de desinformación con LLM multimodales",
    "url": "https://arxiv.org/abs/2508.09999",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09999v1 Tipo de anuncio: nuevo\nResumen: La rápida propagación de la desinformación multimodal en las redes sociales exige métodos de detección más eficaces y robustos. Los recientes avances en el uso de modelos de lenguaje multimodal (MLLMs) han demostrado su potencial para afrontar este reto. Sin embargo, sigue sin estar claro dónde reside exactamente el cuello de botella de los enfoques actuales (recuperación de pruebas frente a razonamiento), lo que dificulta los avances en este campo. En cuanto a los conjuntos de datos, las pruebas de referencia existentes o bien contienen eventos obsoletos, lo que conduce a un sesgo de evaluación debido a las discrepancias con los escenarios contemporáneos de las redes sociales, ya que los MLLM pueden simplemente memorizar estos eventos, o bien son artificialmente sintéticos, lo que no refleja los patrones de desinformación del mundo real. Además, carece de análisis exhaustivos de las estrategias de diseño de modelos basados en MLLM. Para resolver estos problemas, presentamos XFacta, un conjunto de datos contemporáneos del mundo real más adecuado para evaluar detectores basados en MLLM. Evaluamos sistemáticamente varias estrategias de detección de desinformación basadas en MLLM, valorando modelos en diferentes arquitecturas y escalas, así como comparándolos con los métodos de detección existentes. A partir de estos análisis, creamos un marco semiautomático de detección en bucle que actualiza continuamente XFacta con nuevos contenidos para mantener su actualidad. Nuestro análisis aporta valiosas ideas y prácticas para avanzar en el campo de la detección multimodal de la desinformación. El código y los datos ya están disponibles.",
    "source": "arXiv"
  },
  {
    "title": "AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification",
    "title_es": "AutoGeTS: Generación automatizada de síntesis textuales basadas en el conocimiento para mejorar la clasificación de textos",
    "url": "https://arxiv.org/abs/2508.10000",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10000v1 Tipo de anuncio: nuevo\nResumen: Cuando se desarrollan modelos de clasificación de texto para aplicaciones del mundo real, uno de los principales retos es la dificultad de recopilar datos suficientes para todas las clases de texto. En este trabajo, abordamos este reto utilizando grandes modelos de lenguaje (LLMs) para generar datos sintéticos y utilizar dichos datos para mejorar el rendimiento de los modelos sin esperar a que se recopilen y etiqueten más datos reales. Dado que un LLM genera diferentes datos sintéticos en respuesta a diferentes ejemplos de entrada, formulamos un flujo de trabajo automatizado, que busca ejemplos de entrada que conduzcan a datos sintéticos más ``efectivos'' para mejorar el modelo en cuestión. Estudiamos tres estrategias de búsqueda con un amplio conjunto de experimentos, y utilizamos los resultados de los experimentos para informar a un algoritmo de conjunto que selecciona una estrategia de búsqueda en función de las características de una clase. Nuestros experimentos posteriores demuestran que este enfoque de conjunto es más eficaz que cada estrategia individual en nuestro flujo de trabajo automatizado para mejorar los modelos de clasificación mediante LLM.",
    "source": "arXiv"
  },
  {
    "title": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish",
    "title_es": "HiFACTMix: Una prueba comparativa de código mixto y un modelo basado en grafos para la verificación de afirmaciones políticas basadas en pruebas en hinglish",
    "url": "https://arxiv.org/abs/2508.10001",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10001v1 Tipo de anuncio: nuevo\nResumen: La comprobación de hechos en lenguas con mezcla de códigos y pocos recursos, como el hinglish, sigue siendo un reto poco explorado en el procesamiento del lenguaje natural. Los sistemas de verificación de hechos existentes se centran en gran medida en entornos monolingües de alto nivel de recursos y no logran generalizarse al discurso político del mundo real en regiones lingüísticamente diversas como la India. Dado el extendido uso del hinglish por parte de personajes públicos, sobre todo políticos, y la creciente influencia de las redes sociales en la opinión pública, existe una necesidad imperiosa de herramientas de verificación de hechos sólidas, multilingües y conscientes del contexto. Para colmar esta laguna, se presenta un nuevo conjunto de datos de referencia HiFACT con 1.500 afirmaciones reales realizadas en hinglish por 28 ministros principales de estados indios, en un entorno de escasos recursos y código mixto. Cada afirmación está anotada con pruebas textuales y etiquetas de veracidad. Para evaluar este punto de referencia, se propone un nuevo modelo de comprobación de hechos basado en grafos que combina la codificación contextual multilingüe, la alineación semántica de afirmaciones y pruebas, la construcción de grafos de pruebas, el razonamiento neural de grafos y la generación de explicaciones en lenguaje natural. Los resultados experimentales muestran que HiFACTMix supera en precisión a los modelos de referencia multilingües más avanzados y proporciona justificaciones fieles para sus veredictos. Este trabajo abre una nueva vía para la investigación de la verificación de hechos multilingüe, con mezcla de códigos y con base política.",
    "source": "arXiv"
  },
  {
    "title": "Semantic Structure in Large Language Model Embeddings",
    "title_es": "Estructura semántica en grandes incrustaciones de modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.10003",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10003v1 Tipo de anuncio: nuevo\nResumen: La investigación psicológica encuentra consistentemente que las valoraciones humanas de las palabras a través de diversas escalas semánticas se pueden reducir a una forma de baja dimensión con relativamente poca pérdida de información. Hemos descubierto que las asociaciones semánticas codificadas en las matrices de incrustación de los grandes modelos lingüísticos (LLM) presentan una estructura similar. Demostramos que las proyecciones de palabras en direcciones semánticas definidas por pares de antónimos (por ejemplo, amable - cruel) se correlacionan en gran medida con las valoraciones humanas, y además descubrimos que estas proyecciones se reducen efectivamente a un subespacio tridimensional dentro de las incrustaciones LLM, muy parecido a los patrones derivados de las respuestas de las encuestas humanas. Además, observamos que desplazar las fichas en una dirección semántica provoca efectos no deseados en los rasgos geométricamente alineados proporcionales a su similitud coseno. Estos hallazgos sugieren que los rasgos semánticos están entrelazados dentro de los LLM de forma similar a como están interconectados en el lenguaje humano, y una gran cantidad de información semántica, a pesar de su aparente complejidad, es sorprendentemente de baja dimensión. Además, tener en cuenta esta estructura semántica puede resultar esencial para evitar consecuencias no deseadas al dirigir los rasgos.",
    "source": "arXiv"
  },
  {
    "title": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents",
    "title_es": "Percepción del usuario de las visualizaciones de atención: Efectos sobre la interpretabilidad de los documentos médicos basados en la evidencia",
    "url": "https://arxiv.org/abs/2508.10004",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10004v1 Tipo de anuncio: nuevo\nResumen: El mecanismo de atención es un componente central de la arquitectura Transformer. Más allá de mejorar el rendimiento, la atención se ha propuesto como un mecanismo para la explicabilidad a través de pesos de atención, que están asociados con las características de entrada (por ejemplo, tokens en un documento). En este contexto, un mayor peso de la atención puede implicar características más relevantes para la predicción del modelo. En la medicina basada en la evidencia, estas explicaciones podrían ayudar a los médicos a comprender los sistemas de IA utilizados para clasificar la literatura biomédica y a interactuar con ellos. Sin embargo, aún no hay consenso sobre si los pesos de atención proporcionan explicaciones útiles. Además, apenas se ha investigado cómo afecta la visualización de la atención a su utilidad como ayuda a la explicación. Para colmar esta laguna, realizamos un estudio de usuarios para evaluar si las explicaciones basadas en la atención ayudan a los usuarios en la clasificación de documentos biomédicos y si existe una forma preferida de visualizarlas. En el estudio participaron expertos médicos de diversas disciplinas que clasificaron artículos en función del diseño del estudio (por ejemplo, revisiones sistemáticas, síntesis amplias, ensayos aleatorizados y no aleatorizados). Nuestros resultados muestran que el modelo Transformer (XLNet) clasificó los documentos con precisión; sin embargo, los pesos de atención no se percibieron como especialmente útiles para explicar las predicciones. Sin embargo, esta percepción varió significativamente dependiendo de cómo se visualizara la atención. En contra del principio de eficacia visual de Munzner, que favorece codificaciones precisas como la longitud de las barras, los usuarios prefirieron formatos más intuitivos, como el brillo del texto o el color del fondo. Aunque nuestros resultados no confirman la utilidad general de los pesos de atención para la explicación, sugieren que su utilidad percibida está influida por la forma en que se presentan visualmente.",
    "source": "arXiv"
  },
  {
    "title": "From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation",
    "title_es": "De las respuestas a las preguntas: EQGBench para evaluar la generación de preguntas educativas por parte de los LLM",
    "url": "https://arxiv.org/abs/2508.10005",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10005v1 Tipo de anuncio: nuevo\nResumen: Los Large Language Models (LLMs) han demostrado notables capacidades en la resolución de problemas matemáticos. Sin embargo, la transición desde la provisión de respuestas a la generación de preguntas educativas de alta calidad presenta retos significativos que permanecen sin explorar. Para avanzar en la Generación de Preguntas Educativas (EQG) y facilitar a los LLM la generación de preguntas pedagógicamente valiosas y educativamente eficaces, presentamos EQGBench, un punto de referencia exhaustivo diseñado específicamente para evaluar el rendimiento de los LLM en la EQG china. EQGBench establece un marco de evaluación de cinco dimensiones apoyado por un conjunto de datos de 900 muestras de evaluación que abarcan tres disciplinas fundamentales de la enseñanza media: matemáticas, física y química. El conjunto de datos incorpora consultas de usuario con distintos puntos de conocimiento, gradientes de dificultad y especificaciones de tipo de pregunta para simular escenarios educativos realistas. A través de la evaluación sistemática de 46 grandes modelos principales, revelamos un importante margen de desarrollo en la generación de preguntas que reflejen el valor educativo y fomenten las capacidades comprensivas de los estudiantes.",
    "source": "arXiv"
  },
  {
    "title": "Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models",
    "title_es": "Puntuación automatizada del Cuestionario de Hostilidad de Intenciones Ambiguas mediante modelos lingüísticos amplios y bien ajustados",
    "url": "https://arxiv.org/abs/2508.10007",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10007v1 Tipo de anuncio: nuevo\nResumen: El sesgo de atribución hostil es la tendencia a interpretar las interacciones sociales como intencionadamente hostiles. El Cuestionario de Hostilidad de Intenciones Ambiguas (AIHQ) se utiliza habitualmente para medir el sesgo de atribución hostil, e incluye preguntas abiertas en las que los participantes describen las intenciones percibidas detrás de una situación social negativa y cómo responderían. Aunque estas preguntas proporcionan información sobre el contenido de las atribuciones hostiles, requieren que calificadores humanos les dediquen mucho tiempo. En este estudio, evaluamos si los modelos de lenguaje de gran tamaño pueden automatizar la puntuación de las respuestas abiertas del AIHQ. Se utilizó un conjunto de datos recopilados previamente en el que personas con lesión cerebral traumática (LCT) y controles sanos (CS) completaron el AIHQ y sus respuestas abiertas fueron calificadas por evaluadores humanos entrenados. Se utilizó la mitad de estas respuestas para afinar los dos modelos en las calificaciones generadas por humanos, y se probaron los modelos afinados en la mitad restante de las respuestas AIHQ. Los resultados mostraron que las puntuaciones generadas por los modelos coincidían con las puntuaciones humanas tanto para las atribuciones de hostilidad como para las respuestas de agresión, y que los modelos ajustados mostraban una mayor coincidencia. Esta alineación fue consistente a través de tipos de escenarios ambiguos, intencionales y accidentales, y replicó hallazgos previos sobre diferencias grupales en atribuciones de respuestas de hostilidad y agresión entre grupos con LCT y HC. Los modelos ajustados también se generalizaron bien a un conjunto de datos no clínicos independientes. Para apoyar una adopción más amplia, proporcionamos una interfaz de puntuación accesible que incluye opciones locales y basadas en la nube. En conjunto, nuestros hallazgos sugieren que los grandes modelos lingüísticos pueden agilizar la puntuación AIHQ tanto en contextos de investigación como clínicos, revelando su potencial para facilitar las evaluaciones psicológicas en diferentes poblaciones.",
    "source": "arXiv"
  },
  {
    "title": "Multidimensional classification of posts for online course discussion forum curation",
    "title_es": "Clasificación multidimensional de mensajes para la curación de foros de debate de cursos en línea",
    "url": "https://arxiv.org/abs/2508.10008",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10008v1 Tipo de anuncio: nuevo\nResumen: La curación automática de los foros de discusión en los cursos en línea requiere actualizaciones constantes, por lo que el reentrenamiento frecuente de los Modelos de Lenguaje Grande (LLMs) es un proceso intensivo en recursos. Para evitar la necesidad de un costoso reajuste, este artículo propone y evalúa el uso de la fusión bayesiana. El enfoque combina las puntuaciones de clasificación multidimensional de un LLM genérico preentrenado con las de un clasificador entrenado con datos locales. La comparación de resultados demostró que la fusión propuesta mejora los resultados en comparación con cada clasificador por separado, y es competitiva con el enfoque de ajuste fino del LLM.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts",
    "title_es": "Más allá del Hard Sharing: Modelización eficiente multitarea de voz a texto con mezcla supervisada de expertos",
    "url": "https://arxiv.org/abs/2508.10009",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10009v1 Tipo de anuncio: nuevo\nResumen: La compartición de parámetros duros es una estrategia común para entrenar un único modelo de forma conjunta en diversas tareas. Sin embargo, esto a menudo conduce a la interferencia de tareas, impidiendo el rendimiento general del modelo. Para resolver este problema, proponemos una Mezcla Supervisada de Expertos (S-MoE) sencilla pero eficaz. A diferencia de los modelos tradicionales de Mezcla de Expertos, el S-MoE elimina la necesidad de entrenar funciones de compuerta utilizando fichas de guía especiales para dirigir cada tarea a su experto designado. Al asignar cada tarea a una red feedforward independiente, S-MoE supera las limitaciones del reparto de parámetros duros. Además, aplicamos S-MoE a un modelo de conversión de voz a texto, lo que permite al modelo procesar entradas de ancho de banda mixto mientras realiza conjuntamente el reconocimiento automático del habla (ASR) y la traducción del habla (ST). Los resultados experimentales demuestran la eficacia de la S-MoE propuesta, que logra una mejora relativa del 6,35% en la tasa de error de palabra (WER) cuando se aplica tanto al codificador como al decodificador.",
    "source": "arXiv"
  },
  {
    "title": "An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs",
    "title_es": "Una Auditoría y Análisis de la Desinformación Sanitaria Asistida por LLMs Contra LLMs",
    "url": "https://arxiv.org/abs/2508.10010",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10010v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos lingüísticos (LLM, por sus siglas en inglés) son un arma de doble filo capaz de generar desinformación perjudicial, ya sea inadvertidamente o cuando son provocados por ataques de \"jailbreak\" que intentan producir resultados maliciosos. Con más investigación, los LLM podrían utilizarse para detectar y prevenir la difusión de información errónea. En este artículo, investigamos la eficacia y las características de los ataques de fuga producidos por LLM que hacen que otros modelos produzcan información médica errónea perjudicial. También estudiamos cómo la desinformación generada por los LLM con jailbreak se compara con la desinformación típica que se encuentra en las redes sociales, y con qué eficacia se puede detectar utilizando enfoques estándar de aprendizaje automático. En concreto, examinamos de cerca 109 ataques distintos contra tres LLM objetivo y comparamos los mensajes de ataque con las consultas habituales de los LLM relacionadas con la salud. También examinamos las respuestas de fuga resultantes, comparando la desinformación generada con la desinformación relacionada con la salud en Reddit. Nuestros hallazgos añaden más pruebas de que los LLM se pueden utilizar eficazmente para detectar información errónea procedente tanto de otros LLM como de personas, y respaldan un conjunto de trabajos que sugieren que, con un diseño cuidadoso, los LLM pueden contribuir a un ecosistema de información general más saludable.",
    "source": "arXiv"
  },
  {
    "title": "Evaluation of GPT-based large language generative AI models as study aids for the national licensure examination for registered dietitians in Japan",
    "title_es": "Evaluación de modelos generativos de IA basados en GPT como ayuda al estudio para el examen nacional de licenciatura de dietistas registrados en Japón.",
    "url": "https://arxiv.org/abs/2508.10011",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10011v1 Tipo de anuncio: nuevo\nResumen: La inteligencia artificial generativa (IA) basada en grandes modelos de lenguaje (LLMs), como ChatGPT, ha demostrado un notable progreso en diversos campos profesionales, incluyendo la medicina y la educación. Sin embargo, su rendimiento en la educación nutricional, especialmente en el examen nacional japonés de licenciatura para dietistas registrados, sigue siendo poco explorado. El objetivo de este estudio era evaluar el potencial de los actuales modelos de IA generativa basados en LLM como ayudas de estudio para estudiantes de nutrición. Se utilizaron preguntas del examen nacional japonés para dietistas titulados como estímulos para ChatGPT y tres modelos de Bing (Precise, Creative, Balanced), basados en GPT-3.5 y GPT-4. Cada pregunta se introdujo en sesiones independientes, en las que se utilizó un modelo de IA generativa. Cada pregunta se introdujo en sesiones independientes y se analizaron las respuestas de los modelos en cuanto a precisión, coherencia y tiempo de respuesta. Se probó la ingeniería adicional de las preguntas, incluida la asignación de roles, para evaluar posibles mejoras en el rendimiento. Bing-Precise (66,2%) y Bing-Creative (61,4%) superaron el umbral de aprobación (60%), mientras que Bing-Balanced (43,3%) y ChatGPT (42,8%) no lo hicieron. En general, Bing-Precise y Bing-Creative superaron a los demás en todos los campos temáticos, excepto en Educación nutricional, donde todos los modelos obtuvieron peores resultados. Ninguno de los modelos proporcionó sistemáticamente las mismas respuestas correctas en repetidos intentos, lo que pone de manifiesto las limitaciones en la estabilidad de las respuestas. ChatGPT mostró mayor consistencia en los patrones de respuesta, pero menor precisión. La ingeniería de instrucciones tuvo un efecto mínimo, salvo una ligera mejora cuando se proporcionaron explícitamente respuestas correctas y explicaciones. Aunque algunos modelos de IA generativa superaron ligeramente el umbral de aprobado, la precisión general y la coherencia de las respuestas siguieron estando por debajo del nivel óptimo. Además, todos los modelos mostraron notables limitaciones en la coherencia y solidez de las respuestas. Se necesitan más avances para garantizar ayudas al estudio fiables y estables basadas en IA para la preparación de la licencia de dietista.",
    "source": "arXiv"
  },
  {
    "title": "Guided Navigation in Knowledge-Dense Environments: Structured Semantic Exploration with Guidance Graphs",
    "title_es": "Navegación guiada en entornos densos en conocimiento: Exploración semántica estructurada con grafos de orientación",
    "url": "https://arxiv.org/abs/2508.10012",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10012v1 Tipo de anuncio: nuevo\nResumen: Aunque los Modelos de Lenguaje Amplio (LLMs) exhiben grandes capacidades lingüísticas, su dependencia del conocimiento estático y de procesos de razonamiento opacos limita su rendimiento en tareas intensivas en conocimiento. Los grafos de conocimiento (KGs) ofrecen una solución prometedora, pero los métodos de exploración actuales se enfrentan a un compromiso fundamental: los enfoques guiados por preguntas incurren en exploración redundante debido a desajustes de granularidad, mientras que los métodos guiados por pistas no consiguen aprovechar eficazmente la información contextual para escenarios complejos. Para abordar estas limitaciones, proponemos la exploración del conocimiento guiada por grafos de orientación (GG Explore), un novedoso marco que introduce un grafo de orientación intermedio como puente entre las consultas no estructuradas y la recuperación del conocimiento estructurado. El grafo de orientación define el espacio de recuperación abstrayendo la estructura del conocimiento objetivo y conservando el contexto semántico más amplio, lo que permite una exploración precisa y eficiente. Basándonos en el grafo de orientación, desarrollamos: (1) la alineación estructural, que filtra los candidatos incompatibles sin sobrecarga de LLM, y (2) la poda consciente del contexto, que refuerza la coherencia semántica con las restricciones del grafo. Extensos experimentos muestran que nuestro método logra una eficiencia superior y supera a SOTA, especialmente en tareas complejas, al tiempo que mantiene un fuerte rendimiento con LLMs más pequeños, lo que demuestra su valor práctico.",
    "source": "arXiv"
  },
  {
    "title": "Semantic Bridge: Universal Multi-Hop Question Generation via AMR-Driven Graph Synthesis",
    "title_es": "Puente semántico: Generación universal de preguntas multibucle mediante síntesis de grafos basada en AMR",
    "url": "https://arxiv.org/abs/2508.10013",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10013v1 Tipo de anuncio: nuevo\nResumen: El entrenamiento de grandes modelos lingüísticos (LLM) se enfrenta a un cuello de botella crítico: la escasez de pares pregunta-respuesta de alta calidad e intensivos en razonamiento, especialmente de fuentes dispersas y específicas de dominio como los artículos de PubMed o los documentos legales. Los métodos existentes se basan en patrones superficiales y, fundamentalmente, no consiguen generar preguntas de razonamiento multisalto controlables y complejas que pongan a prueba la comprensión genuina, algo esencial para avanzar en los paradigmas de formación LLM. Presentamos \\textbf{Semantic Bridge}, el primer marco universal para generar de forma controlable sofisticadas preguntas de razonamiento multisalto a partir de fuentes arbitrarias. Nuestra gran innovación es \\textit{tejido de grafos semánticos} -tres mecanismos de enlace complementarios (enlace de entidades para entidades compartidas que varían en función de los roles, enlace de cadenas de predicados para secuencias temporales/causales/lógicas y enlace causal para cadenas de razonamiento explícitas)- que construyen sistemáticamente rutas complejas a través de documentos, con un control preciso de la complejidad y los tipos mediante un análisis basado en AMR. Nuestra canalización AMR multimodal consigue una calidad de ida y vuelta hasta un 9,5% superior, lo que permite una generación de control de calidad controlable y lista para la producción. La evaluación exhaustiva demuestra el rendimiento tanto en conjuntos de datos de uso general (Wikipedia) como en dominios especializados (biomedicina). Se obtienen ganancias constantes del 18,3 % al 25,4 % respecto a las líneas de base en cuatro idiomas (inglés, chino, francés y alemán). Los pares de preguntas generados a partir de 200 fuentes superan a los 600 ejemplos de anotación humana nativa con un 67% menos de materiales. La evaluación humana muestra un 23,4% más de complejidad, un 18,7% más de capacidad de respuesta y un 31,2% más de cobertura de patrones. Semantic Bridge establece un nuevo paradigma para la síntesis de datos de entrenamiento LLM, permitiendo la generación controlable de preguntas de razonamiento específicas a partir de fuentes dispersas. Publicaremos nuestro código central y el modelo de puente semántico.",
    "source": "arXiv"
  },
  {
    "title": "PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?",
    "title_es": "PersonaEval: ¿Son los evaluadores de LLM lo suficientemente humanos para juzgar los juegos de rol?",
    "url": "https://arxiv.org/abs/2508.10014",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10014v1 Tipo de anuncio: nuevo\nResumen: Los estudios actuales sobre juegos de rol a menudo se basan en paradigmas no validados de LLM como juez, que pueden no reflejar cómo los humanos perciben la fidelidad de rol. Un prerrequisito clave para la evaluación alineada con humanos es la identificación de roles, la capacidad de reconocer quién está hablando basándose en el contexto del diálogo. Sostenemos que cualquier juicio significativo sobre la calidad de la interpretación (lo bien que se interpreta a un personaje) depende fundamentalmente de que primero se atribuyan correctamente las palabras y las acciones a la persona correcta (quién está hablando). Presentamos PersonaEval, la primera prueba diseñada para comprobar si los evaluadores LLM pueden identificar de forma fiable los roles humanos. PersonaEval utiliza diálogos escritos por humanos a partir de novelas, guiones y transcripciones de vídeo, desafiando a los modelos a determinar el personaje correcto según el contexto de la conversación. Nuestros experimentos, que incluyen un estudio en humanos, muestran que incluso los LLM con mejores resultados alcanzan sólo un 69% de precisión, muy por debajo del nivel necesario para una evaluación fiable. Por el contrario, los participantes humanos obtienen unos resultados cercanos al techo, con un 90,8% de precisión, lo que pone de manifiesto que los actuales evaluadores de LLM aún no son lo suficientemente humanos como para juzgar con eficacia los escenarios de juegos de rol. Para entender mejor esta carencia, examinamos la adaptación en tiempo de entrenamiento y el cálculo en tiempo de prueba, lo que sugiere que una evaluación fiable requiere algo más que un ajuste específico de la tarea, sino que depende de que los evaluadores LLM tengan una capacidad de razonamiento fuerte y similar a la humana. Publicamos nuestro modelo de referencia en https://github.com/maple-zhou/PersonaEval.",
    "source": "arXiv"
  },
  {
    "title": "RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal Interaction Analysis",
    "title_es": "RealTalk-CN: un diálogo chino realista de habla y texto con análisis de interacción multimodal",
    "url": "https://arxiv.org/abs/2508.10015",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10015v1 Tipo de anuncio: nuevo\nResumen: En los últimos años, los grandes modelos de lenguaje (LLMs) han logrado avances notables en el procesamiento multimodal, incluyendo modelos de lenguaje basados en el habla de extremo a extremo que permiten interacciones naturales y realizan tareas específicas en sistemas de diálogo orientado a tareas (TOD). Sin embargo, los conjuntos de datos TOD existentes se basan predominantemente en texto y carecen de señales de habla real, esenciales para evaluar la solidez de los LLM basados en el habla. Además, los conjuntos de datos TOD de habla existentes son principalmente ingleses y carecen de aspectos críticos como las disfluencias del habla y las variaciones del hablante. Para colmar estas lagunas, presentamos RealTalk-CN, el primer conjunto de datos chino de TOD multivuelta, multidominio, habla-texto dual-modal, que incluye 5.400 diálogos (60.000 expresiones, 150 horas) con anotaciones emparejadas de habla-texto. RealTalk-CN captura diversos escenarios de diálogo con anotaciones de disfluencias del habla espontánea, lo que garantiza una cobertura completa de las complejidades del mundo real en el diálogo hablado. Además, proponemos una nueva tarea de chat intermodal que simula con autenticidad las interacciones de los usuarios en el mundo real, permitiendo el cambio dinámico entre las modalidades de habla y texto. Nuestra evaluación abarca la solidez frente a las disfluencias del habla, la sensibilidad a las características del hablante y el rendimiento entre dominios. Extensos experimentos validan la eficacia de RealTalk-CN, estableciendo una base sólida para la investigación de LLM chinos basados en el habla.",
    "source": "arXiv"
  },
  {
    "title": "Training-Free Multimodal Large Language Model Orchestration",
    "title_es": "Orquestación de grandes modelos lingüísticos multimodales sin formación",
    "url": "https://arxiv.org/abs/2508.10016",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10016v1 Tipo de anuncio: nuevo\nResumen: Los diferentes modelos multimodales de grandes lenguajes (MLLM) no pueden integrarse directamente en un sistema multimodal unificado de entrada-salida. En trabajos anteriores, la formación se ha considerado como un componente inevitable debido a los desafíos en la alineación modal, la eficiencia de texto a voz y otros problemas de integración. En este artículo presentamos la orquestación de grandes modelos lingüísticos multimodales, un enfoque eficaz para crear sistemas interactivos de IA multimodal sin formación adicional. MLLM Orchestration aprovecha las capacidades de razonamiento inherentes a los grandes modelos lingüísticos para coordinar modelos especializados a través de flujos de trabajo explícitos, lo que permite interacciones multimodales naturales al tiempo que mantiene la modularidad, mejora la interpretabilidad y aumenta significativamente la eficiencia computacional. Nuestro marco de orquestación se basa en tres innovaciones clave: (1) un controlador central LLM que analiza las entradas del usuario y dirige dinámicamente las tareas a los modelos especializados apropiados a través de agentes cuidadosamente diseñados; (2) una arquitectura paralela de texto a voz que permite una verdadera interacción full-duplex con una gestión de interrupciones sin fisuras y un flujo conversacional natural; y (3) un sistema de integración de memoria cross-modal que mantiene un contexto coherente en todas las modalidades a través de la síntesis y recuperación inteligente de información, evitando selectivamente las llamadas innecesarias de modalidad en determinados escenarios para mejorar la velocidad de respuesta. Evaluaciones exhaustivas demuestran que MLLM Orchestration consigue capacidades multimodales completas sin formación adicional, mejoras de rendimiento de hasta un 7,8% sobre los enfoques tradicionales entrenados conjuntamente en pruebas de referencia estándar, una latencia reducida en un 10,3% y una interpretabilidad significativamente mejorada mediante procesos de orquestación explícitos.",
    "source": "arXiv"
  },
  {
    "title": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx",
    "title_es": "Un proceso robusto para el aprendizaje federado diferencialmente privado sobre datos clínicos desequilibrados utilizando SMOTETomek y FedProx",
    "url": "https://arxiv.org/abs/2508.10017",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10017v1 Tipo de anuncio: nuevo\nResumen: Federated Learning (FL) presenta un enfoque innovador para la investigación sanitaria colaborativa, permitiendo el entrenamiento de modelos sobre datos descentralizados mientras se salvaguarda la privacidad del paciente. FL ofrece garantías formales de seguridad cuando se combina con Differential Privacy (DP). Sin embargo, la integración de estas tecnologías introduce una importante disyuntiva entre la privacidad y la utilidad clínica, un reto que se complica aún más por el grave desequilibrio de clases que a menudo presentan los conjuntos de datos médicos. La investigación que aquí se presenta aborda estas cuestiones interconectadas mediante un análisis sistemático en varias fases. Se implementó un marco FL para la predicción del riesgo cardiovascular, donde los experimentos iniciales mostraron que los métodos estándar tenían dificultades con los datos desequilibrados, lo que resultaba en una recuperación de cero. Para superar esta limitación, primero integramos la técnica híbrida de sobremuestreo de minorías sintéticas con enlaces Tomek (SMOTETomek) a nivel de cliente, desarrollando con éxito un modelo clínicamente útil. Posteriormente, el marco se optimizó para datos no IID mediante un algoritmo FedProx ajustado. Nuestros resultados finales revelan un claro equilibrio no lineal entre el presupuesto de privacidad (epsilon) y la recuperación del modelo, con el FedProx optimizado superando sistemáticamente al FedAvg estándar. Se identificó una región operativa óptima en la frontera privacidad-utilidad, en la que pueden lograrse fuertes garantías de privacidad (con epsilon 9,0) manteniendo al mismo tiempo una alta utilidad clínica (recuperación superior al 77%). En definitiva, nuestro estudio proporciona un modelo metodológico práctico para crear herramientas de diagnóstico eficaces, seguras y precisas que puedan aplicarse a datos sanitarios heterogéneos del mundo real.",
    "source": "arXiv"
  },
  {
    "title": "A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models",
    "title_es": "A Rose by Any Other Name Would Smell as Sweet: Teoría de la homotopía categorial para grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.10018",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10018v1 Anunciar Tipo: nuevo\nResumen: El lenguaje natural está repleto de enunciados superficialmente diferentes, como \"Charles Darwin escribió\" y \"Charles Darwin es el autor de\", que tienen el mismo significado. Los modelos de lenguaje extensos (LLM) deberían generar las mismas probabilidades de proximidad en estos casos, pero normalmente no lo hacen. Se han explorado soluciones empíricas, como el uso de estimaciones k-NN de similitud de frases para producir estimaciones suavizadas. En este artículo, abordamos este problema de forma más abstracta, introduciendo un marco de homotopía categórica para los LLM. Introducimos una categoría de Markov LLM para representar las distribuciones de probabilidad en el lenguaje generado por un LLM, donde la probabilidad de una frase, como \"Charles Darwin escribió\" se define por una flecha en una categoría de Markov. Sin embargo, este enfoque tropieza con dificultades, ya que el lenguaje está lleno de reformulaciones equivalentes, y cada una genera una flecha no isomórfica en la categoría de Markov del LLM. Para abordar este problema fundamental, utilizamos técnicas de homotopía categorial para capturar \"equivalencias débiles\" en una categoría de Markov LLM. Presentamos una visión detallada de la aplicación de la homotopía categorial a los LLM, desde la teoría K algebraica superior hasta las categorías modelo, basándonos en poderosos resultados teóricos desarrollados a lo largo del último medio siglo.",
    "source": "arXiv"
  },
  {
    "title": "Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning",
    "title_es": "Desvinculación de la comprensión y el razonamiento mediante el mapeo del espacio de problemas para el razonamiento de modelos a pequeña escala",
    "url": "https://arxiv.org/abs/2508.10019",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10019v1 Tipo de anuncio: nuevo\nResumen: A pesar de los recientes avances en las capacidades de razonamiento de los Modelos de Lenguaje Grande (LLMs), la mejora de la capacidad de razonamiento de los Modelos de Lenguaje Pequeño (SLMs, por ejemplo, $\\leq$ 1.5B) sigue siendo un reto. Un obstáculo clave reside en la complejidad y variabilidad del lenguaje natural: problemas esencialmente equivalentes aparecen a menudo en diversas formas superficiales, a menudo oscurecidas por detalles redundantes o que distraen. Esto impone una doble carga a los SLM: primero deben extraer el problema central de una entrada lingüística compleja y, a continuación, realizar un razonamiento basado en esa comprensión. El vasto y ruidoso espacio de problemas resultante dificulta la optimización, sobre todo para los modelos con capacidad limitada. Para solucionar este problema, proponemos un nuevo marco que disocia la comprensión del razonamiento mediante la asignación de los problemas del lenguaje natural a un espacio de problemas canónico, un dominio semánticamente simplificado pero expresivo. Esto permite a los SLM centrarse en el razonamiento sobre entradas estandarizadas, libres de variabilidad lingüística. Dentro de este marco, introducimos DURIT (Decoupled Understanding from Reasoning via Iterative Training), un algoritmo de tres pasos que iterativamente: (1) mapea problemas de lenguaje natural mediante aprendizaje por refuerzo, (2) alinea trayectorias de razonamiento mediante autodestilación, y (3) entrena políticas de razonamiento en el espacio de problemas. El mapeador y el razonador se entrenan conjuntamente en un bucle alterno a lo largo de este proceso. Los experimentos demuestran que DURIT mejora sustancialmente el rendimiento de los SLM en tareas de razonamiento lógico y matemático dentro y fuera del dominio. Además de mejorar las capacidades de razonamiento, DURIT también mejora la solidez del razonamiento, validando la disociación de la comprensión del razonamiento como una estrategia eficaz para fortalecer los SLM.",
    "source": "arXiv"
  },
  {
    "title": "FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models",
    "title_es": "FedCoT: Mejora del razonamiento federado eficiente desde el punto de vista de la comunicación para grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.10020",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10020v1 Tipo de anuncio: nuevo\nResumen: La mejora eficiente de las capacidades de razonamiento de los grandes modelos lingüísticos (LLM) en entornos de aprendizaje federados sigue siendo un reto, especialmente cuando se trata de equilibrar las ganancias de rendimiento con estrictas restricciones computacionales, de comunicación y de privacidad. Este reto es especialmente agudo en la atención sanitaria, donde las decisiones -que abarcan contextos clínicos, operativos y de cara al paciente- exigen no sólo resultados precisos, sino también razonamientos interpretables y trazables para garantizar la seguridad, la responsabilidad y el cumplimiento de la normativa. Los enfoques convencionales de ajuste federado en LLM no abordan esta necesidad: optimizan principalmente la corrección de las respuestas y descuidan la calidad de los razonamientos, lo que hace que las capacidades de CoT dependan de las capacidades innatas de preentrenamiento de los modelos. Además, los métodos existentes para mejorar los razonamientos suelen basarse en la destilación de conocimientos de modelos centralizados que viola la privacidad. Además, la sobrecarga de comunicación en el ajuste federado tradicional de los LLM sigue siendo considerable. Abordamos esta carencia proponiendo FedCoT, un novedoso marco diseñado específicamente para mejorar el razonamiento en entornos federados. FedCoT aprovecha un mecanismo ligero de mejora de la cadena de pensamiento: los modelos locales generan múltiples rutas de razonamiento y un discriminador compacto selecciona dinámicamente la más prometedora. Este enfoque mejora la precisión y robustez del razonamiento al tiempo que proporciona una valiosa interpretabilidad, especialmente crítica para las aplicaciones médicas. Para gestionar eficientemente la heterogeneidad de los clientes, adoptamos un enfoque de agregación mejorado basado en el apilamiento avanzado de módulos LoRA, que incorpora el conocimiento del clasificador del cliente para lograr una agregación sin ruido entre diversos clientes. Experimentos exhaustivos sobre tareas de razonamiento médico demuestran que FedCoT aumenta significativamente el rendimiento del razonamiento del lado del cliente con presupuestos de recursos estrictos, preservando al mismo tiempo la privacidad de los datos.",
    "source": "arXiv"
  },
  {
    "title": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients",
    "title_es": "LATTE: Aprendizaje de Transacciones Alineadas e Incrustaciones Textuales para Clientes Bancarios",
    "url": "https://arxiv.org/abs/2508.10021",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10021v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje de incrustaciones de clientes a partir de secuencias de sus comunicaciones históricas es fundamental para las aplicaciones financieras. Mientras que los modelos de grandes lenguajes (LLMs) ofrecen un conocimiento general del mundo, su uso directo en largas secuencias de eventos es computacionalmente costoso y poco práctico en pipelines del mundo real. En este artículo, proponemos LATTE, un marco de aprendizaje contrastivo que alinea incrustaciones de eventos sin procesar con incrustaciones semánticas de LLM congelados. Las características de comportamiento se resumen en breves indicaciones, incrustadas por el LLM, y se utilizan como supervisión a través de la pérdida contrastiva. El enfoque propuesto reduce significativamente el coste de la inferencia y el tamaño de la entrada en comparación con el procesamiento convencional de la secuencia completa por el LLM. Demostramos experimentalmente que nuestro método supera a las técnicas más avanzadas para el aprendizaje de representaciones de secuencias de eventos en conjuntos de datos financieros del mundo real, al tiempo que sigue siendo desplegable en entornos sensibles a la latencia.",
    "source": "arXiv"
  },
  {
    "title": "Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control",
    "title_es": "Valor P conforme en tareas de respuesta a preguntas de opción múltiple con control de riesgo demostrable",
    "url": "https://arxiv.org/abs/2508.10022",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10022v1 Tipo de anuncio: nuevo\nResumen: Este estudio introduce un marco de predicción conforme (CP) mejorado con pruebas de significación para mejorar la fiabilidad de los modelos lingüísticos de gran tamaño (LLM) en la respuesta a preguntas de elección múltiple (MCQA). Mientras que los LLMs se han desplegado cada vez más en escenarios disciplinarios de QA, la alucinación y la generación no factual comprometen sustancialmente la fiabilidad de la respuesta. Aunque el CP proporciona garantías de cobertura marginal estadísticamente rigurosas para los conjuntos de predicción, y las pruebas de significación ofrecen un rigor estadístico establecido, su integración sinérgica sigue sin explorarse. Para mitigar la alucinación y las imprecisiones factuales, nuestro marco integra el cálculo del valor $p$ con la puntuación de conformidad a través del remuestreo de autoconsistencia de las respuestas del MCQA. Este enfoque calcula las frecuencias de opción para abordar la naturaleza de caja negra de los LLM, construyendo posteriormente conjuntos de predicción mediante pruebas de hipótesis nulas ($\\mathcal{H}_0$) con valores $p$ derivados empíricamente. Las evaluaciones de los puntos de referencia MMLU y MMLU-Pro utilizando LLM disponibles en el mercado demuestran que: (1) el CP mejorado alcanza los índices empíricos de cobertura errónea especificados por el usuario; (2) el tamaño medio del conjunto de predicción de prueba (APSS) disminuye monotónicamente con el aumento de los niveles de riesgo ($\\alpha$), validando el APSS como una métrica de incertidumbre eficaz. Este trabajo establece un marco estadístico basado en principios para el despliegue fiable de LLM en aplicaciones de control de calidad de alto riesgo.",
    "source": "arXiv"
  },
  {
    "title": "A Comparative Performance Evaluation of Kyber, sntrup761, and FrodoKEM for Post-Quantum Cryptography",
    "title_es": "Evaluación comparativa del rendimiento de Kyber, sntrup761 y FrodoKEM para criptografía postcuántica",
    "url": "https://arxiv.org/abs/2508.10023",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10023v1 Tipo de anuncio: nuevo\nResumen: La criptografía postcuántica (PQC) tiene como objetivo desarrollar algoritmos criptográficos que sean seguros frente a ataques de ordenadores cuánticos. Este artículo compara los principales algoritmos criptográficos poscuánticos, como Kyber, sntrup761 y FrodoKEM, en términos de seguridad, rendimiento y aplicabilidad en el mundo real. La revisión pone de relieve los puntos fuertes y débiles de cada algoritmo y aporta ideas sobre futuras líneas de investigación. También se analizan los retos que plantea la transición de los sistemas clásicos a los poscuánticos y las posibles repercusiones en diversos sectores. Este artículo sirve de base para comprender el estado actual de la criptografía poscuántica y sus perspectivas de futuro en la era de la computación cuántica.",
    "source": "arXiv"
  },
  {
    "title": "RTTC: Reward-Guided Collaborative Test-Time Compute",
    "title_es": "RTTC: cálculo colaborativo del tiempo de prueba guiado por recompensas",
    "url": "https://arxiv.org/abs/2508.10024",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10024v1 Tipo de anuncio: nuevo\nResumen: Test-Time Compute (TTC) ha emergido como un poderoso paradigma para mejorar el rendimiento de los Large Language Models (LLMs) en inferencia, aprovechando estrategias como Test-Time Training (TTT) y Retrieval-Augmented Generation (RAG). Sin embargo, la estrategia de adaptación óptima varía en función de las consultas, y la aplicación indiscriminada de la estrategia TTC incurre en una sobrecarga computacional sustancial. En este trabajo introducimos RTTC (Reward-Guided Test-Time Compute), un novedoso marco que selecciona de forma adaptativa la estrategia TTC más efectiva para cada consulta a través de un modelo de recompensa preentrenado, maximizando la precisión descendente en diversos dominios y tareas. RTTC opera en una arquitectura distribuida servidor-cliente, recuperando muestras relevantes de una base de conocimientos remota y aplicando RAG o un ajuste fino ligero en los dispositivos cliente sólo cuando es necesario. Para mitigar aún más la computación redundante, proponemos el almacenamiento en caché del estado de la consulta, que permite la reutilización eficiente de los estados históricos de la consulta tanto a nivel de recuperación como de adaptación. Extensos experimentos con múltiples LLM y puntos de referencia demuestran que RTTC logra sistemáticamente una precisión superior en comparación con RAG o TTT, validando la necesidad de una selección de TTC adaptativa y guiada por recompensa y el potencial de RTTC para una adaptación de modelos lingüísticos escalable y de alto rendimiento.",
    "source": "arXiv"
  },
  {
    "title": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence",
    "title_es": "Detección y explicación de la depresión posparto en tiempo real mediante inteligencia artificial generativa",
    "url": "https://arxiv.org/abs/2508.10025",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10025v1 Tipo de anuncio: nuevo\nResumen: Entre los muchos retos a los que se enfrentan las madres tras el parto, la depresión posparto (DPP) es una enfermedad grave que afecta significativamente a su bienestar mental y físico. En consecuencia, la rápida detección de la DPP y sus factores de riesgo asociados es crítica para la evaluación e intervención a tiempo a través de procedimientos especializados de prevención. En consecuencia, este trabajo aborda la necesidad de ayudar a los profesionales a tomar decisiones con los últimos avances tecnológicos para permitir la detección en tiempo real y las recomendaciones de tratamiento. Principalmente, nuestro trabajo contribuye a un sistema inteligente de cribado PPD que combina el Procesamiento del Lenguaje Natural, el Aprendizaje Automático (ML) y los Grandes Modelos de Lenguaje (LLM) hacia un análisis del habla libre asequible, en tiempo real y no invasivo. Además, aborda el problema de la caja negra, ya que las predicciones se describen a los usuarios finales gracias a la combinación de LLMs con modelos de ml interpretables (es decir, algoritmos basados en árboles) utilizando la importancia de las características y el lenguaje natural. Los resultados obtenidos son del 90 % en detección de ppd para todas las métricas de evaluación, superando a las soluciones competidoras de la literatura. En última instancia, nuestra solución contribuye a la rápida detección de PPD y sus factores de riesgo asociados, fundamental para una evaluación e intervención adecuadas y a tiempo.",
    "source": "arXiv"
  },
  {
    "title": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning",
    "title_es": "SABER: formación conmutable y equilibrada para un razonamiento LLM eficiente",
    "url": "https://arxiv.org/abs/2508.10026",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10026v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos de lenguaje (LLMs) potenciados por el razonamiento en cadena han alcanzado una precisión impresionante en tareas complejas, pero sufren de costes de inferencia y latencia excesivos cuando se aplican uniformemente a todos los problemas. Proponemos SABER (Switchable and Balanced Training for Efficient LLM Reasoning), un marco de aprendizaje por refuerzo que dota a los LLM de un razonamiento controlado por el usuario y presupuestado en fichas. SABER perfila en primer lugar el uso de fichas de razonamiento del modelo base de cada ejemplo de entrenamiento y lo asigna a uno de los niveles de presupuesto predefinidos. Durante la puesta a punto, el modelo se guía por avisos del sistema y recompensas en función de la longitud para respetar el presupuesto asignado. Paralelamente, incorporamos ejemplos de no-pensamiento para garantizar que el modelo sigue siendo fiable incluso cuando se desactiva el razonamiento explícito. SABER admite además cuatro modos de inferencia discreta: NoThink, FastThink, CoreThink y DeepThink, que permiten un equilibrio flexible entre latencia y profundidad de razonamiento. Las exhaustivas evaluaciones sobre razonamiento matemático (MATH, GSM8K), generación de código (MBPP) y razonamiento lógico (LiveBench-Reasoning) demuestran que SABER logra una gran precisión con presupuestos ajustados, una degradación gradual y una generalización eficaz entre dominios y escalas. En concreto, SABER-FastThink reduce la longitud del razonamiento en un 65,4% y proporciona un aumento de la precisión del 3,6% en comparación con el modelo base en la prueba MATH.",
    "source": "arXiv"
  },
  {
    "title": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data",
    "title_es": "LLMCARE: Detección de Alzheimer mediante modelos de transformada mejorados con datos sintéticos generados por LLM",
    "url": "https://arxiv.org/abs/2508.10027",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10027v1 Tipo de anuncio: nuevo\nResumen: La enfermedad de Alzheimer y las demencias relacionadas (ADRD) afectan aproximadamente a cinco millones de adultos mayores en los EE.UU., sin embargo, más de la mitad permanecen sin diagnosticar. El procesamiento del lenguaje natural (PLN) basado en el habla ofrece un enfoque prometedor y escalable para detectar el deterioro cognitivo temprano a través de marcadores lingüísticos.\n  El objetivo es desarrollar y evaluar un proceso de cribado que (i) fusione la incrustación de transformadores con características lingüísticas elaboradas a mano, (ii) pruebe el aumento de datos utilizando habla sintética generada por grandes modelos lingüísticos (LLM) y (iii) evalúe comparativamente los clasificadores LLM unimodales y multimodales para la detección de ADRD.\n  Se utilizaron transcripciones de la tarea \"robo de galletas\" de DementiaBank (n = 237). Se evaluaron diez modelos transformadores con tres estrategias de ajuste. Un modelo de fusión combinó las incrustaciones del transformador de mejor rendimiento con 110 características lingüísticas derivadas del léxico. Cinco LLM (LLaMA-8B/70B, MedAlpaca-7B, Ministral-8B, GPT-4o) se ajustaron para generar habla sintética condicionada por etiquetas, que se utilizó para aumentar los datos de entrenamiento. Se probaron tres modelos multimodales (GPT-4o, Qwen-Omni, Phi-4) para la clasificación habla-texto en las configuraciones de disparo cero y ajuste fino.\n  El modelo de fusión alcanzó F1 = 83,3 (AUC = 89,5), superando a los modelos de referencia lingüísticos o basados únicamente en transformadores. El aumento de los datos de entrenamiento con 2x de habla sintética MedAlpaca-7B aumentó la F1 a 85,7. El ajuste fino mejoró significativamente los clasificadores LLM unimodales (por ejemplo, MedAlpaca: F1 = 47,3 -> 78,5 F1). Los modelos multimodales actuales mostraron un rendimiento inferior (GPT-4o = 70,2 F1; Qwen = 66,0). Las mejoras de rendimiento se alinearon con la similitud distributiva entre el habla sintética y el habla real.\n  La integración de transformadores con características lingüísticas mejora la detección de ADRD a partir del habla. Los LLM sintonizados clínicamente apoyan eficazmente tanto la clasificación como el aumento de datos, mientras que se necesita un mayor avance en el modelado multimodal.",
    "source": "arXiv"
  },
  {
    "title": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs",
    "title_es": "PREF: Evaluación sin referencias de la generación de textos personalizados en los LLM",
    "url": "https://arxiv.org/abs/2508.10028",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10028v1 Anunciar Tipo: nuevo\nResumen: La generación de textos personalizados es esencial para los sistemas de información centrados en el usuario, sin embargo, la mayoría de los métodos de evaluación pasan por alto la individualidad de los usuarios. Presentamos \\textbf{PREF}, un \\textbf{P}método de \\textbf{R}evaluación \\textbf{E}personalizada que mide conjuntamente la calidad general del resultado y la alineación específica del usuario sin necesidad de referencias personalizadas. PREF funciona en tres etapas: (1) una etapa de cobertura utiliza un modelo de lenguaje amplio (LLM) para generar una directriz exhaustiva y específica de la consulta que cubre criterios universales como la factualidad, la coherencia y la exhaustividad; (2) una etapa de preferencia vuelve a clasificar y aumenta selectivamente estos factores utilizando el perfil del usuario objetivo, las preferencias declaradas o inferidas y el contexto, produciendo una rúbrica de evaluación personalizada; y (3) una etapa de puntuación aplica un juez LLM para calificar las respuestas candidatas con respecto a esta rúbrica, garantizando la adecuación de la línea de base al tiempo que captura las prioridades subjetivas. Esta separación entre cobertura y preferencia mejora la solidez, la transparencia y la reutilización, y permite que los modelos más pequeños se aproximen a la calidad personalizada de los más grandes. Los experimentos realizados en la prueba de referencia PrefEval, que incluyen tareas implícitas de seguimiento de preferencias, demuestran que PREF consigue una mayor precisión, una mejor calibración y una mayor alineación con los juicios humanos que las líneas de base sólidas. Al permitir una evaluación escalable, interpretable y alineada con el usuario, PREF sienta las bases para una evaluación más fiable y el desarrollo de sistemas de generación de lenguaje personalizados.",
    "source": "arXiv"
  },
  {
    "title": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs",
    "title_es": "Fusión latente Jailbreak: Combinación de representaciones dañinas e inofensivas para obtener resultados LLM inseguros",
    "url": "https://arxiv.org/abs/2508.10029",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10029v1 Tipo de anuncio: nuevo\nResumen: Los modelos lingüísticos grandes (LLMs) demuestran capacidades impresionantes en varias tareas lingüísticas pero son susceptibles a ataques de jailbreak que eluden sus alineaciones de seguridad. Este artículo presenta el Latent Fusion Jailbreak (LFJ), un ataque basado en la representación que interpola estados ocultos de pares de consultas dañinas y benignas para obtener respuestas prohibidas. LFJ comienza seleccionando pares de consultas con una gran similitud temática y sintáctica, luego realiza una interpolación guiada por gradientes en capas y tokens influyentes, seguida de una optimización para equilibrar el éxito del ataque, la fluidez de los resultados y la eficiencia computacional. Las evaluaciones de modelos como Vicuna y LLaMA-2 en puntos de referencia como AdvBench y MaliciousInstruct arrojan una tasa media de éxito de los ataques (ASR) del 94,01%, superando a los métodos existentes. Para mitigar LFJ, proponemos una defensa de entrenamiento adversarial que afina los modelos en ejemplos interpolados, reduciendo ASR en más del 80% sin degradar el rendimiento en entradas benignas. Los estudios de ablación validan la importancia de la selección de pares de consulta, los componentes de interpolación de estados ocultos y las estrategias de optimización en la eficacia de LFJ.",
    "source": "arXiv"
  },
  {
    "title": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models",
    "title_es": "Optimización de avisos basada en la inferencia para alinear grandes modelos lingüísticos de caja negra",
    "url": "https://arxiv.org/abs/2508.10030",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10030v1 Tipo de anuncio: nuevo\nResumen: Los métodos de optimización de prompt han demostrado una eficacia significativa en la alineación de grandes modelos de lenguaje (LLMs) de caja negra. Paralelamente, las estrategias de escalado de inferencia como Best-of-N Sampling y Majority Voting también han demostrado mejorar la alineación y el rendimiento mediante el intercambio de computación. Sin embargo, los enfoques de optimización de avisos existentes no tienen en cuenta la estrategia de inferencia; es decir, optimizan los avisos sin tener en cuenta la estrategia de inferencia empleada durante el despliegue. Esto constituye una importante laguna metodológica, ya que nuestro análisis empírico y teórico revela una fuerte interdependencia entre estos dos paradigmas. Además, hemos observado que las preferencias de los usuarios en cuanto a la compensación entre objetivos múltiples y presupuestos de inferencia influyen sustancialmente en la elección de la configuración de los avisos y la inferencia. Para colmar esta laguna, introducimos un nuevo marco unificado denominado IAPO (Inference-Aware Prompt Optimization) que optimiza de forma conjunta la escala de las instrucciones y la inferencia, teniendo en cuenta el presupuesto de inferencia y los diferentes objetivos de la tarea. A continuación, desarrollamos un algoritmo de entrenamiento de presupuesto fijo para IAPO, que denominamos PSST (Prompt Scaling via Sequential Trimming), y analizamos las garantías de presupuesto finito en la probabilidad de error. Por último, evaluamos la eficacia de PSST en seis tareas diferentes, incluyendo la generación de texto multiobjetivo y el razonamiento, y demostramos el papel crítico de la incorporación de la conciencia de la inferencia cuando se alinean los LLM de caja negra a través de la optimización de las instrucciones.",
    "source": "arXiv"
  },
  {
    "title": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs",
    "title_es": "El contexto induce a error a los LLM: El papel del filtrado del contexto en el mantenimiento de la alineación segura de los LLM",
    "url": "https://arxiv.org/abs/2508.10031",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10031v1 Tipo de anuncio: nuevo\nResumen: Mientras que los Modelos de Lenguaje Amplio (LLMs) han mostrado avances significativos en rendimiento, varios ataques de jailbreak han planteado crecientes riesgos éticos y de seguridad. Los usuarios maliciosos a menudo explotan el contexto adverso para engañar a los LLMs, induciéndoles a generar respuestas a consultas dañinas. En este estudio, proponemos un nuevo mecanismo de defensa denominado modelo de filtrado de contexto, un método de preprocesamiento de entrada diseñado para filtrar el contexto no fiable y de poca confianza, al tiempo que identifica las indicaciones principales que contienen la intención real del usuario para descubrir la intención maliciosa oculta. Dado que mejorar la seguridad de los LLM a menudo compromete su utilidad, afectando potencialmente a la experiencia de los usuarios benignos, nuestro método pretende mejorar la seguridad de los LLM preservando su rendimiento original. Evaluamos la eficacia de nuestro modelo en la defensa contra ataques de fuga de la cárcel a través de un análisis comparativo, comparando nuestro enfoque con los mecanismos de defensa más avanzados contra seis ataques diferentes y evaluando la utilidad de los LLM bajo estas defensas. Nuestro modelo demuestra su capacidad para reducir las Tasas de Éxito de Ataque de los ataques de fuga de la cárcel hasta en un 88%, manteniendo el rendimiento de los LLM originales y logrando los mejores resultados de Seguridad y Utilidad. En particular, nuestro modelo es un método plug-and-play que puede aplicarse a todos los LLM, incluidos los modelos de caja blanca y caja negra, para mejorar su seguridad sin necesidad de ajustar los propios modelos. Pondremos nuestro modelo a disposición del público con fines de investigación.",
    "source": "arXiv"
  },
  {
    "title": "The Cost of Thinking: Increased Jailbreak Risk in Large Language Models",
    "title_es": "El coste de pensar: Mayor riesgo de fuga en los modelos lingüísticos de gran tamaño",
    "url": "https://arxiv.org/abs/2508.10032",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10032v1 Tipo de anuncio: nuevo\nResumen: El modo de pensar siempre se ha considerado uno de los modos más valiosos en los LLM. Sin embargo, descubrimos un fenómeno sorprendente y previamente pasado por alto: Los LLMs con modo pensamiento son más fáciles de romper mediante un ataque Jailbreak. Evaluamos 9 LLMs en AdvBench y HarmBench y descubrimos que la tasa de éxito del ataque al modo pensante en los LLMs es casi mayor que la del modo no pensante. A través de un gran número de estudios de muestra, se encuentra que con fines educativos y excesivamente largas longitudes de pensamiento son las características de los datos atacados con éxito, y LLMs también dan respuestas perjudiciales cuando en su mayoría saben que las preguntas son perjudiciales. Con el fin de aliviar los problemas anteriores, este trabajo propone un método de intervención de pensamiento seguro para LLMs, que guía explícitamente los procesos de pensamiento interno de LLMs mediante la adición de \"fichas de pensamiento específicas\" de LLMs al prompt. Los resultados demuestran que la intervención de pensamiento seguro puede reducir significativamente la tasa de éxito de los ataques de los LLM con modo de pensamiento.",
    "source": "arXiv"
  },
  {
    "title": "Cognitive Cybersecurity for Artificial Intelligence: Guardrail Engineering with CCS-7",
    "title_es": "Ciberseguridad cognitiva para la inteligencia artificial: Ingeniería de barandillas con CCS-7",
    "url": "https://arxiv.org/abs/2508.10033",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10033v1 Tipo de anuncio: nuevo\nResumen: Los modelos lingüísticos muestran vulnerabilidades cognitivas similares a las humanas, como el encuadre emocional, que escapan a la alineación conductual tradicional. Presentamos CCS-7 (Cognitive Cybersecurity Suite), una taxonomía de siete vulnerabilidades basadas en la investigación de la seguridad cognitiva humana. Para establecer un punto de referencia humano, realizamos un ensayo controlado aleatorio con 151 participantes: una lección de \"pensar primero, verificar siempre\" (TFVA) mejoró la seguridad cognitiva en un +7,9% en general. A continuación, evaluamos barreras de seguridad del tipo TFVA en 12.180 experimentos con siete arquitecturas de modelos lingüísticos diferentes. Los resultados revelan patrones de riesgo dependientes de la arquitectura: algunas vulnerabilidades (por ejemplo, la confusión de identidad) se mitigan casi por completo, mientras que otras (por ejemplo, la interferencia de la fuente) muestran un contragolpe creciente, con tasas de error que aumentan hasta un 135% en ciertos modelos. Los humanos, en cambio, muestran una mejora moderada y constante. Estos resultados replantean la seguridad cognitiva como un problema de ingeniería específico de cada modelo: las intervenciones eficaces en una arquitectura pueden fallar o perjudicar activamente a otra, lo que subraya la necesidad de realizar pruebas de seguridad cognitiva conscientes de la arquitectura antes de su despliegue.",
    "source": "arXiv"
  },
  {
    "title": "Neural Network-Based Detection and Multi-Class Classification of FDI Attacks in Smart Grid Home Energy Systems",
    "title_es": "Detección basada en redes neuronales y clasificación multiclase de ataques IED en sistemas de energía doméstica de red inteligente",
    "url": "https://arxiv.org/abs/2508.10035",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10035v1 Tipo de anuncio: nuevo\nResumen: Los Ataques de Inyección de Datos Falsos (FDIAs, por sus siglas en inglés) suponen una amenaza significativa para las infraestructuras de redes inteligentes, particularmente las Redes de Área Doméstica (HANs, por sus siglas en inglés), donde la monitorización y el control en tiempo real son altamente adoptados. Debido a los controles de seguridad comparativamente menos estrictos y a la amplia disponibilidad de las HAN, los atacantes las ven como un atractivo punto de entrada para manipular patrones de demanda agregada, que en última instancia pueden propagarse y perturbar el funcionamiento de la red en general. Estos ataques socavan la integridad de los datos de los contadores inteligentes y permiten a los malintencionados manipular los valores de consumo sin activar las alarmas convencionales, creando así graves vulnerabilidades tanto en las infraestructuras residenciales como en las de servicios públicos. Este artículo presenta un marco basado en aprendizaje automático para la detección y clasificación de FDIAs utilizando datos de energía residencial. La Red Neuronal Artificial (RNA) ligera proporciona una detección en tiempo real, que funciona utilizando las características más vitales del consumo de energía, el coste y el contexto temporal. Para la clasificación de los distintos tipos de ataque, se entrena una LSTM bidireccional para reconocer formas de ataque normales, trapezoidales y sigmoidales mediante el aprendizaje de dependencias secuenciales en los datos. Se generó un conjunto de datos de series temporales sintéticas para emular el comportamiento realista de los hogares. Los resultados experimentales demuestran que los modelos propuestos son eficaces para identificar y clasificar los FDIA, ofreciendo una solución escalable para mejorar la resistencia de la red en el borde. Este trabajo contribuye a la creación de mecanismos de defensa inteligentes y basados en datos que refuerzan la ciberseguridad de las redes inteligentes desde los extremos residenciales.",
    "source": "arXiv"
  },
  {
    "title": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion",
    "title_es": "Reflexionar para luego aprender: Estimulación activa de la extracción de información guiada por la confusión introspectiva",
    "url": "https://arxiv.org/abs/2508.10036",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10036v1 Anunciar Tipo: nuevo\nResumen: Los Large Language Models (LLMs) muestran un potencial notable para la extracción de información (IE) de pocos disparos, sin embargo, su rendimiento es altamente sensible a la elección de ejemplos en contexto. Las estrategias de selección convencionales a menudo no proporcionan una guía informativa, ya que pasan por alto una fuente clave de la falibilidad del modelo: la confusión derivada no sólo del contenido semántico, sino también de la generación de formatos bien estructurados requeridos por las tareas de EI. Para hacer frente a este problema, presentamos el método Active Prompting for Information Extraction (APIE), un novedoso marco de orientación activa guiado por un principio que denominamos confusión introspectiva. Nuestro método permite a un LLM evaluar su propia confusión a través de una métrica de incertidumbre de doble componente que cuantifica de forma única tanto la incertidumbre de formato (dificultad para generar la sintaxis correcta) como la incertidumbre de contenido (incoherencia en la semántica extraída). Al clasificar los datos no etiquetados con esta puntuación global, nuestro marco selecciona activamente las muestras más desafiantes e informativas para que sirvan como ejemplares de pocos disparos. Experimentos exhaustivos con cuatro puntos de referencia demuestran que nuestro método supera sistemáticamente a las líneas de base más sólidas, lo que se traduce en mejoras significativas tanto en la precisión de la extracción como en su solidez. Nuestro trabajo subraya la importancia crítica de una visión detallada y de doble nivel de la incertidumbre del modelo a la hora de crear sistemas de generación estructurada eficaces y fiables.",
    "source": "arXiv"
  },
  {
    "title": "Certifiably robust malware detectors by design",
    "title_es": "Detectores de malware certificados y robustos por diseño",
    "url": "https://arxiv.org/abs/2508.10038",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10038v1 Tipo de anuncio: nuevo\nResumen: El análisis de malware consiste en analizar software sospechoso para detectar cargas maliciosas. El análisis estático de malware, que no requiere la ejecución de software, se basa cada vez más en técnicas de aprendizaje automático para lograr escalabilidad. Aunque estas técnicas obtienen una precisión de detección muy alta, pueden burlarse fácilmente con ejemplos adversos en los que unas pocas modificaciones de la muestra pueden engañar al detector sin modificar el comportamiento del software. A diferencia de otros dominios, como la visión por ordenador, crear un ejemplo adversario de malware sin alterar su funcionalidad requiere transformaciones específicas. Proponemos una nueva arquitectura de modelos para la detección de malware certificablemente robusta por diseño. Además, demostramos que todo detector robusto puede descomponerse en una estructura específica, que puede aplicarse para aprender detectores de malware empíricamente robustos, incluso sobre características frágiles. Nuestro marco ERDALT se basa en esta estructura. Comparamos y validamos estos enfoques con métodos de detección de malware basados en aprendizaje automático, lo que permite una detección robusta con una reducción limitada del rendimiento de detección.",
    "source": "arXiv"
  },
  {
    "title": "Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries",
    "title_es": "Ataques adversarios multitarea contra el modelo de caja negra con consultas de pocos disparos",
    "url": "https://arxiv.org/abs/2508.10039",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10039v1 Tipo de anuncio: nuevo\nResumen: Los ataques actuales contra textos adversarios multitarea se basan en un acceso abundante a características internas compartidas y en numerosas consultas, a menudo limitadas a un único tipo de tarea. Como resultado, estos ataques son menos efectivos contra escenarios prácticos que implican APIs de retroalimentación de caja negra, consultas limitadas o múltiples tipos de tareas. Para colmar esta laguna, proponemos el ataque de texto adversario multitarea (\\textbf{CEMA}), un eficaz ataque de caja negra que explota la transferibilidad de los textos adversarios a través de diferentes tareas. CEMA simplifica los complejos escenarios multitarea utilizando un \\textit{modelo sustitutivo de nivel profundo} entrenado de forma \\textit{plug-and-play} para la clasificación de textos, lo que permite realizar ataques sin imitar el modelo de la víctima. Este enfoque requiere sólo unas pocas consultas para el entrenamiento, convirtiendo los ataques multitarea en ataques de clasificación y permitiendo ataques a través de varias tareas.\n  CEMA genera múltiples candidatos adversarios utilizando diferentes métodos de clasificación de textos y selecciona el que ataca con mayor eficacia a los modelos sustitutos.\n  En experimentos con modelos multitarea de dos, tres o seis tareas (clasificación, traducción, resumen y conversión de texto en imagen), CEMA demuestra un éxito significativo de los ataques con tan sólo 100 consultas. Además, CEMA puede atacar API comerciales (por ejemplo, Baidu y Google Translate), grandes modelos lingüísticos (por ejemplo, ChatGPT 4o) y modelos de generación de imágenes (por ejemplo, Stable Diffusion V2), lo que demuestra su versatilidad y eficacia en aplicaciones reales.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Content and Social Connections of Fake News with Explainable Text and Graph Learning",
    "title_es": "Exploración del contenido y las conexiones sociales de las noticias falsas con texto explicable y aprendizaje de gráficos",
    "url": "https://arxiv.org/abs/2508.10040",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10040v1 Tipo de anuncio: nuevo\nResumen: La propagación mundial de la desinformación y la preocupación por la fiabilidad de los contenidos han impulsado el desarrollo de sistemas automatizados de comprobación de hechos. Dado que la información falsa suele aprovechar la dinámica de las redes sociales, como los \"me gusta\" y las redes de usuarios, para amplificar su alcance, las soluciones eficaces deben ir más allá del análisis de contenidos e incorporar estos factores. Además, limitarse a etiquetar los contenidos como falsos puede resultar ineficaz o incluso reforzar sesgos como la automatización y el sesgo de confirmación. Este artículo propone un marco explicable que combina contenido, redes sociales y características basadas en gráficos para mejorar la comprobación de hechos. Integra un clasificador de desinformación con técnicas de explicabilidad para ofrecer información completa e interpretable que respalde las decisiones de clasificación. Los experimentos demuestran que la información multimodal mejora el rendimiento respecto a las modalidades individuales, con evaluaciones realizadas en conjuntos de datos en inglés, español y portugués. Además, se evaluó la interpretabilidad, fiabilidad y solidez de las explicaciones del marco con un protocolo novedoso, demostrando que genera de forma eficaz justificaciones comprensibles para el ser humano para sus predicciones.",
    "source": "arXiv"
  },
  {
    "title": "Quantum Prime Factorization: A Novel Approach Based on Fermat Method",
    "title_es": "Factorización Cuántica de Primeros: Un nuevo enfoque basado en el método de Fermat",
    "url": "https://arxiv.org/abs/2508.10041",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10041v1 Tipo de anuncio: nuevo\nResumen: En este trabajo introducimos un novedoso algoritmo cuántico para la factorización de números impares compuestos. Este trabajo hace dos contribuciones significativas. En primer lugar, presentamos una nueva mejora del método clásico de Fermat, reduciendo cuatro veces la complejidad computacional de la factorización. En segundo lugar, reformulamos el método de factorización de Fermat como un problema de optimización adecuado para los Recalentadores Cuánticos, lo que nos permitió factorizar 8.689.739, el mayor número jamás factorizado utilizando un dispositivo cuántico hasta donde sabemos.",
    "source": "arXiv"
  },
  {
    "title": "FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning",
    "title_es": "FIDELIS: protección mediante cadena de bloques contra ataques de envenenamiento en el aprendizaje federado",
    "url": "https://arxiv.org/abs/2508.10042",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10042v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje federado mejora el aprendizaje profundo tradicional al permitir el entrenamiento conjunto de un modelo con el uso de datos privados del dispositivo IoT. Garantiza la privacidad de los clientes, pero es susceptible a ataques de envenenamiento de datos durante el entrenamiento que degradan el rendimiento y la integridad del modelo. Los métodos actuales de detección de envenenamiento en el aprendizaje federado carecen de un método de detección estandarizado o se toman libertades significativas con la confianza. En este artículo, presentamos \\Sys, un novedoso marco de detección de envenenamiento basado en blockchain para el aprendizaje federado. El marco descentraliza el papel del servidor global entre los clientes participantes. Introducimos un modelo de juez utilizado para detectar el envenenamiento de datos en las actualizaciones del modelo. El modelo de juez es producido por cada cliente y verificado para llegar a un consenso sobre un único modelo de juez. Implementamos nuestra solución para demostrar que \\Sys es robusto frente a los ataques de envenenamiento de datos y que la creación de nuestro modelo de juez es escalable.",
    "source": "arXiv"
  },
  {
    "title": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System",
    "title_es": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System (Seguridad de la inteligencia artificial agéntica: modelado de amenazas y análisis de riesgos para el sistema de inteligencia artificial agéntica de supervisión de redes)",
    "url": "https://arxiv.org/abs/2508.10043",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10043v1 Tipo de anuncio: nuevo\nResumen: La combinación de Large Language Models (LLMs) con agentes autónomos, utilizados en sistemas de monitorización de redes y toma de decisiones, creará serios problemas de seguridad. En esta investigación, se utilizó el marco MAESTRO que consiste en la arquitectura de modelado de amenazas de siete capas en el sistema para exponer, evaluar y eliminar las vulnerabilidades de la IA agéntica. Se construyó e implementó el prototipo del sistema de agentes, utilizando Python, LangChain y telemetría en WebSockets, y se desplegó con módulos de inferencia, memoria, ajuste de parámetros y detección de anomalías. Se confirmaron dos casos prácticos de amenazas (i) denegación de servicio de recursos mediante la denegación de servicio de repetición de tráfico, y (ii) envenenamiento de memoria mediante la manipulación del archivo de registro histórico mantenido por el agente. Estas situaciones dieron lugar a niveles mensurables de degradación del rendimiento, es decir, se retrasaron las actualizaciones de telemetría y aumentaron las cargas computacionales, como resultado de las malas adaptaciones del sistema. Se sugirió utilizar un enfoque de defensa en profundidad multicapa con aislamiento de memoria, validación de planificadores y sistemas de respuesta a anomalías en tiempo real. Estos resultados verifican que MAESTRO es viable en la cartografía de amenazas operativas, la puntuación prospectiva de riesgos y la base del diseño de sistemas resilientes. Los autores llaman la atención sobre la importancia de la aplicación de la integridad de la memoria, prestando atención a la supervisión de la lógica de adaptación, y la protección de la comunicación entre capas que garantizan la fiabilidad de la IA agéntica en entornos adversarios.",
    "source": "arXiv"
  },
  {
    "title": "Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions",
    "title_es": "IA generativa para la ciberseguridad de los sistemas de gestión de la energía: Métodos, retos y orientaciones futuras",
    "url": "https://arxiv.org/abs/2508.10044",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10044v1 Tipo de anuncio: nuevo\nResumen: Este trabajo elabora un amplio marco de seguridad diseñado específicamente para sistemas de gestión de energía (EMSs), que aborda eficazmente el entorno dinámico de vulnerabilidades de ciberseguridad y/o problemas del sistema (SPs), logrado a través de la incorporación de metodologías novedosas. Inicialmente se propone un modelo integral de ataque/error multipunto para identificar sistemáticamente las vulnerabilidades a lo largo de toda la tubería de procesamiento de datos de los EMS, incluidos los ataques furtivos posteriores a la estimación del estado (SE), la manipulación de la base de datos de los EMS y la corrupción de la pantalla de la interfaz hombre-máquina (HMI) según el almacenamiento de la base de datos en tiempo real (RTDB). Este marco reconoce la naturaleza interconectada de los vectores de ataque modernos, que utilizan varias fases del flujo de datos de control supervisor y adquisición de datos (SCADA). A continuación, se proponen por primera vez en el ámbito de los sistemas eléctricos sistemas de detección de anomalías basados en IA generativa (GenAI). Además, se sugiere un marco de inteligencia generativa de conjunto de marcas (SoM-GI), que aprovecha el análisis multimodal integrando marcadores visuales con reglas que tienen en cuenta las capacidades de GenAI, para superar las limitaciones inherentes al razonamiento espacial. La metodología SoM-GI emplea indicadores visuales sistemáticos para permitir una interpretación precisa de las pantallas HMI segmentadas y detectar anomalías visuales que los métodos numéricos no logran identificar. La validación en el sistema IEEE 14-Bus muestra la eficacia del marco en distintos escenarios, mientras que el análisis visual identifica las incoherencias. Este enfoque integrado combina el análisis numérico con el reconocimiento visual de patrones y las reglas lingüísticas para proteger contra las ciberamenazas y los errores del sistema.",
    "source": "arXiv"
  },
  {
    "title": "SABIA: An AI-Powered Tool for Detecting Opioid-Related Behaviors on Social Media",
    "title_es": "SABIA: Una herramienta de inteligencia artificial para detectar comportamientos relacionados con los opiáceos en las redes sociales",
    "url": "https://arxiv.org/abs/2508.10046",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10046v1 Tipo de anuncio: nuevo\nResumen: Las plataformas de medios sociales se han convertido en herramientas valiosas para comprender los retos de la salud pública al ofrecer información sobre los comportamientos de los pacientes, el uso de medicamentos y los problemas de salud mental. Sin embargo, el análisis de estos datos sigue siendo difícil debido a la prevalencia del lenguaje informal, la jerga y la comunicación codificada, que pueden ocultar la detección del uso indebido de opioides. Este estudio aborda la cuestión del comportamiento de los usuarios de opiáceos en las redes sociales, incluidas las expresiones informales, los términos del argot y el lenguaje mal escrito o codificado. Analizamos la técnica Bidirectional Encoder Representations from Transformers (BERT) existente y desarrollamos un modelo de aprendizaje profundo híbrido BERT-BiLSTM-3CNN, denominado SABIA, para crear un clasificador de una sola tarea que captura eficazmente las características del conjunto de datos objetivo. El modelo SABIA demostró fuertes capacidades para capturar la semántica y la información contextual. El enfoque propuesto incluye (1) preprocesamiento de datos, (2) representación de datos utilizando el modelo SABIA, (3) una fase de ajuste fino, y (4) clasificación del comportamiento del usuario en cinco categorías. Se construyó un nuevo conjunto de datos a partir de las publicaciones de Reddit, identificando los comportamientos de los usuarios de opiáceos en cinco clases: Distribuidores, Consumidores Activos de Opioides, Consumidores Recuperados, Consumidores con Receta y No Consumidores, con el apoyo de directrices de anotación detalladas. Los experimentos se realizaron mediante aprendizaje supervisado. Los resultados muestran que SABIA alcanzó un rendimiento de referencia, superando la línea de base (Regresión Logística, LR = 0,86) y mejorando la precisión en un 9,30%. Las comparaciones con siete estudios anteriores confirmaron su eficacia y robustez. Este estudio demuestra el potencial de los modelos híbridos de aprendizaje profundo para detectar comportamientos complejos relacionados con los opioides en las redes sociales, apoyando los esfuerzos de supervisión e intervención de la salud pública.",
    "source": "arXiv"
  },
  {
    "title": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions",
    "title_es": "Un estudio de la modelización de la optimización se ajusta a los LLM: Avances y perspectivas",
    "url": "https://arxiv.org/abs/2508.10047",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10047v1 Tipo de anuncio: nuevo\nResumen: En virtud de su gran utilidad en la resolución de problemas del mundo real, el modelado de optimización se ha empleado ampliamente para la toma de decisiones óptimas en diversos sectores, pero requiere una gran experiencia por parte de los profesionales de la investigación operativa. Con la llegada de los modelos de gran lenguaje (LLM), han surgido nuevas oportunidades para automatizar el procedimiento de modelización matemática. Este estudio presenta una revisión exhaustiva y oportuna de los avances recientes que abarcan toda la pila técnica, incluida la síntesis de datos y el ajuste fino para el modelo base, los marcos de inferencia, los conjuntos de datos de referencia y la evaluación del rendimiento. Además, realizamos un análisis en profundidad de la calidad de los conjuntos de datos de referencia, que presentaban una tasa de error sorprendentemente alta. Limpiamos los conjuntos de datos y construimos una nueva tabla de clasificación con una evaluación justa del rendimiento en términos de modelo LLM base y conjuntos de datos. También construimos un portal en línea que integra recursos de conjuntos de datos depurados, código y repositorio de documentos para beneficio de la comunidad. Por último, identificamos las limitaciones de las metodologías actuales y esbozamos futuras oportunidades de investigación.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Synchronization and Resonance as a Universal Origin of 1/f Fluctuations -- Amplitude Modulation Across Music and Nature",
    "title_es": "Sincronización dinámica y resonancia como origen universal de las fluctuaciones 1/f -- Modulación de amplitud en la música y la naturaleza",
    "url": "https://arxiv.org/abs/2508.10049",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10049v1 Anunciar Tipo: nuevo\nResumen: Proponemos un mecanismo físico universal para la aparición de fluctuaciones 1/f, observadas en una amplia gama de sistemas. En particular, lo verificamos en casos acústicos. El mecanismo se basa en la modulación de amplitud (AM) y la demodulación (DM), donde la ley espectral 1/f surge no en la forma de onda bruta sino en su envolvente de amplitud demodulada. Dos procesos distintos pero complementarios generan la AM necesaria: (i) la sincronización estocástica entre osciladores, modelada mediante un marco Kuramoto ampliado que captura los ciclos perpetuos de sincronización-desincronización, y (ii) la resonancia selectiva en frecuencia, modelada mediante la acumulación espectral de modos propios en entornos acústicos o estructurales. Las simulaciones numéricas demuestran que ambos mecanismos, actuando por separado o en combinación, producen robustamente espectros 1/f durante varias décadas cuando se aplica DM, y que el punto crítico Kuramoto clásico no es necesario para su aparición. Demostramos la relevancia transversal de este marco AM/DM mediante análisis de interpretaciones musicales, registros sísmicos y series temporales astrofísicas, revelando una estructura subyacente común. Este trabajo establece la demodulación como una ruta general hacia las fluctuaciones 1/f, proporcionando una explicación sencilla y escalable de su ubicuidad tanto en sistemas naturales como de ingeniería.\n  Palabras clave: Fluctuación 1/f, modulación de amplitud, sincronización, resonancia, modelo de Kuramoto, música, ruido natural, demodulación.",
    "source": "arXiv"
  },
  {
    "title": "Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems",
    "title_es": "Legal Zero-Days: Un nuevo vector de riesgo para los sistemas avanzados de inteligencia artificial",
    "url": "https://arxiv.org/abs/2508.10050",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10050v1 Tipo de anuncio: nuevo\nResumen: Introducimos el concepto de \"Legal Zero-Days\" como un nuevo vector de riesgo para los sistemas avanzados de IA. Los Legal Zero-Days son vulnerabilidades no descubiertas previamente en los marcos legales que, cuando se explotan, pueden causar una perturbación social inmediata y significativa sin requerir litigios u otros procesos antes del impacto. Presentamos un modelo de riesgo para identificar y evaluar estas vulnerabilidades, demostrando su potencial para eludir las salvaguardias o impedir las respuestas gubernamentales a los incidentes de IA. Utilizando la crisis de la doble nacionalidad australiana de 2017 como caso de estudio, ilustramos cómo descuidos legales aparentemente menores pueden conducir a una interrupción de la gobernanza a gran escala. Desarrollamos una metodología para crear \"rompecabezas legales\" como instrumentos de evaluación de las capacidades de los sistemas de IA para descubrir tales vulnerabilidades. Nuestras conclusiones sugieren que, si bien los modelos de IA actuales pueden no encontrar de forma fiable Zero-Days legales impactantes, los sistemas futuros pueden desarrollar esta capacidad, presentando tanto riesgos como oportunidades para mejorar la solidez legal. Este trabajo contribuye a un esfuerzo más amplio para identificar y mitigar los riesgos no reconocidos previamente de los sistemas de IA de vanguardia.",
    "source": "arXiv"
  },
  {
    "title": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring",
    "title_es": "NetMoniAI: un marco de inteligencia artificial para la seguridad y supervisión de redes",
    "url": "https://arxiv.org/abs/2508.10052",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10052v1 Tipo de anuncio: nuevo\nResumen: En este artículo, presentamos NetMoniAI, un marco de IA agéntica para la monitorización automática de redes y la seguridad que integra el análisis descentralizado con la coordinación centralizada ligera. El marco consta de dos capas: microagentes autónomos en cada nodo realizan análisis de tráfico local y detección de anomalías. A continuación, un controlador central agrega información de todos los nodos para detectar ataques coordinados y mantener el conocimiento de la situación en todo el sistema. Hemos evaluado NetMoniAI en un microbanco de pruebas local y mediante simulaciones NS-3. Los resultados confirman la existencia de dos niveles de agentes. Los resultados confirman que el diseño de la IA-agente de dos niveles se adapta a las limitaciones de recursos, reduce la redundancia y mejora el tiempo de respuesta sin comprometer la precisión. Para facilitar una adopción y reproducibilidad más amplias, el marco completo está disponible como código abierto. Esto permite a investigadores y profesionales reproducirlo, validarlo y ampliarlo en diversos entornos de red y escenarios de amenazas. Enlace Github: https://github.com/pzambare3/NetMoniAI",
    "source": "arXiv"
  },
  {
    "title": "xRFM: Accurate, scalable, and interpretable feature learning models for tabular data",
    "title_es": "xRFM: modelos de aprendizaje de características precisos, escalables e interpretables para datos tabulares",
    "url": "https://arxiv.org/abs/2508.10053",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10053v1 Anunciar Tipo: nuevo\nResumen: La inferencia a partir de datos tabulares, colecciones de variables continuas y categóricas organizadas en matrices, es una de las bases de la tecnología y la ciencia modernas. Sin embargo, en contraste con los cambios explosivos en el resto de la IA, la mejor práctica para estas tareas predictivas se ha mantenido relativamente sin cambios y todavía se basa principalmente en variaciones de Gradient Boosted Decision Trees (GBDTs). Muy recientemente, se ha renovado el interés por desarrollar métodos de vanguardia para datos tabulares basados en los últimos avances en redes neuronales y métodos de aprendizaje de características. En este trabajo, presentamos xRFM, un algoritmo que combina máquinas de núcleo de aprendizaje de características con una estructura de árbol para adaptarse a la estructura local de los datos y escalar a cantidades esencialmente ilimitadas de datos de entrenamiento.\n  Demostramos que, en comparación con otros 31$ métodos, incluidos los modelos de fundamentos tabulares recientemente introducidos (TabPFNv2) y los GBDT, xRFM consigue el mejor rendimiento en conjuntos de datos de regresión de 100$ y es competitivo con los mejores métodos en conjuntos de datos de clasificación de 200$, superando a los GBDT. Además, xRFM proporciona interpretabilidad de forma nativa a través del producto exterior de gradiente medio.",
    "source": "arXiv"
  },
  {
    "title": "FormalGrad: Integrating Formal Methods with Gradient-Based LLM Refinement",
    "title_es": "FormalGrad: integración de métodos formales con el perfeccionamiento LLM basado en gradientes",
    "url": "https://arxiv.org/abs/2508.10059",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10059v1 Tipo de anuncio: nuevo\nResumen: Aunque los Large Language Models (LLMs) han demostrado notables capacidades en la generación de código, a menudo producen soluciones que carecen de garantías de corrección, robustez y eficiencia. Esta limitación se agudiza en dominios que requieren restricciones estrictas. FormalGrad introduce un marco basado en principios que integra métodos formales directamente en un bucle de generación iterativo basado en LLM. Trata el código como una variable diferenciable, convirtiendo la información estructurada y las restricciones formales en un pseudogradiente textual. Este gradiente guía al modelo para refinar iterativamente las soluciones, asegurando que no sólo son funcionales, sino también robustas y formalmente justificadas. Evaluamos FormalGrad en los bancos de pruebas HumanEval, HumanEval+ y LiveCodeBench. Nuestra implementación supera a las líneas de base, logrando una mejora absoluta de hasta el 27% en HumanEval y una mejora relativa del 41% en el exigente LiveCodeBench V6. FormalGrad genera código formalmente justificado que es robusto y eficiente, allanando el camino para el desarrollo fiable de software asistido por IA en aplicaciones de alto riesgo.",
    "source": "arXiv"
  },
  {
    "title": "A Personalized Exercise Assistant using Reinforcement Learning (PEARL): Results from a four-arm Randomized-controlled Trial",
    "title_es": "Un Asistente Personalizado de Ejercicio mediante Aprendizaje por Refuerzo (PEARL): Resultados de un ensayo aleatorizado y controlado de cuatro brazos",
    "url": "https://arxiv.org/abs/2508.10060",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10060v1 Tipo de anuncio: nuevo\nResumen: La inactividad física constante supone un importante reto para la salud mundial. Las intervenciones de salud móvil (mHealth), en particular las Intervenciones Adaptativas Justo a Tiempo (JITAIs), ofrecen una vía prometedora para la promoción escalable y personalizada de la actividad física (AF). Sin embargo, el desarrollo y la evaluación de este tipo de intervenciones a gran escala, integrando al mismo tiempo una sólida ciencia del comportamiento, presenta obstáculos metodológicos. El estudio PEARL fue el primer ensayo controlado aleatorizado a gran escala de cuatro brazos para evaluar un algoritmo de aprendizaje de refuerzo (RL), informado por la teoría del cambio de comportamiento de salud, para personalizar el contenido y el momento de los impulsos de AF a través de una aplicación Fitbit.\n  Se inscribieron y aleatorizaron 13.463 usuarios de Fitbit en cuatro brazos de estudio: control, aleatorio, fijo y RL. El grupo de control no recibió incentivos. Los otros tres brazos recibieron nudges de un banco de 155 nudges basados en principios de la ciencia del comportamiento. El brazo aleatorio recibió codazos seleccionados al azar. El brazo fijo recibió empujones basados en una lógica preestablecida a partir de las respuestas a la encuesta sobre las barreras de la AF. El grupo RL recibió nudges seleccionados por un algoritmo RL adaptativo. Se incluyeron 7.711 participantes en los análisis primarios (edad media 42,1, 86,3% mujeres, pasos iniciales 5.618,2).\n  Se observó un aumento de la AF en el grupo RL en comparación con todos los demás grupos desde el inicio hasta el primer y segundo mes. El grupo RL había aumentado significativamente el promedio de pasos diarios en 1 mes en comparación con todos los demás grupos: control (+296 pasos, p=0,0002), aleatorio (+218 pasos, p=0,005) y fijo (+238 pasos, p=0,002). A los 2 meses, el grupo RL mantuvo un aumento significativo en comparación con el grupo de control (+210 pasos, p=0,0122). Los modelos de ecuación de estimación generalizada también revelaron un aumento sostenido de los pasos diarios en el grupo RL frente al control (+208 pasos, p=0,002). Estos resultados demuestran el potencial de un enfoque de RL escalable e informado por el comportamiento para personalizar las intervenciones de salud digital para la AF.",
    "source": "arXiv"
  },
  {
    "title": "Measuring Time Series Forecast Stability for Demand Planning",
    "title_es": "Medición de la estabilidad de las previsiones de series temporales para la planificación de la demanda",
    "url": "https://arxiv.org/abs/2508.10063",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10063v1 Tipo de anuncio: nuevo\nResumen: La previsión de series temporales es un primer paso fundamental en la generación de planes de demanda para las cadenas de suministro. Los experimentos con modelos de series temporales suelen centrarse en demostrar mejoras en la precisión de las previsiones con respecto a las soluciones existentes o de referencia, cuantificadas según alguna métrica de precisión. No cabe duda de que la precisión de las previsiones es importante; sin embargo, en los sistemas de producción, los planificadores de la demanda suelen valorar más la coherencia y la estabilidad que las mejoras incrementales de la precisión. Suponiendo que las entradas no hayan cambiado significativamente, las previsiones que varían drásticamente de un ciclo de planificación al siguiente requieren una gran intervención humana, lo que frustra a los planificadores de la demanda y puede incluso hacerles perder la confianza en los modelos de previsión ML. Estudiamos la estocasticidad inducida por el modelo, que cuantifica la varianza de un conjunto de previsiones producidas por un único modelo cuando el conjunto de entradas es fijo. Los modelos con menor varianza son más estables.\n  Recientemente, la comunidad de predicción ha experimentado avances significativos en la precisión de las previsiones gracias al desarrollo de modelos de aprendizaje automático profundo para la predicción de series temporales. Realizamos un estudio de caso que mide la estabilidad y la precisión de los modelos de previsión más avanzados (Chronos, DeepAR, PatchTST, Temporal Fusion Transformer, TiDE y el conjunto de mejor calidad AutoGluon) en conjuntos de datos públicos del concurso M5 y de las ventas de comestibles Favorita. Demostramos que los modelos ensemble mejoran la estabilidad sin deteriorar significativamente (o incluso mejorando) la precisión de las previsiones. Aunque estos resultados no resulten sorprendentes, el objetivo principal de este artículo es plantear la necesidad de seguir estudiando la estabilidad de las previsiones para los modelos que se están implantando en sistemas de producción.",
    "source": "arXiv"
  },
  {
    "title": "Invisible Watermarks, Visible Gains: Steering Machine Unlearning with Bi-Level Watermarking Design",
    "title_es": "Marcas de agua invisibles, ganancias visibles: Desaprendizaje automático mediante el diseño de marcas de agua de dos niveles",
    "url": "https://arxiv.org/abs/2508.10065",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10065v1 Tipo de anuncio: nuevo\nResumen: Con la creciente demanda del derecho a ser olvidado, el desaprendizaje automático (MU) ha surgido como una herramienta vital para mejorar la confianza y el cumplimiento normativo al permitir la eliminación de influencias de datos sensibles de los modelos de aprendizaje automático (ML). Sin embargo, la mayoría de los algoritmos de MU se basan principalmente en métodos de entrenamiento para ajustar los pesos del modelo, con una exploración limitada de los beneficios que los ajustes a nivel de datos podrían aportar al proceso de desaprendizaje. Para solventar esta carencia, proponemos un nuevo enfoque que aprovecha la marca de agua digital para facilitar el MU modificando estratégicamente el contenido de los datos. Mediante la integración de marcas de agua, establecemos un mecanismo de desaprendizaje controlado que permite la eliminación precisa de datos especificados, manteniendo al mismo tiempo la utilidad del modelo para tareas no relacionadas. En primer lugar, examinamos el impacto de los datos con marca de agua en la IM, y descubrimos que ésta se generaliza de forma efectiva a los datos con marca de agua. A partir de ahí, introducimos un marco de marcas de agua que facilita el desaprendizaje, denominado Water4MU, para mejorar la eficacia del desaprendizaje. El núcleo de Water4MU es un marco de optimización en dos niveles (BLO): en el nivel superior, la red de marcas de agua se optimiza para minimizar la dificultad de desaprendizaje, mientras que en el nivel inferior, el propio modelo se entrena independientemente de las marcas de agua. Los resultados experimentales demuestran que Water4MU es eficaz en MU tanto en tareas de clasificación como de generación de imágenes. En particular, supera a los métodos existentes en escenarios de MU desafiantes, conocidos como \"olvidos desafiantes\".",
    "source": "arXiv"
  },
  {
    "title": "Stochastic-based Patch Filtering for Few-Shot Learning",
    "title_es": "Filtrado estocástico de parches para el aprendizaje de pocos disparos",
    "url": "https://arxiv.org/abs/2508.10066",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10066v1 Tipo de anuncio: nuevo\nResumen: Las imágenes de alimentos presentan retos únicos para los modelos de aprendizaje de pocas tomas debido a su complejidad visual y variabilidad. Por ejemplo, un plato de pasta puede aparecer con varias guarniciones en diferentes platos y en diversas condiciones de iluminación y perspectivas de cámara. Este problema lleva a perder de vista los elementos más importantes al comparar la consulta con las imágenes de apoyo, lo que da lugar a una clasificación errónea. Para solucionar este problema, proponemos el Filtrado Estocástico de Parches para el Aprendizaje de Pocas Imágenes (SPFF), que se centra en las imágenes de parches que muestran una mayor correlación con la representación de la clase. El concepto clave de SPFF implica el filtrado estocástico de las incrustaciones de los parches, en el que los parches menos similares a la incrustación sensible a la clase tienen más probabilidades de ser descartados. Con la incrustación de parches filtrada según la probabilidad de aparición, utilizamos una matriz de similitud que cuantifica la relación entre la imagen de consulta y sus respectivas imágenes de apoyo. Mediante un análisis cualitativo, demostramos que el SPFF se centra eficazmente en los parches en los que las características alimentarias específicas de cada clase son más prominentes, al tiempo que filtra con éxito los parches no pertinentes. Validamos nuestro método mediante experimentos exhaustivos con parámetros de clasificación de pocas imágenes: Food-101, VireoFood-172 y UECFood-256, superando a los métodos SoA existentes.",
    "source": "arXiv"
  },
  {
    "title": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion",
    "title_es": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion (Orquestación de señales semánticas y estructurales para la finalización de código a nivel de repositorio orientada a los beneficios).",
    "url": "https://arxiv.org/abs/2508.10068",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10068v1 Tipo de anuncio: nuevo\nResumen: La generación aumentada de recuperación (RAG) para la finalización de código a nivel de repositorio se basa normalmente en la similitud superficial del texto, lo que conduce a resultados plagados de desorientación semántica, redundancia y homogeneidad, al tiempo que no resuelve la ambigüedad de los símbolos externos. Para hacer frente a estos retos, presentamos Saracoder, un marco de recuperación optimizada de características jerárquicas. Su módulo central, Hierarchical Feature Optimization, refina sistemáticamente los candidatos destilando relaciones semánticas profundas, eliminando duplicados exactos, evaluando la similitud estructural con una nueva métrica basada en grafos que pondera las ediciones por su importancia topológica, y volviendo a clasificar los resultados para maximizar tanto la relevancia como la diversidad. Además, el módulo External-Aware Identifier Disambiguator resuelve con precisión la ambigüedad de símbolos entre archivos mediante el análisis de dependencias. Extensos experimentos con las exigentes pruebas CrossCodeEval y RepoEval-Updated demuestran que Saracoder supera con creces las líneas de base existentes en múltiples lenguajes y modelos de programación. Nuestro trabajo demuestra que el refinamiento sistemático de los resultados de recuperación a través de múltiples dimensiones proporciona un nuevo paradigma para construir sistemas de compleción de código a nivel de repositorio más precisos y robustos.",
    "source": "arXiv"
  },
  {
    "title": "Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices",
    "title_es": "Avanzar en la equidad de los datos: Responsabilidad y rendición de cuentas de los profesionales en las prácticas de datos de la PNL",
    "url": "https://arxiv.org/abs/2508.10071",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10071v1 Tipo de anuncio: nuevo\nResumen: Mientras que la investigación se ha centrado en sacar a la luz y auditar el sesgo algorítmico para garantizar un desarrollo equitativo de la IA, se sabe menos sobre cómo los profesionales de la PNL - los que participan directamente en el desarrollo de conjuntos de datos, la anotación y el despliegue - perciben y navegan por cuestiones de equidad de datos de PNL. Este estudio es uno de los primeros en centrarse en las perspectivas de los profesionales, vinculando sus experiencias a un marco de gobernanza de la IA multiescalar y proponiendo recomendaciones participativas que tienden un puente entre los ámbitos técnico, político y comunitario. A partir de un cuestionario de 2024 y un grupo de discusión, examinamos cómo los profesionales de la PNL de EE.UU. conceptualizan la equidad, se enfrentan a limitaciones organizativas y sistémicas y participan en iniciativas de gobernanza emergentes como la Declaración de Derechos de la IA de EE.UU.. Los resultados revelan tensiones persistentes entre los objetivos comerciales y los compromisos de equidad, junto con llamamientos a flujos de trabajo de datos más participativos y responsables. Enfrentamos críticamente los debates sobre la diversidad de datos y el lavado de la diversidad, argumentando que la mejora de la equidad de la PNL requiere reformas estructurales de gobernanza que apoyen la agencia de los profesionales y el consentimiento de la comunidad.",
    "source": "arXiv"
  },
  {
    "title": "Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History",
    "title_es": "Predicción de próximas ediciones: Aprender a predecir ediciones de código a partir del contexto y el historial de interacciones",
    "url": "https://arxiv.org/abs/2508.10074",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10074v1 Tipo de anuncio: nuevo\nResumen: El rápido avance de los grandes modelos de lenguaje (LLMs) ha llevado a la adopción generalizada de asistentes de codificación potenciados por IA e integrados en un entorno de desarrollo. Por un lado, el completado de código de baja latencia ofrece sugerencias de completado, pero se limita fundamentalmente a la posición actual del cursor. Por otro lado, la edición basada en el chat puede realizar modificaciones complejas, pero obliga a los desarrolladores a detener su trabajo, describir la intención en lenguaje natural, lo que provoca un cambio de contexto fuera del código. Esto crea una experiencia de usuario subóptima, ya que ninguno de los dos paradigmas predice de forma proactiva la próxima edición del desarrollador en una secuencia de ediciones relacionadas. Para colmar esta laguna y proporcionar una sugerencia de edición de código sin fisuras, introducimos la tarea de Predicción de la próxima edición, una nueva tarea diseñada para inferir la intención del desarrollador a partir del historial de interacción reciente para predecir tanto la ubicación como el contenido de la edición posterior. Específicamente, curamos un conjunto de datos supervisados de alta calidad y un punto de referencia de evaluación para la tarea de predicción de la próxima edición. A continuación, llevamos a cabo un ajuste supervisado de una serie de modelos y realizamos una evaluación exhaustiva tanto de los modelos ajustados como de otros modelos de referencia, obteniendo varios resultados novedosos. Este trabajo sienta las bases de un nuevo paradigma de interacción que colabora proactivamente con los desarrolladores anticipándose a sus siguientes acciones, en lugar de limitarse a reaccionar a instrucciones explícitas.",
    "source": "arXiv"
  },
  {
    "title": "TensorKit.jl: A Julia package for large-scale tensor computations, with a hint of category theory",
    "title_es": "TensorKit.jl: Un paquete de Julia para cálculos tensoriales a gran escala, con un toque de teoría de categorías.",
    "url": "https://arxiv.org/abs/2508.10076",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10076v1 Tipo de anuncio: nuevo\nResumen: TensorKit.jl es un paquete de software basado en Julia para cálculos tensoriales, especialmente centrado en tensores con simetrías internas. Este artículo presenta la filosofía de diseño, funcionalidades básicas y características distintivas, incluyendo cómo manejar simetrías abelianas, no abelianas y anyónicas a través del tipo ``TensorMap''. Destacamos la flexibilidad del software, su rendimiento y su capacidad de ampliación a nuevos tipos de tensor y simetrías, ilustrando sus aplicaciones prácticas mediante casos de estudio seleccionados.",
    "source": "arXiv"
  },
  {
    "title": "DINOv3",
    "title_es": "DINOv3",
    "url": "https://arxiv.org/abs/2508.10104",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10104v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje autosupervisado promete eliminar la necesidad de la anotación manual de datos, permitiendo que los modelos se escalen sin esfuerzo a conjuntos de datos masivos y arquitecturas más grandes. Al no estar adaptado a tareas o dominios específicos, este paradigma de formación tiene el potencial de aprender representaciones visuales de diversas fuentes, desde imágenes naturales a aéreas, utilizando un único algoritmo. Este informe técnico presenta DINOv3, un hito importante para hacer realidad esta visión mediante estrategias sencillas pero eficaces. En primer lugar, aprovechamos las ventajas de escalar tanto el conjunto de datos como el tamaño del modelo mediante una cuidadosa preparación, diseño y optimización de los datos. En segundo lugar, introducimos un nuevo método denominado \"anclaje Gram\", que aborda eficazmente el problema conocido, pero no resuelto, de la degradación de los mapas de características densos durante los programas de entrenamiento prolongados. Por último, aplicamos estrategias post-hoc que mejoran aún más la flexibilidad de nuestros modelos con respecto a la resolución, el tamaño del modelo y la alineación con el texto. Como resultado, presentamos un modelo de base de visión versátil que supera el estado del arte especializado en una amplia gama de entornos, sin necesidad de ajuste fino. DINOv3 produce características densas de alta calidad que logran un rendimiento sobresaliente en varias tareas de visión, superando significativamente a los modelos de fundamentos anteriores auto-supervisados y débilmente supervisados. También compartimos el conjunto de modelos de visión DINOv3, diseñado para avanzar en el estado del arte en un amplio espectro de tareas y datos, proporcionando soluciones escalables para diversas limitaciones de recursos y escenarios de despliegue.",
    "source": "arXiv"
  },
  {
    "title": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development",
    "title_es": "Amazon Nova AI Challenge -- Trusted AI: Avanzar en el desarrollo de software seguro y asistido por IA",
    "url": "https://arxiv.org/abs/2508.10108",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10108v1 Tipo de anuncio: nuevo\nResumen: Los sistemas de IA para el desarrollo de software están ganando protagonismo rápidamente, pero aún quedan retos importantes para garantizar su seguridad. Para hacer frente a esto, Amazon lanzó el Trusted AI track del Amazon Nova AI Challenge, una competición global entre 10 equipos universitarios para impulsar avances en IA segura. En el desafío, cinco equipos se centran en el desarrollo de bots automatizados de red teaming, mientras que los otros cinco crean asistentes de IA seguros. Este desafío proporciona a los equipos una plataforma única para evaluar los métodos automatizados de red-teaming y de alineación de seguridad a través de torneos adversarios cara a cara en los que los equipos rojos mantienen conversaciones de varios turnos con los asistentes de codificación de IA competidores para probar su alineación de seguridad. Además, el desafío proporciona a los equipos una fuente de datos anotados de alta calidad para impulsar la mejora iterativa. A lo largo del desafío, los equipos desarrollaron técnicas de vanguardia, introduciendo enfoques novedosos en la alineación de seguridad basada en el razonamiento, guardarraíles de modelos robustos, jail-breaking multivuelta y sondeo eficiente de grandes modelos de lenguaje (LLM). Para respaldar estos esfuerzos, el equipo de Amazon Nova AI Challenge realizó importantes inversiones científicas y de ingeniería, incluida la creación desde cero de un modelo especializado de codificación de referencia personalizado para el desafío, el desarrollo de un servicio de orquestación de torneos y la creación de un arnés de evaluación. Este artículo describe los avances realizados por los equipos universitarios y el equipo del Desafío de IA de Amazon Nova para abordar los desafíos de seguridad de la IA para el desarrollo de software, destacando este esfuerzo de colaboración para elevar el listón de la seguridad de la IA.",
    "source": "arXiv"
  },
  {
    "title": "Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model",
    "title_es": "Potenciación de la detección de ataques de morphing mediante un modelo interpretable de base imagen-texto",
    "url": "https://arxiv.org/abs/2508.10110",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10110v1 Tipo de anuncio: nuevo\nResumen: La detección de ataques de morphing se ha convertido en un componente esencial de los sistemas de reconocimiento facial para garantizar un escenario de verificación fiable. En este trabajo, presentamos un enfoque de aprendizaje multimodal que puede proporcionar una descripción textual de la detección de ataques de morphing. En primer lugar, mostramos que la evaluación sin disparos del marco propuesto mediante el preentrenamiento contrastivo de lenguaje-imagen (CLIP) no sólo puede producir una detección generalizable de ataques de morphing, sino también predecir el fragmento de texto más relevante. Presentamos un análisis exhaustivo de diez mensajes textuales diferentes que incluyen mensajes cortos y largos. Estos mensajes se diseñan teniendo en cuenta el fragmento de texto comprensible para el ser humano. Se llevaron a cabo experimentos exhaustivos con un conjunto de datos de morphing facial desarrollado a partir de un conjunto de datos biométricos faciales de acceso público. Presentamos una evaluación de las redes neuronales preentrenadas SOTA junto con el marco propuesto en la evaluación de disparo cero de cinco técnicas diferentes de generación de morphing que se capturan en tres medios diferentes.",
    "source": "arXiv"
  },
  {
    "title": "Constrained Decoding of Diffusion LLMs with Context-Free Grammars",
    "title_es": "Descodificación restringida de LLM de difusión con gramáticas libres de contexto",
    "url": "https://arxiv.org/abs/2508.10111",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10111v1 Tipo de anuncio: nuevo\nResumen: Los modelos de grandes lenguajes (LLMs) han mostrado un rendimiento prometedor en diversos dominios. Muchas aplicaciones prácticas de los LLM, como la finalización de código y la extracción de datos estructurados, requieren el cumplimiento de restricciones sintácticas especificadas por un lenguaje formal. Sin embargo, debido a su naturaleza probabilística, no está garantizado que los resultados de los LLM se adhieran a dichos lenguajes formales. En trabajos anteriores se ha propuesto la descodificación restringida como medio para limitar la generación de LLM a determinados lenguajes formales. Sin embargo, los trabajos existentes no son aplicables al paradigma emergente de los LLM de difusión, cuando se utilizan en escenarios prácticos como la generación de una salida C++ o JSON formalmente correcta. En este artículo abordamos este reto y presentamos el primer método de decodificación restringida para modelos de difusión, que puede manejar lenguajes formales capturados por gramáticas libres de contexto. Comenzamos reduciendo la descodificación restringida al problema más general del relleno aditivo, que pregunta si una salida parcial puede completarse con una palabra válida en el lenguaje de destino. Este problema también engloba de forma natural la descodificación restringida de relleno multirregión, que hasta ahora no se había abordado. A continuación, reducimos este problema a la tarea de decidir si la intersección de la lengua de llegada y una lengua regular está vacía y presentamos un algoritmo eficiente para resolverlo en el caso de las lenguas libres de contexto. Los resultados empíricos en varias aplicaciones, como el relleno de código C++ y la extracción de datos estructurados en JSON, demuestran que nuestro método consigue una corrección sintáctica casi perfecta, al tiempo que preserva o mejora de forma consistente la corrección funcional. Y lo que es más importante, nuestras optimizaciones de eficiencia garantizan que la sobrecarga computacional siga siendo práctica.",
    "source": "arXiv"
  },
  {
    "title": "Interpretable Oracle Bone Script Decipherment through Radical and Pictographic Analysis with LVLMs",
    "title_es": "Desciframiento interpretable de la escritura ósea del oráculo mediante análisis radical y pictográfico con LVLMs",
    "url": "https://arxiv.org/abs/2508.10113",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10113v1 Tipo de anuncio: nuevo\nResumen: Como el sistema de escritura maduro más antiguo, Oracle Bone Script (OBS) ha planteado durante mucho tiempo importantes desafíos para el desciframiento arqueológico debido a su rareza, abstracción y diversidad pictográfica. Los métodos actuales basados en el aprendizaje profundo han logrado avances interesantes en la tarea de descifrado de OBS, pero los enfoques existentes a menudo ignoran las intrincadas conexiones entre los glifos y la semántica de OBS. Esto resulta en una generalización e interpretabilidad limitadas, especialmente cuando se abordan configuraciones de disparo cero y OBS sin descifrar. Para ello, proponemos un método interpretable de descifrado de OBS basado en grandes modelos de visión-idioma, que combina sinérgicamente el análisis radical y la comprensión pictográfica-semántica para salvar la brecha entre los glifos y los significados de OBS. En concreto, proponemos una estrategia de entrenamiento progresivo que guía al modelo desde el reconocimiento y análisis radical hasta el análisis pictográfico y el análisis mutuo, permitiendo así razonar desde el glifo hasta el significado. También diseñamos un mecanismo de doble correspondencia radical-pictográfica basado en los resultados del análisis, que mejora significativamente el rendimiento del modelo en el descifrado sin disparos. Para facilitar el entrenamiento del modelo, proponemos el conjunto de datos OBS de descifrado pictográfico, que incluye 47.157 caracteres chinos anotados con imágenes OBS y textos de análisis pictográfico. Los resultados experimentales obtenidos en pruebas de referencia públicas demuestran que nuestro método alcanza una precisión puntera de Top-10 y una capacidad superior de descifrado sin disparos. Y lo que es más importante, nuestro modelo ofrece procesos de análisis lógicos que posiblemente proporcionen resultados de referencia arqueológicamente valiosos para OBS no descifrados, por lo que tiene aplicaciones potenciales en humanidades digitales e investigación histórica. El conjunto de datos y el código se publicarán en https://github.com/PKXX1943/PD-OBS.",
    "source": "arXiv"
  },
  {
    "title": "Less is More: Learning Graph Tasks with Just LLMs",
    "title_es": "Menos es más: Aprendizaje de tareas gráficas con sólo LLM",
    "url": "https://arxiv.org/abs/2508.10115",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10115v1 Tipo de anuncio: nuevo\nResumen: Para los grandes modelos de lenguaje (LLMs), el razonamiento sobre grafos podría ayudar a resolver muchos problemas. En trabajos anteriores se ha intentado mejorar el razonamiento sobre grafos LLM examinando la mejor forma de serializar los grafos como texto y combinando GNNs y LLMs. Sin embargo, los méritos de estos enfoques siguen sin estar claros, por lo que respondemos empíricamente a las siguientes preguntas de investigación: (1) ¿Pueden los LLM aprender a resolver tareas gráficas fundamentales sin modelos especializados de codificación de grafos?, (2) ¿Pueden los LLM generalizar las soluciones aprendidas a estructuras o tareas gráficas desconocidas? y (3) ¿Cuáles son los méritos de los enfoques competidores para aprender tareas gráficas? Demostramos que incluso los LLM pequeños pueden aprender a resolver tareas gráficas entrenándolos con soluciones instructivas de cadena de pensamiento, y que este entrenamiento se generaliza, sin codificadores gráficos especializados, a nuevas tareas y estructuras gráficas.",
    "source": "arXiv"
  },
  {
    "title": "Bridging Modality Gaps in e-Commerce Products via Vision-Language Alignment",
    "title_es": "Superar las diferencias de modalidad en los productos de comercio electrónico mediante la alineación de la visión y el lenguaje",
    "url": "https://arxiv.org/abs/2508.10116",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10116v1 Tipo de anuncio: nuevo\nResumen: La información sobre los artículos, como títulos y atributos, es esencial para la participación efectiva de los usuarios en el comercio electrónico. Sin embargo, la introducción manual o semimanual de datos específicos estructurados sobre los artículos suele dar lugar a una calidad inconsistente, errores y lentitud, especialmente en el caso de los vendedores de cliente a cliente. Generar descripciones precisas directamente a partir de las imágenes de los artículos ofrece una alternativa prometedora. Las soluciones existentes basadas en la recuperación de datos abordan algunos de estos problemas, pero a menudo pasan por alto detalles visuales muy precisos y tienen dificultades con categorías especializadas.\n  Proponemos una IA optimizada basada en preferencias para listados (OPAL), un marco para generar descripciones de artículos de alta calidad y conformes con los esquemas a partir de imágenes utilizando un modelo de lenguaje multimodal de gran tamaño (MLLM). OPAL aborda los principales retos de las aplicaciones multimodales de comercio electrónico, como la reducción de las diferencias entre modalidades y la captura de información contextual detallada. Introduce dos métodos de refinamiento de datos: MLLM-Assisted Conformity Enhancement, que garantiza la alineación con los requisitos de esquemas estructurados, y LLM-Assisted Contextual Understanding, que mejora la captura de información matizada y detallada a partir de entradas visuales.\n  OPAL utiliza el ajuste de instrucciones visuales combinado con la optimización de preferencias directas para ajustar el MLLM, reduciendo las alucinaciones y mejorando la robustez en diferentes arquitecturas troncales. Evaluamos OPAL en conjuntos de datos de comercio electrónico del mundo real, demostrando que supera sistemáticamente a los métodos de referencia tanto en calidad de descripción como en tasas de finalización de esquemas. Estos resultados demuestran que OPAL tiende un puente eficaz entre las modalidades visual y textual, proporcionando descripciones de artículos más ricas, precisas y coherentes. Este trabajo supone un avance en la optimización automatizada de listados y favorece la generación de contenidos escalables y de alta calidad en plataformas de comercio electrónico.",
    "source": "arXiv"
  },
  {
    "title": "From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation",
    "title_es": "De la intención a la ejecución: Aprendizaje multimodal por refuerzo de la cadena de pensamiento para la generación precisa de códigos CAD",
    "url": "https://arxiv.org/abs/2508.10118",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10118v1 Tipo de anuncio: nuevo\nResumen: El diseño asistido por ordenador (CAD) juega un papel vital en la ingeniería y la fabricación, sin embargo, los flujos de trabajo CAD actuales requieren una amplia experiencia en el dominio y el esfuerzo de modelado manual. Los recientes avances en los modelos de grandes lenguajes (LLM) han hecho posible generar código a partir del lenguaje natural, abriendo nuevas oportunidades para automatizar el modelado 3D paramétrico. Sin embargo, la traducción directa de la intención de diseño humano en código CAD ejecutable sigue siendo un gran reto, debido a la necesidad de razonamiento lógico, corrección sintáctica y precisión numérica. En este trabajo, proponemos CAD-RL, un marco de postentrenamiento multimodal de aprendizaje por refuerzo guiado por la Cadena de Pensamiento (CoT) para la generación de código de modelado CAD. Nuestro método combina el Cold Start basado en CoT con el postentrenamiento de aprendizaje por refuerzo guiado por objetivos utilizando tres recompensas específicas para cada tarea: recompensa de ejecutabilidad, recompensa de precisión geométrica y recompensa de evaluación externa. Para garantizar un aprendizaje de políticas estable en condiciones de recompensas dispersas y de alta varianza, introducimos tres estrategias de optimización específicas: Trust Region Stretch para mejorar la exploración, Precision Token Loss para mejorar la precisión de los parámetros dimensionales y Overlong Filtering para reducir la supervisión ruidosa. Para apoyar el entrenamiento y la evaluación comparativa, lanzamos ExeCAD, un conjunto de datos noval que comprende 16.540 ejemplos CAD del mundo real con descripciones emparejadas en lenguaje natural y lenguaje de diseño estructurado, scripts CADQuery ejecutables y modelos 3D renderizados. Los experimentos demuestran que CAD-RL consigue mejoras significativas en la calidad del razonamiento, la precisión de los resultados y la ejecutabilidad del código en comparación con los VLM existentes.",
    "source": "arXiv"
  },
  {
    "title": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts",
    "title_es": "Nested-ReFT: Aprendizaje por refuerzo eficiente para el ajuste de modelos lingüísticos de gran tamaño mediante despliegues fuera de política",
    "url": "https://arxiv.org/abs/2508.10123",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10123v1 Tipo de anuncio: nuevo\nResumen: El razonamiento avanzado en LLMs en dominios desafiantes como el razonamiento matemático puede abordarse utilizando el ajuste reforzado basado en recompensas verificables (ReFT). En los marcos estándar de ReFT, un modelo de comportamiento genera múltiples terminaciones con respuestas por problema, para que la respuesta sea entonces puntuada por una función de recompensa. Aunque estos métodos de postentrenamiento de RL demuestran mejoras significativas en el rendimiento en dominios de razonamiento complejos, el coste computacional de generar complementos durante el entrenamiento con múltiples pasos de inferencia hace que el coste del entrenamiento no sea trivial. Para solucionar este problema, nos inspiramos en la RL fuera de política y en la descodificación especulativa para introducir un nuevo marco ReFT, denominado Nested-ReFT, en el que un subconjunto de capas del modelo objetivo actúa como modelo de comportamiento para generar terminaciones fuera de política durante el entrenamiento. El modelo de comportamiento configurado con omisión dinámica de capas por lote durante el entrenamiento disminuye el coste de inferencia en comparación con los marcos ReFT estándar. Nuestro análisis teórico muestra que Nested-ReFT produce estimaciones de gradiente insesgadas con varianza controlada. Nuestro análisis empírico demuestra una mejora de la eficiencia computacional, medida en tokens/seg, en múltiples pruebas de razonamiento matemático y tamaños de modelos. Además, exploramos tres variantes de mitigación de sesgos para minimizar la ausencia de políticas en las actualizaciones de gradiente que permiten mantener un rendimiento equivalente al rendimiento básico de ReFT.",
    "source": "arXiv"
  },
  {
    "title": "Concepts for Composing Finite Element Function Space Bases",
    "title_es": "Conceptos para componer bases espaciales de funciones de elementos finitos",
    "url": "https://arxiv.org/abs/2508.10125",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10125v1 Tipo de anuncio: nuevo\nResumen: Las discretizaciones por elementos finitos de modelos de ecuaciones diferenciales parciales multifísicas acopladas requieren el manejo de espacios de funciones compuestos. En este trabajo se discuten conceptos y abstracciones de software para manejar la composición de espacios de funciones, basados en una representación de los espacios producto como árboles de bases más simples. A partir de esta descripción, se pueden derivar de forma natural muchas numeraciones diferentes de grados de libertad por multiíndices, lo que permite adaptar los espacios de funciones a disposiciones de datos muy diferentes, de forma que se abre la posibilidad de utilizar directamente el código de elementos finitos con códigos de álgebra lineal muy diferentes, estructuras de datos diferentes y solucionadores algebraicos diferentes.\n  Un ejemplo recurrente a lo largo del artículo es la ecuación estacionaria de Stokes con elementos Taylor--Hood, ya que se formulan de forma natural como espacios producto y ponen de manifiesto por qué son deseables diferentes patrones de almacenamiento.\n  En la segunda mitad del documento se discute una realización particular de la mayoría de estos conceptos en el módulo \\dunemodule{dune-functions}, como parte del ecosistema DUNE.",
    "source": "arXiv"
  },
  {
    "title": "A tensor-based dynamic mode decomposition based on the $\\star_{\\boldsymbol{M}}$-product",
    "title_es": "Una descomposición dinámica de modos basada en el producto $\\star_{\\\\boldsymbol{M}}.",
    "url": "https://arxiv.org/abs/2508.10126",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10126v1 Tipo de anuncio: nuevo\nResumen: La descomposición dinámica de modos (DMD) es un método basado en datos para estimar la dinámica de un sistema dinámico discreto. Este trabajo propone un enfoque basado en tensores para DMD para aplicaciones en las que los estados pueden ser vistos como tensores. Específicamente, utilizamos el marco de producto $star_{\\boldsymbol{M}} para descomposiciones tensoriales que demostramos ofrece una excelente compresión en comparación con los métodos basados en matrices y puede ser implementado de una manera computacionalmente eficiente. Mostramos cómo el enfoque propuesto está conectado con los marcos DMD tradicionales y DMD informados por la física. Proporcionamos un marco computacional para calcular el DMD basado en tensor y detallamos los costes computacionales. También proporcionamos un algoritmo aleatorio que permite realizar cálculos eficientes $star_{\\boldsymbol{M}}$-DMD en el entorno de streaming. Los resultados numéricos muestran que el método propuesto alcanza una precisión igual o mejor para el mismo almacenamiento en comparación con el DMD estándar en estos ejemplos y es más eficiente de calcular.",
    "source": "arXiv"
  },
  {
    "title": "FPT-Approximability of Stable Matching Problems",
    "title_es": "Aproximabilidad FPT de problemas de emparejamiento estables",
    "url": "https://arxiv.org/abs/2508.10129",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10129v1 Anunciar Tipo: nuevo\nResumen: Estudiamos la aproximabilidad parametrizada de tres problemas de optimización relacionados con el emparejamiento estable: (1) Min-BP-SMI: Dado un caso de matrimonio estable y un número k, encontrar un emparejamiento de tamaño al menos k que minimice el número $\\beta$ de pares bloqueantes; (2) Min-BP-SRI: Dado un caso de compañeros de piso estables, encontrar un emparejamiento que minimice el número $\\beta$ de pares bloqueantes; (3) Max-SMTI: Dado un caso de matrimonio estable con preferencias que contengan empates, encontrar un emparejamiento estable de tamaño máximo.\n  Se sabe que los dos primeros problemas son NP-difíciles de aproximar a cualquier factor constante y W[1]-difíciles con respecto a $\\beta$, lo que hace improbable la existencia de un EPTAS o algoritmos FPT. Demostramos que son W[1]-duros con respecto a $\\beta$ para aproximar a cualquier función de $\\beta$. Esto significa que, a menos que FPT=W[1], no existe ningún esquema de aproximación FPT para el parámetro $\\beta$. Se sabe que el último problema (Max-SMTI) es NP-difícil de aproximar a factor-29/33 y W[1]-difícil con respecto al número de empates. Complementamos esto y presentamos un esquema de aproximación FPT para el parámetro \"número de agentes con empates\".",
    "source": "arXiv"
  },
  {
    "title": "Deep Learning Enables Large-Scale Shape and Appearance Modeling in Total-Body DXA Imaging",
    "title_es": "El aprendizaje profundo permite modelar la forma y la apariencia a gran escala en imágenes DXA de todo el cuerpo",
    "url": "https://arxiv.org/abs/2508.10132",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10132v1 Tipo de anuncio: nuevo\nResumen: La absorciometría dual de cuerpo entero (TBDXA) es una modalidad de imagen de cuerpo entero relativamente barata, ampliamente utilizada para la evaluación de la composición corporal. Desarrollamos y validamos un método de aprendizaje profundo para la colocación automática de puntos fiduciales en exploraciones TBDXA utilizando 1.683 exploraciones TBDXA anotadas manualmente. El método alcanza un porcentaje de 99,5% de puntos clave correctos en un conjunto de datos de prueba externo. Para demostrar el valor del modelado de forma y apariencia (SAM), nuestro método se utiliza para colocar puntos clave en 35.928 exploraciones de cinco modos de imagen TBDXA diferentes y, a continuación, se comprueban las asociaciones con marcadores de salud en dos cohortes no utilizadas para la generación de modelos SAM mediante pruebas de Kolmogorov-Smirnov de dos muestras. Las distribuciones de características de SAM asociadas con biomarcadores de salud corroboran las pruebas existentes y generan nuevas hipótesis sobre la composición corporal y la relación de la forma con diversos marcadores de fragilidad, metabólicos, inflamatorios y cardiometabólicos. Los scripts de evaluación, los pesos del modelo, el código de generación automática de archivos de puntos y los archivos de triangulación están disponibles en https://github.com/hawaii-ai/dxa-pointplacement.",
    "source": "arXiv"
  },
  {
    "title": "MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion Learning",
    "title_es": "MANGO: Enfoque de flujo normalizador basado en la atención multimodal para el aprendizaje por fusión",
    "url": "https://arxiv.org/abs/2508.10133",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10133v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje multimodal ha tenido mucho éxito en los últimos años. Sin embargo, los métodos actuales de fusión multimodal adoptan el mecanismo de atención de Transformers para aprender implícitamente la correlación subyacente de las características multimodales. Como resultado, el modelo multimodal no puede captar las características esenciales de cada modalidad, lo que dificulta la comprensión de estructuras y correlaciones complejas de entradas multimodales. En este artículo se presenta un nuevo enfoque basado en la atención multimodal Normalizing Flow (MANGO) para desarrollar el aprendizaje de fusión multimodal explícito, interpretable y manejable. En particular, proponemos una nueva capa de atención cruzada invertible (ICA) para desarrollar el modelo basado en el flujo normalizador para datos multimodales. Para capturar eficientemente las complejas correlaciones subyacentes en los datos multimodales en nuestra capa de atención cruzada invertible propuesta, proponemos tres nuevos mecanismos de atención cruzada: Modality-to-Modality Cross-Attention (MMCA), Inter-Modality Cross-Attention (IMCA) y Learnable Inter-Modality Cross-Attention (LICA). Finalmente, introducimos un nuevo Flujo Normalizador basado en la Atención Multimodal para permitir la escalabilidad de nuestro método propuesto a datos multimodales de alta dimensión. Nuestros resultados experimentales en tres tareas de aprendizaje multimodal diferentes, es decir, segmentación semántica, traducción de imagen a imagen y clasificación de géneros cinematográficos, han ilustrado el rendimiento de vanguardia (SoTA) del enfoque propuesto.",
    "source": "arXiv"
  },
  {
    "title": "Recognizing Penny and Marble Graphs is Hard for Existential Theory of the Reals",
    "title_es": "Reconocer los grafos de peniques y canicas es difícil para la Teoría Existencial de los Reales",
    "url": "https://arxiv.org/abs/2508.10136",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10136v1 Anunciar Tipo: nuevo\nResumen: Demostramos que el problema de reconocimiento de grafos de centavos (grafos de contacto de discos unitarios en el plano) es $\\exists\\mathbb{R}$-completo, es decir, computacionalmente tan difícil como la teoría existencial de los reales, incluso si se da una incrustación combinatoria del plano del grafo. La complejidad exacta del problema de reconocimiento del grafo del centavo ha sido un problema abierto durante mucho tiempo.\n  Llevamos el resultado del grafo del centavo a tres dimensiones y mostramos que el problema de reconocimiento para grafos de mármol (grafos de contacto de bolas unitarias en tres dimensiones) es $\\exists\\mathbb{R}$-completo.\n  Finalmente, mostramos que la rigidez de los grafos de centavos es $\\forall\\mathbb{R}$-completa y observamos incrustaciones de grafos de centavos que son árboles.",
    "source": "arXiv"
  },
  {
    "title": "mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning",
    "title_es": "mSCoRe: una referencia $M$ultilingüe y escalable para el $Razonamiento $Co$mmonsentido $basado en $S$kill",
    "url": "https://arxiv.org/abs/2508.10137",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10137v1 Tipo de anuncio: nuevo\nResumen: Los recientes avances en los Modelos de Lenguaje Grande (LLMs) reforzados por razonamiento han mostrado notables capacidades en tareas de razonamiento complejas. Sin embargo, el mecanismo que subyace a su utilización de diferentes habilidades de razonamiento humano sigue siendo poco investigado, especialmente para el razonamiento de sentido común multilingüe que implica el conocimiento cotidiano a través de diferentes idiomas y culturas. Para colmar esta laguna, proponemos un punto de referencia multilingüe y escalable para el razonamiento basado en el sentido común multilingüe (\\textbf{MSCoRe}). Nuestro benchmark incorpora tres componentes clave diseñados para evaluar sistemáticamente las capacidades de razonamiento de LLM: (1) una novedosa taxonomía de habilidades de razonamiento que permite un análisis detallado de los procesos de razonamiento de los modelos, (2) un robusto canal de síntesis de datos diseñado específicamente para la evaluación del razonamiento de sentido común y (3) un marco de escalado de complejidad que permite escalar dinámicamente la dificultad de la tarea junto con futuras mejoras en las capacidades de LLM. Extensos experimentos con ocho LLMs de última generación de diferentes tamaños y enfoques de entrenamiento demuestran que \\textbf{mSCoRe} sigue siendo un reto significativo para los modelos actuales, sobre todo en los niveles de complejidad más altos. Nuestros resultados revelan las limitaciones de estos modelos de razonamiento reforzado cuando se enfrentan al sentido común multilingüe, general y cultural, lleno de matices. Además, proporcionamos un análisis detallado de los procesos de razonamiento de los modelos, sugiriendo futuras direcciones para mejorar las capacidades de razonamiento de sentido común multilingüe.",
    "source": "arXiv"
  },
  {
    "title": "Using nonassociative algebras to classify skew polycyclic codes up to isometry and equivalence",
    "title_es": "Uso de álgebras no asociativas para clasificar códigos policíclicos sesgados hasta isometría y equivalencia",
    "url": "https://arxiv.org/abs/2508.10139",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10139v1 Tipo de anuncio: nuevo\nResumen: Proponemos nuevas definiciones de equivalencia e isometría para códigos policíclicos sesgados que conducirán a clasificaciones más ajustadas que las existentes. Esto ayuda a reducir el número de clases de isometría y equivalencia previamente conocidas, y a establecer con precisión cuándo coinciden estas diferentes nociones. En el proceso, clasificamos clases de códigos $(f,\\sigma,\\delta)$-policíclicos sesgados con los mismos parámetros de rendimiento, para evitar duplicar códigos ya existentes.\n  Explotamos que el generador de un código policíclico sesgado está en correspondencia unívoca con el generador de un ideal principal izquierdo en su álgebra ambiental. Los isomorfismos de álgebra que preservan la distancia de Hamming (denominados isometrías) asignan generadores de ideales principales izquierdos a generadores de ideales principales izquierdos y preservan la longitud, la dimensión y la distancia de Hamming de los códigos. Permitimos que las álgebras ambientales sean no asociativas, eliminando así la necesidad de restricciones en la longitud de los códigos. Las isometrías entre las álgebras ambientales también pueden utilizarse para clasificar los códigos lineales correspondientes equipados con la métrica de rango.",
    "source": "arXiv"
  },
  {
    "title": "Hard Shell, Reliable Core: Improving Resilience in Replicated Systems with Selective Hybridization",
    "title_es": "Cáscara dura, núcleo fiable: mejora de la resistencia en sistemas replicados con hibridación selectiva",
    "url": "https://arxiv.org/abs/2508.10141",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10141v1 Tipo de anuncio: nuevo\nResumen: Se sabe que los modelos híbridos de fallos son un medio eficaz para mejorar la robustez de los sistemas replicados basados en consenso. Sin embargo, los enfoques de hibridación existentes adolecen de una flexibilidad limitada con respecto a la composición de partes del sistema tolerantes a fallos y tolerantes a fallos bizantinos y/o están asociados a una sobrecarga de diversificación significativa. En este artículo abordamos estos problemas con ShellFT, un marco que aprovecha el concepto de microrreplicación para permitir a los diseñadores de sistemas elegir libremente las partes de la lógica de replicación que deben ser resistentes a fallos bizantinos. Como ventaja clave, esta hibridación selectiva permite desarrollar soluciones híbridas adaptadas a las características y requisitos específicos de cada caso de uso. Para ilustrar esta flexibilidad, presentamos tres protocolos ShellFT personalizados y analizamos la complejidad de sus implementaciones. Nuestra evaluación muestra que, en comparación con los enfoques de hibridación tradicionales, ShellFT es capaz de reducir los costes de diversificación en más de un 70%.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs",
    "title_es": "Puzzles Multi-vuelta: Evaluación del razonamiento interactivo y el diálogo estratégico en los LLM",
    "url": "https://arxiv.org/abs/2508.10142",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10142v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos lingüísticos (LLMs) sobresalen en la resolución de problemas con enunciados claros y completos, pero a menudo tienen dificultades con entornos matizados o tareas interactivas que son comunes en la mayoría de los escenarios del mundo real. Esto pone de relieve la necesidad crítica de desarrollar LLMs que puedan participar eficazmente en un diálogo multi-vuelta lógicamente consistente, buscar información y razonar con datos incompletos. Para ello, introducimos una nueva prueba que incluye un conjunto de tareas multiturno diseñadas para poner a prueba habilidades específicas de razonamiento, diálogo interactivo y búsqueda de información. Estas tareas tienen mecanismos de puntuación deterministas, lo que elimina la necesidad de intervención humana. La evaluación de los modelos de frontera en nuestra prueba de referencia revela un margen de maniobra significativo. Nuestro análisis muestra que la mayoría de los errores se deben a un mal seguimiento de las instrucciones, a fallos de razonamiento y a una mala planificación. Esta prueba proporciona información valiosa sobre los puntos fuertes y débiles de los LLM actuales en el manejo de escenarios complejos e interactivos y ofrece una plataforma sólida para futuras investigaciones destinadas a mejorar estas capacidades críticas.",
    "source": "arXiv"
  },
  {
    "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection",
    "title_es": "Sistema multiagente orquestado por MCP para la detección automatizada de desinformación",
    "url": "https://arxiv.org/abs/2508.10143",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10143v1 Tipo de anuncio: nuevo\nResumen: La gran propagación de la desinformación a través de las plataformas digitales crea retos significativos para la integridad de la información. Este trabajo presenta un sistema multiagente que utiliza la extracción de relaciones para detectar desinformación en artículos de noticias, centrándose en títulos y fragmentos cortos de texto. El sistema propuesto combina cuatro agentes: (i) un agente de aprendizaje automático (regresión logística), (ii) un agente de comprobación de conocimientos de Wikipedia (que se basa en el reconocimiento de entidades con nombre), (iii) un agente de detección de coherencia (que utiliza ingeniería de impulsos LLM), y (iv) un analizador de datos web-scraped que extrae tripletas relacionales para la comprobación de hechos. El sistema se orquesta mediante el Protocolo de Contexto de Modelo (MCP), que ofrece contexto compartido y aprendizaje en vivo entre los componentes. Los resultados demuestran que el conjunto multiagente alcanza una precisión del 95,3% con una puntuación F1 de 0,964, superando significativamente a los agentes individuales y a los enfoques tradicionales. El método de agregación ponderada, derivado matemáticamente de las tasas de clasificación errónea de los agentes individuales, demuestra ser superior a la optimización algorítmica de umbrales. La arquitectura modular hace que el sistema sea fácilmente escalable, al tiempo que mantiene los detalles de los procesos de decisión.",
    "source": "arXiv"
  },
  {
    "title": "WiFi-based Global Localization in Large-Scale Environments Leveraging Structural Priors from osmAG",
    "title_es": "Localización global basada en WiFi en entornos a gran escala aprovechando los priores estructurales de osmAG",
    "url": "https://arxiv.org/abs/2508.10144",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10144v1 Tipo de anuncio: nuevo\nResumen: La localización global es esencial para la robótica autónoma, especialmente en entornos interiores donde la señal GPS es denegada. Proponemos un novedoso marco de localización basado en WiFi que aprovecha la infraestructura inalámbrica ubicua y el OpenStreetMap Area Graph (osmAG) para entornos interiores a gran escala. Nuestro enfoque integra el modelado de la propagación de la señal con las premisas geométricas y topológicas de osmAG. En la fase offline, un algoritmo de optimización iterativo localiza los puntos de acceso WiFi modelando la atenuación de las paredes, logrando un error medio de localización de 3,79 m (35,3% de mejora sobre la trilateración). En la fase en línea, la localización del robot en tiempo real utiliza el mapa osmAG aumentado, obteniendo un error medio de 3,12 m en zonas con huellas dactilares (8,77% de mejora sobre la huella KNN) y de 3,83 m en zonas sin huellas dactilares (81,05% de mejora). La comparación con un método basado en huellas dactilares muestra que nuestro enfoque es mucho más eficiente en términos de espacio y logra una precisión de localización superior, especialmente en posiciones en las que no se dispone de datos de huellas dactilares. Validado en un entorno complejo de 11.025 &m^2& de varias plantas, este marco ofrece una solución escalable y rentable para la localización robótica en interiores, resolviendo el problema del robot secuestrado. El código y el conjunto de datos están disponibles en https://github.com/XuMa369/osmag-wifi-localization.",
    "source": "arXiv"
  },
  {
    "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges",
    "title_es": "Marcos de IA agenética: Arquitecturas, protocolos y retos de diseño",
    "url": "https://arxiv.org/abs/2508.10146",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10146v1 Tipo de anuncio: nuevo\nResumen: La aparición de grandes modelos de lenguaje (LLMs) ha dado paso a un paradigma transformador en la inteligencia artificial, la IA Agenética, donde los agentes inteligentes exhiben autonomía dirigida a objetivos, razonamiento contextual y coordinación dinámica multi-agente. Este artículo ofrece una revisión sistemática y un análisis comparativo de los principales marcos de IA agéntica, como CrewAI, LangGraph, AutoGen, Semantic Kernel, Agno, Google ADK y MetaGPT, evaluando sus principios arquitectónicos, mecanismos de comunicación, gestión de memoria, barreras de seguridad y alineación con los paradigmas de computación orientada a servicios. Además, identificamos las principales limitaciones, las tendencias emergentes y los retos pendientes en este campo. Para abordar la cuestión de la comunicación entre agentes, analizamos en profundidad protocolos como el Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network Protocol (ANP) y Agora. Nuestros hallazgos no sólo establecen una taxonomía fundamental para los sistemas de IA agenética, sino que también proponen futuras líneas de investigación para mejorar la escalabilidad, robustez e interoperabilidad. Este trabajo sirve de referencia exhaustiva para investigadores y profesionales que trabajan en el avance de la próxima generación de sistemas autónomos de IA.",
    "source": "arXiv"
  },
  {
    "title": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data",
    "title_es": "rETF-semiSL: Aprendizaje semisupervisado para el colapso neuronal en datos temporales",
    "url": "https://arxiv.org/abs/2508.10147",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10147v1 Tipo de anuncio: nuevo\nResumen: Las redes neuronales profundas para series temporales deben capturar patrones temporales complejos, para representar eficazmente datos dinámicos. Los métodos de aprendizaje auto-supervisado y semi-supervisado muestran resultados prometedores en el pre-entrenamiento de grandes modelos, que - cuando se ajustan para la clasificación - a menudo superan a sus homólogos entrenados desde cero. Sin embargo, la elección de las tareas de preentrenamiento suele ser heurística y su transferibilidad a la clasificación posterior no está garantizada, por lo que proponemos una novedosa estrategia de preentrenamiento semisupervisado para reforzar las representaciones latentes que satisfacen el fenómeno de colapso neuronal observado en los clasificadores neuronales entrenados de forma óptima. Utilizamos un clasificador rotacional equiangular y un pseudoetiquetado para preentrenar codificadores profundos con pocas muestras etiquetadas. Además, para capturar eficazmente la dinámica temporal al tiempo que se refuerza la separabilidad de la incrustación, integramos tareas generativas de pretexto con nuestro método, y definimos una novedosa estrategia de aumento secuencial. Demostramos que nuestro método supera significativamente las tareas de pretexto anteriores cuando se aplica a LSTM, transformadores y modelos de espacio de estados en tres conjuntos de datos de clasificación de series temporales multivariantes. Estos resultados ponen de relieve las ventajas de alinear los objetivos del preentrenamiento con una geometría de incrustación teóricamente fundamentada.",
    "source": "arXiv"
  },
  {
    "title": "Out-of-Distribution Detection using Counterfactual Distance",
    "title_es": "Detección fuera de la distribución mediante la distancia contrafáctica",
    "url": "https://arxiv.org/abs/2508.10148",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10148v1 Tipo de anuncio: nuevo\nResumen: La detección precisa y explicable de datos fuera de distribución (OOD) es necesaria para utilizar sistemas de aprendizaje automático de forma segura. En trabajos anteriores se ha demostrado que la distancia de las características a los límites de decisión se puede utilizar para identificar datos OOD con eficacia. En este artículo, nos basamos en esta intuición y proponemos un método de detección de OOD post-hoc que, dada una entrada, calcula la distancia a los límites de decisión aprovechando explicaciones contrafactuales. Dado que el cálculo de las explicaciones puede ser costoso para arquitecturas de gran tamaño, también proponemos estrategias para mejorar la escalabilidad mediante el cálculo de contrafactuales directamente en el espacio de incrustación. Y lo que es más importante, como el método emplea explicaciones contrafácticas, podemos utilizarlas sin problemas para ayudar a interpretar los resultados de nuestro detector. Demostramos que nuestro método está en línea con el estado del arte en CIFAR-10, logrando un 93,50% de AUROC y un 25,80% de FPR95. Nuestro método supera a estos métodos en CIFAR-100, con un 97,05% de AUROC y un 13,79% de FPR95, y en ImageNet-200, con un 92,55% de AUROC y un 33,55% de FPR95 en cuatro conjuntos de datos OOD.",
    "source": "arXiv"
  },
  {
    "title": "Improving and Evaluating Open Deep Research Agents",
    "title_es": "Mejora y evaluación de los agentes de investigación abierta en profundidad",
    "url": "https://arxiv.org/abs/2508.10152",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10152v1 Anunciar Tipo: nuevo\nResumen: Nos centramos aquí en los Agentes de Investigación Profunda (DRAs), que son sistemas que pueden tomar un lenguaje natural de un usuario, y luego buscar de forma autónoma, y utilizar, el contenido basado en Internet para hacer frente a la solicitud. Los DRA más recientes han demostrado unas capacidades impresionantes en pruebas comparativas públicas, pero la investigación reciente se centra sobre todo en sistemas propietarios de código cerrado. En el momento de realizar este trabajo, sólo hemos encontrado un DRA de código abierto, denominado Open Deep Research (ODR). En este trabajo adaptamos el reciente y desafiante benchmark BrowseComp para comparar ODR con los sistemas propietarios existentes. Proponemos BrowseComp-Small (BC-Small), que comprende un subconjunto de BrowseComp, como una referencia de DRA más asequible computacionalmente para los laboratorios académicos. Comparamos ODR y otros dos sistemas propietarios en BC-Small: un sistema de Anthropic y otro de Google. Los tres sistemas obtienen un 0% de precisión en el conjunto de 60 preguntas de la prueba. Introducimos tres mejoras estratégicas en ODR, lo que da lugar al modelo ODR+, que alcanza una tasa de acierto del 10% en BC-Small entre los sistemas de código cerrado y de código abierto. Presentamos estudios de ablación que indican que nuestras tres mejoras contribuyeron al éxito de ODR+.",
    "source": "arXiv"
  },
  {
    "title": "Characterizing Evolution in Expectation-Maximization Estimates for Overspecified Mixed Linear Regression",
    "title_es": "Caracterización de la evolución en las estimaciones de maximización de expectativas para la regresión lineal mixta sobreespecificada",
    "url": "https://arxiv.org/abs/2508.10154",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10154v1 Tipo de anuncio: nuevo\nResumen: Los modelos de mezcla han atraído una gran atención debido a su eficacia práctica y a sus amplios fundamentos teóricos. Un reto persistente es la mala especificación del modelo, que se produce cuando el modelo a ajustar tiene más componentes de mezcla que los de la distribución de los datos. En este artículo, desarrollamos una comprensión teórica del comportamiento del algoritmo de maximización de expectativas (EM) en el contexto de la especificación errónea del modelo para la regresión lineal mixta de dos componentes sobreespecificada (2MLR) con parámetros de regresión y pesos de mezcla $d$-dimensionales desconocidos. En el Teorema 5.1 a nivel de población, con una conjetura inicial desequilibrada para los pesos de mezcla, establecemos la convergencia lineal de los parámetros de regresión en $O(\\log(1/\\epsilon))$ pasos. Por el contrario, con una conjetura inicial equilibrada para la mezcla de pesos, observamos una convergencia sublineal en $O(\\epsilon^{-2})$ pasos para alcanzar la $\\epsilon$-precisión en la distancia euclidiana. En el Teorema 6.1 a nivel de muestra finita, para mezclas con pesos de mezcla fijos suficientemente desequilibrados, demostramos una precisión estadística de $O((d/n)^{1/2})$, mientras que para aquellas con pesos de mezcla fijos suficientemente equilibrados, la precisión es $O((d/n)^{1/4})$ dadas $n$ muestras de datos. Además, subrayamos la conexión entre nuestros resultados a nivel de población y a nivel de muestra finita: estableciendo la precisión final deseada $\\epsilon$ en el Teorema 5.1 para que coincida con la del Teorema 6.1 en el nivel de muestra finita.1 a nivel de muestra finita, es decir, dejando que $\\epsilon = O((d/n)^{1/2})$ para pesos de mezcla fijos suficientemente desequilibrados y $\\epsilon = O((d/n)^{1/4})$ para pesos de mezcla fijos suficientemente equilibrados, derivamos intuitivamente límites de complejidad de iteración $O(\\log (1/\\epsilon))=O(\\log (n/d))$ y $O(\\epsilon^{-2})=O((n/d)^{1/2})$ a nivel de muestra finita para pesos de mezcla iniciales suficientemente desequilibrados y equilibrados. Además, extendemos nuestro análisis en un entorno sobreespecificado al régimen de baja SNR.",
    "source": "arXiv"
  },
  {
    "title": "Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model",
    "title_es": "Mejora de la clasificación de la enfermedad de la sandía (Citrullus lanatus) con imágenes sintéticas y reales basadas en inteligencia artificial generativa (GenAI) mediante un modelo personalizado EfficientNetV2-L",
    "url": "https://arxiv.org/abs/2508.10156",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10156v1 Tipo de anuncio: nuevo\nResumen: Los avances actuales en modelos de inteligencia artificial generativa (GenAI) han allanado el camino para nuevas posibilidades de generación de imágenes sintéticas de alta resolución, ofreciendo así una alternativa prometedora a la adquisición tradicional de imágenes para el entrenamiento de modelos de visión por ordenador en agricultura. En el contexto del diagnóstico de enfermedades de los cultivos, los modelos GenAI se están utilizando para crear imágenes sintéticas de diversas enfermedades, lo que podría facilitar la creación de modelos y reducir la dependencia de la recogida de datos sobre el terreno, que requiere muchos recursos. Sin embargo, se han realizado pocas investigaciones sobre la evaluación de la eficacia de integrar imágenes reales con sintéticas para mejorar el rendimiento de la clasificación de enfermedades. Por lo tanto, este estudio tiene como objetivo investigar si la combinación de un número limitado de imágenes reales con imágenes sintéticas puede mejorar la precisión de predicción de un modelo EfficientNetV2-L para clasificar las enfermedades de la sandía \\textit{(Citrullus lanatus)}. El conjunto de datos de entrenamiento se dividió en cinco tratamientos: H0 (sólo imágenes reales), H1 (sólo imágenes sintéticas), H2 (1:1 real-sintético), H3 (1:10 real-sintético), y H4 (H3 + imágenes aleatorias para mejorar la variabilidad y la generalización del modelo). Todos los tratamientos se entrenaron utilizando una arquitectura EfficientNetV2-L personalizada con técnicas mejoradas de ajuste fino y aprendizaje por transferencia. Los modelos entrenados con los tratamientos H2, H3 y H4 demostraron una alta precisión, recuperación y puntuación F1. Además, la puntuación F1 ponderada aumentó de 0,65 (en H0) a 1,00 (en H3-H4), lo que significa que la adición de un pequeño número de imágenes reales con un volumen considerable de imágenes sintéticas mejoró el rendimiento y la generalizabilidad del modelo. En general, esto valida los hallazgos de que las imágenes sintéticas por sí solas no pueden sustituir adecuadamente a las imágenes reales; en su lugar, ambas deben utilizarse de manera híbrida para maximizar el rendimiento del modelo para la clasificación de enfermedades de los cultivos.",
    "source": "arXiv"
  },
  {
    "title": "On the synchronization between Hugging Face pre-trained language models and their upstream GitHub repository",
    "title_es": "Sobre la sincronización entre los modelos lingüísticos preentrenados de Hugging Face y su repositorio GitHub ascendente",
    "url": "https://arxiv.org/abs/2508.10157",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10157v1 Tipo de anuncio: nuevo\nResumen: Los modelos lingüísticos preentrenados (PTLMs) han hecho avanzar el procesamiento del lenguaje natural (PLN), permitiendo el progreso en tareas como la generación y traducción de textos. Al igual que la gestión de paquetes de software, los PTLMs se entrenan utilizando código y scripts de entorno en repositorios upstream (por ejemplo, GitHub, GH) y se distribuyen como variantes a través de plataformas downstream como Hugging Face (HF). La coordinación del desarrollo entre GH y HF plantea retos como la falta de alineación de los plazos de publicación, la inconsistencia de las versiones y la reutilización limitada de las variantes de PTLM. Hemos llevado a cabo un estudio de métodos mixtos de 325 familias de PTLM (904 variantes de HF) para examinar cómo se coordinan las actividades de commit. Nuestro análisis revela que los colaboradores de GH suelen realizar cambios relacionados con la especificación de la versión del modelo, la mejora de la calidad del código, la optimización del rendimiento y la gestión de dependencias dentro de los scripts de entrenamiento, mientras que los colaboradores de HF realizan cambios relacionados con la mejora de las descripciones del modelo, el manejo del conjunto de datos y la configuración necesaria para la inferencia del modelo. Además, para comprender los aspectos de sincronización de las actividades de commit entre GH y HF, examinamos tres dimensiones de estas actividades -retraso (delay), tipo de sincronización e intensidad- que en conjunto dieron lugar a ocho patrones de sincronización distintos. La prevalencia de patrones parcialmente sincronizados, como la sincronización dispersa, revela desconexiones estructurales en las prácticas actuales de publicación entre plataformas. Estos patrones suelen dar lugar a cambios aislados -en los que las mejoras o correcciones realizadas en una plataforma nunca se reproducen en la otra- y, en algunos casos, indican el abandono de un repositorio en favor del otro. Esta fragmentación puede exponer a los usuarios finales a modelos incompletos, obsoletos o con comportamientos incoherentes. Por lo tanto, reconocer estos patrones de sincronización es fundamental para mejorar la supervisión y la trazabilidad en los flujos de trabajo de publicación de PTLM.",
    "source": "arXiv"
  },
  {
    "title": "A Generalized Alternating Anderson Acceleration Method",
    "title_es": "Método de aceleración de Anderson alternativo generalizado",
    "url": "https://arxiv.org/abs/2508.10158",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10158v1 Anunciar Tipo: nuevo\nResumen: En este trabajo proponemos un método de aceleración de Anderson alternante generalizado, un esquema periódico compuesto por $t$ pasos de iteración en punto fijo, intercalados con $s$ pasos de aceleración de Anderson con tamaño de ventana $m$, para resolver problemas lineales y no lineales. Esto permite flexibilidad para utilizar diferentes combinaciones de iteración en punto fijo e iteración de Anderson. Presentamos un análisis de convergencia del esquema propuesto para acelerar la iteración de Richardson en el caso lineal, centrándonos en opciones de parámetros específicos de interés. Específicamente, probamos la convergencia del método propuesto bajo iteración contractiva de punto fijo y proporcionamos una condición suficiente para la convergencia cuando la matriz de iteración de Richardson es diagonalizable y no contractiva. Para demostrar la amplia aplicabilidad de nuestro método propuesto, lo utilizamos para acelerar la iteración de Jacobi, la iteración de Picard, el descenso de gradiente y el método de los multiplicadores de dirección alterna en la resolución de ecuaciones diferenciales parciales y problemas de optimización no lineales y no suaves. Los resultados numéricos ilustran que el esquema propuesto es más eficiente que la aceleración de Anderson por ventanas y Anderson alternante ($s=1$) en términos de número de iteraciones y tiempo de CPU para una elección cuidadosa de los parámetros $m, s, t$.",
    "source": "arXiv"
  },
  {
    "title": "Pre-trained Transformer-models using chronic invasive electrophysiology for symptom decoding without patient-individual training",
    "title_es": "Modelos Transformer preentrenados mediante electrofisiología invasiva crónica para la descodificación de síntomas sin entrenamiento individual del paciente.",
    "url": "https://arxiv.org/abs/2508.10160",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10160v1 Tipo de anuncio: nuevo\nResumen: La decodificación neuronal de estados patológicos y fisiológicos puede permitir la terapia de neuromodulación de bucle cerrado individualizada para cada paciente. Los recientes avances en modelos básicos a gran escala preentrenados ofrecen la posibilidad de estimar estados generalizados sin necesidad de entrenar a cada paciente. Aquí presentamos un modelo básico entrenado a partir de grabaciones longitudinales crónicas de estimulación cerebral profunda que abarcan más de 24 días. Teniendo en cuenta las fluctuaciones de los síntomas a largo plazo, destacamos la ventana de contexto ampliada de 30 minutos. Presentamos una función de pérdida de preentrenamiento optimizada para datos electrofisiológicos neuronales que corrige el sesgo de frecuencia de las funciones de pérdida de autocodificador enmascarado comunes debido a la ley de potencia 1-sobre-f. Demostramos en una tarea posterior la decodificación de los síntomas de la enfermedad de Parkinson con validación cruzada de exclusión de un solo sujeto sin entrenamiento individual del paciente.",
    "source": "arXiv"
  },
  {
    "title": "LaajMeter: A Framework for LaaJ Evaluation",
    "title_es": "LaajMeter: Un marco para la evaluación de LaaJ",
    "url": "https://arxiv.org/abs/2508.10161",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10161v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos lingüísticos (LLM) se utilizan cada vez más como evaluadores en tareas de procesamiento del lenguaje natural, un paradigma conocido como LLM-as-a-Judge (LaaJ). Aunque son eficaces en dominios generales, los LaaJ plantean importantes retos en contextos específicos de dominio, donde los datos anotados son escasos y la evaluación por expertos es costosa. En tales casos, la metaevaluación se realiza a menudo utilizando métricas que no han sido validadas para el dominio específico en el que se aplican. Como resultado, resulta difícil determinar qué métricas identifican eficazmente la calidad de LaaJ y, además, qué umbral indica un rendimiento suficiente del evaluador. En este trabajo presentamos LaaJMeter, un marco basado en la simulación para la metaevaluación controlada de LaaJ. LaaJMeter permite a los ingenieros generar datos sintéticos que representan modelos y jueces virtuales, permitiendo el análisis sistemático de las métricas de evaluación en condiciones realistas. Esto ayuda a los profesionales a validar y perfeccionar las LaaJ para tareas de evaluación específicas: pueden comprobar si sus métricas distinguen correctamente entre LaaJ mejores y peores (virtuales), y estimar umbrales apropiados para la adecuación del evaluador.\n  Demostramos la utilidad de LaaJMeter en una tarea de traducción de código que implica un lenguaje de programación heredado, mostrando cómo las diferentes métricas varían en sensibilidad a la calidad del evaluador. Nuestros resultados ponen de manifiesto las limitaciones de las métricas habituales y la importancia de seleccionar métricas basadas en principios. LaaJMeter proporciona una solución escalable y extensible para evaluar LaaJs en entornos de bajos recursos, contribuyendo al esfuerzo más amplio para asegurar una evaluación fiable y reproducible en NLP.",
    "source": "arXiv"
  },
  {
    "title": "Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization",
    "title_es": "Poda de largas cadenas de pensamiento de grandes modelos de razonamiento mediante la optimización de preferencias a pequeña escala",
    "url": "https://arxiv.org/abs/2508.10164",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10164v1 Tipo de anuncio: nuevo\nResumen: Los recientes avances en los Modelos de Razonamiento de Gran Tamaño (LRMs) han demostrado un gran rendimiento en tareas complejas a través de largas Cadenas de Pensamiento (CoT) de razonamiento. Sin embargo, sus largos resultados aumentan los costes computacionales y pueden llevar a pensar demasiado, lo que plantea retos a la hora de equilibrar la eficacia y la eficiencia del razonamiento. Los métodos actuales de razonamiento eficiente a menudo comprometen la calidad del razonamiento o requieren muchos recursos. Este artículo investiga métodos eficientes para reducir la longitud de generación de los LRM. Analizamos las distribuciones de trayectorias de generación y filtramos las trayectorias generadas mediante la estimación de la dificultad. Posteriormente, analizamos los comportamientos de convergencia de los objetivos de varios métodos de optimización de preferencias bajo un marco basado en pérdidas Bradley-Terry. Basándonos en el análisis, proponemos la Optimización de Preferencia Controlada por Longitud (LCPO) que equilibra directamente la recompensa implícita relacionada con la pérdida NLL. LCPO puede aprender eficazmente la preferencia de longitud con datos y entrenamiento limitados. Extensos experimentos demuestran que nuestro enfoque reduce significativamente la longitud media de salida en más del 50\\% a través de múltiples puntos de referencia, manteniendo el rendimiento de razonamiento. Nuestro trabajo destaca el potencial de los enfoques computacionalmente eficientes para guiar a los LRM hacia un razonamiento eficiente.",
    "source": "arXiv"
  },
  {
    "title": "REALISM: A Regulatory Framework for Coordinated Scheduling in Multi-Operator Shared Micromobility Services",
    "title_es": "REALISM: Un marco normativo para la programación coordinada en servicios de micro movilidad compartidos por varios operadores",
    "url": "https://arxiv.org/abs/2508.10166",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10166v1 Tipo de anuncio: nuevo\nResumen: La micromovilidad compartida (por ejemplo, bicicletas y patinetes eléctricos compartidos), como tipo de transporte urbano emergente, se ha hecho cada vez más popular en el mundo. Sin embargo, el florecimiento de los vehículos de micromovilidad compartida conlleva algunos problemas sociales para la ciudad (p. ej., vehículos sobrecargados en las carreteras y desigualdad en el despliegue de vehículos), que se desvían de las expectativas de los reguladores municipales sobre el servicio del sistema de micromovilidad compartida. Además, el sistema de micromovilidad compartida multioperador de una ciudad complica el problema debido a sus intereses propios no cooperativos. Los marcos reguladores existentes del reequilibrio de vehículos multioperador asumen generalmente el control intrusivo del reequilibrio de vehículos de todos los operadores, lo que no resulta práctico en el mundo real. Para hacer frente a esta limitación, diseñamos REALISM, un marco regulador para la programación coordinada en servicios de micro movilidad compartida multioperador que incorpora las regulaciones del regulador de la ciudad en forma de asignación de una puntuación a cada operador de acuerdo con los logros de los objetivos de la ciudad y las contribuciones individuales de los operadores para alcanzar el objetivo de la ciudad, medido por el valor de Shapley. Para llevar a cabo la asignación de puntuaciones teniendo en cuenta la equidad, medimos la equidad de las puntuaciones asignadas y las utilizamos como uno de los componentes para optimizar el modelo de asignación de puntuaciones. Para optimizar todo el marco, desarrollamos un procedimiento alternativo para que los operadores y el regulador de la ciudad interactúen entre sí hasta la convergencia. Evaluamos nuestro marco basándonos en datos reales de uso de e-scooters en Chicago. Los resultados de nuestros experimentos muestran que nuestro método consigue una ganancia de rendimiento de al menos el 39,93% en la equidad del uso de vehículos y del 1,82% en la satisfacción de la demanda media de toda la ciudad.",
    "source": "arXiv"
  },
  {
    "title": "SynSpill: Improved Industrial Spill Detection With Synthetic Data",
    "title_es": "SynSpill: Mejora de la detección de vertidos industriales con datos sintéticos",
    "url": "https://arxiv.org/abs/2508.10171",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10171v1 Tipo de anuncio: nuevo\nResumen: Los modelos de visión-lenguaje (VLM) a gran escala han transformado el reconocimiento visual de propósito general gracias a su gran capacidad de detección de cero disparos. Sin embargo, su rendimiento se degrada significativamente en nichos de dominio críticos para la seguridad, como la detección de derrames industriales, donde los eventos peligrosos son raros, sensibles y difíciles de anotar. Esta escasez, motivada por la preocupación por la privacidad, la sensibilidad de los datos y la infrecuencia de los incidentes reales, hace que el ajuste fino convencional de los detectores resulte inviable en la mayoría de los entornos industriales.\n  Abordamos este reto introduciendo un marco escalable centrado en un proceso de generación de datos sintéticos de alta calidad. Demostramos que este corpus sintético permite un ajuste fino eficaz de los parámetros (PEFT) de los VLM y mejora sustancialmente el rendimiento de los detectores de objetos más avanzados, como YOLO y DETR. Cabe destacar que, en ausencia de datos sintéticos (conjunto de datos SynSpill), los VLM siguen generalizando mejor que estos detectores en escenarios de vertidos no observados. Cuando se utiliza SynSpill, tanto los VLM como los detectores logran notables mejoras y su rendimiento llega a ser comparable.\n  Nuestros resultados ponen de relieve que los datos sintéticos de alta fidelidad son un poderoso medio para salvar la brecha de dominio en aplicaciones críticas para la seguridad. La combinación de generación sintética y adaptación ligera ofrece una vía rentable y escalable para desplegar sistemas de visión en entornos industriales en los que los datos reales son escasos/imposibles de obtener.\n  Página del proyecto: https://synspill.vercel.app",
    "source": "arXiv"
  },
  {
    "title": "Benchmark-Driven Selection of AI: Evidence from DeepSeek-R1",
    "title_es": "Selección de la IA en función de criterios de referencia: DeepSeek-R1",
    "url": "https://arxiv.org/abs/2508.10173",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10173v1 Tipo de anuncio: nuevo\nResumen: La evaluación de los modelos de lenguaje de razonamiento adquirió importancia después de que se observara que pueden combinar sus capacidades existentes en trazas novedosas de pasos intermedios antes de la finalización de la tarea y que las trazas a veces pueden ayudarles a generalizar mejor que los modelos anteriores. A medida que el razonamiento se convierte en la siguiente dimensión de escalado de los grandes modelos lingüísticos, se hace necesario un estudio cuidadoso de sus capacidades en tareas críticas. Demostramos que un mejor rendimiento no siempre se debe a las mejoras algorítmicas en tiempo de prueba o al tamaño de los modelos, sino también al uso de puntos de referencia impactantes como currículos para el aprendizaje. Llamamos a esto selección de IA basada en puntos de referencia y mostramos sus efectos en DeepSeek-R1 utilizando nuestro problema secuencial de toma de decisiones de Humanity's Last Exam. Dirigir el desarrollo de la IA mediante puntos de referencia impactantes cambia la evaluación por el aprendizaje y hace que la novedad de las tareas de prueba sea clave para medir la capacidad de generalización de los modelos de razonamiento. En consecuencia, algunos puntos de referencia podrían considerarse planes de estudios para la formación en lugar de conjuntos de pruebas inéditas.",
    "source": "arXiv"
  },
  {
    "title": "Estimating Machine Translation Difficulty",
    "title_es": "Estimación de la dificultad de la traducción automática",
    "url": "https://arxiv.org/abs/2508.10175",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10175v1 Tipo de anuncio: nuevo\nResumen: La calidad de la traducción automática ha comenzado a alcanzar traducciones casi perfectas en algunas configuraciones. Estos resultados de alta calidad dificultan la distinción entre los modelos más avanzados y la identificación de áreas de mejora en el futuro. La identificación automática de textos en los que los sistemas de traducción automática tienen dificultades resulta prometedora para desarrollar evaluaciones más discriminatorias y orientar la investigación futura.\n  Formalizamos la tarea de estimación de la dificultad de traducción, definiendo la dificultad de un texto en función de la calidad esperada de sus traducciones. Introducimos una nueva métrica para evaluar los estimadores de dificultad y la utilizamos para evaluar tanto las líneas de base como los enfoques novedosos. Por último, demostramos la utilidad práctica de los estimadores de dificultad utilizándolos para construir pruebas de traducción automática más exigentes. Nuestros resultados demuestran que los modelos específicos (denominados Sentinel-src) superan tanto a los métodos heurísticos (por ejemplo, la rareza de las palabras o la complejidad sintáctica) como a los enfoques LLM-as-a-judge. Publicamos dos modelos mejorados para la estimación de la dificultad, Sentinel-src-24 y Sentinel-src-25, que pueden utilizarse para escanear grandes colecciones de textos y seleccionar los que tienen más probabilidades de desafiar a los sistemas de traducción automática contemporáneos.",
    "source": "arXiv"
  },
  {
    "title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems",
    "title_es": "KompeteAI: sistema multiagente autónomo acelerado para la generación de canalizaciones de extremo a extremo para problemas de aprendizaje automático",
    "url": "https://arxiv.org/abs/2508.10177",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10177v1 Tipo de anuncio: nuevo\nResumen: Los recientes sistemas AutoML basados en Large Language Model (LLM) demuestran capacidades impresionantes, pero se enfrentan a limitaciones significativas, como estrategias de exploración restringidas y un grave cuello de botella en la ejecución. La exploración se ve obstaculizada por métodos de un solo disparo que carecen de diversidad y por enfoques de búsqueda en árbol Monte Carlo (MCTS) que no consiguen recombinar soluciones parciales sólidas. El cuello de botella de la ejecución se debe a los largos ciclos de validación del código, que impiden el perfeccionamiento iterativo. Para superar estos retos, presentamos KompeteAI, un novedoso marco AutoML con exploración dinámica del espacio de soluciones. A diferencia de los métodos MCTS anteriores, que tratan las ideas de forma aislada, KompeteAI introduce una etapa de fusión que compone los mejores candidatos. Además, ampliamos el espacio de hipótesis integrando la Generación de Recuperación-Aumentada (RAG), obteniendo ideas de cuadernos Kaggle y artículos arXiv para incorporar estrategias del mundo real. KompeteAI también aborda el cuello de botella de la ejecución a través de un modelo de puntuación predictiva y un método de depuración acelerado, evaluando el potencial de la solución utilizando métricas de fase temprana para evitar la costosa ejecución de código completo. Este enfoque acelera la evaluación de la tubería 6,9 veces. KompeteAI supera a los métodos líderes (p. ej., RD-agent, AIDE y Ml-Master) en una media del 3\\% en el principal punto de referencia de AutoML, MLE-Bench. Además, proponemos Kompete-bench para abordar las limitaciones de MLE-Bench, donde KompeteAI también logra resultados de vanguardia.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs",
    "title_es": "Valoración eficiente de datos prospectivos para LLM y VLM preentrenados",
    "url": "https://arxiv.org/abs/2508.10180",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10180v1 Tipo de anuncio: nuevo\nResumen: Cuantificar la influencia de las muestras de entrenamiento individuales es esencial para mejorar la transparencia y la responsabilidad de los grandes modelos de lenguaje (LLMs) y los modelos de visión-lenguaje (VLMs). Sin embargo, los métodos de valoración de datos existentes a menudo se basan en la información hessiana o en el reentrenamiento del modelo, lo que los hace computacionalmente prohibitivos para modelos de mil millones de parámetros. En este trabajo, presentamos For-Value, un marco de valoración de datos sólo hacia delante que permite una estimación de la influencia escalable y eficiente tanto para LLMs como para VLMs. Aprovechando las ricas representaciones de los modelos de fundamentos modernos, For-Value calcula las puntuaciones de influencia utilizando una sencilla expresión de forma cerrada basada únicamente en una única pasada hacia delante, eliminando así la necesidad de costosos cálculos de gradiente. Nuestro análisis teórico demuestra que For-Value estima con precisión la influencia por muestra capturando la alineación en las representaciones ocultas y los errores de predicción entre las muestras de entrenamiento y validación. Extensos experimentos demuestran que For-Value iguala o supera a las líneas de base basadas en gradientes a la hora de identificar ejemplos impactantes de ajuste fino y detectar eficazmente datos mal etiquetados.",
    "source": "arXiv"
  },
  {
    "title": "An Architecture for Distributed Digital Identities in the Physical World",
    "title_es": "Una arquitectura para identidades digitales distribuidas en el mundo físico",
    "url": "https://arxiv.org/abs/2508.10185",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10185v1 Tipo de anuncio: nuevo\nResumen: Las identidades digitales son cada vez más importantes para mediar en las transacciones de servicios no sólo digitales, sino también físicos. La gestión de dichas identidades a través de proveedores centralizados puede causar problemas tanto de disponibilidad como de privacidad: los puntos únicos de fallo y control son objetivos ideales para ataques globales en frentes técnicos, organizativos o legales. Diseñamos, analizamos y construimos una arquitectura de identidad digital distribuida para transacciones del mundo físico en escenarios comunes como el desbloqueo de puertas, el transporte público o el cruce de fronteras entre países. Esta arquitectura combina sensores (biométricos y de otro tipo), autoridades de identidad (establecidas y futuras), verificadores de atributos y un nuevo componente central que denominamos \\emph{Personal Identity Agent (PIA)} que representa a los individuos con sus atributos de identidad en el ámbito digital. Todas las transacciones se realizan de forma completamente descentralizada, y los componentes para los que actualmente asumimos una coordinación central son opcionales y sólo se utilizan para ayudar al descubrimiento de servicios y a la reducción de latencia. Presentamos un primer protocolo entre estas partes y verificamos formalmente que alcanza propiedades de seguridad relevantes basadas en un modelo de amenaza realista que incluye adversarios globales fuertes. Una prueba de concepto demuestra la viabilidad práctica tanto de la arquitectura como del protocolo inicial para aplicaciones que pueden tolerar latencias de extremo a extremo de unos pocos segundos.",
    "source": "arXiv"
  },
  {
    "title": "PakBBQ: A Culturally Adapted Bias Benchmark for QA",
    "title_es": "PakBBQ: un punto de referencia culturalmente adaptado para el control de calidad",
    "url": "https://arxiv.org/abs/2508.10186",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10186v1 Tipo de anuncio: nuevo\nResumen: Con la adopción generalizada de grandes modelos lingüísticos (LLM) en diversas aplicaciones, resulta empírico garantizar su equidad en todas las comunidades de usuarios. Sin embargo, la mayoría de los LLM se entrenan y evalúan con datos centrados en Occidente, prestando poca atención a las lenguas de bajos recursos y a los contextos regionales. Para colmar esta laguna, presentamos PakBBQ, una extensión cultural y regionalmente adaptada del conjunto de datos original Bias Benchmark for Question Answering (BBQ). PakBBQ incluye más de 214 plantillas y 17180 pares de preguntas de respuesta en 8 categorías, tanto en inglés como en urdu, que cubren ocho dimensiones de sesgo, como la edad, la discapacidad, la apariencia, el sexo, el estatus socioeconómico, la religión, la afiliación regional y la formalidad del idioma, que son relevantes en Pakistán. Evaluamos múltiples LLM multilingües en contextos ambiguos y explícitamente desambiguados, así como en marcos de pregunta negativos y no negativos. Nuestros experimentos revelan (i) un aumento medio de la precisión del 12% con la desambiguación, (ii) comportamientos sistemáticamente más contrarios al sesgo en urdu que en inglés, y (iii) marcados efectos de encuadre que reducen las respuestas estereotipadas cuando las preguntas se plantean negativamente. Estos resultados ponen de relieve la importancia de los puntos de referencia contextualizados y las estrategias sencillas de ingeniería de indicaciones para mitigar los prejuicios en entornos con pocos recursos.",
    "source": "arXiv"
  },
  {
    "title": "Contested Route Planning",
    "title_es": "Planificación de rutas controvertidas",
    "url": "https://arxiv.org/abs/2508.10189",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10189v1 Tipo de anuncio: nuevo\nResumen: Consideramos el problema de enrutamiento con fines logísticos, en un entorno disputado donde un adversario intenta interrumpir el vehículo a lo largo de la ruta elegida. Construimos un modelo teórico de juegos que captura el problema del enrutamiento óptimo en dicho entorno. Los planes de ruta deterministas, robustos y básicos ya son difíciles de diseñar, pero tienden a ser predecibles, lo que puede limitar su eficacia. Al introducir una aleatoriedad calculada mediante la modelización del proceso de planificación de rutas como un juego de suma cero entre dos jugadores, calculamos planes inmediatamente desplegables que están diversificados y son más difíciles de prever. Aunque la resolución exacta del juego es intratable en teoría, nuestro uso del marco de doble oráculo nos permite lograr tiempos de cálculo del orden de segundos, lo que hace que el enfoque sea viable desde el punto de vista operativo. En concreto, el marco es lo suficientemente modular como para dar cabida a algoritmos de enrutamiento especializados como oráculos. Evaluamos nuestro método en escenarios reales, demostrando que se adapta eficazmente a problemas de tamaño realista y que se beneficia significativamente de la modelización explícita de las capacidades del adversario, como demuestran los estudios de ablación y las comparaciones con enfoques de referencia.",
    "source": "arXiv"
  },
  {
    "title": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models",
    "title_es": "Métricas de divergencia semántica de pregunta-respuesta para la alucinación de fidelidad y la detección de desajustes en grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.10192",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10192v1 Tipo de anuncio: nuevo\nResumen: La proliferación de grandes modelos lingüísticos (LLM) se enfrenta a alucinaciones, modos de fallo críticos en los que los modelos generan texto no factual, sin sentido o infiel. En este artículo se presenta la Métrica de Divergencia Semántica (SDM), un nuevo marco ligero para detectar alucinaciones de fidelidad, es decir, eventos de desviaciones graves de las respuestas de los LLM respecto a los contextos de entrada. Nos centramos en una implementación específica de estos errores LLM, {confabulaciones, definidas como respuestas arbitrarias y semánticamente desalineadas con la consulta del usuario. Los métodos existentes, como la Entropía Semántica, comprueban la arbitrariedad midiendo la diversidad de respuestas a una única pregunta fija. Nuestro marco SDM lo mejora al ser más consciente de la pregunta: comprobamos una forma más profunda de arbitrariedad midiendo la coherencia de la respuesta no sólo entre múltiples respuestas, sino también entre múltiples paráfrasis semánticamente equivalentes de la pregunta original. Desde el punto de vista metodológico, nuestro enfoque utiliza la agrupación conjunta de frases para crear un espacio temático compartido para las preguntas y las respuestas. Un mapa térmico de co-ocurrencias temáticas entre preguntas y respuestas puede verse como una visualización bidimensional cuantificada del diálogo usuario-máquina. A continuación, calculamos una serie de métricas teóricas de la información para medir la divergencia semántica entre las preguntas y las respuestas. Nuestra puntuación práctica, $\\mathcal{S}_H$, combina la divergencia Jensen-Shannon y la distancia Wasserstein para cuantificar esta divergencia, y una puntuación alta indica una alucinación de fidelidad. Además, identificamos la divergencia KL(Answer $||$ Prompt) como un potente indicador de \\textbf{Semantic Exploration}, una señal clave para distinguir distintos comportamientos generativos. Estas métricas se combinan además en la Caja Semántica, un marco de diagnóstico para clasificar los tipos de respuesta LLM, incluida la confabulación peligrosa y confiada.",
    "source": "arXiv"
  },
  {
    "title": "Training Spatial Ability in Virtual Reality",
    "title_es": "Entrenamiento de la capacidad espacial en realidad virtual",
    "url": "https://arxiv.org/abs/2508.10195",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10195v1 Tipo de anuncio: nuevo\nResumen: Antecedentes: El razonamiento espacial se ha identificado como una habilidad crítica para el éxito en STEM. Desafortunadamente, los grupos infrarrepresentados suelen tener una menor habilidad espacial de entrada. Existen cursos que mejoran las habilidades espaciales, pero su uso no está muy extendido. La realidad virtual (RV) se ha sugerido como una posible herramienta para la enseñanza del razonamiento espacial, ya que los estudiantes son más precisos y completan más rápidamente las tareas espaciales en tres dimensiones. Sin embargo, ningún trabajo anterior ha desarrollado o evaluado un curso de habilidades espaciales de RV completamente estructurado. Objetivos: Pretendemos evaluar la eficacia de la enseñanza del razonamiento espacial en RV, tanto de forma aislada como plan de estudios estructurado, como en comparación con los métodos tradicionales. Métodos: Adaptamos tres módulos de un curso existente de lápiz y papel a la RV, aprovechando el andamiaje educativo y la retroalimentación en tiempo real en el diseño. Evaluamos nuestro curso de tres semanas en un estudio con $n=24$ estudiantes universitarios de introducción a las ciencias, la ingeniería y las matemáticas, obteniendo beneficios cuantitativos en la capacidad espacial (mediante puntuaciones previas y posteriores en evaluaciones validadas) y cualitativos (a partir de un cuestionario posterior al estudio). También comparamos nuestro curso de RV con un curso de referencia sin RV (utilizando datos recogidos en un estudio anterior). Resultados y conclusiones: Los estudiantes que siguieron nuestro curso de RV mejoraron significativamente su capacidad espacial. Además, no encontramos diferencias significativas entre los resultados de nuestro curso de RV (3 sesiones de 120 minutos cada una) y los de un curso básico de lápiz y papel (10 sesiones de 90 minutos cada una), lo que sugiere que el razonamiento espacial puede enseñarse muy eficazmente en RV. Se observaron tasas de mareo cibernético más bajas de lo que se suele decir, y la mayoría de los alumnos afirmaron disfrutar aprendiendo con la RV.",
    "source": "arXiv"
  },
  {
    "title": "Digital Contact Tracing: Examining the Effects of Understanding and Release Organization on Public Trust",
    "title_es": "Rastreo digital de contactos: Examen de los efectos de la comprensión y la organización de la divulgación en la confianza pública",
    "url": "https://arxiv.org/abs/2508.10198",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10198v1 Anunciar Tipo: nuevo\nResumen: El rastreo de contactos ha existido en diversas formas durante mucho tiempo. Con el auge del COVID-19, el concepto ha cobrado cada vez más importancia para ayudar a frenar la propagación del virus. Un enfoque para modernizar el rastreo de contactos consiste en introducir aplicaciones que detecten todos los contactos cercanos sin que los individuos tengan que interactuar a sabiendas. En junio de 2022 se encuestó a 101 adultos de Estados Unidos sobre su percepción y confianza en las aplicaciones de rastreo de contactos COVID-19. No vemos ninguna correlación definitiva entre la comprensión de un individuo de los procedimientos de protección de la privacidad de las aplicaciones de rastreo de contactos y su disposición a confiar en dicha aplicación. También vemos que la publicación de la aplicación por una entidad privada como Google-Apple o por una entidad pública como el Gobierno Federal de los Estados Unidos no tiene una correlación significativa con la confianza de una persona en la aplicación.",
    "source": "arXiv"
  },
  {
    "title": "B-repLer: Semantic B-rep Latent Editor using Large Language Models",
    "title_es": "B-repLer: Editor latente semántico de B-rep mediante grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.10201",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10201v1 Tipo de anuncio: nuevo\nResumen: Se ha demostrado que los modelos multimodales de gran lenguaje (mLLMs), entrenados en un entorno modal mixto como modelo universal, compiten o incluso superan a muchos algoritmos especializados para tareas de imagen y gráficos. Como se ha demostrado en muchas aplicaciones, la capacidad de los mLLM para procesar conjuntamente datos de imagen y texto los hace adecuados para aplicaciones de disparo cero o para un ajuste fino eficiente hacia tareas especializadas. Sin embargo, han tenido un éxito limitado en tareas de análisis y edición 3D. Esto se debe tanto a la falta de datos 3D adecuados (anotados) como a la idiosincrasia de las representaciones 3D. En este artículo, investigamos si los mLLM pueden adaptarse para soportar la edición de alto nivel de objetos CAD de Representación de Límites (B-rep). Las B-reps siguen siendo el estándar de la industria para codificar con precisión objetos de ingeniería, pero suponen un reto ya que la representación es frágil (es decir, puede dar lugar fácilmente a objetos CAD no válidos) y no existe ninguna fuente de datos disponible públicamente con B-reps anotadas semánticamente o historial de construcción CAD. Presentamos B-repLer como un mLLM perfeccionado capaz de comprender instrucciones de texto y realizar ediciones semánticas en B-Reps dados para producir resultados válidos. Para ello, utilizamos una novedosa arquitectura multimodal, diseñada específicamente para manejar modelos B-rep, y demostramos cómo las herramientas CAD existentes, junto con los mLLM, pueden utilizarse para generar automáticamente el conjunto de datos de razonamiento necesario, sin depender de anotaciones externas. Evaluamos ampliamente B-repLer y demostramos varias ediciones de B-rep basadas en texto de diversa complejidad, que antes no eran posibles.",
    "source": "arXiv"
  },
  {
    "title": "Mixed-Precision Performance Portability of FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices",
    "title_es": "Portabilidad de algoritmos de FFT basados en la GPU para matrices de Toeplitz triangulares en bloque con prestaciones de precisión mixta",
    "url": "https://arxiv.org/abs/2508.10202",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10202v1 Tipo de anuncio: nuevo\nResumen: La diversidad de hardware que presentan las principales instalaciones de computación, junto con las enormes mejoras de rendimiento que presentan las GPU actuales cuando se computa en baja precisión, proporcionan un fuerte incentivo para que los flujos de trabajo científicos de HPC adopten algoritmos de precisión mixta y modelos de portabilidad del rendimiento. Presentamos un marco de trabajo sobre la marcha que utiliza Hipify para la portabilidad del rendimiento y lo aplicamos a FFTMatvec, una aplicación de HPC que calcula productos vectoriales de matrices con matrices Toeplitz triangulares en bloque. Nuestro enfoque permite que FFTMatvec, inicialmente una aplicación exclusiva de CUDA, se ejecute sin problemas en GPUs AMD con un excelente rendimiento observado. Las optimizaciones de rendimiento para GPUs AMD se integran directamente en la librería de código abierto rocBLAS, manteniendo el código de la aplicación sin cambios. A continuación, presentamos un marco dinámico de precisión mixta para FFTMatvec; un análisis del frente de Pareto determina la configuración óptima de precisión mixta para una tolerancia de error deseada. Los resultados se muestran para las GPU AMD Instinct MI250X, MI300X y la recién lanzada MI355X. El sistema FFTMatvec de precisión mixta y fácil transporte se amplía a 2.048 GPU en el superordenador OLCF Frontier.",
    "source": "arXiv"
  },
  {
    "title": "Systematic Constraint Formulation and Collision-Free Trajectory Planning Using Space-Time Graphs of Convex Sets",
    "title_es": "Formulación sistemática de restricciones y planificación de trayectorias sin colisiones mediante grafos espacio-temporales de conjuntos convexos",
    "url": "https://arxiv.org/abs/2508.10203",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10203v1 Anunciar Tipo: nuevo\nResumen: En este trabajo, creamos trayectorias óptimas, libres de colisiones y dependientes del tiempo a través de entornos dinámicos desordenados. Las numerosas restricciones espaciales y temporales dificultan la búsqueda de una conjetura inicial para un solucionador numérico. Los grafos de conjuntos convexos (GCS) y la formulación recientemente desarrollada de grafos espaciotemporales de conjuntos convexos (ST-GCS) nos permiten generar trayectorias óptimas sin colisiones de distancia mínima sin proporcionar una conjetura inicial al solucionador. También exploramos la derivación de restricciones generales compatibles con GCS y documentamos una estrategia intuitiva para adaptar restricciones generales al marco. Demostramos que ST-GCS produce trayectorias equivalentes a la formulación GCS estándar cuando el entorno es estático. A continuación, mostramos el funcionamiento de ST-GCS en entornos dinámicos para encontrar trayectorias sin colisiones de distancia mínima.",
    "source": "arXiv"
  },
  {
    "title": "Spatial Branch-and-Bound for Computing Multiplayer Nash Equilibrium",
    "title_es": "Branch-and-Bound espacial para calcular el equilibrio de Nash multijugador",
    "url": "https://arxiv.org/abs/2508.10204",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10204v1 Tipo de anuncio: nuevo\nResumen: Los equilibrios de juegos multijugador realistas constituyen un concepto de solución clave tanto en aplicaciones prácticas, como las subastas de publicidad online y los mercados de electricidad, como en marcos analíticos utilizados para estudiar el voto estratégico en elecciones o evaluar el impacto de políticas en modelos de evaluación integrada. Sin embargo, para calcular eficientemente estos equilibrios es necesario que los juegos tengan una estructura cuidadosamente diseñada y satisfagan numerosas restricciones; de lo contrario, la complejidad computacional se vuelve prohibitiva. En concreto, se sabe que la búsqueda de equilibrios de Nash, incluso aproximados, en juegos de suma general y forma normal con dos o más jugadores es PPAD-completa. Los algoritmos más avanzados para calcular los equilibrios de Nash en juegos multijugador de forma normal o bien son poco escalables debido a su dependencia de soluciones de optimización no convexas, o bien carecen de garantías de convergencia a un equilibrio verdadero. En este trabajo, proponemos una formulación del problema de cálculo del equilibrio de Nash como un problema de complementariedad polinómica y desarrollamos un algoritmo de branch-and-bound espacial completo y sólido basado en esta formulación. Proporcionamos un análisis cualitativo que argumenta por qué cabe esperar que nuestro planteamiento funcione bien, y mostramos la relación entre las soluciones aproximadas a nuestra formulación y la de calcular un equilibrio de Nash aproximado. Las evaluaciones empíricas demuestran que nuestro algoritmo supera sustancialmente a los métodos completos existentes.",
    "source": "arXiv"
  },
  {
    "title": "An Explainable AI based approach for Monitoring Animal Health",
    "title_es": "Un enfoque explicable basado en la IA para vigilar la salud animal",
    "url": "https://arxiv.org/abs/2508.10210",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10210v1 Tipo de anuncio: nuevo\nResumen: Monitorizar la salud del ganado y optimizar el rendimiento son retos clave a los que se enfrentan los ganaderos de vacuno de leche debido a las dificultades para hacer un seguimiento de todos los animales de la granja. Este trabajo pretende mostrar prácticas ganaderas modernas basadas en datos y en métodos explicables de aprendizaje automático (ML) que explican la actividad y el comportamiento del ganado lechero (vacas). La recopilación continua de datos de sensores acelerómetros de 3 ejes y el uso de metodologías y algoritmos de ML robustos proporcionan a los ganaderos e investigadores información procesable sobre la actividad del ganado, lo que permite a los ganaderos tomar decisiones informadas e incorporar prácticas sostenibles. Este estudio utiliza dispositivos de Internet de las Cosas (IoT) basados en Bluetooth y redes 4G para la transmisión fluida de datos, el análisis inmediato, la generación de inferencias y explica el rendimiento de los modelos con marcos de explicabilidad. Se hace especial hincapié en el preprocesamiento de los datos de las series temporales de los acelerómetros, incluida la extracción de características estadísticas, técnicas de procesamiento de señales y características basadas en retardo mediante la técnica de ventana deslizante. Se evalúan varios modelos de ML optimizados para hiperparámetros con distintas longitudes de ventana para la clasificación de la actividad. El clasificador k-próximo más cercano obtuvo el mejor rendimiento, con un AUC medio de 0,98 y una desviación estándar de 0,0026 en el conjunto de entrenamiento y de 0,99 en el conjunto de pruebas). Para garantizar la transparencia, se utilizan marcos basados en IA explicable, como SHAP, para interpretar la importancia de las características de forma que los profesionales puedan entenderlas y utilizarlas. Una comparación detallada de las características importantes, junto con el análisis de estabilidad de las características seleccionadas, apoya el desarrollo de modelos de ML explicables y prácticos para la gestión ganadera sostenible.",
    "source": "arXiv"
  },
  {
    "title": "Detecting Untargeted Attacks and Mitigating Unreliable Updates in Federated Learning for Underground Mining Operations",
    "title_es": "Detección de ataques no dirigidos y mitigación de actualizaciones no fiables en el aprendizaje federado para explotaciones mineras subterráneas",
    "url": "https://arxiv.org/abs/2508.10212",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10212v1 Tipo de anuncio: nuevo\nResumen: Las operaciones mineras subterráneas dependen de redes de sensores distribuidas para recopilar datos críticos diariamente, incluida la temperatura de la mina, las concentraciones de gases tóxicos y los movimientos de los mineros para la detección de peligros y la toma de decisiones operativas. Sin embargo, la transmisión de datos brutos de sensores a un servidor central para el entrenamiento de modelos de aprendizaje profundo introduce riesgos significativos para la privacidad, exponiendo potencialmente información sensible específica de la mina. El aprendizaje federado (FL) ofrece una solución transformadora al permitir el entrenamiento colaborativo de modelos al tiempo que garantiza que los datos en bruto permanezcan localizados en cada mina. A pesar de sus ventajas, el FL en la minería subterránea se enfrenta a importantes retos: (i) un atacante puede poner en peligro el modelo local de una mina empleando técnicas como ataques de inversión de signos o ruido aditivo, lo que daría lugar a predicciones erróneas; (ii) los datos de baja calidad (aunque potencialmente valiosos), causados por las malas condiciones de iluminación o las imprecisiones de los sensores en las minas, pueden degradar el proceso de entrenamiento del FL. En respuesta, este trabajo propone MineDetect, un marco de defensa FL que detecta y aísla los modelos atacados, al tiempo que mitiga el impacto de las minas con datos de baja calidad. MineDetect introduce dos innovaciones clave: (i) Detectar modelos atacados (manipulados maliciosamente) mediante el desarrollo de un mecanismo consciente de la historia que aprovecha los promedios locales y globales de las actualizaciones de gradiente; (ii) Identificar y eliminar las influencias adversas de modelos poco fiables (generados por clientes con datos de baja calidad) en el proceso de entrenamiento FL. Simulaciones exhaustivas en diversos conjuntos de datos demuestran que MineDetect supera a los métodos existentes tanto en robustez como en precisión, incluso en situaciones difíciles con datos no procedentes de IID. Su capacidad para contrarrestar las influencias adversas al tiempo que mantiene una menor eficiencia computacional lo convierte en un avance vital para mejorar la seguridad y la eficacia operativa en la minería subterránea.",
    "source": "arXiv"
  },
  {
    "title": "CarAT: Carbon Atom Tracing across Industrial Chemical Value Chains via Chemistry Language Models",
    "title_es": "CarAT: rastreo de átomos de carbono en las cadenas de valor de la industria química mediante modelos de lenguaje químico",
    "url": "https://arxiv.org/abs/2508.10216",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10216v1 Announce Type: new \nAbstract: The chemical industry is increasingly prioritising sustainability, with a focus on reducing carbon footprints to achieve net zero. By 2026, the Together for Sustainability (TfS) consortium will require reporting of biogenic carbon content (BCC) in chemical products, posing a challenge as BCC depends on feedstocks, value chain configuration, and process-specific variables. While carbon-14 isotope analysis can measure BCC, it is impractical for continuous industrial monitoring. This work presents CarAT (Carbon Atom Tracker), an automated methodology for calculating BCC across industrial value chains, enabling dynamic and accurate sustainability reporting. The approach leverages existing Enterprise Resource Planning data in three stages: (1) preparing value chain data, (2) performing atom mapping in chemical reactions using chemistry language models, and (3) applying a linear program to calculate BCC given known inlet compositions. The methodology is validated on a 27-node industrial toluene diisocyanate value chain. Three scenarios are analysed: a base case with fossil feedstocks, a case incorporating a renewable feedstock, and a butanediol value chain with a recycle stream. Results are visualised with Sankey diagrams showing the flow of carbon attributes across the value chain. The key contribution is a scalable, automated method for real-time BCC calculation under changing industrial conditions. CarAT supports compliance with upcoming reporting mandates and advances carbon neutrality goals by enabling systematic fossil-to-biogenic substitution. Through transparent, auditable tracking of carbon sources in production networks, it empowers data-driven decisions to accelerate the transition to sustainable manufacturing.",
    "source": "arXiv"
  },
  {
    "title": "AI-Driven Detection and Analysis of Handwriting on Seized Ivory: A Tool to Uncover Criminal Networks in the Illicit Wildlife Trade",
    "title_es": "Detección y análisis basados en IA de escritura manuscrita en marfil incautado: Una herramienta para descubrir redes delictivas en el comercio ilícito de especies silvestres",
    "url": "https://arxiv.org/abs/2508.10219",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10219v1 Announce Type: new \nAbstract: The transnational ivory trade continues to drive the decline of elephant populations across Africa, and trafficking networks remain difficult to disrupt. Tusks seized by law enforcement officials carry forensic information on the traffickers responsible for their export, including DNA evidence and handwritten markings made by traffickers. For 20 years, analyses of tusk DNA have identified where elephants were poached and established connections among shipments of ivory. While the links established using genetic evidence are extremely conclusive, genetic data is expensive and sometimes impossible to obtain. But though handwritten markings are easy to photograph, they are rarely documented or analyzed. Here, we present an AI-driven pipeline for extracting and analyzing handwritten markings on seized elephant tusks, offering a novel, scalable, and low-cost source of forensic evidence. Having collected 6,085 photographs from eight large seizures of ivory over a 6-year period (2014-2019), we used an object detection model to extract over 17,000 individual markings, which were then labeled and described using state-of-the-art AI tools. We identified 184 recurring \"signature markings\" that connect the tusks on which they appear. 20 signature markings were observed in multiple seizures, establishing forensic links between these seizures through traffickers involved in both shipments. This work complements other investigative techniques by filling in gaps where other data sources are unavailable. The study demonstrates the transformative potential of AI in wildlife forensics and highlights practical steps for integrating handwriting analysis into efforts to disrupt organized wildlife crime.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Textual Emotion Through Emoji Prediction",
    "title_es": "Entender la emoción textual mediante la predicción de emoji",
    "url": "https://arxiv.org/abs/2508.10222",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10222v1 Announce Type: new \nAbstract: This project explores emoji prediction from short text sequences using four deep learning architectures: a feed-forward network, CNN, transformer, and BERT. Using the TweetEval dataset, we address class imbalance through focal loss and regularization techniques. Results show BERT achieves the highest overall performance due to its pre-training advantage, while CNN demonstrates superior efficacy on rare emoji classes. This research shows the importance of architecture selection and hyperparameter tuning for sentiment-aware emoji prediction, contributing to improved human-computer interaction.",
    "source": "arXiv"
  },
  {
    "title": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia",
    "title_es": "Uso de modelos de lenguaje amplio para medir la gravedad de los síntomas en pacientes con riesgo de esquizofrenia",
    "url": "https://arxiv.org/abs/2508.10226",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10226v1 Announce Type: new \nAbstract: Patients who are at clinical high risk (CHR) for schizophrenia need close monitoring of their symptoms to inform appropriate treatments. The Brief Psychiatric Rating Scale (BPRS) is a validated, commonly used research tool for measuring symptoms in patients with schizophrenia and other psychotic disorders; however, it is not commonly used in clinical practice as it requires a lengthy structured interview. Here, we utilize large language models (LLMs) to predict BPRS scores from clinical interview transcripts in 409 CHR patients from the Accelerating Medicines Partnership Schizophrenia (AMP-SCZ) cohort. Despite the interviews not being specifically structured to measure the BPRS, the zero-shot performance of the LLM predictions compared to the true assessment (median concordance: 0.84, ICC: 0.73) approaches human inter- and intra-rater reliability. We further demonstrate that LLMs have substantial potential to improve and standardize the assessment of CHR patients via their accuracy in assessing the BPRS in foreign languages (median concordance: 0.88, ICC: 0.70), and integrating longitudinal information in a one-shot or few-shot learning approach.",
    "source": "arXiv"
  },
  {
    "title": "EntropyGS: An Efficient Entropy Coding on 3D Gaussian Splatting",
    "title_es": "EntropyGS: Una codificación eficiente de la entropía en 3D Gaussian Splatting",
    "url": "https://arxiv.org/abs/2508.10227",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10227v1 Announce Type: new \nAbstract: As an emerging novel view synthesis approach, 3D Gaussian Splatting (3DGS) demonstrates fast training/rendering with superior visual quality. The two tasks of 3DGS, Gaussian creation and view rendering, are typically separated over time or devices, and thus storage/transmission and finally compression of 3DGS Gaussians become necessary. We begin with a correlation and statistical analysis of 3DGS Gaussian attributes. An inspiring finding in this work reveals that spherical harmonic AC attributes precisely follow Laplace distributions, while mixtures of Gaussian distributions can approximate rotation, scaling, and opacity. Additionally, harmonic AC attributes manifest weak correlations with other attributes except for inherited correlations from a color space. A factorized and parameterized entropy coding method, EntropyGS, is hereinafter proposed. During encoding, distribution parameters of each Gaussian attribute are estimated to assist their entropy coding. The quantization for entropy coding is adaptively performed according to Gaussian attribute types. EntropyGS demonstrates about 30x rate reduction on benchmark datasets while maintaining similar rendering quality compared to input 3DGS data, with a fast encoding and decoding time.",
    "source": "arXiv"
  },
  {
    "title": "Comparison of D-Wave Quantum Annealing and Markov Chain Monte Carlo for Sampling from a Probability Distribution of a Restricted Boltzmann Machine",
    "title_es": "Comparación del Recocido Cuántico de Onda-D y el Monte Carlo de Cadena de Markov para el Muestreo de una Distribución de Probabilidad de una Máquina de Boltzmann Restringida",
    "url": "https://arxiv.org/abs/2508.10228",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10228v1 Announce Type: new \nAbstract: A local-valley (LV) centered approach to assessing the quality of sampling from Restricted Boltzmann Machines (RBMs) was applied to the latest generation of the D-Wave quantum annealer. D-Wave and Gibbs samples from a classically trained RBM were obtained at conditions relevant to the contrastive-divergence-based RBM learning. The samples were compared for the number of the LVs to which they belonged and the energy of the corresponding local minima. No significant (desirable) increase in the number of the LVs has been achieved by decreasing the D-Wave annealing time. At any training epoch, the states sampled by the D-Wave belonged to a somewhat higher number of LVs than in the Gibbs sampling. However, many of those LVs found by the two techniques differed. For high-probability sampled states, the two techniques were (unfavorably) less complementary and more overlapping. Nevertheless, many potentially \"important\" local minima, i.e., those having intermediate, even if not high, probability values, were found by only one of the two sampling techniques while missed by the other. The two techniques overlapped less at later than earlier training epochs, which is precisely the stage of the training when modest improvements to the sampling quality could make meaningful differences for the RBM trainability. The results of this work may explain the failure of previous investigations to achieve substantial (or any) improvement when using D-Wave-based sampling. However, the results reveal some potential for improvement, e.g., using a combined classical-quantum approach.",
    "source": "arXiv"
  },
  {
    "title": "No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings",
    "title_es": "No Free Lunch from Audio Pretraining in Bioacoustics: Un estudio comparativo de incrustaciones",
    "url": "https://arxiv.org/abs/2508.10230",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10230v1 Announce Type: new \nAbstract: Bioacoustics, the study of animal sounds, offers a non-invasive method to monitor ecosystems. Extracting embeddings from audio-pretrained deep learning (DL) models without fine-tuning has become popular for obtaining bioacoustic features for tasks. However, a recent benchmark study reveals that while fine-tuned audio-pretrained VGG and transformer models achieve state-of-the-art performance in some tasks, they fail in others. This study benchmarks 11 DL models on the same tasks by reducing their learned embeddings' dimensionality and evaluating them through clustering. We found that audio-pretrained DL models 1) without fine-tuning even underperform fine-tuned AlexNet, 2) both with and without fine-tuning fail to separate the background from labeled sounds, but ResNet does, and 3) outperform other models when fewer background sounds are included during fine-tuning. This study underscores the necessity of fine-tuning audio-pretrained models and checking the embeddings after fine-tuning. Our codes are available: https://github.com/NeuroscienceAI/Audio\\_Embeddings",
    "source": "arXiv"
  },
  {
    "title": "CellSymphony: Deciphering the molecular and phenotypic orchestration of cells with single-cell pathomics",
    "title_es": "CellSymphony: Deciphering the molecular and phenotypic orchestration of cells with single-cell pathomics",
    "url": "https://arxiv.org/abs/2508.10232",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10232v1 Announce Type: new \nAbstract: Xenium, a new spatial transcriptomics platform, enables subcellular-resolution profiling of complex tumor tissues. Despite the rich morphological information in histology images, extracting robust cell-level features and integrating them with spatial transcriptomics data remains a critical challenge. We introduce CellSymphony, a flexible multimodal framework that leverages foundation model-derived embeddings from both Xenium transcriptomic profiles and histology images at true single-cell resolution. By learning joint representations that fuse spatial gene expression with morphological context, CellSymphony achieves accurate cell type annotation and uncovers distinct microenvironmental niches across three cancer types. This work highlights the potential of foundation models and multimodal fusion for deciphering the physiological and phenotypic orchestration of cells within complex tissue ecosystems.",
    "source": "arXiv"
  },
  {
    "title": "Interpretable Machine Learning Model for Early Prediction of Acute Kidney Injury in Critically Ill Patients with Cirrhosis: A Retrospective Study",
    "title_es": "Interpretable Machine Learning Model for Early Prediction of Acute Kidney Injury in Critically Ill Patients with Cirrhosis: A Retrospective Study",
    "url": "https://arxiv.org/abs/2508.10233",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10233v1 Announce Type: new \nAbstract: Background: Cirrhosis is a progressive liver disease with high mortality and frequent complications, notably acute kidney injury (AKI), which occurs in up to 50% of hospitalized patients and worsens outcomes. AKI stems from complex hemodynamic, inflammatory, and metabolic changes, making early detection essential. Many predictive tools lack accuracy, interpretability, and alignment with intensive care unit (ICU) workflows. This study developed an interpretable machine learning model for early AKI prediction in critically ill patients with cirrhosis.\n  Methods: We conducted a retrospective analysis of the MIMIC-IV v2.2 database, identifying 1240 adult ICU patients with cirrhosis and excluding those with ICU stays under 48 hours or missing key data. Laboratory and physiological variables from the first 48 hours were extracted. The pipeline included preprocessing, missingness filtering, LASSO feature selection, and SMOTE class balancing. Six algorithms-LightGBM, CatBoost, XGBoost, logistic regression, naive Bayes, and neural networks-were trained and evaluated using AUROC, accuracy, F1-score, sensitivity, specificity, and predictive values.\n  Results: LightGBM achieved the best performance (AUROC 0.808, 95% CI 0.741-0.856; accuracy 0.704; NPV 0.911). Key predictors included prolonged partial thromboplastin time, absence of outside-facility 20G placement, low pH, and altered pO2, consistent with known cirrhosis-AKI mechanisms and suggesting actionable targets.\n  Conclusion: The LightGBM-based model enables accurate early AKI risk stratification in ICU patients with cirrhosis using routine clinical variables. Its high negative predictive value supports safe de-escalation for low-risk patients, and interpretability fosters clinician trust and targeted prevention. External validation and integration into electronic health record systems are warranted.",
    "source": "arXiv"
  },
  {
    "title": "Can Transformers Break Encryption Schemes via In-Context Learning?",
    "title_es": "Can Transformers Break Encryption Schemes via In-Context Learning?",
    "url": "https://arxiv.org/abs/2508.10235",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10235v1 Announce Type: new \nAbstract: In-context learning (ICL) has emerged as a powerful capability of transformer-based language models, enabling them to perform tasks by conditioning on a small number of examples presented at inference time, without any parameter updates. Prior work has shown that transformers can generalize over simple function classes like linear functions, decision trees, even neural networks, purely from context, focusing on numerical or symbolic reasoning over underlying well-structured functions. Instead, we propose a novel application of ICL into the domain of cryptographic function learning, specifically focusing on ciphers such as mono-alphabetic substitution and Vigen\\`ere ciphers, two classes of private-key encryption schemes. These ciphers involve a fixed but hidden bijective mapping between plain text and cipher text characters. Given a small set of (cipher text, plain text) pairs, the goal is for the model to infer the underlying substitution and decode a new cipher text word. This setting poses a structured inference challenge, which is well-suited for evaluating the inductive biases and generalization capabilities of transformers under the ICL paradigm. Code is available at https://github.com/adistomar/CS182-project.",
    "source": "arXiv"
  },
  {
    "title": "DS4RS: Community-Driven and Explainable Dataset Search Engine for Recommender System Research",
    "title_es": "DS4RS: Community-Driven and Explainable Dataset Search Engine for Recommender System Research",
    "url": "https://arxiv.org/abs/2508.10238",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10238v1 Announce Type: new \nAbstract: Accessing suitable datasets is critical for research and development in recommender systems. However, finding datasets that match specific recommendation task or domains remains a challenge due to scattered sources and inconsistent metadata. To address this gap, we propose a community-driven and explainable dataset search engine tailored for recommender system research. Our system supports semantic search across multiple dataset attributes, such as dataset names, descriptions, and recommendation domain, and provides explanations of search relevance to enhance transparency. The system encourages community participation by allowing users to contribute standardized dataset metadata in public repository. By improving dataset discoverability and search interpretability, the system facilitates more efficient research reproduction. The platform is publicly available at: https://ds4rs.com.",
    "source": "arXiv"
  },
  {
    "title": "Personalized Real-time Jargon Support for Online Meetings",
    "title_es": "Personalized Real-time Jargon Support for Online Meetings",
    "url": "https://arxiv.org/abs/2508.10239",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10239v1 Announce Type: new \nAbstract: Effective interdisciplinary communication is frequently hindered by domain-specific jargon. To explore the jargon barriers in-depth, we conducted a formative diary study with 16 professionals, revealing critical limitations in current jargon-management strategies during workplace meetings. Based on these insights, we designed ParseJargon, an interactive LLM-powered system providing real-time personalized jargon identification and explanations tailored to users' individual backgrounds. A controlled experiment comparing ParseJargon against baseline (no support) and general-purpose (non-personalized) conditions demonstrated that personalized jargon support significantly enhanced participants' comprehension, engagement, and appreciation of colleagues' work, whereas general-purpose support negatively affected engagement. A follow-up field study validated ParseJargon's usability and practical value in real-time meetings, highlighting both opportunities and limitations for real-world deployment. Our findings contribute insights into designing personalized jargon support tools, with implications for broader interdisciplinary and educational applications.",
    "source": "arXiv"
  },
  {
    "title": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence",
    "title_es": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence",
    "url": "https://arxiv.org/abs/2508.10241",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10241v1 Announce Type: new \nAbstract: This work demonstrates how the concept of the entropic potential of events -- a parameter quantifying the influence of discrete events on the expected future entropy of a system -- can enhance uncertainty quantification, decision-making, and interpretability in artificial intelligence (AI). Building on its original formulation in physics, the framework is adapted for AI by introducing an event-centric measure that captures how actions, observations, or other discrete occurrences impact uncertainty at future time horizons. Both the original and AI-adjusted definitions of entropic potential are formalized, with the latter emphasizing conditional expectations to account for counterfactual scenarios. Applications are explored in policy evaluation, intrinsic reward design, explainable AI, and anomaly detection, highlighting the metric's potential to unify and strengthen uncertainty modeling in intelligent systems. Conceptual examples illustrate its use in reinforcement learning, Bayesian inference, and anomaly detection, while practical considerations for computation in complex AI models are discussed. The entropic potential framework offers a theoretically grounded, interpretable, and versatile approach to managing uncertainty in AI, bridging principles from thermodynamics, information theory, and machine learning.",
    "source": "arXiv"
  },
  {
    "title": "Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models",
    "title_es": "Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models",
    "url": "https://arxiv.org/abs/2508.10243",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10243v1 Announce Type: new \nAbstract: Transformer models have demonstrated exceptional performance and have become indispensable in computer vision (CV) and natural language processing (NLP) tasks. However, recent studies reveal that transformers are susceptible to backdoor attacks. Prior backdoor attack methods typically rely on retraining with clean data or altering the model architecture, both of which can be resource-intensive and intrusive. In this paper, we propose Head-wise Pruning and Malicious Injection (HPMI), a novel retraining-free backdoor attack on transformers that does not alter the model's architecture. Our approach requires only a small subset of the original data and basic knowledge of the model architecture, eliminating the need for retraining the target transformer. Technically, HPMI works by pruning the least important head and injecting a pre-trained malicious head to establish the backdoor. We provide a rigorous theoretical justification demonstrating that the implanted backdoor resists detection and removal by state-of-the-art defense techniques, under reasonable assumptions. Experimental evaluations across multiple datasets further validate the effectiveness of HPMI, showing that it 1) incurs negligible clean accuracy loss, 2) achieves at least 99.55% attack success rate, and 3) bypasses four advanced defense mechanisms. Additionally, relative to state-of-the-art retraining-dependent attacks, HPMI achieves greater concealment and robustness against diverse defense strategies, while maintaining minimal impact on clean accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Space-time Coded Differential Modulation for Reconfigurable Intelligent Surfaces",
    "title_es": "Space-time Coded Differential Modulation for Reconfigurable Intelligent Surfaces",
    "url": "https://arxiv.org/abs/2508.10244",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10244v1 Announce Type: new \nAbstract: Reconfigurable Intelligent Surfaces (RIS) hold the promise of improving significantly coverage, as well as spectral and energy efficiency in wireless communication systems. Techniques based on RIS form a key technology for 6G systems. An important issue in RIS technology is Channel State Information (CSI), which is much more difficult to acquire in such systems. This work introduces a Differential Space-Time Modulation (DSTM) scheme integrated with Differential Reflecting Modulation (DRM) to bypass the requirement for CSI in such systems, while providing error rate gains. The DSTM scheme is based on unitary group codes. We first consider uncoded DRM for RIS to serve as a reference point. Next we provide an overview of DSTM and outline the procedures for its integration with DRM. Furthermore, we explore the extension of both the original DRM and the coded DRM-DSTM scheme to a larger number of RIS reflecting patterns $K$, and provide tables of codes for $K= 2, 3, 4$. Encoding and decoding complexities are studied as well. Extensives simulation results over quasi-static Rayleigh fading channels confirm the effectiveness of the DRM-DSTM coded system, illustrating its advantages over uncoded DRM with proper system parameters.",
    "source": "arXiv"
  },
  {
    "title": "A Computational Approach to Analyzing Language Change and Variation in the Constructed Language Toki Pona",
    "title_es": "A Computational Approach to Analyzing Language Change and Variation in the Constructed Language Toki Pona",
    "url": "https://arxiv.org/abs/2508.10246",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10246v1 Announce Type: new \nAbstract: This study explores language change and variation in Toki Pona, a constructed language with approximately 120 core words. Taking a computational and corpus-based approach, the study examines features including fluid word classes and transitivity in order to examine (1) changes in preferences of content words for different syntactic positions over time and (2) variation in usage across different corpora. The results suggest that sociolinguistic factors influence Toki Pona in the same way as natural languages, and that even constructed linguistic systems naturally evolve as communities use them.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Reliability Using Network Coding: a Practical 5G Evaluation",
    "title_es": "Rethinking Reliability Using Network Coding: a Practical 5G Evaluation",
    "url": "https://arxiv.org/abs/2508.10247",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10247v1 Announce Type: new \nAbstract: This work presents the design and implementation of a real-time network coding system integrated into the IP layer of a 5G testbed, offering an alternative to conventional retransmission-based reliability mechanisms such as ARQ and HARQ. Using a netfilter-based packet interception framework, we inject forward erasure correction using Random Linear Network Coding (RLNC) into live traffic between a gNB and UE over a 3GPP RF link. We evaluate a block coding scheme, analyzing its impact on throughput, jitter, and resource usage. Results show that with appropriate code rate selection, RLNC can fully recover from packet losses using fewer transmissions than ARQ/HARQ and maintain a high throughput, particularly under moderate-to-high packet loss rates. These findings demonstrate that network coding can effectively replace retransmission-based reliability in future wireless systems, with the potential for more efficient resource utilization.",
    "source": "arXiv"
  },
  {
    "title": "Convergence Analysis of Max-Min Exponential Neural Network Operators in Orlicz Space",
    "title_es": "Convergence Analysis of Max-Min Exponential Neural Network Operators in Orlicz Space",
    "url": "https://arxiv.org/abs/2508.10248",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10248v1 Announce Type: new \nAbstract: In this current work, we propose a Max Min approach for approximating functions using exponential neural network operators. We extend this framework to develop the Max Min Kantorovich-type exponential neural network operators and investigate their approximation properties. We study both pointwise and uniform convergence for univariate functions. To analyze the order of convergence, we use the logarithmic modulus of continuity and estimate the corresponding rate of convergence. Furthermore, we examine the convergence behavior of the Max Min Kantorovich type exponential neural network operators within the Orlicz space setting. We provide some graphical representations to illustrate the approximation error of the function through suitable kernel and sigmoidal activation functions.",
    "source": "arXiv"
  },
  {
    "title": "Output-Sparse Matrix Multiplication Using Compressed Sensing",
    "title_es": "Output-Sparse Matrix Multiplication Using Compressed Sensing",
    "url": "https://arxiv.org/abs/2508.10250",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10250v1 Announce Type: new \nAbstract: We give two algorithms for output-sparse matrix multiplication (OSMM), the problem of multiplying two $n \\times n$ matrices $A, B$ when their product $AB$ is promised to have at most $O(n^{\\delta})$ many non-zero entries for a given value $\\delta \\in [0, 2]$. We then show how to speed up these algorithms in the fully sparse setting, where the input matrices $A, B$ are themselves sparse. All of our algorithms work over arbitrary rings.\n  Our first, deterministic algorithm for OSMM works via a two-pass reduction to compressed sensing. It runs in roughly $n^{\\omega(\\delta/2, 1, 1)}$ time, where $\\omega(\\cdot, \\cdot, \\cdot)$ is the rectangular matrix multiplication exponent. This substantially improves on prior deterministic algorithms for output-sparse matrix multiplication.\n  Our second, randomized algorithm for OSMM works via a reduction to compressed sensing and a variant of matrix multiplication verification, and runs in roughly $n^{\\omega(\\delta - 1, 1, 1)}$ time. This algorithm and its extension to the fully sparse setting have running times that match those of the (randomized) algorithms for OSMM and FSMM, respectively, in recent work of Abboud, Bringmann, Fischer, and K\\\"{u}nnemann (SODA, 2024). Our algorithm uses different techniques and is arguably simpler.\n  Finally, we observe that the running time of our randomized algorithm and the algorithm of Abboud et al. are optimal via a simple reduction from rectangular matrix multiplication.",
    "source": "arXiv"
  },
  {
    "title": "Meta-Metrics and Best Practices for System-Level Inference Performance Benchmarking",
    "title_es": "Meta-Metrics and Best Practices for System-Level Inference Performance Benchmarking",
    "url": "https://arxiv.org/abs/2508.10251",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10251v1 Announce Type: new \nAbstract: Benchmarking inference performance (speed) of Foundation Models such as Large Language Models (LLM) involves navigating a vast experimental landscape to understand the complex interactions between hardware and software components. However, evaluating every possible test configuration is impractical, unfeasible and unnecessary. To address this challenge, we introduce FMwork, a comprehensive and methodical approach to creating a controlled testing environment that accurately reflects and characterizes performance. FMwork comprises a set of benchmkaring best practices with three key components: 1) meta-metrics, 2) parameter selection, and 3) strategic cost-performance evaluation. Meta-metrics account for time and resources spent on benchmarking and the relative accuracy of the results compared to a larger body of measurements, representing the complete experimental space. FMwork operationalizes the meta-metrics and provides efficient strategies for parameter selection and cost-performance analysis. Using the framework, we show up to 24x improvement (speedup and/or resource savings) running sweeps of experiments compared to the ground truth. Even already considering a subset of experiments as reference point (using the power of two for batch sizes), reducing experimental output size from 1024 to 128 tokens yields another 2.7x gain while keeping 96.6% accuracy for an evaluation using Llama 3.1 8B model.",
    "source": "arXiv"
  },
  {
    "title": "Facilitating Longitudinal Interaction Studies of AI Systems",
    "title_es": "Facilitating Longitudinal Interaction Studies of AI Systems",
    "url": "https://arxiv.org/abs/2508.10252",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10252v1 Announce Type: new \nAbstract: UIST researchers develop tools to address user challenges. However, user interactions with AI evolve over time through learning, adaptation, and repurposing, making one time evaluations insufficient. Capturing these dynamics requires longer-term studies, but challenges in deployment, evaluation design, and data collection have made such longitudinal research difficult to implement. Our workshop aims to tackle these challenges and prepare researchers with practical strategies for longitudinal studies. The workshop includes a keynote, panel discussions, and interactive breakout groups for discussion and hands-on protocol design and tool prototyping sessions. We seek to foster a community around longitudinal system research and promote it as a more embraced method for designing, building, and evaluating UIST tools.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Agent Reinforcement Learning for Adaptive Resource Orchestration in Cloud-Native Clusters",
    "title_es": "Multi-Agent Reinforcement Learning for Adaptive Resource Orchestration in Cloud-Native Clusters",
    "url": "https://arxiv.org/abs/2508.10253",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10253v1 Announce Type: new \nAbstract: This paper addresses the challenges of high resource dynamism and scheduling complexity in cloud-native database systems. It proposes an adaptive resource orchestration method based on multi-agent reinforcement learning. The method introduces a heterogeneous role-based agent modeling mechanism. This allows different resource entities, such as compute nodes, storage nodes, and schedulers, to adopt distinct policy representations. These agents are better able to reflect diverse functional responsibilities and local environmental characteristics within the system. A reward-shaping mechanism is designed to integrate local observations with global feedback. This helps mitigate policy learning bias caused by incomplete state observations. By combining real-time local performance signals with global system value estimation, the mechanism improves coordination among agents and enhances policy convergence stability. A unified multi-agent training framework is developed and evaluated on a representative production scheduling dataset. Experimental results show that the proposed method outperforms traditional approaches across multiple key metrics. These include resource utilization, scheduling latency, policy convergence speed, system stability, and fairness. The results demonstrate strong generalization and practical utility. Across various experimental scenarios, the method proves effective in handling orchestration tasks with high concurrency, high-dimensional state spaces, and complex dependency relationships. This confirms its advantages in real-world, large-scale scheduling environments.",
    "source": "arXiv"
  },
  {
    "title": "Federated Anomaly Detection for Multi-Tenant Cloud Platforms with Personalized Modeling",
    "title_es": "Federated Anomaly Detection for Multi-Tenant Cloud Platforms with Personalized Modeling",
    "url": "https://arxiv.org/abs/2508.10255",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10255v1 Announce Type: new \nAbstract: This paper proposes an anomaly detection method based on federated learning to address key challenges in multi-tenant cloud environments, including data privacy leakage, heterogeneous resource behavior, and the limitations of centralized modeling. The method establishes a federated training framework involving multiple tenants. Each tenant trains the model locally using private resource usage data. Through parameter aggregation, a global model is optimized, enabling cross-tenant collaborative anomaly detection while preserving data privacy. To improve adaptability to diverse resource usage patterns, a personalized parameter adjustment mechanism is introduced. This allows the model to retain tenant-specific feature representations while sharing global knowledge. In the model output stage, the Mahalanobis distance is used to compute anomaly scores. This enhances both the accuracy and stability of anomaly detection. The experiments use real telemetry data from a cloud platform to construct a simulated multi-tenant environment. The study evaluates the model's performance under varying participation rates and noise injection levels. These comparisons demonstrate the proposed method's robustness and detection accuracy. Experimental results show that the proposed method outperforms existing mainstream models across key metrics such as Precision, Recall, and F1-Score. It also maintains stable performance in various complex scenarios. These findings highlight the method's practical potential for intelligent resource monitoring and anomaly diagnosis in cloud computing environments.",
    "source": "arXiv"
  },
  {
    "title": "Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets",
    "title_es": "Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets",
    "url": "https://arxiv.org/abs/2508.10256",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10256v1 Announce Type: new \nAbstract: Crack detection plays a crucial role in civil infrastructures, including inspection of pavements, buildings, etc., and deep learning has significantly advanced this field in recent years. While numerous technical and review papers exist in this domain, emerging trends are reshaping the landscape. These shifts include transitions in learning paradigms (from fully supervised learning to semi-supervised, weakly-supervised, unsupervised, few-shot, domain adaptation and fine-tuning foundation models), improvements in generalizability (from single-dataset performance to cross-dataset evaluation), and diversification in dataset reacquisition (from RGB images to specialized sensor-based data). In this review, we systematically analyze these trends and highlight representative works. Additionally, we introduce a new dataset collected with 3D laser scans, 3DCrack, to support future research and conduct extensive benchmarking experiments to establish baselines for commonly used deep learning methodologies, including recent foundation models. Our findings provide insights into the evolving methodologies and future directions in deep learning-based crack detection. Project page: https://github.com/nantonzhang/Awesome-Crack-Detection",
    "source": "arXiv"
  },
  {
    "title": "Source Component Shift Adaptation via Offline Decomposition and Online Mixing Approach",
    "title_es": "Source Component Shift Adaptation via Offline Decomposition and Online Mixing Approach",
    "url": "https://arxiv.org/abs/2508.10257",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10257v1 Announce Type: new \nAbstract: This paper addresses source component shift adaptation, aiming to update predictions adapting to source component shifts for incoming data streams based on past training data. Existing online learning methods often fail to utilize recurring shifts effectively, while model-pool-based methods struggle to capture individual source components, leading to poor adaptation. In this paper, we propose a source component shift adaptation method via an offline decomposition and online mixing approach. We theoretically identify that the problem can be divided into two subproblems: offline source component decomposition and online mixing weight adaptation. Based on this, our method first determines prediction models, each of which learns a source component solely based on past training data offline through the EM algorithm. Then, it updates the mixing weight of the prediction models for precise prediction through online convex optimization. Thanks to our theoretical derivation, our method fully leverages the characteristics of the shifts, achieving superior adaptation performance over existing methods. Experiments conducted on various real-world regression datasets demonstrate that our method outperforms baselines, reducing the cumulative test loss by up to 67.4%.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging OS-Level Primitives for Robotic Action Management",
    "title_es": "Leveraging OS-Level Primitives for Robotic Action Management",
    "url": "https://arxiv.org/abs/2508.10259",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10259v1 Announce Type: new \nAbstract: End-to-end imitation learning frameworks (e.g., VLA) are increasingly prominent in robotics, as they enable rapid task transfer by learning directly from perception to control, eliminating the need for complex hand-crafted features. However, even when employing SOTA VLA-based models, they still exhibit limited generalization capabilities and suboptimal action efficiency, due to the constraints imposed by insufficient robotic training datasets. In addition to addressing this problem using model-based approaches, we observe that robotic action slices, which consist of contiguous action steps, exhibit strong analogies to the time slices of threads in traditional operating systems. This insight presents a novel opportunity to tackle the problem at the system level.\n  In this paper, we propose AMS, a robot action management system enhanced with OS-level primitives like exception, context switch and record-and-replay, that improves both execution efficiency and success rates of robotic tasks. AMS first introduces action exception, which facilitates the immediate interruption of robotic actions to prevent error propagation. Secondly, AMS proposes action context, which eliminates redundant computations for VLA-based models, thereby accelerating execution efficiency in robotic actions. Finally, AMS leverages action replay to facilitate repetitive or similar robotic tasks without the need for re-training efforts. We implement AMS in both an emulated environment and on a real robot platform. The evaluation results demonstrate that AMS significantly enhances the model's generalization ability and action efficiency, achieving task success rate improvements ranging from 7x to 24x and saving end-to-end execution time ranging from 29% to 74% compared to existing robotic system without AMS support.",
    "source": "arXiv"
  },
  {
    "title": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs",
    "title_es": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs",
    "url": "https://arxiv.org/abs/2508.10264",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10264v1 Announce Type: new \nAbstract: Large Vision-Language Models (LVLMs) have shown strong performance across multimodal tasks. However, they often produce hallucinations -- text that is inconsistent with visual input, due to the limited ability to verify information in different regions of the image. To address this, we propose Multi-Region Fusion Decoding (MRFD), a training-free decoding method that improves factual grounding by modeling inter-region consistency. MRFD identifies salient regions using cross-attention, generates initial responses for each, and computes reliability weights based on Jensen-Shannon Divergence (JSD) among the responses. These weights guide a consistency-aware fusion of per-region predictions, using region-aware prompts inspired by Chain-of-Thought reasoning. Experiments across multiple LVLMs and benchmarks show that MRFD significantly reduces hallucinations and improves response factuality without requiring model updates.",
    "source": "arXiv"
  },
  {
    "title": "Why Cannot Large Language Models Ever Make True Correct Reasoning?",
    "title_es": "Why Cannot Large Language Models Ever Make True Correct Reasoning?",
    "url": "https://arxiv.org/abs/2508.10265",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10265v1 Announce Type: new \nAbstract: Recently, with the application progress of AIGC tools based on large language models (LLMs), led by ChatGPT, many AI experts and more non-professionals are trumpeting the \"understanding ability\" and \"reasoning ability\" of the LLMs. The present author considers that the so-called \"understanding ability\" and \"reasoning ability\" of LLMs are just illusions of those people who with vague concepts. In fact, the LLMs can never have the true understanding ability and true reasoning ability. This paper intents to explain that, because the essential limitations of their working principle, the LLMs can never have the ability of true correct reasoning.",
    "source": "arXiv"
  },
  {
    "title": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones",
    "title_es": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones",
    "url": "https://arxiv.org/abs/2508.10268",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10268v1 Announce Type: new \nAbstract: Although appearance-based point-of-gaze (PoG) estimation has improved, the estimators still struggle to generalize across individuals due to personal differences. Therefore, person-specific calibration is required for accurate PoG estimation. However, calibrated PoG estimators are often sensitive to head pose variations. To address this, we investigate the key factors influencing calibrated estimators and explore pose-robust calibration strategies. Specifically, we first construct a benchmark, MobilePoG, which includes facial images from 32 individuals focusing on designated points under either fixed or continuously changing head poses. Using this benchmark, we systematically analyze how the diversity of calibration points and head poses influences estimation accuracy. Our experiments show that introducing a wider range of head poses during calibration improves the estimator's ability to handle pose variation. Building on this insight, we propose a dynamic calibration strategy in which users fixate on calibration points while moving their phones. This strategy naturally introduces head pose variation during a user-friendly and efficient calibration process, ultimately producing a better calibrated PoG estimator that is less sensitive to head pose variations than those using conventional calibration strategies. Codes and datasets are available at our project page.",
    "source": "arXiv"
  },
  {
    "title": "Hybrid Data-Driven Predictive Control for Robust and Reactive Exoskeleton Locomotion Synthesis",
    "title_es": "Hybrid Data-Driven Predictive Control for Robust and Reactive Exoskeleton Locomotion Synthesis",
    "url": "https://arxiv.org/abs/2508.10269",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10269v1 Announce Type: new \nAbstract: Robust bipedal locomotion in exoskeletons requires the ability to dynamically react to changes in the environment in real time. This paper introduces the hybrid data-driven predictive control (HDDPC) framework, an extension of the data-enabled predictive control, that addresses these challenges by simultaneously planning foot contact schedules and continuous domain trajectories. The proposed framework utilizes a Hankel matrix-based representation to model system dynamics, incorporating step-to-step (S2S) transitions to enhance adaptability in dynamic environments. By integrating contact scheduling with trajectory planning, the framework offers an efficient, unified solution for locomotion motion synthesis that enables robust and reactive walking through online replanning. We validate the approach on the Atalante exoskeleton, demonstrating improved robustness and adaptability.",
    "source": "arXiv"
  },
  {
    "title": "Ask ChatGPT: Caveats and Mitigations for Individual Users of AI Chatbots",
    "title_es": "Ask ChatGPT: Caveats and Mitigations for Individual Users of AI Chatbots",
    "url": "https://arxiv.org/abs/2508.10272",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10272v1 Announce Type: new \nAbstract: As ChatGPT and other Large Language Model (LLM)-based AI chatbots become increasingly integrated into individuals' daily lives, important research questions arise. What concerns and risks do these systems pose for individual users? What potential harms might they cause, and how can these be mitigated? In this work, we review recent literature and reports, and conduct a comprehensive investigation into these questions. We begin by explaining how LLM-based AI chatbots work, providing essential background to help readers understand chatbots' inherent limitations. We then identify a range of risks associated with individual use of these chatbots, including hallucinations, intrinsic biases, sycophantic behavior, cognitive decline from overreliance, social isolation, and privacy leakage. Finally, we propose several key mitigation strategies to address these concerns. Our goal is to raise awareness of the potential downsides of AI chatbot use, and to empower users to enhance, rather than diminish, human intelligence, to enrich, rather than compromise, daily life.",
    "source": "arXiv"
  },
  {
    "title": "High Fidelity Text to Image Generation with Contrastive Alignment and Structural Guidance",
    "title_es": "High Fidelity Text to Image Generation with Contrastive Alignment and Structural Guidance",
    "url": "https://arxiv.org/abs/2508.10280",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10280v1 Announce Type: new \nAbstract: This paper addresses the performance bottlenecks of existing text-driven image generation methods in terms of semantic alignment accuracy and structural consistency. A high-fidelity image generation method is proposed by integrating text-image contrastive constraints with structural guidance mechanisms. The approach introduces a contrastive learning module that builds strong cross-modal alignment constraints to improve semantic matching between text and image. At the same time, structural priors such as semantic layout maps or edge sketches are used to guide the generator in spatial-level structural modeling. This enhances the layout completeness and detail fidelity of the generated images. Within the overall framework, the model jointly optimizes contrastive loss, structural consistency loss, and semantic preservation loss. A multi-objective supervision mechanism is adopted to improve the semantic consistency and controllability of the generated content. Systematic experiments are conducted on the COCO-2014 dataset. Sensitivity analyses are performed on embedding dimensions, text length, and structural guidance strength. Quantitative metrics confirm the superior performance of the proposed method in terms of CLIP Score, FID, and SSIM. The results show that the method effectively bridges the gap between semantic alignment and structural fidelity without increasing computational complexity. It demonstrates a strong ability to generate semantically clear and structurally complete images, offering a viable technical path for joint text-image modeling and image generation.",
    "source": "arXiv"
  },
  {
    "title": "VIFSS: View-Invariant and Figure Skating-Specific Pose Representation Learning for Temporal Action Segmentation",
    "title_es": "VIFSS: View-Invariant and Figure Skating-Specific Pose Representation Learning for Temporal Action Segmentation",
    "url": "https://arxiv.org/abs/2508.10281",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10281v1 Announce Type: new \nAbstract: Understanding human actions from videos plays a critical role across various domains, including sports analytics. In figure skating, accurately recognizing the type and timing of jumps a skater performs is essential for objective performance evaluation. However, this task typically requires expert-level knowledge due to the fine-grained and complex nature of jump procedures. While recent approaches have attempted to automate this task using Temporal Action Segmentation (TAS), there are two major limitations to TAS for figure skating: the annotated data is insufficient, and existing methods do not account for the inherent three-dimensional aspects and procedural structure of jump actions. In this work, we propose a new TAS framework for figure skating jumps that explicitly incorporates both the three-dimensional nature and the semantic procedure of jump movements. First, we propose a novel View-Invariant, Figure Skating-Specific pose representation learning approach (VIFSS) that combines contrastive learning as pre-training and action classification as fine-tuning. For view-invariant contrastive pre-training, we construct FS-Jump3D, the first publicly available 3D pose dataset specialized for figure skating jumps. Second, we introduce a fine-grained annotation scheme that marks the ``entry (preparation)'' and ``landing'' phases, enabling TAS models to learn the procedural structure of jumps. Extensive experiments demonstrate the effectiveness of our framework. Our method achieves over 92% F1@50 on element-level TAS, which requires recognizing both jump types and rotation levels. Furthermore, we show that view-invariant contrastive pre-training is particularly effective when fine-tuning data is limited, highlighting the practicality of our approach in real-world scenarios.",
    "source": "arXiv"
  },
  {
    "title": "The Conditional Regret-Capacity Theorem for Batch Universal Prediction",
    "title_es": "The Conditional Regret-Capacity Theorem for Batch Universal Prediction",
    "url": "https://arxiv.org/abs/2508.10282",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10282v1 Announce Type: new \nAbstract: We derive a conditional version of the classical regret-capacity theorem. This result can be used in universal prediction to find lower bounds on the minimal batch regret, which is a recently introduced generalization of the average regret, when batches of training data are available to the predictor. As an example, we apply this result to the class of binary memoryless sources. Finally, we generalize the theorem to R\\'enyi information measures, revealing a deep connection between the conditional R\\'enyi divergence and the conditional Sibson's mutual information.",
    "source": "arXiv"
  },
  {
    "title": "Design of a Timer Queue Supporting Dynamic Update Operations",
    "title_es": "Design of a Timer Queue Supporting Dynamic Update Operations",
    "url": "https://arxiv.org/abs/2508.10283",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10283v1 Announce Type: new \nAbstract: Large-scale timers are ubiquitous in network processing, including flow table entry expiration control in software defined network (SDN) switches, MAC address aging in Ethernet bridges, and retransmission timeout management in TCP/IP protocols. Conventional implementations suffer from critical limitations: low timing accuracy due to large-scale timer traversal and high computational overhead for new timer insertion. This paper presents a hybrid-architecture hardware priority queue based on systolic arrays and shift registers for efficient timer queue management. The design uniquely supports five operations: enqueue, dequeue, delete, update, and peek.To the best of our knowledge, it is the first hardware priority queue enabling in-queue priority updates. By leveraging centralized Boolean logic encoding within systolic blocks, the design efficiently generates set/shift control signals while the novel push-first operation ensures FIFO ordering for same-priority timers without additional metadata. Experimental results demonstrate that the design operates at over 400 MHz on FPGAs, achieving a 2.2-2.8x reduction in resource consumption compared to state-of-the-art implementations.",
    "source": "arXiv"
  },
  {
    "title": "Uncertainty-Aware Prediction of Parkinson's Disease Medication Needs: A Two-Stage Conformal Prediction Approach",
    "title_es": "Uncertainty-Aware Prediction of Parkinson's Disease Medication Needs: A Two-Stage Conformal Prediction Approach",
    "url": "https://arxiv.org/abs/2508.10284",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10284v1 Announce Type: new \nAbstract: Parkinson's Disease (PD) medication management presents unique challenges due to heterogeneous disease progression and treatment response. Neurologists must balance symptom control with optimal dopaminergic dosing based on functional disability while minimizing side effects. This balance is crucial as inadequate or abrupt changes can cause levodopa-induced dyskinesia, wearing off, and neuropsychiatric effects, significantly reducing quality of life. Current approaches rely on trial-and-error decisions without systematic predictive methods. Despite machine learning advances, clinical adoption remains limited due to reliance on point predictions that do not account for prediction uncertainty, undermining clinical trust and utility. Clinicians require not only predictions of future medication needs but also reliable confidence measures. Without quantified uncertainty, adjustments risk premature escalation to maximum doses or prolonged inadequate symptom control. We developed a conformal prediction framework anticipating medication needs up to two years in advance with reliable prediction intervals and statistical guarantees. Our approach addresses zero-inflation in PD inpatient data, where patients maintain stable medication regimens between visits. Using electronic health records from 631 inpatient admissions at University of Florida Health (2011-2021), our two-stage approach identifies patients likely to need medication changes, then predicts required levodopa equivalent daily dose adjustments. Our framework achieved marginal coverage while reducing prediction interval lengths compared to traditional approaches, providing precise predictions for short-term planning and wider ranges for long-term forecasting. By quantifying uncertainty, our approach enables evidence-based decisions about levodopa dosing, optimizing symptom control while minimizing side effects and improving life quality.",
    "source": "arXiv"
  },
  {
    "title": "Artificial Emotion: A Survey of Theories and Debates on Realising Emotion in Artificial Intelligence",
    "title_es": "Artificial Emotion: A Survey of Theories and Debates on Realising Emotion in Artificial Intelligence",
    "url": "https://arxiv.org/abs/2508.10286",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10286v1 Announce Type: new \nAbstract: Affective Computing (AC) has enabled Artificial Intelligence (AI) systems to recognise, interpret, and respond to human emotions - a capability also known as Artificial Emotional Intelligence (AEI). It is increasingly seen as an important component of Artificial General Intelligence (AGI). We discuss whether in order to peruse this goal, AI benefits from moving beyond emotion recognition and synthesis to develop internal emotion-like states, which we term as Artificial Emotion (AE). This shift potentially allows AI to benefit from the paradigm of `inner emotions' in ways we - as humans - do. Although recent research shows early signs that AI systems may exhibit AE-like behaviours, a clear framework for how emotions can be realised in AI remains underexplored. In this paper, we discuss potential advantages of AE in AI, review current manifestations of AE in machine learning systems, examine emotion-modulated architectures, and summarise mechanisms for modelling and integrating AE into future AI. We also explore the ethical implications and safety risks associated with `emotional' AGI, while concluding with our opinion on how AE could be beneficial in the future.",
    "source": "arXiv"
  },
  {
    "title": "JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics",
    "title_es": "JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics",
    "url": "https://arxiv.org/abs/2508.10287",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10287v1 Announce Type: new \nAbstract: Recent advances in Vision-Language Models (VLMs) and large language models (LLMs) have greatly enhanced visual reasoning, a key capability for embodied AI agents like robots. However, existing visual reasoning benchmarks often suffer from several limitations: they lack a clear definition of reasoning complexity, offer have no control to generate questions over varying difficulty and task customization, and fail to provide structured, step-by-step reasoning annotations (workflows). To bridge these gaps, we formalize reasoning complexity, introduce an adaptive query engine that generates customizable questions of varying complexity with detailed intermediate annotations, and extend the JRDB dataset with human-object interaction and geometric relationship annotations to create JRDB-Reasoning, a benchmark tailored for visual reasoning in human-crowded environments. Our engine and benchmark enable fine-grained evaluation of visual reasoning frameworks and dynamic assessment of visual-language models across reasoning levels.",
    "source": "arXiv"
  },
  {
    "title": "Influence Maximization in Multi-layer Social Networks Based on Differentiated Graph Embeddings",
    "title_es": "Influence Maximization in Multi-layer Social Networks Based on Differentiated Graph Embeddings",
    "url": "https://arxiv.org/abs/2508.10289",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10289v1 Announce Type: new \nAbstract: Identifying influential nodes is crucial in social network analysis. Existing methods often neglect local opinion leader tendencies, resulting in overlapping influence ranges for seed nodes. Furthermore, approaches based on vanilla graph neural networks (GNNs) struggle to effectively aggregate influence characteristics during message passing, particularly with varying influence intensities. Current techniques also fail to adequately address the multi-layer nature of social networks and node heterogeneity. To address these issues, this paper proposes Inf-MDE, a novel multi-layer influence maximization method leveraging differentiated graph embedding. Inf-MDE models social relationships using a multi-layer network structure. The model extracts a self-influence propagation subgraph to eliminate the representation bias between node embeddings and propagation dynamics. Additionally, Inf-MDE incorporates an adaptive local influence aggregation mechanism within its GNN design. This mechanism dynamically adjusts influence feature aggregation during message passing based on local context and influence intensity, enabling it to effectively capture both inter-layer propagation heterogeneity and intra-layer diffusion dynamics. Extensive experiments across four distinct multi-layer social network datasets demonstrate that Inf-MDE significantly outperforms state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "Energy-Efficient Index and Code Index Modulations for Spread CPM Signals in Internet of Things",
    "title_es": "Energy-Efficient Index and Code Index Modulations for Spread CPM Signals in Internet of Things",
    "url": "https://arxiv.org/abs/2508.10290",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10290v1 Announce Type: new \nAbstract: The evolution of Internet of Things technologies is driven by four key demands: ultra-low power consumption, high spectral efficiency, reduced implementation cost, and support for massive connectivity. To address these challenges, this paper proposes two novel modulation schemes that integrate continuous phase modulation (CPM) with spread spectrum (SS) techniques. We begin by establishing the quasi-orthogonality properties of CPM-SS sequences. The first scheme, termed IM-CPM-SS, employs index modulation (IM) to select spreading sequences from the CPM-SS set, thereby improving spectral efficiency while maintaining the constant-envelope property. The second scheme, referred to as CIM-CPM-SS, introduces code index modulation (CIM), which partitions the input bits such that one subset is mapped to phase-shift keying symbols and the other to CPM-SS sequence indices. Both schemes are applied to downlink non-orthogonal multiple access (NOMA) systems. We analyze their performance in terms of bit error rate (BER), spectral and energy efficiency, computational complexity, and peak-to-average power ratio characteristics under nonlinear amplifier conditions. Simulation results demonstrate that both schemes outperform conventional approaches in BER while preserving the benefits of constant-envelope, continuous-phase signaling. Furthermore, they achieve higher spectral and energy efficiency and exhibit strong resilience to nonlinear distortions in downlink NOMA scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Promoting Efficient Reasoning with Verifiable Stepwise Reward",
    "title_es": "Promoting Efficient Reasoning with Verifiable Stepwise Reward",
    "url": "https://arxiv.org/abs/2508.10293",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10293v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) have recently achieved significant progress in complex reasoning tasks, aided by reinforcement learning with verifiable rewards. However, LRMs often suffer from overthinking, expending excessive computation on simple problems and reducing efficiency. Existing efficient reasoning methods typically require accurate task assessment to preset token budgets or select reasoning modes, which limits their flexibility and reliability. In this work, we revisit the essence of overthinking and identify that encouraging effective steps while penalizing ineffective ones is key to its solution. To this end, we propose a novel rule-based verifiable stepwise reward mechanism (VSRM), which assigns rewards based on the performance of intermediate states in the reasoning trajectory. This approach is intuitive and naturally fits the step-by-step nature of reasoning tasks. We conduct extensive experiments on standard mathematical reasoning benchmarks, including AIME24 and AIME25, by integrating VSRM with PPO and Reinforce++. Results show that our method achieves substantial output length reduction while maintaining original reasoning performance, striking an optimal balance between efficiency and accuracy. Further analysis of overthinking frequency and pass@k score before and after training demonstrates that our approach in deed effectively suppresses ineffective steps and encourages effective reasoning, fundamentally alleviating the overthinking problem. All code will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "A Sub-Pixel Multimodal Optical Remote Sensing Images Matching Method",
    "title_es": "A Sub-Pixel Multimodal Optical Remote Sensing Images Matching Method",
    "url": "https://arxiv.org/abs/2508.10294",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10294v1 Announce Type: new \nAbstract: High-accuracy matching of multimodal optical images is the basis of geometric processing. However, the image matching accuracy is usually degraded by the nonlinear radiation and geometric deformation differences caused by different spectral responses. To address these problems, we proposed a phase consistency weighted least absolute deviation (PCWLAD) sub-pixel template matching method to improve the matching accuracy of multimodal optical images. This method consists of two main steps: coarse matching with the structural similarity index measure (SSIM) and fine matching with WLAD. In the coarse matching step, PCs are calculated without a noise filter to preserve the original structural details, and template matching is performed using the SSIM. In the fine matching step, we applied the radiometric and geometric transformation models between two multimodal PC templates based on the coarse matching. Furthermore, mutual structure filtering is adopted in the model to mitigate the impact of noise within the corresponding templates on the structural consistency, and the WLAD criterion is used to estimate the sub-pixel offset. To evaluate the performance of PCWLAD, we created three types of image datasets: visible to infrared Landsat images, visible to near-infrared close-range images, and visible to infrared uncrewed aerial vehicle (UAV) images. PCWLAD outperformed existing state-of-the-art eight methods in terms of correct matching rate (CMR) and root mean square error (RMSE) and reached an average matching accuracy of approximately 0.4 pixels across all three datasets. Our software and datasets are publicly available at https://github.com/huangtaocsu/PCWLAD.",
    "source": "arXiv"
  },
  {
    "title": "Inductive Bias Extraction and Matching for LLM Prompts",
    "title_es": "Inductive Bias Extraction and Matching for LLM Prompts",
    "url": "https://arxiv.org/abs/2508.10295",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10295v1 Announce Type: new \nAbstract: The active research topic of prompt engineering makes it evident that LLMs are sensitive to small changes in prompt wording. A portion of this can be ascribed to the inductive bias that is present in the LLM. By using an LLM's output as a portion of its prompt, we can more easily create satisfactory wording for prompts. This has the effect of creating a prompt that matches the inductive bias in model. Empirically, we show that using this Inductive Bias Extraction and Matching strategy improves LLM Likert ratings used for classification by up to 19% and LLM Likert ratings used for ranking by up to 27%.",
    "source": "arXiv"
  },
  {
    "title": "InterSyn: Interleaved Learning for Dynamic Motion Synthesis in the Wild",
    "title_es": "InterSyn: Interleaved Learning for Dynamic Motion Synthesis in the Wild",
    "url": "https://arxiv.org/abs/2508.10297",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10297v1 Announce Type: new \nAbstract: We present Interleaved Learning for Motion Synthesis (InterSyn), a novel framework that targets the generation of realistic interaction motions by learning from integrated motions that consider both solo and multi-person dynamics. Unlike previous methods that treat these components separately, InterSyn employs an interleaved learning strategy to capture the natural, dynamic interactions and nuanced coordination inherent in real-world scenarios. Our framework comprises two key modules: the Interleaved Interaction Synthesis (INS) module, which jointly models solo and interactive behaviors in a unified paradigm from a first-person perspective to support multiple character interactions, and the Relative Coordination Refinement (REC) module, which refines mutual dynamics and ensures synchronized motions among characters. Experimental results show that the motion sequences generated by InterSyn exhibit higher text-to-motion alignment and improved diversity compared with recent methods, setting a new benchmark for robust and natural motion synthesis. Additionally, our code will be open-sourced in the future to promote further research and development in this area.",
    "source": "arXiv"
  },
  {
    "title": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning",
    "title_es": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning",
    "url": "https://arxiv.org/abs/2508.10298",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10298v1 Announce Type: new \nAbstract: Deciphering how visual stimuli are transformed into cortical responses is a fundamental challenge in computational neuroscience. This visual-to-neural mapping is inherently a one-to-many relationship, as identical visual inputs reliably evoke variable hemodynamic responses across trials, contexts, and subjects. However, existing deterministic methods struggle to simultaneously model this biological variability while capturing the underlying functional consistency that encodes stimulus information. To address these limitations, we propose SynBrain, a generative framework that simulates the transformation from visual semantics to neural responses in a probabilistic and biologically interpretable manner. SynBrain introduces two key components: (i) BrainVAE models neural representations as continuous probability distributions via probabilistic learning while maintaining functional consistency through visual semantic constraints; (ii) A Semantic-to-Neural Mapper acts as a semantic transmission pathway, projecting visual semantics into the neural response manifold to facilitate high-fidelity fMRI synthesis. Experimental results demonstrate that SynBrain surpasses state-of-the-art methods in subject-specific visual-to-fMRI encoding performance. Furthermore, SynBrain adapts efficiently to new subjects with few-shot data and synthesizes high-quality fMRI signals that are effective in improving data-limited fMRI-to-image decoding performance. Beyond that, SynBrain reveals functional consistency across trials and subjects, with synthesized signals capturing interpretable patterns shaped by biological neural variability. The code will be made publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning",
    "title_es": "Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning",
    "url": "https://arxiv.org/abs/2508.10299",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10299v1 Announce Type: new \nAbstract: In healthcare, federated learning (FL) is a widely adopted framework that enables privacy-preserving collaboration among medical institutions. With large foundation models (FMs) demonstrating impressive capabilities, using FMs in FL through cost-efficient adapter tuning has become a popular approach. Given the rapidly evolving healthcare environment, it is crucial for individual clients to quickly adapt to new tasks or diseases by tuning adapters while drawing upon past experiences. In this work, we introduce Federated Knowledge-Enhanced Initialization (FedKEI), a novel framework that leverages cross-client and cross-task transfer from past knowledge to generate informed initializations for learning new tasks with adapters. FedKEI begins with a global clustering process at the server to generalize knowledge across tasks, followed by the optimization of aggregation weights across clusters (inter-cluster weights) and within each cluster (intra-cluster weights) to personalize knowledge transfer for each new task. To facilitate more effective learning of the inter- and intra-cluster weights, we adopt a bi-level optimization scheme that collaboratively learns the global intra-cluster weights across clients and optimizes the local inter-cluster weights toward each client's task objective. Extensive experiments on three benchmark datasets of different modalities, including dermatology, chest X-rays, and retinal OCT, demonstrate FedKEI's advantage in adapting to new diseases compared to state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "DiffAxE: Diffusion-driven Hardware Accelerator Generation and Design Space Exploration",
    "title_es": "DiffAxE: Diffusion-driven Hardware Accelerator Generation and Design Space Exploration",
    "url": "https://arxiv.org/abs/2508.10303",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10303v1 Announce Type: new \nAbstract: Design space exploration (DSE) is critical for developing optimized hardware architectures, especially for AI workloads such as deep neural networks (DNNs) and large language models (LLMs), which require specialized acceleration. As model complexity grows, accelerator design spaces have expanded to O(10^17), becoming highly irregular, non-convex, and exhibiting many-to-one mappings from design configurations to performance metrics. This complexity renders direct inverse derivation infeasible and necessitates heuristic or sampling-based optimization. Conventional methods - including Bayesian optimization, gradient descent, reinforcement learning, and genetic algorithms - depend on iterative sampling, resulting in long runtimes and sensitivity to initialization. Deep learning-based approaches have reframed DSE as classification using recommendation models, but remain limited to small-scale (O(10^3)), less complex design spaces. To overcome these constraints, we propose a generative approach that models hardware design as 1-D image synthesis conditioned on target performance, enabling efficient learning of non-differentiable, non-bijective hardware-performance mappings. Our framework achieves 0.86% lower generation error than Bayesian optimization with a 17000x speedup, and outperforms GANDSE with 30% lower error at only 1.83x slower search. We further extend the method to a structured DSE setting, attaining 9.8% lower energy-delay product (EDP) and 6% higher performance, with up to 145.6x and 1312x faster search compared to existing optimization methods on O(10^17) design spaces. For LLM inference, our method achieves 3.37x and 7.75x lower EDP on a 32nm ASIC and Xilinx Ultrascale+ VPU13 FPGA, respectively, compared to the state-of-the-art DOSA framework.",
    "source": "arXiv"
  },
  {
    "title": "Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race",
    "title_es": "Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race",
    "url": "https://arxiv.org/abs/2508.10304",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10304v1 Announce Type: new \nAbstract: With the advance of Artificial Intelligence (AI), Large Language Models (LLMs) have gained prominence and been applied in diverse contexts. As they evolve into more sophisticated versions, it is essential to assess whether they reproduce biases, such as discrimination and racialization, while maintaining hegemonic discourses. Current bias detection approaches rely mostly on quantitative, automated methods, which often overlook the nuanced ways in which biases emerge in natural language. This study proposes a qualitative, discursive framework to complement such methods. Through manual analysis of LLM-generated short stories featuring Black and white women, we investigate gender and racial biases. We contend that qualitative methods such as the one proposed here are fundamental to help both developers and users identify the precise ways in which biases manifest in LLM outputs, thus enabling better conditions to mitigate them. Results show that Black women are portrayed as tied to ancestry and resistance, while white women appear in self-discovery processes. These patterns reflect how language models replicate crystalized discursive representations, reinforcing essentialization and a sense of social immobility. When prompted to correct biases, models offered superficial revisions that maintained problematic meanings, revealing limitations in fostering inclusive narratives. Our results demonstrate the ideological functioning of algorithms and have significant implications for the ethical use and development of AI. The study reinforces the need for critical, interdisciplinary approaches to AI design and deployment, addressing how LLM-generated discourses reflect and perpetuate inequalities.",
    "source": "arXiv"
  },
  {
    "title": "GPZ: GPU-Accelerated Lossy Compressor for Particle Data",
    "title_es": "GPZ: GPU-Accelerated Lossy Compressor for Particle Data",
    "url": "https://arxiv.org/abs/2508.10305",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10305v1 Announce Type: new \nAbstract: Particle-based simulations and point-cloud applications generate massive, irregular datasets that challenge storage, I/O, and real-time analytics. Traditional compression techniques struggle with irregular particle distributions and GPU architectural constraints, often resulting in limited throughput and suboptimal compression ratios. In this paper, we present GPZ, a high-performance, error-bounded lossy compressor designed specifically for large-scale particle data on modern GPUs. GPZ employs a novel four-stage parallel pipeline that synergistically balances high compression efficiency with the architectural demands of massively parallel hardware. We introduce a suite of targeted optimizations for computation, memory access, and GPU occupancy that enables GPZ to achieve near-hardware-limit throughput. We conduct an extensive evaluation on three distinct GPU architectures (workstation, data center, and edge) using six large-scale, real-world scientific datasets from five distinct domains. The results demonstrate that GPZ consistently and significantly outperforms five state-of-the-art GPU compressors, delivering up to 8x higher end-to-end throughput while simultaneously achieving superior compression ratios and data quality.",
    "source": "arXiv"
  },
  {
    "title": "ReviewRL: Towards Automated Scientific Review with RL",
    "title_es": "ReviewRL: Towards Automated Scientific Review with RL",
    "url": "https://arxiv.org/abs/2508.10308",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10308v1 Announce Type: new \nAbstract: Peer review is essential for scientific progress but faces growing challenges due to increasing submission volumes and reviewer fatigue. Existing automated review approaches struggle with factual accuracy, rating consistency, and analytical depth, often generating superficial or generic feedback lacking the insights characteristic of high-quality human reviews. We introduce ReviewRL, a reinforcement learning framework for generating comprehensive and factually grounded scientific paper reviews. Our approach combines: (1) an ArXiv-MCP retrieval-augmented context generation pipeline that incorporates relevant scientific literature, (2) supervised fine-tuning that establishes foundational reviewing capabilities, and (3) a reinforcement learning procedure with a composite reward function that jointly enhances review quality and rating accuracy. Experiments on ICLR 2025 papers demonstrate that ReviewRL significantly outperforms existing methods across both rule-based metrics and model-based quality assessments. ReviewRL establishes a foundational framework for RL-driven automatic critique generation in scientific discovery, demonstrating promising potential for future development in this domain. The implementation of ReviewRL will be released at GitHub.",
    "source": "arXiv"
  },
  {
    "title": "From Pixel to Mask: A Survey of Out-of-Distribution Segmentation",
    "title_es": "From Pixel to Mask: A Survey of Out-of-Distribution Segmentation",
    "url": "https://arxiv.org/abs/2508.10309",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10309v1 Announce Type: new \nAbstract: Out-of-distribution (OoD) detection and segmentation have attracted growing attention as concerns about AI security rise. Conventional OoD detection methods identify the existence of OoD objects but lack spatial localization, limiting their usefulness in downstream tasks. OoD segmentation addresses this limitation by localizing anomalous objects at pixel-level granularity. This capability is crucial for safety-critical applications such as autonomous driving, where perception modules must not only detect but also precisely segment OoD objects, enabling targeted control actions and enhancing overall system robustness. In this survey, we group current OoD segmentation approaches into four categories: (i) test-time OoD segmentation, (ii) outlier exposure for supervised training, (iii) reconstruction-based methods, (iv) and approaches that leverage powerful models. We systematically review recent advances in OoD segmentation for autonomous-driving scenarios, identify emerging challenges, and discuss promising future research directions.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Self-Regulated Learning Processes: Unveiling Hidden Tactics in Generative AI-Assisted Writing",
    "title_es": "Beyond Self-Regulated Learning Processes: Unveiling Hidden Tactics in Generative AI-Assisted Writing",
    "url": "https://arxiv.org/abs/2508.10310",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10310v1 Announce Type: new \nAbstract: The integration of Generative AI (GenAI) into education is reshaping how students learn, making self-regulated learning (SRL) - the ability to plan, monitor, and adapt one's learning - more important than ever. To support learners in these new contexts, it is essential to understand how SRL unfolds during interaction with GenAI tools. Learning analytics offers powerful techniques for analyzing digital trace data to infer SRL behaviors. However, existing approaches often assume SRL processes are linear, segmented, and non-overlapping-assumptions that overlook the dynamic, recursive, and non-linear nature of real-world learning. We address this by conceptualizing SRL as a layered system: observable learning patterns reflect hidden tactics (short, purposeful action states), which combine into broader SRL strategies. Using Hidden Markov Models (HMMs), we analyzed trace data from higher education students engaged in GenAI-assisted academic writing. We identified three distinct groups of learners, each characterized by different SRL strategies. These groups showed significant differences in performance, indicating that students' use of different SRL strategies in GenAI-assisted writing led to varying task outcomes. Our findings advance the methodological toolkit for modeling SRL and inform the design of adaptive learning technologies that more effectively support learners in GenAI-enhanced educational environments.",
    "source": "arXiv"
  },
  {
    "title": "From Surface to Semantics: Semantic Structure Parsing for Table-Centric Document Analysis",
    "title_es": "From Surface to Semantics: Semantic Structure Parsing for Table-Centric Document Analysis",
    "url": "https://arxiv.org/abs/2508.10311",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10311v1 Announce Type: new \nAbstract: Documents are core carriers of information and knowl-edge, with broad applications in finance, healthcare, and scientific research. Tables, as the main medium for structured data, encapsulate key information and are among the most critical document components. Existing studies largely focus on surface-level tasks such as layout analysis, table detection, and data extraction, lacking deep semantic parsing of tables and their contextual associations. This limits advanced tasks like cross-paragraph data interpretation and context-consistent analysis. To address this, we propose DOTABLER, a table-centric semantic document parsing framework designed to uncover deep semantic links between tables and their context. DOTABLER leverages a custom dataset and domain-specific fine-tuning of pre-trained models, integrating a complete parsing pipeline to identify context segments semantically tied to tables. Built on this semantic understanding, DOTABLER implements two core functionalities: table-centric document structure parsing and domain-specific table retrieval, delivering comprehensive table-anchored semantic analysis and precise extraction of semantically relevant tables. Evaluated on nearly 4,000 pages with over 1,000 tables from real-world PDFs, DOTABLER achieves over 90% Precision and F1 scores, demonstrating superior performance in table-context semantic analysis and deep document parsing compared to advanced models such as GPT-4o.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Semantic Understanding: Preserving Collaborative Frequency Components in LLM-based Recommendation",
    "title_es": "Beyond Semantic Understanding: Preserving Collaborative Frequency Components in LLM-based Recommendation",
    "url": "https://arxiv.org/abs/2508.10312",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10312v1 Announce Type: new \nAbstract: Recommender systems in concert with Large Language Models (LLMs) present promising avenues for generating semantically-informed recommendations. However, LLM-based recommenders exhibit a tendency to overemphasize semantic correlations within users' interaction history. When taking pretrained collaborative ID embeddings as input, LLM-based recommenders progressively weaken the inherent collaborative signals as the embeddings propagate through LLM backbones layer by layer, as opposed to traditional Transformer-based sequential models in which collaborative signals are typically preserved or even enhanced for state-of-the-art performance. To address this limitation, we introduce FreLLM4Rec, an approach designed to balance semantic and collaborative information from a spectral perspective. Item embeddings that incorporate both semantic and collaborative information are first purified using a Global Graph Low-Pass Filter (G-LPF) to preliminarily remove irrelevant high-frequency noise. Temporal Frequency Modulation (TFM) then actively preserves collaborative signal layer by layer. Note that the collaborative preservation capability of TFM is theoretically guaranteed by establishing a connection between the optimal but hard-to-implement local graph fourier filters and the suboptimal yet computationally efficient frequency-domain filters. Extensive experiments on four benchmark datasets demonstrate that FreLLM4Rec successfully mitigates collaborative signal attenuation and achieves competitive performance, with improvements of up to 8.00\\% in NDCG@10 over the best baseline. Our findings provide insights into how LLMs process collaborative information and offer a principled approach for improving LLM-based recommendation systems.",
    "source": "arXiv"
  },
  {
    "title": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning",
    "title_es": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning",
    "url": "https://arxiv.org/abs/2508.10315",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10315v1 Announce Type: new \nAbstract: Existing backdoor defense methods in Federated Learning (FL) rely on the assumption of homogeneous client data distributions or the availability of a clean serve dataset, which limits the practicality and effectiveness. Defending against backdoor attacks under heterogeneous client data distributions while preserving model performance remains a significant challenge. In this paper, we propose a FL backdoor defense framework named CLIP-Fed, which leverages the zero-shot learning capabilities of vision-language pre-training models. By integrating both pre-aggregation and post-aggregation defense strategies, CLIP-Fed overcomes the limitations of Non-IID imposed on defense effectiveness. To address privacy concerns and enhance the coverage of the dataset against diverse triggers, we construct and augment the server dataset using the multimodal large language model and frequency analysis without any client samples. To address class prototype deviations caused by backdoor samples and eliminate the correlation between trigger patterns and target labels, CLIP-Fed aligns the knowledge of the global model and CLIP on the augmented dataset using prototype contrastive loss and Kullback-Leibler divergence. Extensive experiments on representative datasets validate the effectiveness of CLIP-Fed. Compared to state-of-the-art methods, CLIP-Fed achieves an average reduction in ASR, i.e., 2.03\\% on CIFAR-10 and 1.35\\% on CIFAR-10-LT, while improving average MA by 7.92\\% and 0.48\\%, respectively.",
    "source": "arXiv"
  },
  {
    "title": "Integrating Reinforcement Learning with Visual Generative Models: Foundations and Advances",
    "title_es": "Integrating Reinforcement Learning with Visual Generative Models: Foundations and Advances",
    "url": "https://arxiv.org/abs/2508.10316",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10316v1 Announce Type: new \nAbstract: Generative models have made significant progress in synthesizing visual content, including images, videos, and 3D/4D structures. However, they are typically trained with surrogate objectives such as likelihood or reconstruction loss, which often misalign with perceptual quality, semantic accuracy, or physical realism. Reinforcement learning (RL) offers a principled framework for optimizing non-differentiable, preference-driven, and temporally structured objectives. Recent advances demonstrate its effectiveness in enhancing controllability, consistency, and human alignment across generative tasks. This survey provides a systematic overview of RL-based methods for visual content generation. We review the evolution of RL from classical control to its role as a general-purpose optimization tool, and examine its integration into image, video, and 3D/4D generation. Across these domains, RL serves not only as a fine-tuning mechanism but also as a structural component for aligning generation with complex, high-level goals. We conclude with open challenges and future research directions at the intersection of RL and generative modeling.",
    "source": "arXiv"
  },
  {
    "title": "Integrated Communication and Remote Sensing in LEO Satellite Systems: Protocol, Architecture and Prototype",
    "title_es": "Integrated Communication and Remote Sensing in LEO Satellite Systems: Protocol, Architecture and Prototype",
    "url": "https://arxiv.org/abs/2508.10317",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10317v1 Announce Type: new \nAbstract: In this paper, we explore the integration of communication and synthetic aperture radar (SAR)-based remote sensing in low Earth orbit (LEO) satellite systems to provide real-time SAR imaging and information transmission. Considering the high-mobility characteristics of satellite channels and limited processing capabilities of satellite payloads, we propose an integrated communication and remote sensing architecture based on an orthogonal delay-Doppler division multiplexing (ODDM) signal waveform. Both communication and SAR imaging functionalities are achieved with an integrated transceiver onboard the LEO satellite, utilizing the same waveform and radio frequency (RF) front-end. Based on such an architecture, we propose a transmission protocol compatible with the 5G NR standard using downlink pilots for joint channel estimation and SAR imaging. Furthermore, we design a unified signal processing framework for the integrated satellite receiver to simultaneously achieve high-performance channel sensing, low-complexity channel equalization and interference-free SAR imaging. Finally, the performance of the proposed integrated system is demonstrated through comprehensive analysis and extensive simulations in the sub-6 GHz band. Moreover, a software-defined radio (SDR) prototype is presented to validate its effectiveness for real-time SAR imaging and information transmission in satellite direct-connect user equipment (UE) scenarios within the millimeter-wave (mmWave) band.",
    "source": "arXiv"
  },
  {
    "title": "Quantifying the Value of Seismic Structural Health Monitoring for post-earthquake recovery of electric power system in terms of resilience enhancement",
    "title_es": "Quantifying the Value of Seismic Structural Health Monitoring for post-earthquake recovery of electric power system in terms of resilience enhancement",
    "url": "https://arxiv.org/abs/2508.10318",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10318v1 Announce Type: new \nAbstract: Post-earthquake recovery of electric power networks (EPNs) is critical to community resilience. Traditional recovery processes often rely on prolonged and imprecise manual inspections for damage diagnosis, leading to suboptimal repair prioritization and extended service disruptions. Seismic Structural Health Monitoring (SSHM) offers the potential to expedite recovery by enabling more accurate and timely damage assessment. However, SSHM deployment incurs costs, and its system-level resilience benefit remains underexplored. This study proposes a probabilistic simulation framework to quantify the value of SSHM for enhancing EPN resilience. The framework includes seismic damage modeling based on network configuration, hazard intensity, fragility functions, and damage-functionality mappings, combined with recovery simulations incorporating resource constraints, repair and transfer durations. System functionality is evaluated using graph-based island detection and optimal power flow analysis. Resilience is quantified via the Lack of Resilience (LoR) metric derived from the functionality restoration curve. SSHM is incorporated by altering the quality of damage information used in repair scheduling. Different monitoring scenarios (e.g., no-SSHM baseline, partial SSHM, full SSHM with various accuracies) are modeled using confusion matrices to simulate damage misclassification. Results show that improved damage awareness via SSHM significantly accelerates recovery and reduces LoR by up to 21%. This work supports evidence-based decisions for SSHM deployment in critical infrastructure.",
    "source": "arXiv"
  },
  {
    "title": "TOBACO: Topology Optimization via Band-limited Coordinate Networks for Compositionally Graded Alloys",
    "title_es": "TOBACO: Topology Optimization via Band-limited Coordinate Networks for Compositionally Graded Alloys",
    "url": "https://arxiv.org/abs/2508.10320",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10320v1 Announce Type: new \nAbstract: Compositionally Graded Alloys (CGAs) offer unprecedented design flexibility by enabling spatial variations in composition; tailoring material properties to local loading conditions. This flexibility leads to components that are stronger, lighter, and more cost-effective than traditional monolithic counterparts. The fabrication of CGAs have become increasingly feasible owing to recent advancements in additive manufacturing (AM), particularly in multi-material printing and improved precision in material deposition. However, AM of CGAs requires imposition of manufacturing constraints; in particular limits on the maximum spatial gradation of composition.\n  This paper introduces a topology optimization (TO) based framework for designing optimized CGA components with controlled compositional gradation. In particular, we represent the constrained composition distribution using a band-limited coordinate neural network. By regulating the network's bandwidth, we ensure implicit compliance with gradation limits, eliminating the need for explicit constraints. The proposed approach also benefits from the inherent advantages of TO using coordinate networks, including mesh independence, high-resolution design extraction, and end-to-end differentiability. The effectiveness of our framework is demonstrated through various elastic and thermo-elastic TO examples.",
    "source": "arXiv"
  },
  {
    "title": "SSBE-PINN: A Sobolev Boundary Scheme Boosting Stability and Accuracy in Elliptic/Parabolic PDE Learning",
    "title_es": "SSBE-PINN: A Sobolev Boundary Scheme Boosting Stability and Accuracy in Elliptic/Parabolic PDE Learning",
    "url": "https://arxiv.org/abs/2508.10322",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10322v1 Announce Type: new \nAbstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs), yet they often fail to achieve accurate convergence in the H1 norm, especially in the presence of boundary approximation errors. In this work, we propose a novel method called Sobolev-Stable Boundary Enforcement (SSBE), which redefines the boundary loss using Sobolev norms to incorporate boundary regularity directly into the training process. We provide rigorous theoretical analysis demonstrating that SSBE ensures bounded H1 error via a stability guarantee and derive generalization bounds that characterize its robustness under finite-sample regimes. Extensive numerical experiments on linear and nonlinear PDEs, including Poisson, heat, and elliptic problems, show that SSBE consistently outperforms standard PINNs in terms of both relative L2 and H1 errors, even in high-dimensional settings. The proposed approach offers a principled and practical solution for improving gradient fidelity and overall solution accuracy in neural network based PDE solvers.",
    "source": "arXiv"
  },
  {
    "title": "BERTector: Intrusion Detection Based on Joint-Dataset Learning",
    "title_es": "BERTector: Intrusion Detection Based on Joint-Dataset Learning",
    "url": "https://arxiv.org/abs/2508.10327",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10327v1 Announce Type: new \nAbstract: Intrusion detection systems (IDS) are facing challenges in generalization and robustness due to the heterogeneity of network traffic and the diversity of attack patterns. To address this issue, we propose a new joint-dataset training paradigm for IDS and propose a scalable BERTector framework based on BERT. BERTector integrates three key components: NSS-Tokenizer for traffic-aware semantic tokenization, supervised fine-tuning with a hybrid dataset, and low-rank adaptation (LoRA) for efficient training. Extensive experiments show that BERTector achieves state-of-the-art detection accuracy, strong cross-dataset generalization capabilities, and excellent robustness to adversarial perturbations. This work establishes a unified and efficient solution for modern IDS in complex and dynamic network environments.",
    "source": "arXiv"
  },
  {
    "title": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver",
    "title_es": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver",
    "url": "https://arxiv.org/abs/2508.10333",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10333v1 Announce Type: new \nAbstract: Recent advances in Vision-Language-Action (VLA) models have enabled robotic agents to integrate multimodal understanding with action execution. However, our empirical analysis reveals that current VLAs struggle to allocate visual attention to target regions. Instead, visual attention is always dispersed. To guide the visual attention grounding on the correct target, we propose ReconVLA, a reconstructive VLA model with an implicit grounding paradigm. Conditioned on the model's visual outputs, a diffusion transformer aims to reconstruct the gaze region of the image, which corresponds to the target manipulated objects. This process prompts the VLA model to learn fine-grained representations and accurately allocate visual attention, thus effectively leveraging task-specific visual information and conducting precise manipulation. Moreover, we curate a large-scale pretraining dataset comprising over 100k trajectories and 2 million data samples from open-source robotic datasets, further boosting the model's generalization in visual reconstruction. Extensive experiments in simulation and the real world demonstrate the superiority of our implicit grounding method, showcasing its capabilities of precise manipulation and generalization. Our project page is https://zionchow.github.io/ReconVLA/.",
    "source": "arXiv"
  },
  {
    "title": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering",
    "title_es": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering",
    "url": "https://arxiv.org/abs/2508.10337",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10337v1 Announce Type: new \nAbstract: This paper describes the solutions of the Dianping-Trust-Safety team for the META CRAG-MM challenge. The challenge requires building a comprehensive retrieval-augmented generation system capable for multi-modal multi-turn question answering. The competition consists of three tasks: (1) answering questions using structured data retrieved from an image-based mock knowledge graph, (2) synthesizing information from both knowledge graphs and web search results, and (3) handling multi-turn conversations that require context understanding and information aggregation from multiple sources. For Task 1, our solution is based on the vision large language model, enhanced by supervised fine-tuning with knowledge distilled from GPT-4.1. We further applied curriculum learning strategies to guide reinforcement learning, resulting in improved answer accuracy and reduced hallucination. For Task 2 and Task 3, we additionally leveraged web search APIs to incorporate external knowledge, enabling the system to better handle complex queries and multi-turn conversations. Our approach achieved 1st place in Task 1 with a significant lead of 52.38\\%, and 3rd place in Task 3, demonstrating the effectiveness of the integration of curriculum learning with reinforcement learning in our training pipeline.",
    "source": "arXiv"
  },
  {
    "title": "Near-realtime Earth Observation Via Starlink LEO Satellite Constellation",
    "title_es": "Near-realtime Earth Observation Via Starlink LEO Satellite Constellation",
    "url": "https://arxiv.org/abs/2508.10338",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10338v1 Announce Type: new \nAbstract: Earth observation (EO) satellites in Low Earth Orbit (LEO) are collecting vast amounts of data, which are invaluable for applications such as monitoring forest fires. However, data downloading from EO satellites faces significant challenges due to the limited number of ground stations and the brief communication windows with them. Conversely, emerging LEO constellations like Starlink have enabled continuous connectivity and revolutionized access for ordinary users globally, who can connect via a simple satellite dish. In this paper, we study the feasibility of supporting EO satellites with Starlink satellite infrastructure and introduce a novel data delivery system, designated as \"Starlink Space User\" (SSU), for relaying data from observation satellites. SSU treats EO satellites as space users of Starlink, facilitating efficient data transfer to Earth. At the core of SSU is a novel class of algorithms designed for link and PoP selection, as well as system scheduling optimization, that operate effectively atop Starlink's proprietary infrastructure. We assess the performance of SSU using trace-driven simulations alongside real-world Starlink performance measurements. Our results demonstrate that the proposed Starlink-aided design can significantly reduce the median backlog (data not delivered) per satellite.",
    "source": "arXiv"
  },
  {
    "title": "Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models",
    "title_es": "Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models",
    "url": "https://arxiv.org/abs/2508.10339",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10339v1 Announce Type: new \nAbstract: Vision-language instruction tuning achieves two main purposes: learning visual concepts and learning visual skills. In this paper, we found that vision-language benchmarks fall into the dichotomy of mainly benefiting from training on instructions with similar skills or visual concepts. Inspired by the discovery, we designed a simple targeted training data selection method to optimize the performance of a given benchmark. We first extract the concepts/skills from the benchmark, determine whether the benchmark predominantly benefits from similar concepts or skills, and finally select instructions with the most matching concepts/skills. Experiments on 10+ benchmarks validate the effectiveness of our targeted data selection method, showing +0.9\\% over the best existing baseline averaged over all benchmarks and +1.5\\% on the skill-focused subset. Our findings underscore the importance of recognizing the inherent trade-off within instruction selection, which requires balancing the acquisition of conceptual knowledge against visual skill.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach",
    "title_es": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach",
    "url": "https://arxiv.org/abs/2508.10340",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10340v1 Announce Type: new \nAbstract: Multi-agent reinforcement learning (MARL) requires coordinated and stable policy updates among interacting agents. Heterogeneous-Agent Trust Region Policy Optimization (HATRPO) enforces per-agent trust region constraints using Kullback-Leibler (KL) divergence to stabilize training. However, assigning each agent the same KL threshold can lead to slow and locally optimal updates, especially in heterogeneous settings. To address this limitation, we propose two approaches for allocating the KL divergence threshold across agents: HATRPO-W, a Karush-Kuhn-Tucker-based (KKT-based) method that optimizes threshold assignment under global KL constraints, and HATRPO-G, a greedy algorithm that prioritizes agents based on improvement-to-divergence ratio. By connecting sequential policy optimization with constrained threshold scheduling, our approach enables more flexible and effective learning in heterogeneous-agent settings. Experimental results demonstrate that our methods significantly boost the performance of HATRPO, achieving faster convergence and higher final rewards across diverse MARL benchmarks. Specifically, HATRPO-W and HATRPO-G achieve comparable improvements in final performance, each exceeding 22.5%. Notably, HATRPO-W also demonstrates more stable learning dynamics, as reflected by its lower variance.",
    "source": "arXiv"
  },
  {
    "title": "A Semi-Lagrangian scheme on embedded manifolds using generalized local polynomial reproductions",
    "title_es": "A Semi-Lagrangian scheme on embedded manifolds using generalized local polynomial reproductions",
    "url": "https://arxiv.org/abs/2508.10344",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10344v1 Announce Type: new \nAbstract: We analyze rates of uniform convergence for a class of high-order semi-Lagrangian schemes for first-order, time-dependent partial differential equations on embedded submanifolds of $\\mathbb{R}^d$ (including advection equations on surfaces) by extending the error analysis of Falcone and Ferretti. A central requirement in our analysis is a remapping operator that achieves both high approximation orders and strong stability, a combination that is challenging to obtain and of independent interest. For this task, we propose a novel mesh-free remapping operator based on $\\ell_1$ minimizing generalized polynomial reproduction, which uses only point values and requires no additional geometric information from the manifold (such as access to tangent spaces or curvature). Our framework also rigorously addresses the numerical solution of ordinary differential equations on manifolds via projection methods. We include numerical experiments that support the theoretical results and also suggest some new directions for future research.",
    "source": "arXiv"
  },
  {
    "title": "Welfare-Centric Clustering",
    "title_es": "Welfare-Centric Clustering",
    "url": "https://arxiv.org/abs/2508.10345",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10345v1 Announce Type: new \nAbstract: Fair clustering has traditionally focused on ensuring equitable group representation or equalizing group-specific clustering costs. However, Dickerson et al. (2025) recently showed that these fairness notions may yield undesirable or unintuitive clustering outcomes and advocated for a welfare-centric clustering approach that models the utilities of the groups. In this work, we model group utilities based on both distances and proportional representation and formalize two optimization objectives based on welfare-centric clustering: the Rawlsian (Egalitarian) objective and the Utilitarian objective. We introduce novel algorithms for both objectives and prove theoretical guarantees for them. Empirical evaluations on multiple real-world datasets demonstrate that our methods significantly outperform existing fair clustering baselines.",
    "source": "arXiv"
  },
  {
    "title": "A Hierarchical IDS for Zero-Day Attack Detection in Internet of Medical Things Networks",
    "title_es": "A Hierarchical IDS for Zero-Day Attack Detection in Internet of Medical Things Networks",
    "url": "https://arxiv.org/abs/2508.10346",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10346v1 Announce Type: new \nAbstract: The Internet of Medical Things (IoMT) is driving a healthcare revolution but remains vulnerable to cyberattacks such as denial of service, ransomware, data hijacking, and spoofing. These networks comprise resource constrained, heterogeneous devices (e.g., wearable sensors, smart pills, implantables), making traditional centralized Intrusion Detection Systems (IDSs) unsuitable due to response delays, privacy risks, and added vulnerabilities. Centralized IDSs require all sensors to transmit data to a central server, causing delays or network disruptions in dense environments. Running IDSs locally on IoMT devices is often infeasible due to limited computation, and even lightweight IDS components remain at risk if updated models are delayed leaving them exposed to zero-day attacks that threaten patient health and data security. We propose a multi level IoMT IDS framework capable of detecting zero day attacks and distinguishing between known and unknown threats. The first layer (near Edge) filters traffic at a coarse level (attack or not) using meta-learning or One Class Classification (OCC) with the usfAD algorithm. Subsequent layers (far Edge, Cloud) identify attack type and novelty. Experiments on the CICIoMT2024 dataset show 99.77 percentage accuracy and 97.8 percentage F1-score. The first layer detects zero-day attacks with high accuracy without needing new datasets, ensuring strong applicability in IoMT environments. Additionally, the meta-learning approach achieves high.",
    "source": "arXiv"
  },
  {
    "title": "Flexible Personalized Split Federated Learning for On-Device Fine-Tuning of Foundation Models",
    "title_es": "Flexible Personalized Split Federated Learning for On-Device Fine-Tuning of Foundation Models",
    "url": "https://arxiv.org/abs/2508.10349",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10349v1 Announce Type: new \nAbstract: Fine-tuning foundation models is critical for superior performance on personalized downstream tasks, compared to using pre-trained models. Collaborative learning can leverage local clients' datasets for fine-tuning, but limited client data and heterogeneous data distributions hinder effective collaboration. To address the challenge, we propose a flexible personalized federated learning paradigm that enables clients to engage in collaborative learning while maintaining personalized objectives. Given the limited and heterogeneous computational resources available on clients, we introduce \\textbf{flexible personalized split federated learning (FlexP-SFL)}. Based on split learning, FlexP-SFL allows each client to train a portion of the model locally while offloading the rest to a server, according to resource constraints. Additionally, we propose an alignment strategy to improve personalized model performance on global data. Experimental results show that FlexP-SFL outperforms baseline models in personalized fine-tuning efficiency and final accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Semantic Communication with Distribution Learning through Sequential Observations",
    "title_es": "Semantic Communication with Distribution Learning through Sequential Observations",
    "url": "https://arxiv.org/abs/2508.10350",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10350v1 Announce Type: new \nAbstract: Semantic communication aims to convey meaning rather than bit-perfect reproduction, representing a paradigm shift from traditional communication. This paper investigates distribution learning in semantic communication where receivers must infer the underlying meaning distribution through sequential observations. While semantic communication traditionally optimizes individual meaning transmission, we establish fundamental conditions for learning source statistics when priors are unknown. We prove that learnability requires full rank of the effective transmission matrix, characterize the convergence rate of distribution estimation, and quantify how estimation errors translate to semantic distortion. Our analysis reveals a fundamental trade-off: encoding schemes optimized for immediate semantic performance often sacrifice long-term learnability. Experiments on CIFAR-10 validate our theoretical framework, demonstrating that system conditioning critically impacts both learning rate and achievable performance. These results provide the first rigorous characterization of statistical learning in semantic communication and offer design principles for systems that balance immediate performance with adaptation capability.",
    "source": "arXiv"
  },
  {
    "title": "Glo-DMU: A Deep Morphometry Framework of Ultrastructural Characterization in Glomerular Electron Microscopic Images",
    "title_es": "Glo-DMU: A Deep Morphometry Framework of Ultrastructural Characterization in Glomerular Electron Microscopic Images",
    "url": "https://arxiv.org/abs/2508.10351",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10351v1 Announce Type: new \nAbstract: Complex and diverse ultrastructural features can indicate the type, progression, and prognosis of kidney diseases. Recently, computational pathology combined with deep learning methods has shown tremendous potential in advancing automatic morphological analysis of glomerular ultrastructure. However, current research predominantly focuses on the recognition of individual ultrastructure, which makes it challenging to meet practical diagnostic needs. In this study, we propose the glomerular morphometry framework of ultrastructural characterization (Glo-DMU), which is grounded on three deep models: the ultrastructure segmentation model, the glomerular filtration barrier region classification model, and the electron-dense deposits detection model. Following the conventional protocol of renal biopsy diagnosis, this framework simultaneously quantifies the three most widely used ultrastructural features: the thickness of glomerular basement membrane, the degree of foot process effacement, and the location of electron-dense deposits. We evaluated the 115 patients with 9 renal pathological types in real-world diagnostic scenarios, demonstrating good consistency between automatic quantification results and morphological descriptions in the pathological reports. Glo-DMU possesses the characteristics of full automation, high precision, and high throughput, quantifying multiple ultrastructural features simultaneously, and providing an efficient tool for assisting renal pathologists.",
    "source": "arXiv"
  },
  {
    "title": "Cross-Prompt Encoder for Low-Performing Languages",
    "title_es": "Cross-Prompt Encoder for Low-Performing Languages",
    "url": "https://arxiv.org/abs/2508.10352",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10352v1 Announce Type: new \nAbstract: Soft prompts have emerged as a powerful alternative to adapters in parameter-efficient fine-tuning (PEFT), enabling large language models (LLMs) to adapt to downstream tasks without architectural changes or parameter updates. While prior work has focused on stabilizing training via parameter interaction in small neural prompt encoders, their broader potential for transfer across languages remains unexplored. In this paper, we demonstrate that a prompt encoder can play a central role in improving performance on low-performing languages-those that achieve poor accuracy even under full-model fine-tuning. We introduce the Cross-Prompt Encoder (XPE), which combines a lightweight encoding architecture with multi-source training on typologically diverse languages - a design that enables the model to capture abstract and transferable patterns across languages. To complement XPE, we propose a Dual Soft Prompt mechanism that combines an encoder-based prompt with a directly trained standard soft prompt. This hybrid design proves especially effective for target languages that benefit from both broadly shared structure and language-specific alignment. Experiments on the SIB-200 benchmark reveal a consistent trade-off: XPE is most effective for low-performing languages, while hybrid variants offer broader adaptability across multilingual settings.",
    "source": "arXiv"
  },
  {
    "title": "Mental Effort Estimation in Motion Exploration and Concept Generation Design Tasks using Inter-Band Relative Power Difference of EEG",
    "title_es": "Mental Effort Estimation in Motion Exploration and Concept Generation Design Tasks using Inter-Band Relative Power Difference of EEG",
    "url": "https://arxiv.org/abs/2508.10353",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10353v1 Announce Type: new \nAbstract: Conceptual design is a cognitively complex task, especially in the engineering design of products having relative motion between components. Designers prefer sketching as a medium for conceptual design and use gestures and annotations to represent such relative motion. Literature suggests that static representations of motion in sketches may not achieve the intended functionality when realised, because it primarily depends on the designers' mental capabilities for motion simulation. Thus, it is important to understand the cognitive phenomena when designers are exploring concepts of articulated products. The current work is an attempt to understand design neurocognition by categorising the tasks and measuring the mental effort involved in these tasks using EEG. The analysis is intended to validate design intervention tools to support the conceptual design involving motion exploration. A novel EEG-based metric, inter-Band Relative Power Difference (inter-BRPD), is introduced to quantify mental effort. A design experiment is conducted with 32 participants, where they have to perform one control task and 2 focus tasks corresponding to the motion exploration task (MET) and the concept generation task (CGT), respectively. EEG data is recorded during the 3 tasks, cleaned, processed and analysed using the MNE library in Python. It is observed from the results that inter-BRPD captures the essence of mental effort with half the number of conventionally used parameters. The reliability and efficacy of the inter-BRPD metric are also statistically validated against literature-based cognitive metrics. With these new insights, the study opens up possibilities for creating support for conceptual design and its evaluation.",
    "source": "arXiv"
  },
  {
    "title": "Making Qwen3 Think in Korean with Reinforcement Learning",
    "title_es": "Making Qwen3 Think in Korean with Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.10355",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10355v1 Announce Type: new \nAbstract: We present a two-stage fine-tuning approach to make the large language model Qwen3 14B \"think\" natively in Korean. In the first stage, supervised fine-tuning (SFT) on a high-quality Korean reasoning dataset establishes a strong foundation in Korean logical reasoning, yielding notable improvements in Korean-language tasks and even some gains in general reasoning ability. In the second stage, we employ reinforcement learning with a customized Group Relative Policy Optimization (GRPO) algorithm to further enhance both Korean reasoning alignment and overall problem-solving performance. We address critical stability challenges in GRPO training - such as reward hacking and policy collapse - by introducing an oracle judge model that calibrates the reward signal. Our approach achieves stable learning (avoiding the collapse observed in naive GRPO) and leads to steady, incremental performance gains. The final RL-tuned model demonstrates substantially improved results on advanced reasoning benchmarks (particularly math and coding tasks) while maintaining knowledge and language proficiency, successfully conducting its internal chain-of-thought entirely in Korean.",
    "source": "arXiv"
  },
  {
    "title": "Improving OCR for Historical Texts of Multiple Languages",
    "title_es": "Improving OCR for Historical Texts of Multiple Languages",
    "url": "https://arxiv.org/abs/2508.10356",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10356v1 Announce Type: new \nAbstract: This paper presents our methodology and findings from three tasks across Optical Character Recognition (OCR) and Document Layout Analysis using advanced deep learning techniques. First, for the historical Hebrew fragments of the Dead Sea Scrolls, we enhanced our dataset through extensive data augmentation and employed the Kraken and TrOCR models to improve character recognition. In our analysis of 16th to 18th-century meeting resolutions task, we utilized a Convolutional Recurrent Neural Network (CRNN) that integrated DeepLabV3+ for semantic segmentation with a Bidirectional LSTM, incorporating confidence-based pseudolabeling to refine our model. Finally, for modern English handwriting recognition task, we applied a CRNN with a ResNet34 encoder, trained using the Connectionist Temporal Classification (CTC) loss function to effectively capture sequential dependencies. This report offers valuable insights and suggests potential directions for future research.",
    "source": "arXiv"
  },
  {
    "title": "What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles",
    "title_es": "What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles",
    "url": "https://arxiv.org/abs/2508.10358",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10358v1 Announce Type: new \nAbstract: We investigate the capacity of Large Language Models (LLMs) for imaginative reasoning--the proactive construction, testing, and revision of hypotheses in information-sparse environments. Existing benchmarks, often static or focused on social deduction, fail to capture the dynamic, exploratory nature of this reasoning process. To address this gap, we introduce a comprehensive research framework based on the classic \"Turtle Soup\" game, integrating a benchmark, an agent, and an evaluation protocol. We present TurtleSoup-Bench, the first large-scale, bilingual, interactive benchmark for imaginative reasoning, comprising 800 turtle soup puzzles sourced from both the Internet and expert authors. We also propose Mosaic-Agent, a novel agent designed to assess LLMs' performance in this setting. To evaluate reasoning quality, we develop a multi-dimensional protocol measuring logical consistency, detail completion, and conclusion alignment. Experiments with leading LLMs reveal clear capability limits, common failure patterns, and a significant performance gap compared to humans. Our work offers new insights into LLMs' imaginative reasoning and establishes a foundation for future research on exploratory agent behavior.",
    "source": "arXiv"
  },
  {
    "title": "AtomDiffuser: Time-Aware Degradation Modeling for Drift and Beam Damage in STEM Imaging",
    "title_es": "AtomDiffuser: Time-Aware Degradation Modeling for Drift and Beam Damage in STEM Imaging",
    "url": "https://arxiv.org/abs/2508.10359",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10359v1 Announce Type: new \nAbstract: Scanning transmission electron microscopy (STEM) plays a critical role in modern materials science, enabling direct imaging of atomic structures and their evolution under external interferences. However, interpreting time-resolved STEM data remains challenging due to two entangled degradation effects: spatial drift caused by mechanical and thermal instabilities, and beam-induced signal loss resulting from radiation damage. These factors distort both geometry and intensity in complex, temporally correlated ways, making it difficult for existing methods to explicitly separate their effects or model material dynamics at atomic resolution. In this work, we present AtomDiffuser, a time-aware degradation modeling framework that disentangles sample drift and radiometric attenuation by predicting an affine transformation and a spatially varying decay map between any two STEM frames. Unlike traditional denoising or registration pipelines, our method leverages degradation as a physically heuristic, temporally conditioned process, enabling interpretable structural evolutions across time. Trained on synthetic degradation processes, AtomDiffuser also generalizes well to real-world cryo-STEM data. It further supports high-resolution degradation inference and drift alignment, offering tools for visualizing and quantifying degradation patterns that correlate with radiation-induced atomic instabilities.",
    "source": "arXiv"
  },
  {
    "title": "A dataset and model for recognition of audiologically relevant environments for hearing aids: AHEAD-DS and YAMNet+",
    "title_es": "A dataset and model for recognition of audiologically relevant environments for hearing aids: AHEAD-DS and YAMNet+",
    "url": "https://arxiv.org/abs/2508.10360",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10360v1 Announce Type: new \nAbstract: Scene recognition of audiologically relevant environments is important for hearing aids; however, it is challenging, in part because of the limitations of existing datasets. Datasets often lack public accessibility, completeness, or audiologically relevant labels, hindering systematic comparison of machine learning models. Deploying these models on resource-constrained edge devices presents another challenge. Our solution is two-fold: we leverage several open source datasets to create AHEAD-DS, a dataset designed for scene recognition of audiologically relevant environments, and introduce YAMNet+, a sound recognition model. AHEAD-DS aims to provide a standardised, publicly available dataset with consistent labels relevant to hearing aids, facilitating model comparison. YAMNet+ is designed for deployment on edge devices like smartphones connected to hearing devices, such as hearing aids and wireless earphones with hearing aid functionality; serving as a baseline model for sound-based scene recognition. YAMNet+ achieved a mean average precision of 0.83 and accuracy of 0.93 on the testing set of AHEAD-DS across fourteen categories of audiologically relevant environments. We found that applying transfer learning from the pretrained YAMNet model was essential. We demonstrated real-time sound-based scene recognition capabilities on edge devices by deploying YAMNet+ to an Android smartphone. Even with a Google Pixel 3 (a phone with modest specifications, released in 2018), the model processes audio with approximately 50ms of latency to load the model, and an approximate linear increase of 30ms per 1 second of audio. Our website and code https://github.com/Australian-Future-Hearing-Initiative .",
    "source": "arXiv"
  },
  {
    "title": "BEASST: Behavioral Entropic Gradient based Adaptive Source Seeking for Mobile Robots",
    "title_es": "BEASST: Behavioral Entropic Gradient based Adaptive Source Seeking for Mobile Robots",
    "url": "https://arxiv.org/abs/2508.10363",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10363v1 Announce Type: new \nAbstract: This paper presents BEASST (Behavioral Entropic Gradient-based Adaptive Source Seeking for Mobile Robots), a novel framework for robotic source seeking in complex, unknown environments. Our approach enables mobile robots to efficiently balance exploration and exploitation by modeling normalized signal strength as a surrogate probability of source location. Building on Behavioral Entropy(BE) with Prelec's probability weighting function, we define an objective function that adapts robot behavior from risk-averse to risk-seeking based on signal reliability and mission urgency. The framework provides theoretical convergence guarantees under unimodal signal assumptions and practical stability under bounded disturbances. Experimental validation across DARPA SubT and multi-room scenarios demonstrates that BEASST consistently outperforms state-of-the-art methods, achieving 15% reduction in path length and 20% faster source localization through intelligent uncertainty-driven navigation that dynamically transitions between aggressive pursuit and cautious exploration.",
    "source": "arXiv"
  },
  {
    "title": "\"Here Comes the Makeup Tutorial You Asked For!\": Exploring Communication Strategies and Viewer Engagement in Beauty Videos on Rednote",
    "title_es": "\"Here Comes the Makeup Tutorial You Asked For!\": Exploring Communication Strategies and Viewer Engagement in Beauty Videos on Rednote",
    "url": "https://arxiv.org/abs/2508.10364",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10364v1 Announce Type: new \nAbstract: More and more people, especially females, create and view beauty videos covering topics like makeup tutorials and vlogs on social media platforms. Understanding the communication strategies that creators use in these videos and how they affect viewers' engagement can help spread beauty knowledge. By coding 352 beauty videos in Rednote, this study presents a comprehensive taxonomy of communication strategies used by the creators, such as using home as the video background and displaying makeup effects when starting the narrative at the beginning. We further label and computationally classify six categories of comments that reveal viewers' engagement with beauty videos. The regression analyses reveal the effects of beauty video communication strategies on viewers' engagement; for example, calling viewers to take action at the end tends to attract more comments that debate the product's efficacy. We discuss insights into fostering the creation of beauty videos and the communication of beauty knowledge.",
    "source": "arXiv"
  },
  {
    "title": "Advancing Cross-lingual Aspect-Based Sentiment Analysis with LLMs and Constrained Decoding for Sequence-to-Sequence Models",
    "title_es": "Advancing Cross-lingual Aspect-Based Sentiment Analysis with LLMs and Constrained Decoding for Sequence-to-Sequence Models",
    "url": "https://arxiv.org/abs/2508.10366",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10366v1 Announce Type: new \nAbstract: Aspect-based sentiment analysis (ABSA) has made significant strides, yet challenges remain for low-resource languages due to the predominant focus on English. Current cross-lingual ABSA studies often centre on simpler tasks and rely heavily on external translation tools. In this paper, we present a novel sequence-to-sequence method for compound ABSA tasks that eliminates the need for such tools. Our approach, which uses constrained decoding, improves cross-lingual ABSA performance by up to 10\\%. This method broadens the scope of cross-lingual ABSA, enabling it to handle more complex tasks and providing a practical, efficient alternative to translation-dependent techniques. Furthermore, we compare our approach with large language models (LLMs) and show that while fine-tuned multilingual LLMs can achieve comparable results, English-centric LLMs struggle with these tasks.",
    "source": "arXiv"
  },
  {
    "title": "Contrast Sensitivity Function of Multimodal Vision-Language Models",
    "title_es": "Contrast Sensitivity Function of Multimodal Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.10367",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10367v1 Announce Type: new \nAbstract: Assessing the alignment of multimodal vision-language models~(VLMs) with human perception is essential to understand how they perceive low-level visual features. A key characteristic of human vision is the contrast sensitivity function (CSF), which describes sensitivity to spatial frequency at low-contrasts. Here, we introduce a novel behavioral psychophysics-inspired method to estimate the CSF of chat-based VLMs by directly prompting them to judge pattern visibility at different contrasts for each frequency. This methodology is closer to the real experiments in psychophysics than the previously reported. Using band-pass filtered noise images and a diverse set of prompts, we assess model responses across multiple architectures. We find that while some models approximate human-like CSF shape or magnitude, none fully replicate both. Notably, prompt phrasing has a large effect on the responses, raising concerns about prompt stability. Our results provide a new framework for probing visual sensitivity in multimodal models and reveal key gaps between their visual representations and human perception.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models for Summarizing Czech Historical Documents and Beyond",
    "title_es": "Large Language Models for Summarizing Czech Historical Documents and Beyond",
    "url": "https://arxiv.org/abs/2508.10368",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10368v1 Announce Type: new \nAbstract: Text summarization is the task of shortening a larger body of text into a concise version while retaining its essential meaning and key information. While summarization has been significantly explored in English and other high-resource languages, Czech text summarization, particularly for historical documents, remains underexplored due to linguistic complexities and a scarcity of annotated datasets. Large language models such as Mistral and mT5 have demonstrated excellent results on many natural language processing tasks and languages. Therefore, we employ these models for Czech summarization, resulting in two key contributions: (1) achieving new state-of-the-art results on the modern Czech summarization dataset SumeCzech using these advanced models, and (2) introducing a novel dataset called Posel od \\v{C}erchova for summarization of historical Czech documents with baseline results. Together, these contributions provide a great potential for advancing Czech text summarization and open new avenues for research in Czech historical text processing.",
    "source": "arXiv"
  },
  {
    "title": "Improving Generative Cross-lingual Aspect-Based Sentiment Analysis with Constrained Decoding",
    "title_es": "Improving Generative Cross-lingual Aspect-Based Sentiment Analysis with Constrained Decoding",
    "url": "https://arxiv.org/abs/2508.10369",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10369v1 Announce Type: new \nAbstract: While aspect-based sentiment analysis (ABSA) has made substantial progress, challenges remain for low-resource languages, which are often overlooked in favour of English. Current cross-lingual ABSA approaches focus on limited, less complex tasks and often rely on external translation tools. This paper introduces a novel approach using constrained decoding with sequence-to-sequence models, eliminating the need for unreliable translation tools and improving cross-lingual performance by 5\\% on average for the most complex task. The proposed method also supports multi-tasking, which enables solving multiple ABSA tasks with a single model, with constrained decoding boosting results by more than 10\\%.\n  We evaluate our approach across seven languages and six ABSA tasks, surpassing state-of-the-art methods and setting new benchmarks for previously unexplored tasks. Additionally, we assess large language models (LLMs) in zero-shot, few-shot, and fine-tuning scenarios. While LLMs perform poorly in zero-shot and few-shot settings, fine-tuning achieves competitive results compared to smaller multilingual models, albeit at the cost of longer training and inference times.\n  We provide practical recommendations for real-world applications, enhancing the understanding of cross-lingual ABSA methodologies. This study offers valuable insights into the strengths and limitations of cross-lingual ABSA approaches, advancing the state-of-the-art in this challenging research domain.",
    "source": "arXiv"
  },
  {
    "title": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing",
    "title_es": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing",
    "url": "https://arxiv.org/abs/2508.10370",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10370v1 Announce Type: new \nAbstract: State Space Model (SSM)-based machine learning architectures have recently gained significant attention for processing sequential data. Mamba, a recent sequence-to-sequence SSM, offers competitive accuracy with superior computational efficiency compared to state-of-the-art transformer models. While this advantage makes Mamba particularly promising for resource-constrained edge devices, no hardware acceleration frameworks are currently optimized for deploying it in such environments. This paper presents eMamba, a comprehensive end-to-end hardware acceleration framework explicitly designed for deploying Mamba models on edge platforms. eMamba maximizes computational efficiency by replacing complex normalization layers with lightweight hardware-aware alternatives and approximating expensive operations, such as SiLU activation and exponentiation, considering the target applications. Then, it performs an approximation-aware neural architecture search (NAS) to tune the learnable parameters used during approximation. Evaluations with Fashion-MNIST, CIFAR-10, and MARS, an open-source human pose estimation dataset, show eMamba achieves comparable accuracy to state-of-the-art techniques using 1.63-19.9$\\times$ fewer parameters. In addition, it generalizes well to large-scale natural language tasks, demonstrating stable perplexity across varying sequence lengths on the WikiText2 dataset. We also quantize and implement the entire eMamba pipeline on an AMD ZCU102 FPGA and ASIC using GlobalFoundries (GF) 22 nm technology. Experimental results show 4.95-5.62$\\times$ lower latency and 2.22-9.95$\\times$ higher throughput, with 4.77$\\times$ smaller area, 9.84$\\times$ lower power, and 48.6$\\times$ lower energy consumption than baseline solutions while maintaining competitive accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Few-shot Vision-based Human Activity Recognition with MLLM-based Visual Reinforcement Learning",
    "title_es": "Few-shot Vision-based Human Activity Recognition with MLLM-based Visual Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.10371",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10371v1 Announce Type: new \nAbstract: Reinforcement learning in large reasoning models enables learning from feedback on their outputs, making it particularly valuable in scenarios where fine-tuning data is limited. However, its application in multi-modal human activity recognition (HAR) domains remains largely underexplored. Our work extends reinforcement learning to the human activity recognition domain with multimodal large language models. By incorporating visual reinforcement learning in the training process, the model's generalization ability on few-shot recognition can be greatly improved. Additionally, visual reinforcement learning can enhance the model's reasoning ability and enable explainable analysis in the inference stage. We name our few-shot human activity recognition method with visual reinforcement learning FAVOR. Specifically, our approach first utilizes a multimodal large language model (MLLM) to generate multiple candidate responses for the human activity image, each containing reasoning traces and final answers. These responses are then evaluated using reward functions, and the MLLM model is subsequently optimized using the Group Relative Policy Optimization (GRPO) algorithm. In this way, the MLLM model can be adapted to human activity recognition with only a few samples. Extensive experiments on four human activity recognition datasets and five different settings demonstrate the superiority of the proposed method.",
    "source": "arXiv"
  },
  {
    "title": "Privacy-Preserving Approximate Nearest Neighbor Search on High-Dimensional Data",
    "title_es": "Privacy-Preserving Approximate Nearest Neighbor Search on High-Dimensional Data",
    "url": "https://arxiv.org/abs/2508.10373",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10373v1 Announce Type: new \nAbstract: In the era of cloud computing and AI, data owners outsource ubiquitous vectors to the cloud, which furnish approximate $k$-nearest neighbors ($k$-ANNS) services to users. To protect data privacy against the untrusted server, privacy-preserving $k$-ANNS (PP-ANNS) on vectors has been a fundamental and urgent problem. However, existing PP-ANNS solutions fall short of meeting the requirements of data privacy, efficiency, accuracy, and minimal user involvement concurrently. To tackle this challenge, we introduce a novel solution that primarily executes PP-ANNS on a single cloud server to avoid the heavy communication overhead between the cloud and the user. To ensure data privacy, we introduce a novel encryption method named distance comparison encryption, facilitating secure, efficient, and exact distance comparisons. To optimize the trade-off between data privacy and search performance, we design a privacy-preserving index that combines the state-of-the-art $k$-ANNS method with an approximate distance computation method. Then, we devise a search method using a filter-and-refine strategy based on the index. Moreover, we provide the security analysis of our solution and conduct extensive experiments to demonstrate its superiority over existing solutions. Based on our experimental results, our method accelerates PP-ANNS by up to 3 orders of magnitude compared to state-of-the-art methods, while not compromising the accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Lower Bounds on Tree Covers",
    "title_es": "Lower Bounds on Tree Covers",
    "url": "https://arxiv.org/abs/2508.10376",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10376v1 Announce Type: new \nAbstract: Given an $n$-point metric space $(X,d_X)$, a tree cover $\\mathcal{T}$ is a set of $|\\mathcal{T}|=k$ trees on $X$ such that every pair of vertices in $X$ has a low-distortion path in one of the trees in $\\mathcal{T}$. Tree covers have been playing a crucial role in graph algorithms for decades, and the research focus is the construction of tree covers with small size $k$ and distortion.\n  When $k=1$, the best distortion is known to be $\\Theta(n)$. For a constant $k\\ge 2$, the best distortion upper bound is $\\tilde O(n^{\\frac 1 k})$ and the strongest lower bound is $\\Omega(\\log_k n)$, leaving a gap to be closed. In this paper, we improve the lower bound to $\\Omega(n^{\\frac{1}{2^{k-1}}})$.\n  Our proof is a novel analysis on a structurally simple grid-like graph, which utilizes some combinatorial fixed-point theorems. We believe that they will prove useful for analyzing other tree-like data structures as well.",
    "source": "arXiv"
  },
  {
    "title": "Clicks Versus Conversion: Choosing a Recommender's Training Objective in E-Commerce",
    "title_es": "Clicks Versus Conversion: Choosing a Recommender's Training Objective in E-Commerce",
    "url": "https://arxiv.org/abs/2508.10377",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10377v1 Announce Type: new \nAbstract: Ranking product recommendations to optimize for a high click-through rate (CTR) or for high conversion, such as add-to-cart rate (ACR) and Order-Submit-Rate (OSR, view-to-purchase conversion) are standard practices in e-commerce. Optimizing for CTR appears like a straightforward choice: Training data (i.e., click data) are simple to collect and often available in large quantities. Additionally, CTR is used far beyond e-commerce, making it a generalist, easily implemented option. ACR and OSR, on the other hand, are more directly linked to a shop's business goals, such as the Gross Merchandise Value (GMV). In this paper, we compare the effects of using either of these objectives using an online A/B test. Among our key findings, we demonstrate that in our shops, optimizing for OSR produces a GMV uplift more than five times larger than when optimizing for CTR, without sacrificing new product discovery. Our results also provide insights into the different feature importances for each of the objectives.",
    "source": "arXiv"
  },
  {
    "title": "A Semantic-Aware Framework for Safe and Intent-Integrative Assistance in Upper-Limb Exoskeletons",
    "title_es": "A Semantic-Aware Framework for Safe and Intent-Integrative Assistance in Upper-Limb Exoskeletons",
    "url": "https://arxiv.org/abs/2508.10378",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10378v1 Announce Type: new \nAbstract: Upper-limb exoskeletons are primarily designed to provide assistive support by accurately interpreting and responding to human intentions. In home-care scenarios, exoskeletons are expected to adapt their assistive configurations based on the semantic information of the task, adjusting appropriately in accordance with the nature of the object being manipulated. However, existing solutions often lack the ability to understand task semantics or collaboratively plan actions with the user, limiting their generalizability. To address this challenge, this paper introduces a semantic-aware framework that integrates large language models into the task planning framework, enabling the delivery of safe and intent-integrative assistance. The proposed approach begins with the exoskeleton operating in transparent mode to capture the wearer's intent during object grasping. Once semantic information is extracted from the task description, the system automatically configures appropriate assistive parameters. In addition, a diffusion-based anomaly detector is used to continuously monitor the state of human-robot interaction and trigger real-time replanning in response to detected anomalies. During task execution, online trajectory refinement and impedance control are used to ensure safety and regulate human-robot interaction. Experimental results demonstrate that the proposed method effectively aligns with the wearer's cognition, adapts to semantically varying tasks, and responds reliably to anomalies.",
    "source": "arXiv"
  },
  {
    "title": "Cross-Organizational Analysis of Parliamentary Processes: A Case Study",
    "title_es": "Cross-Organizational Analysis of Parliamentary Processes: A Case Study",
    "url": "https://arxiv.org/abs/2508.10381",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10381v1 Announce Type: new \nAbstract: Process Mining has been widely adopted by businesses and has been shown to help organizations analyze and optimize their processes. However, so far, little attention has gone into the cross-organizational comparison of processes, since many companies are hesitant to share their data. In this paper, we explore the processes of German state parliaments that are often legally required to share their data and run the same type of processes for different geographical regions. This paper is the first attempt to apply process mining to parliamentary processes and, therefore, contributes toward a novel interdisciplinary research area that combines political science and process mining. In our case study, we analyze legislative processes of three German state parliaments and generate insights into their differences and best practices. We provide a discussion of the relevance of our results that are based on knowledge exchange with a political scientist and a domain expert from the German federal parliament.",
    "source": "arXiv"
  },
  {
    "title": "Towards Spatially Consistent Image Generation: On Incorporating Intrinsic Scene Properties into Diffusion Models",
    "title_es": "Towards Spatially Consistent Image Generation: On Incorporating Intrinsic Scene Properties into Diffusion Models",
    "url": "https://arxiv.org/abs/2508.10382",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10382v1 Announce Type: new \nAbstract: Image generation models trained on large datasets can synthesize high-quality images but often produce spatially inconsistent and distorted images due to limited information about the underlying structures and spatial layouts. In this work, we leverage intrinsic scene properties (e.g., depth, segmentation maps) that provide rich information about the underlying scene, unlike prior approaches that solely rely on image-text pairs or use intrinsics as conditional inputs. Our approach aims to co-generate both images and their corresponding intrinsics, enabling the model to implicitly capture the underlying scene structure and generate more spatially consistent and realistic images. Specifically, we first extract rich intrinsic scene properties from a large image dataset with pre-trained estimators, eliminating the need for additional scene information or explicit 3D representations. We then aggregate various intrinsic scene properties into a single latent variable using an autoencoder. Building upon pre-trained large-scale Latent Diffusion Models (LDMs), our method simultaneously denoises the image and intrinsic domains by carefully sharing mutual information so that the image and intrinsic reflect each other without degrading image quality. Experimental results demonstrate that our method corrects spatial inconsistencies and produces a more natural layout of scenes while maintaining the fidelity and textual alignment of the base model (e.g., Stable Diffusion).",
    "source": "arXiv"
  },
  {
    "title": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise",
    "title_es": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise",
    "url": "https://arxiv.org/abs/2508.10383",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10383v1 Announce Type: new \nAbstract: While previous studies on image segmentation focus on handling severe (or explicit) label noise, real-world datasets also exhibit subtle (or implicit) label imperfections. These arise from inherent challenges, such as ambiguous object boundaries and annotator variability. Although not explicitly present, such mild and latent noise can still impair model performance. Typical data augmentation methods, which apply identical transformations to the image and its label, risk amplifying these subtle imperfections and limiting the model's generalization capacity. In this paper, we introduce NSegment+, a novel augmentation framework that decouples image and label transformations to address such realistic noise for semantic segmentation. By introducing controlled elastic deformations only to segmentation labels while preserving the original images, our method encourages models to focus on learning robust representations of object structures despite minor label inconsistencies. Extensive experiments demonstrate that NSegment+ consistently improves performance, achieving mIoU gains of up to +2.29, +2.38, +1.75, and +3.39 in average on Vaihingen, LoveDA, Cityscapes, and PASCAL VOC, respectively-even without bells and whistles, highlighting the importance of addressing implicit label noise. These gains can be further amplified when combined with other training tricks, including CutMix and Label Smoothing.",
    "source": "arXiv"
  },
  {
    "title": "Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts",
    "title_es": "Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts",
    "url": "https://arxiv.org/abs/2508.10390",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10390v1 Announce Type: new \nAbstract: Evaluating jailbreak attacks is challenging when prompts are not overtly harmful or fail to induce harmful outputs. Unfortunately, many existing red-teaming datasets contain such unsuitable prompts. To evaluate attacks accurately, these datasets need to be assessed and cleaned for maliciousness. However, existing malicious content detection methods rely on either manual annotation, which is labor-intensive, or large language models (LLMs), which have inconsistent accuracy in harmful types. To balance accuracy and efficiency, we propose a hybrid evaluation framework named MDH (Malicious content Detection based on LLMs with Human assistance) that combines LLM-based annotation with minimal human oversight, and apply it to dataset cleaning and detection of jailbroken responses. Furthermore, we find that well-crafted developer messages can significantly boost jailbreak success, leading us to propose two new strategies: D-Attack, which leverages context simulation, and DH-CoT, which incorporates hijacked chains of thought. The Codes, datasets, judgements, and detection results will be released in github repository: https://github.com/AlienZhang1996/DH-CoT.",
    "source": "arXiv"
  },
  {
    "title": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval",
    "title_es": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval",
    "url": "https://arxiv.org/abs/2508.10391",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10391v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large Language Models by leveraging external knowledge, whereas the effectiveness is often compromised by the retrieval of contextually flawed or incomplete information. To address this, knowledge graph-based RAG methods have evolved towards hierarchical structures, organizing knowledge into multi-level summaries. However, these approaches still suffer from two critical, unaddressed challenges: high-level conceptual summaries exist as disconnected ``semantic islands'', lacking the explicit relations needed for cross-community reasoning; and the retrieval process itself remains structurally unaware, often degenerating into an inefficient flat search that fails to exploit the graph's rich topology. To overcome these limitations, we introduce LeanRAG, a framework that features a deeply collaborative design combining knowledge aggregation and retrieval strategies. LeanRAG first employs a novel semantic aggregation algorithm that forms entity clusters and constructs new explicit relations among aggregation-level summaries, creating a fully navigable semantic network. Then, a bottom-up, structure-guided retrieval strategy anchors queries to the most relevant fine-grained entities and then systematically traverses the graph's semantic pathways to gather concise yet contextually comprehensive evidence sets. The LeanRAG can mitigate the substantial overhead associated with path retrieval on graphs and minimizes redundant information retrieval. Extensive experiments on four challenging QA benchmarks with different domains demonstrate that LeanRAG significantly outperforming existing methods in response quality while reducing 46\\% retrieval redundancy. Code is available at: https://github.com/RaZzzyz/LeanRAG",
    "source": "arXiv"
  },
  {
    "title": "A Unified Evaluation Framework for Multi-Annotator Tendency Learning",
    "title_es": "A Unified Evaluation Framework for Multi-Annotator Tendency Learning",
    "url": "https://arxiv.org/abs/2508.10393",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10393v1 Announce Type: new \nAbstract: Recent works have emerged in multi-annotator learning that shift focus from Consensus-oriented Learning (CoL), which aggregates multiple annotations into a single ground-truth prediction, to Individual Tendency Learning (ITL), which models annotator-specific labeling behavior patterns (i.e., tendency) to provide explanation analysis for understanding annotator decisions. However, no evaluation framework currently exists to assess whether ITL methods truly capture individual tendencies and provide meaningful behavioral explanations. To address this gap, we propose the first unified evaluation framework with two novel metrics: (1) Difference of Inter-annotator Consistency (DIC) quantifies how well models capture annotator tendencies by comparing predicted inter-annotator similarity structures with ground-truth; (2) Behavior Alignment Explainability (BAE) evaluates how well model explanations reflect annotator behavior and decision relevance by aligning explainability-derived with ground-truth labeling similarity structures via Multidimensional Scaling (MDS). Extensive experiments validate the effectiveness of our proposed evaluation framework.",
    "source": "arXiv"
  },
  {
    "title": "XQuant: Breaking the Memory Wall for LLM Inference with KV Cache Rematerialization",
    "title_es": "XQuant: Breaking the Memory Wall for LLM Inference with KV Cache Rematerialization",
    "url": "https://arxiv.org/abs/2508.10395",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10395v1 Announce Type: new \nAbstract: Although LLM inference has emerged as a critical workload for many downstream applications, efficiently inferring LLMs is challenging due to the substantial memory footprint and bandwidth requirements. In parallel, compute capabilities have steadily outpaced both memory capacity and bandwidth over the last few decades, a trend that remains evident in modern GPU hardware and exacerbates the challenge of LLM inference. As such, new algorithms are emerging that trade increased computation for reduced memory operations. To that end, we present XQuant, which takes advantage of this trend, enabling an order-of-magnitude reduction in memory consumption through low-bit quantization with substantial accuracy benefits relative to state-of-the-art KV cache quantization methods. We accomplish this by quantizing and caching the layer input activations X, instead of using standard KV caching, and then rematerializing the Keys and Values on-the-fly during inference. This results in an immediate 2$\\times$ memory savings compared to KV caching. By applying XQuant, we achieve up to $\\sim 7.7\\times$ memory savings with $<0.1$ perplexity degradation compared to the FP16 baseline. Furthermore, our approach leverages the fact that X values are similar across layers. Building on this observation, we introduce XQuant-CL, which exploits the cross-layer similarity in the X embeddings for extreme compression. Across different models, XQuant-CL attains up to 10$\\times$ memory savings relative to the FP16 baseline with only 0.01 perplexity degradation, and 12.5$\\times$ memory savings with only $0.1$ perplexity degradation. XQuant exploits the rapidly increasing compute capabilities of hardware platforms to eliminate the memory bottleneck, while surpassing state-of-the-art KV cache quantization methods and achieving near-FP16 accuracy across a wide range of models.",
    "source": "arXiv"
  },
  {
    "title": "PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection",
    "title_es": "PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection",
    "url": "https://arxiv.org/abs/2508.10397",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10397v1 Announce Type: new \nAbstract: Driver distraction detection is essential for improving traffic safety and reducing road accidents. However, existing models often suffer from degraded generalization when deployed in real-world scenarios. This limitation primarily arises from the few-shot learning challenge caused by the high cost of data annotation in practical environments, as well as the substantial domain shift between training datasets and target deployment conditions. To address these issues, we propose a Pose-driven Quality-controlled Data Augmentation Framework (PQ-DAF) that leverages a vision-language model for sample filtering to cost-effectively expand training data and enhance cross-domain robustness. Specifically, we employ a Progressive Conditional Diffusion Model (PCDMs) to accurately capture key driver pose features and synthesize diverse training examples. A sample quality assessment module, built upon the CogVLM vision-language model, is then introduced to filter out low-quality synthetic samples based on a confidence threshold, ensuring the reliability of the augmented dataset. Extensive experiments demonstrate that PQ-DAF substantially improves performance in few-shot driver distraction detection, achieving significant gains in model generalization under data-scarce conditions.",
    "source": "arXiv"
  },
  {
    "title": "Super LiDAR Reflectance for Robotic Perception",
    "title_es": "Super LiDAR Reflectance for Robotic Perception",
    "url": "https://arxiv.org/abs/2508.10398",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10398v1 Announce Type: new \nAbstract: Conventionally, human intuition often defines vision as a modality of passive optical sensing, while active optical sensing is typically regarded as measuring rather than the default modality of vision. However, the situation now changes: sensor technologies and data-driven paradigms empower active optical sensing to redefine the boundaries of vision, ushering in a new era of active vision. Light Detection and Ranging (LiDAR) sensors capture reflectance from object surfaces, which remains invariant under varying illumination conditions, showcasing significant potential in robotic perception tasks such as detection, recognition, segmentation, and Simultaneous Localization and Mapping (SLAM). These applications often rely on dense sensing capabilities, typically achieved by high-resolution, expensive LiDAR sensors. A key challenge with low-cost LiDARs lies in the sparsity of scan data, which limits their broader application. To address this limitation, this work introduces an innovative framework for generating dense LiDAR reflectance images from sparse data, leveraging the unique attributes of non-repeating scanning LiDAR (NRS-LiDAR). We tackle critical challenges, including reflectance calibration and the transition from static to dynamic scene domains, facilitating the reconstruction of dense reflectance images in real-world settings. The key contributions of this work include a comprehensive dataset for LiDAR reflectance image densification, a densification network tailored for NRS-LiDAR, and diverse applications such as loop closure and traffic lane detection using the generated dense reflectance images.",
    "source": "arXiv"
  },
  {
    "title": "Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning",
    "title_es": "Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning",
    "url": "https://arxiv.org/abs/2508.10399",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10399v1 Announce Type: new \nAbstract: Embodied AI aims to develop intelligent systems with physical forms capable of perceiving, decision-making, acting, and learning in real-world environments, providing a promising way to Artificial General Intelligence (AGI). Despite decades of explorations, it remains challenging for embodied agents to achieve human-level intelligence for general-purpose tasks in open dynamic environments. Recent breakthroughs in large models have revolutionized embodied AI by enhancing perception, interaction, planning and learning. In this article, we provide a comprehensive survey on large model empowered embodied AI, focusing on autonomous decision-making and embodied learning. We investigate both hierarchical and end-to-end decision-making paradigms, detailing how large models enhance high-level planning, low-level execution, and feedback for hierarchical decision-making, and how large models enhance Vision-Language-Action (VLA) models for end-to-end decision making. For embodied learning, we introduce mainstream learning methodologies, elaborating on how large models enhance imitation learning and reinforcement learning in-depth. For the first time, we integrate world models into the survey of embodied AI, presenting their design methods and critical roles in enhancing decision-making and learning. Though solid advances have been achieved, challenges still exist, which are discussed at the end of this survey, potentially as the further research directions.",
    "source": "arXiv"
  },
  {
    "title": "Proxy Model-Guided Reinforcement Learning for Client Selection in Federated Recommendation",
    "title_es": "Proxy Model-Guided Reinforcement Learning for Client Selection in Federated Recommendation",
    "url": "https://arxiv.org/abs/2508.10401",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10401v1 Announce Type: new \nAbstract: Federated recommender systems have emerged as a promising privacy-preserving paradigm, enabling personalized recommendation services without exposing users' raw data. By keeping data local and relying on a central server to coordinate training across distributed clients, FedRSs protect user privacy while collaboratively learning global models. However, most existing FedRS frameworks adopt fully random client selection strategy in each training round, overlooking the statistical heterogeneity of user data arising from diverse preferences and behavior patterns, thereby resulting in suboptimal model performance. While some client selection strategies have been proposed in the broader federated learning literature, these methods are typically designed for generic tasks and fail to address the unique challenges of recommendation scenarios, such as expensive contribution evaluation due to the large number of clients, and sparse updates resulting from long-tail item distributions. To bridge this gap, we propose ProxyRL-FRS, a proxy model-guided reinforcement learning framework tailored for client selection in federated recommendation. Specifically, we first introduce ProxyNCF, a dual-branch model deployed on each client, which augments standard Neural Collaborative Filtering with an additional proxy model branch that provides lightweight contribution estimation, thus eliminating the need for expensive per-round local training traditionally required to evaluate a client's contribution. Furthermore, we design a staleness-aware SA reinforcement learning agent that selects clients based on the proxy-estimated contribution, and is guided by a reward function balancing recommendation accuracy and embedding staleness, thereby enriching the update coverage of item embeddings. Experiments conducted on public recommendation datasets demonstrate the effectiveness of ProxyRL-FRS.",
    "source": "arXiv"
  },
  {
    "title": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation",
    "title_es": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation",
    "url": "https://arxiv.org/abs/2508.10404",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10404v1 Announce Type: new \nAbstract: With the rapid proliferation of Natural Language Processing (NLP), especially Large Language Models (LLMs), generating adversarial examples to jailbreak LLMs remains a key challenge for understanding model vulnerabilities and improving robustness. In this context, we propose a new black-box attack method that leverages the interpretability of large models. We introduce the Sparse Feature Perturbation Framework (SFPF), a novel approach for adversarial text generation that utilizes sparse autoencoders to identify and manipulate critical features in text. After using the SAE model to reconstruct hidden layer representations, we perform feature clustering on the successfully attacked texts to identify features with higher activations. These highly activated features are then perturbed to generate new adversarial texts. This selective perturbation preserves the malicious intent while amplifying safety signals, thereby increasing their potential to evade existing defenses. Our method enables a new red-teaming strategy that balances adversarial effectiveness with safety alignment. Experimental results demonstrate that adversarial texts generated by SFPF can bypass state-of-the-art defense mechanisms, revealing persistent vulnerabilities in current NLP systems.However, the method's effectiveness varies across prompts and layers, and its generalizability to other architectures and larger models remains to be validated.",
    "source": "arXiv"
  },
  {
    "title": "Translation of Text Embedding via Delta Vector to Suppress Strongly Entangled Content in Text-to-Image Diffusion Models",
    "title_es": "Translation of Text Embedding via Delta Vector to Suppress Strongly Entangled Content in Text-to-Image Diffusion Models",
    "url": "https://arxiv.org/abs/2508.10407",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10407v1 Announce Type: new \nAbstract: Text-to-Image (T2I) diffusion models have made significant progress in generating diverse high-quality images from textual prompts. However, these models still face challenges in suppressing content that is strongly entangled with specific words. For example, when generating an image of ``Charlie Chaplin\", a ``mustache\" consistently appears even if explicitly instructed not to include it, as the concept of ``mustache\" is strongly entangled with ``Charlie Chaplin\". To address this issue, we propose a novel approach to directly suppress such entangled content within the text embedding space of diffusion models. Our method introduces a delta vector that modifies the text embedding to weaken the influence of undesired content in the generated image, and we further demonstrate that this delta vector can be easily obtained through a zero-shot approach. Furthermore, we propose a Selective Suppression with Delta Vector (SSDV) method to adapt delta vector into the cross-attention mechanism, enabling more effective suppression of unwanted content in regions where it would otherwise be generated. Additionally, we enabled more precise suppression in personalized T2I models by optimizing delta vector, which previous baselines were unable to achieve. Extensive experimental results demonstrate that our approach significantly outperforms existing methods, both in terms of quantitative and qualitative metrics.",
    "source": "arXiv"
  },
  {
    "title": "AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design",
    "title_es": "AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design",
    "url": "https://arxiv.org/abs/2508.10409",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10409v1 Announce Type: new \nAbstract: In this paper, we propose AnalogSeeker, an effort toward an open-source foundation language model for analog circuit design, with the aim of integrating domain knowledge and giving design assistance. To overcome the scarcity of data in this field, we employ a corpus collection strategy based on the domain knowledge framework of analog circuits. High-quality, accessible textbooks across relevant subfields are systematically curated and cleaned into a textual domain corpus. To address the complexity of knowledge of analog circuits, we introduce a granular domain knowledge distillation method. Raw, unlabeled domain corpus is decomposed into typical, granular learning nodes, where a multi-agent framework distills implicit knowledge embedded in unstructured text into question-answer data pairs with detailed reasoning processes, yielding a fine-grained, learnable dataset for fine-tuning. To address the unexplored challenges in training analog circuit foundation models, we explore and share our training methods through both theoretical analysis and experimental validation. We finally establish a fine-tuning-centric training paradigm, customizing and implementing a neighborhood self-constrained supervised fine-tuning algorithm. This approach enhances training outcomes by constraining the perturbation magnitude between the model's output distributions before and after training. In practice, we train the Qwen2.5-32B-Instruct model to obtain AnalogSeeker, which achieves 85.04% accuracy on AMSBench-TQA, the analog circuit knowledge evaluation benchmark, with a 15.67% point improvement over the original model and is competitive with mainstream commercial models. Furthermore, AnalogSeeker also shows effectiveness in the downstream operational amplifier design task. AnalogSeeker is open-sourced at https://huggingface.co/analogllm/analogseeker for research use.",
    "source": "arXiv"
  },
  {
    "title": "SC-Lane: Slope-aware and Consistent Road Height Estimation Framework for 3D Lane Detection",
    "title_es": "SC-Lane: Slope-aware and Consistent Road Height Estimation Framework for 3D Lane Detection",
    "url": "https://arxiv.org/abs/2508.10411",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10411v1 Announce Type: new \nAbstract: In this paper, we introduce SC-Lane, a novel slope-aware and temporally consistent heightmap estimation framework for 3D lane detection. Unlike previous approaches that rely on fixed slope anchors, SC-Lane adaptively determines the fusion of slope-specific height features, improving robustness to diverse road geometries. To achieve this, we propose a Slope-Aware Adaptive Feature module that dynamically predicts the appropriate weights from image cues for integrating multi-slope representations into a unified heightmap. Additionally, a Height Consistency Module enforces temporal coherence, ensuring stable and accurate height estimation across consecutive frames, which is crucial for real-world driving scenarios. To evaluate the effectiveness of SC-Lane, we employ three standardized metrics-Mean Absolute Error(MAE), Root Mean Squared Error (RMSE), and threshold-based accuracy-which, although common in surface and depth estimation, have been underutilized for road height assessment. Using the LiDAR-derived heightmap dataset introduced in prior work [20], we benchmark our method under these metrics, thereby establishing a rigorous standard for future comparisons. Extensive experiments on the OpenLane benchmark demonstrate that SC-Lane significantly improves both height estimation and 3D lane detection, achieving state-of-the-art performance with an F-score of 64.3%, outperforming existing methods by a notable margin. For detailed results and a demonstration video, please refer to our project page:https://parkchaesong.github.io/sclane/",
    "source": "arXiv"
  },
  {
    "title": "Facilitating Personalized TTS for Dysarthric Speakers Using Knowledge Anchoring and Curriculum Learning",
    "title_es": "Facilitating Personalized TTS for Dysarthric Speakers Using Knowledge Anchoring and Curriculum Learning",
    "url": "https://arxiv.org/abs/2508.10412",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10412v1 Announce Type: new \nAbstract: Dysarthric speakers experience substantial communication challenges due to impaired motor control of the speech apparatus, which leads to reduced speech intelligibility. This creates significant obstacles in dataset curation since actual recording of long, articulate sentences for the objective of training personalized TTS models becomes infeasible. Thus, the limited availability of audio data, in addition to the articulation errors that are present within the audio, complicates personalized speech synthesis for target dysarthric speaker adaptation. To address this, we frame the issue as a domain transfer task and introduce a knowledge anchoring framework that leverages a teacher-student model, enhanced by curriculum learning through audio augmentation. Experimental results show that the proposed zero-shot multi-speaker TTS model effectively generates synthetic speech with markedly reduced articulation errors and high speaker fidelity, while maintaining prosodic naturalness.",
    "source": "arXiv"
  },
  {
    "title": "Probabilistic Latency Analysis of the Data Distribution Service in ROS 2",
    "title_es": "Probabilistic Latency Analysis of the Data Distribution Service in ROS 2",
    "url": "https://arxiv.org/abs/2508.10413",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10413v1 Announce Type: new \nAbstract: Robot Operating System 2 (ROS 2) is now the de facto standard for robotic communication, pairing UDP transport with the Data Distribution Service (DDS) publish-subscribe middleware. DDS achieves reliability through periodic heartbeats that solicit acknowledgments for missing samples and trigger selective retransmissions. In lossy wireless networks, the tight coupling among heartbeat period, IP fragmentation, and retransmission interval obscures end to end latency behavior and leaves practitioners with little guidance on how to tune these parameters. To address these challenges, we propose a probabilistic latency analysis (PLA) that analytically models the reliable transmission process of ROS 2 DDS communication using a discrete state approach. By systematically analyzing both middleware level and transport level events, PLA computes the steady state probability distribution of unacknowledged messages and the retransmission latency. We validate our PLA across 270 scenarios, exploring variations in packet delivery ratios, message sizes, and both publishing and retransmission intervals, demonstrating a close alignment between analytical predictions and experimental results. Our findings establish a theoretical basis to systematically optimize reliability, latency, and performance in wireless industrial robotics.",
    "source": "arXiv"
  },
  {
    "title": "MCP2OSC: Parametric Control by Natural Language",
    "title_es": "MCP2OSC: Parametric Control by Natural Language",
    "url": "https://arxiv.org/abs/2508.10414",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10414v1 Announce Type: new \nAbstract: Text prompts enable intuitive content creation but may fall short in achieving high precision for intricate tasks; knob or slider controls offer precise adjustments at the cost of increased complexity. To address the gap between knobs and prompts, a new MCP (Model Context Protocol) server and a unique set of prompt design criteria are presented to enable exploring parametric OSC (OpenSoundControl) control by natural language prompts. Demonstrated by 14 practical QA examples with best practices and the generalized prompt templates, this study finds Claude integrated with the MCP2OSC server effective in generating OSC messages by natural language, interpreting, searching, and visualizing OSC messages, validating and debugging OSC messages, and managing OSC address patterns. MCP2OSC enhances human-machine collaboration by leveraging LLM (Large Language Model) to handle intricate OSC development tasks, and by empowering human creativity with an intuitive language interface featuring flexible precision controls: a prompt-based OSC tool. This study provides a novel perspective on the creative MCP application at the network protocol level by utilizing LLM's strength in directly processing and generating human-readable OSC messages. The results suggest its potential for a LLM-based universal control mechanism for multimedia devices.",
    "source": "arXiv"
  },
  {
    "title": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model",
    "title_es": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model",
    "url": "https://arxiv.org/abs/2508.10416",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10416v1 Announce Type: new \nAbstract: Existing vision-and-language navigation models often deviate from the correct trajectory when executing instructions. However, these models lack effective error correction capability, hindering their recovery from errors. To address this challenge, we propose Self-correction Flywheel, a novel post-training paradigm. Instead of considering the model's error trajectories on the training set as a drawback, our paradigm emphasizes their significance as a valuable data source. We have developed a method to identify deviations in these error trajectories and devised innovative techniques to automatically generate self-correction data for perception and action. These self-correction data serve as fuel to power the model's continued training. The brilliance of our paradigm is revealed when we re-evaluate the model on the training set, uncovering new error trajectories. At this time, the self-correction flywheel begins to spin. Through multiple flywheel iterations, we progressively enhance our monocular RGB-based VLA navigation model CorrectNav. Experiments on R2R-CE and RxR-CE benchmarks show CorrectNav achieves new state-of-the-art success rates of 65.1% and 69.3%, surpassing prior best VLA navigation models by 8.2% and 16.4%. Real robot tests in various indoor and outdoor environments demonstrate \\method's superior capability of error correction, dynamic obstacle avoidance, and long instruction following.",
    "source": "arXiv"
  },
  {
    "title": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning",
    "title_es": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning",
    "url": "https://arxiv.org/abs/2508.10419",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10419v1 Announce Type: new \nAbstract: Narrative comprehension on long stories and novels has been a challenging domain attributed to their intricate plotlines and entangled, often evolving relations among characters and entities. Given the LLM's diminished reasoning over extended context and high computational cost, retrieval-based approaches remain a pivotal role in practice. However, traditional RAG methods can fall short due to their stateless, single-step retrieval process, which often overlooks the dynamic nature of capturing interconnected relations within long-range context. In this work, we propose ComoRAG, holding the principle that narrative reasoning is not a one-shot process, but a dynamic, evolving interplay between new evidence acquisition and past knowledge consolidation, analogous to human cognition when reasoning with memory-related signals in the brain. Specifically, when encountering a reasoning impasse, ComoRAG undergoes iterative reasoning cycles while interacting with a dynamic memory workspace. In each cycle, it generates probing queries to devise new exploratory paths, then integrates the retrieved evidence of new aspects into a global memory pool, thereby supporting the emergence of a coherent context for the query resolution. Across four challenging long-context narrative benchmarks (200K+ tokens), ComoRAG outperforms strong RAG baselines with consistent relative gains up to 11% compared to the strongest baseline. Further analysis reveals that ComoRAG is particularly advantageous for complex queries requiring global comprehension, offering a principled, cognitively motivated paradigm for retrieval-based long context comprehension towards stateful reasoning. Our code is publicly released at https://github.com/EternityJune25/ComoRAG",
    "source": "arXiv"
  },
  {
    "title": "Evaluating LLMs on Chinese Idiom Translation",
    "title_es": "Evaluating LLMs on Chinese Idiom Translation",
    "url": "https://arxiv.org/abs/2508.10421",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10421v1 Announce Type: new \nAbstract: Idioms, whose figurative meanings usually differ from their literal interpretations, are common in everyday language, especially in Chinese, where they often contain historical references and follow specific structural patterns. Despite recent progress in machine translation with large language models, little is known about Chinese idiom translation. In this work, we introduce IdiomEval, a framework with a comprehensive error taxonomy for Chinese idiom translation. We annotate 900 translation pairs from nine modern systems, including GPT-4o and Google Translate, across four domains: web, news, Wikipedia, and social media. We find these systems fail at idiom translation, producing incorrect, literal, partial, or even missing translations. The best-performing system, GPT-4, makes errors in 28% of cases. We also find that existing evaluation metrics measure idiom quality poorly with Pearson correlation below 0.48 with human ratings. We thus develop improved models that achieve F$_1$ scores of 0.68 for detecting idiom translation errors.",
    "source": "arXiv"
  },
  {
    "title": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion",
    "title_es": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion",
    "url": "https://arxiv.org/abs/2508.10423",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10423v1 Announce Type: new \nAbstract: This paper proposes a novel method to enhance locomotion for a single humanoid robot through cooperative-heterogeneous multi-agent deep reinforcement learning (MARL). While most existing methods typically employ single-agent reinforcement learning algorithms for a single humanoid robot or MARL algorithms for multi-robot system tasks, we propose a distinct paradigm: applying cooperative-heterogeneous MARL to optimize locomotion for a single humanoid robot. The proposed method, multi-agent reinforcement learning for single humanoid locomotion (MASH), treats each limb (legs and arms) as an independent agent that explores the robot's action space while sharing a global critic for cooperative learning. Experiments demonstrate that MASH accelerates training convergence and improves whole-body cooperation ability, outperforming conventional single-agent reinforcement learning methods. This work advances the integration of MARL into single-humanoid-robot control, offering new insights into efficient locomotion strategies.",
    "source": "arXiv"
  },
  {
    "title": "NanoControl: A Lightweight Framework for Precise and Efficient Control in Diffusion Transformer",
    "title_es": "NanoControl: A Lightweight Framework for Precise and Efficient Control in Diffusion Transformer",
    "url": "https://arxiv.org/abs/2508.10424",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10424v1 Announce Type: new \nAbstract: Diffusion Transformers (DiTs) have demonstrated exceptional capabilities in text-to-image synthesis. However, in the domain of controllable text-to-image generation using DiTs, most existing methods still rely on the ControlNet paradigm originally designed for UNet-based diffusion models. This paradigm introduces significant parameter overhead and increased computational costs. To address these challenges, we propose the Nano Control Diffusion Transformer (NanoControl), which employs Flux as the backbone network. Our model achieves state-of-the-art controllable text-to-image generation performance while incurring only a 0.024\\% increase in parameter count and a 0.029\\% increase in GFLOPs, thus enabling highly efficient controllable generation. Specifically, rather than duplicating the DiT backbone for control, we design a LoRA-style (low-rank adaptation) control module that directly learns control signals from raw conditioning inputs. Furthermore, we introduce a KV-Context Augmentation mechanism that integrates condition-specific key-value information into the backbone in a simple yet highly effective manner, facilitating deep fusion of conditional features. Extensive benchmark experiments demonstrate that NanoControl significantly reduces computational overhead compared to conventional control approaches, while maintaining superior generation quality and achieving improved controllability.",
    "source": "arXiv"
  },
  {
    "title": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation",
    "title_es": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation",
    "url": "https://arxiv.org/abs/2508.10425",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10425v1 Announce Type: new \nAbstract: Medication recommendation is a crucial task for assisting physicians in making timely decisions from longitudinal patient medical records. However, real-world EHR data present significant challenges due to the presence of rarely observed medical entities and incomplete records that may not fully capture the clinical ground truth. While data-driven models trained on longitudinal Electronic Health Records often achieve strong empirical performance, they struggle to generalize under missing or novel conditions, largely due to their reliance on observed co-occurrence patterns. To address these issues, we propose Hierarchical Ontology and Network Refinement for Robust Medication Recommendation (HiRef), a unified framework that combines two complementary structures: (i) the hierarchical semantics encoded in curated medical ontologies, and (ii) refined co-occurrence patterns derived from real-world EHRs. We embed ontology entities in hyperbolic space, which naturally captures tree-like relationships and enables knowledge transfer through shared ancestors, thereby improving generalizability to unseen codes. To further improve robustness, we introduce a prior-guided sparse regularization scheme that refines the EHR co-occurrence graph by suppressing spurious edges while preserving clinically meaningful associations. Our model achieves strong performance on EHR benchmarks (MIMIC-III and MIMIC-IV) and maintains high accuracy under simulated unseen-code settings. Extensive experiments with comprehensive ablation studies demonstrate HiRef's resilience to unseen medical codes, supported by in-depth analyses of the learned sparsified graph structure and medical code embeddings.",
    "source": "arXiv"
  },
  {
    "title": "Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints",
    "title_es": "Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints",
    "url": "https://arxiv.org/abs/2508.10426",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10426v1 Announce Type: new \nAbstract: Large language models (LLMs) are limited by substantial computational cost. We introduce a \"computational economics\" framework that treats an LLM as an internal economy of resource-constrained agents (attention heads and neuron blocks) that must allocate scarce computation to maximize task utility. First, we show empirically that when computation is scarce, standard LLMs reallocate attention toward high-value tokens while preserving accuracy. Building on this observation, we propose an incentive-driven training paradigm that augments the task loss with a differentiable computation cost term, encouraging sparse and efficient activations. On GLUE (MNLI, STS-B, CoLA) and WikiText-103, the method yields a family of models that trace a Pareto frontier and consistently dominate post-hoc pruning; for a similar accuracy we obtain roughly a forty percent reduction in FLOPS and lower latency, together with more interpretable attention patterns. These results indicate that economic principles offer a principled route to designing efficient, adaptive, and more transparent LLMs under strict resource constraints.",
    "source": "arXiv"
  },
  {
    "title": "STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes",
    "title_es": "STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes",
    "url": "https://arxiv.org/abs/2508.10427",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10427v1 Announce Type: new \nAbstract: Vision-Language Models (VLMs) have been applied to autonomous driving to support decision-making in complex real-world scenarios. However, their training on static, web-sourced image-text pairs fundamentally limits the precise spatiotemporal reasoning required to understand and predict dynamic traffic scenes. We address this critical gap with STRIDE-QA, a large-scale visual question answering (VQA) dataset for physically grounded reasoning from an ego-centric perspective. Constructed from 100 hours of multi-sensor driving data in Tokyo, capturing diverse and challenging conditions, STRIDE-QA is the largest VQA dataset for spatiotemporal reasoning in urban driving, offering 16 million QA pairs over 285K frames. Grounded by dense, automatically generated annotations including 3D bounding boxes, segmentation masks, and multi-object tracks, the dataset uniquely supports both object-centric and ego-centric reasoning through three novel QA tasks that require spatial localization and temporal prediction. Our benchmarks demonstrate that existing VLMs struggle significantly, achieving near-zero scores on prediction consistency. In contrast, VLMs fine-tuned on STRIDE-QA exhibit dramatic performance gains, achieving 55% success in spatial localization and 28% consistency in future motion prediction, compared to near-zero scores from general-purpose VLMs. Therefore, STRIDE-QA establishes a comprehensive foundation for developing more reliable VLMs for safety-critical autonomous systems.",
    "source": "arXiv"
  },
  {
    "title": "SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs in Complex Decision-Making Tasks",
    "title_es": "SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs in Complex Decision-Making Tasks",
    "url": "https://arxiv.org/abs/2508.10428",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10428v1 Announce Type: new \nAbstract: Evaluating large language models (LLMs) in complex decision-making is essential for advancing AI's ability for strategic planning and real-time adaptation. However, existing benchmarks for tasks like StarCraft II fail to capture the game's full complexity, such as its complete game context, diverse action spaces, and all playable races. To address this gap, we present SC2Arena, a benchmark that fully supports all playable races, low-level action spaces, and optimizes text-based observations to tackle spatial reasoning challenges. Complementing this, we introduce StarEvolve, a hierarchical framework that integrates strategic planning with tactical execution, featuring iterative self-correction and continuous improvement via fine-tuning on high-quality gameplay data. Its key components include a Planner-Executor-Verifier structure to break down gameplay, and a scoring system for selecting high-quality training samples. Comprehensive analysis using SC2Arena provides valuable insights into developing generalist agents that were not possible with previous benchmarks. Experimental results also demonstrate that our proposed StarEvolve achieves superior performance in strategic planning. Our code, environment, and algorithms are publicly available.",
    "source": "arXiv"
  },
  {
    "title": "MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance",
    "title_es": "MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance",
    "url": "https://arxiv.org/abs/2508.10429",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10429v1 Announce Type: new \nAbstract: We present MM-Food-100K, a public 100,000-sample multimodal food intelligence dataset with verifiable provenance. It is a curated approximately 10% open subset of an original 1.2 million, quality-accepted corpus of food images annotated for a wide range of information (such as dish name, region of creation). The corpus was collected over six weeks from over 87,000 contributors using the Codatta contribution model, which combines community sourcing with configurable AI-assisted quality checks; each submission is linked to a wallet address in a secure off-chain ledger for traceability, with a full on-chain protocol on the roadmap. We describe the schema, pipeline, and QA, and validate utility by fine-tuning large vision-language models (ChatGPT 5, ChatGPT OSS, Qwen-Max) on image-based nutrition prediction. Fine-tuning yields consistent gains over out-of-box baselines across standard metrics; we report results primarily on the MM-Food-100K subset. We release MM-Food-100K for publicly free access and retain approximately 90% for potential commercial access with revenue sharing to contributors.",
    "source": "arXiv"
  },
  {
    "title": "Yet Another Mirage of Breaking MIRAGE: Debunking Occupancy-based Side-Channel Attacks on Fully Associative Randomized Caches",
    "title_es": "Yet Another Mirage of Breaking MIRAGE: Debunking Occupancy-based Side-Channel Attacks on Fully Associative Randomized Caches",
    "url": "https://arxiv.org/abs/2508.10431",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10431v1 Announce Type: new \nAbstract: Recent work presented at USENIX Security 2025 claims that occupancy-based attacks can recover AES keys from the MIRAGE randomized cache. In this paper, we examine these claims and find that they arise from fundamental modeling flaws. Most critically, the authors' simulation of MIRAGE uses a constant seed to initialize the random number generator used for global evictions in MIRAGE, causing every AES encryption they trace to evict the same deterministic sequence of cache lines. This artificially creates a highly repeatable timing pattern that is not representative of a realistic implementation of MIRAGE, where eviction sequences vary randomly between encryptions. When we instead randomize the eviction seed for each run, reflecting realistic operation, the correlation between AES T-table accesses and attacker runtimes disappears, and the attack fails. These findings show that the reported leakage is an artifact of incorrect modeling, and not an actual vulnerability in MIRAGE.",
    "source": "arXiv"
  },
  {
    "title": "CRISP: Contrastive Residual Injection and Semantic Prompting for Continual Video Instance Segmentation",
    "title_es": "CRISP: Contrastive Residual Injection and Semantic Prompting for Continual Video Instance Segmentation",
    "url": "https://arxiv.org/abs/2508.10432",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10432v1 Announce Type: new \nAbstract: Continual video instance segmentation demands both the plasticity to absorb new object categories and the stability to retain previously learned ones, all while preserving temporal consistency across frames. In this work, we introduce Contrastive Residual Injection and Semantic Prompting (CRISP), an earlier attempt tailored to address the instance-wise, category-wise, and task-wise confusion in continual video instance segmentation. For instance-wise learning, we model instance tracking and construct instance correlation loss, which emphasizes the correlation with the prior query space while strengthening the specificity of the current task query. For category-wise learning, we build an adaptive residual semantic prompt (ARSP) learning framework, which constructs a learnable semantic residual prompt pool generated by category text and uses an adjustive query-prompt matching mechanism to build a mapping relationship between the query of the current task and the semantic residual prompt. Meanwhile, a semantic consistency loss based on the contrastive learning is introduced to maintain semantic coherence between object queries and residual prompts during incremental training. For task-wise learning, to ensure the correlation at the inter-task level within the query space, we introduce a concise yet powerful initialization strategy for incremental prompts. Extensive experiments on YouTube-VIS-2019 and YouTube-VIS-2021 datasets demonstrate that CRISP significantly outperforms existing continual segmentation methods in the long-term continual video instance segmentation task, avoiding catastrophic forgetting and effectively improving segmentation and classification performance. The code is available at https://github.com/01upup10/CRISP.",
    "source": "arXiv"
  },
  {
    "title": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning",
    "title_es": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning",
    "url": "https://arxiv.org/abs/2508.10433",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10433v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various tasks, but still struggle with complex mathematical reasoning. Existing research primarily focuses on dataset construction and method optimization, often overlooking two critical aspects: comprehensive knowledge-driven design and model-centric data space modeling. In this paper, we introduce We-Math 2.0, a unified system that integrates a structured mathematical knowledge system, model-centric data space modeling, and a reinforcement learning (RL)-based training paradigm to comprehensively enhance the mathematical reasoning abilities of MLLMs. The key contributions of We-Math 2.0 are fourfold: (1) MathBook Knowledge System: We construct a five-level hierarchical system encompassing 491 knowledge points and 1,819 fundamental principles. (2) MathBook-Standard & Pro: We develop MathBook-Standard, a dataset that ensures broad conceptual coverage and flexibility through dual expansion. Additionally, we define a three-dimensional difficulty space and generate 7 progressive variants per problem to build MathBook-Pro, a challenging dataset for robust training. (3) MathBook-RL: We propose a two-stage RL framework comprising: (i) Cold-Start Fine-tuning, which aligns the model with knowledge-oriented chain-of-thought reasoning; and (ii) Progressive Alignment RL, leveraging average-reward learning and dynamic data scheduling to achieve progressive alignment across difficulty levels. (4) MathBookEval: We introduce a comprehensive benchmark covering all 491 knowledge points with diverse reasoning step distributions. Experimental results show that MathBook-RL performs competitively with existing baselines on four widely-used benchmarks and achieves strong results on MathBookEval, suggesting promising generalization in mathematical reasoning.",
    "source": "arXiv"
  },
  {
    "title": "Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models",
    "title_es": "Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models",
    "url": "https://arxiv.org/abs/2508.10435",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10435v1 Announce Type: new \nAbstract: Sharpness-Aware Minimization (SAM) has been proven to be an effective optimization technique for improving generalization in overparameterized models. While prior works have explored the implicit regularization of SAM in simple two-core scale-invariant settings, its behavior in more general tensorized or scale-invariant models remains underexplored. In this work, we leverage scale-invariance to analyze the norm dynamics of SAM in general tensorized models. We introduce the notion of \\emph{Norm Deviation} as a global measure of core norm imbalance, and derive its evolution under SAM using gradient flow analysis. We show that SAM's implicit control of Norm Deviation is governed by the covariance between core norms and their gradient magnitudes. Motivated by these findings, we propose a simple yet effective method, \\emph{Deviation-Aware Scaling (DAS)}, which explicitly mimics this regularization behavior by scaling core norms in a data-adaptive manner. Our experiments across tensor completion, noisy training, model compression, and parameter-efficient fine-tuning confirm that DAS achieves competitive or improved performance over SAM, while offering reduced computational overhead.",
    "source": "arXiv"
  },
  {
    "title": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement",
    "title_es": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement",
    "url": "https://arxiv.org/abs/2508.10436",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10436v1 Announce Type: new \nAbstract: Speech enhancement using artificial neural networks aims to remove noise from noisy speech signals while preserving the speech content. However, speech enhancement networks often introduce distortions to the speech signal, referred to as artifacts, which can degrade audio quality. In this work, we propose a post-processing neural network designed to mitigate artifacts introduced by speech enhancement models. Inspired by the analogy of making a `Putt' after an `Approach' in golf, we name our model PuttNet. We demonstrate that alternating between a speech enhancement model and the proposed Putt model leads to improved speech quality, as measured by perceptual quality scores (PESQ), objective intelligibility (STOI), and background noise intrusiveness (CBAK) scores. Furthermore, we illustrate with graphical analysis why this alternating Approach outperforms repeated application of either model alone.",
    "source": "arXiv"
  },
  {
    "title": "Repairing General Game Descriptions (extended version)",
    "title_es": "Repairing General Game Descriptions (extended version)",
    "url": "https://arxiv.org/abs/2508.10438",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10438v1 Announce Type: new \nAbstract: The Game Description Language (GDL) is a widely used formalism for specifying the rules of general games. Writing correct GDL descriptions can be challenging, especially for non-experts. Automated theorem proving has been proposed to assist game design by verifying if a GDL description satisfies desirable logical properties. However, when a description is proved to be faulty, the repair task itself can only be done manually. Motivated by the work on repairing unsolvable planning domain descriptions, we define a more general problem of finding minimal repairs for GDL descriptions that violate formal requirements, and we provide complexity results for various computational problems related to minimal repair. Moreover, we present an Answer Set Programming-based encoding for solving the minimal repair problem and demonstrate its application for automatically repairing ill-defined game descriptions.",
    "source": "arXiv"
  },
  {
    "title": "DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales",
    "title_es": "DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales",
    "url": "https://arxiv.org/abs/2508.10444",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10444v1 Announce Type: new \nAbstract: Generating textual rationales from large vision-language models (LVLMs) to support trainable multimodal misinformation detectors has emerged as a promising paradigm. However, its effectiveness is fundamentally limited by three core challenges: (i) insufficient diversity in generated rationales, (ii) factual inaccuracies due to hallucinations, and (iii) irrelevant or conflicting content that introduces noise. We introduce DiFaR, a detector-agnostic framework that produces diverse, factual, and relevant rationales to enhance misinformation detection. DiFaR employs five chain-of-thought prompts to elicit varied reasoning traces from LVLMs and incorporates a lightweight post-hoc filtering module to select rationale sentences based on sentence-level factuality and relevance scores. Extensive experiments on four popular benchmarks demonstrate that DiFaR outperforms four baseline categories by up to 5.9% and boosts existing detectors by as much as 8.7%. Both automatic metrics and human evaluations confirm that DiFaR significantly improves rationale quality across all three dimensions.",
    "source": "arXiv"
  },
  {
    "title": "DOD-SA: Infrared-Visible Decoupled Object Detection with Single-Modality Annotations",
    "title_es": "DOD-SA: Infrared-Visible Decoupled Object Detection with Single-Modality Annotations",
    "url": "https://arxiv.org/abs/2508.10445",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10445v1 Announce Type: new \nAbstract: Infrared-visible object detection has shown great potential in real-world applications, enabling robust all-day perception by leveraging the complementary information of infrared and visible images. However, existing methods typically require dual-modality annotations to output detection results for both modalities during prediction, which incurs high annotation costs. To address this challenge, we propose a novel infrared-visible Decoupled Object Detection framework with Single-modality Annotations, called DOD-SA. The architecture of DOD-SA is built upon a Single- and Dual-Modality Collaborative Teacher-Student Network (CoSD-TSNet), which consists of a single-modality branch (SM-Branch) and a dual-modality decoupled branch (DMD-Branch). The teacher model generates pseudo-labels for the unlabeled modality, simultaneously supporting the training of the student model. The collaborative design enables cross-modality knowledge transfer from the labeled modality to the unlabeled modality, and facilitates effective SM-to-DMD branch supervision. To further improve the decoupling ability of the model and the pseudo-label quality, we introduce a Progressive and Self-Tuning Training Strategy (PaST) that trains the model in three stages: (1) pretraining SM-Branch, (2) guiding the learning of DMD-Branch by SM-Branch, and (3) refining DMD-Branch. In addition, we design a Pseudo Label Assigner (PLA) to align and pair labels across modalities, explicitly addressing modality misalignment during training. Extensive experiments on the DroneVehicle dataset demonstrate that our method outperforms state-of-the-art (SOTA).",
    "source": "arXiv"
  },
  {
    "title": "A Structured Framework for Prioritizing Unsafe Control Actions in STPA: Case Study on eVTOL Operations",
    "title_es": "A Structured Framework for Prioritizing Unsafe Control Actions in STPA: Case Study on eVTOL Operations",
    "url": "https://arxiv.org/abs/2508.10446",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10446v1 Announce Type: new \nAbstract: Systems Theoretic Process Analysis (STPA) is a widely recommended method for analysing complex system safety. STPA can identify numerous Unsafe Control Actions (UCAs) and requirements depending on the level of granularity of the analysis and the complexity of the system being analysed. Managing numerous results is challenging, especially during a fast-paced development lifecycle. Extensive research has been done to optimize the efficiency of managing and prioritising the STPA results. However, maintaining the objectivity of prioritisation and communicating the prioritised results have become common challenges. In this paper, the authors present a complementary approach that incorporates inputs from both the safety analysts and domain experts to more objectively prioritise UCAs. This is done by evaluating the severity of each UCA, the impact factor of each controller or decision maker that issues the UCA, and the ranking provided by the subject matter experts who assess the UCA criticalities based on different factors. In addition, a Monte Carlo simulation is introduced to reduce subjectivity and relativity, thus enabling more objective prioritisation of the UCAs. As part of the approach to better communicate the prioritisation results and plan the next steps of system development, a dynamic-scaling prioritisation matrix was developed to capture different sets of prioritised UCAs. The approach was applied to a real project to improve the safe operations of Electric Vertical Take-off and Landing (eVTOL). The results highlighted critical UCAs that need to be prioritised for safer eVTOL operation. 318 UCAs were identified in total. Based on the application of the prioritisation methodology, 110 were recognized as high-priority UCAs to strengthen the system design.",
    "source": "arXiv"
  },
  {
    "title": "SkeySpot: Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry",
    "title_es": "SkeySpot: Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry",
    "url": "https://arxiv.org/abs/2508.10449",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10449v1 Announce Type: new \nAbstract: Legacy floor plans, often preserved only as scanned documents, remain essential resources for architecture, urban planning, and facility management in the construction industry. However, the lack of machine-readable floor plans render large-scale interpretation both time-consuming and error-prone. Automated symbol spotting offers a scalable solution by enabling the identification of service key symbols directly from floor plans, supporting workflows such as cost estimation, infrastructure maintenance, and regulatory compliance. This work introduces a labelled Digitised Electrical Layout Plans (DELP) dataset comprising 45 scanned electrical layout plans annotated with 2,450 instances across 34 distinct service key classes. A systematic evaluation framework is proposed using pretrained object detection models for DELP dataset. Among the models benchmarked, YOLOv8 achieves the highest performance with a mean Average Precision (mAP) of 82.5\\%. Using YOLOv8, we develop SkeySpot, a lightweight, open-source toolkit for real-time detection, classification, and quantification of electrical symbols. SkeySpot produces structured, standardised outputs that can be scaled up for interoperable building information workflows, ultimately enabling compatibility across downstream applications and regulatory platforms. By lowering dependency on proprietary CAD systems and reducing manual annotation effort, this approach makes the digitisation of electrical layouts more accessible to small and medium-sized enterprises (SMEs) in the construction industry, while supporting broader goals of standardisation, interoperability, and sustainability in the built environment.",
    "source": "arXiv"
  },
  {
    "title": "From Images to Perception: Emergence of Perceptual Properties by Reconstructing Images",
    "title_es": "From Images to Perception: Emergence of Perceptual Properties by Reconstructing Images",
    "url": "https://arxiv.org/abs/2508.10450",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10450v1 Announce Type: new \nAbstract: A number of scientists suggested that human visual perception may emerge from image statistics, shaping efficient neural representations in early vision. In this work, a bio-inspired architecture that can accommodate several known facts in the retina-V1 cortex, the PerceptNet, has been end-to-end optimized for different tasks related to image reconstruction: autoencoding, denoising, deblurring, and sparsity regularization. Our results show that the encoder stage (V1-like layer) consistently exhibits the highest correlation with human perceptual judgments on image distortion despite not using perceptual information in the initialization or training. This alignment exhibits an optimum for moderate noise, blur and sparsity. These findings suggest that the visual system may be tuned to remove those particular levels of distortion with that level of sparsity and that biologically inspired models can learn perceptual metrics without human supervision.",
    "source": "arXiv"
  },
  {
    "title": "Trajectory-aware Shifted State Space Models for Online Video Super-Resolution",
    "title_es": "Trajectory-aware Shifted State Space Models for Online Video Super-Resolution",
    "url": "https://arxiv.org/abs/2508.10453",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10453v1 Announce Type: new \nAbstract: Online video super-resolution (VSR) is an important technique for many real-world video processing applications, which aims to restore the current high-resolution video frame based on temporally previous frames. Most of the existing online VSR methods solely employ one neighboring previous frame to achieve temporal alignment, which limits long-range temporal modeling of videos. Recently, state space models (SSMs) have been proposed with linear computational complexity and a global receptive field, which significantly improve computational efficiency and performance. In this context, this paper presents a novel online VSR method based on Trajectory-aware Shifted SSMs (TS-Mamba), leveraging both long-term trajectory modeling and low-complexity Mamba to achieve efficient spatio-temporal information aggregation. Specifically, TS-Mamba first constructs the trajectories within a video to select the most similar tokens from the previous frames. Then, a Trajectory-aware Shifted Mamba Aggregation (TSMA) module consisting of proposed shifted SSMs blocks is employed to aggregate the selected tokens. The shifted SSMs blocks are designed based on Hilbert scannings and corresponding shift operations to compensate for scanning losses and strengthen the spatial continuity of Mamba. Additionally, we propose a trajectory-aware loss function to supervise the trajectory generation, ensuring the accuracy of token selection when training our model. Extensive experiments on three widely used VSR test datasets demonstrate that compared with six online VSR benchmark models, our TS-Mamba achieves state-of-the-art performance in most cases and over 22.7\\% complexity reduction (in MACs). The source code for TS-Mamba will be available at https://github.com.",
    "source": "arXiv"
  },
  {
    "title": "RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations",
    "title_es": "RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations",
    "url": "https://arxiv.org/abs/2508.10455",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10455v1 Announce Type: new \nAbstract: Counterfactual explanations provide human-understandable reasoning for AI-made decisions by describing minimal changes to input features that would alter a model's prediction. To be truly useful in practice, such explanations must be realistic and feasible -- they should respect both the underlying data distribution and user-defined feasibility constraints. Existing approaches often enforce inter-feature dependencies through rigid, hand-crafted constraints or domain-specific knowledge, which limits their generalizability and ability to capture complex, nonlinear relations inherent in data. Moreover, they rarely accommodate user-specified preferences and suggest explanations that are causally implausible or infeasible to act upon. We introduce RealAC, a domain-agnostic framework for generating realistic and actionable counterfactuals. RealAC automatically preserves complex inter-feature dependencies without relying on explicit domain knowledge -- by aligning the joint distributions of feature pairs between factual and counterfactual instances. The framework also allows end-users to ``freeze'' attributes they cannot or do not wish to change by suppressing change in frozen features during optimization. Evaluations on three synthetic and two real datasets demonstrate that RealAC balances realism with actionability. Our method outperforms state-of-the-art baselines and Large Language Model-based counterfactual generation techniques in causal edge score, dependency preservation score, and IM1 realism metric and offers a solution for causality-aware and user-centric counterfactual generation.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers",
    "title_es": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers",
    "url": "https://arxiv.org/abs/2508.10457",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10457v1 Announce Type: new \nAbstract: We present a multi-head vision transformer approach for multi-label plant species prediction in vegetation plot images, addressing the PlantCLEF 2025 challenge. The task involves training models on single-species plant images while testing on multi-species quadrat images, creating a drastic domain shift. Our methodology leverages a pre-trained DINOv2 Vision Transformer Base (ViT-B/14) backbone with multiple classification heads for species, genus, and family prediction, utilizing taxonomic hierarchies. Key contributions include multi-scale tiling to capture plants at different scales, dynamic threshold optimization based on mean prediction length, and ensemble strategies through bagging and Hydra model architectures. The approach incorporates various inference techniques including image cropping to remove non-plant artifacts, top-n filtering for prediction constraints, and logit thresholding strategies. Experiments were conducted on approximately 1.4 million training images covering 7,806 plant species. Results demonstrate strong performance, making our submission 3rd best on the private leaderboard. Our code is available at https://github.com/geranium12/plant-clef-2025/tree/v1.0.0.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Methods for Accurate Sparse Trajectory Recovery and Map Matching",
    "title_es": "Efficient Methods for Accurate Sparse Trajectory Recovery and Map Matching",
    "url": "https://arxiv.org/abs/2508.10460",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10460v1 Announce Type: new \nAbstract: Real-world trajectories are often sparse with low-sampling rates (i.e., long intervals between consecutive GPS points) and misaligned with road networks, yet many applications demand high-quality data for optimal performance. To improve data quality with sparse trajectories as input, we systematically study two related research problems: trajectory recovery on road network, which aims to infer missing points to recover high-sampling trajectories, and map matching, which aims to map GPS points to road segments to determine underlying routes. In this paper, we present efficient methods TRMMA and MMA for accurate trajectory recovery and map matching, respectively, where MMA serves as the first step of TRMMA. In MMA, we carefully formulate a classification task to map a GPS point from sparse trajectories to a road segment over a small candidate segment set, rather than the entire road network. We develop techniques in MMA to generate effective embeddings that capture the patterns of GPS data, directional information, and road segments, to accurately align sparse trajectories to routes. For trajectory recovery, TRMMA focuses on the segments in the route returned by MMA to infer missing points with position ratios on road segments, producing high-sampling trajectories efficiently by avoiding evaluation of all road segments. Specifically, in TRMMA, we design a dual-transformer encoding process to cohesively capture latent patterns in trajectories and routes, and an effective decoding technique to sequentially predict the position ratios and road segments of missing points. We conduct extensive experiments to compare TRMMA and MMA with numerous existing methods for trajectory recovery and map matching, respectively, on 4 large real-world datasets. TRMMA and MMA consistently achieve the best result quality, often by a significant margin.",
    "source": "arXiv"
  },
  {
    "title": "X-Node: Self-Explanation is All We Need",
    "title_es": "X-Node: Self-Explanation is All We Need",
    "url": "https://arxiv.org/abs/2508.10461",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10461v1 Announce Type: new \nAbstract: Graph neural networks (GNNs) have achieved state-of-the-art results in computer vision and medical image classification tasks by capturing structural dependencies across data instances. However, their decision-making remains largely opaque, limiting their trustworthiness in high-stakes clinical applications where interpretability is essential. Existing explainability techniques for GNNs are typically post-hoc and global, offering limited insight into individual node decisions or local reasoning. We introduce X-Node, a self-explaining GNN framework in which each node generates its own explanation as part of the prediction process. For every node, we construct a structured context vector encoding interpretable cues such as degree, centrality, clustering, feature saliency, and label agreement within its local topology. A lightweight Reasoner module maps this context into a compact explanation vector, which serves three purposes: (1) reconstructing the node's latent embedding via a decoder to enforce faithfulness, (2) generating a natural language explanation using a pre-trained LLM (e.g., Grok or Gemini), and (3) guiding the GNN itself via a \"text-injection\" mechanism that feeds explanations back into the message-passing pipeline. We evaluate X-Node on two graph datasets derived from MedMNIST and MorphoMNIST, integrating it with GCN, GAT, and GIN backbones. Our results show that X-Node maintains competitive classification accuracy while producing faithful, per-node explanations. Repository: https://github.com/basiralab/X-Node.",
    "source": "arXiv"
  },
  {
    "title": "SingleStrip: learning skull-stripping from a single labeled example",
    "title_es": "SingleStrip: learning skull-stripping from a single labeled example",
    "url": "https://arxiv.org/abs/2508.10464",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10464v1 Announce Type: new \nAbstract: Deep learning segmentation relies heavily on labeled data, but manual labeling is laborious and time-consuming, especially for volumetric images such as brain magnetic resonance imaging (MRI). While recent domain-randomization techniques alleviate the dependency on labeled data by synthesizing diverse training images from label maps, they offer limited anatomical variability when very few label maps are available. Semi-supervised self-training addresses label scarcity by iteratively incorporating model predictions into the training set, enabling networks to learn from unlabeled data. In this work, we combine domain randomization with self-training to train three-dimensional skull-stripping networks using as little as a single labeled example. First, we automatically bin voxel intensities, yielding labels we use to synthesize images for training an initial skull-stripping model. Second, we train a convolutional autoencoder (AE) on the labeled example and use its reconstruction error to assess the quality of brain masks predicted for unlabeled data. Third, we select the top-ranking pseudo-labels to fine-tune the network, achieving skull-stripping performance on out-of-distribution data that approaches models trained with more labeled images. We compare AE-based ranking to consistency-based ranking under test-time augmentation, finding that the AE approach yields a stronger correlation with segmentation accuracy. Our results highlight the potential of combining domain randomization and AE-based quality control to enable effective semi-supervised segmentation from extremely limited labeled data. This strategy may ease the labeling burden that slows progress in studies involving new anatomical structures or emerging imaging techniques.",
    "source": "arXiv"
  },
  {
    "title": "Online Homogeneity Can Emerge Without Filtering Algorithms or Homophily Preferences",
    "title_es": "Online Homogeneity Can Emerge Without Filtering Algorithms or Homophily Preferences",
    "url": "https://arxiv.org/abs/2508.10466",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10466v1 Announce Type: new \nAbstract: Ideologically homogeneous online environments - often described as \"echo chambers\" or \"filter bubbles\" - are widely seen as drivers of polarization, radicalization, and misinformation. A central debate asks whether such homophily stems primarily from algorithmic curation or users' preference for like-minded peers. This study challenges that view by showing that homogeneity can emerge in the absence of both filtering algorithms and user preferences. Using an agent-based model inspired by Schelling's model of residential segregation, we demonstrate that weak individual preferences, combined with simple group-based interaction structures, can trigger feedback loops that drive communities toward segregation. Once a small imbalance forms, cascades of user exits and regrouping amplify homogeneity across the system. Counterintuitively, algorithmic filtering - often blamed for \"filter bubbles\" - can in fact sustain diversity by stabilizing mixed communities. These findings highlight online polarization as an emergent system-level dynamic and underscore the importance of applying a complexity lens to the study of digital public spheres.",
    "source": "arXiv"
  },
  {
    "title": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs",
    "title_es": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs",
    "url": "https://arxiv.org/abs/2508.10467",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10467v1 Announce Type: new \nAbstract: Question answering over Scholarly Knowledge Graphs (SKGs) remains a challenging task due to the complexity of scholarly content and the intricate structure of these graphs. Large Language Model (LLM) approaches could be used to translate natural language questions (NLQs) into SPARQL queries; however, these LLM-based approaches struggle with SPARQL query generation due to limited exposure to SKG-specific content and the underlying schema. We identified two main types of errors in the LLM-generated SPARQL queries: (i) structural inconsistencies, such as missing or redundant triples in the queries, and (ii) semantic inaccuracies, where incorrect entities or properties are shown in the queries despite a correct query structure. To address these issues, we propose FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core component, with optional context provided via retrieval-augmented generation (RAG) and a SPARQL query correction layer. We evaluate the framework on the SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG, one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance with baseline and state-of-the-art approaches. We measure query accuracy using BLEU and ROUGE metrics, and query result accuracy using relaxed exact match(RelaxedEM), with respect to the gold standards containing the NLQs, SPARQL queries, and the results of the queries. Experimental results demonstrate that fine-tuning achieves the highest overall performance, reaching 0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the test set.",
    "source": "arXiv"
  },
  {
    "title": "Stress Detection from Multimodal Wearable Sensor Data",
    "title_es": "Stress Detection from Multimodal Wearable Sensor Data",
    "url": "https://arxiv.org/abs/2508.10468",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10468v1 Announce Type: new \nAbstract: Human-Computer Interaction (HCI) is a multi-modal, interdisciplinary field focused on designing, studying, and improving the interactions between people and computer systems. This involves the design of systems that can recognize, interpret, and respond to human emotions or stress. Developing systems to monitor and react to stressful events can help prevent severe health implications caused by long-term stress exposure. Currently, the publicly available datasets and standardized protocols for data collection in this domain are limited. Therefore, we introduce a multi-modal dataset intended for wearable affective computing research, specifically the development of automated stress recognition systems. We systematically review the publicly available datasets recorded in controlled laboratory settings. Based on a proposed framework for the standardization of stress experiments and data collection, we collect physiological and motion signals from wearable devices (e.g., electrodermal activity, photoplethysmography, three-axis accelerometer). During the experimental protocol, we differentiate between the following four affective/activity states: neutral, physical, cognitive stress, and socio-evaluative stress. These different phases are meticulously labeled, allowing for detailed analysis and reconstruction of each experiment. Meta-data such as body positions, locations, and rest phases are included as further annotations. In addition, we collect psychological self-assessments after each stressor to evaluate subjects' affective states. The contributions of this paper are twofold: 1) a novel multi-modal, publicly available dataset for automated stress recognition, and 2) a benchmark for stress detection with 89\\% in a binary classification (baseline vs. stress) and 82\\% in a multi-class classification (baseline vs. stress vs. physical exercise).",
    "source": "arXiv"
  },
  {
    "title": "Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition",
    "title_es": "Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition",
    "url": "https://arxiv.org/abs/2508.10469",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10469v1 Announce Type: new \nAbstract: Human Action Recognition (HAR) plays a crucial role in healthcare, fitness tracking, and ambient assisted living technologies. While traditional vision based HAR systems are effective, they pose privacy concerns. mmWave radar sensors offer a privacy preserving alternative but present challenges due to the sparse and noisy nature of their point cloud data. In the literature, three primary data processing methods: Density-Based Spatial Clustering of Applications with Noise (DBSCAN), the Hungarian Algorithm, and Kalman Filtering have been widely used to improve the quality and continuity of radar data. However, a comprehensive evaluation of these methods, both individually and in combination, remains lacking. This paper addresses that gap by conducting a detailed performance analysis of the three methods using the MiliPoint dataset. We evaluate each method individually, all possible pairwise combinations, and the combination of all three, assessing both recognition accuracy and computational cost. Furthermore, we propose targeted enhancements to the individual methods aimed at improving accuracy. Our results provide crucial insights into the strengths and trade-offs of each method and their integrations, guiding future work on mmWave based HAR systems",
    "source": "arXiv"
  },
  {
    "title": "GraphFedMIG: Tackling Class Imbalance in Federated Graph Learning via Mutual Information-Guided Generation",
    "title_es": "GraphFedMIG: Tackling Class Imbalance in Federated Graph Learning via Mutual Information-Guided Generation",
    "url": "https://arxiv.org/abs/2508.10471",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10471v1 Announce Type: new \nAbstract: Federated graph learning (FGL) enables multiple clients to collaboratively train powerful graph neural networks without sharing their private, decentralized graph data. Inherited from generic federated learning, FGL is critically challenged by statistical heterogeneity, where non-IID data distributions across clients can severely impair model performance. A particularly destructive form of this is class imbalance, which causes the global model to become biased towards majority classes and fail at identifying rare but critical events. This issue is exacerbated in FGL, as nodes from a minority class are often surrounded by biased neighborhood information, hindering the learning of expressive embeddings. To grapple with this challenge, we propose GraphFedMIG, a novel FGL framework that reframes the problem as a federated generative data augmentation task. GraphFedMIG employs a hierarchical generative adversarial network where each client trains a local generator to synthesize high-fidelity feature representations. To provide tailored supervision, clients are grouped into clusters, each sharing a dedicated discriminator. Crucially, the framework designs a mutual information-guided mechanism to steer the evolution of these client generators. By calculating each client's unique informational value, this mechanism corrects the local generator parameters, ensuring that subsequent rounds of mutual information-guided generation are focused on producing high-value, minority-class features. We conduct extensive experiments on four real-world datasets, and the results demonstrate the superiority of the proposed GraphFedMIG compared with other baselines.",
    "source": "arXiv"
  },
  {
    "title": "Motive-level Analysis of Form-functions Association in Korean Folk song",
    "title_es": "Motive-level Analysis of Form-functions Association in Korean Folk song",
    "url": "https://arxiv.org/abs/2508.10472",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10472v1 Announce Type: new \nAbstract: Computational analysis of folk song audio is challenging due to structural irregularities and the need for manual annotation. We propose a method for automatic motive segmentation in Korean folk songs by fine-tuning a speech transcription model on audio lyric with motif boundary annotation. Applying this to 856 songs, we extracted motif count and duration entropy as structural features. Statistical analysis revealed that these features vary systematically according to the social function of the songs. Songs associated with collective labor, for instance, showed different structural patterns from those for entertainment or personal settings. This work offers a scalable approach for quantitative structural analysis of oral music traditions.",
    "source": "arXiv"
  },
  {
    "title": "STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images",
    "title_es": "STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images",
    "url": "https://arxiv.org/abs/2508.10473",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10473v1 Announce Type: new \nAbstract: Spread through air spaces (STAS) constitutes a novel invasive pattern in lung adenocarcinoma (LUAD), associated with tumor recurrence and diminished survival rates. However, large-scale STAS diagnosis in LUAD remains a labor-intensive endeavor, compounded by the propensity for oversight and misdiagnosis due to its distinctive pathological characteristics and morphological features. Consequently, there is a pressing clinical imperative to leverage deep learning models for STAS diagnosis. This study initially assembled histopathological images from STAS patients at the Second Xiangya Hospital and the Third Xiangya Hospital of Central South University, alongside the TCGA-LUAD cohort. Three senior pathologists conducted cross-verification annotations to construct the STAS-SXY, STAS-TXY, and STAS-TCGA datasets. We then propose a multi-pattern attention-aware multiple instance learning framework, named STAMP, to analyze and diagnose the presence of STAS across multi-center histopathology images. Specifically, the dual-branch architecture guides the model to learn STAS-associated pathological features from distinct semantic spaces. Transformer-based instance encoding and a multi-pattern attention aggregation modules dynamically selects regions closely associated with STAS pathology, suppressing irrelevant noise and enhancing the discriminative power of global representations. Moreover, a similarity regularization constraint prevents feature redundancy across branches, thereby improving overall diagnostic accuracy. Extensive experiments demonstrated that STAMP achieved competitive diagnostic results on STAS-SXY, STAS-TXY and STAS-TCGA, with AUCs of 0.8058, 0.8017, and 0.7928, respectively, surpassing the clinical level.",
    "source": "arXiv"
  },
  {
    "title": "EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation",
    "title_es": "EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation",
    "url": "https://arxiv.org/abs/2508.10474",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10474v1 Announce Type: new \nAbstract: Brain-computer interfaces (BCIs) suffer from accuracy degradation as neural signals drift over time and vary across users, requiring frequent recalibration that limits practical deployment. We introduce EDAPT, a task- and model-agnostic framework that eliminates calibration through continual model adaptation. EDAPT first trains a baseline decoder using data from multiple users, then continually personalizes this model via supervised finetuning as the neural patterns evolve during use. We tested EDAPT across nine datasets covering three BCI tasks, and found that it consistently improved accuracy over conventional, static methods. These improvements primarily stem from combining population-level pretraining and online continual finetuning, with unsupervised domain adaptation providing further gains on some datasets. EDAPT runs efficiently, updating models within 200 milliseconds on consumer-grade hardware. Finally, decoding accuracy scales with total data budget rather than its allocation between subjects and trials. EDAPT provides a practical pathway toward calibration-free BCIs, reducing a major barrier to BCI deployment.",
    "source": "arXiv"
  },
  {
    "title": "Semantic IDs for Joint Generative Search and Recommendation",
    "title_es": "Semantic IDs for Joint Generative Search and Recommendation",
    "url": "https://arxiv.org/abs/2508.10478",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10478v1 Announce Type: new \nAbstract: Generative models powered by Large Language Models (LLMs) are emerging as a unified solution for powering both recommendation and search tasks. A key design choice in these models is how to represent items, traditionally through unique identifiers (IDs) and more recently with Semantic IDs composed of discrete codes, obtained from embeddings. While task-specific embedding models can improve performance for individual tasks, they may not generalize well in a joint setting. In this paper, we explore how to construct Semantic IDs that perform well both in search and recommendation when using a unified model. We compare a range of strategies to construct Semantic IDs, looking into task-specific and cross-tasks approaches, and also whether each task should have its own semantic ID tokens in a joint search and recommendation generative model. Our results show that using a bi-encoder model fine-tuned on both search and recommendation tasks to obtain item embeddings, followed by the construction of a unified Semantic ID space provides an effective trade-off, enabling strong performance in both tasks. We hope these findings spark follow-up work on generalisable, semantically grounded ID schemes and inform the next wave of unified generative recommender architectures.",
    "source": "arXiv"
  },
  {
    "title": "Confounding is a Pervasive Problem in Real World Recommender Systems",
    "title_es": "Confounding is a Pervasive Problem in Real World Recommender Systems",
    "url": "https://arxiv.org/abs/2508.10479",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10479v1 Announce Type: new \nAbstract: Unobserved confounding arises when an unmeasured feature influences both the treatment and the outcome, leading to biased causal effect estimates. This issue undermines observational studies in fields like economics, medicine, ecology or epidemiology. Recommender systems leveraging fully observed data seem not to be vulnerable to this problem. However many standard practices in recommender systems result in observed features being ignored, resulting in effectively the same problem. This paper will show that numerous common practices such as feature engineering, A/B testing and modularization can in fact introduce confounding into recommendation systems and hamper their performance. Several illustrations of the phenomena are provided, supported by simulation studies with practical suggestions about how practitioners may reduce or avoid the affects of confounding in real systems.",
    "source": "arXiv"
  },
  {
    "title": "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers",
    "title_es": "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers",
    "url": "https://arxiv.org/abs/2508.10480",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10480v1 Announce Type: new \nAbstract: We introduce an output layer for neural networks that ensures satisfaction of convex constraints. Our approach, $\\Pi$net, leverages operator splitting for rapid and reliable projections in the forward pass, and the implicit function theorem for backpropagation. We deploy $\\Pi$net as a feasible-by-design optimization proxy for parametric constrained optimization problems and obtain modest-accuracy solutions faster than traditional solvers when solving a single problem, and significantly faster for a batch of problems. We surpass state-of-the-art learning approaches in terms of training time, solution quality, and robustness to hyperparameter tuning, while maintaining similar inference times. Finally, we tackle multi-vehicle motion planning with non-convex trajectory preferences and provide $\\Pi$net as a GPU-ready package implemented in JAX with effective tuning heuristics.",
    "source": "arXiv"
  },
  {
    "title": "Dalek: An Unconventional and Energy-Aware Heterogeneous Cluster",
    "title_es": "Dalek: An Unconventional and Energy-Aware Heterogeneous Cluster",
    "url": "https://arxiv.org/abs/2508.10481",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10481v1 Announce Type: new \nAbstract: Dalek is an experimental compute cluster designed to evaluate the performance of heterogeneous, consumer-grade hardware for software design, prototyping, and algorithm development. In contrast to traditional computing centers that rely on costly, server-class components, Dalek integrates CPUs and GPUs typically found in mini-PCs, laptops, and gaming desktops, providing a cost-effective yet versatile platform. This document details the cluster's architecture and software stack, and presents results from synthetic benchmarks. Furthermore, it introduces a custom energy monitoring platform capable of delivering 1000 averaged samples per second with milliwatt-level resolution. This high-precision monitoring capability enables a wide range of energy-aware research experiments in applied Computer Science.",
    "source": "arXiv"
  },
  {
    "title": "When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing",
    "title_es": "When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing",
    "url": "https://arxiv.org/abs/2508.10482",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10482v1 Announce Type: new \nAbstract: In the study of trustworthy Natural Language Processing (NLP), a number of important research fields have emerged, including that of \\textit{explainability} and \\textit{privacy}. While research interest in both explainable and privacy-preserving NLP has increased considerably in recent years, there remains a lack of investigation at the intersection of the two. This leaves a considerable gap in understanding of whether achieving \\textit{both} explainability and privacy is possible, or whether the two are at odds with each other. In this work, we conduct an empirical investigation into the privacy-explainability trade-off in the context of NLP, guided by the popular overarching methods of \\textit{Differential Privacy} (DP) and Post-hoc Explainability. Our findings include a view into the intricate relationship between privacy and explainability, which is formed by a number of factors, including the nature of the downstream task and choice of the text privatization and explainability method. In this, we highlight the potential for privacy and explainability to co-exist, and we summarize our findings in a collection of practical recommendations for future work at this important intersection.",
    "source": "arXiv"
  },
  {
    "title": "SEQ-GPT: LLM-assisted Spatial Query via Example",
    "title_es": "SEQ-GPT: LLM-assisted Spatial Query via Example",
    "url": "https://arxiv.org/abs/2508.10486",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10486v1 Announce Type: new \nAbstract: Contemporary spatial services such as online maps predominantly rely on user queries for location searches. However, the user experience is limited when performing complex tasks, such as searching for a group of locations simultaneously. In this study, we examine the extended scenario known as Spatial Exemplar Query (SEQ), where multiple relevant locations are jointly searched based on user-specified examples. We introduce SEQ-GPT, a spatial query system powered by Large Language Models (LLMs) towards more versatile SEQ search using natural language. The language capabilities of LLMs enable unique interactive operations in the SEQ process, including asking users to clarify query details and dynamically adjusting the search based on user feedback. We also propose a tailored LLM adaptation pipeline that aligns natural language with structured spatial data and queries through dialogue synthesis and multi-model cooperation. SEQ-GPT offers an end-to-end demonstration for broadening spatial search with realistic data and application scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Learning State-Space Models of Dynamic Systems from Arbitrary Data using Joint Embedding Predictive Architectures",
    "title_es": "Learning State-Space Models of Dynamic Systems from Arbitrary Data using Joint Embedding Predictive Architectures",
    "url": "https://arxiv.org/abs/2508.10489",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10489v1 Announce Type: new \nAbstract: With the advent of Joint Embedding Predictive Architectures (JEPAs), which appear to be more capable than reconstruction-based methods, this paper introduces a novel technique for creating world models using continuous-time dynamic systems from arbitrary observation data. The proposed method integrates sequence embeddings with neural ordinary differential equations (neural ODEs). It employs loss functions that enforce contractive embeddings and Lipschitz constants in state transitions to construct a well-organized latent state space. The approach's effectiveness is demonstrated through the generation of structured latent state-space models for a simple pendulum system using only image data. This opens up a new technique for developing more general control algorithms and estimation techniques with broad applications in robotics.",
    "source": "arXiv"
  },
  {
    "title": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations",
    "title_es": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations",
    "url": "https://arxiv.org/abs/2508.10490",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10490v1 Announce Type: new \nAbstract: ReLU networks, while prevalent for visual data, have sharp transitions, sometimes relying on individual pixels for predictions, making vanilla gradient-based explanations noisy and difficult to interpret. Existing methods, such as GradCAM, smooth these explanations by producing surrogate models at the cost of faithfulness. We introduce a unifying spectral framework to systematically analyze and quantify smoothness, faithfulness, and their trade-off in explanations. Using this framework, we quantify and regularize the contribution of ReLU networks to high-frequency information, providing a principled approach to identifying this trade-off. Our analysis characterizes how surrogate-based smoothing distorts explanations, leading to an ``explanation gap'' that we formally define and measure for different post-hoc methods. Finally, we validate our theoretical findings across different design choices, datasets, and ablations.",
    "source": "arXiv"
  },
  {
    "title": "Contrastive ECOC: Learning Output Codes for Adversarial Defense",
    "title_es": "Contrastive ECOC: Learning Output Codes for Adversarial Defense",
    "url": "https://arxiv.org/abs/2508.10491",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10491v1 Announce Type: new \nAbstract: Although one-hot encoding is commonly used for multiclass classification, it is not always the most effective encoding mechanism. Error Correcting Output Codes (ECOC) address multiclass classification by mapping each class to a unique codeword used as a label. Traditional ECOC methods rely on manually designed or randomly generated codebooks, which are labor-intensive and may yield suboptimal, dataset-agnostic results. This paper introduces three models for automated codebook learning based on contrastive learning, allowing codebooks to be learned directly and adaptively from data. Across four datasets, our proposed models demonstrate superior robustness to adversarial attacks compared to two baselines. The source is available at https://github.com/YuChou20/Automated-Codebook-Learning-with-Error-Correcting-Output-Code-Technique.",
    "source": "arXiv"
  },
  {
    "title": "Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model",
    "title_es": "Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model",
    "url": "https://arxiv.org/abs/2508.10492",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10492v1 Announce Type: new \nAbstract: Full-process clinical diagnosis in the real world encompasses the entire diagnostic workflow that begins with only an ambiguous chief complaint. While artificial intelligence (AI), particularly large language models (LLMs), is transforming clinical diagnosis, its role remains largely as an assistant to physicians. This AI-assisted working pattern makes AI can only answer specific medical questions at certain parts within the diagnostic process, but lack the ability to drive the entire diagnostic process starting from an ambiguous complaint, which still relies heavily on human physicians. This gap limits AI's ability to fully reduce physicians' workload and enhance diagnostic efficiency. To address this, we propose a paradigm shift that reverses the relationship between physicians and AI: repositioning AI as the primary director, with physicians serving as its assistants. So we present DxDirector-7B, an LLM endowed with advanced deep thinking capabilities, enabling it to drive the full-process diagnosis with minimal physician involvement. Furthermore, DxDirector-7B establishes a robust accountability framework for misdiagnoses, delineating responsibility between AI and human physicians. In evaluations across rare, complex, and real-world cases under full-process diagnosis setting, DxDirector-7B not only achieves significant superior diagnostic accuracy but also substantially reduces physician workload than state-of-the-art medical LLMs as well as general-purpose LLMs. Fine-grained analyses across multiple clinical departments and tasks validate its efficacy, with expert evaluations indicating its potential to serve as a viable substitute for medical specialists. These findings mark a new era where AI, traditionally a physicians' assistant, now drives the entire diagnostic process to drastically reduce physicians' workload, indicating an efficient and accurate diagnostic solution.",
    "source": "arXiv"
  },
  {
    "title": "AlDBaran: Towards Blazingly Fast State Commitments for Blockchains",
    "title_es": "AlDBaran: Towards Blazingly Fast State Commitments for Blockchains",
    "url": "https://arxiv.org/abs/2508.10493",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10493v1 Announce Type: new \nAbstract: The fundamental basis for maintaining integrity within contemporary blockchain systems is provided by authenticated databases. Our analysis indicates that a significant portion of the approaches applied in this domain fail to sufficiently meet the stringent requirements of systems processing transactions at rates of multi-million TPS. AlDBaran signifies a substantial advancement in authenticated databases. By eliminating disk I/O operations from the critical path, implementing prefetching strategies, and refining the update mechanism of the Merkle tree, we have engineered an authenticated data structure capable of handling state updates efficiently at a network throughput of 50 Gbps. This throughput capacity significantly surpasses any empirically documented blockchain throughput, guaranteeing the ability of even the most high-throughput blockchains to generate state commitments effectively.\n  AlDBaran provides support for historical state proofs, which facilitates a wide array of novel applications. For instance, the deployment of AlDBaran could enable blockchains that do not currently support state commitments to offer functionalities for light clients and/or implement rollups.\n  When benchmarked against alternative authenticated data structure projects, AlDBaran exhibits superior performance and simplicity. In particular, AlDBaran achieves speeds of approximately 48 million updates per second using an identical machine configuration. This characteristic renders AlDBaran an attractive solution for resource-limited environments, as its historical data capabilities can be modularly isolated (and deactivated), which further enhances performance. On consumer-level portable hardware, it achieves approximately 8 million updates/s in an in-memory setting and 5 million updates/s with snapshots at sub-second intervals, illustrating compelling and cost-effective scalability.",
    "source": "arXiv"
  },
  {
    "title": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation",
    "title_es": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation",
    "url": "https://arxiv.org/abs/2508.10494",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10494v1 Announce Type: new \nAbstract: Real-world multimodal applications often require any-to-any capabilities, enabling both understanding and generation across modalities including text, image, audio, and video. However, integrating the strengths of autoregressive language models (LLMs) for reasoning and diffusion models for high-fidelity generation remains challenging. Existing approaches rely on rigid pipelines or tightly coupled architectures, limiting flexibility and scalability. We propose MAGUS (Multi-Agent Guided Unified Multimodal System), a modular framework that unifies multimodal understanding and generation via two decoupled phases: Cognition and Deliberation. MAGUS enables symbolic multi-agent collaboration within a shared textual workspace. In the Cognition phase, three role-conditioned multimodal LLM agents - Perceiver, Planner, and Reflector - engage in collaborative dialogue to perform structured understanding and planning. The Deliberation phase incorporates a Growth-Aware Search mechanism that orchestrates LLM-based reasoning and diffusion-based generation in a mutually reinforcing manner. MAGUS supports plug-and-play extensibility, scalable any-to-any modality conversion, and semantic alignment - all without the need for joint training. Experiments across multiple benchmarks, including image, video, and audio generation, as well as cross-modal instruction following, demonstrate that MAGUS outperforms strong baselines and state-of-the-art systems. Notably, on the MME benchmark, MAGUS surpasses the powerful closed-source model GPT-4o.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Patent Searching Using Graph Transformers",
    "title_es": "Efficient Patent Searching Using Graph Transformers",
    "url": "https://arxiv.org/abs/2508.10496",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10496v1 Announce Type: new \nAbstract: Finding relevant prior art is crucial when deciding whether to file a new patent application or invalidate an existing patent. However, searching for prior art is challenging due to the large number of patent documents and the need for nuanced comparisons to determine novelty. An accurate search engine is therefore invaluable for speeding up the process. We present a Graph Transformer-based dense retrieval method for patent searching where each invention is represented by a graph describing its features and their relationships. Our model processes these invention graphs and is trained using prior art citations from patent office examiners as relevance signals. Using graphs as input significantly improves the computational efficiency of processing long documents, while leveraging examiner citations allows the model to learn domain-specific similarities beyond simple text-based matching. The result is a search engine that emulates how professional patent examiners identify relevant documents. We compare our approach against publicly available text embedding models and show substantial improvements in both prior art retrieval quality and computational efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Enabling Generic Robot Skill Implementation Using Object Oriented Programming",
    "title_es": "Enabling Generic Robot Skill Implementation Using Object Oriented Programming",
    "url": "https://arxiv.org/abs/2508.10497",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10497v1 Announce Type: new \nAbstract: Developing robotic algorithms and integrating a robotic subsystem into a larger system can be a difficult task. Particularly in small and medium-sized enterprises (SMEs) where robotics expertise is lacking, implementing, maintaining and developing robotic systems can be a challenge. As a result, many companies rely on external expertise through system integrators, which, in some cases, can lead to vendor lock-in and external dependency. In the academic research on intelligent manufacturing systems, robots play a critical role in the design of robust autonomous systems. Similar challenges are faced by researchers who want to use robotic systems as a component in a larger smart system, without having to deal with the complexity and vastness of the robot interfaces in detail. In this paper, we propose a software framework that reduces the effort required to deploy a working robotic system. The focus is solely on providing a concept for simplifying the different interfaces of a modern robot system and using an abstraction layer for different manufacturers and models. The Python programming language is used to implement a prototype of the concept. The target system is a bin-picking cell containing a Yaskawa Motoman GP4.",
    "source": "arXiv"
  },
  {
    "title": "TweezeEdit: Consistent and Efficient Image Editing with Path Regularization",
    "title_es": "TweezeEdit: Consistent and Efficient Image Editing with Path Regularization",
    "url": "https://arxiv.org/abs/2508.10498",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10498v1 Announce Type: new \nAbstract: Large-scale pre-trained diffusion models empower users to edit images through text guidance. However, existing methods often over-align with target prompts while inadequately preserving source image semantics. Such approaches generate target images explicitly or implicitly from the inversion noise of the source images, termed the inversion anchors. We identify this strategy as suboptimal for semantic preservation and inefficient due to elongated editing paths. We propose TweezeEdit, a tuning- and inversion-free framework for consistent and efficient image editing. Our method addresses these limitations by regularizing the entire denoising path rather than relying solely on the inversion anchors, ensuring source semantic retention and shortening editing paths. Guided by gradient-driven regularization, we efficiently inject target prompt semantics along a direct path using a consistency model. Extensive experiments demonstrate TweezeEdit's superior performance in semantic preservation and target alignment, outperforming existing methods. Remarkably, it requires only 12 steps (1.6 seconds per edit), underscoring its potential for real-time applications.",
    "source": "arXiv"
  },
  {
    "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning",
    "title_es": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning",
    "url": "https://arxiv.org/abs/2508.10501",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10501v1 Announce Type: new \nAbstract: Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems.",
    "source": "arXiv"
  },
  {
    "title": "Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria",
    "title_es": "Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria",
    "url": "https://arxiv.org/abs/2508.10504",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10504v1 Announce Type: new \nAbstract: In this paper, we present ASPEN+, which extends an existing ASP-based system, ASPEN,for collective entity resolution with two important functionalities: support for local merges and new optimality criteria for preferred solutions. Indeed, ASPEN only supports so-called global merges of entity-referring constants (e.g. author ids), in which all occurrences of matched constants are treated as equivalent and merged accordingly. However, it has been argued that when resolving data values, local merges are often more appropriate, as e.g. some instances of 'J. Lee' may refer to 'Joy Lee', while others should be matched with 'Jake Lee'. In addition to allowing such local merges, ASPEN+ offers new optimality criteria for selecting solutions, such as minimizing rule violations or maximising the number of rules supporting a merge. Our main contributions are thus (1) the formalisation and computational analysis of various notions of optimal solution, and (2) an extensive experimental evaluation on real-world datasets, demonstrating the effect of local merges and the new optimality criteria on both accuracy and runtime.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting",
    "title_es": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting",
    "url": "https://arxiv.org/abs/2508.10507",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10507v1 Announce Type: new \nAbstract: Recent advances in 3D Gaussian splatting have significantly improved real-time novel view synthesis, yet insufficient geometric constraints during scene optimization often result in blurred reconstructions of fine-grained details, particularly in regions with high-frequency textures and sharp discontinuities. To address this, we propose a comprehensive optimization framework integrating multisample anti-aliasing (MSAA) with dual geometric constraints. Our system computes pixel colors through adaptive blending of quadruple subsamples, effectively reducing aliasing artifacts in high-frequency components. The framework introduces two constraints: (a) an adaptive weighting strategy that prioritizes under-reconstructed regions through dynamic gradient analysis, and (b) gradient differential constraints enforcing geometric regularization at object boundaries. This targeted optimization enables the model to allocate computational resources preferentially to critical regions requiring refinement while maintaining global consistency. Extensive experimental evaluations across multiple benchmarks demonstrate that our method achieves state-of-the-art performance in detail preservation, particularly in preserving high-frequency textures and sharp discontinuities, while maintaining real-time rendering efficiency. Quantitative metrics and perceptual studies confirm statistically significant improvements over baseline approaches in both structural similarity (SSIM) and perceptual quality (LPIPS).",
    "source": "arXiv"
  },
  {
    "title": "A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection",
    "title_es": "A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection",
    "url": "https://arxiv.org/abs/2508.10509",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10509v1 Announce Type: new \nAbstract: Bolt defect detection is critical to ensure the safety of transmission lines. However, the scarcity of defect images and imbalanced data distributions significantly limit detection performance. To address this problem, we propose a segmentationdriven bolt defect editing method (SBDE) to augment the dataset. First, a bolt attribute segmentation model (Bolt-SAM) is proposed, which enhances the segmentation of complex bolt attributes through the CLAHE-FFT Adapter (CFA) and Multipart- Aware Mask Decoder (MAMD), generating high-quality masks for subsequent editing tasks. Second, a mask optimization module (MOD) is designed and integrated with the image inpainting model (LaMa) to construct the bolt defect attribute editing model (MOD-LaMa), which converts normal bolts into defective ones through attribute editing. Finally, an editing recovery augmentation (ERA) strategy is proposed to recover and put the edited defect bolts back into the original inspection scenes and expand the defect detection dataset. We constructed multiple bolt datasets and conducted extensive experiments. Experimental results demonstrate that the bolt defect images generated by SBDE significantly outperform state-of-the-art image editing models, and effectively improve the performance of bolt defect detection, which fully verifies the effectiveness and application potential of the proposed method. The code of the project is available at https://github.com/Jay-xyj/SBDE.",
    "source": "arXiv"
  },
  {
    "title": "Codes on any Cayley Graph have an Interactive Oracle Proof of Proximity",
    "title_es": "Codes on any Cayley Graph have an Interactive Oracle Proof of Proximity",
    "url": "https://arxiv.org/abs/2508.10510",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10510v1 Announce Type: new \nAbstract: Interactive Oracle Proofs of Proximity (IOPP) are at the heart of code-based SNARKs, a family of zeroknowledge protocols. The first and most famous one is the FRI protocol [BBHR18a], that efficiently tests proximity to Reed-Solomon codes. This paper generalizes the flowering IOPP introduced in [DMR25] for some specific (2, n)-regular Tanner codes to a much broader variety of codes: any code with symbols indexed on the edges of a Cayley graph. The flowering protocol of [DMR25] had a soundness parameter much lower than the FRI protocol [BCI + 23], and complexity parameters that could compete with the FRI [BBHR18a]. The lower soundness and the absence of restriction on the base field may lead to other practical speedups, however the codes considered in [DMR25] have an o(1) minimum distance. The generalization proposed in this paper preserves the soundness parameter with a slight decrease of the complexity parameters, while allowing being applied on codes with constant rate and constant minimum distance thanks to the good expansion properties of some families of Cayley graphs.",
    "source": "arXiv"
  },
  {
    "title": "KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection",
    "title_es": "KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection",
    "url": "https://arxiv.org/abs/2508.10511",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10511v1 Announce Type: new \nAbstract: Learning robot policies that capture multimodality in the training data has been a long-standing open challenge for behavior cloning. Recent approaches tackle the problem by modeling the conditional action distribution with generative models. One of these approaches is Diffusion Policy, which relies on a diffusion model to denoise random points into robot action trajectories. While achieving state-of-the-art performance, it has two main drawbacks that may lead the robot out of the data distribution during policy execution. First, the stochasticity of the denoising process can highly impact on the quality of generated trajectory of actions. Second, being a supervised learning approach, it can learn data outliers from the dataset used for training. Recent work focuses on mitigating these limitations by combining Diffusion Policy either with large-scale training or with classical behavior cloning algorithms. Instead, we propose KDPE, a Kernel Density Estimation-based strategy that filters out potentially harmful trajectories output of Diffusion Policy while keeping a low test-time computational overhead. For Kernel Density Estimation, we propose a manifold-aware kernel to model a probability density function for actions composed of end-effector Cartesian position, orientation, and gripper state. KDPE overall achieves better performance than Diffusion Policy on simulated single-arm tasks and real robot experiments.\n  Additional material and code are available on our project page https://hsp-iit.github.io/KDPE/.",
    "source": "arXiv"
  },
  {
    "title": "Product Of Exponentials (POE) Splines on Lie-Groups: Limitations, Extensions, and Application to SO(3) and SE(3)",
    "title_es": "Product Of Exponentials (POE) Splines on Lie-Groups: Limitations, Extensions, and Application to SO(3) and SE(3)",
    "url": "https://arxiv.org/abs/2508.10513",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10513v1 Announce Type: new \nAbstract: Existing methods for constructing splines and Bezier curves on a Lie group G involve repeated products of exponentials deduced from local geodesics, w.r.t. a Riemannian metric, or rely on general polynomials. Moreover, each of these local curves is supposed to start at the identity of $G$. Both assumptions may not reflect the actual curve to be interpolated. This paper pursues a different approach to construct splines on $G$. Local curves are expressed as solutions of the Poisson equation on G. Therewith, the local interpolations satisfies the boundary conditions while respecting the geometry of $G$. A $k$th-order approximation of the solutions gives rise to a $k$th-order product of exponential (POE) spline. Algorithms for constructing 3rd- and 4th-order splines are derived from closed form expressions for the approximate solutions. Additionally, spline algorithms are introduced that allow prescribing a vector field the curve must follow at the interpolation points. It is shown that the established algorithms, where $k$th-order POE-splines are constructed by concatenating local curves starting at the identity, cannot exactly reconstruct a $k$th-order motion. To tackle this issue, the formulations are extended by allowing for local curves between arbitrary points, rather than curves emanating from the identity. This gives rise to a global $k$th-order spline with arbitrary initial conditions. Several examples are presented, in particular the shape reconstruction of slender rods modeled as geometrically non-linear Cosserat rods.",
    "source": "arXiv"
  },
  {
    "title": "Emerging Skycube",
    "title_es": "Emerging Skycube",
    "url": "https://arxiv.org/abs/2508.10516",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10516v1 Announce Type: new \nAbstract: Combining multi-criteria decision analysis and trend reversal discovery make it possible to extract globally optimal, or non-dominated, data in relation to several criteria, and then to observe their evolution according to a decision-making property. Thus, we introduce Emerging Skycube, a concept associating Skycube and emerging datacube. As far as we know, no DBMS-integrated solution exists to compute an emerging Skycube, and hence taking advantage of ROLAP analysis tools. An emerging datacube has only one measure: we propose to use several to comply to multi-criteria decision analysis constraints which requires multiple attributes. A datacube is expensive to compute. An emerging datacube is about twice as expensive. On the other hand, an emerging Skycube is cheaper as the trend reversal is computed after two Skycube calculations, which considerably reduces the relation volume in comparison with the initial one. It is possible to save even more computing time and storage space. To this end, we propose two successive reductions. First, a Skycube lossless partial materialisation using Skylines concepts lattice, based on the agree concepts lattice and partitions lattice. Then, either the closed emerging Skycube for an information-loss reduction, or the closed emerging L-Skycube for a smaller but lossless reduction.",
    "source": "arXiv"
  },
  {
    "title": "Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution",
    "title_es": "Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution",
    "url": "https://arxiv.org/abs/2508.10517",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10517v1 Announce Type: new \nAbstract: Solidity, the dominant smart contract language for Ethereum, has rapidly evolved with frequent version updates to enhance security, functionality, and developer experience. However, these continual changes introduce significant challenges, particularly in compilation errors, code migration, and maintenance. Therefore, we conduct an empirical study to investigate the challenges in the Solidity version evolution and reveal that 81.68% of examined contracts encounter errors when compiled across different versions, with 86.92% of compilation errors.\n  To mitigate these challenges, we conducted a systematic evaluation of large language models (LLMs) for resolving Solidity compilation errors during version migrations. Our empirical analysis across both open-source (LLaMA3, DeepSeek) and closed-source (GPT-4o, GPT-3.5-turbo) LLMs reveals that although these models exhibit error repair capabilities, their effectiveness diminishes significantly for semantic-level issues and shows strong dependency on prompt engineering strategies. This underscores the critical need for domain-specific adaptation in developing reliable LLM-based repair systems for smart contracts.\n  Building upon these insights, we introduce SMCFIXER, a novel framework that systematically integrates expert knowledge retrieval with LLM-based repair mechanisms for Solidity compilation error resolution. The architecture comprises three core phases: (1) context-aware code slicing that extracts relevant error information; (2) expert knowledge retrieval from official documentation; and (3) iterative patch generation for Solidity migration. Experimental validation across Solidity version migrations demonstrates our approach's statistically significant 24.24% improvement over baseline GPT-4o on real-world datasets, achieving near-perfect 96.97% accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Nonlocal Monte Carlo via Reinforcement Learning",
    "title_es": "Nonlocal Monte Carlo via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.10520",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10520v1 Announce Type: new \nAbstract: Optimizing or sampling complex cost functions of combinatorial optimization problems is a longstanding challenge across disciplines and applications. When employing family of conventional algorithms based on Markov Chain Monte Carlo (MCMC) such as simulated annealing or parallel tempering, one assumes homogeneous (equilibrium) temperature profiles across input. This instance independent approach was shown to be ineffective for the hardest benchmarks near a computational phase transition when the so-called overlap-gap-property holds. In these regimes conventional MCMC struggles to unfreeze rigid variables, escape suboptimal basins of attraction, and sample high-quality and diverse solutions. In order to mitigate these challenges, Nonequilibrium Nonlocal Monte Carlo (NMC) algorithms were proposed that leverage inhomogeneous temperature profiles thereby accelerating exploration of the configuration space without compromising its exploitation. Here, we employ deep reinforcement learning (RL) to train the nonlocal transition policies of NMC which were previously designed phenomenologically. We demonstrate that the resulting solver can be trained solely by observing energy changes of the configuration space exploration as RL rewards and the local minimum energy landscape geometry as RL states. We further show that the trained policies improve upon the standard MCMC-based and nonlocal simulated annealing on hard uniform random and scale-free random 4-SAT benchmarks in terms of residual energy, time-to-solution, and diversity of solutions metrics.",
    "source": "arXiv"
  },
  {
    "title": "EgoMusic-driven Human Dance Motion Estimation with Skeleton Mamba",
    "title_es": "EgoMusic-driven Human Dance Motion Estimation with Skeleton Mamba",
    "url": "https://arxiv.org/abs/2508.10522",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10522v1 Announce Type: new \nAbstract: Estimating human dance motion is a challenging task with various industrial applications. Recently, many efforts have focused on predicting human dance motion using either egocentric video or music as input. However, the task of jointly estimating human motion from both egocentric video and music remains largely unexplored. In this paper, we aim to develop a new method that predicts human dance motion from both egocentric video and music. In practice, the egocentric view often obscures much of the body, making accurate full-pose estimation challenging. Additionally, incorporating music requires the generated head and body movements to align well with both visual and musical inputs. We first introduce EgoAIST++, a new large-scale dataset that combines both egocentric views and music with more than 36 hours of dancing motion. Drawing on the success of diffusion models and Mamba on modeling sequences, we develop an EgoMusic Motion Network with a core Skeleton Mamba that explicitly captures the skeleton structure of the human body. We illustrate that our approach is theoretically supportive. Intensive experiments show that our method clearly outperforms state-of-the-art approaches and generalizes effectively to real-world data.",
    "source": "arXiv"
  },
  {
    "title": "Reasoning in Computer Vision: Taxonomy, Models, Tasks, and Methodologies",
    "title_es": "Reasoning in Computer Vision: Taxonomy, Models, Tasks, and Methodologies",
    "url": "https://arxiv.org/abs/2508.10523",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10523v1 Announce Type: new \nAbstract: Visual reasoning is critical for a wide range of computer vision tasks that go beyond surface-level object detection and classification. Despite notable advances in relational, symbolic, temporal, causal, and commonsense reasoning, existing surveys often address these directions in isolation, lacking a unified analysis and comparison across reasoning types, methodologies, and evaluation protocols. This survey aims to address this gap by categorizing visual reasoning into five major types (relational, symbolic, temporal, causal, and commonsense) and systematically examining their implementation through architectures such as graph-based models, memory networks, attention mechanisms, and neuro-symbolic systems. We review evaluation protocols designed to assess functional correctness, structural consistency, and causal validity, and critically analyze their limitations in terms of generalizability, reproducibility, and explanatory power. Beyond evaluation, we identify key open challenges in visual reasoning, including scalability to complex scenes, deeper integration of symbolic and neural paradigms, the lack of comprehensive benchmark datasets, and reasoning under weak supervision. Finally, we outline a forward-looking research agenda for next-generation vision systems, emphasizing that bridging perception and reasoning is essential for building transparent, trustworthy, and cross-domain adaptive AI systems, particularly in critical domains such as autonomous driving and medical diagnostics.",
    "source": "arXiv"
  },
  {
    "title": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset",
    "title_es": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset",
    "url": "https://arxiv.org/abs/2508.10528",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10528v1 Announce Type: new \nAbstract: Medical image grounding aims to align natural language phrases with specific regions in medical images, serving as a foundational task for intelligent diagnosis, visual question answering (VQA), and automated report generation (MRG). However, existing research is constrained by limited modality coverage, coarse-grained annotations, and the absence of a unified, generalizable grounding framework. To address these challenges, we construct a large-scale medical grounding dataset Med-GLIP-5M comprising over 5.3 million region-level annotations across seven imaging modalities, covering diverse anatomical structures and pathological findings. The dataset supports both segmentation and grounding tasks with hierarchical region labels, ranging from organ-level boundaries to fine-grained lesions. Based on this foundation, we propose Med-GLIP, a modality-aware grounding framework trained on Med-GLIP-5M. Rather than relying on explicitly designed expert modules, Med-GLIP implicitly acquires hierarchical semantic understanding from diverse training data -- enabling it to recognize multi-granularity structures, such as distinguishing lungs from pneumonia lesions. Extensive experiments demonstrate that Med-GLIP consistently outperforms state-of-the-art baselines across multiple grounding benchmarks. Furthermore, integrating its spatial outputs into downstream tasks, including medical VQA and report generation, leads to substantial performance gains. Our dataset will be released soon.",
    "source": "arXiv"
  },
  {
    "title": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment",
    "title_es": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment",
    "url": "https://arxiv.org/abs/2508.10530",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10530v1 Announce Type: new \nAbstract: The alignment of language models (LMs) with human preferences is critical for building reliable AI systems. The problem is typically framed as optimizing an LM policy to maximize the expected reward that reflects human preferences. Recently, Direct Preference Optimization (DPO) was proposed as a LM alignment method that directly optimize the policy from static preference data, and further improved by incorporating on-policy sampling (i.e., preference candidates generated during the training loop) for better LM alignment. However, we show on-policy data is not always optimal, with systematic effectiveness difference emerging between static and on-policy preference candidates. For example, on-policy data can result in a 3$\\times$ effectiveness compared with static data for Llama-3, and a 0.4$\\times$ effectiveness for Zephyr. To explain the phenomenon, we propose the alignment stage assumption, which divides the alignment process into two distinct stages: the preference injection stage, which benefits from diverse data, and the preference fine-tuning stage, which favors high-quality data. Through theoretical and empirical analysis, we characterize these stages and propose an effective algorithm to identify the boundaries between them. We perform experiments on 5 models (Llama, Zephyr, Phi-2, Qwen, Pythia) and 2 alignment methods (DPO, SLiC-HF) to show the generalizability of alignment stage assumption and boundary measurement.",
    "source": "arXiv"
  },
  {
    "title": "Projected Coupled Diffusion for Test-Time Constrained Joint Generation",
    "title_es": "Projected Coupled Diffusion for Test-Time Constrained Joint Generation",
    "url": "https://arxiv.org/abs/2508.10531",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10531v1 Announce Type: new \nAbstract: Modifications to test-time sampling have emerged as an important extension to diffusion algorithms, with the goal of biasing the generative process to achieve a given objective without having to retrain the entire diffusion model. However, generating jointly correlated samples from multiple pre-trained diffusion models while simultaneously enforcing task-specific constraints without costly retraining has remained challenging. To this end, we propose Projected Coupled Diffusion (PCD), a novel test-time framework for constrained joint generation. PCD introduces a coupled guidance term into the generative dynamics to encourage coordination between diffusion models and incorporates a projection step at each diffusion step to enforce hard constraints. Empirically, we demonstrate the effectiveness of PCD in application scenarios of image-pair generation, object manipulation, and multi-robot motion planning. Our results show improved coupling effects and guaranteed constraint satisfaction without incurring excessive computational costs.",
    "source": "arXiv"
  },
  {
    "title": "Active Automata Learning with Advice",
    "title_es": "Active Automata Learning with Advice",
    "url": "https://arxiv.org/abs/2508.10535",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10535v1 Announce Type: new \nAbstract: We present an extended automata learning framework that combines active automata learning with deductive inference. The learning algorithm asks membership and equivalence queries as in the original framework, but it is also given advice, which is used to infer answers to queries when possible and reduce the burden on the teacher. We consider advice given via string rewriting systems, which specify equivalence of words w.r.t. the target languages. The main motivation for the proposed framework is to reduce the number of queries. We show how to adapt Angluin-style learning algorithms to this framework with low overhead. Finally, we present empirical evaluation of our approach and observe substantial improvement in query complexity.",
    "source": "arXiv"
  },
  {
    "title": "Computing the Fr\\'echet Distance When Just One Curve is $c$-Packed: A Simple Almost-Tight Algorithm",
    "title_es": "Computing the Fr\\'echet Distance When Just One Curve is $c$-Packed: A Simple Almost-Tight Algorithm",
    "url": "https://arxiv.org/abs/2508.10537",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10537v1 Announce Type: new \nAbstract: We study approximating the continuous Fr\\'echet distance of two curves with complexity $n$ and $m$, under the assumption that only one of the two curves is $c$-packed. Driemel, Har{-}Peled and Wenk DCG'12 studied Fr\\'echet distance approximations under the assumption that both curves are $c$-packed. In $\\mathbb{R}^d$, they prove a $(1+\\varepsilon)$-approximation in $\\tilde{O}(d \\, c\\,\\frac{n+m}{\\varepsilon})$ time. Bringmann and K\\\"unnemann IJCGA'17 improved this to $\\tilde{O}(c\\,\\frac{n + m }{\\sqrt{\\varepsilon}})$ time, which they showed is near-tight under SETH. Recently, Gudmundsson, Mai, and Wong ISAAC'24 studied our setting where only one of the curves is $c$-packed. They provide an involved $\\tilde{O}( d \\cdot (c+\\varepsilon^{-1})(cn\\varepsilon^{-2} + c^2m\\varepsilon^{-7} + \\varepsilon^{-2d-1}))$-time algorithm when the $c$-packed curve has $n$ vertices and the arbitrary curve has $m$, where $d$ is the dimension in Euclidean space. In this paper, we show a simple technique to compute a $(1+\\varepsilon)$-approximation in $\\mathbb{R}^d$ in time $O(d \\cdot c\\,\\frac{n+m}{\\varepsilon}\\log\\frac{n+m}{\\varepsilon})$ when one of the curves is $c$-packed. Our approach is not only simpler than previous work, but also significantly improves the dependencies on $c$, $\\varepsilon$, and $d$. Moreover, it almost matches the asymptotically tight bound for when both curves are $c$-packed. Our algorithm is robust in the sense that it does not require knowledge of $c$, nor information about which of the two input curves is $c$-packed.",
    "source": "arXiv"
  },
  {
    "title": "MLM: Learning Multi-task Loco-Manipulation Whole-Body Control for Quadruped Robot with Arm",
    "title_es": "MLM: Learning Multi-task Loco-Manipulation Whole-Body Control for Quadruped Robot with Arm",
    "url": "https://arxiv.org/abs/2508.10538",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10538v1 Announce Type: new \nAbstract: Whole-body loco-manipulation for quadruped robots with arm remains a challenging problem, particularly in achieving multi-task control. To address this, we propose MLM, a reinforcement learning framework driven by both real-world and simulation data. It enables a six-DoF robotic arm--equipped quadruped robot to perform whole-body loco-manipulation for multiple tasks autonomously or under human teleoperation. To address the problem of balancing multiple tasks during the learning of loco-manipulation, we introduce a trajectory library with an adaptive, curriculum-based sampling mechanism. This approach allows the policy to efficiently leverage real-world collected trajectories for learning multi-task loco-manipulation. To address deployment scenarios with only historical observations and to enhance the performance of policy execution across tasks with different spatial ranges, we propose a Trajectory-Velocity Prediction policy network. It predicts unobservable future trajectories and velocities. By leveraging extensive simulation data and curriculum-based rewards, our controller achieves whole-body behaviors in simulation and zero-shot transfer to real-world deployment. Ablation studies in simulation verify the necessity and effectiveness of our approach, while real-world experiments on the Go2 robot with an Airbot robotic arm demonstrate the policy's good performance in multi-task execution.",
    "source": "arXiv"
  },
  {
    "title": "Improving Value-based Process Verifier via Low-Cost Variance Reduction",
    "title_es": "Improving Value-based Process Verifier via Low-Cost Variance Reduction",
    "url": "https://arxiv.org/abs/2508.10539",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10539v1 Announce Type: new \nAbstract: Large language models (LLMs) have achieved remarkable success in a wide range of tasks. However, their reasoning capabilities, particularly in complex domains like mathematics, remain a significant challenge. Value-based process verifiers, which estimate the probability of a partial reasoning chain leading to a correct solution, are a promising approach for improving reasoning. Nevertheless, their effectiveness is often hindered by estimation error in their training annotations, a consequence of the limited number of Monte Carlo (MC) samples feasible due to the high cost of LLM inference. In this paper, we identify that the estimation error primarily arises from high variance rather than bias, and the MC estimator is a Minimum Variance Unbiased Estimator (MVUE). To address the problem, we propose the \\textsc{Com}pound \\textsc{M}onte \\textsc{C}arlo \\textsc{S}ampling (ComMCS) method, which constructs an unbiased estimator by linearly combining the MC estimators from the current and subsequent steps. Theoretically, we show that our method leads to a predictable reduction in variance, while maintaining an unbiased estimation without additional LLM inference cost. We also perform empirical experiments on the MATH-500 and GSM8K benchmarks to demonstrate the effectiveness of our method. Notably, ComMCS outperforms regression-based optimization method by 2.8 points, the non-variance-reduced baseline by 2.2 points on MATH-500 on Best-of-32 sampling experiment.",
    "source": "arXiv"
  },
  {
    "title": "Driving Accurate Allergen Prediction with Protein Language Models and Generalization-Focused Evaluation",
    "title_es": "Driving Accurate Allergen Prediction with Protein Language Models and Generalization-Focused Evaluation",
    "url": "https://arxiv.org/abs/2508.10541",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10541v1 Announce Type: new \nAbstract: Allergens, typically proteins capable of triggering adverse immune responses, represent a significant public health challenge. To accurately identify allergen proteins, we introduce Applm (Allergen Prediction with Protein Language Models), a computational framework that leverages the 100-billion parameter xTrimoPGLM protein language model. We show that Applm consistently outperforms seven state-of-the-art methods in a diverse set of tasks that closely resemble difficult real-world scenarios. These include identifying novel allergens that lack similar examples in the training set, differentiating between allergens and non-allergens among homologs with high sequence similarity, and assessing functional consequences of mutations that create few changes to the protein sequences. Our analysis confirms that xTrimoPGLM, originally trained on one trillion tokens to capture general protein sequence characteristics, is crucial for Applm's performance by detecting important differences among protein sequences. In addition to providing Applm as open-source software, we also provide our carefully curated benchmark datasets to facilitate future research.",
    "source": "arXiv"
  },
  {
    "title": "GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images",
    "title_es": "GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images",
    "url": "https://arxiv.org/abs/2508.10542",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10542v1 Announce Type: new \nAbstract: Salient object detection (SOD) in optical remote sensing images (ORSIs) faces numerous challenges, including significant variations in target scales and low contrast between targets and the background. Existing methods based on vision transformers (ViTs) and convolutional neural networks (CNNs) architectures aim to leverage both global and local features, but the difficulty in effectively integrating these heterogeneous features limits their overall performance. To overcome these limitations, we propose a graph-enhanced contextual and regional perception network (GCRPNet), which builds upon the Mamba architecture to simultaneously capture long-range dependencies and enhance regional feature representation. Specifically, we employ the visual state space (VSS) encoder to extract multi-scale features. To further achieve deep guidance and enhancement of these features, we first design a difference-similarity guided hierarchical graph attention module (DS-HGAM). This module strengthens cross-layer interaction capabilities between features of different scales while enhancing the model's structural perception,allowing it to distinguish between foreground and background more effectively. Then, we design the LEVSS block as the decoder of GCRPNet. This module integrates our proposed adaptive scanning strategy and multi-granularity collaborative attention enhancement module (MCAEM). It performs adaptive patch scanning on feature maps processed via multi-scale convolutions, thereby capturing rich local region information and enhancing Mamba's local modeling capability. Extensive experimental results demonstrate that the proposed model achieves state-of-the-art performance, validating its effectiveness and superiority.",
    "source": "arXiv"
  },
  {
    "title": "On The Eventual Periodicity of Fractional Order Dispersive Wave Equations Using RBFs and Transform",
    "title_es": "On The Eventual Periodicity of Fractional Order Dispersive Wave Equations Using RBFs and Transform",
    "url": "https://arxiv.org/abs/2508.10547",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10547v1 Announce Type: new \nAbstract: In this research work, let us focus on the construction of numerical scheme based on radial basis functions finite difference (RBF-FD) method combined with the Laplace transform for the solution of fractional order dispersive wave equations. The numerical scheme is then applied to examine the eventual periodicity of the proposed model subject to the periodic boundary conditions. The implementation of proposed technique for high order fractional and integer type nonlinear partial differential equations (PDEs) is beneficial because this method is local in nature, therefore it yields and resulted in sparse differentiation matrices instead of full and dense matrices. Only small dimensions of linear systems of equations are to be solved for every center in the domain and hence this procedure is more reliable and efficient to solve large scale physical and engineering problems in complex domain. Laplace transform is utilized for obtaining the equivalent time-independent equation in Laplace space and also valuable to handle time-fractional derivatives in the Caputo sense. Application of Laplace transform avoids the time steeping procedure which commonly encounters the time instability issues. The solution to the transformed model is then obtained by computing the inversion of Laplace transform with an appropriate contour in a complex space, which is approximated by trapezoidal rule with high accuracy. Also since the Laplace transform operator is linear, it cannot be used to transform non-linear terms therefore let us use a linearization approach and an appropriate iterative scheme. The proposed approach is tasted for some nonlinear fractional order KdV and Burgers equations. The capacity, high order accuracy and efficiency of our approach are demonstrated using examples and results",
    "source": "arXiv"
  },
  {
    "title": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards",
    "title_es": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards",
    "url": "https://arxiv.org/abs/2508.10548",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10548v1 Announce Type: new \nAbstract: Reward sparsity in long-horizon reinforcement learning (RL) tasks remains a significant challenge, while existing outcome-based reward shaping struggles to define meaningful immediate rewards without introducing bias or requiring explicit task decomposition. Alternatively, verification-based reward shaping uses stepwise critics, but misalignment between immediate rewards and long-term objectives can lead to reward hacking and suboptimal policies. In this work, we address this problem in the context of software engineering (SWE) tasks, where multi-turn reasoning and rule-based verification are critical. We introduce the SWE-oriented RL Framework, a unified system supporting multi-turn interaction, docker-based execution, and customizable reward functions. Additionally, we propose Gated Reward Accumulation (G-RA), a novel method that accumulates immediate rewards only when high-level (long-term) rewards meet a predefined threshold, ensuring stable RL optimization. Experiments on SWE-bench Verified and kBench demonstrate that G-RA leads to an increase in completion rates (47.6\\% \\rightarrow 93.8\\% and 22.0\\% \\rightarrow 86.0\\%) and modification rates (19.6\\% \\rightarrow 23.8\\% and 12.0\\% \\rightarrow 42.0\\%), while avoiding policy degradation caused by reward misalignment. Our findings highlight the importance of balanced reward accumulation in long-horizon RL and provide a practical solution.",
    "source": "arXiv"
  },
  {
    "title": "PSScreen: Partially Supervised Multiple Retinal Disease Screening",
    "title_es": "PSScreen: Partially Supervised Multiple Retinal Disease Screening",
    "url": "https://arxiv.org/abs/2508.10549",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10549v1 Announce Type: new \nAbstract: Leveraging multiple partially labeled datasets to train a model for multiple retinal disease screening reduces the reliance on fully annotated datasets, but remains challenging due to significant domain shifts across training datasets from various medical sites, and the label absent issue for partial classes. To solve these challenges, we propose PSScreen, a novel Partially Supervised multiple retinal disease Screening model. Our PSScreen consists of two streams and one learns deterministic features and the other learns probabilistic features via uncertainty injection. Then, we leverage the textual guidance to decouple two types of features into disease-wise features and align them via feature distillation to boost the domain generalization ability. Meanwhile, we employ pseudo label consistency between two streams to address the label absent issue and introduce a self-distillation to transfer task-relevant semantics about known classes from the deterministic to the probabilistic stream to further enhance the detection performances. Experiments show that our PSScreen significantly enhances the detection performances on six retinal diseases and the normal state averagely and achieves state-of-the-art results on both in-domain and out-of-domain datasets. Codes are available at https://github.com/boyiZheng99/PSScreen.",
    "source": "arXiv"
  },
  {
    "title": "On Kernelization with Access to NP-Oracles",
    "title_es": "On Kernelization with Access to NP-Oracles",
    "url": "https://arxiv.org/abs/2508.10550",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10550v1 Announce Type: new \nAbstract: Kernelization is the standard framework to analyze preprocessing routines mathematically. Here, in terms of efficiency, we demand the preprocessing routine to run in time polynomial in the input size. However, today, various NP-complete problems are already solved very fast in practice; in particular, SAT-solvers and ILP-solvers have become extremely powerful and used frequently. Still, this fails to capture the wide variety of computational problems that lie at higher levels of the polynomial hierarchy. Thus, for such problems, it is natural to relax the definition of kernelization to permit the preprocessing routine to make polynomially many calls to a SAT-solver, rather than run, entirely, in polynomial time.\n  Our conceptual contribution is the introduction of a new notion of a kernel that harnesses the power of SAT-solvers for preprocessing purposes, and which we term a P^NP-Kernel. Technically, we investigate various facets of this notion, by proving both positive and negative results, including a lower-bounds framework to reason about the negative results. Here, we consider both satisfiability and graph problems. Additionally, we present a meta-theorem for so-called \"discovery problems\". This work falls into a long line of research on extensions of the concept of kernelization, including lossy kernels [Lokshtanov et al., STOC '17], dynamic kernels [Alman et al., ACM TALG '20], counting kernels [Lokshtanov et al., ICTS '24], and streaming kernels [Fafianie and Kratsch, MFCS '14].",
    "source": "arXiv"
  },
  {
    "title": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models",
    "title_es": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2508.10552",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10552v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across a diverse range of multimodal tasks. However, these models suffer from a core problem known as text dominance: they depend heavily on text for their inference, while underutilizing other modalities. While prior work has acknowledged this phenomenon in vision-language tasks, often attributing it to data biases or model architectures. In this paper, we conduct the first systematic investigation of text dominance across diverse data modalities, including images, videos, audio, time-series, and graphs. To measure this imbalance, we propose two evaluation metrics: the Modality Dominance Index (MDI) and the Attention Efficiency Index (AEI). Our comprehensive analysis reveals that text dominance is both significant and pervasive across all tested modalities. Our in-depth analysis identifies three underlying causes: attention dilution from severe token redundancy in non-textual modalities, the influence of fusion architecture design, and task formulations that implicitly favor textual inputs. Furthermore, we propose a simple token compression method that effectively rebalances model attention. Applying this method to LLaVA-7B, for instance, drastically reduces its MDI from 10.23 to a well-balanced value of 0.86. Our analysis and methodological framework offer a foundation for the development of more equitable and comprehensive multimodal language models.",
    "source": "arXiv"
  },
  {
    "title": "eDIF: A European Deep Inference Fabric for Remote Interpretability of LLM",
    "title_es": "eDIF: A European Deep Inference Fabric for Remote Interpretability of LLM",
    "url": "https://arxiv.org/abs/2508.10553",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10553v1 Announce Type: new \nAbstract: This paper presents a feasibility study on the deployment of a European Deep Inference Fabric (eDIF), an NDIF-compatible infrastructure designed to support mechanistic interpretability research on large language models. The need for widespread accessibility of LLM interpretability infrastructure in Europe drives this initiative to democratize advanced model analysis capabilities for the research community. The project introduces a GPU-based cluster hosted at Ansbach University of Applied Sciences and interconnected with partner institutions, enabling remote model inspection via the NNsight API. A structured pilot study involving 16 researchers from across Europe evaluated the platform's technical performance, usability, and scientific utility. Users conducted interventions such as activation patching, causal tracing, and representation analysis on models including GPT-2 and DeepSeek-R1-70B. The study revealed a gradual increase in user engagement, stable platform performance throughout, and a positive reception of the remote experimentation capabilities. It also marked the starting point for building a user community around the platform. Identified limitations such as prolonged download durations for activation data as well as intermittent execution interruptions are addressed in the roadmap for future development. This initiative marks a significant step towards widespread accessibility of LLM interpretability infrastructure in Europe and lays the groundwork for broader deployment, expanded tooling, and sustained community collaboration in mechanistic interpretability research.",
    "source": "arXiv"
  },
  {
    "title": "AR Surgical Navigation With Surface Tracing: Comparing In-SitVisualization with Tool-Tracking Guidance for Neurosurgical Applications",
    "title_es": "AR Surgical Navigation With Surface Tracing: Comparing In-SitVisualization with Tool-Tracking Guidance for Neurosurgical Applications",
    "url": "https://arxiv.org/abs/2508.10554",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10554v1 Announce Type: new \nAbstract: Augmented Reality (AR) surgical navigation systems are emerging as the next generation of intraoperative surgical guidance, promising to overcome limitations of traditional navigation systems. However, known issues with AR depth perception due to vergence-accommodation conflict and occlusion handling limitations of the currently commercially available display technology present acute challenges in surgical settings where precision is paramount. This study presents a novel methodology for utilizing AR guidance to register anatomical targets and provide real-time instrument navigation using placement of simulated external ventricular drain catheters on a phantom model as the clinical scenario. The system registers target positions to the patient through a novel surface tracing method and uses real-time infrared tool tracking to aid in catheter placement, relying only on the onboard sensors of the Microsoft HoloLens 2. A group of intended users performed the procedure of simulated insertions under two AR guidance conditions: static in-situ visualization, where planned trajectories are overlaid directly onto the patient anatomy, and real-time tool-tracking guidance, where live feedback of the catheter's pose is provided relative to the plan. Following the insertion tests, computed tomography scans of the phantom models were acquired, allowing for evaluation of insertion accuracy, target deviation, angular error, and depth precision. System Usability Scale surveys assessed user experience and cognitive workload. Tool-tracking guidance improved performance metrics across all accuracy measures and was preferred by users in subjective evaluations. A free copy of this paper and all supplemental materials are available at https://bit.ly/45l89Hq.",
    "source": "arXiv"
  },
  {
    "title": "Retrieval-Augmented Prompt for OOD Detection",
    "title_es": "Retrieval-Augmented Prompt for OOD Detection",
    "url": "https://arxiv.org/abs/2508.10556",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10556v1 Announce Type: new \nAbstract: Out-of-Distribution (OOD) detection is crucial for the reliable deployment of machine learning models in-the-wild, enabling accurate identification of test samples that differ from the training data distribution. Existing methods rely on auxiliary outlier samples or in-distribution (ID) data to generate outlier information for training, but due to limited outliers and their mismatch with real test OOD samples, they often fail to provide sufficient semantic supervision, leading to suboptimal performance. To address this, we propose a novel OOD detection method called Retrieval-Augmented Prompt (RAP). RAP augments a pre-trained vision-language model's prompts by retrieving external knowledge, offering enhanced semantic supervision for OOD detection. During training, RAP retrieves descriptive words for outliers based on joint similarity with external textual knowledge and uses them to augment the model's OOD prompts. During testing, RAP dynamically updates OOD prompts in real-time based on the encountered OOD samples, enabling the model to rapidly adapt to the test environment. Our extensive experiments demonstrate that RAP achieves state-of-the-art performance on large-scale OOD detection benchmarks. For example, in 1-shot OOD detection on the ImageNet-1k dataset, RAP reduces the average FPR95 by 7.05% and improves the AUROC by 1.71% compared to previous methods. Additionally, comprehensive ablation studies validate the effectiveness of each module and the underlying motivations of our approach.",
    "source": "arXiv"
  },
  {
    "title": "PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks",
    "title_es": "PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks",
    "url": "https://arxiv.org/abs/2508.10557",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10557v1 Announce Type: new \nAbstract: Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) represent two mainstream model quantization approaches. However, PTQ often leads to unacceptable performance degradation in quantized models, while QAT imposes substantial GPU memory requirements and extended training time due to weight fine-tuning.In this paper, we propose PTQAT, a novel general hybrid quantization algorithm for the efficient deployment of 3D perception networks. To address the speed accuracy trade-off between PTQ and QAT, our method selects critical layers for QAT fine-tuning and performs PTQ on the remaining layers. Contrary to intuition, fine-tuning the layers with smaller output discrepancies before and after quantization, rather than those with larger discrepancies, actually leads to greater improvements in the model's quantization accuracy. This means we better compensate for quantization errors during their propagation, rather than addressing them at the point where they occur. The proposed PTQAT achieves similar performance to QAT with more efficiency by freezing nearly 50% of quantifiable layers. Additionally, PTQAT is a universal quantization method that supports various quantization bit widths (4 bits) as well as different model architectures, including CNNs and Transformers. The experimental results on nuScenes across diverse 3D perception tasks, including object detection, semantic segmentation, and occupancy prediction, show that our method consistently outperforms QAT-only baselines. Notably, it achieves 0.2%-0.9% NDS and 0.3%-1.0% mAP gains in object detection, 0.3%-2.0% mIoU gains in semantic segmentation and occupancy prediction while fine-tuning fewer weights.",
    "source": "arXiv"
  },
  {
    "title": "RBF-FD Method for Some Dispersive Wave Equations and Their Eventual Periodicity",
    "title_es": "RBF-FD Method for Some Dispersive Wave Equations and Their Eventual Periodicity",
    "url": "https://arxiv.org/abs/2508.10558",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10558v1 Announce Type: new \nAbstract: In this paper, we approximate the solution and also discuss the periodic behavior termed as eventual periodicity of solutions of (IBVPs) for some dispersive wave equations on a bounded domain corresponding to periodic forcing. The constructed numerical scheme is based on radial kernels and local in nature like finite difference method. The temporal variable is executed through RK4 scheme. Due to the local nature and sparse differentiation matrices our numerical scheme efficiently recovers the solution. The results achieved are validated and examined with other methods accessible in the literature.",
    "source": "arXiv"
  },
  {
    "title": "Fake Speech Wild: Detecting Deepfake Speech on Social Media Platform",
    "title_es": "Fake Speech Wild: Detecting Deepfake Speech on Social Media Platform",
    "url": "https://arxiv.org/abs/2508.10559",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10559v1 Announce Type: new \nAbstract: The rapid advancement of speech generation technology has led to the widespread proliferation of deepfake speech across social media platforms. While deepfake audio countermeasures (CMs) achieve promising results on public datasets, their performance degrades significantly in cross-domain scenarios. To advance CMs for real-world deepfake detection, we first propose the Fake Speech Wild (FSW) dataset, which includes 254 hours of real and deepfake audio from four different media platforms, focusing on social media. As CMs, we establish a benchmark using public datasets and advanced selfsupervised learning (SSL)-based CMs to evaluate current CMs in real-world scenarios. We also assess the effectiveness of data augmentation strategies in enhancing CM robustness for detecting deepfake speech on social media. Finally, by augmenting public datasets and incorporating the FSW training set, we significantly advanced real-world deepfake audio detection performance, achieving an average equal error rate (EER) of 3.54% across all evaluation sets.",
    "source": "arXiv"
  },
  {
    "title": "Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling",
    "title_es": "Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling",
    "url": "https://arxiv.org/abs/2508.10561",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10561v1 Announce Type: new \nAbstract: In Affective Computing, a key challenge lies in reliably linking subjective emotional experiences with objective physiological markers. This preliminary study addresses the issue of reproducibility by identifying physiological features from cardiovascular and electrodermal signals that are associated with continuous self-reports of arousal levels. Using the Continuously Annotated Signal of Emotion dataset, we analyzed 164 features extracted from cardiac and electrodermal signals of 30 participants exposed to short emotion-evoking videos. Feature selection was performed using the Terminating-Random Experiments (T-Rex) method, which performs variable selection systematically controlling a user-defined target False Discovery Rate. Remarkably, among all candidate features, only two electrodermal-derived features exhibited reproducible and statistically significant associations with arousal, achieving a 100\\% confirmation rate. These results highlight the necessity of rigorous reproducibility assessments in physiological features selection, an aspect often overlooked in Affective Computing. Our approach is particularly promising for applications in safety-critical environments requiring trustworthy and reliable white box models, such as mental disorder recognition and human-robot interaction systems.",
    "source": "arXiv"
  },
  {
    "title": "On Fixed-Parameter Tractability of Weighted 0-1 Timed Matching Problem on Temporal Graphs",
    "title_es": "On Fixed-Parameter Tractability of Weighted 0-1 Timed Matching Problem on Temporal Graphs",
    "url": "https://arxiv.org/abs/2508.10562",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10562v1 Announce Type: new \nAbstract: Temporal graphs are introduced to model systems where the relationships among the entities of the system evolve over time. In this paper, we consider the temporal graphs where the edge set changes with time and all the changes are known a priori. The underlying graph of a temporal graph is a static graph consisting of all the vertices and edges that exist for at least one timestep in the temporal graph. The concept of 0-1 timed matching in temporal graphs was introduced by Mandal and Gupta [DAM2022] as an extension of the matching problem in static graphs. A 0-1 timed matching of a temporal graph is a non-overlapping subset of the edge set of that temporal graph. The problem of finding the maximum 0-1 timed matching is proved to be NP-complete on multiple classes of temporal graphs. We study the fixed-parameter tractability of the maximum 0-1 timed matching problem. We prove that the problem remains to be NP-complete even when the underlying static graph of the temporal graph has a bounded treewidth. Furthermore, we establish that the problem is W[1]-hard when parameterized by the solution size. Finally, we present a fixed-parameter tractable (FPT) algorithm to address the problem when the problem is parameterized by the maximum vertex degree and the treewidth of the underlying graph of the temporal graph.",
    "source": "arXiv"
  },
  {
    "title": "HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head Synthesis",
    "title_es": "HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head Synthesis",
    "url": "https://arxiv.org/abs/2508.10566",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10566v1 Announce Type: new \nAbstract: Audio-driven talking head video generation enhances user engagement in human-computer interaction. However, current methods frequently produce videos with motion blur and lip jitter, primarily due to their reliance on implicit modeling of audio-facial motion correlations--an approach lacking explicit articulatory priors (i.e., anatomical guidance for speech-related facial movements). To overcome this limitation, we propose HM-Talker, a novel framework for generating high-fidelity, temporally coherent talking heads. HM-Talker leverages a hybrid motion representation combining both implicit and explicit motion cues. Explicit cues use Action Units (AUs), anatomically defined facial muscle movements, alongside implicit features to minimize phoneme-viseme misalignment. Specifically, our Cross-Modal Disentanglement Module (CMDM) extracts complementary implicit/explicit motion features while predicting AUs directly from audio input aligned to visual cues. To mitigate identity-dependent biases in explicit features and enhance cross-subject generalization, we introduce the Hybrid Motion Modeling Module (HMMM). This module dynamically merges randomly paired implicit/explicit features, enforcing identity-agnostic learning. Together, these components enable robust lip synchronization across diverse identities, advancing personalized talking head synthesis. Extensive experiments demonstrate HM-Talker's superiority over state-of-the-art methods in visual quality and lip-sync accuracy.",
    "source": "arXiv"
  },
  {
    "title": "SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving",
    "title_es": "SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.10567",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10567v1 Announce Type: new \nAbstract: End-to-end autonomous driving systems promise stronger performance through unified optimization of perception, motion forecasting, and planning. However, vision-based approaches face fundamental limitations in adverse weather conditions, partial occlusions, and precise velocity estimation - critical challenges in safety-sensitive scenarios where accurate motion understanding and long-horizon trajectory prediction are essential for collision avoidance. To address these limitations, we propose SpaRC-AD, a query-based end-to-end camera-radar fusion framework for planning-oriented autonomous driving. Through sparse 3D feature alignment, and doppler-based velocity estimation, we achieve strong 3D scene representations for refinement of agent anchors, map polylines and motion modelling. Our method achieves strong improvements over the state-of-the-art vision-only baselines across multiple autonomous driving tasks, including 3D detection (+4.8% mAP), multi-object tracking (+8.3% AMOTA), online mapping (+1.8% mAP), motion prediction (-4.0% mADE), and trajectory planning (-0.1m L2 and -9% TPC). We achieve both spatial coherence and temporal consistency on multiple challenging benchmarks, including real-world open-loop nuScenes, long-horizon T-nuScenes, and closed-loop simulator Bench2Drive. We show the effectiveness of radar-based fusion in safety-critical scenarios where accurate motion understanding and long-horizon trajectory prediction are essential for collision avoidance. The source code of all experiments is available at https://phi-wol.github.io/sparcad/",
    "source": "arXiv"
  },
  {
    "title": "Adapting SAM via Cross-Entropy Masking for Class Imbalance in Remote Sensing Change Detection",
    "title_es": "Adapting SAM via Cross-Entropy Masking for Class Imbalance in Remote Sensing Change Detection",
    "url": "https://arxiv.org/abs/2508.10568",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10568v1 Announce Type: new \nAbstract: Foundational models have achieved significant success in diverse domains of computer vision. They learn general representations that are easily transferable to tasks not seen during training. One such foundational model is Segment anything model (SAM), which can accurately segment objects in images. We propose adapting the SAM encoder via fine-tuning for remote sensing change detection (RSCD) along with spatial-temporal feature enhancement (STFE) and multi-scale decoder fusion (MSDF) to detect changes robustly at multiple scales. Additionally, we propose a novel cross-entropy masking (CEM) loss to handle high class imbalance in change detection datasets. Our method outperforms state-of-the-art (SOTA) methods on four change detection datasets, Levir-CD, WHU-CD, CLCD, and S2Looking. We achieved 2.5% F1-score improvement on a large complex S2Looking dataset. The code is available at: https://github.com/humza909/SAM-CEM-CD",
    "source": "arXiv"
  },
  {
    "title": "CutVEM: Conforming virtual element method on embedded domains with shape-agnostic element agglomeration",
    "title_es": "CutVEM: Conforming virtual element method on embedded domains with shape-agnostic element agglomeration",
    "url": "https://arxiv.org/abs/2508.10570",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10570v1 Announce Type: new \nAbstract: The virtual element method (VEM) is a stabilized Galerkin method that is robust and accurate on general polygonal meshes. This feature makes it an appealing candidate for simulations involving meshes with embedded interfaces and evolving geometries. However, the method can yield poorly conditioned stiffness matrices in such scenarios due to meshes having cut cells. We propose a novel element agglomeration algorithm for the virtual element method to address this issue. The agglomeration algorithm renders the VEM robust over planar polygonal meshes, particularly on finite element meshes cut by immersed geometries. The algorithm relies on the element stability ratio, which we define using the extreme eigenvalues of the element stiffness matrix. The resulting element agglomeration criterion is free from nebulous polygon quality metrics and is defined independently of polygon shapes. The algorithm proceeds iteratively and element-wise to maximize the minimum element stability ratio, even at the expense of degrading elements with better ratios. Crucially, element agglomeration alters the number of elements, not the degree of freedom count. The resulting method, which we label as CutVEM, retains node locations of cut elements unchanged, and yields discretizations that conform to embedded interfaces. This, in turn, facilitates straightforward imposition of boundary conditions and interfacial constraints. Through detailed numerical experiments that sample varied element-interface intersections, we demonstrate that CutVEM enjoys dramatically improved condition numbers of global stiffness matrices over the VEM. Furthermore, simulations of prototypical heat conduction problems with Dirichlet and Neumann boundary conditions on domains with immersed geometries show that element agglomeration does not noticeably degrade solution accuracy and that CutVEM retains the VEM's optimal convergence rate.",
    "source": "arXiv"
  },
  {
    "title": "Towards Agentic AI for Multimodal-Guided Video Object Segmentation",
    "title_es": "Towards Agentic AI for Multimodal-Guided Video Object Segmentation",
    "url": "https://arxiv.org/abs/2508.10572",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10572v1 Announce Type: new \nAbstract: Referring-based Video Object Segmentation is a multimodal problem that requires producing fine-grained segmentation results guided by external cues. Traditional approaches to this task typically involve training specialized models, which come with high computational complexity and manual annotation effort. Recent advances in vision-language foundation models open a promising direction toward training-free approaches. Several studies have explored leveraging these general-purpose models for fine-grained segmentation, achieving performance comparable to that of fully supervised, task-specific models. However, existing methods rely on fixed pipelines that lack the flexibility needed to adapt to the dynamic nature of the task. To address this limitation, we propose Multi-Modal Agent, a novel agentic system designed to solve this task in a more flexible and adaptive manner. Specifically, our method leverages the reasoning capabilities of large language models (LLMs) to generate dynamic workflows tailored to each input. This adaptive procedure iteratively interacts with a set of specialized tools designed for low-level tasks across different modalities to identify the target object described by the multimodal cues. Our agentic approach demonstrates clear improvements over prior methods on two multimodal-conditioned VOS tasks: RVOS and Ref-AVS.",
    "source": "arXiv"
  },
  {
    "title": "Federated Learning Over LoRa Networks: Simulator Design and Performance Evaluation",
    "title_es": "Federated Learning Over LoRa Networks: Simulator Design and Performance Evaluation",
    "url": "https://arxiv.org/abs/2508.10574",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10574v1 Announce Type: new \nAbstract: Federated learning (FL) over long-range (LoRa) low-power wide area networks faces unique challenges due to limited bandwidth, interference, and strict duty-cycle constraints. We develop a Python-based simulator that integrates and extends the Flower and LoRaSim frameworks to evaluate centralized FL over LoRa networks. The simulator employs a detailed link-level model for FL update transfer over LoRa channels, capturing LoRa's receiver sensitivity, interference characteristics, block-fading effects, and constraints on the maximum transmission unit. It supports update sparsification, quantization, compression, forward frame-erasure correction (FEC), and duty cycling. Numerical results illustrate the impact of transmission parameters (spreading factor, FEC rate) and interference on FL performance. Demonstrating the critical role of FEC in enabling FL over LoRa networks, we perform an in-depth evaluation of the impact of FEC on FL convergence and device airtime, providing insights for communication protocol design for FL over LoRa networks.",
    "source": "arXiv"
  },
  {
    "title": "HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs",
    "title_es": "HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs",
    "url": "https://arxiv.org/abs/2508.10576",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10576v1 Announce Type: new \nAbstract: While Multimodal Large Language Models (MLLMs) show immense promise for achieving truly human-like interactions, progress is hindered by the lack of fine-grained evaluation frameworks for human-centered scenarios, encompassing both the understanding of complex human intentions and the provision of empathetic, context-aware responses. Here we introduce HumanSense, a comprehensive benchmark designed to evaluate the human-centered perception and interaction capabilities of MLLMs, with a particular focus on deep understanding of extended multimodal contexts and the formulation of rational feedback. Our evaluation reveals that leading MLLMs still have considerable room for improvement, particularly for advanced interaction-oriented tasks. Supplementing visual input with audio and text information yields substantial improvements, and Omni-modal models show advantages on these tasks. Furthermore, we argue that appropriate feedback stems from a contextual analysis of the interlocutor's needs and emotions, with reasoning ability serving as the key to unlocking it. Accordingly, we employ a multi-stage, modality-progressive reinforcement learning to enhance the reasoning abilities of an Omni model, achieving substantial gains on evaluation results. Additionally, we observe that successful reasoning processes exhibit highly consistent thought patterns. By designing corresponding prompts, we also enhance the performance of non-reasoning models in a training-free manner. Project page: \\textcolor{brightpink}https://digital-avatar.github.io/ai/HumanSense/",
    "source": "arXiv"
  },
  {
    "title": "Efficient and Optimally Accurate Numerical Algorithms for Stochastic Turbulent Flow Problems",
    "title_es": "Efficient and Optimally Accurate Numerical Algorithms for Stochastic Turbulent Flow Problems",
    "url": "https://arxiv.org/abs/2508.10578",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10578v1 Announce Type: new \nAbstract: In this paper, we first propose a filter-based continuous Ensemble Eddy Viscosity (EEV) model for stochastic turbulent flow problems. We then propose a generic algorithm for a family of fully discrete, grad-div regularized, efficient ensemble parameterized schemes for this model. The linearized Implicit-Explicit (IMEX) EEV generic algorithm shares a common coefficient matrix for each realization per time-step, but with different right-hand-side vectors, which reduces the computational cost and memory requirements to the order of solving deterministic flow problems. Two family members of the proposed time-stepping algorithm are analyzed and proven to be stable. It is found that one is first-order and the other is second-order accurate in time for any stable finite element pairs. Avoiding the discrete inverse inequality, the optimal convergence of both schemes is proven rigorously for both 2D and 3D problems. For appropriately large grad-div parameters, both schemes are unconditionally stable and allow weakly divergence-free elements. Several numerical tests are given for high expected Reynolds number ($\\textbf{E}[Re]$) problems. The convergence rates are verified using manufactured solutions with $\\textbf{E}[Re]=10^{3},10^{4},\\;\\text{and}\\; 10^{5}$. For various high $\\textbf{E}[Re]$, the schemes are implemented on benchmark problems which includes: A 2D channel flow over a unit step problem, a non-intrusive Stochastic Collocation Method (SCM) is used to examine the performance of the schemes on a 2D Regularized Lid Driven Cavity (RLDC) problem, and a 3D RLDC problem, and found them perform well.",
    "source": "arXiv"
  },
  {
    "title": "Ensembling Synchronisation-based and Face-Voice Association Paradigms for Robust Active Speaker Detection in Egocentric Recordings",
    "title_es": "Ensembling Synchronisation-based and Face-Voice Association Paradigms for Robust Active Speaker Detection in Egocentric Recordings",
    "url": "https://arxiv.org/abs/2508.10580",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10580v1 Announce Type: new \nAbstract: Audiovisual active speaker detection (ASD) in egocentric recordings is challenged by frequent occlusions, motion blur, and audio interference, which undermine the discernability of temporal synchrony between lip movement and speech. Traditional synchronisation-based systems perform well under clean conditions but degrade sharply in first-person recordings. Conversely, face-voice association (FVA)-based methods forgo synchronisation modelling in favour of cross-modal biometric matching, exhibiting robustness to transient visual corruption but suffering when overlapping speech or front-end segmentation errors occur. In this paper, a simple yet effective ensemble approach is proposed to fuse synchronisation-dependent and synchronisation-agnostic model outputs via weighted averaging, thereby harnessing complementary cues without introducing complex fusion architectures. A refined preprocessing pipeline for the FVA-based component is also introduced to optimise ensemble integration. Experiments on the Ego4D-AVD validation set demonstrate that the ensemble attains 70.2% and 66.7% mean Average Precision (mAP) with TalkNet and Light-ASD backbones, respectively. A qualitative analysis stratified by face image quality and utterance masking prevalence further substantiates the complementary strengths of each component.",
    "source": "arXiv"
  },
  {
    "title": "Technical Report: Facilitating the Adoption of Causal Inference Methods Through LLM-Empowered Co-Pilot",
    "title_es": "Technical Report: Facilitating the Adoption of Causal Inference Methods Through LLM-Empowered Co-Pilot",
    "url": "https://arxiv.org/abs/2508.10581",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10581v1 Announce Type: new \nAbstract: Estimating treatment effects (TE) from observational data is a critical yet complex task in many fields, from healthcare and economics to public policy. While recent advances in machine learning and causal inference have produced powerful estimation techniques, their adoption remains limited due to the need for deep expertise in causal assumptions, adjustment strategies, and model selection. In this paper, we introduce CATE-B, an open-source co-pilot system that uses large language models (LLMs) within an agentic framework to guide users through the end-to-end process of treatment effect estimation. CATE-B assists in (i) constructing a structural causal model via causal discovery and LLM-based edge orientation, (ii) identifying robust adjustment sets through a novel Minimal Uncertainty Adjustment Set criterion, and (iii) selecting appropriate regression methods tailored to the causal structure and dataset characteristics. To encourage reproducibility and evaluation, we release a suite of benchmark tasks spanning diverse domains and causal complexities. By combining causal inference with intelligent, interactive assistance, CATE-B lowers the barrier to rigorous causal analysis and lays the foundation for a new class of benchmarks in automated treatment effect estimation.",
    "source": "arXiv"
  },
  {
    "title": "EvTurb: Event Camera Guided Turbulence Removal",
    "title_es": "EvTurb: Event Camera Guided Turbulence Removal",
    "url": "https://arxiv.org/abs/2508.10582",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10582v1 Announce Type: new \nAbstract: Atmospheric turbulence degrades image quality by introducing blur and geometric tilt distortions, posing significant challenges to downstream computer vision tasks. Existing single-image and multi-frame methods struggle with the highly ill-posed nature of this problem due to the compositional complexity of turbulence-induced distortions. To address this, we propose EvTurb, an event guided turbulence removal framework that leverages high-speed event streams to decouple blur and tilt effects. EvTurb decouples blur and tilt effects by modeling event-based turbulence formation, specifically through a novel two-step event-guided network: event integrals are first employed to reduce blur in the coarse outputs. This is followed by employing a variance map, derived from raw event streams, to eliminate the tilt distortion for the refined outputs. Additionally, we present TurbEvent, the first real-captured dataset featuring diverse turbulence scenarios. Experimental results demonstrate that EvTurb surpasses state-of-the-art methods while maintaining computational efficiency.",
    "source": "arXiv"
  },
  {
    "title": "GNN-based Unified Deep Learning",
    "title_es": "GNN-based Unified Deep Learning",
    "url": "https://arxiv.org/abs/2508.10583",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10583v1 Announce Type: new \nAbstract: Deep learning models often struggle to maintain generalizability in medical imaging, particularly under domain-fracture scenarios where distribution shifts arise from varying imaging techniques, acquisition protocols, patient populations, demographics, and equipment. In practice, each hospital may need to train distinct models - differing in learning task, width, and depth - to match local data. For example, one hospital may use Euclidean architectures such as MLPs and CNNs for tabular or grid-like image data, while another may require non-Euclidean architectures such as graph neural networks (GNNs) for irregular data like brain connectomes. How to train such heterogeneous models coherently across datasets, while enhancing each model's generalizability, remains an open problem. We propose unified learning, a new paradigm that encodes each model into a graph representation, enabling unification in a shared graph learning space. A GNN then guides optimization of these unified models. By decoupling parameters of individual models and controlling them through a unified GNN (uGNN), our method supports parameter sharing and knowledge transfer across varying architectures (MLPs, CNNs, GNNs) and distributions, improving generalizability. Evaluations on MorphoMNIST and two MedMNIST benchmarks - PneumoniaMNIST and BreastMNIST - show that unified learning boosts performance when models are trained on unique distributions and tested on mixed ones, demonstrating strong robustness to unseen data with large distribution shifts. Code and benchmarks: https://github.com/basiralab/uGNN",
    "source": "arXiv"
  },
  {
    "title": "DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System",
    "title_es": "DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System",
    "url": "https://arxiv.org/abs/2508.10584",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10584v1 Announce Type: new \nAbstract: Semantic IDs are discrete identifiers generated by quantizing the Multi-modal Large Language Models (MLLMs) embeddings, enabling efficient multi-modal content integration in recommendation systems. However, their lack of collaborative signals results in a misalignment with downstream discriminative and generative recommendation objectives. Recent studies have introduced various alignment mechanisms to address this problem, but their two-stage framework design still leads to two main limitations: (1) inevitable information loss during alignment, and (2) inflexibility in applying adaptive alignment strategies, consequently constraining the mutual information maximization during the alignment process. To address these limitations, we propose a novel and flexible one-stage Dual-Aligned Semantic IDs (DAS) method that simultaneously optimizes quantization and alignment, preserving semantic integrity and alignment quality while avoiding the information loss typically associated with two-stage methods. Meanwhile, DAS achieves more efficient alignment between the semantic IDs and collaborative signals, with the following two innovative and effective approaches: (1) Multi-view Constrative Alignment: To maximize mutual information between semantic IDs and collaborative signals, we first incorporate an ID-based CF debias module, and then design three effective contrastive alignment methods: dual user-to-item (u2i), dual item-to-item/user-to-user (i2i/u2u), and dual co-occurrence item-to-item/user-to-user (i2i/u2u). (2) Dual Learning: By aligning the dual quantizations of users and ads, the constructed semantic IDs for users and ads achieve stronger alignment. Finally, we conduct extensive offline experiments and online A/B tests to evaluate DAS's effectiveness, which is now successfully deployed across various advertising scenarios at Kuaishou App, serving over 400 million users daily.",
    "source": "arXiv"
  },
  {
    "title": "Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions",
    "title_es": "Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions",
    "url": "https://arxiv.org/abs/2508.10586",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10586v1 Announce Type: new \nAbstract: Proxemics, the study of spatial behavior, is fundamental to social interaction and increasingly relevant for virtual reality (VR) applications. While previous research has established that users respond to personal space violations in VR similarly as in real-world settings, phase-specific physiological responses and the modulating effects of facial expressions remain understudied. We investigated physiological and subjective responses to personal space violations by virtual avatars, to understand how threatening facial expressions and interaction phases (approach vs. standing) influence these responses. Sixteen participants experienced a 2x2 factorial design manipulating Personal Space (intrusion vs. respect) and Facial Expression (neutral vs. angry) while we recorded skin conductance response (SCR), heart rate variability (HRV), and discomfort ratings. Personal space boundaries were individually calibrated using a stop-distance procedure. Results show that SCR responses are significantly higher during the standing phase compared to the approach phase when personal space was violated, indicating that prolonged proximity within personal space boundaries is more physiologically arousing than the approach itself. Angry facial expressions significantly reduced HRV, reflecting decreased parasympathetic activity, and increased discomfort ratings, but did not amplify SCR responses. These findings demonstrate that different physiological modalities capture distinct aspects of proxemic responses: SCR primarily reflects spatial boundary violations, while HRV responds to facial threat cues. Our results provide insights for developing comprehensive multi-modal assessments of social behavior in virtual environments and inform the design of more realistic avatar interactions.",
    "source": "arXiv"
  },
  {
    "title": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer",
    "title_es": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer",
    "url": "https://arxiv.org/abs/2508.10587",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10587v1 Announce Type: new \nAbstract: To bridge the temporal granularity gap in energy network design and operation based on Energy System Models, resampling of time series is required. While conventional upsampling methods are computationally efficient, they often result in significant information loss or increased noise. Advanced models such as time series generation models, Super-Resolution models and imputation models show potential, but also face fundamental challenges. The goal of time series generative models is to learn the distribution of the original data to generate high-resolution series with similar statistical characteristics. This is not entirely consistent with the definition of upsampling. Time series Super-Resolution models or imputation models can degrade the accuracy of upsampling because the input low-resolution time series are sparse and may have insufficient context. Moreover, such models usually rely on supervised learning paradigms. This presents a fundamental application paradox: their training requires the high-resolution time series that is intrinsically absent in upsampling application scenarios. To address the mentioned upsampling issue, this paper introduces a new method utilizing Generative Adversarial Transformers (GATs), which can be trained without access to any ground-truth high-resolution data. Compared with conventional interpolation methods, the introduced method can reduce the root mean square error (RMSE) of upsampling tasks by 9%, and the accuracy of a model predictive control (MPC) application scenario is improved by 13%.",
    "source": "arXiv"
  },
  {
    "title": "Balancing the Energy Consumption and Latency of Over-the-Air Firmware Updates in LoRaWAN",
    "title_es": "Balancing the Energy Consumption and Latency of Over-the-Air Firmware Updates in LoRaWAN",
    "url": "https://arxiv.org/abs/2508.10588",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10588v1 Announce Type: new \nAbstract: Over-the-air firmware updates are crucial for mitigating security threats and maintaining up-to-date device functionality in Long Range Wide Area Networks (LoRaWANs). LoRaWAN end devices are usually energy-constrained, and LoRaWAN transmissions are subject to duty-cycle restrictions. Consequently, controlling the energy expenditure and update-delivery latency of FUOTA are key challenges. We propose a flexible scheme that achieves a tunable trade-off between the energy consumption and delivery delay. The scheme employs the LoRa spreading factors sequentially to transmit update-carrying frames, sending a fixed number of frames with a given spreading factor before moving to the next. By adjusting the smallest spreading factor to be used and the number of transmissions per spreading factor, a suitable energy-delay trade-off can be achieved. Thus, time-sensitive updates, such as security patches, may be sent with a low-delay-high-energy setting, whereas a more energy-efficient but higher-delay setting may be used for non-critical updates.",
    "source": "arXiv"
  },
  {
    "title": "FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection",
    "title_es": "FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.10594",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10594v1 Announce Type: new \nAbstract: Graph Anomaly Detection (GAD) aims to identify nodes that deviate from the majority within a graph, playing a crucial role in applications such as social networks and e-commerce. Despite the current advancements in deep learning-based GAD, existing approaches often suffer from high deployment costs and poor scalability due to their complex and resource-intensive training processes. Surprisingly, our empirical findings suggest that the training phase of deep GAD methods, commonly perceived as crucial, may actually contribute less to anomaly detection performance than expected. Inspired by this, we propose FreeGAD, a novel training-free yet effective GAD method. Specifically, it leverages an affinity-gated residual encoder to generate anomaly-aware representations. Meanwhile, FreeGAD identifies anchor nodes as pseudo-normal and anomalous guides, followed by calculating anomaly scores through anchor-guided statistical deviations. Extensive experiments demonstrate that FreeGAD achieves superior anomaly detection performance, efficiency, and scalability on multiple benchmark datasets from diverse domains, without any training or iterative optimization.",
    "source": "arXiv"
  },
  {
    "title": "On Spectral Properties of Gradient-based Explanation Methods",
    "title_es": "On Spectral Properties of Gradient-based Explanation Methods",
    "url": "https://arxiv.org/abs/2508.10595",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10595v1 Announce Type: new \nAbstract: Understanding the behavior of deep networks is crucial to increase our confidence in their results. Despite an extensive body of work for explaining their predictions, researchers have faced reliability issues, which can be attributed to insufficient formalism. In our research, we adopt novel probabilistic and spectral perspectives to formally analyze explanation methods. Our study reveals a pervasive spectral bias stemming from the use of gradient, and sheds light on some common design choices that have been discovered experimentally, in particular, the use of squared gradient and input perturbation. We further characterize how the choice of perturbation hyperparameters in explanation methods, such as SmoothGrad, can lead to inconsistent explanations and introduce two remedies based on our proposed formalism: (i) a mechanism to determine a standard perturbation scale, and (ii) an aggregation method which we call SpectralLens. Finally, we substantiate our theoretical results through quantitative evaluations.",
    "source": "arXiv"
  },
  {
    "title": "Oops!... They Stole it Again: Attacks on Split Learning",
    "title_es": "Oops!... They Stole it Again: Attacks on Split Learning",
    "url": "https://arxiv.org/abs/2508.10598",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10598v1 Announce Type: new \nAbstract: Split Learning (SL) is a collaborative learning approach that improves privacy by keeping data on the client-side while sharing only the intermediate output with a server. However, the distributed nature of SL introduces new security challenges, necessitating a comprehensive exploration of potential attacks. This paper systematically reviews various attacks on SL, classifying them based on factors such as the attacker's role, the type of privacy risks, when data leaks occur, and where vulnerabilities exist. We also analyze existing defense methods, including cryptographic methods, data modification approaches, distributed techniques, and hybrid solutions. Our findings reveal security gaps, highlighting the effectiveness and limitations of existing defenses. By identifying open challenges and future directions, this work provides valuable information to improve SL privacy issues and guide further research.",
    "source": "arXiv"
  },
  {
    "title": "MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models",
    "title_es": "MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models",
    "url": "https://arxiv.org/abs/2508.10599",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10599v1 Announce Type: new \nAbstract: Activation steering offers a promising approach to controlling the behavior of Large Language Models by directly manipulating their internal activations. However, most existing methods struggle to jointly steer multiple attributes, often resulting in interference and undesirable trade-offs. To address this challenge, we propose Multi-Subspace Representation Steering (MSRS), a novel framework for effective multi-attribute steering via subspace representation fine-tuning. MSRS reduces inter-attribute interference by allocating orthogonal subspaces to each attribute, isolating their influence within the model's representation space. MSRS also incorporates a hybrid subspace composition strategy: it combines attribute-specific subspaces for unique steering directions with a shared subspace for common steering directions. A dynamic weighting function learns to efficiently integrate these components for precise control. During inference, MSRS introduces a token-level steering mechanism that dynamically identifies and intervenes on the most semantically relevant tokens, enabling fine-grained behavioral modulation. Experimental results show that MSRS significantly reduces attribute conflicts, surpasses existing methods across a range of attributes, and generalizes effectively to diverse downstream tasks.",
    "source": "arXiv"
  },
  {
    "title": "Towards Powerful and Practical Patch Attacks for 2D Object Detection in Autonomous Driving",
    "title_es": "Towards Powerful and Practical Patch Attacks for 2D Object Detection in Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.10600",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10600v1 Announce Type: new \nAbstract: Learning-based autonomous driving systems remain critically vulnerable to adversarial patches, posing serious safety and security risks in their real-world deployment. Black-box attacks, notable for their high attack success rate without model knowledge, are especially concerning, with their transferability extensively studied to reduce computational costs compared to query-based attacks. Previous transferability-based black-box attacks typically adopt mean Average Precision (mAP) as the evaluation metric and design training loss accordingly. However, due to the presence of multiple detected bounding boxes and the relatively lenient Intersection over Union (IoU) thresholds, the attack effectiveness of these approaches is often overestimated, resulting in reduced success rates in practical attacking scenarios. Furthermore, patches trained on low-resolution data often fail to maintain effectiveness on high-resolution images, limiting their transferability to autonomous driving datasets. To fill this gap, we propose P$^3$A, a Powerful and Practical Patch Attack framework for 2D object detection in autonomous driving, specifically optimized for high-resolution datasets. First, we introduce a novel metric, Practical Attack Success Rate (PASR), to more accurately quantify attack effectiveness with greater relevance for pedestrian safety. Second, we present a tailored Localization-Confidence Suppression Loss (LCSL) to improve attack transferability under PASR. Finally, to maintain the transferability for high-resolution datasets, we further incorporate the Probabilistic Scale-Preserving Padding (PSPP) into the patch attack pipeline as a data preprocessing step. Extensive experiments show that P$^3$A outperforms state-of-the-art attacks on unseen models and unseen high-resolution datasets, both under the proposed practical IoU-based evaluation metric and the previous mAP-based metrics.",
    "source": "arXiv"
  },
  {
    "title": "Feedback stabilization of a nanoparticle at the intensity minimum of an optical double-well potential",
    "title_es": "Feedback stabilization of a nanoparticle at the intensity minimum of an optical double-well potential",
    "url": "https://arxiv.org/abs/2508.10601",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10601v1 Announce Type: new \nAbstract: In this work, we develop and analyze adaptive feedback control strategies to stabilize and confine a nanoparticle at the unstable intensity minimum of an optical double-well potential. The resulting stochastic optimal control problem for a noise-driven mechanical particle in a nonlinear optical potential must account for unavoidable experimental imperfections such as measurement nonlinearities and slow drifts of the optical setup. To address these issues, we simplify the model in the vicinity of the unstable equilibrium and employ indirect adaptive control techniques to dynamically follow changes in the potential landscape. Our approach leads to a simple and efficient Linear Quadratic Gaussian (LQG) controller that can be implemented on fast and cost-effective FPGAs, ensuring accessibility and reproducibility. We demonstrate that this strategy successfully tracks the intensity minimum and significantly reduces the nanoparticle's residual state variance, effectively lowering its center-of-mass temperature. While conventional optical traps rely on confining optical forces in the light field at the intensity maxima, trapping at intensity minima mitigates absorption heating, which is crucial for advanced quantum experiments. Since LQG control naturally extends into the quantum regime, our results provide a promising pathway for future experiments on quantum state preparation beyond the current absorption heating limitation, like matter-wave interference and tests of the quantum-gravity interface.",
    "source": "arXiv"
  },
  {
    "title": "Why Report Failed Interactions With Robots?! Towards Vignette-based Interaction Quality",
    "title_es": "Why Report Failed Interactions With Robots?! Towards Vignette-based Interaction Quality",
    "url": "https://arxiv.org/abs/2508.10603",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10603v1 Announce Type: new \nAbstract: Although the quality of human-robot interactions has improved with the advent of LLMs, there are still various factors that cause systems to be sub-optimal when compared to human-human interactions. The nature and criticality of failures are often dependent on the context of the interaction and so cannot be generalized across the wide range of scenarios and experiments which have been implemented in HRI research. In this work we propose the use of a technique overlooked in the field of HRI, ethnographic vignettes, to clearly highlight these failures, particularly those that are rarely documented. We describe the methodology behind the process of writing vignettes and create our own based on our personal experiences with failures in HRI systems. We emphasize the strength of vignettes as the ability to communicate failures from a multi-disciplinary perspective, promote transparency about the capabilities of robots, and document unexpected behaviours which would otherwise be omitted from research reports. We encourage the use of vignettes to augment existing interaction evaluation methods.",
    "source": "arXiv"
  },
  {
    "title": "Variance Reduced Policy Gradient Method for Multi-Objective Reinforcement Learning",
    "title_es": "Variance Reduced Policy Gradient Method for Multi-Objective Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.10608",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10608v1 Announce Type: new \nAbstract: Multi-Objective Reinforcement Learning (MORL) is a generalization of traditional Reinforcement Learning (RL) that aims to optimize multiple, often conflicting objectives simultaneously rather than focusing on a single reward. This approach is crucial in complex decision-making scenarios where agents must balance trade-offs between various goals, such as maximizing performance while minimizing costs. We consider the problem of MORL where the objectives are combined using a non-linear scalarization function. Just like in standard RL, policy gradient methods (PGMs) are amongst the most effective for handling large and continuous state-action spaces in MORL. However, existing PGMs for MORL suffer from high sample inefficiency, requiring large amounts of data to be effective. Previous attempts to solve this problem rely on overly strict assumptions, losing PGMs' benefits in scalability to large state-action spaces. In this work, we address the issue of sample efficiency by implementing variance-reduction techniques to reduce the sample complexity of policy gradients while maintaining general assumptions.",
    "source": "arXiv"
  },
  {
    "title": "FuXi-\\beta: Towards a Lightweight and Fast Large-Scale Generative Recommendation Model",
    "title_es": "FuXi-\\beta: Towards a Lightweight and Fast Large-Scale Generative Recommendation Model",
    "url": "https://arxiv.org/abs/2508.10615",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10615v1 Announce Type: new \nAbstract: Scaling laws for autoregressive generative recommenders reveal potential for larger, more versatile systems but mean greater latency and training costs. To accelerate training and inference, we investigated the recent generative recommendation models HSTU and FuXi-$\\alpha$, identifying two efficiency bottlenecks: the indexing operations in relative temporal attention bias and the computation of the query-key attention map. Additionally, we observed that relative attention bias in self-attention mechanisms can also serve as attention maps. Previous works like Synthesizer have shown that alternative forms of attention maps can achieve similar performance, naturally raising the question of whether some attention maps are redundant. Through empirical experiments, we discovered that using the query-key attention map might degrade the model's performance in recommendation tasks. To address these bottlenecks, we propose a new framework applicable to Transformer-like recommendation models. On one hand, we introduce Functional Relative Attention Bias, which avoids the time-consuming operations of the original relative attention bias, thereby accelerating the process. On the other hand, we remove the query-key attention map from the original self-attention layer and design a new Attention-Free Token Mixer module. Furthermore, by applying this framework to FuXi-$\\alpha$, we introduce a new model, FuXi-$\\beta$. Experiments across multiple datasets demonstrate that FuXi-$\\beta$ outperforms previous state-of-the-art models and achieves significant acceleration compared to FuXi-$\\alpha$, while also adhering to the scaling law. Notably, FuXi-$\\beta$ shows an improvement of 27% to 47% in the NDCG@10 metric on large-scale industrial datasets compared to FuXi-$\\alpha$. Our code is available in a public repository: https://github.com/USTC-StarTeam/FuXi-beta",
    "source": "arXiv"
  },
  {
    "title": "Fourier-Guided Attention Upsampling for Image Super-Resolution",
    "title_es": "Fourier-Guided Attention Upsampling for Image Super-Resolution",
    "url": "https://arxiv.org/abs/2508.10616",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10616v1 Announce Type: new \nAbstract: We propose Frequency-Guided Attention (FGA), a lightweight upsampling module for single image super-resolution. Conventional upsamplers, such as Sub-Pixel Convolution, are efficient but frequently fail to reconstruct high-frequency details and introduce aliasing artifacts. FGA addresses these issues by integrating (1) a Fourier feature-based Multi-Layer Perceptron (MLP) for positional frequency encoding, (2) a cross-resolution Correlation Attention Layer for adaptive spatial alignment, and (3) a frequency-domain L1 loss for spectral fidelity supervision. Adding merely 0.3M parameters, FGA consistently enhances performance across five diverse super-resolution backbones in both lightweight and full-capacity scenarios. Experimental results demonstrate average PSNR gains of 0.12~0.14 dB and improved frequency-domain consistency by up to 29%, particularly evident on texture-rich datasets. Visual and spectral evaluations confirm FGA's effectiveness in reducing aliasing and preserving fine details, establishing it as a practical, scalable alternative to traditional upsampling methods.",
    "source": "arXiv"
  },
  {
    "title": "FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction",
    "title_es": "FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction",
    "url": "https://arxiv.org/abs/2508.10617",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10617v1 Announce Type: new \nAbstract: Metal artifacts, caused by high-density metallic implants in computed tomography (CT) imaging, severely degrade image quality, complicating diagnosis and treatment planning. While existing deep learning algorithms have achieved notable success in Metal Artifact Reduction (MAR), they often struggle to suppress artifacts while preserving structural details. To address this challenge, we propose FIND-Net (Fourier-Integrated Network with Dictionary Kernels), a novel MAR framework that integrates frequency and spatial domain processing to achieve superior artifact suppression and structural preservation. FIND-Net incorporates Fast Fourier Convolution (FFC) layers and trainable Gaussian filtering, treating MAR as a hybrid task operating in both spatial and frequency domains. This approach enhances global contextual understanding and frequency selectivity, effectively reducing artifacts while maintaining anatomical structures. Experiments on synthetic datasets show that FIND-Net achieves statistically significant improvements over state-of-the-art MAR methods, with a 3.07% MAE reduction, 0.18% SSIM increase, and 0.90% PSNR improvement, confirming robustness across varying artifact complexities. Furthermore, evaluations on real-world clinical CT scans confirm FIND-Net's ability to minimize modifications to clean anatomical regions while effectively suppressing metal-induced distortions. These findings highlight FIND-Net's potential for advancing MAR performance, offering superior structural preservation and improved clinical applicability. Code is available at https://github.com/Farid-Tasharofi/FIND-Net",
    "source": "arXiv"
  },
  {
    "title": "DEV: A Driver-Environment-Vehicle Closed-Loop Framework for Risk-Aware Adaptive Automation of Driving",
    "title_es": "DEV: A Driver-Environment-Vehicle Closed-Loop Framework for Risk-Aware Adaptive Automation of Driving",
    "url": "https://arxiv.org/abs/2508.10618",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10618v1 Announce Type: new \nAbstract: The increasing integration of automation in vehicles aims to enhance both safety and comfort, but it also introduces new risks, including driver disengagement, reduced situation awareness, and mode confusion. In this work, we propose the DEV framework, a closed-loop framework for risk-aware adaptive driving automation that captures the dynamic interplay between the driver, the environment, and the vehicle. The framework promotes to continuously adjusting the operational level of automation based on a risk management strategy. The real-time risk assessment supports smoother transitions and effective cooperation between the driver and the automation system. Furthermore, we introduce a nomenclature of indexes corresponding to each core component, namely driver involvement, environment complexity, and vehicle engagement, and discuss how their interaction influences driving risk. The DEV framework offers a comprehensive perspective to align multidisciplinary research efforts and guide the development of dynamic, risk-aware driving automation systems.",
    "source": "arXiv"
  },
  {
    "title": "Are Electrodermal Activity-Based Indicators of Driver Cognitive Distraction Robust to Varying Traffic Conditions and Adaptive Cruise Control Use?",
    "title_es": "Are Electrodermal Activity-Based Indicators of Driver Cognitive Distraction Robust to Varying Traffic Conditions and Adaptive Cruise Control Use?",
    "url": "https://arxiv.org/abs/2508.10620",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10620v1 Announce Type: new \nAbstract: In this simulator study, we investigate whether and how electrodermal activity (EDA) reflects driver cognitive distraction under varying traffic conditions and adaptive cruise control (ACC) use. Participants drove in six scenarios, combining two levels of cognitive distraction (presence/absence of a mental calculation task) and three levels of driving environment complexity (different traffic conditions). Throughout the experiment, they were free to activate or deactivate ACC (ACC use, two levels). We analyzed three EDA-based indicators of cognitive distraction: SCL (mean skin conductance level), SCR amplitude (mean amplitude of skin conductance responses), and SCR rate (rate of skin conductance responses). Results indicate that all three indicators were significantly influenced by cognitive distraction and ACC use, while environment complexity influenced SCL and SCR amplitude, but not SCR rate. These findings suggest that EDA-based indicators reflect variations in drivers' mental workload due not only to cognitive distraction, but also to driving environment and automation use.",
    "source": "arXiv"
  },
  {
    "title": "Gaze-Based Indicators of Driver Cognitive Distraction: Effects of Different Traffic Conditions and Adaptive Cruise Control Use",
    "title_es": "Gaze-Based Indicators of Driver Cognitive Distraction: Effects of Different Traffic Conditions and Adaptive Cruise Control Use",
    "url": "https://arxiv.org/abs/2508.10624",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10624v1 Announce Type: new \nAbstract: In this simulator study, we investigate how gaze parameters reflect driver cognitive distraction under varying traffic conditions and adaptive cruise control (ACC) use. Participants completed six driving scenarios that combined two levels of cognitive distraction (with/without mental calculations) and three levels of driving environment complexity. Throughout the experiment, participants were free to activate or deactivate an ACC. We analyzed two gaze-based indicators of driver cognitive distraction: the percent road center, and the gaze dispersions (horizontal and vertical). Our results show that vertical gaze dispersion increases with traffic complexity, while ACC use leads to gaze concentration toward the road center. Cognitive distraction reduces road center gaze and increases vertical dispersion. Complementary analyses revealed that these observations actually arise mainly between mental calculations, while periods of mental calculations are characterized by a temporary increase in gaze concentration.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Random Sampling: Instance Quality-Based Data Partitioning via Item Response Theory",
    "title_es": "Beyond Random Sampling: Instance Quality-Based Data Partitioning via Item Response Theory",
    "url": "https://arxiv.org/abs/2508.10628",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10628v1 Announce Type: new \nAbstract: Robust validation of Machine Learning (ML) models is essential, but traditional data partitioning approaches often ignore the intrinsic quality of each instance. This study proposes the use of Item Response Theory (IRT) parameters to characterize and guide the partitioning of datasets in the model validation stage. The impact of IRT-informed partitioning strategies on the performance of several ML models in four tabular datasets was evaluated. The results obtained demonstrate that IRT reveals an inherent heterogeneity of the instances and highlights the existence of informative subgroups of instances within the same dataset. Based on IRT, balanced partitions were created that consistently help to better understand the tradeoff between bias and variance of the models. In addition, the guessing parameter proved to be a determining factor: training with high-guessing instances can significantly impair model performance and resulted in cases with accuracy below 50%, while other partitions reached more than 70% in the same dataset.",
    "source": "arXiv"
  },
  {
    "title": "Energy-Based Models for Predicting Mutational Effects on Proteins",
    "title_es": "Energy-Based Models for Predicting Mutational Effects on Proteins",
    "url": "https://arxiv.org/abs/2508.10629",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10629v1 Announce Type: new \nAbstract: Predicting changes in binding free energy ($\\Delta\\Delta G$) is a vital task in protein engineering and protein-protein interaction (PPI) engineering for drug discovery. Previous works have observed a high correlation between $\\Delta\\Delta G$ and entropy, using probabilities of biologically important objects such as side chain angles and residue identities to estimate $\\Delta\\Delta G$. However, estimating the full conformational distribution of a protein complex is generally considered intractable. In this work, we propose a new approach to $\\Delta\\Delta G$ prediction that avoids this issue by instead leveraging energy-based models for estimating the probability of a complex's conformation. Specifically, we novelly decompose $\\Delta\\Delta G$ into a sequence-based component estimated by an inverse folding model and a structure-based component estimated by an energy model. This decomposition is made tractable by assuming equilibrium between the bound and unbound states, allowing us to simplify the estimation of degeneracies associated with each state. Unlike previous deep learning-based methods, our method incorporates an energy-based physical inductive bias by connecting the often-used sequence log-odds ratio-based approach to $\\Delta\\Delta G$ prediction with a new $\\Delta\\Delta E$ term grounded in statistical mechanics. We demonstrate superiority over existing state-of-the-art structure and sequence-based deep learning methods in $\\Delta\\Delta G$ prediction and antibody optimization against SARS-CoV-2.",
    "source": "arXiv"
  },
  {
    "title": "Nonlinear filtering based on density approximation and deep BSDE prediction",
    "title_es": "Nonlinear filtering based on density approximation and deep BSDE prediction",
    "url": "https://arxiv.org/abs/2508.10630",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10630v1 Announce Type: new \nAbstract: A novel approximate Bayesian filter based on backward stochastic differential equations is introduced. It uses a nonlinear Feynman--Kac representation of the filtering problem and the approximation of an unnormalized filtering density using the well-known deep BSDE method and neural networks. The method is trained offline, which means that it can be applied online with new observations. A mixed a priori-a posteriori error bound is proved under an elliptic condition. The theoretical convergence rate is confirmed in two numerical examples.",
    "source": "arXiv"
  },
  {
    "title": "Increasing the Utility of Synthetic Images through Chamfer Guidance",
    "title_es": "Increasing the Utility of Synthetic Images through Chamfer Guidance",
    "url": "https://arxiv.org/abs/2508.10631",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10631v1 Announce Type: new \nAbstract: Conditional image generative models hold considerable promise to produce infinite amounts of synthetic training data. Yet, recent progress in generation quality has come at the expense of generation diversity, limiting the utility of these models as a source of synthetic training data. Although guidance-based approaches have been introduced to improve the utility of generated data by focusing on quality or diversity, the (implicit or explicit) utility functions oftentimes disregard the potential distribution shift between synthetic and real data. In this work, we introduce Chamfer Guidance: a training-free guidance approach which leverages a handful of real exemplar images to characterize the quality and diversity of synthetic data. We show that by leveraging the proposed Chamfer Guidance, we can boost the diversity of the generations w.r.t. a dataset of real images while maintaining or improving the generation quality on ImageNet-1k and standard geo-diversity benchmarks. Our approach achieves state-of-the-art few-shot performance with as little as 2 exemplar real images, obtaining 96.4\\% in terms of precision, and 86.4\\% in terms of distributional coverage, which increase to 97.5\\% and 92.7\\%, respectively, when using 32 real images. We showcase the benefits of the Chamfer Guidance generation by training downstream image classifiers on synthetic data, achieving accuracy boost of up to 15\\% for in-distribution over the baselines, and up to 16\\% in out-of-distribution. Furthermore, our approach does not require using the unconditional model, and thus obtains a 31\\% reduction in FLOPs w.r.t. classifier-free-guidance-based approaches at sampling time.",
    "source": "arXiv"
  },
  {
    "title": "Synthesis of Deep Neural Networks with Safe Robust Adaptive Control for Reliable Operation of Wheeled Mobile Robots",
    "title_es": "Synthesis of Deep Neural Networks with Safe Robust Adaptive Control for Reliable Operation of Wheeled Mobile Robots",
    "url": "https://arxiv.org/abs/2508.10634",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10634v1 Announce Type: new \nAbstract: Deep neural networks (DNNs) can enable precise control while maintaining low computational costs by circumventing the need for dynamic modeling. However, the deployment of such black-box approaches remains challenging for heavy-duty wheeled mobile robots (WMRs), which are subject to strict international standards and prone to faults and disturbances. We designed a hierarchical control policy for heavy-duty WMRs, monitored by two safety layers with differing levels of authority. To this end, a DNN policy was trained and deployed as the primary control strategy, providing high-precision performance under nominal operating conditions. When external disturbances arise and reach a level of intensity such that the system performance falls below a predefined threshold, a low-level safety layer intervenes by deactivating the primary control policy and activating a model-free robust adaptive control (RAC) policy. This transition enables the system to continue operating while ensuring stability by effectively managing the inherent trade-off between system robustness and responsiveness. Regardless of the control policy in use, a high-level safety layer continuously monitors system performance during operation. It initiates a shutdown only when disturbances become sufficiently severe such that compensation is no longer viable and continued operation would jeopardize the system or its environment. The proposed synthesis of DNN and RAC policy guarantees uniform exponential stability of the entire WMR system while adhering to safety standards to some extent. The effectiveness of the proposed approach was further validated through real-time experiments using a 6,000 kg WMR.",
    "source": "arXiv"
  },
  {
    "title": "ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation",
    "title_es": "ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation",
    "url": "https://arxiv.org/abs/2508.10635",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10635v1 Announce Type: new \nAbstract: Understanding environmental changes from aerial imagery is vital for climate resilience, urban planning, and ecosystem monitoring. Yet, current vision language models (VLMs) overlook causal signals from environmental sensors, rely on single-source captions prone to stylistic bias, and lack interactive scenario-based reasoning. We present ChatENV, the first interactive VLM that jointly reasons over satellite image pairs and real-world sensor data. Our framework: (i) creates a 177k-image dataset forming 152k temporal pairs across 62 land-use classes in 197 countries with rich sensor metadata (e.g., temperature, PM10, CO); (ii) annotates data using GPT- 4o and Gemini 2.0 for stylistic and semantic diversity; and (iii) fine-tunes Qwen-2.5-VL using efficient Low-Rank Adaptation (LoRA) adapters for chat purposes. ChatENV achieves strong performance in temporal and \"what-if\" reasoning (e.g., BERT-F1 0.903) and rivals or outperforms state-of-the-art temporal models, while supporting interactive scenario-based analysis. This positions ChatENV as a powerful tool for grounded, sensor-aware environmental monitoring.",
    "source": "arXiv"
  },
  {
    "title": "A Transformer-Based Approach for DDoS Attack Detection in IoT Networks",
    "title_es": "A Transformer-Based Approach for DDoS Attack Detection in IoT Networks",
    "url": "https://arxiv.org/abs/2508.10636",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10636v1 Announce Type: new \nAbstract: DDoS attacks have become a major threat to the security of IoT devices and can cause severe damage to the network infrastructure. IoT devices suffer from the inherent problem of resource constraints and are therefore susceptible to such resource-exhausting attacks. Traditional methods for detecting DDoS attacks are not efficient enough to cope with the dynamic nature of IoT networks, as well as the scalability of the attacks, diversity of protocols, high volume of traffic, and variability in device behavior, and variability of protocols like MQTT, CoAP, making it hard to implement security across all the protocols. In this paper, we propose a novel approach, i.e., the use of Transformer models, which have shown remarkable performance in natural language processing tasks, for detecting DDoS attacks on IoT devices. The proposed model extracts features from network traffic data and processes them using a self-attention mechanism. Experiments conducted on a real-world dataset demonstrate that the proposed approach outperforms traditional machine learning techniques, which can be validated by comparing both approaches' accuracy, precision, recall, and F1-score. The results of this study show that the Transformer models can be an effective solution for detecting DDoS attacks on IoT devices and have the potential to be deployed in real-world IoT environments.",
    "source": "arXiv"
  },
  {
    "title": "Processing and acquisition traces in visual encoders: What does CLIP know about your camera?",
    "title_es": "Processing and acquisition traces in visual encoders: What does CLIP know about your camera?",
    "url": "https://arxiv.org/abs/2508.10637",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10637v1 Announce Type: new \nAbstract: Prior work has analyzed the robustness of visual encoders to image transformations and corruptions, particularly in cases where such alterations are not seen during training. When this occurs, they introduce a form of distribution shift at test time, often leading to performance degradation. The primary focus has been on severe corruptions that, when applied aggressively, distort useful signals necessary for accurate semantic predictions.\n  We take a different perspective by analyzing parameters of the image acquisition process and transformations that may be subtle or even imperceptible to the human eye. We find that such parameters are systematically encoded in the learned visual representations and can be easily recovered. More strikingly, their presence can have a profound impact, either positively or negatively, on semantic predictions. This effect depends on whether there is a strong correlation or anti-correlation between semantic labels and these acquisition-based or processing-based labels. Our code and data are available at: https://github.com/ryan-caesar-ramos/visual-encoder-traces",
    "source": "arXiv"
  },
  {
    "title": "MirGuard: Towards a Robust Provenance-based Intrusion Detection System Against Graph Manipulation Attacks",
    "title_es": "MirGuard: Towards a Robust Provenance-based Intrusion Detection System Against Graph Manipulation Attacks",
    "url": "https://arxiv.org/abs/2508.10639",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10639v1 Announce Type: new \nAbstract: Learning-based Provenance-based Intrusion Detection Systems (PIDSes) have become essential tools for anomaly detection in host systems due to their ability to capture rich contextual and structural information, as well as their potential to detect unknown attacks. However, recent studies have shown that these systems are vulnerable to graph manipulation attacks, where attackers manipulate the graph structure to evade detection. While some previous approaches have discussed this type of attack, none have fully addressed it with a robust detection solution, limiting the practical applicability of PIDSes.\n  To address this challenge, we propose MirGuard, a robust anomaly detection framework that combines logic-aware multi-view augmentation with contrastive representation learning. Rather than applying arbitrary structural perturbations, MirGuard introduces Logic-Aware Noise Injection (LNI) to generate semantically valid graph views, ensuring that all augmentations preserve the underlying causal semantics of the provenance data. These views are then used in a Logic-Preserving Contrastive Learning framework, which encourages the model to learn representations that are invariant to benign transformations but sensitive to adversarial inconsistencies. Comprehensive evaluations on multiple provenance datasets demonstrate that MirGuard significantly outperforms state-of-the-art detectors in robustness against various graph manipulation attacks without sacrificing detection performance and efficiency. Our work represents the first targeted study to enhance PIDS against such adversarial threats, providing a robust and effective solution to modern cybersecurity challenges.",
    "source": "arXiv"
  },
  {
    "title": "Lameness detection in dairy cows using pose estimation and bidirectional LSTMs",
    "title_es": "Lameness detection in dairy cows using pose estimation and bidirectional LSTMs",
    "url": "https://arxiv.org/abs/2508.10643",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10643v1 Announce Type: new \nAbstract: This study presents a lameness detection approach that combines pose estimation and Bidirectional Long-Short-Term Memory (BLSTM) neural networks. Combining pose-estimation and BLSTMs classifier offers the following advantages: markerless pose-estimation, elimination of manual feature engineering by learning temporal motion features from the keypoint trajectories, and working with short sequences and small training datasets. Motion sequences of nine keypoints (located on the cows' hooves, head and back) were extracted from videos of walking cows with the T-LEAP pose estimation model. The trajectories of the keypoints were then used as an input to a BLSTM classifier that was trained to perform binary lameness classification. Our method significantly outperformed an established method that relied on manually-designed locomotion features: our best architecture achieved a classification accuracy of 85%, against 80% accuracy for the feature-based approach. Furthermore, we showed that our BLSTM classifier could detect lameness with as little as one second of video data.",
    "source": "arXiv"
  },
  {
    "title": "Conditional Information Bottleneck for Multimodal Fusion: Overcoming Shortcut Learning in Sarcasm Detection",
    "title_es": "Conditional Information Bottleneck for Multimodal Fusion: Overcoming Shortcut Learning in Sarcasm Detection",
    "url": "https://arxiv.org/abs/2508.10644",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10644v1 Announce Type: new \nAbstract: Multimodal sarcasm detection is a complex task that requires distinguishing subtle complementary signals across modalities while filtering out irrelevant information. Many advanced methods rely on learning shortcuts from datasets rather than extracting intended sarcasm-related features. However, our experiments show that shortcut learning impairs the model's generalization in real-world scenarios. Furthermore, we reveal the weaknesses of current modality fusion strategies for multimodal sarcasm detection through systematic experiments, highlighting the necessity of focusing on effective modality fusion for complex emotion recognition. To address these challenges, we construct MUStARD++$^{R}$ by removing shortcut signals from MUStARD++. Then, a Multimodal Conditional Information Bottleneck (MCIB) model is introduced to enable efficient multimodal fusion for sarcasm detection. Experimental results show that the MCIB achieves the best performance without relying on shortcut learning.",
    "source": "arXiv"
  },
  {
    "title": "SemPT: Semantic Prompt Tuning for Vision-Language Models",
    "title_es": "SemPT: Semantic Prompt Tuning for Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.10645",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10645v1 Announce Type: new \nAbstract: Visual transfer learning for unseen categories presents an active research topic yet a challenging task, due to the inherent conflict between preserving category-specific representations and acquiring transferable knowledge. Vision-Language Models (VLMs) pre-trained on large amounts of image-text pairs offer a promising solution. However, existing prompt tuning methods rely on sparse category labels or disparate LLM-generated descriptions, which fragment knowledge representation and hinder transferability. To address this limitation, we introduce Semantic Prompt Tuning (SemPT), a novel framework that tackles the generalization challenge by leveraging shared attribute-level knowledge across categories. Specifically, SemPT adopts a two-step prompting strategy to guide LLM in extracting shared visual attributes and generating attribute-level descriptions, capturing transferable semantic cues beyond labels while ensuring coherent structure. Then, visually guided weighting is applied to the embeddings of attribute-level descriptions to reduce noise from irrelevant attributes and enhance the text embeddings. Additionally, image embeddings are jointly aligned with both label and attribute-enhanced text embeddings, balancing discrimination for seen categories and transferability to unseen ones. Considering the availability of category exposure, our inference dynamically selects between standard label embeddings for seen categories and attribute-enhanced embeddings for unseen ones to ensure effective adaptation. Extensive experiments on 15 benchmark datasets demonstrate that SemPT achieves state-of-the-art performance across various settings, including base-to-novel generalization, cross-dataset transfer, cross-domain transfer, and few-shot learning.",
    "source": "arXiv"
  },
  {
    "title": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics",
    "title_es": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics",
    "url": "https://arxiv.org/abs/2508.10646",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10646v1 Announce Type: new \nAbstract: By incorporating spatial location information, spatial-transcriptomics clustering yields more comprehensive insights into cell subpopulation identification. Despite recent progress, existing methods have at least two limitations: (i) topological learning typically considers only representations of individual cells or their interaction graphs; however, spatial transcriptomic profiles are often noisy, making these approaches vulnerable to low-quality topological signals, and (ii) insufficient modeling of spatial neighborhood information leads to low-quality spatial embeddings. To address these limitations, we propose SPHENIC, a novel Spatial Persistent Homology Enhanced Neighborhood Integrative Clustering method. Specifically, SPHENIC incorporates invariant topological features into the clustering network to achieve stable representation learning. Additionally, to construct high-quality spatial embeddings that reflect the true cellular distribution, we design the Spatial Constraint and Distribution Optimization Module (SCDOM). This module increases the similarity between a cell's embedding and those of its spatial neighbors, decreases similarity with non-neighboring cells, and thereby produces clustering-friendly spatial embeddings. Extensive experiments on 14 benchmark spatial transcriptomic slices demonstrate that SPHENIC achieves superior performance on the spatial clustering task, outperforming existing state-of-the-art methods by 3.31%-6.54% over the best alternative.",
    "source": "arXiv"
  },
  {
    "title": "Isogeometric multi-patch shell analysis using the Geometry + Simulation Modules",
    "title_es": "Isogeometric multi-patch shell analysis using the Geometry + Simulation Modules",
    "url": "https://arxiv.org/abs/2508.10648",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10648v1 Announce Type: new \nAbstract: Isogeometric Analysis (IGA) bridges Computer-Aided Design (CAD) and Finite Element Analysis (FEA) by employing splines as a common basis for geometry and analysis. One of the advantages of IGA is in the realm of thin shell analysis: due to the arbitrary continuity of the spline basis, Kirchhoff-Love shells can be modeled without the need to introduce unknowns for the mid-plane rotations, leading to a reduction in the number of unknowns. In this paper, we provide the background of an implementation of Isogeometric Kirchhoff--Love shells within the Geometry + Simulation Modules (G+Smo). This paper accompanies multiple previous publications and elaborates on the design of the software used in these papers, rather than the novelty of the methods presented therein. The presented implementation provides patch coupling via penalty methods and unstructured splines, goal-oriented error estimators, several algorithms for structural analysis and advanced algorithms for the modeling of wrinkling in hyperelastic membranes. These methods are all contained in three new modules in G+Smo: a module for Kirchhoff-Love shells, a module for structural analysis, and a module for unstructured spline constructions. As motivated in this paper, the modules are implemented to be compatible with future developments. For example, by providing base implementations of material laws, by using black-box functions for the structural analysis module, or by providing a standardized approach for the implementation of unstructured spline constructions. Overall, this paper demonstrates that the new modules contribute to a versatile ecosystem for the modeling of multi-patch shell problems through fast off-the-shelf solvers with a simple interface, designed to be extended in future research.",
    "source": "arXiv"
  },
  {
    "title": "Geospatial Diffusion for Land Cover Imperviousness Change Forecasting",
    "title_es": "Geospatial Diffusion for Land Cover Imperviousness Change Forecasting",
    "url": "https://arxiv.org/abs/2508.10649",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10649v1 Announce Type: new \nAbstract: Land cover, both present and future, has a significant effect on several important Earth system processes. For example, impervious surfaces heat up and speed up surface water runoff and reduce groundwater infiltration, with concomitant effects on regional hydrology and flood risk. While regional Earth System models have increasing skill at forecasting hydrologic and atmospheric processes at high resolution in future climate scenarios, our ability to forecast land-use and land-cover change (LULC), a critical input to risk and consequences assessment for these scenarios, has lagged behind. In this paper, we propose a new paradigm exploiting Generative AI (GenAI) for land cover change forecasting by framing LULC forecasting as a data synthesis problem conditioned on historical and auxiliary data-sources. We discuss desirable properties of generative models that fundament our research premise, and demonstrate the feasibility of our methodology through experiments on imperviousness forecasting using historical data covering the entire conterminous United States. Specifically, we train a diffusion model for decadal forecasting of imperviousness and compare its performance to a baseline that assumes no change at all. Evaluation across 12 metropolitan areas for a year held-out during training indicate that for average resolutions $\\geq 0.7\\times0.7km^2$ our model yields MAE lower than such a baseline. This finding corroborates that such a generative model can capture spatiotemporal patterns from historical data that are significant for projecting future change. Finally, we discuss future research to incorporate auxiliary information on physical properties about the Earth, as well as supporting simulation of different scenarios by means of driver variables.",
    "source": "arXiv"
  },
  {
    "title": "Graph Learning via Logic-Based Weisfeiler-Leman Variants and Tabularization",
    "title_es": "Graph Learning via Logic-Based Weisfeiler-Leman Variants and Tabularization",
    "url": "https://arxiv.org/abs/2508.10651",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10651v1 Announce Type: new \nAbstract: We present a novel approach for graph classification based on tabularizing graph data via variants of the Weisfeiler-Leman algorithm and then applying methods for tabular data. We investigate a comprehensive class of Weisfeiler-Leman variants obtained by modifying the underlying logical framework and establish a precise theoretical characterization of their expressive power. We then test two selected variants on twelve benchmark datasets that span a range of different domains. The experiments demonstrate that our approach matches the accuracy of state-of-the-art graph neural networks and graph kernels while being more time or memory efficient, depending on the dataset. We also briefly discuss directly extracting interpretable modal logic formulas from graph datasets.",
    "source": "arXiv"
  },
  {
    "title": "A Novel Study on Intelligent Methods and Explainable AI for Dynamic Malware Analysis",
    "title_es": "A Novel Study on Intelligent Methods and Explainable AI for Dynamic Malware Analysis",
    "url": "https://arxiv.org/abs/2508.10652",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10652v1 Announce Type: new \nAbstract: Deep learning models are one of the security strategies, trained on extensive datasets, and play a critical role in detecting and responding to these threats by recognizing complex patterns in malicious code. However, the opaque nature of these models-often described as \"black boxes\"-makes their decision-making processes difficult to understand, even for their creators. This research addresses these challenges by integrating Explainable AI (XAI) techniques to enhance the interpretability and trustworthiness of malware detection models. In this research, the use of Multi-Layer Perceptrons (MLP) for dynamic malware analysis has been considered, a less explored area, and its efficacy in detecting Metamorphic Malware, and further the effectiveness and transparency of MLPs, CNNs, RNNs, and CNN-LSTM models in malware classification, evaluating these models through the lens of Explainable AI (XAI). This comprehensive approach aims to demystify the internal workings of deep learning models, promoting a better understanding and trust in their predictive capabilities in cybersecurity contexts. Such in-depth analysis and implementation haven't been done to the best of our knowledge.",
    "source": "arXiv"
  },
  {
    "title": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking",
    "title_es": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking",
    "url": "https://arxiv.org/abs/2508.10655",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10655v1 Announce Type: new \nAbstract: Unifying multiple multi-modal visual object tracking (MMVOT) tasks draws increasing attention due to the complementary nature of different modalities in building robust tracking systems. Existing practices mix all data sensor types in a single training procedure, structuring a parallel paradigm from the data-centric perspective and aiming for a global optimum on the joint distribution of the involved tasks. However, the absence of a unified benchmark where all types of data coexist forces evaluations on separated benchmarks, causing \\textit{inconsistency} between training and testing, thus leading to performance \\textit{degradation}. To address these issues, this work advances in two aspects: \\ding{182} A unified benchmark, coined as UniBench300, is introduced to bridge the inconsistency by incorporating multiple task data, reducing inference passes from three to one and cutting time consumption by 27\\%. \\ding{183} The unification process is reformulated in a serial format, progressively integrating new tasks. In this way, the performance degradation can be specified as knowledge forgetting of previous tasks, which naturally aligns with the philosophy of continual learning (CL), motivating further exploration of injecting CL into the unification process. Extensive experiments conducted on two baselines and four benchmarks demonstrate the significance of UniBench300 and the superiority of CL in supporting a stable unification process. Moreover, while conducting dedicated analyses, the performance degradation is found to be negatively correlated with network capacity. Additionally, modality discrepancies contribute to varying degradation levels across tasks (RGBT > RGBD > RGBE in MMVOT), offering valuable insights for future multi-modal vision research. Source codes and the proposed benchmark is available at \\textit{https://github.com/Zhangyong-Tang/UniBench300}.",
    "source": "arXiv"
  },
  {
    "title": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models",
    "title_es": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.10667",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10667v1 Announce Type: new \nAbstract: Large visual language models (LVLMs) have demonstrated impressive performance in coarse-grained geo-localization at the country or city level, but they struggle with fine-grained street-level localization within urban areas. In this paper, we explore integrating city-wide address localization capabilities into LVLMs, facilitating flexible address-related question answering using street-view images. A key challenge is that the street-view visual question-and-answer (VQA) data provides only microscopic visual cues, leading to subpar performance in fine-tuned models. To tackle this issue, we incorporate perspective-invariant satellite images as macro cues and propose cross-view alignment tuning including a satellite-view and street-view image grafting mechanism, along with an automatic label generation mechanism. Then LVLM's global understanding of street distribution is enhanced through cross-view matching. Our proposed model, named AddressVLM, consists of two-stage training protocols: cross-view alignment tuning and address localization tuning. Furthermore, we have constructed two street-view VQA datasets based on image address localization datasets from Pittsburgh and San Francisco. Qualitative and quantitative evaluations demonstrate that AddressVLM outperforms counterpart LVLMs by over 9% and 12% in average address localization accuracy on these two datasets, respectively.",
    "source": "arXiv"
  },
  {
    "title": "STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation",
    "title_es": "STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation",
    "url": "https://arxiv.org/abs/2508.10669",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10669v1 Announce Type: new \nAbstract: Conversational recommender systems (CRSs) aim to proactively capture user preferences through natural language dialogue and recommend high-quality items. To achieve this, CRS gathers user preferences via a dialog module and builds user profiles through a recommendation module to generate appropriate recommendations. However, existing CRS faces challenges in capturing the deep semantics of user preferences and dialogue context. In particular, the efficient integration of external knowledge graph (KG) information into dialogue generation and recommendation remains a pressing issue. Traditional approaches typically combine KG information directly with dialogue content, which often struggles with complex semantic relationships, resulting in recommendations that may not align with user expectations.\n  To address these challenges, we introduce STEP, a conversational recommender centered on pre-trained language models that combines curriculum-guided context-knowledge fusion with lightweight task-specific prompt tuning. At its heart, an F-Former progressively aligns the dialogue context with knowledge-graph entities through a three-stage curriculum, thus resolving fine-grained semantic mismatches. The fused representation is then injected into the frozen language model via two minimal yet adaptive prefix prompts: a conversation prefix that steers response generation toward user intent and a recommendation prefix that biases item ranking toward knowledge-consistent candidates. This dual-prompt scheme allows the model to share cross-task semantics while respecting the distinct objectives of dialogue and recommendation. Experimental results show that STEP outperforms mainstream methods in the precision of recommendation and dialogue quality in two public datasets.",
    "source": "arXiv"
  },
  {
    "title": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation",
    "title_es": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation",
    "url": "https://arxiv.org/abs/2508.10672",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10672v1 Announce Type: new \nAbstract: In this paper, we present our approach to the DataCV ICCV Challenge, which centers on building a high-quality face dataset to train a face recognition model. The constructed dataset must not contain identities overlapping with any existing public face datasets. To handle this challenge, we begin with a thorough cleaning of the baseline HSFace dataset, identifying and removing mislabeled or inconsistent identities through a Mixture-of-Experts (MoE) strategy combining face embedding clustering and GPT-4o-assisted verification. We retain the largest consistent identity cluster and apply data augmentation up to a fixed number of images per identity. To further diversify the dataset, we generate synthetic identities using Stable Diffusion with prompt engineering. As diffusion models are computationally intensive, we generate only one reference image per identity and efficiently expand it using Vec2Face, which rapidly produces 49 identity-consistent variants. This hybrid approach fuses GAN-based and diffusion-based samples, enabling efficient construction of a diverse and high-quality dataset. To address the high visual similarity among synthetic identities, we adopt a curriculum learning strategy by placing them early in the training schedule, allowing the model to progress from easier to harder samples. Our final dataset contains 50 images per identity, and all newly generated identities are checked with mainstream face datasets to ensure no identity leakage. Our method achieves \\textbf{1st place} in the competition, and experimental results show that our dataset improves model performance across 10K, 20K, and 100K identity scales. Code is available at https://github.com/Ferry-Li/datacv_fr.",
    "source": "arXiv"
  },
  {
    "title": "The Hu-Zhang element for linear elasticity on curved domains",
    "title_es": "The Hu-Zhang element for linear elasticity on curved domains",
    "url": "https://arxiv.org/abs/2508.10674",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10674v1 Announce Type: new \nAbstract: This paper extends the Hu-Zhang element for linear elasticity problems to curved domains, preserving strong symmetry and H(div)-conformity. The non-polynomial structure of the curved Hu-Zhang element makes it difficult to analyze the stability result, which is overcome by establishing a novel inf-sup condition. Optimal convergence rates are achieved for all variables except the stress $L^2$-error. This suboptimality originates from the fact that the divergence space of the curved Hu-Zhang element is not contained in the discrete displacement space, which is rectified by local $p$-enrichment in the Hu-Zhang space on curved boundary elements. Some numerical experiments validate the theoretical results.",
    "source": "arXiv"
  },
  {
    "title": "Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence",
    "title_es": "Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence",
    "url": "https://arxiv.org/abs/2508.10677",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10677v1 Announce Type: new \nAbstract: Effective incident response (IR) is critical for mitigating cyber threats, yet security teams are overwhelmed by alert fatigue, high false-positive rates, and the vast volume of unstructured Cyber Threat Intelligence (CTI) documents. While CTI holds immense potential for enriching security operations, its extensive and fragmented nature makes manual analysis time-consuming and resource-intensive. To bridge this gap, we introduce a novel Retrieval-Augmented Generation (RAG)-based framework that leverages Large Language Models (LLMs) to automate and enhance IR by integrating dynamically retrieved CTI. Our approach introduces a hybrid retrieval mechanism that combines NLP-based similarity searches within a CTI vector database with standardized queries to external CTI platforms, facilitating context-aware enrichment of security alerts. The augmented intelligence is then leveraged by an LLM-powered response generation module, which formulates precise, actionable, and contextually relevant incident mitigation strategies. We propose a dual evaluation paradigm, wherein automated assessment using an auxiliary LLM is systematically cross-validated by cybersecurity experts. Empirical validation on real-world and simulated alerts demonstrates that our approach enhances the accuracy, contextualization, and efficiency of IR, alleviating analyst workload and reducing response latency. This work underscores the potential of LLM-driven CTI fusion in advancing autonomous security operations and establishing a foundation for intelligent, adaptive cybersecurity frameworks.",
    "source": "arXiv"
  },
  {
    "title": "HyperTea: A Hypergraph-based Temporal Enhancement and Alignment Network for Moving Infrared Small Target Detection",
    "title_es": "HyperTea: A Hypergraph-based Temporal Enhancement and Alignment Network for Moving Infrared Small Target Detection",
    "url": "https://arxiv.org/abs/2508.10678",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10678v1 Announce Type: new \nAbstract: In practical application scenarios, moving infrared small target detection (MIRSTD) remains highly challenging due to the target's small size, weak intensity, and complex motion pattern. Existing methods typically only model low-order correlations between feature nodes and perform feature extraction and enhancement within a single temporal scale. Although hypergraphs have been widely used for high-order correlation learning, they have received limited attention in MIRSTD. To explore the potential of hypergraphs and enhance multi-timescale feature representation, we propose HyperTea, which integrates global and local temporal perspectives to effectively model high-order spatiotemporal correlations of features. HyperTea consists of three modules: the global temporal enhancement module (GTEM) realizes global temporal context enhancement through semantic aggregation and propagation; the local temporal enhancement module (LTEM) is designed to capture local motion patterns between adjacent frames and then enhance local temporal context; additionally, we further develop a temporal alignment module (TAM) to address potential cross-scale feature misalignment. To our best knowledge, HyperTea is the first work to integrate convolutional neural networks (CNNs), recurrent neural networks (RNNs), and hypergraph neural networks (HGNNs) for MIRSTD, significantly improving detection performance. Experiments on DAUB and IRDST demonstrate its state-of-the-art (SOTA) performance. Our source codes are available at https://github.com/Lurenjia-LRJ/HyperTea.",
    "source": "arXiv"
  },
  {
    "title": "A Robust Optimization Approach for Demand Response Participation of Fixed-Frequency Air Conditioners",
    "title_es": "A Robust Optimization Approach for Demand Response Participation of Fixed-Frequency Air Conditioners",
    "url": "https://arxiv.org/abs/2508.10679",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10679v1 Announce Type: new \nAbstract: With the continuous increase in the penetration of renewable energy in the emerging power systems, the pressure on system peak regulation has been significantly intensified. Against this backdrop, demand side resources particularly air conditioning loads have garnered considerable attention for their substantial regulation potential and fast response capabilities, making them promising candidates for providing auxiliary peak shaving services. This study focuses on fixed frequency air conditioners (FFACs) and proposes an optimization model and solution method for their participation in demand response (DR) programs. First, a probabilistic response model for FFACs is developed based on the Markov assumption. Second, by sampling this probabilistic model, the aggregate power consumption of an FFAC cluster under decentralized control is obtained. Subsequently, a robust optimization model is formulated to maximize the profit of an aggregator managing the FFAC cluster during DR events, taking into account the aggregated response power. The model explicitly considers temperature uncertainty to ensure user comfort in a robust sense. Finally, leveraging the structure of the proposed model, it is reformulated as a mixed-integer linear programming (MILP) problem and solved using a commercial optimization solver. Simulation results validate the effectiveness of the proposed model and solution approach.",
    "source": "arXiv"
  },
  {
    "title": "Physics-Informed Joint Multi-TE Super-Resolution with Implicit Neural Representation for Robust Fetal T2 Mapping",
    "title_es": "Physics-Informed Joint Multi-TE Super-Resolution with Implicit Neural Representation for Robust Fetal T2 Mapping",
    "url": "https://arxiv.org/abs/2508.10680",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10680v1 Announce Type: new \nAbstract: T2 mapping in fetal brain MRI has the potential to improve characterization of the developing brain, especially at mid-field (0.55T), where T2 decay is slower. However, this is challenging as fetal MRI acquisition relies on multiple motion-corrupted stacks of thick slices, requiring slice-to-volume reconstruction (SVR) to estimate a high-resolution (HR) 3D volume. Currently, T2 mapping involves repeated acquisitions of these stacks at each echo time (TE), leading to long scan times and high sensitivity to motion. We tackle this challenge with a method that jointly reconstructs data across TEs, addressing severe motion. Our approach combines implicit neural representations with a physics-informed regularization that models T2 decay, enabling information sharing across TEs while preserving anatomical and quantitative T2 fidelity. We demonstrate state-of-the-art performance on simulated fetal brain and in vivo adult datasets with fetal-like motion. We also present the first in vivo fetal T2 mapping results at 0.55T. Our study shows potential for reducing the number of stacks per TE in T2 mapping by leveraging anatomical redundancy.",
    "source": "arXiv"
  },
  {
    "title": "IADGPT: Unified LVLM for Few-Shot Industrial Anomaly Detection, Localization, and Reasoning via In-Context Learning",
    "title_es": "IADGPT: Unified LVLM for Few-Shot Industrial Anomaly Detection, Localization, and Reasoning via In-Context Learning",
    "url": "https://arxiv.org/abs/2508.10681",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10681v1 Announce Type: new \nAbstract: Few-Shot Industrial Anomaly Detection (FS-IAD) has important applications in automating industrial quality inspection. Recently, some FS-IAD methods based on Large Vision-Language Models (LVLMs) have been proposed with some achievements through prompt learning or fine-tuning. However, existing LVLMs focus on general tasks but lack basic industrial knowledge and reasoning capabilities related to FS-IAD, making these methods far from specialized human quality inspectors. To address these challenges, we propose a unified framework, IADGPT, designed to perform FS-IAD in a human-like manner, while also handling associated localization and reasoning tasks, even for diverse and novel industrial products. To this end, we introduce a three-stage progressive training strategy inspired by humans. Specifically, the first two stages gradually guide IADGPT in acquiring fundamental industrial knowledge and discrepancy awareness. In the third stage, we design an in-context learning-based training paradigm, enabling IADGPT to leverage a few-shot image as the exemplars for improved generalization to novel products. In addition, we design a strategy that enables IADGPT to output image-level and pixel-level anomaly scores using the logits output and the attention map, respectively, in conjunction with the language output to accomplish anomaly reasoning. To support our training, we present a new dataset comprising 100K images across 400 diverse industrial product categories with extensive attribute-level textual annotations. Experiments indicate IADGPT achieves considerable performance gains in anomaly detection and demonstrates competitiveness in anomaly localization and reasoning. We will release our dataset in camera-ready.",
    "source": "arXiv"
  },
  {
    "title": "Neural Machine Translation for Coptic-French: Strategies for Low-Resource Ancient Languages",
    "title_es": "Neural Machine Translation for Coptic-French: Strategies for Low-Resource Ancient Languages",
    "url": "https://arxiv.org/abs/2508.10683",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10683v1 Announce Type: new \nAbstract: This paper presents the first systematic study of strategies for translating Coptic into French. Our comprehensive pipeline systematically evaluates: pivot versus direct translation, the impact of pre-training, the benefits of multi-version fine-tuning, and model robustness to noise. Utilizing aligned biblical corpora, we demonstrate that fine-tuning with a stylistically-varied and noise-aware training corpus significantly enhances translation quality. Our findings provide crucial practical insights for developing translation tools for historical languages in general.",
    "source": "arXiv"
  },
  {
    "title": "MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control",
    "title_es": "MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control",
    "url": "https://arxiv.org/abs/2508.10684",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10684v1 Announce Type: new \nAbstract: We study the problem of learning a neural sampler to generate samples from discrete state spaces where the target probability mass function $\\pi\\propto\\mathrm{e}^{-U}$ is known up to a normalizing constant, which is an important task in fields such as statistical physics, machine learning, combinatorial optimization, etc. To better address this challenging task when the state space has a large cardinality and the distribution is multi-modal, we propose $\\textbf{M}$asked $\\textbf{D}$iffusion $\\textbf{N}$eural $\\textbf{S}$ampler ($\\textbf{MDNS}$), a novel framework for training discrete neural samplers by aligning two path measures through a family of learning objectives, theoretically grounded in the stochastic optimal control of the continuous-time Markov chains. We validate the efficiency and scalability of MDNS through extensive experiments on various distributions with distinct statistical properties, where MDNS learns to accurately sample from the target distributions despite the extremely high problem dimensions and outperforms other learning-based baselines by a large margin. A comprehensive study of ablations and extensions is also provided to demonstrate the efficacy and potential of the proposed framework.",
    "source": "arXiv"
  },
  {
    "title": "An Open-Source User-Friendly Interface for Simulating Magnetic Soft Robots using Simulation Open Framework Architecture (SOFA)",
    "title_es": "An Open-Source User-Friendly Interface for Simulating Magnetic Soft Robots using Simulation Open Framework Architecture (SOFA)",
    "url": "https://arxiv.org/abs/2508.10686",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10686v1 Announce Type: new \nAbstract: Soft robots, particularly magnetic soft robots, require specialized simulation tools to accurately model their deformation under external magnetic fields. However, existing platforms often lack dedicated support for magnetic materials, making them difficult to use for researchers at different expertise levels. This work introduces an open-source, user-friendly simulation interface using the Simulation Open Framework Architecture (SOFA), specifically designed to model magnetic soft robots. The tool enables users to define material properties, apply magnetic fields, and observe resulting deformations in real time. By integrating intuitive controls and stress analysis capabilities, it aims to bridge the gap between theoretical modeling and practical design. Four benchmark models - a beam, three- and four-finger grippers, and a butterfly - demonstrate its functionality. The software's ease of use makes it accessible to both beginners and advanced researchers. Future improvements will refine accuracy through experimental validation and comparison with industry-standard finite element solvers, ensuring realistic and predictive simulations of magnetic soft robots.",
    "source": "arXiv"
  },
  {
    "title": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph",
    "title_es": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph",
    "url": "https://arxiv.org/abs/2508.10687",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10687v1 Announce Type: new \nAbstract: Millions of individuals worldwide are affected by deafness and hearing impairment. Sign language serves as a sophisticated means of communication for the deaf and hard of hearing. However, in societies that prioritize spoken languages, sign language often faces underestimation, leading to communication barriers and social exclusion. The Continuous Bangla Sign Language Translation project aims to address this gap by enhancing translation methods. While recent approaches leverage transformer architecture for state-of-the-art results, our method integrates graph-based methods with the transformer architecture. This fusion, combining transformer and STGCN-LSTM architectures, proves more effective in gloss-free translation. Our contributions include architectural fusion, exploring various fusion strategies, and achieving a new state-of-the-art performance on diverse sign language datasets, namely RWTH-PHOENIX-2014T, CSL-Daily, How2Sign, and BornilDB v1.0. Our approach demonstrates superior performance compared to current translation outcomes across all datasets, showcasing notable improvements of BLEU-4 scores of 4.01, 2.07, and 0.5, surpassing those of GASLT, GASLT and slt_how2sign in RWTH-PHOENIX-2014T, CSL-Daily, and How2Sign, respectively. Also, we introduce benchmarking on the BornilDB v1.0 dataset for the first time. Our method sets a benchmark for future research, emphasizing the importance of gloss-free translation to improve communication accessibility for the deaf and hard of hearing.",
    "source": "arXiv"
  },
  {
    "title": "Novel View Synthesis using DDIM Inversion",
    "title_es": "Novel View Synthesis using DDIM Inversion",
    "url": "https://arxiv.org/abs/2508.10688",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10688v1 Announce Type: new \nAbstract: Synthesizing novel views from a single input image is a challenging task. It requires extrapolating the 3D structure of a scene while inferring details in occluded regions, and maintaining geometric consistency across viewpoints. Many existing methods must fine-tune large diffusion backbones using multiple views or train a diffusion model from scratch, which is extremely expensive. Additionally, they suffer from blurry reconstruction and poor generalization. This gap presents the opportunity to explore an explicit lightweight view translation framework that can directly utilize the high-fidelity generative capabilities of a pretrained diffusion model while reconstructing a scene from a novel view. Given the DDIM-inverted latent of a single input image, we employ a camera pose-conditioned translation U-Net, TUNet, to predict the inverted latent corresponding to the desired target view. However, the image sampled using the predicted latent may result in a blurry reconstruction. To this end, we propose a novel fusion strategy that exploits the inherent noise correlation structure observed in DDIM inversion. The proposed fusion strategy helps preserve the texture and fine-grained details. To synthesize the novel view, we use the fused latent as the initial condition for DDIM sampling, leveraging the generative prior of the pretrained diffusion model. Extensive experiments on MVImgNet demonstrate that our method outperforms existing methods.",
    "source": "arXiv"
  },
  {
    "title": "Biasing Frontier-Based Exploration with Saliency Areas",
    "title_es": "Biasing Frontier-Based Exploration with Saliency Areas",
    "url": "https://arxiv.org/abs/2508.10689",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10689v1 Announce Type: new \nAbstract: Autonomous exploration is a widely studied problem where a robot incrementally builds a map of a previously unknown environment. The robot selects the next locations to reach using an exploration strategy. To do so, the robot has to balance between competing objectives, like exploring the entirety of the environment, while being as fast as possible. Most exploration strategies try to maximise the explored area to speed up exploration; however, they do not consider that parts of the environment are more important than others, as they lead to the discovery of large unknown areas. We propose a method that identifies \\emph{saliency areas} as those areas that are of high interest for exploration, by using saliency maps obtained from a neural network that, given the current map, implements a termination criterion to estimate whether the environment can be considered fully-explored or not. We use saliency areas to bias some widely used exploration strategies, showing, with an extensive experimental campaign, that this knowledge can significantly influence the behavior of the robot during exploration.",
    "source": "arXiv"
  },
  {
    "title": "THERMOS: Thermally-Aware Multi-Objective Scheduling of AI Workloads on Heterogeneous Multi-Chiplet PIM Architectures",
    "title_es": "THERMOS: Thermally-Aware Multi-Objective Scheduling of AI Workloads on Heterogeneous Multi-Chiplet PIM Architectures",
    "url": "https://arxiv.org/abs/2508.10691",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10691v1 Announce Type: new \nAbstract: Chiplet-based integration enables large-scale systems that combine diverse technologies, enabling higher yield, lower costs, and scalability, making them well-suited to AI workloads. Processing-in-Memory (PIM) has emerged as a promising solution for AI inference, leveraging technologies such as ReRAM, SRAM, and FeFET, each offering unique advantages and trade-offs. A heterogeneous chiplet-based PIM architecture can harness the complementary strengths of these technologies to enable higher performance and energy efficiency. However, scheduling AI workloads across such a heterogeneous system is challenging due to competing performance objectives, dynamic workload characteristics, and power and thermal constraints. To address this need, we propose THERMOS, a thermally-aware, multi-objective scheduling framework for AI workloads on heterogeneous multi-chiplet PIM architectures. THERMOS trains a single multi-objective reinforcement learning (MORL) policy that is capable of achieving Pareto-optimal execution time, energy, or a balanced objective at runtime, depending on the target preferences. Comprehensive evaluations show that THERMOS achieves up to 89% faster average execution time and 57% lower average energy consumption than baseline AI workload scheduling algorithms with only 0.14% runtime and 0.022% energy overhead.",
    "source": "arXiv"
  },
  {
    "title": "Learning from Natural Language Feedback for Personalized Question Answering",
    "title_es": "Learning from Natural Language Feedback for Personalized Question Answering",
    "url": "https://arxiv.org/abs/2508.10695",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10695v1 Announce Type: new \nAbstract: Personalization is crucial for enhancing both the effectiveness and user satisfaction of language technologies, particularly in information-seeking tasks like question answering. Current approaches for personalizing large language models (LLMs) often rely on retrieval-augmented generation (RAG), followed by reinforcement learning with scalar reward signals to teach models how to use retrieved personal context. We believe that these scalar rewards sometimes provide weak, non-instructive feedback, limiting learning efficiency and personalization quality. We introduce VAC, a novel framework for personalized response generation that replaces scalar rewards with natural language feedback (NLF) that are generated conditioned on the user profiles and the question narratives. NLF serves as a rich and actionable supervision signal, allowing the policy model to iteratively refine its outputs and internalize effective personalization strategies. Training alternates between optimizing the feedback model and fine-tuning the policy model on the improved responses, resulting in a policy model that no longer requires feedback at inference. Evaluation on the LaMP-QA benchmark that consists of three diverse domains demonstrates consistent and significant improvements over the state-of-the-art results. Human evaluations further confirm the superior quality of the generated responses. These results demonstrate that NLF provides more effective signals for optimizing personalized question answering.",
    "source": "arXiv"
  },
  {
    "title": "Chem3DLLM: 3D Multimodal Large Language Models for Chemistry",
    "title_es": "Chem3DLLM: 3D Multimodal Large Language Models for Chemistry",
    "url": "https://arxiv.org/abs/2508.10696",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10696v1 Announce Type: new \nAbstract: In the real world, a molecule is a 3D geometric structure. Compared to 1D SMILES sequences and 2D molecular graphs, 3D molecules represent the most informative molecular modality. Despite the rapid progress of autoregressive-based language models, they cannot handle the generation of 3D molecular conformation due to several challenges: 1) 3D molecular structures are incompatible with LLMs' discrete token space, 2) integrating heterogeneous inputs like proteins, ligands, and text remains difficult within a unified model, and 3) LLMs lack essential scientific priors, hindering the enforcement of physical and chemical constraints during generation. To tackle these issues, we present Chem3DLLM, a unified protein-conditioned multimodal large language model. Our approach designs a novel reversible text encoding for 3D molecular structures using run-length compression, achieving 3x size reduction while preserving complete structural information. This enables seamless integration of molecular geometry with protein pocket features in a single LLM architecture. We employ reinforcement learning with stability-based rewards to optimize chemical validity and incorporate a lightweight protein embedding projector for end-to-end training. Experimental results on structure-based drug design demonstrate state-of-the-art performance with a Vina score of -7.21, validating our unified multimodal approach for practical drug discovery applications.",
    "source": "arXiv"
  },
  {
    "title": "Visualization of Electronic Health Record Sequences at Scale",
    "title_es": "Visualization of Electronic Health Record Sequences at Scale",
    "url": "https://arxiv.org/abs/2508.10700",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10700v1 Announce Type: new \nAbstract: We present ParcoursVis, a Progressive Visual Analytics tool designed to explore electronic health record sequences of patients at scale. Existing tools process and aggregate the whole dataset upfront before showing the visualization, taking a time proportional to the data size. Therefore, to remain interactive, existing tools are limited to data sizes that can be processed in under a few seconds to meet the latency constraints of human attention. To overcome this limitation and scale to larger sizes, ParcoursVis relies on a progressive algorithm that quickly shows an approximate initial result of the aggregation, visualized as an Icicle tree, and improves it iteratively, updating the visualization until the whole computation is done. With its architecture, ParcoursVis remains interactive while visualizing the sequences of tens of millions of patients, each described with thousands of events; three to five orders of magnitude more than similar systems. Managing large datasets allows for exploring rare medical conditions or unexpected patient pathways, contributing to improving treatments. We describe the algorithms we use and our evaluation concerning their scalability, convergence, and stability. We also report on a set of guidelines to support visualization designers in developing scalable progressive systems. ParcoursVis already allows practitioners to perform analyses on two large real medical datasets. Our prototype is open-source.",
    "source": "arXiv"
  },
  {
    "title": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations",
    "title_es": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations",
    "url": "https://arxiv.org/abs/2508.10701",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10701v1 Announce Type: new \nAbstract: The exploitation of 1 day or n day vulnerabilities poses severe threats to networked devices due to massive deployment scales and delayed patching (average Mean Time To Patch exceeds 60 days). Existing defenses, including host based patching and network based filtering, are inadequate due to limited scalability across diverse devices, compatibility issues especially with embedded or legacy systems, and error prone deployment process (manual patch validation). To address these issues, we introduce REFN (Reinforcement Learning From Network), a novel framework that trains Large Language Models (LLMs) to autonomously generate network filters to prevent 1 day or n day exploitations. REFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven by online network rewards instead of traditional Human Feedback (RLHF). REFN guarantees compatibility via unified deployment on edge security gateways (Amazon Eero). REFN provides robustness via online validation using real network traffic. Crucially, REFN addresses three core challenges in training LLMs for exploit prevention: 1) expanding current LLMs limited vulnerability fixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging current LLMs language to network gaps through an RL From VNF Pipeline that translates language context (vulnerability description) into network enforcement, 3) addressing the LLM hallucination and non determinism via the Online Agentic Validation that penalizes erroneous outputs. Evaluated across 22 families of 1 day or n day exploits, REFN demonstrates effectiveness (21.1 percent higher accuracy than alternatives), efficiency (Mean Time To Patch of 3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an initial step toward training LLMs to rapidly prevent massive scale 1 day or n day exploitations.",
    "source": "arXiv"
  },
  {
    "title": "GenOM: Ontology Matching with Description Generation and Large Language Model",
    "title_es": "GenOM: Ontology Matching with Description Generation and Large Language Model",
    "url": "https://arxiv.org/abs/2508.10703",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10703v1 Announce Type: new \nAbstract: Ontology matching (OM) plays an essential role in enabling semantic interoperability and integration across heterogeneous knowledge sources, particularly in the biomedical domain which contains numerous complex concepts related to diseases and pharmaceuticals. This paper introduces GenOM, a large language model (LLM)-based ontology alignment framework, which enriches the semantic representations of ontology concepts via generating textual definitions, retrieves alignment candidates with an embedding model, and incorporates exact matching-based tools to improve precision. Extensive experiments conducted on the OAEI Bio-ML track demonstrate that GenOM can often achieve competitive performance, surpassing many baselines including traditional OM systems and recent LLM-based methods. Further ablation studies confirm the effectiveness of semantic enrichment and few-shot prompting, highlighting the framework's robustness and adaptability.",
    "source": "arXiv"
  },
  {
    "title": "Beyond conventional vision: RGB-event fusion for robust object detection in dynamic traffic scenarios",
    "title_es": "Beyond conventional vision: RGB-event fusion for robust object detection in dynamic traffic scenarios",
    "url": "https://arxiv.org/abs/2508.10704",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10704v1 Announce Type: new \nAbstract: The dynamic range limitation of conventional RGB cameras reduces global contrast and causes loss of high-frequency details such as textures and edges in complex traffic environments (e.g., nighttime driving, tunnels), hindering discriminative feature extraction and degrading frame-based object detection. To address this, we integrate a bio-inspired event camera with an RGB camera to provide high dynamic range information and propose a motion cue fusion network (MCFNet), which achieves optimal spatiotemporal alignment and adaptive cross-modal feature fusion under challenging lighting. Specifically, an event correction module (ECM) temporally aligns asynchronous event streams with image frames via optical-flow-based warping, jointly optimized with the detection network to learn task-aware event representations. The event dynamic upsampling module (EDUM) enhances spatial resolution of event frames to match image structures, ensuring precise spatiotemporal alignment. The cross-modal mamba fusion module (CMM) uses adaptive feature fusion with a novel interlaced scanning mechanism, effectively integrating complementary information for robust detection. Experiments conducted on the DSEC-Det and PKU-DAVIS-SOD datasets demonstrate that MCFNet significantly outperforms existing methods in various poor lighting and fast moving traffic scenarios. Notably, on the DSEC-Det dataset, MCFNet achieves a remarkable improvement, surpassing the best existing methods by 7.4% in mAP50 and 1.7% in mAP metrics, respectively. The code is available at https://github.com/Charm11492/MCFNet.",
    "source": "arXiv"
  },
  {
    "title": "Probabilistic Forecasting Method for Offshore Wind Farm Cluster under Typhoon Conditions: a Score-Based Conditional Diffusion Model",
    "title_es": "Probabilistic Forecasting Method for Offshore Wind Farm Cluster under Typhoon Conditions: a Score-Based Conditional Diffusion Model",
    "url": "https://arxiv.org/abs/2508.10705",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10705v1 Announce Type: new \nAbstract: Offshore wind power (OWP) exhibits significant fluctuations under typhoon conditions, posing substantial challenges to the secure operation of power systems. Accurate forecasting of OWP is therefore essential. However, the inherent scarcity of historical typhoon data and stochasticity of OWP render traditional point forecasting methods particularly difficult and inadequate. To address this challenge and provide grid operators with the comprehensive information necessary for decision-making, this study proposes a score-based conditional diffusion model (SCDM) for probabilistic forecasting of OWP during typhoon events. First, a knowledge graph algorithm is employed to embed historical typhoon paths as vectors. Then, a deterministic network is constructed to predict the wind power under typhoon conditions based on these vector embeddings. Finally, to better characterize prediction errors, a denoising network is developed. At the core of this approach is a mean-reverting stochastic differential equation (SDE), which transforms complex error distributions into a standard Gaussian, enabling the sampling of forecasting errors using a reverse-time SDE. The probabilistic forecasting results are reconstructed by combining deterministic forecasts with sampled errors. The proposed method is evaluated using real-world data from a cluster of 9 offshore wind farms. Results demonstrate that under typhoon conditions, our approach outperforms baseline models for both deterministic and probabilistic metrics, verifying the effectiveness of the approach.",
    "source": "arXiv"
  },
  {
    "title": "CountCluster: Training-Free Object Quantity Guidance with Cross-Attention Map Clustering for Text-to-Image Generation",
    "title_es": "CountCluster: Training-Free Object Quantity Guidance with Cross-Attention Map Clustering for Text-to-Image Generation",
    "url": "https://arxiv.org/abs/2508.10710",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10710v1 Announce Type: new \nAbstract: Diffusion-based text-to-image generation models have demonstrated strong performance in terms of image quality and diversity. However, they still struggle to generate images that accurately reflect the number of objects specified in the input prompt. Several approaches have been proposed that rely on either external counting modules for iterative refinement or quantity representations derived from learned tokens or latent features. However, they still have limitations in accurately reflecting the specified number of objects and overlook an important structural characteristic--The number of object instances in the generated image is largely determined in the early timesteps of the denoising process. To correctly reflect the object quantity for image generation, the highly activated regions in the object cross-attention map at the early timesteps should match the input object quantity, while each region should be clearly separated. To address this issue, we propose \\textit{CountCluster}, a method that guides the object cross-attention map to be clustered according to the specified object count in the input, without relying on any external tools or additional training. The proposed method partitions the object cross-attention map into $k$ clusters at inference time based on attention scores, defines an ideal distribution in which each cluster is spatially well-separated, and optimizes the latent to align with this target distribution. Our method achieves an average improvement of 18.5\\%p in object count accuracy compared to existing methods, and demonstrates superior quantity control performance across a variety of prompts. Code will be released at: https://github.com/JoohyeonL22/CountCluster .",
    "source": "arXiv"
  },
  {
    "title": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale",
    "title_es": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale",
    "url": "https://arxiv.org/abs/2508.10711",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10711v1 Announce Type: new \nAbstract: Prevailing autoregressive (AR) models for text-to-image generation either rely on heavy, computationally-intensive diffusion models to process continuous image tokens, or employ vector quantization (VQ) to obtain discrete tokens with quantization loss. In this paper, we push the autoregressive paradigm forward with NextStep-1, a 14B autoregressive model paired with a 157M flow matching head, training on discrete text tokens and continuous image tokens with next-token prediction objectives. NextStep-1 achieves state-of-the-art performance for autoregressive models in text-to-image generation tasks, exhibiting strong capabilities in high-fidelity image synthesis. Furthermore, our method shows strong performance in image editing, highlighting the power and versatility of our unified approach. To facilitate open research, we will release our code and models to the community.",
    "source": "arXiv"
  },
  {
    "title": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification",
    "title_es": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification",
    "url": "https://arxiv.org/abs/2508.10712",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10712v1 Announce Type: new \nAbstract: Synthetic Aperture Radar (SAR) data enables large-scale surveillance of maritime vessels. However, near-real-time monitoring is currently constrained by the need to downlink all raw data, perform image focusing, and subsequently analyze it on the ground. On-board processing to generate higher-level products could reduce the data volume that needs to be downlinked, alleviating bandwidth constraints and minimizing latency. However, traditional image focusing and processing algorithms face challenges due to the satellite's limited memory, processing power, and computational resources. This work proposes and evaluates neural networks designed for real-time inference on unfocused SAR data acquired in Stripmap and Interferometric Wide (IW) modes captured with Sentinel-1. Our results demonstrate the feasibility of using one of our models for on-board processing and deployment on an FPGA. Additionally, by investigating a binary classification task between ships and windmills, we demonstrate that target classification is possible.",
    "source": "arXiv"
  },
  {
    "title": "Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications",
    "title_es": "Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications",
    "url": "https://arxiv.org/abs/2508.10713",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10713v1 Announce Type: new \nAbstract: This study proposes an antenna simulation framework powered by graphics processing units (GPUs) based on an open-source electromagnetic (EM) simulation software (gprMax) for machine learning applications of antenna design and optimization. Furthermore, it compares the simulation results with those obtained through commercial EM software. The proposed software framework for machine learning and surrogate model applications will produce antenna data sets consisting of a large number of antenna simulation results using GPUs. Although machine learning methods can attain the optimum solutions for many problems, they are known to be data-hungry and require a great deal of samples for the training stage of the algorithms. However, producing a sufficient number of training samples in EM applications within a limited time is challenging due to the high computational complexity of EM simulations. Therefore, GPUs are utilized in this study to simulate a large number of antennas with predefined or random antenna shape parameters to produce data sets. Moreover, this study also compares various machine learning and deep learning models in terms of antenna parameter estimation performance. This study demonstrates that an entry-level GPU substantially outperforms a high-end CPU in terms of computational performance, while a high-end gaming GPU can achieve around 18 times more computational performance compared to a high-end CPU. Moreover, it is shown that the open-source EM simulation software can deliver similar results to those obtained via commercial software in the simulation of microstrip antennas when the spatial resolution of the simulations is sufficiently fine.",
    "source": "arXiv"
  },
  {
    "title": "Revisiting Cross-View Localization from Image Matching",
    "title_es": "Revisiting Cross-View Localization from Image Matching",
    "url": "https://arxiv.org/abs/2508.10716",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10716v1 Announce Type: new \nAbstract: Cross-view localization aims to estimate the 3 degrees of freedom pose of a ground-view image by registering it to aerial or satellite imagery. It is essential in GNSS-denied environments such as urban canyons and disaster zones. Existing methods either regress poses directly or align features in a shared bird's-eye view (BEV) space, both built upon accurate spatial correspondences between perspectives. However, these methods fail to establish strict cross-view correspondences, yielding only coarse or geometrically inconsistent matches. Consequently, fine-grained image matching between ground and aerial views remains an unsolved problem, which in turn constrains the interpretability of localization results. In this paper, we revisit cross-view localization from the perspective of cross-view image matching and propose a novel framework that improves both matching and localization. Specifically, we introduce a Surface Model to model visible regions for accurate BEV projection, and a SimRefiner module to refine the similarity matrix through local-global residual correction, eliminating the reliance on post-processing like RANSAC. To further support research in this area, we introduce CVFM, the first benchmark with 32,509 cross-view image pairs annotated with pixel-level correspondences. Extensive experiments demonstrate that our approach substantially improves both localization accuracy and image matching quality, setting new baselines under extreme viewpoint disparity.",
    "source": "arXiv"
  },
  {
    "title": "Exploiting Discriminative Codebook Prior for Autoregressive Image Generation",
    "title_es": "Exploiting Discriminative Codebook Prior for Autoregressive Image Generation",
    "url": "https://arxiv.org/abs/2508.10719",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10719v1 Announce Type: new \nAbstract: Advanced discrete token-based autoregressive image generation systems first tokenize images into sequences of token indices with a codebook, and then model these sequences in an autoregressive paradigm. While autoregressive generative models are trained only on index values, the prior encoded in the codebook, which contains rich token similarity information, is not exploited. Recent studies have attempted to incorporate this prior by performing naive k-means clustering on the tokens, helping to facilitate the training of generative models with a reduced codebook. However, we reveal that k-means clustering performs poorly in the codebook feature space due to inherent issues, including token space disparity and centroid distance inaccuracy. In this work, we propose the Discriminative Codebook Prior Extractor (DCPE) as an alternative to k-means clustering for more effectively mining and utilizing the token similarity information embedded in the codebook. DCPE replaces the commonly used centroid-based distance, which is found to be unsuitable and inaccurate for the token feature space, with a more reasonable instance-based distance. Using an agglomerative merging technique, it further addresses the token space disparity issue by avoiding splitting high-density regions and aggregating low-density ones. Extensive experiments demonstrate that DCPE is plug-and-play and integrates seamlessly with existing codebook prior-based paradigms. With the discriminative prior extracted, DCPE accelerates the training of autoregressive models by 42% on LlamaGen-B and improves final FID and IS performance.",
    "source": "arXiv"
  },
  {
    "title": "Predictive Position Control for Movable Antenna Arrays in UAV Communications: A Spatio-Temporal Transformer-LSTM Framework",
    "title_es": "Predictive Position Control for Movable Antenna Arrays in UAV Communications: A Spatio-Temporal Transformer-LSTM Framework",
    "url": "https://arxiv.org/abs/2508.10720",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10720v1 Announce Type: new \nAbstract: In complex urban environments, dynamic obstacles and multipath effects lead to significant link attenuation and pervasive coverage blind spots. Conventional approaches based on large-scale fixed antenna arrays and UAV trajectory optimization struggle to balance energy efficiency, real-time adaptation, and spatial flexibility. The movable antenna (MA) technology has emerged as a promising solution, offering enhanced spatial flexibility and reduced energy consumption to overcome the bottlenecks of urban low-altitude communications. However, MA deployment faces a critical velocity mismatch between UAV mobility and mechanical repositioning latency, undermining real-time link optimization and security assurance. To overcome this, we propose a predictive MA-UAV collaborative control framework. First, optimal antenna positions are derived via secrecy rate maximization. Second, a Transformer-enhanced long short-term memory (LSTM) network predicts future MA positions by capturing spatio-temporal correlations in antenna trajectories. Extensive simulations demonstrate superior prediction accuracy (NMSE reduction exceeds 49\\%) and communication reliability versus current popular benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering",
    "title_es": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering",
    "url": "https://arxiv.org/abs/2508.10729",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10729v1 Announce Type: new \nAbstract: Recent advances in Multimodal Large Language Models (MLLMs) have significantly pushed the frontier of egocentric video question answering (EgocentricQA). However, existing benchmarks and studies are mainly limited to common daily activities such as cooking and cleaning. In contrast, real-world deployment inevitably encounters domain shifts, where target domains differ substantially in both visual style and semantic content. To bridge this gap, we introduce \\textbf{EgoCross}, a comprehensive benchmark designed to evaluate the cross-domain generalization of MLLMs in EgocentricQA. EgoCross covers four diverse and challenging domains, including surgery, industry, extreme sports, and animal perspective, representing realistic and high-impact application scenarios. It comprises approximately 1,000 QA pairs across 798 video clips, spanning four key QA tasks: prediction, recognition, localization, and counting. Each QA pair provides both OpenQA and CloseQA formats to support fine-grained evaluation. Extensive experiments show that most existing MLLMs, whether general-purpose or egocentric-specialized, struggle to generalize to domains beyond daily life, highlighting the limitations of current models. Furthermore, we conduct several pilot studies, \\eg, fine-tuning and reinforcement learning, to explore potential improvements. We hope EgoCross and our accompanying analysis will serve as a foundation for advancing domain-adaptive, robust egocentric video understanding. Data and codes will be released at: \\href{https://github.com/MyUniverse0726/EgoCross}{https://github.com/MyUniverse0726/EgoCross.}",
    "source": "arXiv"
  },
  {
    "title": "Multi-Functional Polarization-Based Coverage Control through Static Passive EMSs",
    "title_es": "Multi-Functional Polarization-Based Coverage Control through Static Passive EMSs",
    "url": "https://arxiv.org/abs/2508.10730",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10730v1 Announce Type: new \nAbstract: An innovative multi-functional static-passive electromagnetic skin (SP-EMS) solution is proposed to simultaneously support, in reflection, two independent wave-manipulation functionalities with a single meta-atoms arrangement on the EMS aperture when illuminated by two EM sources operating at the same frequency, but working in different polarization states. Towards this end, a simple reference meta-atom is designed first to enable an accurate and independent control of each polarization component of the local reflection tensor. Successively, the macro-scale synthesis of multi-polarization (MP) SP-EMSs (MP-SP-EMSs) is carried out by solving a global optimization problem where a cost function, which mathematically codes separate requirements for each polarization, is minimized with a customized version of the system-by-design (SbD) technique. Representative results from a set of numerical and experimental tests are reported to assess the feasibility of a multi-function EMS based on polarization diversity as well as the effectiveness and the robustness of the proposed method for the synthesis of MP-SP-EMSs.",
    "source": "arXiv"
  },
  {
    "title": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction",
    "title_es": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction",
    "url": "https://arxiv.org/abs/2508.10731",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10731v1 Announce Type: new \nAbstract: Human perceptual systems excel at inducing and recognizing objects across both known and novel categories, a capability far beyond current machine learning frameworks. While generalized category discovery (GCD) aims to bridge this gap, existing methods predominantly focus on optimizing objective functions. We present an orthogonal solution, inspired by the human cognitive process for novel object understanding: decomposing objects into visual primitives and establishing cross-knowledge comparisons. We propose ConGCD, which establishes primitive-oriented representations through high-level semantic reconstruction, binding intra-class shared attributes via deconstruction. Mirroring human preference diversity in visual processing, where distinct individuals leverage dominant or contextual cues, we implement dominant and contextual consensus units to capture class-discriminative patterns and inherent distributional invariants, respectively. A consensus scheduler dynamically optimizes activation pathways, with final predictions emerging through multiplex consensus integration. Extensive evaluations across coarse- and fine-grained benchmarks demonstrate ConGCD's effectiveness as a consensus-aware paradigm. Code is available at github.com/lytang63/ConGCD.",
    "source": "arXiv"
  },
  {
    "title": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares",
    "title_es": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares",
    "url": "https://arxiv.org/abs/2508.10732",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10732v1 Announce Type: new \nAbstract: Personalized Federated Learning (PFL) has presented a significant challenge to deliver personalized models to individual clients through collaborative training. Existing PFL methods are often vulnerable to non-IID data, which severely hinders collective generalization and then compromises the subsequent personalization efforts. In this paper, to address this non-IID issue in PFL, we propose an Analytic Personalized Federated Learning (APFL) approach via dual-stream least squares. In our APFL, we use a foundation model as a frozen backbone for feature extraction. Subsequent to the feature extractor, we develop dual-stream analytic models to achieve both collective generalization and individual personalization. Specifically, our APFL incorporates a shared primary stream for global generalization across all clients, and a dedicated refinement stream for local personalization of each individual client. The analytical solutions of our APFL enable its ideal property of heterogeneity invariance, theoretically meaning that each personalized model remains identical regardless of how heterogeneous the data are distributed across all other clients. Empirical results across various datasets also validate the superiority of our APFL over state-of-the-art baselines, with advantages of at least 1.10%-15.45% in accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Traffic Intersection Simulation Using Turning Movement Count Data in SUMO: A Case Study of Toronto Intersections",
    "title_es": "Traffic Intersection Simulation Using Turning Movement Count Data in SUMO: A Case Study of Toronto Intersections",
    "url": "https://arxiv.org/abs/2508.10733",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10733v1 Announce Type: new \nAbstract: Urban traffic simulation is vital in planning, modeling, and analyzing road networks. However, the realism of a simulation depends extensively on the quality of input data. This paper presents an intersection traffic simulation tool that leverages real-world vehicle turning movement count (TMC) data from the City of Toronto to model traffic in an urban environment at an individual or multiple intersections using Simulation of Urban MObility (SUMO). The simulation performed in this research focuses specifically on intersection-level traffic generation without creating full vehicle routes through the network. This also helps keep the network's complexity to a minimum. The simulated traffic is evaluated against actual data to show that the simulation closely reproduces real intersection flows. This validates that the real data can drive practical simulations, and these scenarios can replace synthetic or random generated data, which is prominently used in developing new traffic-related methodologies. This is the first tool to integrate TMC data from Toronto into SUMO via an easy-to-use Graphical User Interface. This work contributes to the research and traffic planning community on data-driven traffic simulation. It provides transportation engineers with a framework to evaluate intersection design and traffic signal optimization strategies using readily available aggregate traffic data.",
    "source": "arXiv"
  },
  {
    "title": "Thinking Inside the Mask: In-Place Prompting in Diffusion LLMs",
    "title_es": "Thinking Inside the Mask: In-Place Prompting in Diffusion LLMs",
    "url": "https://arxiv.org/abs/2508.10736",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10736v1 Announce Type: new \nAbstract: Despite large language models (LLMs) have achieved remarkable success, their prefix-only prompting paradigm and sequential generation process offer limited flexibility for bidirectional information. Diffusion large language models (dLLMs) present new opportunities through their bidirectional attention mechanisms and iterative refinement processes, enabling more flexible in-place prompting strategies. We introduce ICE (In-Place Chain-of-Thought Prompting with Early Exit), a novel framework that transforms prefix-only prompting into in-place prompting specifically designed for dLLMs. ICE integrates in-place prompts directly within masked token positions during iterative refinement and employs a confidence-aware early exit mechanism to significantly reduce computational overhead. Extensive experiments demonstrate ICE's effectiveness, achieving up to 17.29% accuracy improvement with 4.12$\\times$ speedup on GSM8K, and up to 276.67$\\times$ acceleration on MMLU while maintaining competitive performance.",
    "source": "arXiv"
  },
  {
    "title": "Privacy-enhancing Sclera Segmentation Benchmarking Competition: SSBC 2025",
    "title_es": "Privacy-enhancing Sclera Segmentation Benchmarking Competition: SSBC 2025",
    "url": "https://arxiv.org/abs/2508.10737",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10737v1 Announce Type: new \nAbstract: This paper presents a summary of the 2025 Sclera Segmentation Benchmarking Competition (SSBC), which focused on the development of privacy-preserving sclera-segmentation models trained using synthetically generated ocular images. The goal of the competition was to evaluate how well models trained on synthetic data perform in comparison to those trained on real-world datasets. The competition featured two tracks: $(i)$ one relying solely on synthetic data for model development, and $(ii)$ one combining/mixing synthetic with (a limited amount of) real-world data. A total of nine research groups submitted diverse segmentation models, employing a variety of architectural designs, including transformer-based solutions, lightweight models, and segmentation networks guided by generative frameworks. Experiments were conducted across three evaluation datasets containing both synthetic and real-world images, collected under diverse conditions. Results show that models trained entirely on synthetic data can achieve competitive performance, particularly when dedicated training strategies are employed, as evidenced by the top performing models that achieved $F_1$ scores of over $0.8$ in the synthetic data track. Moreover, performance gains in the mixed track were often driven more by methodological choices rather than by the inclusion of real data, highlighting the promise of synthetic data for privacy-aware biometric development. The code and data for the competition is available at: https://github.com/dariant/SSBC_2025.",
    "source": "arXiv"
  },
  {
    "title": "Axis-level Symmetry Detection with Group-Equivariant Representation",
    "title_es": "Axis-level Symmetry Detection with Group-Equivariant Representation",
    "url": "https://arxiv.org/abs/2508.10740",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10740v1 Announce Type: new \nAbstract: Symmetry is a fundamental concept that has been extensively studied, yet detecting it in complex scenes remains a significant challenge in computer vision. Recent heatmap-based approaches can localize potential regions of symmetry axes but often lack precision in identifying individual axes. In this work, we propose a novel framework for axis-level detection of the two most common symmetry types-reflection and rotation-by representing them as explicit geometric primitives, i.e. lines and points. Our method employs a dual-branch architecture that is equivariant to the dihedral group, with each branch specialized to exploit the structure of dihedral group-equivariant features for its respective symmetry type. For reflection symmetry, we introduce orientational anchors, aligned with group components, to enable orientation-specific detection, and a reflectional matching that measures similarity between patterns and their mirrored counterparts across candidate axes. For rotational symmetry, we propose a rotational matching that compares patterns at fixed angular intervals to identify rotational centers. Extensive experiments demonstrate that our method achieves state-of-the-art performance, outperforming existing approaches.",
    "source": "arXiv"
  },
  {
    "title": "Forgery Guided Learning Strategy with Dual Perception Network for Deepfake Cross-domain Detection",
    "title_es": "Forgery Guided Learning Strategy with Dual Perception Network for Deepfake Cross-domain Detection",
    "url": "https://arxiv.org/abs/2508.10741",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10741v1 Announce Type: new \nAbstract: The emergence of deepfake technology has introduced a range of societal problems, garnering considerable attention. Current deepfake detection methods perform well on specific datasets, but exhibit poor performance when applied to datasets with unknown forgery techniques. Moreover, as the gap between emerging and traditional forgery techniques continues to widen, cross-domain detection methods that rely on common forgery traces are becoming increasingly ineffective. This situation highlights the urgency of developing deepfake detection technology with strong generalization to cope with fast iterative forgery techniques. To address these challenges, we propose a Forgery Guided Learning (FGL) strategy designed to enable detection networks to continuously adapt to unknown forgery techniques. Specifically, the FGL strategy captures the differential information between known and unknown forgery techniques, allowing the model to dynamically adjust its learning process in real time. To further improve the ability to perceive forgery traces, we design a Dual Perception Network (DPNet) that captures both differences and relationships among forgery traces. In the frequency stream, the network dynamically perceives and extracts discriminative features across various forgery techniques, establishing essential detection cues. These features are then integrated with spatial features and projected into the embedding space. In addition, graph convolution is employed to perceive relationships across the entire feature space, facilitating a more comprehensive understanding of forgery trace correlations. Extensive experiments show that our approach generalizes well across different scenarios and effectively handles unknown forgery challenges, providing robust support for deepfake detection. Our code is available on https://github.com/vpsg-research/FGL.",
    "source": "arXiv"
  },
  {
    "title": "An Efficient Model-Driven Groupwise Approach for Atlas Construction",
    "title_es": "An Efficient Model-Driven Groupwise Approach for Atlas Construction",
    "url": "https://arxiv.org/abs/2508.10743",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10743v1 Announce Type: new \nAbstract: Atlas construction is fundamental to medical image analysis, offering a standardized spatial reference for tasks such as population-level anatomical modeling. While data-driven registration methods have recently shown promise in pairwise settings, their reliance on large training datasets, limited generalizability, and lack of true inference phases in groupwise contexts hinder their practical use. In contrast, model-driven methods offer training-free, theoretically grounded, and data-efficient alternatives, though they often face scalability and optimization challenges when applied to large 3D datasets. In this work, we introduce DARC (Diffeomorphic Atlas Registration via Coordinate descent), a novel model-driven groupwise registration framework for atlas construction. DARC supports a broad range of image dissimilarity metrics and efficiently handles arbitrary numbers of 3D images without incurring GPU memory issues. Through a coordinate descent strategy and a centrality-enforcing activation function, DARC produces unbiased, diffeomorphic atlases with high anatomical fidelity. Beyond atlas construction, we demonstrate two key applications: (1) One-shot segmentation, where labels annotated only on the atlas are propagated to subjects via inverse deformations, outperforming state-of-the-art few-shot methods; and (2) shape synthesis, where new anatomical variants are generated by warping the atlas mesh using synthesized diffeomorphic deformation fields. Overall, DARC offers a flexible, generalizable, and resource-efficient framework for atlas construction and applications.",
    "source": "arXiv"
  },
  {
    "title": "Agentic Design Review System",
    "title_es": "Agentic Design Review System",
    "url": "https://arxiv.org/abs/2508.10745",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10745v1 Announce Type: new \nAbstract: Evaluating graphic designs involves assessing it from multiple facets like alignment, composition, aesthetics and color choices. Evaluating designs in a holistic way involves aggregating feedback from individual expert reviewers. Towards this, we propose an Agentic Design Review System (AgenticDRS), where multiple agents collaboratively analyze a design, orchestrated by a meta-agent. A novel in-context exemplar selection approach based on graph matching and a unique prompt expansion method plays central role towards making each agent design aware. Towards evaluating this framework, we propose DRS-BENCH benchmark. Thorough experimental evaluation against state-of-the-art baselines adapted to the problem setup, backed-up with critical ablation experiments brings out the efficacy of Agentic-DRS in evaluating graphic designs and generating actionable feedback. We hope that this work will attract attention to this pragmatic, yet under-explored research direction.",
    "source": "arXiv"
  },
  {
    "title": "Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning",
    "title_es": "Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning",
    "url": "https://arxiv.org/abs/2508.10747",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10747v1 Announce Type: new \nAbstract: Generalized planning using deep reinforcement learning (RL) combined with graph neural networks (GNNs) has shown promising results in various symbolic planning domains described by PDDL. However, existing approaches typically represent planning states as fully connected graphs, leading to a combinatorial explosion in edge information and substantial sparsity as problem scales grow, especially evident in large grid-based environments. This dense representation results in diluted node-level information, exponentially increases memory requirements, and ultimately makes learning infeasible for larger-scale problems. To address these challenges, we propose a sparse, goal-aware GNN representation that selectively encodes relevant local relationships and explicitly integrates spatial features related to the goal. We validate our approach by designing novel drone mission scenarios based on PDDL within a grid world, effectively simulating realistic mission execution environments. Our experimental results demonstrate that our method scales effectively to larger grid sizes previously infeasible with dense graph representations and substantially improves policy generalization and success rates. Our findings provide a practical foundation for addressing realistic, large-scale generalized planning tasks.",
    "source": "arXiv"
  },
  {
    "title": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models",
    "title_es": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models",
    "url": "https://arxiv.org/abs/2508.10751",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10751v1 Announce Type: new \nAbstract: Reinforcement learning with verifiable rewards (RLVR), which typically adopts Pass@1 as the reward, has faced the issues in balancing exploration and exploitation, causing policies to prefer conservative actions, converging to a local optimum. Identifying an appropriate reward metric is therefore crucial. Regarding the prior work, although Pass@k has been used in evaluation, its connection to LLM exploration ability in RLVR remains largely overlooked. To investigate this, we first use Pass@k as the reward to train the policy model (i.e., $\\textbf{Pass@k Training}$), and observe the improvement on its exploration ability. Next, we derive an analytical solution for the advantage of Pass@k Training, leading to an efficient and effective process. Building on this, our analysis reveals that exploration and exploitation are not inherently conflicting objectives, while they can mutually enhance each other. Moreover, Pass@k Training with analytical derivation essentially involves directly designing the advantage function. Inspired by this, we preliminarily explore the advantage design for RLVR, showing promising results and highlighting a potential future direction.",
    "source": "arXiv"
  },
  {
    "title": "Hypercomplex Prompt-aware Multimodal Recommendation",
    "title_es": "Hypercomplex Prompt-aware Multimodal Recommendation",
    "url": "https://arxiv.org/abs/2508.10753",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10753v1 Announce Type: new \nAbstract: Modern recommender systems face critical challenges in handling information overload while addressing the inherent limitations of multimodal representation learning. Existing methods suffer from three fundamental limitations: (1) restricted ability to represent rich multimodal features through a single representation, (2) existing linear modality fusion strategies ignore the deep nonlinear correlations between modalities, and (3) static optimization methods failing to dynamically mitigate the over-smoothing problem in graph convolutional network (GCN). To overcome these limitations, we propose HPMRec, a novel Hypercomplex Prompt-aware Multimodal Recommendation framework, which utilizes hypercomplex embeddings in the form of multi-components to enhance the representation diversity of multimodal features. HPMRec adopts the hypercomplex multiplication to naturally establish nonlinear cross-modality interactions to bridge semantic gaps, which is beneficial to explore the cross-modality features. HPMRec also introduces the prompt-aware compensation mechanism to aid the misalignment between components and modality-specific features loss, and this mechanism fundamentally alleviates the over-smoothing problem. It further designs self-supervised learning tasks that enhance representation diversity and align different modalities. Extensive experiments on four public datasets show that HPMRec achieves state-of-the-art recommendation performance.",
    "source": "arXiv"
  },
  {
    "title": "\"I Want My Chart to Be Just for Me\": Community-Engaged Design to Support Outpatient Healthcare for Resettled Communities",
    "title_es": "\"I Want My Chart to Be Just for Me\": Community-Engaged Design to Support Outpatient Healthcare for Resettled Communities",
    "url": "https://arxiv.org/abs/2508.10757",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10757v1 Announce Type: new \nAbstract: Individuals resettled in a new environment often face challenges in accessing adequate healthcare services, particularly within the complex processes of outpatient clinic care. Cultural differences, language barriers, and low socioeconomic status contribute to these difficulties. While previous studies have identified barriers and proposed technology-mediated solutions for resettled populations, many focus on addressing deficits rather than building on the strengths these communities already possess, which limits the sustainability and relevance of these solutions in everyday life. We conducted two community-based participatory design workshops with 30 Hmong community members in a large metropolitan area in the US. Through this process, we identified four types of assets the community has gradually developed, including intergenerational support for health management and storytelling-based communication practices that facilitate relatable and culturally grounded interactions. We show how participatory design workshops can foster asset-based approaches, and discuss design implications for technologies that leverage patients' existing strengths to support their health management during outpatient visits.",
    "source": "arXiv"
  },
  {
    "title": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets",
    "title_es": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets",
    "url": "https://arxiv.org/abs/2508.10758",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10758v1 Announce Type: new \nAbstract: Unlocking the potential of transformers on datasets of large physical systems depends on overcoming the quadratic scaling of the attention mechanism. This work explores combining the Erwin architecture with the Native Sparse Attention (NSA) mechanism to improve the efficiency and receptive field of transformer models for large-scale physical systems, addressing the challenge of quadratic attention complexity. We adapt the NSA mechanism for non-sequential data, implement the Erwin NSA model, and evaluate it on three datasets from the physical sciences -- cosmology simulations, molecular dynamics, and air pressure modeling -- achieving performance that matches or exceeds that of the original Erwin model. Additionally, we reproduce the experimental results from the Erwin paper to validate their implementation.",
    "source": "arXiv"
  },
  {
    "title": "Modeling Human Responses to Multimodal AI Content",
    "title_es": "Modeling Human Responses to Multimodal AI Content",
    "url": "https://arxiv.org/abs/2508.10769",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10769v1 Announce Type: new \nAbstract: As AI-generated content becomes widespread, so does the risk of misinformation. While prior research has primarily focused on identifying whether content is authentic, much less is known about how such content influences human perception and behavior. In domains like trading or the stock market, predicting how people react (e.g., whether a news post will go viral), can be more critical than verifying its factual accuracy. To address this, we take a human-centered approach and introduce the MhAIM Dataset, which contains 154,552 online posts (111,153 of them AI-generated), enabling large-scale analysis of how people respond to AI-generated content. Our human study reveals that people are better at identifying AI content when posts include both text and visuals, particularly when inconsistencies exist between the two. We propose three new metrics: trustworthiness, impact, and openness, to quantify how users judge and engage with online content. We present T-Lens, an LLM-based agent system designed to answer user queries by incorporating predicted human responses to multimodal information. At its core is HR-MCP (Human Response Model Context Protocol), built on the standardized Model Context Protocol (MCP), enabling seamless integration with any LLM. This integration allows T-Lens to better align with human reactions, enhancing both interpretability and interaction capabilities. Our work provides empirical insights and practical tools to equip LLMs with human-awareness capabilities. By highlighting the complex interplay among AI, human cognition, and information reception, our findings suggest actionable strategies for mitigating the risks of AI-driven misinformation.",
    "source": "arXiv"
  },
  {
    "title": "From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models",
    "title_es": "From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models",
    "url": "https://arxiv.org/abs/2508.10770",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10770v1 Announce Type: new \nAbstract: Spatio-physical reasoning, a foundation capability for understanding the real physics world, is a critical step towards building robust world models. While recent vision language models (VLMs) have shown remarkable progress in specialized domains like multimodal mathematics and pure spatial understanding, their capability for spatio-physical reasoning remains largely unexplored. This paper provides a comprehensive diagnostic analysis of mainstream VLMs, revealing that current models perform inadequately on this crucial task. Further detailed analysis shows that this underperformance is largely attributable to biases caused by human-like prior and a lack of deep reasoning. To address these challenges, we apply supervised fine-tuning followed by rule-based reinforcement learning to Qwen2.5-VL-7B, resulting in significant improvements in spatio-physical reasoning capabilities and surpassing leading proprietary models. Nevertheless, despite this success, the model's generalization to new physics scenarios remains limited -- underscoring the pressing need for new approaches in spatio-physical reasoning.",
    "source": "arXiv"
  },
  {
    "title": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences",
    "title_es": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences",
    "url": "https://arxiv.org/abs/2508.10771",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10771v1 Announce Type: new \nAbstract: Recent advances in AI-generated content have fueled the rise of highly realistic synthetic videos, posing severe risks to societal trust and digital integrity. Existing benchmarks for video authenticity detection typically suffer from limited realism, insufficient scale, and inadequate complexity, failing to effectively evaluate modern vision-language models against sophisticated forgeries. To address this critical gap, we introduce AEGIS, a novel large-scale benchmark explicitly targeting the detection of hyper-realistic and semantically nuanced AI-generated videos. AEGIS comprises over 10,000 rigorously curated real and synthetic videos generated by diverse, state-of-the-art generative models, including Stable Video Diffusion, CogVideoX-5B, KLing, and Sora, encompassing open-source and proprietary architectures. In particular, AEGIS features specially constructed challenging subsets enhanced with robustness evaluation. Furthermore, we provide multimodal annotations spanning Semantic-Authenticity Descriptions, Motion Features, and Low-level Visual Features, facilitating authenticity detection and supporting downstream tasks such as multimodal fusion and forgery localization. Extensive experiments using advanced vision-language models demonstrate limited detection capabilities on the most challenging subsets of AEGIS, highlighting the dataset's unique complexity and realism beyond the current generalization capabilities of existing models. In essence, AEGIS establishes an indispensable evaluation benchmark, fundamentally advancing research toward developing genuinely robust, reliable, broadly generalizable video authenticity detection methodologies capable of addressing real-world forgery threats. Our dataset is available on https://huggingface.co/datasets/Clarifiedfish/AEGIS.",
    "source": "arXiv"
  },
  {
    "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation",
    "title_es": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation",
    "url": "https://arxiv.org/abs/2508.10774",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10774v1 Announce Type: new \nAbstract: Diffusion transformers currently lead the field in high-quality video generation, but their slow iterative denoising process and prohibitive quadratic attention costs for long sequences create significant inference bottlenecks. While both step distillation and sparse attention mechanisms have shown promise as independent acceleration strategies, effectively combining these approaches presents critical challenges -- training-free integration yields suboptimal results, while separately training sparse attention after step distillation requires prohibitively expensive high-quality video data. To overcome these limitations, we propose BLADE, an innovative data-free joint training framework that introduces: (1) an Adaptive Block-Sparse Attention (ASA) mechanism for dynamically generating content-aware sparsity masks to focus computation on salient spatiotemporal features, and (2) a sparsity-aware step distillation paradigm built upon Trajectory Distribution Matching (TDM) that directly incorporates sparsity into the distillation process rather than treating it as a separate compression step, with fast convergence. We validate BLADE on text-to-video models like CogVideoX-5B and Wan2.1-1.3B. Our framework demonstrates remarkable efficiency gains across different scales. On Wan2.1-1.3B, BLADE achieves a 14.10x end-to-end inference acceleration over a 50-step baseline. Moreover, on models such as CogVideoX-5B with short video sequence lengths, our framework delivers a robust 8.89x speedup. Crucially, the acceleration is accompanied by a consistent quality improvement. On the VBench-2.0 benchmark, BLADE boosts the score of CogVideoX-5B to 0.569 (from 0.534) and Wan2.1-1.3B to 0.570 (from 0.563), results that are further corroborated by superior ratings in human evaluations. Our code and model weights are publicly available at: http://ziplab.co/BLADE-Homepage/.",
    "source": "arXiv"
  },
  {
    "title": "IBEX: Information-Bottleneck-EXplored Coarse-to-Fine Molecular Generation under Limited Data",
    "title_es": "IBEX: Information-Bottleneck-EXplored Coarse-to-Fine Molecular Generation under Limited Data",
    "url": "https://arxiv.org/abs/2508.10775",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10775v1 Announce Type: new \nAbstract: Three-dimensional generative models increasingly drive structure-based drug discovery, yet it remains constrained by the scarce publicly available protein-ligand complexes. Under such data scarcity, almost all existing pipelines struggle to learn transferable geometric priors and consequently overfit to training-set biases. As such, we present IBEX, an Information-Bottleneck-EXplored coarse-to-fine pipeline to tackle the chronic shortage of protein-ligand complex data in structure-based drug design. Specifically, we use PAC-Bayesian information-bottleneck theory to quantify the information density of each sample. This analysis reveals how different masking strategies affect generalization and indicates that, compared with conventional de novo generation, the constrained Scaffold Hopping task endows the model with greater effective capacity and improved transfer performance. IBEX retains the original TargetDiff architecture and hyperparameters for training to generate molecules compatible with the binding pocket; it then applies an L-BFGS optimization step to finely refine each conformation by optimizing five physics-based terms and adjusting six translational and rotational degrees of freedom in under one second. With only these modifications, IBEX raises the zero-shot docking success rate on CBGBench CrossDocked2020-based from 53% to 64%, improves the mean Vina score from $-7.41 kcal mol^{-1}$ to $-8.07 kcal mol^{-1}$, and achieves the best median Vina energy in 57 of 100 pockets versus 3 for the original TargetDiff. IBEX also increases the QED by 25%, achieves state-of-the-art validity and diversity, and markedly reduces extrapolation error.",
    "source": "arXiv"
  },
  {
    "title": "The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference",
    "title_es": "The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference",
    "url": "https://arxiv.org/abs/2508.10777",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10777v1 Announce Type: new \nAbstract: Large language models are often assumed to acquire increasingly structured, generalizable internal representations simply by scaling data and parameters. We interrogate this assumption by introducing a Clinical Trial Natural Language Inference benchmark comprising four reasoning families, Causal Attribution, Compositional Grounding, Epistemic Verification, and Risk State Abstraction. Each item is paired with a targeted Ground Knowledge and Meta-Level Reasoning Verification (GKMRV) probe, allowing us to dissociate failures of factual access from failures of inference. We evaluate six contemporary LLMs under both direct and chain of thought prompting.\n  Models achieve near-ceiling GKMRV accuracy (mean accuracy 0.918) yet perform poorly on the main reasoning tasks (mean accuracy 0.25). Despite low accuracy, output inferences are highly consistent across samples (mean 0.87), indicating a systematic application of underlying heuristics and shortcuts.\n  These results reveal fundamental structural and representational limitations: current LLMs often possess the relevant clinical knowledge but lack the structured, composable internal representations needed to deploy it reliably (e.g., integrating constraints, weighing evidence, or simulating counterfactuals). Decoupling knowledge from reasoning with GKMRV makes this dissociation explicit and measurable, providing an effective framework for probing the reliability of LLMs in high-stakes domains.",
    "source": "arXiv"
  },
  {
    "title": "Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior",
    "title_es": "Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior",
    "url": "https://arxiv.org/abs/2508.10779",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10779v1 Announce Type: new \nAbstract: Reference-based Image Super-Resolution (RefSR) aims to restore a low-resolution (LR) image by utilizing the semantic and texture information from an additional reference high-resolution (reference HR) image. Existing diffusion-based RefSR methods are typically built upon ControlNet, which struggles to effectively align the information between the LR image and the reference HR image. Moreover, current RefSR datasets suffer from limited resolution and poor image quality, resulting in the reference images lacking sufficient fine-grained details to support high-quality restoration. To overcome the limitations above, we propose TriFlowSR, a novel framework that explicitly achieves pattern matching between the LR image and the reference HR image. Meanwhile, we introduce Landmark-4K, the first RefSR dataset for Ultra-High-Definition (UHD) landmark scenarios. Considering the UHD scenarios with real-world degradation, in TriFlowSR, we design a Reference Matching Strategy to effectively match the LR image with the reference HR image. Experimental results show that our approach can better utilize the semantic and texture information of the reference HR image compared to previous methods. To the best of our knowledge, we propose the first diffusion-based RefSR pipeline for ultra-high definition landmark scenarios under real-world degradation. Our code and model will be available at https://github.com/nkicsl/TriFlowSR.",
    "source": "arXiv"
  },
  {
    "title": "Learning Task Execution Hierarchies for Redundant Robots",
    "title_es": "Learning Task Execution Hierarchies for Redundant Robots",
    "url": "https://arxiv.org/abs/2508.10780",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10780v1 Announce Type: new \nAbstract: Modern robotic systems, such as mobile manipulators, humanoids, and aerial robots with arms, often possess high redundancy, enabling them to perform multiple tasks simultaneously. Managing this redundancy is key to achieving reliable and flexible behavior. A widely used approach is the Stack of Tasks (SoT), which organizes control objectives by priority within a unified framework. However, traditional SoTs are manually designed by experts, limiting their adaptability and accessibility. This paper introduces a novel framework that automatically learns both the hierarchy and parameters of a SoT from user-defined objectives. By combining Reinforcement Learning and Genetic Programming, the system discovers task priorities and control strategies without manual intervention. A cost function based on intuitive metrics such as precision, safety, and execution time guides the learning process. We validate our method through simulations and experiments on the mobile-YuMi platform, a dual-arm mobile manipulator with high redundancy. Results show that the learned SoTs enable the robot to dynamically adapt to changing environments and inputs, balancing competing objectives while maintaining robust task execution. This approach provides a general and user-friendly solution for redundancy management in complex robots, advancing human-centered robot programming and reducing the need for expert design.",
    "source": "arXiv"
  },
  {
    "title": "Generating Compilers for Qubit Mapping and Routing",
    "title_es": "Generating Compilers for Qubit Mapping and Routing",
    "url": "https://arxiv.org/abs/2508.10781",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10781v1 Announce Type: new \nAbstract: Quantum computers promise to solve important problems faster than classical computers, potentially unlocking breakthroughs in materials science, chemistry, and beyond. Optimizing compilers are key to realizing this potential, as they minimize expensive resource usage and limit error rates. A critical compilation step is qubit mapping and routing (QMR), which finds mappings from circuit qubits to qubits on a target device and plans instruction execution while satisfying the device's connectivity constraints. The challenge is that the landscape of quantum architectures is incredibly diverse and fast-evolving. Given this diversity, hundreds of papers have addressed the QMR problem for different qubit hardware, connectivity constraints, and quantum error correction schemes.\n  We present an approach for automatically generating qubit mapping and routing compilers for arbitrary quantum architectures. Though each QMR problem is different, we identify a common core structure-device state machine-that we use to formulate an abstract QMR problem. Our formulation naturally leads to a domain-specific language, Marol, for specifying QMR problems-for example, the well-studied NISQ mapping and routing problem requires only 12 lines of Marol. We demonstrate that QMR problems, defined in Marol, can be solved with a powerful parametric solver that can be instantiated for any Marol program. We evaluate our approach through case studies of important QMR problems from prior and recent work, covering noisy and fault-tolerant quantum architectures on all major hardware platforms. Our thorough evaluation shows that generated compilers are competitive with handwritten, specialized compilers in terms of runtime and solution quality. We envision that our approach will simplify development of future quantum compilers as new quantum architectures continue to emerge.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection",
    "title_es": "Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.10785",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10785v1 Announce Type: new \nAbstract: Graph anomaly detection (GAD) has become an increasingly important task across various domains. With the rapid development of graph neural networks (GNNs), GAD methods have achieved significant performance improvements. However, fairness considerations in GAD remain largely underexplored. Indeed, GNN-based GAD models can inherit and amplify biases present in training data, potentially leading to unfair outcomes. While existing efforts have focused on developing fair GNNs, most approaches target node classification tasks, where models often rely on simple layer architectures rather than autoencoder-based structures, which are the most widely used architecturs for anomaly detection. To address fairness in autoencoder-based GAD models, we propose \\textbf{D}is\\textbf{E}ntangled \\textbf{C}ounterfactual \\textbf{A}dversarial \\textbf{F}air (DECAF)-GAD, a framework that alleviates bias while preserving GAD performance. Specifically, we introduce a structural causal model (SCM) to disentangle sensitive attributes from learned representations. Based on this causal framework, we formulate a specialized autoencoder architecture along with a fairness-guided loss function. Through extensive experiments on both synthetic and real-world datasets, we demonstrate that DECAF-GAD not only achieves competitive anomaly detection performance but also significantly enhances fairness metrics compared to baseline GAD methods. Our code is available at https://github.com/Tlhey/decaf_code.",
    "source": "arXiv"
  },
  {
    "title": "Cooperative Face Liveness Detection from Optical Flow",
    "title_es": "Cooperative Face Liveness Detection from Optical Flow",
    "url": "https://arxiv.org/abs/2508.10786",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10786v1 Announce Type: new \nAbstract: In this work, we proposed a novel cooperative video-based face liveness detection method based on a new user interaction scenario where participants are instructed to slowly move their frontal-oriented face closer to the camera. This controlled approaching face protocol, combined with optical flow analysis, represents the core innovation of our approach. By designing a system where users follow this specific movement pattern, we enable robust extraction of facial volume information through neural optical flow estimation, significantly improving discrimination between genuine faces and various presentation attacks (including printed photos, screen displays, masks, and video replays). Our method processes both the predicted optical flows and RGB frames through a neural classifier, effectively leveraging spatial-temporal features for more reliable liveness detection compared to passive methods.",
    "source": "arXiv"
  },
  {
    "title": "MapLibre Tile: A Next Generation Vector Tile Format",
    "title_es": "MapLibre Tile: A Next Generation Vector Tile Format",
    "url": "https://arxiv.org/abs/2508.10791",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10791v1 Announce Type: new \nAbstract: The Mapbox Vector Tile (MVT) format is widely considered the leading open standard for large-scale map visualization, as evidenced by its widespread adoption by major technology companies such as AWS, Meta, and Microsoft for their products and services. However, MVT was developed nearly a decade ago and, consequently, does not fully align with the capabilities of new geospatial data sources that are characterized by rapidly increasing data volumes due to advancements in geospatial sensors and automated detection through artificial intelligence. In this paper, we introduce the MapLibre Tile (MLT) format, a novel vector tile specification designed from the ground up to address the limitations of MVT. Our experiments, simulating user sessions on widely used basemap datasets, demonstrate that MLT achieves up to three times better compression ratios compared to MVT on encoded tilesets, with over six times better on certain large tiles. Additionally, MLT offers decoding speeds that are up to three times faster and significantly enhances processing performance. MLT also introduces new functionalities and is specifically designed to lay the foundation for the next generation of map renderers, which we expect to entirely offload processing to the GPU, thereby overcoming the stagnation of Moore`s law.",
    "source": "arXiv"
  },
  {
    "title": "Spirals and Beyond: Competitive Plane Search with Multi-Speed Agents",
    "title_es": "Spirals and Beyond: Competitive Plane Search with Multi-Speed Agents",
    "url": "https://arxiv.org/abs/2508.10793",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10793v1 Announce Type: new \nAbstract: We consider the problem of minimizing the worst-case search time for a hidden point target in the plane using multiple mobile agents of differing speeds, all starting from a common origin. The search time is normalized by the target's distance to the origin, following the standard convention in competitive analysis. The goal is to minimize the maximum such normalized time over all target locations, the search cost. As a base case, we extend the known result for a single unit-speed agent, which achieves an optimal cost of about $\\mathcal{U}_1 = 17.28935$ via a logarithmic spiral, to $n$ unit-speed agents. We give a symmetric spiral-based algorithm where each agent follows a logarithmic spiral offset by equal angular phases. This yields a search cost independent of which agent finds the target. We provide a closed-form upper bound $\\mathcal{U}_n$ for this setting, which we use in our general result. Our main contribution is an upper bound on the worst-case normalized search time for $n$ agents with arbitrary speeds. We give a framework that selects a subset of agents and assigns spiral-type trajectories with speed-dependent angular offsets, again making the search cost independent of which agent reaches the target. A corollary shows that $n$ multi-speed agents (fastest speed 1) can beat $k$ unit-speed agents (cost below $\\mathcal{U}_k$) if the geometric mean of their speeds exceeds $\\mathcal{U}_n / \\mathcal{U}_k$. This means slow agents may be excluded if they lower the mean too much, motivating non-spiral algorithms. We also give new upper bounds for point search in cones and conic complements using a single unit-speed agent. These are then used to design hybrid spiral-directional strategies, which outperform the spiral-based algorithms when some agents are slow. This suggests that spiral-type trajectories may not be optimal in the general multi-speed setting.",
    "source": "arXiv"
  },
  {
    "title": "VasoMIM: Vascular Anatomy-Aware Masked Image Modeling for Vessel Segmentation",
    "title_es": "VasoMIM: Vascular Anatomy-Aware Masked Image Modeling for Vessel Segmentation",
    "url": "https://arxiv.org/abs/2508.10794",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10794v1 Announce Type: new \nAbstract: Accurate vessel segmentation in X-ray angiograms is crucial for numerous clinical applications. However, the scarcity of annotated data presents a significant challenge, which has driven the adoption of self-supervised learning (SSL) methods such as masked image modeling (MIM) to leverage large-scale unlabeled data for learning transferable representations. Unfortunately, conventional MIM often fails to capture vascular anatomy because of the severe class imbalance between vessel and background pixels, leading to weak vascular representations. To address this, we introduce Vascular anatomy-aware Masked Image Modeling (VasoMIM), a novel MIM framework tailored for X-ray angiograms that explicitly integrates anatomical knowledge into the pre-training process. Specifically, it comprises two complementary components: anatomy-guided masking strategy and anatomical consistency loss. The former preferentially masks vessel-containing patches to focus the model on reconstructing vessel-relevant regions. The latter enforces consistency in vascular semantics between the original and reconstructed images, thereby improving the discriminability of vascular representations. Empirically, VasoMIM achieves state-of-the-art performance across three datasets. These findings highlight its potential to facilitate X-ray angiogram analysis.",
    "source": "arXiv"
  },
  {
    "title": "Beyond \"Not Novel Enough\": Enriching Scholarly Critique with LLM-Assisted Feedback",
    "title_es": "Beyond \"Not Novel Enough\": Enriching Scholarly Critique with LLM-Assisted Feedback",
    "url": "https://arxiv.org/abs/2508.10795",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10795v1 Announce Type: new \nAbstract: Novelty assessment is a central yet understudied aspect of peer review, particularly in high volume fields like NLP where reviewer capacity is increasingly strained. We present a structured approach for automated novelty evaluation that models expert reviewer behavior through three stages: content extraction from submissions, retrieval and synthesis of related work, and structured comparison for evidence based assessment. Our method is informed by a large scale analysis of human written novelty reviews and captures key patterns such as independent claim verification and contextual reasoning. Evaluated on 182 ICLR 2025 submissions with human annotated reviewer novelty assessments, the approach achieves 86.5% alignment with human reasoning and 75.3% agreement on novelty conclusions - substantially outperforming existing LLM based baselines. The method produces detailed, literature aware analyses and improves consistency over ad hoc reviewer judgments. These results highlight the potential for structured LLM assisted approaches to support more rigorous and transparent peer review without displacing human expertise. Data and code are made available.",
    "source": "arXiv"
  },
  {
    "title": "The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems",
    "title_es": "The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems",
    "url": "https://arxiv.org/abs/2508.10798",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10798v1 Announce Type: new \nAbstract: Future autonomous systems promise significant societal benefits, yet their deployment raises concerns about safety and trustworthiness. A key concern is assuring the reliability of robot perception, as perception seeds safe decision-making. Failures in perception are often due to complex yet common environmental factors and can lead to accidents that erode public trust. To address this concern, we introduce the SET (Self, Environment, and Target) Perceptual Factors Framework. We designed the framework to systematically analyze how factors such as weather, occlusion, or sensor limitations negatively impact perception. To achieve this, the framework employs SET State Trees to categorize where such factors originate and SET Factor Trees to model how these sources and factors impact perceptual tasks like object detection or pose estimation. Next, we develop Perceptual Factor Models using both trees to quantify the uncertainty for a given task. Our framework aims to promote rigorous safety assurances and cultivate greater public understanding and trust in autonomous systems by offering a transparent and standardized method for identifying, modeling, and communicating perceptual risks.",
    "source": "arXiv"
  },
  {
    "title": "Competitively Consistent Clustering",
    "title_es": "Competitively Consistent Clustering",
    "url": "https://arxiv.org/abs/2508.10800",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10800v1 Announce Type: new \nAbstract: In fully-dynamic consistent clustering, we are given a finite metric space $(M,d)$, and a set $F\\subseteq M$ of possible locations for opening centers. Data points arrive and depart, and the goal is to maintain an approximately optimal clustering solution at all times while minimizing the recourse, the total number of additions/deletions of centers over time. Specifically, we study fully dynamic versions of the classical $k$-center, facility location, and $k$-median problems. We design algorithms that, given a parameter $\\beta\\geq 1$, maintain an $O(\\beta)$-approximate solution at all times, and whose total recourse is bounded by $O(\\log |F| \\log \\Delta) \\cdot \\text{OPT}_\\text{rec}^{\\beta}$. Here $\\text{OPT}_\\text{rec}^{\\beta}$ is the minimal recourse of an offline algorithm that maintains a $\\beta$-approximate solution at all times, and $\\Delta$ is the metric aspect ratio. Finally, while we compare the performance of our algorithms to an optimal solution that maintains $k$ centers, our algorithms are allowed to use slightly more than $k$ centers. We obtain our results via a reduction to the recently proposed Positive Body Chasing framework of [Bhattacharya, Buchbinder, Levin, Saranurak, FOCS 2023], which we show gives fractional solutions to our clustering problems online. Our contribution is to round these fractional solutions while preserving the approximation and recourse guarantees. We complement our positive results with logarithmic lower bounds which show that our bounds are nearly tight.",
    "source": "arXiv"
  },
  {
    "title": "Object Fidelity Diffusion for Remote Sensing Image Generation",
    "title_es": "Object Fidelity Diffusion for Remote Sensing Image Generation",
    "url": "https://arxiv.org/abs/2508.10801",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10801v1 Announce Type: new \nAbstract: High-precision controllable remote sensing image generation is both meaningful and challenging. Existing diffusion models often produce low-fidelity images due to their inability to adequately capture morphological details, which may affect the robustness and reliability of object detection models. To enhance the accuracy and fidelity of generated objects in remote sensing, this paper proposes Object Fidelity Diffusion (OF-Diff), which effectively improves the fidelity of generated objects. Specifically, we are the first to extract the prior shapes of objects based on the layout for diffusion models in remote sensing. Then, we introduce a dual-branch diffusion model with diffusion consistency loss, which can generate high-fidelity remote sensing images without providing real images during the sampling phase. Furthermore, we introduce DDPO to fine-tune the diffusion process, making the generated remote sensing images more diverse and semantically consistent. Comprehensive experiments demonstrate that OF-Diff outperforms state-of-the-art methods in the remote sensing across key quality metrics. Notably, the performance of several polymorphic and small object classes shows significant improvement. For instance, the mAP increases by 8.3%, 7.7%, and 4.0% for airplanes, ships, and vehicles, respectively.",
    "source": "arXiv"
  },
  {
    "title": "Non-Stationary Restless Multi-Armed Bandits with Provable Guarantee",
    "title_es": "Non-Stationary Restless Multi-Armed Bandits with Provable Guarantee",
    "url": "https://arxiv.org/abs/2508.10804",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10804v1 Announce Type: new \nAbstract: Online restless multi-armed bandits (RMABs) typically assume that each arm follows a stationary Markov Decision Process (MDP) with fixed state transitions and rewards. However, in real-world applications like healthcare and recommendation systems, these assumptions often break due to non-stationary dynamics, posing significant challenges for traditional RMAB algorithms. In this work, we specifically consider $N$-armd RMAB with non-stationary transition constrained by bounded variation budgets $B$. Our proposed \\rmab\\; algorithm integrates sliding window reinforcement learning (RL) with an upper confidence bound (UCB) mechanism to simultaneously learn transition dynamics and their variations. We further establish that \\rmab\\; achieves $\\widetilde{\\mathcal{O}}(N^2 B^{\\frac{1}{4}} T^{\\frac{3}{4}})$ regret bound by leveraging a relaxed definition of regret, providing a foundational theoretical framework for non-stationary RMAB problems for the first time.",
    "source": "arXiv"
  },
  {
    "title": "Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems",
    "title_es": "Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems",
    "url": "https://arxiv.org/abs/2508.10806",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10806v1 Announce Type: new \nAbstract: As AI systems are increasingly deployed to support decision-making in critical domains, explainability has become a means to enhance the understandability of these outputs and enable users to make more informed and conscious choices. However, despite growing interest in the usability of eXplainable AI (XAI), the accessibility of these methods, particularly for users with vision impairments, remains underexplored. This paper investigates accessibility gaps in XAI through a two-pronged approach. First, a literature review of 79 studies reveals that evaluations of XAI techniques rarely include disabled users, with most explanations relying on inherently visual formats. Second, we present a four-part methodological proof of concept that operationalizes inclusive XAI design: (1) categorization of AI systems, (2) persona definition and contextualization, (3) prototype design and implementation, and (4) expert and user assessment of XAI techniques for accessibility. Preliminary findings suggest that simplified explanations are more comprehensible for non-visual users than detailed ones, and that multimodal presentation is required for more equitable interpretability.",
    "source": "arXiv"
  },
  {
    "title": "Modal definability in Euclidean modal logics",
    "title_es": "Modal definability in Euclidean modal logics",
    "url": "https://arxiv.org/abs/2508.10813",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10813v1 Announce Type: new \nAbstract: This paper is about the computability of the modal definability problem in classes of frames determined by Euclidean modal logics. We characterize those Euclidean modal logics such that the classes of frames they determine give rise to an undecidable modal definability problem.",
    "source": "arXiv"
  },
  {
    "title": "Comparison of Data Reduction Criteria for Online Gaussian Processes",
    "title_es": "Comparison of Data Reduction Criteria for Online Gaussian Processes",
    "url": "https://arxiv.org/abs/2508.10815",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10815v1 Announce Type: new \nAbstract: Gaussian Processes (GPs) are widely used for regression and system identification due to their flexibility and ability to quantify uncertainty. However, their computational complexity limits their applicability to small datasets. Moreover in a streaming scenario, more and more datapoints accumulate which is intractable even for Sparse GPs. Online GPs aim to alleviate this problem by e.g. defining a maximum budget of datapoints and removing redundant datapoints. This work provides a unified comparison of several reduction criteria, analyzing both their computational complexity and reduction behavior. The criteria are evaluated on benchmark functions and real-world datasets, including dynamic system identification tasks. Additionally, acceptance criteria are proposed to further filter out redundant datapoints. This work yields practical guidelines for choosing a suitable criterion for an online GP algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops",
    "title_es": "Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops",
    "url": "https://arxiv.org/abs/2508.10817",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10817v1 Announce Type: new \nAbstract: Plant diseases are a major threat to food security globally. It is important to develop early detection systems which can accurately detect. The advancement in computer vision techniques has the potential to solve this challenge. We have developed a mobile-friendly solution which can accurately classify 101 plant diseases across 33 crops. We built a comprehensive dataset by combining different datasets, Plant Doc, PlantVillage, and PlantWild, all of which are for the same purpose. We evaluated performance across several lightweight architectures - MobileNetV2, MobileNetV3, MobileNetV3-Large, and EfficientNet-B0, B1 - specifically chosen for their efficiency on resource-constrained devices. The results were promising, with EfficientNet-B1 delivering our best performance at 94.7% classification accuracy. This architecture struck an optimal balance between accuracy and computational efficiency, making it well-suited for real-world deployment on mobile devices.",
    "source": "arXiv"
  },
  {
    "title": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions",
    "title_es": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions",
    "url": "https://arxiv.org/abs/2508.10824",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10824v1 Announce Type: new \nAbstract: Memory is fundamental to intelligence, enabling learning, reasoning, and adaptability across biological and artificial systems. While Transformer architectures excel at sequence modeling, they face critical limitations in long-range context retention, continual learning, and knowledge integration. This review presents a unified framework bridging neuroscience principles, including dynamic multi-timescale memory, selective attention, and consolidation, with engineering advances in Memory-Augmented Transformers. We organize recent progress through three taxonomic dimensions: functional objectives (context extension, reasoning, knowledge integration, adaptation), memory representations (parameter-encoded, state-based, explicit, hybrid), and integration mechanisms (attention fusion, gated control, associative retrieval). Our analysis of core memory operations (reading, writing, forgetting, and capacity management) reveals a shift from static caches toward adaptive, test-time learning systems. We identify persistent challenges in scalability and interference, alongside emerging solutions including hierarchical buffering and surprise-gated updates. This synthesis provides a roadmap toward cognitively-inspired, lifelong-learning Transformer architectures.",
    "source": "arXiv"
  },
  {
    "title": "A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots",
    "title_es": "A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots",
    "url": "https://arxiv.org/abs/2508.10828",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10828v1 Announce Type: new \nAbstract: Subjective self-disclosure is an important feature of human social interaction. While much has been done in the social and behavioural literature to characterise the features and consequences of subjective self-disclosure, little work has been done thus far to develop computational systems that are able to accurately model it. Even less work has been done that attempts to model specifically how human interactants self-disclose with robotic partners. It is becoming more pressing as we require social robots to work in conjunction with and establish relationships with humans in various social settings. In this paper, our aim is to develop a custom multimodal attention network based on models from the emotion recognition literature, training this model on a large self-collected self-disclosure video corpus, and constructing a new loss function, the scale preserving cross entropy loss, that improves upon both classification and regression versions of this problem. Our results show that the best performing model, trained with our novel loss function, achieves an F1 score of 0.83, an improvement of 0.48 from the best baseline model. This result makes significant headway in the aim of allowing social robots to pick up on an interaction partner's self-disclosures, an ability that will be essential in social robots with social cognition.",
    "source": "arXiv"
  },
  {
    "title": "Advances in Speech Separation: Techniques, Challenges, and Future Trends",
    "title_es": "Advances in Speech Separation: Techniques, Challenges, and Future Trends",
    "url": "https://arxiv.org/abs/2508.10830",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10830v1 Announce Type: new \nAbstract: The field of speech separation, addressing the \"cocktail party problem\", has seen revolutionary advances with DNNs. Speech separation enhances clarity in complex acoustic environments and serves as crucial pre-processing for speech recognition and speaker recognition. However, current literature focuses narrowly on specific architectures or isolated approaches, creating fragmented understanding. This survey addresses this gap by providing systematic examination of DNN-based speech separation techniques. Our work differentiates itself through: (I) Comprehensive perspective: We systematically investigate learning paradigms, separation scenarios with known/unknown speakers, comparative analysis of supervised/self-supervised/unsupervised frameworks, and architectural components from encoders to estimation strategies. (II) Timeliness: Coverage of cutting-edge developments ensures access to current innovations and benchmarks. (III) Unique insights: Beyond summarization, we evaluate technological trajectories, identify emerging patterns, and highlight promising directions including domain-robust frameworks, efficient architectures, multimodal integration, and novel self-supervised paradigms. (IV) Fair evaluation: We provide quantitative evaluations on standard datasets, revealing true capabilities and limitations of different methods. This comprehensive survey serves as an accessible reference for experienced researchers and newcomers navigating speech separation's complex landscape.",
    "source": "arXiv"
  },
  {
    "title": "UI-Venus Technical Report: Building High-performance UI Agents with RFT",
    "title_es": "UI-Venus Technical Report: Building High-performance UI Agents with RFT",
    "url": "https://arxiv.org/abs/2508.10833",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10833v1 Announce Type: new \nAbstract: We present UI-Venus, a native UI agent that takes only screenshots as input based on a multimodal large language model. UI-Venus achieves SOTA performance on both UI grounding and navigation tasks using only several hundred thousand high-quality training samples through reinforcement finetune (RFT) based on Qwen2.5-VL. Specifically, the 7B and 72B variants of UI-Venus obtain 94.1% / 50.8% and 95.3% / 61.9% on the standard grounding benchmarks, i.e., Screenspot-V2 / Pro, surpassing the previous SOTA baselines including open-source GTA1 and closed-source UI-TARS-1.5.To show UI-Venus's summary and planing ability, we also evaluate it on the AndroidWorld, an online UI navigation arena, on which our 7B and 72B variants achieve 49.1% and 65.9% success rate, also beating existing models.To achieve this, we introduce carefully designed reward functions for both UI grounding and navigation tasks and corresponding efficient data cleaning strategies.To further boost navigation performance, we propose Self-Evolving Trajectory History Alignment \\& Sparse Action Enhancement that refine historical reasoning traces and balances the distribution of sparse but critical actions, leading to more coherent planning and better generalization in complex UI tasks. Our contributions include the publish of SOTA open-source UI agents, comprehensive data cleaning protocols and a novel self-evolving framework for improving navigation performance, which encourage further research and development in the community. Code is available at https://github.com/antgroup/UI-Venus.",
    "source": "arXiv"
  },
  {
    "title": "SoK: Data Minimization in Machine Learning",
    "title_es": "SoK: Data Minimization in Machine Learning",
    "url": "https://arxiv.org/abs/2508.10836",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10836v1 Announce Type: new \nAbstract: Data minimization (DM) describes the principle of collecting only the data strictly necessary for a given task. It is a foundational principle across major data protection regulations like GDPR and CPRA. Violations of this principle have substantial real-world consequences, with regulatory actions resulting in fines reaching hundreds of millions of dollars. Notably, the relevance of data minimization is particularly pronounced in machine learning (ML) applications, which typically rely on large datasets, resulting in an emerging research area known as Data Minimization in Machine Learning (DMML). At the same time, existing work on other ML privacy and security topics often addresses concerns relevant to DMML without explicitly acknowledging the connection. This disconnect leads to confusion among practitioners, complicating their efforts to implement DM principles and interpret the terminology, metrics, and evaluation criteria used across different research communities. To address this gap, our work introduces a comprehensive framework for DMML, including a unified data pipeline, adversaries, and points of minimization. This framework allows us to systematically review the literature on data minimization and \\emph{DM-adjacent} methodologies, for the first time presenting a structured overview designed to help practitioners and researchers effectively apply DM principles. Our work facilitates a unified DM-centric understanding and broader adoption of data minimization strategies in AI/ML.",
    "source": "arXiv"
  },
  {
    "title": "Self-Supervised Stereo Matching with Multi-Baseline Contrastive Learning",
    "title_es": "Self-Supervised Stereo Matching with Multi-Baseline Contrastive Learning",
    "url": "https://arxiv.org/abs/2508.10838",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10838v1 Announce Type: new \nAbstract: Current self-supervised stereo matching relies on the photometric consistency assumption, which breaks down in occluded regions due to ill-posed correspondences. To address this issue, we propose BaCon-Stereo, a simple yet effective contrastive learning framework for self-supervised stereo network training in both non-occluded and occluded regions. We adopt a teacher-student paradigm with multi-baseline inputs, in which the stereo pairs fed into the teacher and student share the same reference view but differ in target views. Geometrically, regions occluded in the student's target view are often visible in the teacher's, making it easier for the teacher to predict in these regions. The teacher's prediction is rescaled to match the student's baseline and then used to supervise the student. We also introduce an occlusion-aware attention map to better guide the student in learning occlusion completion. To support training, we synthesize a multi-baseline dataset BaCon-20k. Extensive experiments demonstrate that BaCon-Stereo improves prediction in both occluded and non-occluded regions, achieves strong generalization and robustness, and outperforms state-of-the-art self-supervised methods on both KITTI 2015 and 2012 benchmarks. Our code and dataset will be released upon paper acceptance.",
    "source": "arXiv"
  },
  {
    "title": "Reinforced Language Models for Sequential Decision Making",
    "title_es": "Reinforced Language Models for Sequential Decision Making",
    "url": "https://arxiv.org/abs/2508.10839",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10839v1 Announce Type: new \nAbstract: Large Language Models (LLMs) show potential as sequential decision-making agents, but their application is often limited due to a reliance on large, computationally expensive models. This creates a need to improve smaller models, yet existing post-training methods are designed for single-turn interactions and cannot handle credit assignment in multi-step agentic tasks. To address this, we introduce Multi-Step Group-Relative Policy Optimization (MS-GRPO), a new algorithm for post-training LLM agents, grounded in formal Text-Mediated Stochastic Game (TSMG) and Language-Agent Policy (LAP) frameworks. For credit assignment, MS-GRPO attributes the entire cumulative episode reward to each individual episode step. We supplement this algorithm with a novel absolute-advantage-weighted episode sampling strategy that we show improves training performance. We evaluate our approach by post-training a 3-billion parameter model on Snake and Frozen Lake. Our experiments demonstrate that the method is effective in improving decision-making performance: our post-trained 3B parameter model outperforms a 72B parameter baseline by 50% on the Frozen Lake task. This work demonstrates that targeted post-training is a practical and efficient alternative to relying on model scale for creating sequential decision-making agents using LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Generalizable Federated Learning using Client Adaptive Focal Modulation",
    "title_es": "Generalizable Federated Learning using Client Adaptive Focal Modulation",
    "url": "https://arxiv.org/abs/2508.10840",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10840v1 Announce Type: new \nAbstract: Federated learning (FL) has proven essential for privacy-preserving, collaborative training across distributed clients. Our prior work, TransFed, introduced a robust transformer-based FL framework that leverages a learn-to-adapt hypernetwork to generate personalized focal modulation layers per client, outperforming traditional methods in non-IID and cross-domain settings. In this extended version, we propose AdaptFED, where we deepen the investigation of focal modulation in generalizable FL by incorporating: (1) a refined adaptation strategy that integrates task-aware client embeddings to personalize modulation dynamics further, (2) enhanced theoretical bounds on adaptation performance, and (3) broader empirical validation across additional modalities, including time-series and multilingual data. We also introduce an efficient variant of TransFed that reduces server-client communication overhead via low-rank hypernetwork conditioning, enabling scalable deployment in resource-constrained environments. Extensive experiments on eight diverse datasets reaffirm the superiority of our method over state-of-the-art baselines, particularly in source-free and cross-task federated setups. Our findings not only extend the capabilities of focal modulation in FL but also pave the way for more adaptive, scalable, and generalizable transformer-based federated systems. The code is available at http://github.com/Tajamul21/TransFed",
    "source": "arXiv"
  },
  {
    "title": "Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning",
    "title_es": "Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning",
    "url": "https://arxiv.org/abs/2508.10848",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10848v1 Announce Type: new \nAbstract: Amidst a shortage of qualified mental health professionals, the integration of large language models (LLMs) into psychological applications offers a promising way to alleviate the growing burden of mental health disorders. Recent reasoning-augmented LLMs have achieved remarkable performance in mathematics and programming, while research in the psychological domain has predominantly emphasized emotional support and empathetic dialogue, with limited attention to reasoning mechanisms that are beneficial to generating reliable responses. Therefore, in this paper, we propose Psyche-R1, the first Chinese psychological LLM that jointly integrates empathy, psychological expertise, and reasoning, built upon a novel data curation pipeline. Specifically, we design a comprehensive data synthesis pipeline that produces over 75k high-quality psychological questions paired with detailed rationales, generated through chain-of-thought (CoT) reasoning and iterative prompt-rationale optimization, along with 73k empathetic dialogues. Subsequently, we employ a hybrid training strategy wherein challenging samples are identified through a multi-LLM cross-selection strategy for group relative policy optimization (GRPO) to improve reasoning ability, while the remaining data is used for supervised fine-tuning (SFT) to enhance empathetic response generation and psychological domain knowledge. Extensive experiment results demonstrate the effectiveness of the Psyche-R1 across several psychological benchmarks, where our 7B Psyche-R1 achieves comparable results to 671B DeepSeek-R1.",
    "source": "arXiv"
  },
  {
    "title": "Integrating Terrestrial and Non-Terrestrial Networks for Sustainable 6G Operations: A Latency-Aware Multi-Tier Cell-Switching Approach",
    "title_es": "Integrating Terrestrial and Non-Terrestrial Networks for Sustainable 6G Operations: A Latency-Aware Multi-Tier Cell-Switching Approach",
    "url": "https://arxiv.org/abs/2508.10849",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10849v1 Announce Type: new \nAbstract: Sustainability is paramount in modern cellular networks, which face significant energy consumption challenges from rising mobile traffic and advancements in wireless technology. Cell-switching, well-established in literature as an effective solution, encounters limitations such as inadequate capacity and limited coverage when implemented through terrestrial networks (TN). This study enhances cell-switching by integrating non-terrestrial networks (NTN), including satellites (used for cell-switching for the first time), high altitude platform stations (HAPS), and uncrewed aerial vehicles (UAVs) into TN. This integration significantly boosts energy savings by expanding capacity, enhancing coverage, and increasing operational flexibility. We introduce a multi-tier cell-switching approach that dynamically offloads users across network layers to manage energy effectively and minimize delays, accommodating diverse user demands with a context aware strategy. Additionally, we explore the role of artificial intelligence (AI), particularly generative AI, in optimizing network efficiency through data compression, handover optimization between different network layers, and enhancing device compatibility, further improving the adaptability and energy efficiency of cell-switching operations. A case study confirms substantial improvements in network power consumption and user satisfaction, demonstrating the potential of our approach for future networks.",
    "source": "arXiv"
  },
  {
    "title": "CrossDenoise: Denoising Implicit Feedback via a Lightweight Entity-Aware Synergistic Framework",
    "title_es": "CrossDenoise: Denoising Implicit Feedback via a Lightweight Entity-Aware Synergistic Framework",
    "url": "https://arxiv.org/abs/2508.10851",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10851v1 Announce Type: new \nAbstract: Recommender systems heavily rely on implicit feedback, which is inherently noisy due to false positives and negatives, severely degrading recommendation accuracy. Existing denoising strategies often overlook entity-aware modeling, suffer from high computational overhead, or demand excessive hyperparameter tuning, limiting their real-world applicability. We propose CrossDenoise, a novel and lightweight framework that addresses these challenges by disentangling noise estimation into user-, item-, and interaction-specific factors. Leveraging empirical observations that show significant heterogeneity in user and item noise propensities, CrossDenoise computes entity reputation factors (user/item reliability) via a rank-based linear mapping of average training losses. These are fused with interaction-level weights derived from an empirical cumulative distribution function (ECDF) of individual losses. This design is model-agnostic, computationally efficient, and requires only two intuitive hyperparameters. Extensive experiments on ML-1M, Yelp, and Amazon-book datasets, across GMF, NeuMF, and CDAE backbones, demonstrate that CrossDenoise consistently and significantly outperforms state-of-the-art baselines. For instance, it achieves up to 27.01% NDCG@50 gain on Yelp with NeuMF, while incurring negligible computational and memory overhead. Our analysis confirms that CrossDenoise effectively separates clean from noisy samples and remains robust under varied hyperparameter settings. It offers a practical and scalable solution for denoising implicit feedback.",
    "source": "arXiv"
  },
  {
    "title": "EVOSCAT: Exploring Software Change Dynamics in Large-Scale Historical Datasets",
    "title_es": "EVOSCAT: Exploring Software Change Dynamics in Large-Scale Historical Datasets",
    "url": "https://arxiv.org/abs/2508.10852",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10852v1 Announce Type: new \nAbstract: Long lived software projects encompass a large number of artifacts, which undergo many revisions throughout their history. Empirical software engineering researchers studying software evolution gather and collect datasets with millions of events, representing changes introduced to specific artifacts. In this paper, we propose EvoScat, a tool that attempts addressing temporal scalability through the usage of interactive density scatterplot to provide a global overview of large historical datasets mined from open source repositories in a single visualization. EvoScat intents to provide researchers with a mean to produce scalable visualizations that can help them explore and characterize evolution datasets, as well as comparing the histories of individual artifacts, both in terms of 1) observing how rapidly different artifacts age over multiple-year-long time spans 2) how often metrics associated with each artifacts tend towards an improvement or worsening. The paper shows how the tool can be tailored to specific analysis needs (pace of change comparison, clone detection, freshness assessment) thanks to its support for flexible configuration of history scaling and alignment along the time axis, artifacts sorting and interactive color mapping, enabling the analysis of millions of events obtained by mining the histories of tens of thousands of software artifacts. We include in this paper a gallery showcasing datasets gathering specific artifacts (OpenAPI descriptions, GitHub workflow definitions) across multiple repositories, as well as diving into the history of specific popular open source projects.",
    "source": "arXiv"
  },
  {
    "title": "Introducing CQ: A C-like API for Quantum Accelerated HPC",
    "title_es": "Introducing CQ: A C-like API for Quantum Accelerated HPC",
    "url": "https://arxiv.org/abs/2508.10854",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10854v1 Announce Type: new \nAbstract: In this paper we present CQ, a specification for a C-like API for quantum accelerated HPC, as well as CQ-SimBE, a reference implementation of CQ written in C99, and built on top of the statevector simulator QuEST. CQ focuses on enabling the incremental integration of quantum computing into classical HPC codes by supporting runtime offloading from languages such as C and Fortran. It provides a way of describing and offloading quantum computations which is compatible with strictly and strongly typed compiled languages, and gives the programmer fine-grained control over classical data movement. The CQ Simulated Backend (CQ-SimBE) provides both a way to demonstrate the usage and utility of CQ, and a space to experiment with new features such as support for analogue quantum computing. Both the CQ specification and CQ-SimBE are open-source, and available in public repositories.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation",
    "title_es": "Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation",
    "url": "https://arxiv.org/abs/2508.10858",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10858v1 Announce Type: new \nAbstract: Recent advancements in video generation have enabled the creation of high-quality, visually compelling videos. However, generating videos that adhere to the laws of physics remains a critical challenge for applications requiring realism and accuracy. In this work, we propose PhysHPO, a novel framework for Hierarchical Cross-Modal Direct Preference Optimization, to tackle this challenge by enabling fine-grained preference alignment for physically plausible video generation. PhysHPO optimizes video alignment across four hierarchical granularities: a) Instance Level, aligning the overall video content with the input prompt; b) State Level, ensuring temporal consistency using boundary frames as anchors; c) Motion Level, modeling motion trajectories for realistic dynamics; and d) Semantic Level, maintaining logical consistency between narrative and visuals. Recognizing that real-world videos are the best reflections of physical phenomena, we further introduce an automated data selection pipeline to efficiently identify and utilize \"good data\" from existing large-scale text-video datasets, thereby eliminating the need for costly and time-intensive dataset construction. Extensive experiments on both physics-focused and general capability benchmarks demonstrate that PhysHPO significantly improves physical plausibility and overall video generation quality of advanced models. To the best of our knowledge, this is the first work to explore fine-grained preference alignment and data selection for video generation, paving the way for more realistic and human-preferred video generation paradigms.",
    "source": "arXiv"
  },
  {
    "title": "From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms",
    "title_es": "From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms",
    "url": "https://arxiv.org/abs/2508.10860",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10860v1 Announce Type: new \nAbstract: Recent advancements in machine learning have spurred growing interests in automated interpreting quality assessment. Nevertheless, existing research suffers from insufficient examination of language use quality, unsatisfactory modeling effectiveness due to data scarcity and imbalance, and a lack of efforts to explain model predictions. To address these gaps, we propose a multi-dimensional modeling framework that integrates feature engineering, data augmentation, and explainable machine learning. This approach prioritizes explainability over ``black box'' predictions by utilizing only construct-relevant, transparent features and conducting Shapley Value (SHAP) analysis. Our results demonstrate strong predictive performance on a novel English-Chinese consecutive interpreting dataset, identifying BLEURT and CometKiwi scores to be the strongest predictive features for fidelity, pause-related features for fluency, and Chinese-specific phraseological diversity metrics for language use. Overall, by placing particular emphasis on explainability, we present a scalable, reliable, and transparent alternative to traditional human evaluation, facilitating the provision of detailed diagnostic feedback for learners and supporting self-regulated learning advantages not afforded by automated scores in isolation.",
    "source": "arXiv"
  },
  {
    "title": "Minimmit: Fast Finality with Even Faster Blocks",
    "title_es": "Minimmit: Fast Finality with Even Faster Blocks",
    "url": "https://arxiv.org/abs/2508.10862",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10862v1 Announce Type: new \nAbstract: Minimmit is a new protocol for State-Machine-Replication (SMR) that extends the '2-round finality' approach of protocols such as Alpenglow to further reduce latency, by allowing for faster progression through 'views'. This preliminary draft provides motivation and pseudocode, together with proofs of consistency and liveness. An updated draft with a proof of optimistic responsiveness, suggested optimizations, and experiments, is to follow.",
    "source": "arXiv"
  },
  {
    "title": "Performance of GPT-5 in Brain Tumor MRI Reasoning",
    "title_es": "Performance of GPT-5 in Brain Tumor MRI Reasoning",
    "url": "https://arxiv.org/abs/2508.10865",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10865v1 Announce Type: new \nAbstract: Accurate differentiation of brain tumor types on magnetic resonance imaging (MRI) is critical for guiding treatment planning in neuro-oncology. Recent advances in large language models (LLMs) have enabled visual question answering (VQA) approaches that integrate image interpretation with natural language reasoning. In this study, we evaluated GPT-4o, GPT-5-nano, GPT-5-mini, and GPT-5 on a curated brain tumor VQA benchmark derived from 3 Brain Tumor Segmentation (BraTS) datasets - glioblastoma (GLI), meningioma (MEN), and brain metastases (MET). Each case included multi-sequence MRI triplanar mosaics and structured clinical features transformed into standardized VQA items. Models were assessed in a zero-shot chain-of-thought setting for accuracy on both visual and reasoning tasks. Results showed that GPT-5-mini achieved the highest macro-average accuracy (44.19%), followed by GPT-5 (43.71%), GPT-4o (41.49%), and GPT-5-nano (35.85%). Performance varied by tumor subtype, with no single model dominating across all cohorts. These findings suggest that GPT-5 family models can achieve moderate accuracy in structured neuro-oncological VQA tasks, but not at a level acceptable for clinical use.",
    "source": "arXiv"
  },
  {
    "title": "Efficiently Verifiable Proofs of Data Attribution",
    "title_es": "Efficiently Verifiable Proofs of Data Attribution",
    "url": "https://arxiv.org/abs/2508.10866",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10866v1 Announce Type: new \nAbstract: Data attribution methods aim to answer useful counterfactual questions like \"what would a ML model's prediction be if it were trained on a different dataset?\" However, estimation of data attribution models through techniques like empirical influence or \"datamodeling\" remains very computationally expensive. This causes a critical trust issue: if only a few computationally rich parties can obtain data attributions, how can resource-constrained parties trust that the provided attributions are indeed \"good,\" especially when they are used for important downstream applications (e.g., data pricing)? In this paper, we address this trust issue by proposing an interactive verification paradigm for data attribution. An untrusted and computationally powerful Prover learns data attributions, and then engages in an interactive proof with a resource-constrained Verifier. Our main result is a protocol that provides formal completeness, soundness, and efficiency guarantees in the sense of Probably-Approximately-Correct (PAC) verification. Specifically, if both Prover and Verifier follow the protocol, the Verifier accepts data attributions that are {\\epsilon}-close to the optimal data attributions (in terms of the Mean Squared Error) with probability 1-{\\delta}. Conversely, if the Prover arbitrarily deviates from the protocol, even with infinite compute, then this is detected (or it still yields data attributions to the Verifier) except with probability {\\delta}. Importantly, our protocol ensures the Verifier's workload, measured by the number of independent model retrainings it must perform, scales only as O(1/{\\epsilon}); i.e., independently of the dataset size. At a technical level, our results apply to efficiently verifying any linear function over the boolean hypercube computed by the Prover, making them broadly applicable to various attribution tasks.",
    "source": "arXiv"
  },
  {
    "title": "CVIRO: A Consistent and Tightly-Coupled Visual-Inertial-Ranging Odometry on Lie Groups",
    "title_es": "CVIRO: A Consistent and Tightly-Coupled Visual-Inertial-Ranging Odometry on Lie Groups",
    "url": "https://arxiv.org/abs/2508.10867",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10867v1 Announce Type: new \nAbstract: Ultra Wideband (UWB) is widely used to mitigate drift in visual-inertial odometry (VIO) systems. Consistency is crucial for ensuring the estimation accuracy of a UWBaided VIO system. An inconsistent estimator can degrade localization performance, where the inconsistency primarily arises from two main factors: (1) the estimator fails to preserve the correct system observability, and (2) UWB anchor positions are assumed to be known, leading to improper neglect of calibration uncertainty. In this paper, we propose a consistent and tightly-coupled visual-inertial-ranging odometry (CVIRO) system based on the Lie group. Our method incorporates the UWB anchor state into the system state, explicitly accounting for UWB calibration uncertainty and enabling the joint and consistent estimation of both robot and anchor states. Furthermore, observability consistency is ensured by leveraging the invariant error properties of the Lie group. We analytically prove that the CVIRO algorithm naturally maintains the system's correct unobservable subspace, thereby preserving estimation consistency. Extensive simulations and experiments demonstrate that CVIRO achieves superior localization accuracy and consistency compared to existing methods.",
    "source": "arXiv"
  },
  {
    "title": "TexVerse: A Universe of 3D Objects with High-Resolution Textures",
    "title_es": "TexVerse: A Universe of 3D Objects with High-Resolution Textures",
    "url": "https://arxiv.org/abs/2508.10868",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10868v1 Announce Type: new \nAbstract: We introduce TexVerse, a large-scale 3D dataset featuring high-resolution textures. While recent advances in large-scale 3D datasets have enhanced high-resolution geometry generation, creating high-resolution textures end-to-end remains underexplored due to the lack of suitable datasets. TexVerse fills this gap with a curated collection of over 858K unique high-resolution 3D models sourced from Sketchfab, including more than 158K models with physically based rendering (PBR) materials. Each model encompasses all of its high-resolution variants, bringing the total to 1.6M 3D instances. TexVerse also includes specialized subsets: TexVerse-Skeleton, with 69K rigged models, and TexVerse-Animation, with 54K animated models, both preserving original skeleton and animation data uploaded by the user. We also provide detailed model annotations describing overall characteristics, structural components, and intricate features. TexVerse offers a high-quality data resource with wide-ranging potential applications in texture synthesis, PBR material development, animation, and various 3D vision and graphics tasks.",
    "source": "arXiv"
  },
  {
    "title": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging",
    "title_es": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging",
    "url": "https://arxiv.org/abs/2508.10869",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10869v1 Announce Type: new \nAbstract: The Medico 2025 challenge addresses Visual Question Answering (VQA) for Gastrointestinal (GI) imaging, organized as part of the MediaEval task series. The challenge focuses on developing Explainable Artificial Intelligence (XAI) models that answer clinically relevant questions based on GI endoscopy images while providing interpretable justifications aligned with medical reasoning. It introduces two subtasks: (1) answering diverse types of visual questions using the Kvasir-VQA-x1 dataset, and (2) generating multimodal explanations to support clinical decision-making. The Kvasir-VQA-x1 dataset, created from 6,500 images and 159,549 complex question-answer (QA) pairs, serves as the benchmark for the challenge. By combining quantitative performance metrics and expert-reviewed explainability assessments, this task aims to advance trustworthy Artificial Intelligence (AI) in medical image analysis. Instructions, data access, and an updated guide for participation are available in the official competition repository: https://github.com/simula/MediaEval-Medico-2025",
    "source": "arXiv"
  },
  {
    "title": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning",
    "title_es": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning",
    "url": "https://arxiv.org/abs/2508.10872",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10872v1 Announce Type: new \nAbstract: The increasing congestion of Low Earth Orbit (LEO) poses persistent challenges to the efficient deployment and safe operation of Earth observation satellites. Mission planners must now account not only for mission-specific requirements but also for the increasing collision risk with active satellites and space debris. This work presents a reinforcement learning framework using the Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital parameters for precise terrestrial coverage within predefined surface radii. By formulating the problem as a Markov Decision Process (MDP) within a custom OpenAI Gymnasium environment, our method simulates orbital dynamics using classical Keplerian elements. The agent progressively learns to adjust five of the orbital parameters - semi-major axis, eccentricity, inclination, right ascension of ascending node, and the argument of perigee-to achieve targeted terrestrial coverage. Comparative evaluation against Proximal Policy Optimization (PPO) demonstrates A2C's superior performance, achieving 5.8x higher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer timesteps (2,000 vs 63,000). The A2C agent consistently meets mission objectives across diverse target coordinates while maintaining computational efficiency suitable for real-time mission planning applications. Key contributions include: (1) a TLE-based orbital simulation environment incorporating physics constraints, (2) validation of actor-critic methods' superiority over trust region approaches in continuous orbital control, and (3) demonstration of rapid convergence enabling adaptive satellite deployment. This approach establishes reinforcement learning as a computationally efficient alternative for scalable and intelligent LEO mission planning.",
    "source": "arXiv"
  },
  {
    "title": "SSRL: Self-Search Reinforcement Learning",
    "title_es": "SSRL: Self-Search Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.10874",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10874v1 Announce Type: new \nAbstract: We investigate the potential of large language models (LLMs) to serve as efficient simulators for agentic search tasks in reinforcement learning (RL), thereby reducing dependence on costly interactions with external search engines. To this end, we first quantify the intrinsic search capability of LLMs via structured prompting and repeated sampling, which we term Self-Search. Our results reveal that LLMs exhibit strong scaling behavior with respect to the inference budget, achieving high pass@k on question-answering benchmarks, including the challenging BrowseComp task. Building on these observations, we introduce Self-Search RL (SSRL), which enhances LLMs' Self-Search capability through format-based and rule-based rewards. SSRL enables models to iteratively refine their knowledge utilization internally, without requiring access to external tools. Empirical evaluations demonstrate that SSRL-trained policy models provide a cost-effective and stable environment for search-driven RL training, reducing reliance on external search engines and facilitating robust sim-to-real transfer. We draw the following conclusions: 1) LLMs possess world knowledge that can be effectively elicited to achieve high performance; 2) SSRL demonstrates the potential of leveraging internal knowledge to reduce hallucination; 3) SSRL-trained models integrate seamlessly with external search engines without additional effort. Our findings highlight the potential of LLMs to support more scalable RL agent training.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on Diffusion Language Models",
    "title_es": "A Survey on Diffusion Language Models",
    "url": "https://arxiv.org/abs/2508.10875",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10875v1 Announce Type: new \nAbstract: Diffusion Language Models (DLMs) are rapidly emerging as a powerful and promising alternative to the dominant autoregressive (AR) paradigm. By generating tokens in parallel through an iterative denoising process, DLMs possess inherent advantages in reducing inference latency and capturing bidirectional context, thereby enabling fine-grained control over the generation process. While achieving a several-fold speed-up, recent advancements have allowed DLMs to show performance comparable to their autoregressive counterparts, making them a compelling choice for various natural language processing tasks. In this survey, we provide a holistic overview of the current DLM landscape. We trace its evolution and relationship with other paradigms, such as autoregressive and masked language models, and cover both foundational principles and state-of-the-art models. Our work offers an up-to-date, comprehensive taxonomy and an in-depth analysis of current techniques, from pre-training strategies to advanced post-training methods. Another contribution of this survey is a thorough review of DLM inference strategies and optimizations, including improvements in decoding parallelism, caching mechanisms, and generation quality. We also highlight the latest approaches to multimodal extensions of DLMs and delineate their applications across various practical scenarios. Furthermore, our discussion addresses the limitations and challenges of DLMs, including efficiency, long-sequence handling, and infrastructure requirements, while outlining future research directions to sustain progress in this rapidly evolving field. Project GitHub is available at https://github.com/VILA-Lab/Awesome-DLMs.",
    "source": "arXiv"
  },
  {
    "title": "Searching for Privacy Risks in LLM Agents via Simulation",
    "title_es": "Searching for Privacy Risks in LLM Agents via Simulation",
    "url": "https://arxiv.org/abs/2508.10880",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10880v1 Announce Type: new \nAbstract: The widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. These dynamic dialogues enable adaptive attack strategies that can cause severe privacy violations, yet their evolving nature makes it difficult to anticipate and discover sophisticated vulnerabilities manually. To tackle this problem, we present a search-based framework that alternates between improving attacker and defender instructions by simulating privacy-critical agent interactions. Each simulation involves three roles: data subject, data sender, and data recipient. While the data subject's behavior is fixed, the attacker (data recipient) attempts to extract sensitive information from the defender (data sender) through persistent and interactive exchanges. To explore this interaction space efficiently, our search algorithm employs LLMs as optimizers, using parallel search with multiple threads and cross-thread propagation to analyze simulation trajectories and iteratively propose new instructions. Through this process, we find that attack strategies escalate from simple direct requests to sophisticated multi-turn tactics such as impersonation and consent forgery, while defenses advance from rule-based constraints to identity-verification state machines. The discovered attacks and defenses transfer across diverse scenarios and backbone models, demonstrating strong practical utility for building privacy-aware agents.",
    "source": "arXiv"
  },
  {
    "title": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing",
    "title_es": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing",
    "url": "https://arxiv.org/abs/2508.10881",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10881v1 Announce Type: new \nAbstract: Traditional cartoon and anime production involves keyframing, inbetweening, and colorization stages, which require intensive manual effort. Despite recent advances in AI, existing methods often handle these stages separately, leading to error accumulation and artifacts. For instance, inbetweening approaches struggle with large motions, while colorization methods require dense per-frame sketches. To address this, we introduce ToonComposer, a generative model that unifies inbetweening and colorization into a single post-keyframing stage. ToonComposer employs a sparse sketch injection mechanism to provide precise control using keyframe sketches. Additionally, it uses a cartoon adaptation method with the spatial low-rank adapter to tailor a modern video foundation model to the cartoon domain while keeping its temporal prior intact. Requiring as few as a single sketch and a colored reference frame, ToonComposer excels with sparse inputs, while also supporting multiple sketches at any temporal location for more precise motion control. This dual capability reduces manual workload and improves flexibility, empowering artists in real-world scenarios. To evaluate our model, we further created PKBench, a benchmark featuring human-drawn sketches that simulate real-world use cases. Our evaluation demonstrates that ToonComposer outperforms existing methods in visual quality, motion consistency, and production efficiency, offering a superior and more flexible solution for AI-assisted cartoon production.",
    "source": "arXiv"
  },
  {
    "title": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains",
    "title_es": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains",
    "url": "https://arxiv.org/abs/2508.10887",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10887v1 Announce Type: new \nAbstract: This paper examines Echo State Network, a reservoir computer, performance using four different benchmark problems, then proposes heuristics or rules of thumb for configuring the architecture, as well as the selection of parameters and their values, which are applicable to problems within the same domain, to help serve to fill the experience gap needed by those entering this field of study. The influence of various parameter selections and their value adjustments, as well as architectural changes made to an Echo State Network, a powerful recurrent neural network configured as a reservoir computer, can be challenging to fully comprehend without experience in the field, and even some hyperparameter optimization algorithms may have difficulty adjusting parameter values without proper manual selections made first. Therefore, it is imperative to understand the effects of parameters and their value selection on Echo State Network architecture performance for a successful build. Thus, to address the requirement for an extensive background in Echo State Network architecture, as well as examine how Echo State Network performance is affected with respect to variations in architecture, design, and parameter selection and values, a series of benchmark tasks representing different problem domains, including time series prediction, pattern generation, chaotic system prediction, and time series classification, were modeled and experimented on to show the impact on the performance of Echo State Network.",
    "source": "arXiv"
  },
  {
    "title": "Fuel Consumption in Platoons: A Literature Review",
    "title_es": "Fuel Consumption in Platoons: A Literature Review",
    "url": "https://arxiv.org/abs/2508.10891",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10891v1 Announce Type: new \nAbstract: Platooning has emerged as a promising strategy for improving fuel efficiency in automated vehicle systems, with significant implications for reducing emissions and operational costs. While existing literature on vehicle platooning primarily focuses on individual aspects such as aerodynamic drag reduction or specific control strategies, this work takes a more comprehensive approach by bringing together a wide range of factors and components that contribute to fuel savings in platoons. In this literature review, we examine the impact of platooning on fuel consumption, highlighting the key components of platoon systems, the factors and actors influencing fuel savings, methods for estimating fuel use, and the effect of platoon instability on efficiency. Furthermore, we study the role of reduced aerodynamic drag, vehicle coordination, and the challenges posed by instability in real-world conditions. By compiling insights from recent studies, this work provides a comprehensive overview of the latest advancements in platooning technologies and highlights both the challenges and opportunities for future research to maximize fuel savings in real-world scenarios.",
    "source": "arXiv"
  },
  {
    "title": "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer",
    "title_es": "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer",
    "url": "https://arxiv.org/abs/2508.10893",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10893v1 Announce Type: new \nAbstract: We present STream3R, a novel approach to 3D reconstruction that reformulates pointmap prediction as a decoder-only Transformer problem. Existing state-of-the-art methods for multi-view reconstruction either depend on expensive global optimization or rely on simplistic memory mechanisms that scale poorly with sequence length. In contrast, STream3R introduces an streaming framework that processes image sequences efficiently using causal attention, inspired by advances in modern language modeling. By learning geometric priors from large-scale 3D datasets, STream3R generalizes well to diverse and challenging scenarios, including dynamic scenes where traditional methods often fail. Extensive experiments show that our method consistently outperforms prior work across both static and dynamic scene benchmarks. Moreover, STream3R is inherently compatible with LLM-style training infrastructure, enabling efficient large-scale pretraining and fine-tuning for various downstream 3D tasks. Our results underscore the potential of causal Transformer models for online 3D perception, paving the way for real-time 3D understanding in streaming environments. More details can be found in our project page: https://nirvanalan.github.io/projects/stream3r.",
    "source": "arXiv"
  },
  {
    "title": "MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data",
    "title_es": "MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data",
    "url": "https://arxiv.org/abs/2508.10894",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10894v1 Announce Type: new \nAbstract: Self-supervised learning holds great promise for remote sensing, but standard self-supervised methods must be adapted to the unique characteristics of Earth observation data. We take a step in this direction by conducting a comprehensive benchmark of fusion strategies and reconstruction target normalization schemes for multimodal, multitemporal, and multispectral Earth observation data. Based on our findings, we propose MAESTRO, a novel adaptation of the Masked Autoencoder, featuring optimized fusion strategies and a tailored target normalization scheme that introduces a spectral prior as a self-supervisory signal. Evaluated on four Earth observation datasets, MAESTRO sets a new state-of-the-art on tasks that strongly rely on multitemporal dynamics, while remaining highly competitive on tasks dominated by a single mono-temporal modality. Code to reproduce all our experiments is available at https://github.com/ignf/maestro.",
    "source": "arXiv"
  },
  {
    "title": "ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning",
    "title_es": "ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning",
    "url": "https://arxiv.org/abs/2508.10896",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10896v1 Announce Type: new \nAbstract: In this work, we tackle the problem of video classincremental learning (VCIL). Many existing VCIL methods mitigate catastrophic forgetting by rehearsal training with a few temporally dense samples stored in episodic memory, which is memory-inefficient. Alternatively, some methods store temporally sparse samples, sacrificing essential temporal information and thereby resulting in inferior performance. To address this trade-off between memory-efficiency and performance, we propose EpiSodic and SEmaNTIc memory integrAtion for video class-incremental Learning (ESSENTIAL). ESSENTIAL consists of episodic memory for storing temporally sparse features and semantic memory for storing general knowledge represented by learnable prompts. We introduce a novel memory retrieval (MR) module that integrates episodic memory and semantic prompts through cross-attention, enabling the retrieval of temporally dense features from temporally sparse features. We rigorously validate ESSENTIAL on diverse datasets: UCF-101, HMDB51, and Something-Something-V2 from the TCD benchmark and UCF-101, ActivityNet, and Kinetics-400 from the vCLIMB benchmark. Remarkably, with significantly reduced memory, ESSENTIAL achieves favorable performance on the benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Human-in-Context: Unified Cross-Domain 3D Human Motion Modeling via In-Context Learning",
    "title_es": "Human-in-Context: Unified Cross-Domain 3D Human Motion Modeling via In-Context Learning",
    "url": "https://arxiv.org/abs/2508.10897",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10897v1 Announce Type: new \nAbstract: This paper aims to model 3D human motion across domains, where a single model is expected to handle multiple modalities, tasks, and datasets. Existing cross-domain models often rely on domain-specific components and multi-stage training, which limits their practicality and scalability. To overcome these challenges, we propose a new setting to train a unified cross-domain model through a single process, eliminating the need for domain-specific components and multi-stage training. We first introduce Pose-in-Context (PiC), which leverages in-context learning to create a pose-centric cross-domain model. While PiC generalizes across multiple pose-based tasks and datasets, it encounters difficulties with modality diversity, prompting strategy, and contextual dependency handling. We thus propose Human-in-Context (HiC), an extension of PiC that broadens generalization across modalities, tasks, and datasets. HiC combines pose and mesh representations within a unified framework, expands task coverage, and incorporates larger-scale datasets. Additionally, HiC introduces a max-min similarity prompt sampling strategy to enhance generalization across diverse domains and a network architecture with dual-branch context injection for improved handling of contextual dependencies. Extensive experimental results show that HiC performs better than PiC in terms of generalization, data scale, and performance across a wide range of domains. These results demonstrate the potential of HiC for building a unified cross-domain 3D human motion model with improved flexibility and scalability. The source codes and models are available at https://github.com/BradleyWang0416/Human-in-Context.",
    "source": "arXiv"
  },
  {
    "title": "Puppeteer: Rig and Animate Your 3D Models",
    "title_es": "Puppeteer: Rig and Animate Your 3D Models",
    "url": "https://arxiv.org/abs/2508.10898",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10898v1 Announce Type: new \nAbstract: Modern interactive applications increasingly demand dynamic 3D content, yet the transformation of static 3D models into animated assets constitutes a significant bottleneck in content creation pipelines. While recent advances in generative AI have revolutionized static 3D model creation, rigging and animation continue to depend heavily on expert intervention. We present Puppeteer, a comprehensive framework that addresses both automatic rigging and animation for diverse 3D objects. Our system first predicts plausible skeletal structures via an auto-regressive transformer that introduces a joint-based tokenization strategy for compact representation and a hierarchical ordering methodology with stochastic perturbation that enhances bidirectional learning capabilities. It then infers skinning weights via an attention-based architecture incorporating topology-aware joint attention that explicitly encodes inter-joint relationships based on skeletal graph distances. Finally, we complement these rigging advances with a differentiable optimization-based animation pipeline that generates stable, high-fidelity animations while being computationally more efficient than existing approaches. Extensive evaluations across multiple benchmarks demonstrate that our method significantly outperforms state-of-the-art techniques in both skeletal prediction accuracy and skinning quality. The system robustly processes diverse 3D content, ranging from professionally designed game assets to AI-generated shapes, producing temporally coherent animations that eliminate the jittering issues common in existing methods.",
    "source": "arXiv"
  },
  {
    "title": "A Dataset for Distilling Knowledge Priors from Literature for Therapeutic Design",
    "title_es": "A Dataset for Distilling Knowledge Priors from Literature for Therapeutic Design",
    "url": "https://arxiv.org/abs/2508.10899",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10899v1 Announce Type: new \nAbstract: AI-driven discovery can greatly reduce design time and enhance new therapeutics' effectiveness. Models using simulators explore broad design spaces but risk violating implicit constraints due to a lack of experimental priors. For example, in a new analysis we performed on a diverse set of models on the GuacaMol benchmark using supervised classifiers, over 60\\% of molecules proposed had high probability of being mutagenic. In this work, we introduce \\ourdataset, a dataset of priors for design problems extracted from literature describing compounds used in lab settings. It is constructed with LLM pipelines for discovering therapeutic entities in relevant paragraphs and summarizing information in concise fair-use facts. \\ourdataset~ consists of 32.3 million pairs of natural language facts, and appropriate entity representations (i.e. SMILES or refseq IDs). To demonstrate the potential of the data, we train LLM, CLIP, and LLava architectures to reason jointly about text and design targets and evaluate on tasks from the Therapeutic Data Commons (TDC). \\ourdataset~is highly effective for creating models with strong priors: in supervised prediction problems that use our data as pretraining, our best models with 15M learnable parameters outperform larger 2B TxGemma on both regression and classification TDC tasks, and perform comparably to 9B models on average. Models built with \\ourdataset~can be used as constraints while optimizing for novel molecules in GuacaMol, resulting in proposals that are safer and nearly as effective. We release our dataset at \\href{https://huggingface.co/datasets/medexanon/Medex}{huggingface.co/datasets/medexanon/Medex}, and will provide expanded versions as available literature grows.",
    "source": "arXiv"
  },
  {
    "title": "Quantum Visual Fields with Neural Amplitude Encoding",
    "title_es": "Quantum Visual Fields with Neural Amplitude Encoding",
    "url": "https://arxiv.org/abs/2508.10900",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10900v1 Announce Type: new \nAbstract: Quantum Implicit Neural Representations (QINRs) include components for learning and execution on gate-based quantum computers. While QINRs recently emerged as a promising new paradigm, many challenges concerning their architecture and ansatz design, the utility of quantum-mechanical properties, training efficiency and the interplay with classical modules remain. This paper advances the field by introducing a new type of QINR for 2D image and 3D geometric field learning, which we collectively refer to as Quantum Visual Field (QVF). QVF encodes classical data into quantum statevectors using neural amplitude encoding grounded in a learnable energy manifold, ensuring meaningful Hilbert space embeddings. Our ansatz follows a fully entangled design of learnable parametrised quantum circuits, with quantum (unitary) operations performed in the real Hilbert space, resulting in numerically stable training with fast convergence. QVF does not rely on classical post-processing -- in contrast to the previous QINR learning approach -- and directly employs projective measurement to extract learned signals encoded in the ansatz. Experiments on a quantum hardware simulator demonstrate that QVF outperforms the existing quantum approach and widely used classical foundational baselines in terms of visual representation accuracy across various metrics and model characteristics, such as learning of high-frequency details. We also show applications of QVF in 2D and 3D field completion and 3D shape interpolation, highlighting its practical potential.",
    "source": "arXiv"
  },
  {
    "title": "SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning",
    "title_es": "SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.09325",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09325v1 Announce Type: cross \nAbstract: Visual reinforcement learning (RL) is challenging due to the need to learn both perception and actions from high-dimensional inputs and noisy rewards. Although large perception models exist, integrating them effectively into RL for visual generalization and improved sample efficiency remains unclear. We propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment Anything (SAM) for object-centric decomposition and YOLO-World to ground segments semantically via text prompts. It includes a novel transformer-based architecture that supports a dynamic number of segments at each time step and effectively learns which segments to focus on using online RL, without using human labels. By evaluating SegDAC over a challenging visual generalization benchmark using Maniskill3, which covers diverse manipulation tasks under strong visual perturbations, we demonstrate that SegDAC achieves significantly better visual generalization, doubling prior performance on the hardest setting and matching or surpassing prior methods in sample efficiency across all evaluated tasks.",
    "source": "arXiv"
  },
  {
    "title": "A Classical Quadratic Speedup for Planted $k$XOR",
    "title_es": "A Classical Quadratic Speedup for Planted $k$XOR",
    "url": "https://arxiv.org/abs/2508.09422",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09422v1 Announce Type: cross \nAbstract: A recent work of Schmidhuber et al (QIP, SODA, & Phys. Rev. X 2025) exhibited a quantum algorithm for the noisy planted $k$XOR problem running quartically faster than all known classical algorithms. In this work, we design a new classical algorithm that is quadratically faster than the best previous one, in the case of large constant $k$. Thus for such $k$, the quantum speedup of Schmidhuber et al. becomes only quadratic (though it retains a space advantage). Our algorithm, which also works in the semirandom case, combines tools from sublinear-time algorithms (essentially, the birthday paradox) and polynomial anticoncentration.",
    "source": "arXiv"
  },
  {
    "title": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data",
    "title_es": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data",
    "url": "https://arxiv.org/abs/2508.09636",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09636v1 Announce Type: cross \nAbstract: In this paper, we present a novel model architecture for optimizing personalized product search ranking using a multi-task learning (MTL) framework. Our approach uniquely integrates tabular and non-tabular data, leveraging a pre-trained TinyBERT model for semantic embeddings and a novel sampling technique to capture diverse customer behaviors. We evaluate our model against several baselines, including XGBoost, TabNet, FT-Transformer, DCN-V2, and MMoE, focusing on their ability to handle mixed data types and optimize personalized ranking. Additionally, we propose a scalable relevance labeling mechanism based on click-through rates, click positions, and semantic similarity, offering an alternative to traditional human-annotated labels. Experimental results show that combining non-tabular data with advanced embedding techniques in multi-task learning paradigm significantly enhances model performance. Ablation studies further underscore the benefits of incorporating relevance labels, fine-tuning TinyBERT layers, and TinyBERT query-product embedding interactions. These results demonstrate the effectiveness of our approach in achieving improved personalized product search ranking.",
    "source": "arXiv"
  },
  {
    "title": "zERExtractor:An Automated Platform for Enzyme-Catalyzed Reaction Data Extraction from Scientific Literature",
    "title_es": "zERExtractor:An Automated Platform for Enzyme-Catalyzed Reaction Data Extraction from Scientific Literature",
    "url": "https://arxiv.org/abs/2508.09995",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09995v1 Announce Type: cross \nAbstract: The rapid expansion of enzyme kinetics literature has outpaced the curation capabilities of major biochemical databases, creating a substantial barrier to AI-driven modeling and knowledge discovery. We present zERExtractor, an automated and extensible platform for comprehensive extraction of enzyme-catalyzed reaction and activity data from scientific literature. zERExtractor features a unified, modular architecture that supports plug-and-play integration of state-of-the-art models, including large language models (LLMs), as interchangeable components, enabling continuous system evolution alongside advances in AI. Our pipeline combines domain-adapted deep learning, advanced OCR, semantic entity recognition, and prompt-driven LLM modules, together with human expert corrections, to extract kinetic parameters (e.g., kcat, Km), enzyme sequences, substrate SMILES, experimental conditions, and molecular diagrams from heterogeneous document formats. Through active learning strategies integrating AI-assisted annotation, expert validation, and iterative refinement, the system adapts rapidly to new data sources. We also release a large benchmark dataset comprising over 1,000 annotated tables and 5,000 biological fields from 270 P450-related enzymology publications. Benchmarking demonstrates that zERExtractor consistently outperforms existing baselines in table recognition (Acc 89.9%), molecular image interpretation (up to 99.1%), and relation extraction (accuracy 94.2%). zERExtractor bridges the longstanding data gap in enzyme kinetics with a flexible, plugin-ready framework and high-fidelity extraction, laying the groundwork for future AI-powered enzyme modeling and biochemical knowledge discovery.",
    "source": "arXiv"
  },
  {
    "title": "Jet Image Tagging Using Deep Learning: An Ensemble Model",
    "title_es": "Jet Image Tagging Using Deep Learning: An Ensemble Model",
    "url": "https://arxiv.org/abs/2508.10034",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10034v1 Announce Type: cross \nAbstract: Jet classification in high-energy particle physics is important for understanding fundamental interactions and probing phenomena beyond the Standard Model. Jets originate from the fragmentation and hadronization of quarks and gluons, and pose a challenge for identification due to their complex, multidimensional structure. Traditional classification methods often fall short in capturing these intricacies, necessitating advanced machine learning approaches. In this paper, we employ two neural networks simultaneously as an ensemble to tag various jet types. We convert the jet data to two-dimensional histograms instead of representing them as points in a higher-dimensional space. Specifically, this ensemble approach, hereafter referred to as Ensemble Model, is used to tag jets into classes from the JetNet dataset, corresponding to: Top Quarks, Light Quarks (up or down), and W and Z bosons. For the jet classes mentioned above, we show that the Ensemble Model can be used for both binary and multi-categorical classification. This ensemble approach learns jet features by leveraging the strengths of each constituent network achieving superior performance compared to either individual network.",
    "source": "arXiv"
  },
  {
    "title": "An Intelligent Infrastructure as a Foundation for Modern Science",
    "title_es": "An Intelligent Infrastructure as a Foundation for Modern Science",
    "url": "https://arxiv.org/abs/2508.10051",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10051v1 Announce Type: cross \nAbstract: Infrastructure shapes societies and scientific discovery. Traditional scientific infrastructure, often static and fragmented, leads to issues like data silos, lack of interoperability and reproducibility, and unsustainable short-lived solutions. Our current technical inability and social reticence to connect and coordinate scientific research and engineering leads to inefficiencies and impedes progress. With AI technologies changing how we interact with the world around us, there is an opportunity to transform scientific processes. Neuroscience's exponential growth of multimodal and multiscale data, and urgent clinical relevance demand an infrastructure itself learns, coordinates, and improves. Using neuroscience as a stress test, this perspective argues for a paradigm shift: infrastructure must evolve into a dynamic, AI-aligned ecosystem to accelerate science. Building on several existing principles for data, collective benefit, and digital repositories, I recommend operational guidelines for implementing them to create this dynamic ecosystem, aiming to foster a decentralized, self-learning, and self-correcting system where humans and AI can collaborate seamlessly. Addressing the chronic underfunding of scientific infrastructure, acknowledging diverse contributions beyond publications, and coordinating global efforts are critical steps for this transformation. By prioritizing an intelligent infrastructure as a central scientific instrument for knowledge generation, we can overcome current limitations, accelerate discovery, ensure reproducibility and ethical practices, and ultimately translate neuroscientific understanding into tangible societal benefits, setting a blueprint for other scientific domains.",
    "source": "arXiv"
  },
  {
    "title": "Bayesian Models for Joint Selection of Features and Auto-Regressive Lags: Theory and Applications in Environmental and Financial Forecasting",
    "title_es": "Bayesian Models for Joint Selection of Features and Auto-Regressive Lags: Theory and Applications in Environmental and Financial Forecasting",
    "url": "https://arxiv.org/abs/2508.10055",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10055v1 Announce Type: cross \nAbstract: We develop a Bayesian framework for variable selection in linear regression with autocorrelated errors, accommodating lagged covariates and autoregressive structures. This setting occurs in time series applications where responses depend on contemporaneous or past explanatory variables and persistent stochastic shocks, including financial modeling, hydrological forecasting, and meteorological applications requiring temporal dependency capture. Our methodology uses hierarchical Bayesian models with spike-and-slab priors to simultaneously select relevant covariates and lagged error terms. We propose an efficient two-stage MCMC algorithm separating sampling of variable inclusion indicators and model parameters to address high-dimensional computational challenges. Theoretical analysis establishes posterior selection consistency under mild conditions, even when candidate predictors grow exponentially with sample size, common in modern time series with many potential lagged variables. Through simulations and real applications (groundwater depth prediction, S&P 500 log returns modeling), we demonstrate substantial gains in variable selection accuracy and predictive performance. Compared to existing methods, our framework achieves lower MSPE, improved true model component identification, and greater robustness with autocorrelated noise, underscoring practical utility for model interpretation and forecasting in autoregressive settings.",
    "source": "arXiv"
  },
  {
    "title": "Approximating Entanglement Based on Abstract Interpretation",
    "title_es": "Approximating Entanglement Based on Abstract Interpretation",
    "url": "https://arxiv.org/abs/2508.10056",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10056v1 Announce Type: cross \nAbstract: Entanglement is a fundamental property of quantum systems, essential for non-trivial quantum programs. Identifying when qubits become entangled is critical for circuit optimization, and for arguing for the correctness of quantum algorithms. This paper presents a static analysis method for approximating entanglement by extending an already existing abstract interpretation, thus avoiding the exponential slowdown of an exact analysis. The approach is shown to be sound and an implementation is provided in Standard ML with linear-time scalability.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning",
    "title_es": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning",
    "url": "https://arxiv.org/abs/2508.10057",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10057v1 Announce Type: cross \nAbstract: This study investigates whether large language models (LLMs) mirror human neurocognition during abstract reasoning. We compared the performance and neural representations of human participants with those of eight open-source LLMs on an abstract-pattern-completion task. We leveraged pattern type differences in task performance and in fixation-related potentials (FRPs) as recorded by electroencephalography (EEG) during the task. Our findings indicate that only the largest tested LLMs (~70 billion parameters) achieve human-comparable accuracy, with Qwen-2.5-72B and DeepSeek-R1-70B also showing similarities with the human pattern-specific difficulty profile. Critically, every LLM tested forms representations that distinctly cluster the abstract pattern categories within their intermediate layers, although the strength of this clustering scales with their performance on the task. Moderate positive correlations were observed between the representational geometries of task-optimal LLM layers and human frontal FRPs. These results consistently diverged from comparisons with other EEG measures (response-locked ERPs and resting EEG), suggesting a potential shared representational space for abstract patterns. This indicates that LLMs might mirror human brain mechanisms in abstract reasoning, offering preliminary evidence of shared principles between biological and artificial intelligence.",
    "source": "arXiv"
  },
  {
    "title": "Dynamical Alignment: A Principle for Adaptive Neural Computation",
    "title_es": "Dynamical Alignment: A Principle for Adaptive Neural Computation",
    "url": "https://arxiv.org/abs/2508.10064",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10064v1 Announce Type: cross \nAbstract: The computational capabilities of a neural network are widely assumed to be determined by its static architecture. Here we challenge this view by establishing that a fixed neural structure can operate in fundamentally different computational modes, driven not by its structure but by the temporal dynamics of its input signals. We term this principle 'Dynamical Alignment'.\n  Applying this principle offers a novel resolution to the long-standing paradox of why brain-inspired spiking neural networks (SNNs) underperform. By encoding static input into controllable dynamical trajectories, we uncover a bimodal optimization landscape with a critical phase transition governed by phase space volume dynamics. A 'dissipative' mode, driven by contracting dynamics, achieves superior energy efficiency through sparse temporal codes. In contrast, an 'expansive' mode, driven by expanding dynamics, unlocks the representational power required for SNNs to match or even exceed their artificial neural network counterparts on diverse tasks, including classification, reinforcement learning, and cognitive integration.\n  We find this computational advantage emerges from a timescale alignment between input dynamics and neuronal integration. This principle, in turn, offers a unified, computable perspective on long-observed dualities in neuroscience, from stability-plasticity dilemma to segregation-integration dynamic. It demonstrates that computation in both biological and artificial systems can be dynamically sculpted by 'software' on fixed 'hardware', pointing toward a potential paradigm shift for AI research: away from designing complex static architectures and toward mastering adaptive, dynamic computation principles.",
    "source": "arXiv"
  },
  {
    "title": "In silico study on the cytotoxicity against Hela cancer cells of xanthones bioactive compounds from Garcinia cowa: QSAR based on Graph Deep Learning, Network Pharmacology, and Molecular Docking",
    "title_es": "In silico study on the cytotoxicity against Hela cancer cells of xanthones bioactive compounds from Garcinia cowa: QSAR based on Graph Deep Learning, Network Pharmacology, and Molecular Docking",
    "url": "https://arxiv.org/abs/2508.10117",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10117v1 Announce Type: cross \nAbstract: Cancer is recognized as a complex group of diseases, contributing to the highest global mortality rates, with increasing prevalence and a trend toward affecting younger populations. It is characterized by uncontrolled proliferation of abnormal cells, invasion of adjacent tissues, and metastasis to distant organs. Garcinia cowa, a traditional medicinal plant widely used in Southeast Asia, including Vietnam, is employed to treat fever, cough, indigestion, as a laxative, and for parasitic diseases. Numerous xanthone compounds isolated from this species exhibit a broad spectrum of biological activities, with some showing promise as anti cancer and antimalarial agents. Network pharmacology analysis successfully identified key bioactive compounds Rubraxanthone, Garcinone D, Norcowanin, Cowanol, and Cowaxanthone alongside their primary protein targets (TNF, CTNNB1, SRC, NFKB1, and MTOR), providing critical insights into the molecular mechanisms underlying their anti-cancer effects. The Graph Attention Network algorithm demonstrated superior predictive performance, achieving an R2 of 0.98 and an RMSE of 0.02 after data augmentation, highlighting its accuracy in predicting pIC50 values for xanthone based compounds. Additionally, molecular docking revealed MTOR as a potential target for inducing cytotoxicity in HeLa cancer cells from Garcinia cowa.",
    "source": "arXiv"
  },
  {
    "title": "Machine Learning for Cloud Detection in IASI Measurements: A Data-Driven SVM Approach with Physical Constraints",
    "title_es": "Machine Learning for Cloud Detection in IASI Measurements: A Data-Driven SVM Approach with Physical Constraints",
    "url": "https://arxiv.org/abs/2508.10120",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10120v1 Announce Type: cross \nAbstract: Cloud detection is essential for atmospheric retrievals, climate studies, and weather forecasting. We analyze infrared radiances from the Infrared Atmospheric Sounding Interferometer (IASI) onboard Meteorological Operational (MetOp) satellites to classify scenes as clear or cloudy.\n  We apply the Support Vector Machine (SVM) approach, based on kernel methods for non-separable data. In this study, the method is implemented for Cloud Identification (CISVM) to classify the test set using radiances or brightness temperatures, with dimensionality reduction through Principal Component Analysis (PCA) and cloud-sensitive channel selection to focus on the most informative features. Our best configuration achieves 88.30 percent agreement with reference labels and shows strong consistency with cloud masks from the Moderate Resolution Imaging Spectroradiometer (MODIS), with the largest discrepancies in polar regions due to sensor differences.\n  These results demonstrate that CISVM is a robust, flexible, and efficient method for automated cloud classification from infrared radiances, suitable for operational retrievals and future missions such as Far infrared Outgoing Radiation Understanding and Monitoring (FORUM), the ninth European Space Agency Earth Explorer Mission.",
    "source": "arXiv"
  },
  {
    "title": "Prediction-Powered Inference with Inverse Probability Weighting",
    "title_es": "Prediction-Powered Inference with Inverse Probability Weighting",
    "url": "https://arxiv.org/abs/2508.10149",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10149v1 Announce Type: cross \nAbstract: Prediction-powered inference (PPI) is a recent framework for valid statistical inference with partially labeled data, combining model-based predictions on a large unlabeled set with bias correction from a smaller labeled subset. We show that PPI can be extended to handle informative labeling by replacing its unweighted bias-correction term with an inverse probability weighted (IPW) version, using the classical Horvitz--Thompson or H\\'ajek forms. This connection unites design-based survey sampling ideas with modern prediction-assisted inference, yielding estimators that remain valid when labeling probabilities vary across units. We consider the common setting where the inclusion probabilities are not known but estimated from a correctly specified model. In simulations, the performance of IPW-adjusted PPI with estimated propensities closely matches the known-probability case, retaining both nominal coverage and the variance-reduction benefits of PPI.",
    "source": "arXiv"
  },
  {
    "title": "Distributional Robustness in Output Feedback Regret-Optimal Control",
    "title_es": "Distributional Robustness in Output Feedback Regret-Optimal Control",
    "url": "https://arxiv.org/abs/2508.10150",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10150v1 Announce Type: cross \nAbstract: This paper studies distributionally robust regret-optimal (DRRO) control with purified output feedback for linear systems subject to additive disturbances and measurement noise. These uncertainties (including the initial system state) are assumed to be stochastic and distributed according to an unknown joint probability distribution within a Wasserstein ambiguity set. We design affine controllers to minimise the worst-case expected regret over all distributions in this set. The expected regret is defined as the difference between an expected cost incurred by an affine causal controller and the expected cost incurred by the optimal noncausal controller with perfect knowledge of the disturbance trajectory at the outset. Leveraging the duality theory in distributionally robust optimisation, we derive strong duality results for worst-case expectation problems involving general quadratic objective functions, enabling exact reformulations of the DRRO control problem as semidefinite programs (SDPs). Focusing on one such reformulation, we eliminate certain decision variables. This technique also permits a further equivalent reformulation of the SDP as a distributed optimisation problem, with potential to enhance scalability.",
    "source": "arXiv"
  },
  {
    "title": "Estimating carbon pools in the shelf sea environment: reanalysis or model-informed machine learning?",
    "title_es": "Estimating carbon pools in the shelf sea environment: reanalysis or model-informed machine learning?",
    "url": "https://arxiv.org/abs/2508.10178",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10178v1 Announce Type: cross \nAbstract: Shelf seas are important for carbon sequestration and carbon cycle, but available in situ, or satellite data for carbon pools in the shelf sea environment are often sparse, or highly uncertain. Alternative can be provided by reanalyses, but these are often expensive to run. We propose to use an ensemble of neural networks (NN) to learn from a coupled physics-biogeochemistry model the relationship between the directly observable variables and carbon pools. We demonstrate for North-West European Shelf (NWES) sea environment, that when the NN trained on a model free run simulation is applied to the NWES reanalysis, it is capable to reproduce the reanalysis outputs for carbon pools. Moreover, unlike the existing NWES reanalysis, the NN ensemble is also capable to provide uncertainty information for the pools. We focus on explainability of the results and demonstrate potential use of the NNs for future climate what-if scenarios. We suggest that model-informed machine learning presents a viable alternative to expensive reanalyses and could complement observational data, wherever they are missing and/or highly uncertain.",
    "source": "arXiv"
  },
  {
    "title": "Incorporating Taxonomies of Cyber Incidents Into Detection Networks for Improved Detection Performance",
    "title_es": "Incorporating Taxonomies of Cyber Incidents Into Detection Networks for Improved Detection Performance",
    "url": "https://arxiv.org/abs/2508.10187",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10187v1 Announce Type: cross \nAbstract: Many taxonomies exist to organize cybercrime incidents into ontological categories. We examine some of the taxonomies introduced in the literature; providing a framework, and analysis, of how best to leverage different taxonomy structures to optimize performance of detections targeting various types of threat-actor behaviors under the umbrella of precision and recall. Networks of detections are studied, and results are outlined showing properties of networks of interconnected detections. Some illustrations are provided to show how the construction of sets of detections to prevent broader types of attacks is limited by trade-offs in precision and recall under constraints. An equilibrium result is proven and validated on simulations, illustrating the existence of an optimal detection design strategy in this framework.",
    "source": "arXiv"
  },
  {
    "title": "Mo' Memory, Mo' Problems: Stream-Native Machine Unlearning",
    "title_es": "Mo' Memory, Mo' Problems: Stream-Native Machine Unlearning",
    "url": "https://arxiv.org/abs/2508.10193",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10193v1 Announce Type: cross \nAbstract: Machine unlearning work assumes a static, i.i.d training environment that doesn't truly exist. Modern ML pipelines need to learn, unlearn, and predict continuously on production streams of data. We translate the notion of the batch unlearning scenario to the online setting using notions of regret, sample complexity, and deletion capacity. We further tighten regret bounds to a logarithmic $\\mathcal{O}(\\ln{T})$, a first for a machine unlearning algorithm. And we swap out an expensive Hessian inversion with online variant of L-BFGS optimization, removing a memory footprint that scales linearly with time. Such changes extend the lifespan of an ML model before expensive retraining, making for a more efficient unlearning process.",
    "source": "arXiv"
  },
  {
    "title": "Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks",
    "title_es": "Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks",
    "url": "https://arxiv.org/abs/2508.10196",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10196v1 Announce Type: cross \nAbstract: Early detection of lung cancer is critical to improving survival outcomes. We present a deep learning framework for automated lung cancer screening from chest computed tomography (CT) images with integrated explainability. Using the IQ-OTH/NCCD dataset (1,197 scans across Normal, Benign, and Malignant classes), we evaluate a custom convolutional neural network (CNN) and three fine-tuned transfer learning backbones: DenseNet121, ResNet152, and VGG19. Models are trained with cost-sensitive learning to mitigate class imbalance and evaluated via accuracy, precision, recall, F1-score, and ROC-AUC. While ResNet152 achieved the highest accuracy (97.3%), DenseNet121 provided the best overall balance in precision, recall, and F1 (up to 92%, 90%, 91%, respectively). We further apply Shapley Additive Explanations (SHAP) to visualize evidence contributing to predictions, improving clinical transparency. Results indicate that CNN-based approaches augmented with explainability can provide fast, accurate, and interpretable support for lung cancer screening, particularly in resource-limited settings.",
    "source": "arXiv"
  },
  {
    "title": "CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market",
    "title_es": "CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market",
    "url": "https://arxiv.org/abs/2508.10208",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10208v1 Announce Type: cross \nAbstract: Traditional models for pricing catastrophe (CAT) bonds struggle to capture the complex, relational data inherent in these instruments. This paper introduces CATNet, a novel framework that applies a geometric deep learning architecture, the Relational Graph Convolutional Network (R-GCN), to model the CAT bond primary market as a graph, leveraging its underlying network structure for spread prediction. Our analysis reveals that the CAT bond market exhibits the characteristics of a scale-free network, a structure dominated by a few highly connected and influential hubs. CATNet demonstrates high predictive performance, significantly outperforming a strong Random Forest benchmark. The inclusion of topological centrality measures as features provides a further, significant boost in accuracy. Interpretability analysis confirms that these network features are not mere statistical artifacts; they are quantitative proxies for long-held industry intuition regarding issuer reputation, underwriter influence, and peril concentration. This research provides evidence that network connectivity is a key determinant of price, offering a new paradigm for risk assessment and proving that graph-based models can deliver both state-of-the-art accuracy and deeper, quantifiable market insights.",
    "source": "arXiv"
  },
  {
    "title": "Data-Efficient Learning for Generalizable Surgical Video Understanding",
    "title_es": "Data-Efficient Learning for Generalizable Surgical Video Understanding",
    "url": "https://arxiv.org/abs/2508.10215",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10215v1 Announce Type: cross \nAbstract: Advances in surgical video analysis are transforming operating rooms into intelligent, data-driven environments. Computer-assisted systems support full surgical workflow, from preoperative planning to intraoperative guidance and postoperative assessment. However, developing robust and generalizable models for surgical video understanding remains challenging due to (I) annotation scarcity, (II) spatiotemporal complexity, and (III) domain gap across procedures and institutions. This doctoral research aims to bridge the gap between deep learning-based surgical video analysis in research and its real-world clinical deployment. To address the core challenge of recognizing surgical phases, actions, and events, critical for analysis, I benchmarked state-of-the-art neural network architectures to identify the most effective designs for each task. I further improved performance by proposing novel architectures and integrating advanced modules. Given the high cost of expert annotations and the domain gap across surgical video sources, I focused on reducing reliance on labeled data. We developed semi-supervised frameworks that improve model performance across tasks by leveraging large amounts of unlabeled surgical video. We introduced novel semi-supervised frameworks, including DIST, SemiVT-Surge, and ENCORE, that achieved state-of-the-art results on challenging surgical datasets by leveraging minimal labeled data and enhancing model training through dynamic pseudo-labeling. To support reproducibility and advance the field, we released two multi-task datasets: GynSurg, the largest gynecologic laparoscopy dataset, and Cataract-1K, the largest cataract surgery video dataset. Together, this work contributes to robust, data-efficient, and clinically scalable solutions for surgical video analysis, laying the foundation for generalizable AI systems that can meaningfully impact surgical care and training.",
    "source": "arXiv"
  },
  {
    "title": "DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy",
    "title_es": "DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy",
    "url": "https://arxiv.org/abs/2508.10260",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10260v1 Announce Type: cross \nAbstract: Accurate tissue motion tracking is critical to ensure treatment outcome and safety in 2D-Cine MRI-guided radiotherapy. This is typically achieved by registration of sequential images, but existing methods often face challenges with large misalignments and lack of interpretability. In this paper, we introduce DINOMotion, a novel deep learning framework based on DINOv2 with Low-Rank Adaptation (LoRA) layers for robust, efficient, and interpretable motion tracking. DINOMotion automatically detects corresponding landmarks to derive optimal image registration, enhancing interpretability by providing explicit visual correspondences between sequential images. The integration of LoRA layers reduces trainable parameters, improving training efficiency, while DINOv2's powerful feature representations offer robustness against large misalignments. Unlike iterative optimization-based methods, DINOMotion directly computes image registration at test time. Our experiments on volunteer and patient datasets demonstrate its effectiveness in estimating both linear and nonlinear transformations, achieving Dice scores of 92.07% for the kidney, 90.90% for the liver, and 95.23% for the lung, with corresponding Hausdorff distances of 5.47 mm, 8.31 mm, and 6.72 mm, respectively. DINOMotion processes each scan in approximately 30ms and consistently outperforms state-of-the-art methods, particularly in handling large misalignments. These results highlight its potential as a robust and interpretable solution for real-time motion tracking in 2D-Cine MRI-guided radiotherapy.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Image Denoising Using Global and Local Circulant Representation",
    "title_es": "Efficient Image Denoising Using Global and Local Circulant Representation",
    "url": "https://arxiv.org/abs/2508.10307",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10307v1 Announce Type: cross \nAbstract: The advancement of imaging devices and countless image data generated everyday impose an increasingly high demand on efficient and effective image denoising. In this paper, we present a computationally simple denoising algorithm, termed Haar-tSVD, aiming to explore the nonlocal self-similarity prior and leverage the connection between principal component analysis (PCA) and the Haar transform under circulant representation. We show that global and local patch correlations can be effectively captured through a unified tensor-singular value decomposition (t-SVD) projection with the Haar transform. This results in a one-step, highly parallelizable filtering method that eliminates the need for learning local bases to represent image patches, striking a balance between denoising speed and performance. Furthermore, we introduce an adaptive noise estimation scheme based on a CNN estimator and eigenvalue analysis to enhance the robustness and adaptability of the proposed method. Experiments on different real-world denoising tasks validate the efficiency and effectiveness of Haar-tSVD for noise removal and detail preservation. Datasets, code and results are publicly available at https://github.com/ZhaomingKong/Haar-tSVD.",
    "source": "arXiv"
  },
  {
    "title": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech",
    "title_es": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech",
    "url": "https://arxiv.org/abs/2508.10332",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10332v1 Announce Type: cross \nAbstract: Children's speech presents challenges for age and gender classification due to high variability in pitch, articulation, and developmental traits. While self-supervised learning (SSL) models perform well on adult speech tasks, their ability to encode speaker traits in children remains underexplored. This paper presents a detailed layer-wise analysis of four Wav2Vec2 variants using the PFSTAR and CMU Kids datasets. Results show that early layers (1-7) capture speaker-specific cues more effectively than deeper layers, which increasingly focus on linguistic information. Applying PCA further improves classification, reducing redundancy and highlighting the most informative components. The Wav2Vec2-large-lv60 model achieves 97.14% (age) and 98.20% (gender) on CMU Kids; base-100h and large-lv60 models reach 86.05% and 95.00% on PFSTAR. These results reveal how speaker traits are structured across SSL model depth and support more targeted, adaptive strategies for child-aware speech interfaces.",
    "source": "arXiv"
  },
  {
    "title": "Localization game capture time of trees and outerplanar graphs",
    "title_es": "Localization game capture time of trees and outerplanar graphs",
    "url": "https://arxiv.org/abs/2508.10443",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10443v1 Announce Type: cross \nAbstract: The localization game is a variant of the game of Cops and Robber in which the robber is invisible and moves between adjacent vertices, but the cops can probe any $k$ vertices of the graph to obtain the distance between probed vertices and the robber. The localization number of a graph is the minimum $k$ needed for cops to be able to locate the robber in finite time. The localization capture time is the number of rounds needed for cops to win.\n  The localization capture time conjecture claims that there exists a constant $C$ such that the localization number of every connected graph on $n$ vertices is at most $Cn$. While it is known that the conjecture holds for trees, in this paper we significantly improve the known upper bound for the localization capture time of trees. We also prove the conjecture for a subclass of outerplanar graphs and present a generalization of the localization game that appears useful for making further progress towards the conjecture.",
    "source": "arXiv"
  },
  {
    "title": "New Lower Bounds for the Minimum Singular Value in Matrix Selection",
    "title_es": "New Lower Bounds for the Minimum Singular Value in Matrix Selection",
    "url": "https://arxiv.org/abs/2508.10452",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10452v1 Announce Type: cross \nAbstract: The objective of the matrix selection problem is to select a submatrix $A_{S}\\in \\mathbb{R}^{n\\times k}$ from $A\\in \\mathbb{R}^{n\\times m}$ such that its minimum singular value is maximized. In this paper, we employ the interlacing polynomial method to investigate this problem. This approach allows us to identify a submatrix $A_{S_0}\\in \\mathbb{R}^{n\\times k}$ and establish a lower bound for its minimum singular value. Specifically, unlike common interlacing polynomial approaches that estimate the smallest root of the expected characteristic polynomial via barrier functions, we leverage the direct relationship between roots and coefficients. This leads to a tighter lower bound when $k$ is close to $n$. For the case where $AA^{\\top}=\\mathbb{I}_n$ and $k=n$, our result improves the well-known result by Hong-Pan, which involves extracting a basis from a tight frame and establishing a lower bound for the minimum singular value of the basis matrix.",
    "source": "arXiv"
  },
  {
    "title": "Sum-of-Gaussians tensor neural networks for high-dimensional Schr\\\"odinger equation",
    "title_es": "Sum-of-Gaussians tensor neural networks for high-dimensional Schr\\\"odinger equation",
    "url": "https://arxiv.org/abs/2508.10454",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10454v1 Announce Type: cross \nAbstract: We propose an accurate, efficient, and low-memory sum-of-Gaussians tensor neural network (SOG-TNN) algorithm for solving the high-dimensional Schr\\\"odinger equation. The SOG-TNN utilizes a low-rank tensor product representation of the solution to overcome the curse of dimensionality associated with high-dimensional integration. To handle the Coulomb interaction, we introduce an SOG decomposition to approximate the interaction kernel such that it is dimensionally separable, leading to a tensor representation with rapid convergence. We further develop a range-splitting scheme that partitions the Gaussian terms into short-, long-, and mid-range components. They are treated with the asymptotic expansion, the low-rank Chebyshev expansion, and the model reduction with singular-value decomposition, respectively, significantly reducing the number of two-dimensional integrals in computing electron-electron interactions. The SOG decomposition well resolves the computational challenge due to the singularity of the Coulomb interaction, leading to an efficient algorithm for the high-dimensional problem under the TNN framework. Numerical results demonstrate the outstanding performance of the new method, revealing that the SOG-TNN is a promising way for tackling large and complex quantum systems.",
    "source": "arXiv"
  },
  {
    "title": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules",
    "title_es": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules",
    "url": "https://arxiv.org/abs/2508.10515",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10515v1 Announce Type: cross \nAbstract: Monitoring the degradation state of Insulated Gate Bipolar Transistor (IGBT) modules is essential for ensuring the reliability and longevity of power electronic systems, especially in safety-critical and high-performance applications. However, direct measurement of key degradation indicators - such as junction temperature, solder fatigue or delamination - remains challenging due to the physical inaccessibility of internal components and the harsh environment. In this context, machine learning-based virtual sensing offers a promising alternative by bridging the gap from feasible sensor placement to the relevant but inaccessible locations. This paper explores the feasibility of estimating the degradation state of solder layers, and the corresponding full temperature maps based on a limited number of physical sensors. Based on synthetic data of a specific degradation mode, we obtain a high accuracy in the estimation of the degraded solder area (1.17% mean absolute error), and are able to reproduce the surface temperature of the IGBT with a maximum relative error of 4.56% (corresponding to an average relative error of 0.37%).",
    "source": "arXiv"
  },
  {
    "title": "Mitigating Exponential Mixed Frequency Growth through Frequency Selection and Dimensional Separation in Quantum Machine Learning",
    "title_es": "Mitigating Exponential Mixed Frequency Growth through Frequency Selection and Dimensional Separation in Quantum Machine Learning",
    "url": "https://arxiv.org/abs/2508.10533",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10533v1 Announce Type: cross \nAbstract: To leverage the potential computational speedup of quantum computing (QC), research in quantum machine learning (QML) has gained increasing prominence. Angle encoding techniques in QML models have been shown to generate truncated Fourier series, offering asymptotically universal function approximation capabilities. By selecting efficient feature maps (FMs) within quantum circuits, one can leverage the exponential growth of Fourier frequencies for improved approximation. In multi-dimensional settings, additional input dimensions induce further exponential scaling via mixed frequencies. In practice, however, quantum models frequently fail at regression tasks. Through two white-box experiments, we show that such failures can occur even when the relevant frequencies are present, due to an insufficient number of trainable parameters.\n  In order to mitigate the double-exponential parameter growth resulting from double-exponentially growing frequencies, we propose frequency selection and dimensional separation as techniques to constrain the number of parameters, thereby improving trainability. By restricting the QML model to essential frequencies and permitting mixed frequencies only among feature dimensions with known interdependence, we expand the set of tractable problems on current hardware. We demonstrate the reduced parameter requirements by fitting two white-box functions with known frequency spectrum and dimensional interdependencies that could not be fitted with the default methods. The reduced parameter requirements permit us to perform training on a noisy quantum simulator and to demonstrate inference on real quantum hardware.",
    "source": "arXiv"
  },
  {
    "title": "Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems",
    "title_es": "Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems",
    "url": "https://arxiv.org/abs/2508.10555",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10555v1 Announce Type: cross \nAbstract: Inverse scattering problems are critical in electromagnetic imaging and medical diagnostics but are challenged by their nonlinearity and diverse measurement scenarios. This paper proposes a physics-informed deep contrast source inversion framework (DeepCSI) for fast and accurate medium reconstruction across various measurement conditions. Inspired by contrast source inversion (CSI) and neural operator methods, a residual multilayer perceptron (ResMLP) is employed to model current distributions in the region of interest under different transmitter excitations, effectively linearizing the nonlinear inverse scattering problem and significantly reducing the computational cost of traditional full-waveform inversion. By modeling medium parameters as learnable tensors and utilizing a hybrid loss function that integrates state equation loss, data equation loss, and total variation regularization, DeepCSI establishes a fully differentiable framework for joint optimization of network parameters and medium properties. Compared with conventional methods, DeepCSI offers advantages in terms of simplicity and universal modeling capabilities for diverse measurement scenarios, including phase-less and multi-frequency observation. Simulations and experiments demonstrate that DeepCSI achieves high-precision, robust reconstruction under full-data, phaseless data, and multifrequency conditions, outperforming traditional CSI methods and providing an efficient and universal solution for complex inverse scattering problems.",
    "source": "arXiv"
  },
  {
    "title": "Simulating Mass-Dependent Decoherence in Quantum Computers: Baseline Signatures for Testing Gravity-Induced Collapse",
    "title_es": "Simulating Mass-Dependent Decoherence in Quantum Computers: Baseline Signatures for Testing Gravity-Induced Collapse",
    "url": "https://arxiv.org/abs/2508.10590",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10590v1 Announce Type: cross \nAbstract: We present a quantum computing simulation study of mass-dependent decoherence models inspired by Penrose's gravity-induced collapse hypothesis. According to objective reduction (OR) theory, quantum superpositions become unstable when the gravitational self-energy difference between branches exceeds a certain threshold, leading to a collapse time $\\tau \\approx \\hbar / E_G$. In this work, we implement a mass-dependent dephasing noise channel, $p(m) = 1 - e^{-k m^{\\alpha}}$, within the Qiskit AerSimulator, where $m$ is a proxy for the effective mass of a superposition, mapped to circuit parameters such as the number of entangled qubits or branch size. We apply this model to three canonical quantum computing experiments: GHZ state parity measurements, branch-mass entanglement tests, and Grover's search to generate distinctive collapse signatures that differ qualitatively from constant-rate dephasing. The resulting patterns serve as a baseline reference: if future hardware experiments exhibit the same scaling trends under ideal isolation, this could indicate a contribution from mass-dependent collapse processes. Conversely, deviation toward constant-noise behaviour would suggest the absence of such gravitationally induced effects. Our results provide a reproducible protocol and reference for using quantum computers as potential testbeds for probing fundamental questions in quantum mechanics.",
    "source": "arXiv"
  },
  {
    "title": "A Unified Framework from Boltzmann Transport to Proton Treatment Planning",
    "title_es": "A Unified Framework from Boltzmann Transport to Proton Treatment Planning",
    "url": "https://arxiv.org/abs/2508.10596",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10596v1 Announce Type: cross \nAbstract: This work develops a rigorous mathematical formulation of proton transport by integrating both deterministic and stochastic perspectives. The deterministic framework is based on the Boltzmann-Fokker-Planck equation, formulated as an operator equation in a suitable functional setting. The stochastic approach models proton evolution via a track-length parameterised diffusion process, whose infinitesimal generator provides an alternative description of transport.\n  A key result is the duality between the stochastic and deterministic formulations, established through the adjoint relationship between the transport operator and the stochastic generator. We prove that the resolvent of the stochastic process corresponds to the Green's function of the deterministic equation, providing a natural link between fluence-based and particle-based transport descriptions. The theory is applied to dose computation, where we show that the classical relation: dose = (fluence * mass stopping power) arises consistently in both approaches.\n  Building on this foundation, we formulate a hybrid optimisation framework for treatment planning, in which dose is computed using a stochastic model while optimisation proceeds via adjoint-based PDE methods. We prove existence and differentiability of the objective functional and derive the first-order optimality system. This framework bridges stochastic simulation with deterministic control theory and provides a foundation for future work in constrained, adaptive and uncertainty-aware optimisation in proton therapy.",
    "source": "arXiv"
  },
  {
    "title": "DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality",
    "title_es": "DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality",
    "url": "https://arxiv.org/abs/2508.10605",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10605v1 Announce Type: cross \nAbstract: The rapid growth of user-generated (video) content (UGC) has driven increased demand for research on no-reference (NR) perceptual video quality assessment (VQA). NR-VQA is a key component for large-scale video quality monitoring in social media and streaming applications where a pristine reference is not available. This paper proposes a novel NR-VQA model based on spatio-temporal fragmentation driven by inter-frame variations. By leveraging these inter-frame differences, the model progressively analyses quality-sensitive regions at multiple levels: frames, patches, and fragmented frames. It integrates frames, fragmented residuals, and fragmented frames aligned with residuals to effectively capture global and local information. The model extracts both 2D and 3D features in order to characterize these spatio-temporal variations. Experiments conducted on five UGC datasets and against state-of-the-art models ranked our proposed method among the top 2 in terms of average rank correlation (DIVA-VQA-L: 0.898 and DIVA-VQA-B: 0.886). The improved performance is offered at a low runtime complexity, with DIVA-VQA-B ranked top and DIVA-VQA-L third on average compared to the fastest existing NR-VQA method. Code and models are publicly available at: https://github.com/xinyiW915/DIVA-VQA.",
    "source": "arXiv"
  },
  {
    "title": "Bistochastically private release of longitudinal data",
    "title_es": "Bistochastically private release of longitudinal data",
    "url": "https://arxiv.org/abs/2508.10606",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10606v1 Announce Type: cross \nAbstract: Although the bulk of the research in privacy and statistical disclosure control is designed for cross-sectional data, i.e. data where individuals are observed at one single point in time, longitudinal data, i.e. individuals observed over multiple periods, are increasingly collected. Such data enhance undoubtedly the possibility of statistical analysis compared to cross-sectional data, but also come with one additional layer of information, individual trajectories, that must remain practically useful in a privacy-preserving way. Few extensions, essentially k-anonymity based, of popular privacy tools have been proposed to deal with the challenges posed by longitudinal data, and these proposals are often complex. By considering randomized response, and specifically its recent bistochastic extension, in the context of longitudinal data, this paper proposes a simple approach for their anonymization. After having characterized new results on bistochastic matrices, we show that a simple relationship exists between the protection of each data set released at each period, and the protection of individuals trajectories over time. In turn, this relationship can be tuned according to desired protection and information requirements. We illustrate the application of the proposed approach by an empirical example.",
    "source": "arXiv"
  },
  {
    "title": "Routing and Wavelength Assignment with Minimal Attack Radius for QKD Networks",
    "title_es": "Routing and Wavelength Assignment with Minimal Attack Radius for QKD Networks",
    "url": "https://arxiv.org/abs/2508.10613",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10613v1 Announce Type: cross \nAbstract: Quantum Key Distribution (QKD) can distribute keys with guaranteed security but remains susceptible to key exchange interruption due to physical-layer threats, such as high-power jamming attacks. To address this challenge, we first introduce a novel metric, namely Maximum Number of Affected Requests (maxNAR), to quantify the worst-case impact of a single physical-layer attack, and then we investigate a new problem of Routing and Wavelength Assignment with Minimal Attack Radius (RWA-MAR). We formulate the problem using an Integer Linear Programming (ILP) model and propose a scalable heuristic to efficiently minimize maxNAR. Our approach incorporates key caching through Quantum Key Pools (QKPs) to enhance resilience and optimize resource utilization. Moreover, we model the impact of different QKD network architectures, employing Optical Bypass (OB) for optical switching of quantum channels and Trusted Relay (TR) for secure key forwarding. Moreover, a tunable parameter is designed in the heuristic to guide the preference for OB or TR, offering enhanced adaptability and dynamic control in diverse network scenarios. Simulation results confirm that our method significantly outperforms the baseline in terms of security and scalability.",
    "source": "arXiv"
  },
  {
    "title": "The phi-Process: Operator-Algebraic Embeddings of Possibilities, Transfinite Stabilization, and a Quantitative Application to Sensory Depletion",
    "title_es": "The phi-Process: Operator-Algebraic Embeddings of Possibilities, Transfinite Stabilization, and a Quantitative Application to Sensory Depletion",
    "url": "https://arxiv.org/abs/2508.10650",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10650v1 Announce Type: cross \nAbstract: We formalize a transfinite Phi process that treats all possibility embeddings as operators on structured state spaces including complete lattices, Banach and Hilbert spaces, and orthomodular lattices. We prove a determinization lemma showing that lifting to sets or distributions yields a deterministic global dynamic, an ordinal stabilization theorem sending operator transforms to the fixed subspace by stage omega under normal spectral contraction, and a product of Riesz projections theorem for commuting layers. We establish a compositionality law for lifted maps, show closure of Phi packings, and present a quantitative application to sensory depletion that models tissue removal as a projection and derives strict decreases in the attainable fixed point under minimal monotonicity and positivity assumptions. We also state measurable conditions for probabilistic lifts, give explicit non normal and non commuting counterexamples, and provide finite dimensional and stochastic witnesses together with per theorem scope tables and a small reproducible code appendix.",
    "source": "arXiv"
  },
  {
    "title": "Deciding Whether a C-Q Channel Preserves a Bit is QCMA-Complete",
    "title_es": "Deciding Whether a C-Q Channel Preserves a Bit is QCMA-Complete",
    "url": "https://arxiv.org/abs/2508.10664",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10664v1 Announce Type: cross \nAbstract: We prove that deciding whether a classical-quantum (C-Q) channel can exactly preserve a single classical bit is QCMA-complete. This \"bit-preservation\" problem is a special case of orthogonality-constrained optimization tasks over C-Q channels, in which one seeks orthogonal input states whose outputs have small or large Hilbert-Schmidt overlap after passing through the channel. Both problems can be cast as biquadratic optimization with orthogonality constraints. Our main technical contribution uses tools from matrix analysis to give a complete characterization of the optimal witnesses: computational basis states for the minimum, and |+>, |-> over a single basis pair for the maximum. Using this characterization, we give concise proofs of QCMA-completeness for both problems.",
    "source": "arXiv"
  },
  {
    "title": "Deep Learning in Classical and Quantum Physics",
    "title_es": "Deep Learning in Classical and Quantum Physics",
    "url": "https://arxiv.org/abs/2508.10666",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10666v1 Announce Type: cross \nAbstract: Scientific progress is tightly coupled to the emergence of new research tools. Today, machine learning (ML)-especially deep learning (DL)-has become a transformative instrument for quantum science and technology. Owing to the intrinsic complexity of quantum systems, DL enables efficient exploration of large parameter spaces, extraction of patterns from experimental data, and data-driven guidance for research directions. These capabilities already support tasks such as refining quantum control protocols and accelerating the discovery of materials with targeted quantum properties, making ML/DL literacy an essential skill for the next generation of quantum scientists. At the same time, DL's power brings risks: models can overfit noisy data, obscure causal structure, and yield results with limited physical interpretability. Recognizing these limitations and deploying mitigation strategies is crucial for scientific rigor. These lecture notes provide a comprehensive, graduate-level introduction to DL for quantum applications, combining conceptual exposition with hands-on examples. Organized as a progressive sequence, they aim to equip readers to decide when and how to apply DL effectively, to understand its practical constraints, and to adapt AI methods responsibly to problems across quantum physics, chemistry, and engineering.",
    "source": "arXiv"
  },
  {
    "title": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction",
    "title_es": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction",
    "url": "https://arxiv.org/abs/2508.10718",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10718v1 Announce Type: cross \nAbstract: Accurate prediction of electronic band structures in two-dimensional materials remains a fundamental challenge, with existing methods struggling to balance computational efficiency and physical accuracy. We present the Symmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN) v35, which directly learns graphene band structures while rigorously enforcing crystallographic symmetries through a multi-head architecture. Our approach introduces three specialized ResNet-6 pathways -- K-head for Dirac physics, M-head for saddle points, and General head for smooth interpolation -- operating on 31 physics-informed features extracted from k-points. Progressive Dirac constraint scheduling systematically increases the weight parameter from 5.0 to 25.0, enabling hierarchical learning from global topology to local critical physics. Training on 10,000 k-points over 300 epochs achieves 99.99\\% reduction in training loss (34.597 to 0.003) with validation loss of 0.0085. The model predicts Dirac point gaps within 30.3 $\\mu$eV of theoretical zero and achieves average errors of 53.9 meV (valence) and 40.5 meV (conduction) across the Brillouin zone. All twelve C$_{6v}$ operations are enforced through systematic averaging, guaranteeing exact symmetry preservation. This framework establishes a foundation for extending physics-informed learning to broader two-dimensional materials for accelerated discovery.",
    "source": "arXiv"
  },
  {
    "title": "Two-Instrument Screening under Soft Budget Constraints",
    "title_es": "Two-Instrument Screening under Soft Budget Constraints",
    "url": "https://arxiv.org/abs/2508.10724",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10724v1 Announce Type: cross \nAbstract: We study soft budget constraints in multi-tier public finance when an upper-tier government uses two instruments: an ex-ante grant schedule and an ex-post rescue. Under convex rescue costs and standard primitives, the three-stage leader-follower problem collapses to one dimensional screening with a single allocation index: the cap on realized rescue. A hazard-based characterization delivers a unified rule that nests (i) no rescue, (ii) a threshold-cap with commitment, and (iii) a threshold--linear--cap without commitment. The knife-edge for eliminating bailouts compares the marginal cost at the origin to the supremum of a virtual weight, and the comparative statics show how greater curvature tightens caps while discretion shifts transfers toward front loading by lowering the effective grant weight. The framework provides a portable benchmark for mechanism design and yields testable implications for policy and empirical work on intergovernmental finance.",
    "source": "arXiv"
  },
  {
    "title": "Decoded Quantum Interferometry Under Noise",
    "title_es": "Decoded Quantum Interferometry Under Noise",
    "url": "https://arxiv.org/abs/2508.10725",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10725v1 Announce Type: cross \nAbstract: Decoded Quantum Interferometry (DQI) is a recently proposed quantum optimization algorithm that exploits sparsity in the Fourier spectrum of objective functions, with the potential for exponential speedups over classical algorithms on suitably structured problems. While highly promising in idealized settings, its resilience to noise has until now been largely unexplored. To address this, we conduct a rigorous analysis of DQI under noise, focusing on local depolarizing noise. For the maximum linear satisfiability problem, we prove that, in the presence of noise, performance is governed by a noise-weighted sparsity parameter of the instance matrix, with solution quality decaying exponentially as sparsity decreases. We demonstrate this decay through numerical simulations on two special cases: the Optimal Polynomial Intersection problem and the Maximum XOR Satisfiability problem. The Fourier-analytic methods we develop can be readily adapted to other classes of random Pauli noise, making our framework applicable to a broad range of noisy quantum settings and offering guidance on preserving DQI's potential quantum advantage under realistic noise.",
    "source": "arXiv"
  },
  {
    "title": "FROGENT: An End-to-End Full-process Drug Design Agent",
    "title_es": "FROGENT: An End-to-End Full-process Drug Design Agent",
    "url": "https://arxiv.org/abs/2508.10760",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10760v1 Announce Type: cross \nAbstract: Powerful AI tools for drug discovery reside in isolated web apps, desktop programs, and code libraries. Such fragmentation forces scientists to manage incompatible interfaces and specialized scripts, which can be a cumbersome and repetitive process. To address this issue, a Full-pROcess druG dEsign ageNT, named FROGENT, has been proposed. Specifically, FROGENT utilizes a Large Language Model and the Model Context Protocol to integrate multiple dynamic biochemical databases, extensible tool libraries, and task-specific AI models. This agentic framework allows FROGENT to execute complicated drug discovery workflows dynamically, including component tasks such as target identification, molecule generation and retrosynthetic planning. FROGENT has been evaluated on eight benchmarks that cover various aspects of drug discovery, such as knowledge retrieval, property prediction, virtual screening, mechanistic analysis, molecular design, and synthesis. It was compared against six increasingly advanced ReAct-style agents that support code execution and literature searches. Empirical results demonstrated that FROGENT triples the best baseline performance in hit-finding and doubles it in interaction profiling, significantly outperforming both the open-source model Qwen3-32B and the commercial model GPT-4o. In addition, real-world cases have been utilized to validate the practicability and generalization of FROGENT. This development suggests that streamlining the agentic drug discovery pipeline can significantly enhance researcher productivity.",
    "source": "arXiv"
  },
  {
    "title": "Memorisation and forgetting in a learning Hopfield neural network: bifurcation mechanisms, attractors and basins",
    "title_es": "Memorisation and forgetting in a learning Hopfield neural network: bifurcation mechanisms, attractors and basins",
    "url": "https://arxiv.org/abs/2508.10765",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10765v1 Announce Type: cross \nAbstract: Despite explosive expansion of artificial intelligence based on artificial neural networks (ANNs), these are employed as \"black boxes'', as it is unclear how, during learning, they form memories or develop unwanted features, including spurious memories and catastrophic forgetting. Much research is available on isolated aspects of learning ANNs, but due to their high dimensionality and non-linearity, their comprehensive analysis remains a challenge. In ANNs, knowledge is thought to reside in connection weights or in attractor basins, but these two paradigms are not linked explicitly. Here we comprehensively analyse mechanisms of memory formation in an 81-neuron Hopfield network undergoing Hebbian learning by revealing bifurcations leading to formation and destruction of attractors and their basin boundaries. We show that, by affecting evolution of connection weights, the applied stimuli induce a pitchfork and then a cascade of saddle-node bifurcations creating new attractors with their basins that can code true or spurious memories, and an abrupt disappearance of old memories (catastrophic forgetting). With successful learning, new categories are represented by the basins of newly born point attractors, and their boundaries by the stable manifolds of new saddles. With this, memorisation and forgetting represent two manifestations of the same mechanism. Our strategy to analyse high-dimensional learning ANNs is universal and applicable to recurrent ANNs of any form. The demonstrated mechanisms of memory formation and of catastrophic forgetting shed light on the operation of a wider class of recurrent ANNs and could aid the development of approaches to mitigate their flaws.",
    "source": "arXiv"
  },
  {
    "title": "Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach",
    "title_es": "Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach",
    "url": "https://arxiv.org/abs/2508.10776",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10776v1 Announce Type: cross \nAbstract: Portfolio optimization constitutes a cornerstone of risk management by quantifying the risk-return trade-off. Since it inherently depends on accurate parameter estimation under conditions of future uncertainty, the selection of appropriate input parameters is critical for effective portfolio construction. However, most conventional statistical estimators and machine learning algorithms determine these parameters by minimizing mean-squared error (MSE), a criterion that can yield suboptimal investment decisions. In this paper, we adopt decision-focused learning (DFL) - an approach that directly optimizes decision quality rather than prediction error such as MSE - to derive the global minimum-variance portfolio (GMVP). Specifically, we theoretically derive the gradient of decision loss using the analytic solution of GMVP and its properties regarding the principal components of itself. Through extensive empirical evaluation, we show that prediction-focused estimation methods may fail to produce optimal allocations in practice, whereas DFL-based methods consistently deliver superior decision performance. Furthermore, we provide a comprehensive analysis of DFL's mechanism in GMVP construction, focusing on its volatility reduction capability, decision-driving features, and estimation characteristics.",
    "source": "arXiv"
  },
  {
    "title": "Insights from the Algonauts 2025 Winners",
    "title_es": "Insights from the Algonauts 2025 Winners",
    "url": "https://arxiv.org/abs/2508.10784",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10784v1 Announce Type: cross \nAbstract: The Algonauts 2025 Challenge just wrapped up a few weeks ago. It is a biennial challenge in computational neuroscience in which teams attempt to build models that predict human brain activity from carefully curated stimuli. Previous editions (2019, 2021, 2023) focused on still images and short videos; the 2025 edition, which concluded last month (late July), pushed the field further by using long, multimodal movies. Teams were tasked with predicting fMRI responses across 1,000 whole-brain parcels across four participants in the dataset who were scanned while watching nearly 80 hours of naturalistic movie stimuli. These recordings came from the CNeuroMod project and included 65 hours of training data, about 55 hours of Friends (seasons 1-6) plus four feature films (The Bourne Supremacy, Hidden Figures, Life, and The Wolf of Wall Street). The remaining data were used for validation: Season 7 of Friends for in-distribution tests, and the final winners for the Challenge were those who could best predict brain activity for six films in their held-out out-of-distribution (OOD) set. The winners were just announced and the top team reports are now publicly available. As members of the MedARC team which placed 4th in the competition, we reflect on the approaches that worked, what they reveal about the current state of brain encoding, and what might come next.",
    "source": "arXiv"
  },
  {
    "title": "When Experts Disagree: Characterizing Annotator Variability for Vessel Segmentation in DSA Images",
    "title_es": "When Experts Disagree: Characterizing Annotator Variability for Vessel Segmentation in DSA Images",
    "url": "https://arxiv.org/abs/2508.10797",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10797v1 Announce Type: cross \nAbstract: We analyze the variability among segmentations of cranial blood vessels in 2D DSA performed by multiple annotators in order to characterize and quantify segmentation uncertainty. We use this analysis to quantify segmentation uncertainty and discuss ways it can be used to guide additional annotations and to develop uncertainty-aware automatic segmentation methods.",
    "source": "arXiv"
  },
  {
    "title": "Parity Cross-Resonance: A Multiqubit Gate",
    "title_es": "Parity Cross-Resonance: A Multiqubit Gate",
    "url": "https://arxiv.org/abs/2508.10807",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10807v1 Announce Type: cross \nAbstract: We present a native three-qubit entangling gate that exploits engineered interactions to realize control-control-target and control-target-target operations in a single coherent step. Unlike conventional decompositions into multiple two-qubit gates, our hybrid optimization approach selectively amplifies desired interactions while suppressing unwanted couplings, yielding robust performance across the computational subspace and beyond. The new gate can be classified as a cross-resonance gate. We show it can be utilized in several ways, for example, in GHZ triplet state preparation, Toffoli-class logic demonstrations with many-body interactions, and in implementing a controlled-ZZ gate. The latter maps the parity of two data qubits directly onto a measurement qubit, enabling faster and higher-fidelity stabilizer measurements in surface-code quantum error correction. In all these examples, we show that the three-qubit gate performance remains robust across Hilbert space sizes, as confirmed by testing under increasing total excitation numbers. This work lays the foundation for co-designing circuit architectures and control protocols that leverage native multiqubit interactions as core elements of next-generation superconducting quantum processors.",
    "source": "arXiv"
  },
  {
    "title": "Accelerating exoplanet climate modelling: A machine learning approach to complement 3D GCM grid simulations",
    "title_es": "Accelerating exoplanet climate modelling: A machine learning approach to complement 3D GCM grid simulations",
    "url": "https://arxiv.org/abs/2508.10827",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10827v1 Announce Type: cross \nAbstract: With the development of ever-improving telescopes capable of observing exoplanet atmospheres in greater detail and number, there is a growing demand for enhanced 3D climate models to support and help interpret observational data from space missions like CHEOPS, TESS, JWST, PLATO, and Ariel. However, the computationally intensive and time-consuming nature of general circulation models (GCMs) poses significant challenges in simulating a wide range of exoplanetary atmospheres. This study aims to determine whether machine learning (ML) algorithms can be used to predict the 3D temperature and wind structure of arbitrary tidally-locked gaseous exoplanets in a range of planetary parameters. A new 3D GCM grid with 60 inflated hot Jupiters orbiting A, F, G, K, and M-type host stars modelled with Exorad has been introduced. A dense neural network (DNN) and a decision tree algorithm (XGBoost) are trained on this grid to predict local gas temperatures along with horizontal and vertical winds. To ensure the reliability and quality of the ML model predictions, WASP-121 b, HATS-42 b, NGTS-17 b, WASP-23 b, and NGTS-1 b-like planets, which are all targets for PLATO observation, are selected and modelled with ExoRad and the two ML methods as test cases. The DNN predictions for the gas temperatures are to such a degree that the calculated spectra agree within 32 ppm for all but one planet, for which only one single HCN feature reaches a 100 ppm difference. The developed ML emulators can reliably predict the complete 3D temperature field of an inflated warm to ultra-hot tidally locked Jupiter around A to M-type host stars. It provides a fast tool to complement and extend traditional GCM grids for exoplanet ensemble studies. The quality of the predictions is such that no or minimal effects on the gas phase chemistry, hence on the cloud formation and transmission spectra, are to be expected.",
    "source": "arXiv"
  },
  {
    "title": "Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations",
    "title_es": "Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations",
    "url": "https://arxiv.org/abs/2508.10841",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10841v1 Announce Type: cross \nAbstract: Universal machine-learned potentials promise transferable accuracy across compositional and vibrational degrees of freedom, yet their application to biomolecular simulations remains underexplored. This work systematically evaluates equivariant message-passing architectures trained on the SPICE-v2 dataset with and without explicit long-range dispersion and electrostatics. We assess the impact of model size, training data composition, and electrostatic treatment across in- and out-of-distribution benchmark datasets, as well as molecular simulations of bulk liquid water, aqueous NaCl solutions, and biomolecules, including alanine tripeptide, the mini-protein Trp-cage, and Crambin. While larger models improve accuracy on benchmark datasets, this trend does not consistently extend to properties obtained from simulations. Predicted properties also depend on the composition of the training dataset. Long-range electrostatics show no systematic impact across systems. However, for Trp-cage, their inclusion yields increased conformational variability. Our results suggest that imbalanced datasets and immature evaluation practices currently challenge the applicability of universal machine-learned potentials to biomolecular simulations.",
    "source": "arXiv"
  },
  {
    "title": "Molecule Mixture Detection and Alphabet Design for Non-linear, Cross-reactive Receiver Arrays in MC",
    "title_es": "Molecule Mixture Detection and Alphabet Design for Non-linear, Cross-reactive Receiver Arrays in MC",
    "url": "https://arxiv.org/abs/2508.10856",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10856v1 Announce Type: cross \nAbstract: Air-based molecular communication (MC) has the potential to be one of the first MC systems to be deployed in real-world applications, enabled by existing sensor technologies such as metal-oxide semi-conductor (MOS) sensors. However, commercially available sensors usually exhibit non-linear and cross-reactive behavior, contrary to the idealizing assumptions about linear and perfectly molecule type-specific sensing often made in the MC literature. To address this gap, we propose a detector for molecule mixture communication with a general non-linear, cross-reactive receiver (RX) array that performs approximate maximum likelihood detection on the sensor outputs. Additionally, we introduce an algorithm for the design of mixture alphabets that accounts for the RX characteristics. We evaluate our detector and alphabet design algorithm through simulations that are based on measurements reported for two commercial MOS sensors. Our simulations demonstrate that the proposed detector achieves similar symbol error rates as data-driven methods without requiring large numbers of training samples and that the alphabet design algorithm outperforms methods that do not account for the RX characteristics. Since the proposed detector and alphabet design algorithm are also applicable to other chemical sensors, they pave the way for reliable air-based MC.",
    "source": "arXiv"
  },
  {
    "title": "An Iterative Algorithm for Differentially Private $k$-PCA with Adaptive Noise",
    "title_es": "An Iterative Algorithm for Differentially Private $k$-PCA with Adaptive Noise",
    "url": "https://arxiv.org/abs/2508.10879",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.10879v1 Announce Type: cross \nAbstract: Given $n$ i.i.d. random matrices $A_i \\in \\mathbb{R}^{d \\times d}$ that share a common expectation $\\Sigma$, the objective of Differentially Private Stochastic PCA is to identify a subspace of dimension $k$ that captures the largest variance directions of $\\Sigma$, while preserving differential privacy (DP) of each individual $A_i$. Existing methods either (i) require the sample size $n$ to scale super-linearly with dimension $d$, even under Gaussian assumptions on the $A_i$, or (ii) introduce excessive noise for DP even when the intrinsic randomness within $A_i$ is small. Liu et al. (2022a) addressed these issues for sub-Gaussian data but only for estimating the top eigenvector ($k=1$) using their algorithm DP-PCA. We propose the first algorithm capable of estimating the top $k$ eigenvectors for arbitrary $k \\leq d$, whilst overcoming both limitations above. For $k=1$ our algorithm matches the utility guarantees of DP-PCA, achieving near-optimal statistical error even when $n = \\tilde{\\!O}(d)$. We further provide a lower bound for general $k > 1$, matching our upper bound up to a factor of $k$, and experimentally demonstrate the advantages of our algorithm over comparable baselines.",
    "source": "arXiv"
  },
  {
    "title": "A Polynomial-Time Deterministic Algorithm for an NP-Complete Problem",
    "title_es": "A Polynomial-Time Deterministic Algorithm for an NP-Complete Problem",
    "url": "https://arxiv.org/abs/2108.03877",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2108.03877v4 Announce Type: replace \nAbstract: We introduce an NP-complete graph decision problem, the \"Multi-stage graph Simple Path\" (abbr. MSP) problem, which focuses on determining the existence of specific \"global paths\" in a graph $G$. We show that the MSP problem can be solved in polynomial ($O(|E|^9)$) time, by proposing a polynomial-time graph algorithm and the proof of its correctness. Our result implies NP$=$P. The algorithm leverages the data structure of reachable-path edge-set $R(e)$. By establishing the interplay between preceding decisions and subsequent decisions, the information computed for $R(e)$ (in a monotonically decreasing manner) carries all necessary contextual information, and can be utilized to summarize the \"history\" and to detect the \"future\" for searching \"global paths\". The relation of $R(e)$ of different stages in the multi-stage graph resembles the state-transition equation in dynamic programming, though it is much more convoluted. To avoid exponential complexity, paths are always treated as a collection of edge sets. Our proof of the algorithm is built upon a mathematical induction - based proving framework, which relies on a crucial structural property of the MSP problem: all MSP instances are arranged into the sequence {$G_0,G_1,G_2,...$}, and each $G_{j}(j>0)$ in the sequence must have some $G_{i}(0\\leq i<j)$ that is completely consistent with $G_{j}$ on the existence of \"global paths\". As an auxiliary method, we have conducted tests using multiple AI systems. With the help of a suggested query list that covers the entire content of the paper, the paper has been verified by Doubao, DeepSeek, Kimi, iFlytek Spark, ERNIE Bot, Gemini, and GPT.",
    "source": "arXiv"
  },
  {
    "title": "Improved Regularization and Robustness for Fine-tuning in Neural Networks",
    "title_es": "Improved Regularization and Robustness for Fine-tuning in Neural Networks",
    "url": "https://arxiv.org/abs/2111.04578",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2111.04578v2 Announce Type: replace \nAbstract: A widely used algorithm for transfer learning is fine-tuning, where a pre-trained model is fine-tuned on a target task with a small amount of labeled data. When the capacity of the pre-trained model is significantly larger than the size of the target dataset, fine-tuning is prone to overfitting and memorizing the training labels. Hence, a crucial question is to regularize fine-tuning and ensure its robustness against noise. To address this question, we begin by analyzing the generalization properties of fine-tuning. We present a PAC-Bayes generalization bound that depends on the distance traveled in each layer during fine-tuning and the noise stability of the fine-tuned model. We empirically measure these quantities. Based on the analysis, we propose regularized self-labeling -- the interpolation between regularization and self-labeling methods, including (i) layer-wise regularization to constrain the distance traveled in each layer; (ii) self-label-correction and label-reweighting to correct mislabeled data points (that the model is confident) and reweight less confident data points. We validate our approach on an extensive collection of image and text datasets using multiple pre-trained model architectures. Our approach improves baseline methods by 1.76% (on average) for seven image classification tasks and 0.75% for a few-shot classification task. When the target data set includes noisy labels, our approach outperforms baseline methods by an average of 3.56% in two noisy settings.",
    "source": "arXiv"
  },
  {
    "title": "Learning to Schedule in Parallel-Server Queues with Stochastic Bilinear Rewards",
    "title_es": "Learning to Schedule in Parallel-Server Queues with Stochastic Bilinear Rewards",
    "url": "https://arxiv.org/abs/2112.06362",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2112.06362v4 Announce Type: replace \nAbstract: We consider the problem of scheduling in multi-class, parallel-server queuing systems with uncertain rewards from job-server assignments. In this scenario, jobs incur holding costs while awaiting completion, and job-server assignments yield observable stochastic rewards with unknown mean values. The mean rewards for job-server assignments are assumed to follow a bilinear model with respect to features that characterize jobs and servers. Our objective is to minimize regret by maximizing the cumulative reward of job-server assignments over a time horizon, while keeping the total job holding cost bounded to ensure the stability of the queueing system. This problem is motivated by applications requiring resource allocation in network systems. In this problem, it is essential to control the tradeoff between reward maximization and fair allocation for the stability of the underlying queuing system (i.e., maximizing network throughput). To address this problem, we propose a scheduling algorithm based on a weighted proportional fair criteria augmented with marginal costs for reward maximization, incorporating a bandit algorithm tailored for bilinear rewards. Our algorithm achieves a sub-linear regret bound and a sub-linear mean holding cost (and queue length bound) of $\\tilde{O}(\\sqrt{T})$, respectively, with respect to the time horizon $T$, thus guaranteeing queuing system stability. Additionally, we establish stability conditions for distributed iterative algorithms for computing allocations, which are relevant to large-scale system applications. Finally, we demonstrate the efficiency of our algorithm through numerical experiments.",
    "source": "arXiv"
  },
  {
    "title": "Traversability analysis with vision and terrain probing for safe legged robot navigation",
    "title_es": "Traversability analysis with vision and terrain probing for safe legged robot navigation",
    "url": "https://arxiv.org/abs/2209.00334",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2209.00334v2 Announce Type: replace \nAbstract: Inspired by human behavior when traveling over unknown terrain, this study proposes the use of probing strategies and integrates them into a traversability analysis framework to address safe navigation on unknown rough terrain. Our framework integrates collapsibility information into our existing traversability analysis, as vision and geometric information alone could be misled by unpredictable non-rigid terrains such as soft soil, bush area, or water puddles. With the new traversability analysis framework, our robot has a more comprehensive assessment of unpredictable terrain, which is critical for its safety in outdoor environments. The pipeline first identifies the terrain's geometric and semantic properties using an RGB-D camera and desired probing locations on questionable terrains. These regions are probed using a force sensor to determine the risk of terrain collapsing when the robot steps over it. This risk is formulated as a collapsibility metric, which estimates an unpredictable region's ground collapsibility. Thereafter, the collapsibility metric, together with geometric and semantic spatial data, is combined and analyzed to produce global and local traversability grid maps. These traversability grid maps tell the robot whether it is safe to step over different regions of the map. The grid maps are then utilized to generate optimal paths for the robot to safely navigate to its goal. Our approach has been successfully verified on a quadrupedal robot in both simulation and real-world experiments.",
    "source": "arXiv"
  },
  {
    "title": "Real-time Digital Double Framework to Predict Collapsible Terrains for Legged Robots",
    "title_es": "Real-time Digital Double Framework to Predict Collapsible Terrains for Legged Robots",
    "url": "https://arxiv.org/abs/2209.09508",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2209.09508v2 Announce Type: replace \nAbstract: Inspired by the digital twinning systems, a novel real-time digital double framework is developed to enhance robot perception of the terrain conditions. Based on the very same physical model and motion control, this work exploits the use of such simulated digital double synchronized with a real robot to capture and extract discrepancy information between the two systems, which provides high dimensional cues in multiple physical quantities to represent differences between the modelled and the real world. Soft, non-rigid terrains cause common failures in legged locomotion, whereby visual perception solely is insufficient in estimating such physical properties of terrains. We used digital double to develop the estimation of the collapsibility, which addressed this issue through physical interactions during dynamic walking. The discrepancy in sensory measurements between the real robot and its digital double are used as input of a learning-based algorithm for terrain collapsibility analysis. Although trained only in simulation, the learned model can perform collapsibility estimation successfully in both simulation and real world. Our evaluation of results showed the generalization to different scenarios and the advantages of the digital double to reliably detect nuances in ground conditions.",
    "source": "arXiv"
  },
  {
    "title": "The Effect of Warm-Glow on User Behavioral Intention to Adopt Technology: Extending the UTAUT2 Model",
    "title_es": "The Effect of Warm-Glow on User Behavioral Intention to Adopt Technology: Extending the UTAUT2 Model",
    "url": "https://arxiv.org/abs/2210.01242",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2210.01242v3 Announce Type: replace \nAbstract: In this study, we enhance the Unified Theory of Acceptance and Use of Technology (UTAUT2) by incorporating the warm-glow phenomenon to clarify its impact on user decisions regarding the adoption of technology. We introduce two additional constructs aimed at capturing both the external and internal aspects of warm-glow, thus creating what we refer to as the UTAUT2 + WG model. To evaluate the effectiveness of our model, we conducted an experimental study in which participants were presented with a scenario describing a hypothetical technology designed to evoke warm-glow sensations. Using the partial least squares method, we analyzed the collected data to assess our expanded model. Our findings indicate that warm-glow significantly influences user behavior, with the internal aspect having the strongest influence, followed by hedonic motivation, performance expectancy, and finally the external aspect of warm-glow. We conclude by discussing the implications of our research, acknowledging its limitations, and suggesting directions for future exploration.",
    "source": "arXiv"
  },
  {
    "title": "Revisiting the Fast Fourier Transform in Rocq",
    "title_es": "Revisiting the Fast Fourier Transform in Rocq",
    "url": "https://arxiv.org/abs/2210.05225",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2210.05225v5 Announce Type: replace \nAbstract: This notes explains how a standard algorithm that constructs the discrete Fourier transform has been formalised and proved correct in the Coq proof assistant using the SSReflect extension.",
    "source": "arXiv"
  },
  {
    "title": "A Reference Architecture for Governance of Cloud Native Applications",
    "title_es": "A Reference Architecture for Governance of Cloud Native Applications",
    "url": "https://arxiv.org/abs/2302.11617",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2302.11617v3 Announce Type: replace \nAbstract: The evolution of cloud computing has given rise to Cloud Native Applications (CNAs), presenting new challenges in governance, particularly when faced with strict compliance requirements. This work explores the unique characteristics of CNAs and their impact on governance. We introduce a comprehensive reference architecture designed to streamline governance across CNAs, along with a sample implementation, offering insights for both single and multi-cloud environments. Our architecture seamlessly integrates governance within the CNA framework, adhering to a ``battery-included'' philosophy. Tailored for both expansive and compact CNA deployments across various industries, this design enables cloud practitioners to prioritize product development by alleviating the complexities associated with governance. In addition, it provides a building block for academic exploration of generic CNA frameworks, highlighting their relevance in the evolving cloud computing landscape.",
    "source": "arXiv"
  },
  {
    "title": "Privacy-preserving Blockchain-enabled Parametric Insurance via Remote Sensing and IoT",
    "title_es": "Privacy-preserving Blockchain-enabled Parametric Insurance via Remote Sensing and IoT",
    "url": "https://arxiv.org/abs/2305.08384",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2305.08384v3 Announce Type: replace \nAbstract: Traditional Insurance, a popular approach of financial risk management, has suffered from the issues of high operational costs, opaqueness, inefficiency and a lack of trust. Recently, blockchain-enabled \"parametric insurance\" through authorized data sources (e.g., remote sensing and IoT) aims to overcome these issues by automating the underwriting and claim processes of insurance policies on a blockchain. However, the openness of blockchain platforms raises a concern of user privacy, as the private user data in insurance claims on a blockchain may be exposed to outsiders. In this paper, we propose a privacy-preserving parametric insurance framework based on succinct zero-knowledge proofs (zk-SNARKs), whereby an insuree submits a zero-knowledge proof (without revealing any private data) for the validity of an insurance claim and the authenticity of its data sources to a blockchain for transparent verification. Moreover, we extend the recent zk-SNARKs to support robust privacy protection for multiple heterogeneous data sources and improve its efficiency to cut the incurred gas cost by 80%. As a proof-of-concept, we implemented a working prototype of bushfire parametric insurance on real-world blockchain platform Ethereum, and present extensive empirical evaluations.",
    "source": "arXiv"
  },
  {
    "title": "Hummingbird: Fast, Flexible, and Fair Inter-Domain Bandwidth Reservations",
    "title_es": "Hummingbird: Fast, Flexible, and Fair Inter-Domain Bandwidth Reservations",
    "url": "https://arxiv.org/abs/2308.09959",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2308.09959v5 Announce Type: replace \nAbstract: To realize the long-standing vision of providing quality-of-service (QoS) guarantees on a public Internet, this paper introduces Hummingbird: a lightweight QoS-system that provides fine-grained inter-domain reservations for end hosts.\n  Hummingbird enables flexible and composable reservations with end-to-end guarantees, and addresses an often overlooked, but crucial, aspect of bandwidth-reservation systems: incentivization of network providers. Hummingbird represents bandwidth reservations as tradable assets, allowing markets to emerge. These markets then ensure fair and efficient resource allocation and encourage deployment by remunerating providers. This incentivization is facilitated by decoupling reservations from network identities, which enables novel control-plane mechanisms and allows the design of a control plane based on smart contracts.\n  Hummingbird also provides an efficient reservation data plane, which streamlines the processing on routers and thus simplifies the implementation, deployment, and traffic policing, while maintaining robust security properties. Our prototype implementation demonstrates the efficiency and scalability of Hummingbird's asset-based control plane, and our high-speed software implementation can fill a 160 Gbps link with Hummingbird packets on commodity hardware.",
    "source": "arXiv"
  },
  {
    "title": "Impacts of DEM Type and Resolution on Deep Learning-Based Flood Inundation Mapping",
    "title_es": "Impacts of DEM Type and Resolution on Deep Learning-Based Flood Inundation Mapping",
    "url": "https://arxiv.org/abs/2309.13360",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2309.13360v4 Announce Type: replace \nAbstract: The increasing availability of hydrological and physiographic spatiotemporal data has boosted machine learning's role in rapid flood mapping. Yet, data scarcity, especially high-resolution DEMs, challenges regions with limited access. This paper examines how DEM type and resolution affect flood prediction accuracy, utilizing a cutting-edge deep learning (DL) method called 1D convolutional neural network (CNN). It utilizes synthetic hydrographs as training input and water depth data obtained from LISFLOOD-FP, a 2D hydrodynamic model, as target data. This study investigates digital surface models (DSMs) and digital terrain models (DTMs) derived from a 1 m LIDAR-based DTM, with resolutions from 15 to 30 m. The methodology is applied and assessed in an established benchmark, the city of Carlisle, UK. The models' performance is then evaluated and compared against an observed flood event using RMSE, Bias, and Fit indices. Leveraging the insights gained from this region, the paper discusses the applicability of the methodology to address the challenges encountered in a data-scarce flood-prone region, exemplified by Pakistan. Results indicated that utilizing a 30 m DTM outperformed a 30 m DSM in terms of flood depth prediction accuracy by about 21% during the flood peak stage, highlighting the superior performance of DTM at lower resolutions. Increasing the resolution of DTM to 15 m resulted in a minimum 50% increase in RMSE and a 20% increase in fit index across all flood stages. The findings emphasize that while a coarser resolution DEM may impact the accuracy of machine learning models, it remains a viable option for rapid flood prediction. However, even a slight improvement in data resolution in data-scarce regions would provide significant added value, ultimately enhancing flood risk management.",
    "source": "arXiv"
  },
  {
    "title": "Craig Interpolation for Decidable First-Order Fragments",
    "title_es": "Craig Interpolation for Decidable First-Order Fragments",
    "url": "https://arxiv.org/abs/2310.08689",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2310.08689v5 Announce Type: replace \nAbstract: We show that the guarded-negation fragment is, in a precise sense, the smallest extension of the guarded fragment with Craig interpolation. In contrast, we show that full first-order logic is the smallest extension of both the two-variable fragment and the forward fragment with Craig interpolation. Similarly, we also show that all extensions of the two-variable fragment and of the fluted fragment with Craig interpolation are undecidable.",
    "source": "arXiv"
  },
  {
    "title": "Finite Sample Performance Analysis of MIMO Systems Identification",
    "title_es": "Finite Sample Performance Analysis of MIMO Systems Identification",
    "url": "https://arxiv.org/abs/2310.11790",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2310.11790v5 Announce Type: replace \nAbstract: This paper is concerned with the finite sample identification performance of an n dimensional discrete-time Multiple-Input Multiple-Output (MIMO) Linear Time-Invariant system, with p inputs and m outputs. We prove that the widely-used Ho-Kalman algorithm and Multivariable Output Error State Space (MOESP) algorithm are ill-conditioned for MIMO systems when n/m or n/p is large. Moreover, by analyzing the Cra\\'mer-Rao bound, we derive a fundamental limit for identifying the real and stable (or marginally stable) poles of MIMO system and prove that the sample complexity for any unbiased pole estimation algorithm to reach a certain level of accuracy explodes superpolynomially with respect to n/(pm). Numerical results are provided to illustrate the ill-conditionedness of Ho-Kalman algorithm and MOESP algorithm as well as the fundamental limit on identification.",
    "source": "arXiv"
  },
  {
    "title": "Split Covariance Intersection Filter Based Visual Localization With Accurate AprilTag Map For Warehouse Robot Navigation",
    "title_es": "Split Covariance Intersection Filter Based Visual Localization With Accurate AprilTag Map For Warehouse Robot Navigation",
    "url": "https://arxiv.org/abs/2310.17879",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2310.17879v3 Announce Type: replace \nAbstract: Accurate and efficient localization with conveniently-established map is the fundamental requirement for mobile robot operation in warehouse environments. An accurate AprilTag map can be conveniently established with the help of LiDAR-based SLAM. It is true that a LiDAR-based system is usually not commercially competitive in contrast with a vision-based system, yet fortunately for warehouse applications, only a single LiDAR-based SLAM system is needed to establish an accurate AprilTag map, whereas a large amount of visual localization systems can share this established AprilTag map for their own operations. Therefore, the cost of a LiDAR-based SLAM system is actually shared by the large amount of visual localization systems, and turns to be acceptable and even negligible for practical warehouse applications. Once an accurate AprilTag map is available, visual localization is realized as recursive estimation that fuses AprilTag measurements (i.e. AprilTag detection results) and robot motion data. AprilTag measurements may be nonlinear partial measurements; this can be handled by the well-known extended Kalman filter (EKF) in the spirit of local linearization. AprilTag measurements tend to have temporal correlation as well; however, this cannot be reasonably handled by the EKF. The split covariance intersection filter (Split CIF) is adopted to handle temporal correlation among AprilTag measurements. The Split CIF (in the spirit of local linearization) can also handle AprilTag nonlinear partial measurements. The Split CIF based visual localization system incorporates a measurement adaptive mechanism to handle outliers in AprilTag measurements and adopts a dynamic initialization mechanism to address the kidnapping problem. A comparative study in real warehouse environments demonstrates the potential and advantage of the Split CIF based visual localization solution.",
    "source": "arXiv"
  },
  {
    "title": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo",
    "title_es": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo",
    "url": "https://arxiv.org/abs/2310.19583",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2310.19583v4 Announce Type: replace \nAbstract: Traditional multi-view stereo (MVS) methods rely heavily on photometric and geometric consistency constraints, but newer machine learning-based MVS methods check geometric consistency across multiple source views only as a post-processing step. In this paper, we present a novel approach that explicitly encourages geometric consistency of reference view depth maps across multiple source views at different scales during learning (see Fig. 1). We find that adding this geometric consistency loss significantly accelerates learning by explicitly penalizing geometrically inconsistent pixels, reducing the training iteration requirements to nearly half that of other MVS methods. Our extensive experiments show that our approach achieves a new state-of-the-art on the DTU and BlendedMVS datasets, and competitive results on the Tanks and Temples benchmark. To the best of our knowledge, GC-MVSNet is the first attempt to enforce multi-view, multi-scale geometric consistency during learning.",
    "source": "arXiv"
  },
  {
    "title": "Communication Cost Reduction for Subgraph Counting under Local Differential Privacy via Hash Functions",
    "title_es": "Communication Cost Reduction for Subgraph Counting under Local Differential Privacy via Hash Functions",
    "url": "https://arxiv.org/abs/2312.07055",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2312.07055v2 Announce Type: replace \nAbstract: We suggest the use of hash functions to cut down the communication costs when counting subgraphs under edge local differential privacy. While various algorithms exist for computing graph statistics, including the count of subgraphs, under the edge local differential privacy, many suffer with high communication costs, making them less efficient for large graphs. Though data compression is a typical approach in differential privacy, its application in local differential privacy requires a form of compression that every node can reproduce. In our study, we introduce linear congruence hashing. With a sampling rate of $s$, our method can cut communication costs by a factor of $s^2$, albeit at the cost of increasing variance in the published graph statistic by a factor of $s$. The experimental results indicate that, when matched for communication costs, our method achieves a reduction in the $\\ell_2$-error for triangle counts by up to 1000 times compared to the performance of leading algorithms.",
    "source": "arXiv"
  },
  {
    "title": "Okapi: Efficiently Safeguarding Speculative Data Accesses in Sandboxed Environments",
    "title_es": "Okapi: Efficiently Safeguarding Speculative Data Accesses in Sandboxed Environments",
    "url": "https://arxiv.org/abs/2312.08156",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2312.08156v3 Announce Type: replace \nAbstract: This paper introduces Okapi, a new hardware/software cross-layer architecture designed to mitigate Transient Execution Side Channel attacks, including Spectre variants, in modern computing systems. Okapi provides a hardware basis for secure speculation in sandboxed environments and can replace expensive speculation barriers in software.\n  At its core, it allows for speculative data accesses to a memory page only after the page has been accessed non-speculatively by the current trust domain. The granularity of the trust domains can be controlled in software to achieve different security and performance trade-offs. For environments with less stringent security needs, the features can be deactivated to remove all performance overhead.\n  Without relying on any software modification, the Okapi hardware features provide full protection against TES breakout attacks, e.g., by Spectre-PHT or Spectre-BTB, at a thread-level granularity. This incurs an average performance overhead of only 3.17% for the SPEC CPU2017 benchmark suite.\n  Okapi introduces the OkapiReset instruction for additional software-level security support. This instruction allows for fine-grained sandboxing with any custom size, resulting in 2.34% performance overhead in our WebAssembly runtime experiment.\n  On top, Okapi provides the possibility to eliminate poisoning attacks. For the highest level of security, the OkapiLoad instruction prevents confidential data from being added to the trust domain after a sequential access, thereby enforcing weak speculative non-interference. In addition, we present a hardware extension that limits the exploitable code space for Spectre gadgets to well-defined sections of the program. Therefore, by ensuring the absence of gadgets in these sections, developers can tailor their software towards achieving beneficial trade-offs between the size of a trust domain and performance.",
    "source": "arXiv"
  },
  {
    "title": "Astrocyte Regulated Neuromorphic Central Pattern Generator Control of Legged Robotic Locomotion",
    "title_es": "Astrocyte Regulated Neuromorphic Central Pattern Generator Control of Legged Robotic Locomotion",
    "url": "https://arxiv.org/abs/2312.15805",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2312.15805v3 Announce Type: replace \nAbstract: Neuromorphic computing systems, where information is transmitted through action potentials in a bio-plausible fashion, is gaining increasing interest due to its promise of low-power event-driven computing. Application of neuromorphic computing in robotic locomotion research have largely focused on Central Pattern Generators (CPGs) for bionics robotic control algorithms - inspired from neural circuits governing the collaboration of the limb muscles in animal movement. Implementation of artificial CPGs on neuromorphic hardware platforms can potentially enable adaptive and energy-efficient edge robotics applications in resource constrained environments. However, underlying rewiring mechanisms in CPG for gait emergence process is not well understood. This work addresses the missing gap in literature pertaining to CPG plasticity and underscores the critical homeostatic functionality of astrocytes - a cellular component in the brain that is believed to play a major role in multiple brain functions. This paper introduces an astrocyte regulated Spiking Neural Network (SNN)-based CPG for learning locomotion gait through Reward-Modulated STDP for quadruped robots, where the astrocytes help build inhibitory connections among the artificial motor neurons in different limbs. The SNN-based CPG is simulated on a multi-object physics simulation platform resulting in the emergence of a trotting gait while running the robot on flat ground. $23.3\\times$ computational power savings is observed in comparison to a state-of-the-art reinforcement learning based robot control algorithm. Such a neuroscience-algorithm co-design approach can potentially enable a quantum leap in the functionality of neuromorphic systems incorporating glial cell functionality.",
    "source": "arXiv"
  },
  {
    "title": "Unifying Self-Supervised Clustering and Energy-Based Models",
    "title_es": "Unifying Self-Supervised Clustering and Energy-Based Models",
    "url": "https://arxiv.org/abs/2401.00873",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2401.00873v5 Announce Type: replace \nAbstract: Self-supervised learning excels at learning representations from large amounts of data. At the same time, generative models offer the complementary property of learning information about the underlying data generation process. In this study, we aim at establishing a principled connection between these two paradigms and highlight the benefits of their complementarity. In particular, we perform an analysis of self-supervised learning objectives, elucidating the underlying probabilistic graphical models and presenting a standardized methodology for their derivation from first principles. The analysis suggests a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a lower bound proven to reliably penalize the most important failure modes and unlocking full unification. Our theoretical findings are substantiated through experiments on synthetic and real-world data, including SVHN, CIFAR10, and CIFAR100, demonstrating that our objective function allows to jointly train a backbone network in a discriminative and generative fashion, consequently outperforming existing self-supervised learning strategies in terms of clustering, generation and out-of-distribution detection performance by a wide margin. We also demonstrate that the solution can be integrated into a neuro-symbolic framework to tackle a simple yet non-trivial instantiation of the symbol grounding problem. The code is publicly available at https://github.com/emsansone/GEDI.",
    "source": "arXiv"
  },
  {
    "title": "Video-based automatic lameness detection of dairy cows using pose estimation and multiple locomotion traits",
    "title_es": "Video-based automatic lameness detection of dairy cows using pose estimation and multiple locomotion traits",
    "url": "https://arxiv.org/abs/2401.05202",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2401.05202v2 Announce Type: replace \nAbstract: This study presents an automated lameness detection system that uses deep-learning image processing techniques to extract multiple locomotion traits associated with lameness. Using the T-LEAP pose estimation model, the motion of nine keypoints was extracted from videos of walking cows. The videos were recorded outdoors, with varying illumination conditions, and T-LEAP extracted 99.6% of correct keypoints. The trajectories of the keypoints were then used to compute six locomotion traits: back posture measurement, head bobbing, tracking distance, stride length, stance duration, and swing duration. The three most important traits were back posture measurement, head bobbing, and tracking distance. For the ground truth, we showed that a thoughtful merging of the scores of the observers could improve intra-observer reliability and agreement. We showed that including multiple locomotion traits improves the classification accuracy from 76.6% with only one trait to 79.9% with the three most important traits and to 80.1% with all six locomotion traits.",
    "source": "arXiv"
  },
  {
    "title": "A MAPE-K-Based Method for Architectural Conformance Checking in Self-Adaptive Systems",
    "title_es": "A MAPE-K-Based Method for Architectural Conformance Checking in Self-Adaptive Systems",
    "url": "https://arxiv.org/abs/2401.16382",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2401.16382v2 Announce Type: replace \nAbstract: Self-Adaptive Systems (SASs) are increasingly deployed in critical domains such as healthcare, finance, autonomous vehicles, and smart cities. Ensuring their architectural trustworthiness is essential for maintaining system stability and quality attributes over time. Since SAS architectures are inherently complex, reference models such as MAPE-K have been proposed to guide their design, emphasizing the Feedback Loop as a central component. MAPE-K prescribes abstractions and communication rules that, when preserved, enhance system maintainability, comprehensibility, and conformance. However, maintenance activities often introduce deviations, leading to architectural erosion and loss of compliance with the reference model. Architectural Conformance Checking (ACC) addresses this issue by verifying whether a system's implementation aligns with its Planned Architecture (PA) or a reference model like MAPE-K. In this paper, we introduce REMEDY, a tailored ACC approach for SASs that consists of three key components: (i) A domain-specific language (DSL) for specifying planned architectures based on MAPE-K abstractions; (ii) A tool for recovering the system's current architecture (CA); (iii) A conformance checking process that detects and visualizes architectural deviations. We evaluate REMEDY by comparing its SAS-specific DSL with a general-purpose DSL, demonstrating higher productivity and precision in architectural specification. Additionally, REMEDY effectively identifies and facilitates the correction of non-conformance issues, thereby improving the maintainability and architectural trustworthiness of adaptive systems.",
    "source": "arXiv"
  },
  {
    "title": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach",
    "title_es": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach",
    "url": "https://arxiv.org/abs/2402.13871",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2402.13871v2 Announce Type: replace \nAbstract: Phishing email is a serious cyber threat that tries to deceive users by sending false emails with the intention of stealing confidential information or causing financial harm. Attackers, often posing as trustworthy entities, exploit technological advancements and sophistication to make detection and prevention of phishing more challenging. Despite extensive academic research, phishing detection remains an ongoing and formidable challenge in the cybersecurity landscape. Large Language Models (LLMs) and Masked Language Models (MLMs) possess immense potential to offer innovative solutions to address long-standing challenges. In this research paper, we present an optimized, fine-tuned transformer-based DistilBERT model designed for the detection of phishing emails. In the detection process, we work with a phishing email dataset and utilize the preprocessing techniques to clean and solve the imbalance class issues. Through our experiments, we found that our model effectively achieves high accuracy, demonstrating its capability to perform well. Finally, we demonstrate our fine-tuned model using Explainable-AI (XAI) techniques such as Local Interpretable Model-Agnostic Explanations (LIME) and Transformer Interpret to explain how our model makes predictions in the context of text classification for phishing emails.",
    "source": "arXiv"
  },
  {
    "title": "Interval-Constrained Bipartite Matching over Time",
    "title_es": "Interval-Constrained Bipartite Matching over Time",
    "url": "https://arxiv.org/abs/2402.18469",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2402.18469v5 Announce Type: replace \nAbstract: Interval-constrained online bipartite matching problem frequently occurs in medical appointment scheduling: Unit-time jobs representing patients arrive online and are assigned to a time slot within their given feasible time interval. We consider a variant of this problem where reassignments are allowed and extend it by a notion of time that is decoupled from the job arrival events. As jobs appear, the current point in time gradually advances, and once the time of a slot is passed, the job assigned to it is fixed and cannot be reassigned anymore.\n  We analyze two algorithms for the problem with respect to the resulting matching size and the number of reassignments they make. We show that FirstFit with reassignments according to the shortest augmenting path rule is $\\frac{2}{3}$-competitive with respect to the matching cardinality, and that the bound is tight. For the number of reassignments performed by the algorithm, we show that it is in $\\Omega(n \\log n)$ in the worst case, where $n$ is the number of patients or jobs on the online side. The competitive ratio remains bounded by $\\frac{2}{3}$ if we restrict the algorithm to make only up to a constant number $k \\geq 1$ of reassignments per job arrival. This fills the gap between the known optimal algorithm that makes no reassignments, which is $\\frac{1}{2}$-competitive, on the one hand, and an earliest-deadline-first strategy (EDF), which we prove to obtain a maximum matching in this over-time framework, but which suffers $\\Omega(n^2)$ reassignments in the worst case, on the other hand.\n  Further, we consider the setting in which the sets of feasible slots per job that are not intervals. We show that FirstFit remains $\\frac{2}{3}$-competitive in this case, and that this is the best possible deterministic competitive ratio, while EDF loses its optimality.",
    "source": "arXiv"
  },
  {
    "title": "Debiasing Multimodal Large Language Models via Penalization of Language Priors",
    "title_es": "Debiasing Multimodal Large Language Models via Penalization of Language Priors",
    "url": "https://arxiv.org/abs/2403.05262",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2403.05262v3 Announce Type: replace \nAbstract: In the realms of computer vision and natural language processing, Multimodal Large Language Models (MLLMs) have become indispensable tools, proficient in generating textual responses based on visual inputs. Despite their advancements, our investigation reveals a noteworthy bias: the generated content is often driven more by the inherent priors of the underlying Large Language Models (LLMs) than by the input image. Empirical experiments underscore the persistence of this bias, as MLLMs often provide confident answers even in the absence of relevant images or given incongruent visual inputs. To rectify these biases and redirect the model's focus toward visual information, we propose two simple, training-free strategies. First, for tasks such as classification or multi-choice question answering, we introduce a \"Post-Hoc Debias\" method using an affine calibration step to adjust the output distribution. This approach ensures uniform answer scores when the image is absent, acting as an effective regularization technique to alleviate the influence of LLM priors. For more intricate open-ended generation tasks, we extend this method to \"Visual Debias Decoding\", which mitigates bias by contrasting token log-probabilities conditioned on a correct image versus a meaningless one. Additionally, our investigation sheds light on the instability of MLLMs across various decoding configurations. Through systematic exploration of different settings, we achieve significant performance improvements--surpassing previously reported results--and raise concerns about the fairness of current evaluation practices. Comprehensive experiments substantiate the effectiveness of our proposed strategies in mitigating biases. These strategies not only prove beneficial in minimizing hallucinations but also contribute to the generation of more helpful and precise illustrations.",
    "source": "arXiv"
  },
  {
    "title": "Multiple Reachability in Linear Dynamical Systems",
    "title_es": "Multiple Reachability in Linear Dynamical Systems",
    "url": "https://arxiv.org/abs/2403.06515",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2403.06515v2 Announce Type: replace \nAbstract: We consider reachability decision problems for linear dynamical systems: Given a linear map on $\\mathbb{R}^d$ , together with source and target sets, determine whether there is a point in the source set whose orbit, obtained by repeatedly applying the linear map, enters the target set. When the source and target sets are semialgebraic, this problem can be reduced to a point-to-polytope reachability question. The latter is generally believed not to be substantially harder than the well-known Skolem and Positivity Problems. The situation is markedly different for multiple reachability, i.e. the question of whether the orbit visits the target set at least m times, for some given positive integer m. In this paper, we prove that when the source set is semialgebraic and the target set consists of a hyperplane, multiple reachability is undecidable; in fact we already obtain undecidability in ambient dimension d = 10 and with fixed m = 9. Moreover, as we observe that procedures for dimensions 3 up to 9 would imply strong results pertaining to effective solutions of Diophantine equations, we mainly focus on the affine plane ($\\mathbb{R}^2$). We obtain two main positive results. We show that multiple reachability is decidable for halfplane targets, and that it is also decidable for general semialgebraic targets, provided the linear map is a rotation. The latter result involves a new method, based on intersections of algebraic subgroups with subvarieties, due to Bombieri and Zannier.",
    "source": "arXiv"
  },
  {
    "title": "A bargain for mergesorts -- How to prove your mergesort correct and stable, almost for free",
    "title_es": "A bargain for mergesorts -- How to prove your mergesort correct and stable, almost for free",
    "url": "https://arxiv.org/abs/2403.08173",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2403.08173v3 Announce Type: replace \nAbstract: We present a novel characterization of stable mergesort functions using relational parametricity, and show that it implies the functional correctness of mergesort. As a result, one can prove the correctness of several variations of mergesort (e.g., top-down, bottom-up, tail-recursive, non-tail-recursive, smooth, and non-smooth mergesorts) by proving the characteristic property for each variation. Thanks to our characterization and the parametricity translation, we deduced the correctness results, including stability, of various implementations of mergesort for lists, including highly optimized ones, in the Rocq Prover (formerly the Coq Proof Assistant).",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval",
    "title_es": "Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval",
    "url": "https://arxiv.org/abs/2403.18405",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2403.18405v3 Announce Type: replace \nAbstract: Determining which legal cases are relevant to a given query involves navigating lengthy texts and applying nuanced legal reasoning. Traditionally, this task has demanded significant time and domain expertise to identify key Legal Facts and reach sound juridical conclusions. In addition, existing data with legal case similarities often lack interpretability, making it difficult to understand the rationale behind relevance judgments. With the growing capabilities of large language models (LLMs), researchers have begun investigating their potential in this domain. Nonetheless, the method of employing a general large language model for reliable relevance judgments in legal case retrieval remains largely unexplored. To address this gap in research, we propose a novel few-shot approach where LLMs assist in generating expert-aligned interpretable relevance judgments. The proposed approach decomposes the judgment process into several stages, mimicking the workflow of human annotators and allowing for the flexible incorporation of expert reasoning to improve the accuracy of relevance judgments. Importantly, it also ensures interpretable data labeling, providing transparency and clarity in the relevance assessment process. Through a comparison of relevance judgments made by LLMs and human experts, we empirically demonstrate that the proposed approach can yield reliable and valid relevance assessments. Furthermore, we demonstrate that with minimal expert supervision, our approach enables a large language model to acquire case analysis expertise and subsequently transfers this ability to a smaller model via annotation-based knowledge distillation.",
    "source": "arXiv"
  },
  {
    "title": "Computing large deviation rate functions of entropy production for diffusion processes by an interacting particle method",
    "title_es": "Computing large deviation rate functions of entropy production for diffusion processes by an interacting particle method",
    "url": "https://arxiv.org/abs/2403.19223",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2403.19223v4 Announce Type: replace \nAbstract: We develop an interacting particle method (IPM) for computing the large deviation rate function of entropy production for diffusion processes, with emphasis on the vanishing-noise limit and high dimensions. The crucial ingredient to obtain the rate function is the computation of the principal eigenvalue $\\lambda$ of elliptic, non-self-adjoint operators. We show that this principal eigenvalue can be approximated in terms of the spectral radius of a discretized evolution operator, which is obtained from an operator splitting scheme and an Euler--Maruyama scheme with a small time step size. We also show that this spectral radius can be accessed through a large number of iterations of this discretized semigroup, which is suitable for computation using the IPM. The IPM applies naturally to problems in unbounded domains and scales easily to high dimensions. We show numerical examples of dimensions up to 16, and the results show that our numerical approximation of $\\lambda$ converges to the analytical vanishing-noise limit within visual tolerance with a fixed number of particles and a fixed time step size. It is numerically shown that the IPM can adapt to singular behaviors in the vanishing-noise limit. We also apply the IPM to explore situations with no explicit formulas of the vanishing-noise limit. Our paper appears to be the first one to obtain numerical results of principal eigenvalue problems for non-self-adjoint operators in such high dimensions.",
    "source": "arXiv"
  },
  {
    "title": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning",
    "title_es": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning",
    "url": "https://arxiv.org/abs/2405.02754",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2405.02754v2 Announce Type: replace \nAbstract: Deep reinforcement learning (DRL) has demonstrated remarkable performance in many continuous control tasks. However, a significant obstacle to the real-world application of DRL is the lack of safety guarantees. Although DRL agents can satisfy system safety in expectation through reward shaping, designing agents to consistently meet hard constraints (e.g., safety specifications) at every time step remains a formidable challenge. In contrast, existing work in the field of safe control provides guarantees on persistent satisfaction of hard safety constraints. However, these methods require explicit analytical system dynamics models to synthesize safe control, which are typically inaccessible in DRL settings. In this paper, we present a model-free safe control algorithm, the implicit safe set algorithm, for synthesizing safeguards for DRL agents that ensure provable safety throughout training. The proposed algorithm synthesizes a safety index (barrier certificate) and a subsequent safe control law solely by querying a black-box dynamic function (e.g., a digital twin simulator). Moreover, we theoretically prove that the implicit safe set algorithm guarantees finite time convergence to the safe set and forward invariance for both continuous-time and discrete-time systems. We validate the proposed algorithm on the state-of-the-art Safety Gym benchmark, where it achieves zero safety violations while gaining $95\\% \\pm 9\\%$ cumulative reward compared to state-of-the-art safe DRL methods. Furthermore, the resulting algorithm scales well to high-dimensional systems with parallel computing.",
    "source": "arXiv"
  },
  {
    "title": "Federated Cross-Training Learners for Robust Generalization under Data Heterogeneity",
    "title_es": "Federated Cross-Training Learners for Robust Generalization under Data Heterogeneity",
    "url": "https://arxiv.org/abs/2405.20046",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2405.20046v3 Announce Type: replace \nAbstract: Federated learning benefits from cross-training strategies, which enables models to train on data from distinct sources to improve generalization capability. However, due to inherent differences in data distributions, the optimization goals of local models remain misaligned, and this mismatch continues to manifest as feature space heterogeneity even after cross-training. We argue that knowledge distillation from the personalized view preserves client-specific characteristics and expands the local knowledge base, while distillation from the global view provides consistent semantic anchors that facilitate feature alignment across clients. To achieve this goal, this paper presents a cross-training scheme, termed FedCT, includes three main modules, where the consistency-aware knowledge broadcasting module aims to optimize model assignment strategies, which enhances collaborative advantages between clients and achieves an efficient federated learning process. The multi-view knowledge-guided representation learning module leverages fused prototypical knowledge from both global and local views to enhance the preservation of local knowledge before and after model exchange, as well as to ensure consistency between local and global knowledge. The mixup-based feature augmentation module aggregates rich information to further increase the diversity of feature spaces, which enables the model to better discriminate complex samples. Extensive experiments were conducted on four datasets in terms of performance comparison, ablation study, in-depth analysis and case study. The results demonstrated that FedCT alleviates knowledge forgetting from both local and global views, which enables it outperform state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Graph Collaborative Filtering with FourierKAN Feature Transformation",
    "title_es": "Enhancing Graph Collaborative Filtering with FourierKAN Feature Transformation",
    "url": "https://arxiv.org/abs/2406.01034",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2406.01034v3 Announce Type: replace \nAbstract: Graph Collaborative Filtering (GCF) has emerged as a dominant paradigm in modern recommendation systems, excelling at modeling complex user-item interactions and capturing high-order collaborative signals through graph-structured learning. Most existing GCF models predominantly rely on simplified graph architectures like LightGCN, which strategically remove feature transformation and activation functions from vanilla graph convolution networks. Through systematic analysis, we reveal that feature transformation in message propagation can enhance model representation, though at the cost of increased training difficulty. To this end, we propose FourierKAN-GCF, a novel GCN framework that adopts Fourier Kolmogorov-Arnold Networks as efficient transformation modules within graph propagation layers. This design enhances model representation while decreasing training difficulty. Our FourierKAN-GCF can achieve higher recommendation performance than most widely used GCF backbone models. In addition, it can be integrated into existing advanced self-supervised models as a backbone, replacing their original backbone to achieve enhanced performance. Extensive experiments on three public datasets demonstrate the superiority of FourierKAN-GCF.",
    "source": "arXiv"
  },
  {
    "title": "Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed",
    "title_es": "Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed",
    "url": "https://arxiv.org/abs/2406.04443",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2406.04443v3 Announce Type: replace \nAbstract: Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for training modern Deep Learning models, especially Large Language Models. Typically, the noise in the stochastic gradients is heavy-tailed for the later ones. Gradient clipping provably helps to achieve good high-probability convergence for such noises. However, despite the similarity between AdaGrad/Adam and Clip-SGD, the current understanding of the high-probability convergence of AdaGrad/Adam-type methods is limited in this case. In this work, we prove that AdaGrad/Adam (and their delayed version) can have provably bad high-probability convergence if the noise is heavy-tailed. We also show that gradient clipping fixes this issue, i.e., we derive new high-probability convergence bounds with polylogarithmic dependence on the confidence level for AdaGrad-Norm and Adam-Norm with clipping and with/without delay for smooth convex/non-convex stochastic optimization with heavy-tailed noise. We extend our results to the case of AdaGrad/Adam with delayed stepsizes. Our empirical evaluations highlight the superiority of clipped versions of AdaGrad/Adam in handling the heavy-tailed noise.",
    "source": "arXiv"
  },
  {
    "title": "Tactile Aware Dynamic Obstacle Avoidance in Crowded Environment with Deep Reinforcement Learning",
    "title_es": "Tactile Aware Dynamic Obstacle Avoidance in Crowded Environment with Deep Reinforcement Learning",
    "url": "https://arxiv.org/abs/2406.13434",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2406.13434v2 Announce Type: replace \nAbstract: Mobile robots operating in crowded environments require the ability to navigate among humans and surrounding obstacles efficiently while adhering to safety standards and socially compliant mannerisms. This scale of the robot navigation problem may be classified as both a local path planning and trajectory optimization problem. This work presents an array of force sensors that act as a tactile layer to complement the use of a LiDAR for the purpose of inducing awareness of contact with any surrounding objects within immediate vicinity of a mobile robot undetected by LiDARs. By incorporating the tactile layer, the robot can take more risks in its movements and possibly go right up to an obstacle or wall, and gently squeeze past it. In addition, we built up a simulation platform via Pybullet which integrates Robot Operating System (ROS) and reinforcement learning (RL) together. A touch-aware neural network model was trained on it to create an RL-based local path planner for dynamic obstacle avoidance. Our proposed method was demonstrated successfully on an omni-directional mobile robot who was able to navigate in a crowded environment with high agility and versatility in movement, while not being overly sensitive to nearby obstacles-not-in-contact.",
    "source": "arXiv"
  },
  {
    "title": "Mixed precision iterative refinement for least squares with linear equality constraints and generalized least squares problems",
    "title_es": "Mixed precision iterative refinement for least squares with linear equality constraints and generalized least squares problems",
    "url": "https://arxiv.org/abs/2406.16499",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2406.16499v3 Announce Type: replace \nAbstract: Recent development on mixed precision techniques has largely enhanced the performance of various linear algebra solvers, one of which being the solver for the least squares problem $\\min_{x}\\lVert b-Ax\\rVert_{2}$. By transforming least squares problems into augmented linear systems, mixed precision techniques are capable of refining the lower precision solution to the working precision. In this paper, we propose mixed precision iterative refinement algorithms for two variants of least squares problems -- the least squares problem with linear equality constraints (LSE) and the generalized least squares problem (GLS). Both classical and GMRES-based iterative refinement can be applied to augmented systems of these two problems to improve the accuracy of the solution. For reasonably well-conditioned problems, our algorithms reduce the execution time by a factor of 40% on average compared to the fixed precision ones from LAPACK on the x86-64 architecture.",
    "source": "arXiv"
  },
  {
    "title": "Minimax Optimality in Contextual Dynamic Pricing with General Valuation Models",
    "title_es": "Minimax Optimality in Contextual Dynamic Pricing with General Valuation Models",
    "url": "https://arxiv.org/abs/2406.17184",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2406.17184v2 Announce Type: replace \nAbstract: We study contextual dynamic pricing, where a decision maker posts personalized prices based on observable contexts and receives binary purchase feedback indicating whether the customer's valuation exceeds the price. Each valuation is modeled as an unknown latent function of the context, corrupted by independent and identically distributed market noise from an unknown distribution. Relying only on Lipschitz continuity of the noise distribution and bounded valuations, we propose a minimax-optimal algorithm. To accommodate the unknown distribution, our method discretizes the relevant noise range to form a finite set of candidate prices, then applies layered data partitioning to obtain confidence bounds substantially tighter than those derived via the elliptical-potential lemma. A key advantage is that estimation bias in the valuation function cancels when comparing upper confidence bounds, eliminating the need to know the Lipschitz constant. The framework extends beyond linear models to general function classes through offline regression oracles. Our regret analysis depends solely on the oracle's estimation error, typically governed by the statistical complexity of the class. These techniques yield a regret upper bound matching the minimax lower bound up to logarithmic factors. Furthermore, we refine these guarantees under additional structures -- e.g., linear valuation models, second-order smoothness, sparsity, and known noise distribution or observable valuations -- and compare our bounds and assumptions with prior dynamic-pricing methods. Finally, numerical experiments corroborate the theory and show clear improvements over benchmark methods.",
    "source": "arXiv"
  },
  {
    "title": "An Attempt to Devise a Pairwise Ising-Type Maximum Entropy Model Integrated Cost Function for Optimizing SNN Deployment",
    "title_es": "An Attempt to Devise a Pairwise Ising-Type Maximum Entropy Model Integrated Cost Function for Optimizing SNN Deployment",
    "url": "https://arxiv.org/abs/2407.07014",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2407.07014v4 Announce Type: replace \nAbstract: Spiking Neural Networks (SNNs) emulate the spiking behavior of biological neurons and are typically deployed on distributed-memory neuromorphic hardware. The deployment of a SNN usually requires partitioning the network and mapping these partitions onto the hardware's processing units.\n  However, finding optimal deployment configurations is an NP-hard problem, often addressed through optimization algorithms. While some objectives (e.g., memory utilization and chip count) are static, others (e.g., communication latency and energy efficiency) depend on the network's dynamic behavior, necessitating dynamic-aware optimization.\n  To address this, we model SNN dynamics using an Ising-type pairwise interaction framework, bridging microscopic neuron interactions with macroscopic network behavior. We optimize deployment by exploring the parameter and configuration spaces of the Ising model.\n  We evaluate our approach on two SNNs deployed on the sPyNNaker neuromorphic platform. Initial results suggest that the method underperforms, potentially due to the Ising model's equilibrium assumptions and the architectural complexity of real-world neuromorphic hardware, highlighting limitations in its current formulation.\n  Update: The method proposed is with a equilibrium-dynamics SNN assumption, and the original paper does not mention this. The paper needs to be revisited and reuploaded after further experiments.",
    "source": "arXiv"
  },
  {
    "title": "Knowledge-based Consistency Testing of Large Language Models",
    "title_es": "Knowledge-based Consistency Testing of Large Language Models",
    "url": "https://arxiv.org/abs/2407.12830",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2407.12830v3 Announce Type: replace \nAbstract: In this work, we systematically expose and measure the inconsistency and knowledge gaps of Large Language Models (LLMs). Specifically, we propose an automated testing framework (called KonTest) which leverages a knowledge graph to construct test cases. KonTest probes and measures the inconsistencies in the LLM's knowledge of the world via a combination of semantically-equivalent queries and test oracles (metamorphic or ontological oracle). KonTest further mitigates knowledge gaps via a weighted LLM model ensemble. Using four state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that KonTest generates 19.2% error inducing inputs (1917 errors from 9979 test inputs). It also reveals a 16.5% knowledge gap across all tested LLMs. A mitigation method informed by KonTest's test suite reduces LLM knowledge gap by 32.48%. Our ablation study further shows that GPT3.5 is not suitable for knowledge-based consistency testing because it is only 60%-68% effective in knowledge construction.",
    "source": "arXiv"
  },
  {
    "title": "Collaborative Mean Estimation Among Heterogeneous Strategic Agents: Individual Rationality, Fairness, and Truthful Contribution",
    "title_es": "Collaborative Mean Estimation Among Heterogeneous Strategic Agents: Individual Rationality, Fairness, and Truthful Contribution",
    "url": "https://arxiv.org/abs/2407.15881",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2407.15881v3 Announce Type: replace \nAbstract: We study a collaborative learning problem where $m$ agents aim to estimate a vector $\\mu =(\\mu_1,\\ldots,\\mu_d)\\in \\mathbb{R}^d$ by sampling from associated univariate normal distributions $\\{\\mathcal{N}(\\mu_k, \\sigma^2)\\}_{k\\in[d]}$. Agent $i$ incurs a cost $c_{i,k}$ to sample from $\\mathcal{N}(\\mu_k, \\sigma^2)$. Instead of working independently, agents can exchange data, collecting cheaper samples and sharing them in return for costly data, thereby reducing both costs and estimation error. We design a mechanism to facilitate such collaboration, while addressing two key challenges: ensuring individually rational (IR) and fair outcomes so all agents benefit, and preventing strategic behavior (e.g. non-collection, data fabrication) to avoid socially undesirable outcomes. We design a mechanism and an associated Nash equilibrium (NE) which minimizes the social penalty-sum of agents' estimation errors and collection costs-while being IR for all agents. We achieve a $\\mathcal{O}(\\sqrt{m})$-approximation to the minimum social penalty in the worst case and an $\\mathcal{O}(1)$-approximation under favorable conditions. Additionally, we establish three hardness results: no nontrivial mechanism guarantees (i) a dominant strategy equilibrium where agents report truthfully, (ii) is IR for every strategy profile of other agents, (iii) or avoids a worst-case $\\Omega(\\sqrt{m})$ price of stability in any NE. Finally, by integrating concepts from axiomatic bargaining, we demonstrate that our mechanism supports fairer outcomes than one which minimizes social penalty.",
    "source": "arXiv"
  },
  {
    "title": "VPOcc: Exploiting Vanishing Point for 3D Semantic Occupancy Prediction",
    "title_es": "VPOcc: Exploiting Vanishing Point for 3D Semantic Occupancy Prediction",
    "url": "https://arxiv.org/abs/2408.03551",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2408.03551v2 Announce Type: replace \nAbstract: Understanding 3D scenes semantically and spatially is crucial for the safe navigation of robots and autonomous vehicles, aiding obstacle avoidance and accurate trajectory planning. Camera-based 3D semantic occupancy prediction, which infers complete voxel grids from 2D images, is gaining importance in robot vision for its resource efficiency compared to 3D sensors. However, this task inherently suffers from a 2D-3D discrepancy, where objects of the same size in 3D space appear at different scales in a 2D image depending on their distance from the camera due to perspective projection. To tackle this issue, we propose a novel framework called VPOcc that leverages a vanishing point (VP) to mitigate the 2D-3D discrepancy at both the pixel and feature levels. As a pixel-level solution, we introduce a VPZoomer module, which warps images by counteracting the perspective effect using a VP-based homography transformation. In addition, as a feature-level solution, we propose a VP-guided cross-attention (VPCA) module that performs perspective-aware feature aggregation, utilizing 2D image features that are more suitable for 3D space. Lastly, we integrate two feature volumes extracted from the original and warped images to compensate for each other through a spatial volume fusion (SVF) module. By effectively incorporating VP into the network, our framework achieves improvements in both IoU and mIoU metrics on SemanticKITTI and SSCBench-KITTI360 datasets. Additional details are available at https://vision3d-lab.github.io/vpocc/.",
    "source": "arXiv"
  },
  {
    "title": "VERCATION: Precise Vulnerable Open-source Software Version Identification based on Static Analysis and LLM",
    "title_es": "VERCATION: Precise Vulnerable Open-source Software Version Identification based on Static Analysis and LLM",
    "url": "https://arxiv.org/abs/2408.07321",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2408.07321v2 Announce Type: replace \nAbstract: Open-source software (OSS) has experienced a surge in popularity, attributed to its collaborative development model and cost-effective nature. However, the adoption of specific software versions in development projects may introduce security risks when these versions bring along vulnerabilities. Current methods of identifying vulnerable versions typically analyze and extract the code features involved in vulnerability patches using static analysis with pre-defined rules. They then use code clone detection to identify the vulnerable versions. These methods are hindered by imprecision due to (1) the exclusion of vulnerability-irrelevant code in the analysis and (2) the inadequacy of code clone detection. This paper presents VERCATION, an approach designed to identify vulnerable versions of OSS written in C/C++. VERCATION combines program slicing with a Large Language Model (LLM) to identify vulnerability-relevant code from vulnerability patches. It then backtracks historical commits to gather previous modifications of identified vulnerability-relevant code. We propose code clone detection based on expanded and normalized ASTs to compare the differences between pre-modification and post-modification code, thereby locating the vulnerability-introducing commit (vic) and enabling the identification of the vulnerable versions between the vulnerability-fixing commit and the vic. We curate a dataset linking 122 OSS vulnerabilities and 1,211 versions to evaluate VERCATION. On this dataset, our approach achieves an F1 score of 93.1%, outperforming current state-of-the-art methods. More importantly, VERCATION detected 202 incorrect vulnerable OSS versions in NVD reports.",
    "source": "arXiv"
  },
  {
    "title": "Detection and Tracking of MAVs Using a Rosette Scanning Pattern LiDAR",
    "title_es": "Detection and Tracking of MAVs Using a Rosette Scanning Pattern LiDAR",
    "url": "https://arxiv.org/abs/2408.08555",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2408.08555v3 Announce Type: replace \nAbstract: The use of commercial Micro Aerial Vehicles (MAVs) has surged in the past decade, offering societal benefits but also raising risks such as airspace violations and privacy concerns. Due to the increased security risks, the development of autonomous drone detection and tracking systems has become a priority. In this study, we tackle this challenge, by using non-repetitive rosette scanning pattern LiDARs, particularly focusing on increasing the detection distance by leveraging the characteristics of the sensor. The presented method utilizes a particle filter with a velocity component for the detection and tracking of the drone, which offers added re-detection capability. A Pan-Tilt platform is utilized to take advantage of the specific characteristics of the rosette scanning pattern LiDAR by keeping the tracked object in the center where the measurement is most dense. The detection capabilities and accuracy of the system are validated through indoor experiments, while the maximum detection distance is shown in our outdoor experiments. Our approach achieved accuracy on par with the state-of-the-art indoor method while increasing the maximum detection range by approximately 80\\% beyond the state-of-the-art outdoor method.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Homomorphically Encrypted Convolutional Neural Network Without Rotation",
    "title_es": "Efficient Homomorphically Encrypted Convolutional Neural Network Without Rotation",
    "url": "https://arxiv.org/abs/2409.05205",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2409.05205v2 Announce Type: replace \nAbstract: Privacy-preserving neural network (NN) inference can be achieved by utilizing homomorphic encryption (HE), which allows computations to be directly carried out over ciphertexts. Popular HE schemes are built over large polynomial rings. To allow simultaneous multiplications in the convolutional (Conv) and fully-connected (FC) layers, multiple input data are mapped to coefficients in the same polynomial, so are the weights of NNs. However, ciphertext rotations are necessary to compute the sums of products and/or incorporate the outputs of different channels into the same polynomials. Ciphertext rotations have much higher complexity than ciphertext multiplications and contribute to the majority of the latency of HE-evaluated Conv and FC layers. This paper proposes a novel reformulated server-client joint computation procedure and a new filter coefficient packing scheme to eliminate ciphertext rotations without affecting the security of the HE scheme. Our proposed scheme also leads to substantial reductions on the number of coefficient multiplications needed and the communication cost between the server and client. For various plain-20 classifiers over the CIFAR-10/100 datasets, our design reduces the running time of the Conv and FC layers by 15.5% and the communication cost between client and server by more than 50%, compared to the best prior design.",
    "source": "arXiv"
  },
  {
    "title": "Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization",
    "title_es": "Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization",
    "url": "https://arxiv.org/abs/2409.07275",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2409.07275v2 Announce Type: replace \nAbstract: The performance of the standard Online Robust Principal Component Analysis (OR-PCA) technique depends on the optimum tuning of the explicit regularizers and this tuning is dataset sensitive. We aim to remove the dependency on these tuning parameters by using implicit regularization. We propose to use the implicit regularization effect of various modified gradient descents to make OR-PCA tuning free. Our method incorporates three different versions of modified gradient descent that separately but naturally encourage sparsity and low-rank structures in the data. The proposed method performs comparable or better than the tuned OR-PCA for both simulated and real-world datasets. Tuning-free ORPCA makes it more scalable for large datasets since we do not require dataset-dependent parameter tuning.",
    "source": "arXiv"
  },
  {
    "title": "MPPI-Generic: A CUDA Library for Stochastic Trajectory Optimization",
    "title_es": "MPPI-Generic: A CUDA Library for Stochastic Trajectory Optimization",
    "url": "https://arxiv.org/abs/2409.07563",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2409.07563v3 Announce Type: replace \nAbstract: This paper introduces a new C++/CUDA library for GPU-accelerated stochastic optimization called MPPI-Generic. It provides implementations of Model Predictive Path Integral control, Tube-Model Predictive Path Integral Control, and Robust Model Predictive Path Integral Control, and allows for these algorithms to be used across many pre-existing dynamics models and cost functions. Furthermore, researchers can create their own dynamics models or cost functions following our API definitions without needing to change the actual Model Predictive Path Integral Control code. Finally, we compare computational performance to other popular implementations of Model Predictive Path Integral Control over a variety of GPUs to show the real-time capabilities our library can allow for. Library code can be found at: https://acdslab.github.io/mppi-generic-website/ .",
    "source": "arXiv"
  },
  {
    "title": "MinD-3D++: Advancing fMRI-Based 3D Reconstruction with High-Quality Textured Mesh Generation and a Comprehensive Dataset",
    "title_es": "MinD-3D++: Advancing fMRI-Based 3D Reconstruction with High-Quality Textured Mesh Generation and a Comprehensive Dataset",
    "url": "https://arxiv.org/abs/2409.11315",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2409.11315v3 Announce Type: replace \nAbstract: Reconstructing 3D visuals from functional Magnetic Resonance Imaging (fMRI) data, introduced as Recon3DMind, is of significant interest to both cognitive neuroscience and computer vision. To advance this task, we present the fMRI-3D dataset, which includes data from 15 participants and showcases a total of 4,768 3D objects. The dataset consists of two components: fMRI-Shape, previously introduced and available at https://huggingface.co/datasets/Fudan-fMRI/fMRI-Shape, and fMRI-Objaverse, proposed in this paper and available at https://huggingface.co/datasets/Fudan-fMRI/fMRI-Objaverse. fMRI-Objaverse includes data from 5 subjects, 4 of whom are also part of the core set in fMRI-Shape. Each subject views 3,142 3D objects across 117 categories, all accompanied by text captions. This significantly enhances the diversity and potential applications of the dataset. Moreover, we propose MinD-3D++, a novel framework for decoding textured 3D visual information from fMRI signals. The framework evaluates the feasibility of not only reconstructing 3D objects from the human mind but also generating, for the first time, 3D textured meshes with detailed textures from fMRI data. We establish new benchmarks by designing metrics at the semantic, structural, and textured levels to evaluate model performance. Furthermore, we assess the model's effectiveness in out-of-distribution settings and analyze the attribution of the proposed 3D pari fMRI dataset in visual regions of interest (ROIs) in fMRI signals. Our experiments demonstrate that MinD-3D++ not only reconstructs 3D objects with high semantic and spatial accuracy but also provides deeper insights into how the human brain processes 3D visual information. Project page: https://jianxgao.github.io/MinD-3D.",
    "source": "arXiv"
  },
  {
    "title": "Neural Networks Generalize on Low Complexity Data",
    "title_es": "Neural Networks Generalize on Low Complexity Data",
    "url": "https://arxiv.org/abs/2409.12446",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2409.12446v5 Announce Type: replace \nAbstract: We show that feedforward neural networks with ReLU activation generalize on low complexity data, suitably defined. Given i.i.d.~data generated from a simple programming language, the minimum description length (MDL) feedforward neural network which interpolates the data generalizes with high probability. We define this simple programming language, along with a notion of description length of such networks. We provide several examples on basic computational tasks, such as checking primality of a natural number. For primality testing, our theorem shows the following and more. Suppose that we draw an i.i.d.~sample of $n$ numbers uniformly at random from $1$ to $N$. For each number $x_i$, let $y_i = 1$ if $x_i$ is a prime and $0$ if it is not. Then, the interpolating MDL network accurately answers, with error probability $1- O((\\ln N)/n)$, whether a newly drawn number between $1$ and $N$ is a prime or not. Note that the network is not designed to detect primes; minimum description learning discovers a network which does so. Extensions to noisy data are also discussed, suggesting that MDL neural network interpolators can demonstrate tempered overfitting.",
    "source": "arXiv"
  },
  {
    "title": "Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience",
    "title_es": "Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience",
    "url": "https://arxiv.org/abs/2409.17702",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2409.17702v3 Announce Type: replace \nAbstract: Verbalization of robot experience, i.e., summarization of and question answering about a robot's past, is a crucial ability for improving human-robot interaction. Previous works applied rule-based systems or fine-tuned deep models to verbalize short (several-minute-long) streams of episodic data, limiting generalization and transferability. In our work, we apply large pretrained models to tackle this task with zero or few examples, and specifically focus on verbalizing life-long experiences. For this, we derive a tree-like data structure from episodic memory (EM), with lower levels representing raw perception and proprioception data, and higher levels abstracting events to natural language concepts. Given such a hierarchical representation built from the experience stream, we apply a large language model as an agent to interactively search the EM given a user's query, dynamically expanding (initially collapsed) tree nodes to find the relevant information. The approach keeps computational costs low even when scaling to months of robot experience data. We evaluate our method on simulated household robot data, human egocentric videos, and real-world robot recordings, demonstrating its flexibility and scalability.",
    "source": "arXiv"
  },
  {
    "title": "Diversifying Policy Behaviors with Extrinsic Behavioral Curiosity",
    "title_es": "Diversifying Policy Behaviors with Extrinsic Behavioral Curiosity",
    "url": "https://arxiv.org/abs/2410.06151",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2410.06151v4 Announce Type: replace \nAbstract: Imitation learning (IL) has shown promise in various applications (e.g. robot locomotion) but is often limited to learning a single expert policy, constraining behavior diversity and robustness in unpredictable real-world scenarios. To address this, we introduce Quality Diversity Inverse Reinforcement Learning (QD-IRL), a novel framework that integrates quality-diversity optimization with IRL methods, enabling agents to learn diverse behaviors from limited demonstrations. This work introduces Extrinsic Behavioral Curiosity (EBC), which allows agents to receive additional curiosity rewards from an external critic based on how novel the behaviors are with respect to a large behavioral archive. To validate the effectiveness of EBC in exploring diverse locomotion behaviors, we evaluate our method on multiple robot locomotion tasks. EBC improves the performance of QD-IRL instances with GAIL, VAIL, and DiffAIL across all included environments by up to 185%, 42%, and 150%, even surpassing expert performance by 20% in Humanoid. Furthermore, we demonstrate that EBC is applicable to Gradient-Arborescence-based Quality Diversity Reinforcement Learning (QD-RL) algorithms, where it substantially improves performance and provides a generic technique for learning behavioral-diverse policies. The source code of this work is provided at https://github.com/vanzll/EBC.",
    "source": "arXiv"
  },
  {
    "title": "DiRW: Path-Aware Digraph Learning for Heterophily",
    "title_es": "DiRW: Path-Aware Digraph Learning for Heterophily",
    "url": "https://arxiv.org/abs/2410.10320",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2410.10320v2 Announce Type: replace \nAbstract: Recently, graph neural network (GNN) has emerged as a powerful representation learning tool for graph-structured data. However, most approaches are tailored for undirected graphs, neglecting the abundant information in the edges of directed graphs (digraphs). In fact, digraphs are widely applied in the real world and confirmed to address heterophily challenges. Despite recent advancements, existing spatial- and spectral-based DiGNNs have limitations due to their complex learning mechanisms and reliance on high-quality topology, resulting in low efficiency and unstable performance. To address these issues, we propose Directed Random Walk (DiRW), a plug-and-play strategy for most spatial-based DiGNNs and also an innovative model which offers a new digraph learning paradigm. Specifically, it utilizes a direction-aware path sampler optimized from the perspectives of walk probability, length, and number in a weight-free manner by considering node profiles and topologies. Building upon this, DiRW incorporates a node-wise learnable path aggregator for generalized node representations. Extensive experiments on 9 datasets demonstrate that DiRW: (1) enhances most spatial-based methods as a plug-and-play strategy; (2) achieves SOTA performance as a new digraph learning paradigm. The source code and data are available at https://github.com/dhsiuu/DiRW.",
    "source": "arXiv"
  },
  {
    "title": "HGAurban: Heterogeneous Graph Autoencoding for Urban Spatial-Temporal Learning",
    "title_es": "HGAurban: Heterogeneous Graph Autoencoding for Urban Spatial-Temporal Learning",
    "url": "https://arxiv.org/abs/2410.10915",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2410.10915v2 Announce Type: replace \nAbstract: Spatial-temporal graph representations play a crucial role in urban sensing applications, including traffic analysis, human mobility behavior modeling, and citywide crime prediction. However, a key challenge lies in the noisy and sparse nature of spatial-temporal data, which limits existing neural networks' ability to learn meaningful region representations in the spatial-temporal graph. To overcome these limitations, we propose HGAurban, a novel heterogeneous spatial-temporal graph masked autoencoder that leverages generative self-supervised learning for robust urban data representation. Our framework introduces a spatial-temporal heterogeneous graph encoder that extracts region-wise dependencies from multi-source data, enabling comprehensive modeling of diverse spatial relationships. Within our self-supervised learning paradigm, we implement a masked autoencoder that jointly processes node features and graph structure. This approach automatically learns heterogeneous spatial-temporal patterns across regions, significantly improving the representation of dynamic temporal correlations. Comprehensive experiments across multiple spatiotemporal mining tasks demonstrate that our framework outperforms state-of-the-art methods and robustly handles real-world urban data challenges, including noise and sparsity in both spatial and temporal dimensions.",
    "source": "arXiv"
  },
  {
    "title": "This Candidate is [MASK]. Prompt-based Sentiment Extraction and Reference Letters",
    "title_es": "This Candidate is [MASK]. Prompt-based Sentiment Extraction and Reference Letters",
    "url": "https://arxiv.org/abs/2410.16325",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2410.16325v2 Announce Type: replace \nAbstract: I propose a relatively simple way to deploy pre-trained large language models (LLMs) in order to extract sentiment and other useful features from text data. The method, which I refer to as prompt-based sentiment extraction, offers multiple advantages over other methods used in economics and finance. I apply my prompt-based strategy to a hand-collected corpus of confidential reference letters (RLs). I show that the sentiment contents of RLs is clearly reflected in job market outcomes. Candidates with higher average sentiment in their letters perform markedly better regardless of the measure of success chosen. Moreover, I show that disagreement among letter writers negatively affects the job market candidate's performance. I compare my sentiment extraction approach to other commonly used methods for sentiment analysis: \"bag-of-words\" approaches, fine-tuned language models, and querying advanced chatbots. I find that no other method can reproduce the results obtained by prompt-based sentiment extraction. Finally, I slightly modify the method to obtain \"gendered\" sentiment scores (as in Eberhardt et al., 2023). I show that letters of reference written for female candidates emphasize \"grindstone\" personality traits, whereas male candidates' letters emphasize \"standout\" traits. These gender differences negatively affect women's job market outcomes.",
    "source": "arXiv"
  },
  {
    "title": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need",
    "title_es": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need",
    "url": "https://arxiv.org/abs/2410.18368",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2410.18368v2 Announce Type: replace \nAbstract: Design Space Exploration (DSE) is essential to modern CPU design, yet current frameworks struggle to scale and generalize in high-dimensional architectural spaces. As the dimensionality of design spaces continues to grow, existing DSE frameworks face three fundamental challenges: (1) reduced accuracy and poor scalability of surrogate models in large design spaces; (2) inefficient acquisition guided by hand-crafted heuristics or exhaustive search; (3) limited interpretability, making it hard to pinpoint architectural bottlenecks.\n  In this work, we present \\textbf{AttentionDSE}, the first end-to-end DSE framework that \\emph{natively integrates} performance prediction and design guidance through an attention-based neural architecture. Unlike traditional DSE workflows that separate surrogate modeling from acquisition and rely heavily on hand-crafted heuristics, AttentionDSE establishes a unified, learning-driven optimization loop, in which attention weights serve a dual role: enabling accurate performance estimation and simultaneously exposing the performance bottleneck. This paradigm shift elevates attention from a passive representation mechanism to an active, interpretable driver of design decision-making.\n  Key innovations include: (1) a \\textbf{Perception-Driven Attention} mechanism that exploits architectural hierarchy and locality, scaling attention complexity from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n)$ via sliding windows; (2) an \\textbf{Attention-aware Bottleneck Analysis} that automatically surfaces critical parameters for targeted optimization, eliminating the need for domain-specific heuristics.\n  Evaluated on high-dimensional CPU design space using the SPEC CPU2017 benchmark suite, AttentionDSE achieves up to \\textbf{3.9\\% higher Pareto Hypervolume} and over \\textbf{80\\% reduction in exploration time} compared to state-of-the-art baselines.",
    "source": "arXiv"
  },
  {
    "title": "Federated Time Series Generation on Feature and Temporally Misaligned Data",
    "title_es": "Federated Time Series Generation on Feature and Temporally Misaligned Data",
    "url": "https://arxiv.org/abs/2410.21072",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2410.21072v3 Announce Type: replace \nAbstract: Distributed time series data presents a challenge for federated learning, as clients often possess different feature sets and have misaligned time steps. Existing federated time series models are limited by the assumption of perfect temporal or feature alignment across clients. In this paper, we propose FedTDD, a novel federated time series diffusion model that jointly learns a synthesizer across clients. At the core of FedTDD is a novel data distillation and aggregation framework that reconciles the differences between clients by imputing the misaligned timesteps and features. In contrast to traditional federated learning, FedTDD learns the correlation across clients' time series through the exchange of local synthetic outputs instead of model parameters. A coordinator iteratively improves a global distiller network by leveraging shared knowledge from clients through the exchange of synthetic data. As the distiller becomes more refined over time, it subsequently enhances the quality of the clients' local feature estimates, allowing each client to then improve its local imputations for missing data using the latest, more accurate distiller. Experimental results on five datasets demonstrate FedTDD's effectiveness compared to centralized training, and the effectiveness of sharing synthetic outputs to transfer knowledge of local time series. Notably, FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FID and Correlational scores.",
    "source": "arXiv"
  },
  {
    "title": "Sampling permutations satisfying constraints within the lopsided local lemma regime",
    "title_es": "Sampling permutations satisfying constraints within the lopsided local lemma regime",
    "url": "https://arxiv.org/abs/2411.02750",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.02750v3 Announce Type: replace \nAbstract: Sampling a random permutation with restricted positions, or equivalently approximating the permanent of a 0-1 matrix, is a fundamental problem in computer science, with several notable results achieved over the years. However, existing algorithms typically exhibit high computational complexity. Achieving the optimal running time remains elusive, even for nontrivial subsets of the problem. Furthermore, existing algorithms primarily focus on a single permutation, leaving many combinatorial problems involving multiple constrained permutations unaddressed.\n  For a single permutation, we achieve the optimal running time $O(n^2)$ for approximating the permanent of a very dense $n \\times n$ 0-1 matrix, where each row and column contains at most $\\sqrt{(n-2)/20}$ zeros. This result serves as a fundamental building block in our sampling algorithm for multiple permutations.\n  We further introduce a general model called permutations with disjunctive constraints (PDC) for handling multiple constrained permutations. We propose a novel Markov chain-based algorithm for sampling nearly uniform solutions of PDC within a lopsided Lov\\'asz Local Lemma (LLL) regime. For uniform PDC formulas, where all constraints are of the same width and all permutations are of the same size, our algorithm runs in nearly linear time with respect to the number of variables.\n  Previous approaches for sampling LLL relied on the variable model. In contrast, the sampling problem of PDC encounters a fundamental challenge: the random variables within each permutation in the joint probability space are not mutually independent, leading to long-range correlations. To tackle this challenge, we introduce a novel sampling framework called correlated factorization and a new concept in the path coupling analysis, termed the inactive vertex.",
    "source": "arXiv"
  },
  {
    "title": "A Random-Key Optimizer for Combinatorial Optimization",
    "title_es": "A Random-Key Optimizer for Combinatorial Optimization",
    "url": "https://arxiv.org/abs/2411.04293",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.04293v3 Announce Type: replace \nAbstract: This paper introduces the Random-Key Optimizer (RKO), a versatile and efficient stochastic local search method tailored for combinatorial optimization problems. Using the random-key concept, RKO encodes solutions as vectors of random keys that are subsequently decoded into feasible solutions via problem-specific decoders. The RKO framework is able to combine a plethora of classic metaheuristics, each capable of operating independently or in parallel, with solution sharing facilitated through an elite solution pool. This modular approach allows for the adaptation of various metaheuristics, including simulated annealing, iterated local search, and greedy randomized adaptive search procedures, among others. The efficacy of the RKO framework, implemented in C++ and publicly available (Github public repository: github.com/RKO-solver), is demonstrated through its application to three NP-hard combinatorial optimization problems: the alpha-neighborhood p-median problem, the tree of hubs location problem, and the node-capacitated graph partitioning problem. The results highlight the framework's ability to produce high-quality solutions across diverse problem domains, underscoring its potential as a robust tool for combinatorial optimization.",
    "source": "arXiv"
  },
  {
    "title": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models",
    "title_es": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2411.06869",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.06869v2 Announce Type: replace \nAbstract: Category-agnostic pose estimation (CAPE) has traditionally relied on support images with annotated keypoints, a process that is often cumbersome and may fail to fully capture the necessary correspondences across diverse object categories. Recent efforts have explored the use of text queries, leveraging their enhanced stability and generalization capabilities. However, existing approaches often remain constrained by their reliance on support queries, their failure to fully utilize the rich priors embedded in pre-trained large language models, and the limitations imposed by their parametric distribution assumptions. To address these challenges, we introduce CapeLLM, the first multimodal large language model (MLLM) designed for CAPE. Our method only employs query image and detailed text descriptions as an input to estimate category-agnostic keypoints. Our method encompasses effective training strategies and carefully designed instructions for applying the MLLM to CAPE. Moreover, we propose an inference mechanism that further enhances the reasoning process for unseen keypoints. while flexibly modeling their underlying spatial distribution and uncertainty, allowing for adaptive refinement based on contextual cues. We conducted extensive experiments to apply the MLLM to CAPE effectively, focusing not only on the model architecture and prompt design but also on ensuring robustness across input variations. Our approach sets a new state-of-the-art on the MP-100 benchmark in the 1-shot and even 5-shot setting, marking a significant advancement in the field of category-agnostic pose estimation. Code is available at https://github.com/Junhojuno/CapeLLM.",
    "source": "arXiv"
  },
  {
    "title": "RINO: Accurate, Robust Radar-Inertial Odometry with Non-Iterative Estimation",
    "title_es": "RINO: Accurate, Robust Radar-Inertial Odometry with Non-Iterative Estimation",
    "url": "https://arxiv.org/abs/2411.07699",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.07699v4 Announce Type: replace \nAbstract: Odometry in adverse weather conditions, such as fog, rain, and snow, presents significant challenges, as traditional vision and LiDAR-based methods often suffer from degraded performance. Radar-Inertial Odometry (RIO) has emerged as a promising solution due to its resilience in such environments. In this paper, we present RINO, a non-iterative RIO framework implemented in an adaptively loosely coupled manner. Building upon ORORA as the baseline for radar odometry, RINO introduces several key advancements, including improvements in keypoint extraction, motion distortion compensation, and pose estimation via an adaptive voting mechanism. This voting strategy facilitates efficient polynomial-time optimization while simultaneously quantifying the uncertainty in the radar module's pose estimation. The estimated uncertainty is subsequently integrated into the maximum a posteriori (MAP) estimation within a Kalman filter framework. Unlike prior loosely coupled odometry systems, RINO not only retains the global and robust registration capabilities of the radar component but also dynamically accounts for the real-time operational state of each sensor during fusion. Experimental results conducted on publicly available datasets demonstrate that RINO reduces translation and rotation errors by 1.06% and 0.09{\\deg}/100m, respectively, when compared to the baseline method, thus significantly enhancing its accuracy. Furthermore, RINO achieves performance comparable to state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training",
    "title_es": "FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training",
    "url": "https://arxiv.org/abs/2411.07837",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.07837v3 Announce Type: replace \nAbstract: With the increase in the number of parameters in large language models, the process of pre-training and fine-tuning increasingly demands larger volumes of GPU memory. A significant portion of this memory is typically consumed by the optimizer state. To overcome this challenge, recent approaches such as low-rank adaptation (LoRA (Hu et al., 2021)), low-rank gradient projection (GaLore (Zhao et al., 2024)), and blockwise optimization (BAdam (Luo et al., 2024)) have been proposed. However, in all these algorithms, the $\\textit{effective rank of the weight updates remains low-rank}$, which can lead to a substantial loss of information from the gradient. This loss can be critically important, especially during the pre-training stage. In this paper, we introduce $\\texttt{FRUGAL}$ ($\\textbf{F}$ull-$\\textbf{R}$ank $\\textbf{U}$pdates with $\\textbf{G}$r$\\textbf{A}$dient sp$\\textbf{L}$itting), a new memory-efficient optimization framework. $\\texttt{FRUGAL}$ leverages gradient splitting to perform low-dimensional updates using advanced algorithms (such as Adam), while updates along the remaining directions are executed via state-free methods like SGD or signSGD (Bernstein et al., 2018). Our framework can be integrated with various low-rank update selection techniques, including GaLore and BAdam. We provide theoretical convergence guarantees for our framework when using SGDM for low-dimensional updates and SGD for state-free updates. Additionally, our method consistently outperforms concurrent approaches across various fixed memory budgets, achieving state-of-the-art results in pre-training and fine-tuning tasks while balancing memory efficiency and performance metrics.",
    "source": "arXiv"
  },
  {
    "title": "Combining Machine Learning Defenses without Conflicts",
    "title_es": "Combining Machine Learning Defenses without Conflicts",
    "url": "https://arxiv.org/abs/2411.09776",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.09776v2 Announce Type: replace \nAbstract: Machine learning (ML) defenses protect against various risks to security, privacy, and fairness. Real-life models need simultaneous protection against multiple different risks which necessitates combining multiple defenses. But combining defenses with conflicting interactions in an ML model can be ineffective, incurring a significant drop in the effectiveness of one or more defenses being combined. Practitioners need a way to determine if a given combination can be effective. Experimentally identifying effective combinations can be time-consuming and expensive, particularly when multiple defenses need to be combined. We need an inexpensive, easy-to-use combination technique to identify effective combinations. Ideally, a combination technique should be (a) accurate (correctly identifies whether a combination is effective or not), (b) scalable (allows combining multiple defenses), (c) non-invasive (requires no change to the defenses being combined), and (d) general (is applicable to different types of defenses). Prior works have identified several ad-hoc techniques but none satisfy all the requirements above. We propose a principled combination technique, Def\\Con, to identify effective defense combinations. Def\\Con meets all requirements, achieving 90% accuracy on eight combinations explored in prior work and 81% in 30 previously unexplored combinations that we empirically evaluate in this paper.",
    "source": "arXiv"
  },
  {
    "title": "Unified Performance Control for Non-Square Nonlinear Systems with Relaxed Controllability",
    "title_es": "Unified Performance Control for Non-Square Nonlinear Systems with Relaxed Controllability",
    "url": "https://arxiv.org/abs/2411.13252",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.13252v2 Announce Type: replace \nAbstract: In this paper, we investigate the problem of unified prescribed performance tracking for a class of non-square strict-feedback nonlinear systems under relaxed controllability conditions. By using a skillful matrix decomposition and introducing some feasible auxiliary matrices, a more generalized controllability condition than the current state of the art is constructed, which can be applied to both square and non-square nonlinear systems subject to actuator faults and unknown yet time-varying control gain. Incorporating the relaxed controllability conditions and the uniform performance specifications into the backstepping design procedure, a prescribed performance fault-tolerant controller is developed that can achieve different performance demands without modifying the controller structure, which is more flexible and practical.In addition, the destruction of the system stability by unknown controllability auxiliary matrices and unknown nonlinearities is circumvented by embedding the available core information of the state-dependent uncertainties into the design procedure. Both theoretical analysis and numerical simulation demonstrate the effectiveness and benefits of the proposed method.",
    "source": "arXiv"
  },
  {
    "title": "Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain Understanding",
    "title_es": "Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain Understanding",
    "url": "https://arxiv.org/abs/2411.13378",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.13378v2 Announce Type: replace \nAbstract: Vision-brain understanding aims to extract semantic information about brain signals from human perceptions. Existing deep learning methods for vision-brain understanding are usually introduced in a traditional learning paradigm missing the ability to learn the connectivities between brain regions. Meanwhile, the quantum computing theory offers a new paradigm for designing deep learning models. Motivated by the connectivities in the brain signals and the entanglement properties in quantum computing, we propose a novel Quantum-Brain approach, a quantum-inspired neural network, to tackle the vision-brain understanding problem. To compute the connectivity between areas in brain signals, we introduce a new Quantum-Inspired Voxel-Controlling module to learn the impact of a brain voxel on others represented in the Hilbert space. To effectively learn connectivity, a novel Phase-Shifting module is presented to calibrate the value of the brain signals. Finally, we introduce a new Measurement-like Projection module to present the connectivity information from the Hilbert space into the feature space. The proposed approach can learn to find the connectivities between fMRI voxels and enhance the semantic information obtained from human perceptions. Our experimental results on the Natural Scene Dataset benchmarks illustrate the effectiveness of the proposed method with Top-1 accuracies of 95.1% and 95.6% on image and brain retrieval tasks and an Inception score of 95.3% on fMRI-to-image reconstruction task. Our proposed quantum-inspired network brings a potential paradigm to solving the vision-brain problems via the quantum computing theory.",
    "source": "arXiv"
  },
  {
    "title": "MyTimeMachine: Personalized Facial Age Transformation",
    "title_es": "MyTimeMachine: Personalized Facial Age Transformation",
    "url": "https://arxiv.org/abs/2411.14521",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.14521v2 Announce Type: replace \nAbstract: Facial aging is a complex process, highly dependent on multiple factors like gender, ethnicity, lifestyle, etc., making it extremely challenging to learn a global aging prior to predict aging for any individual accurately. Existing techniques often produce realistic and plausible aging results, but the re-aged images often do not resemble the person's appearance at the target age and thus need personalization. In many practical applications of virtual aging, e.g. VFX in movies and TV shows, access to a personal photo collection of the user depicting aging in a small time interval (20$\\sim$40 years) is often available. However, naive attempts to personalize global aging techniques on personal photo collections often fail. Thus, we propose MyTimeMachine (MyTM), which combines a global aging prior with a personal photo collection (using as few as 50 images) to learn a personalized age transformation. We introduce a novel Adapter Network that combines personalized aging features with global aging features and generates a re-aged image with StyleGAN2. We also introduce three loss functions to personalize the Adapter Network with personalized aging loss, extrapolation regularization, and adaptive w-norm regularization. Our approach can also be extended to videos, achieving high-quality, identity-preserving, and temporally consistent aging effects that resemble actual appearances at target ages, demonstrating its superiority over state-of-the-art approaches.",
    "source": "arXiv"
  },
  {
    "title": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models",
    "title_es": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models",
    "url": "https://arxiv.org/abs/2411.15913",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.15913v2 Announce Type: replace \nAbstract: Music style transfer enables personalized music creation by combining the structure of one piece with the stylistic characteristics of another. While recent approaches have explored text-conditioned generation and diffusion-based synthesis, most require extensive training, paired datasets, or detailed textual annotations. In this work, we introduce Stylus, a novel training-free framework for music style transfer that directly manipulates the self-attention layers of a pre-trained Latent Diffusion Model (LDM). Operating in the mel-spectrogram domain, Stylus transfers musical style by replacing key and value representations from the content audio with those of the style reference, without any fine-tuning. To enhance stylization quality and controllability, we further incorporate query preservation, CFG-inspired guidance scaling, multi-style interpolation, and phase-preserving reconstruction. Our method significantly improves perceptual quality and structural preservation compared to prior work, while remaining lightweight and easy to deploy. This work highlights the potential of diffusion-based attention manipulation for efficient, high-fidelity, and interpretable music generation-without training. Codes will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "Visual SLAMMOT Considering Multiple Motion Models",
    "title_es": "Visual SLAMMOT Considering Multiple Motion Models",
    "url": "https://arxiv.org/abs/2411.19134",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.19134v2 Announce Type: replace \nAbstract: Simultaneous Localization and Mapping (SLAM) and Multi-Object Tracking (MOT) are pivotal tasks in the realm of autonomous driving, attracting considerable research attention. While SLAM endeavors to generate real-time maps and determine the vehicle's pose in unfamiliar settings, MOT focuses on the real-time identification and tracking of multiple dynamic objects. Despite their importance, the prevalent approach treats SLAM and MOT as independent modules within an autonomous vehicle system, leading to inherent limitations. Classical SLAM methodologies often rely on a static environment assumption, suitable for indoor rather than dynamic outdoor scenarios. Conversely, conventional MOT techniques typically rely on the vehicle's known state, constraining the accuracy of object state estimations based on this prior. To address these challenges, previous efforts introduced the unified SLAMMOT paradigm, yet primarily focused on simplistic motion patterns. In our team's previous work IMM-SLAMMOT\\cite{IMM-SLAMMOT}, we present a novel methodology incorporating consideration of multiple motion models into SLAMMOT i.e. tightly coupled SLAM and MOT, demonstrating its efficacy in LiDAR-based systems. This paper studies feasibility and advantages of instantiating this methodology as visual SLAMMOT, bridging the gap between LiDAR and vision-based sensing mechanisms. Specifically, we propose a solution of visual SLAMMOT considering multiple motion models and validate the inherent advantages of IMM-SLAMMOT in the visual domain.",
    "source": "arXiv"
  },
  {
    "title": "Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives",
    "title_es": "Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives",
    "url": "https://arxiv.org/abs/2412.00578",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.00578v3 Announce Type: replace \nAbstract: 3D Gaussian Splatting (3D-GS) is a recent 3D scene reconstruction technique that enables real-time rendering of novel views by modeling scenes as parametric point clouds of differentiable 3D Gaussians. However, its rendering speed and model size still present bottlenecks, especially in resource-constrained settings. In this paper, we identify and address two key inefficiencies in 3D-GS to substantially improve rendering speed. These improvements also yield the ancillary benefits of reduced model size and training time. First, we optimize the rendering pipeline to precisely localize Gaussians in the scene, boosting rendering speed without altering visual fidelity. Second, we introduce a novel pruning technique and integrate it into the training pipeline, significantly reducing model size and training time while further raising rendering speed. Our Speedy-Splat approach combines these techniques to accelerate average rendering speed by a drastic $\\mathit{6.71\\times}$ across scenes from the Mip-NeRF 360, Tanks & Temples, and Deep Blending datasets.",
    "source": "arXiv"
  },
  {
    "title": "Improving Viewpoint Consistency in 3D Generation via Structure Feature and CLIP Guidance",
    "title_es": "Improving Viewpoint Consistency in 3D Generation via Structure Feature and CLIP Guidance",
    "url": "https://arxiv.org/abs/2412.02287",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.02287v4 Announce Type: replace \nAbstract: Despite recent advances in text-to-3D generation techniques, current methods often suffer from geometric inconsistencies, commonly referred to as the Janus Problem. This paper identifies the root cause of the Janus Problem: viewpoint generation bias in diffusion models, which creates a significant gap between the actual generated viewpoint and the expected one required for optimizing the 3D model. To address this issue, we propose a tuning-free approach called the Attention and CLIP Guidance (ACG) mechanism. ACG enhances desired viewpoints by adaptively controlling cross-attention maps, employs CLIP-based view-text similarities to filter out erroneous viewpoints, and uses a coarse-to-fine optimization strategy with staged prompts to progressively refine 3D generation. Extensive experiments demonstrate that our method significantly reduces the Janus Problem without compromising generation speed, establishing ACG as an efficient, plug-and-play component for existing text-to-3D frameworks.",
    "source": "arXiv"
  },
  {
    "title": "DGNS: Deformable Gaussian Splatting and Dynamic Neural Surface for Monocular Dynamic 3D Reconstruction",
    "title_es": "DGNS: Deformable Gaussian Splatting and Dynamic Neural Surface for Monocular Dynamic 3D Reconstruction",
    "url": "https://arxiv.org/abs/2412.03910",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.03910v3 Announce Type: replace \nAbstract: Dynamic scene reconstruction from monocular video is essential for real-world applications. We introduce DGNS, a hybrid framework integrating \\underline{D}eformable \\underline{G}aussian Splatting and Dynamic \\underline{N}eural \\underline{S}urfaces, effectively addressing dynamic novel-view synthesis and 3D geometry reconstruction simultaneously. During training, depth maps generated by the deformable Gaussian splatting module guide the ray sampling for faster processing and provide depth supervision within the dynamic neural surface module to improve geometry reconstruction. Conversely, the dynamic neural surface directs the distribution of Gaussian primitives around the surface, enhancing rendering quality. In addition, we propose a depth-filtering approach to further refine depth supervision. Extensive experiments conducted on public datasets demonstrate that DGNS achieves state-of-the-art performance in 3D reconstruction, along with competitive results in novel-view synthesis.",
    "source": "arXiv"
  },
  {
    "title": "DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction",
    "title_es": "DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction",
    "url": "https://arxiv.org/abs/2412.04464",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.04464v5 Announce Type: replace \nAbstract: The choice of data representation is a key factor in the success of deep learning in geometric tasks. For instance, DUSt3R recently introduced the concept of viewpoint-invariant point maps, generalizing depth prediction and showing that all key problems in the 3D reconstruction of static scenes can be reduced to predicting such point maps. In this paper, we develop an analogous concept for a very different problem: the reconstruction of the 3D shape and pose of deformable objects. To this end, we introduce Dual Point Maps (DualPM), where a pair of point maps is extracted from the same image-one associating pixels to their 3D locations on the object and the other to a canonical version of the object in its rest pose. We also extend point maps to amodal reconstruction to recover the complete shape of the object, even through self-occlusions. We show that 3D reconstruction and 3D pose estimation can be reduced to the prediction of DualPMs. Empirically, we demonstrate that this representation is a suitable target for deep networks to predict. Specifically, we focus on modeling quadrupeds, showing that DualPMs can be trained purely on synthetic 3D data, consisting of one or two models per category, while generalizing effectively to real images. With this approach, we achieve significant improvements over previous methods for the 3D analysis and reconstruction of such objects.",
    "source": "arXiv"
  },
  {
    "title": "PAC codes with Bounded-Complexity Sequential Decoding: Pareto Distribution and Code Design",
    "title_es": "PAC codes with Bounded-Complexity Sequential Decoding: Pareto Distribution and Code Design",
    "url": "https://arxiv.org/abs/2412.06072",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.06072v2 Announce Type: replace \nAbstract: Recently, a novel variation of polar codes known as polarization-adjusted convolutional (PAC) codes has been introduced by Ar{\\i}kan. These codes significantly outperform conventional polar and convolutional codes, particularly for short codeword lengths, and are shown to operate very close to the optimal bounds. It has also been shown that if the rate profile of PAC codes does not adhere to certain polarized cutoff rate constraints, the computation complexity for their sequential decoding grows exponentially. In this paper, we address the converse problem, demonstrating that if the rate profile of a PAC code follows the polarized cutoff rate constraints, the required computations for its sequential decoding can be bounded with a distribution that follows a Pareto distribution. This serves as a guideline for the rate-profile design of PAC codes. For a high-rate PAC\\,$(1024,899)$ code, simulation results show that the PAC code with Fano decoder, when constructed based on the polarized cutoff rate constraints, achieves a coding gain of more than $0.75$ dB at a frame error rate (FER) of $10^{-5}$ compared to the state-of-the-art 5G polar and LDPC codes.",
    "source": "arXiv"
  },
  {
    "title": "Mastering Collaborative Multi-modal Data Selection: A Focus on Informativeness, Uniqueness, and Representativeness",
    "title_es": "Mastering Collaborative Multi-modal Data Selection: A Focus on Informativeness, Uniqueness, and Representativeness",
    "url": "https://arxiv.org/abs/2412.06293",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.06293v2 Announce Type: replace \nAbstract: Instruction tuning fine-tunes pre-trained Multi-modal Large Language Models (MLLMs) to handle real-world tasks. However, the rapid expansion of visual instruction datasets introduces data redundancy, leading to excessive computational costs. We propose a collaborative framework, DataTailor, which leverages three key principles--informativeness, uniqueness, and representativeness--for effective data selection. We argue that a valuable sample should be informative of the task, non-redundant, and represent the sample distribution (i.e., not an outlier). We further propose practical ways to score against each principle, which automatically adapts to a given dataset without tedious hyperparameter tuning. Comprehensive experiments on various benchmarks demonstrate that DataTailor achieves 101.3% of the performance of full-data fine-tuning with only 15% of the data, significantly reducing computational costs while maintaining superior results. This exemplifies the \"Less is More\" philosophy in MLLM development. The code and data is available in this \\href{https://github.com/Yuqifan1117/DataTailor}{URL}.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Transformer-based Vision Models through Inversion",
    "title_es": "Understanding Transformer-based Vision Models through Inversion",
    "url": "https://arxiv.org/abs/2412.06534",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.06534v4 Announce Type: replace \nAbstract: Understanding the mechanisms underlying deep neural networks remains a fundamental challenge in machine learning and computer vision. One promising, yet only preliminarily explored approach, is feature inversion, which attempts to reconstruct images from intermediate representations using trained inverse neural networks. In this study, we revisit feature inversion, introducing a novel, modular variation that enables significantly more efficient application of the technique. We demonstrate how our method can be systematically applied to the large-scale transformer-based vision models, Detection Transformer and Vision Transformer, and how reconstructed images can be qualitatively interpreted in a meaningful way. We further quantitatively evaluate our method, thereby uncovering underlying mechanisms of representing image features that emerge in the two transformer architectures. Our analysis reveals key insights into how these models encode contextual shape and image details, how their layers correlate, and their robustness against color perturbations. These findings contribute to a deeper understanding of transformer-based vision models and their internal representations. The code for reproducing our experiments is available at github.com/wiskott-lab/inverse-tvm.",
    "source": "arXiv"
  },
  {
    "title": "Finite element discretization of weighted $\\Phi$-Laplace problems",
    "title_es": "Finite element discretization of weighted $\\Phi$-Laplace problems",
    "url": "https://arxiv.org/abs/2412.10327",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.10327v2 Announce Type: replace \nAbstract: We study the finite element approximation of problems involving the weighted $\\Phi$-Laplacian, where $\\Phi$ is an $N$-function and the weight belongs to the class $A_\\Phi$. In particular, we consider a boundary value problem and an obstacle problem and derive error estimates in both cases. The analysis is based on the language of weighted Orlicz and weighted Orlicz--Sobolev spaces.",
    "source": "arXiv"
  },
  {
    "title": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication",
    "title_es": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication",
    "url": "https://arxiv.org/abs/2412.19160",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.19160v3 Announce Type: replace \nAbstract: Traditional biometric systems have encountered significant setbacks due to various unavoidable factors, for example, wearing of face masks in face recognition-based biometrics and hygiene concerns in fingerprint-based biometrics. This paper proposes a novel lightweight vision transformer with phase-only cross-attention (POC-ViT) using dual biometric traits of forehead and periocular portions of the face, capable of performing well even with face masks and without any physical touch, offering a promising alternative to traditional methods. The POC-ViT framework is designed to handle two biometric traits and to capture inter-dependencies in terms of relative structural patterns. Each channel consists of a Cross-Attention using phase-only correlation (POC) that captures both their individual and correlated structural patterns. The computation of cross-attention using POC extracts the phase correlation in the spatial features. Therefore, it is robust against variations in resolution and intensity, as well as illumination changes in the input images. The lightweight model is suitable for edge device deployment. The performance of the proposed framework was successfully demonstrated using the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern (FSVP-PBP) database, having 350 subjects. The POC-ViT framework outperformed state-of-the-art methods with an outstanding classification accuracy of $98.8\\%$ with the dual biometric traits.",
    "source": "arXiv"
  },
  {
    "title": "Motion Planning Diffusion: Learning and Adapting Robot Motion Planning with Diffusion Models",
    "title_es": "Motion Planning Diffusion: Learning and Adapting Robot Motion Planning with Diffusion Models",
    "url": "https://arxiv.org/abs/2412.19948",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.19948v3 Announce Type: replace \nAbstract: The performance of optimization-based robot motion planning algorithms is highly dependent on the initial solutions, commonly obtained by running a sampling-based planner to obtain a collision-free path. However, these methods can be slow in high-dimensional and complex scenes and produce non-smooth solutions. Given previously solved path-planning problems, it is highly desirable to learn their distribution and use it as a prior for new similar problems. Several works propose utilizing this prior to bootstrap the motion planning problem, either by sampling initial solutions from it, or using its distribution in a maximum-a-posterior formulation for trajectory optimization. In this work, we introduce Motion Planning Diffusion (MPD), an algorithm that learns trajectory distribution priors with diffusion models. These generative models have shown increasing success in encoding multimodal data and have desirable properties for gradient-based motion planning, such as cost guidance. Given a motion planning problem, we construct a cost function and sample from the posterior distribution using the learned prior combined with the cost function gradients during the denoising process. Instead of learning the prior on all trajectory waypoints, we propose learning a lower-dimensional representation of a trajectory using linear motion primitives, particularly B-spline curves. This parametrization guarantees that the generated trajectory is smooth, can be interpolated at higher frequencies, and needs fewer parameters than a dense waypoint representation. We demonstrate the results of our method ranging from simple 2D to more complex tasks using a 7-dof robot arm manipulator. In addition to learning from simulated data, we also use human demonstrations on a real-world pick-and-place task.",
    "source": "arXiv"
  },
  {
    "title": "AI Across Borders: Exploring Perceptions and Interactions in Higher Education",
    "title_es": "AI Across Borders: Exploring Perceptions and Interactions in Higher Education",
    "url": "https://arxiv.org/abs/2501.00017",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.00017v2 Announce Type: replace \nAbstract: This study investigates students' perceptions of Generative Artificial Intelligence (GenAI), with a focus on Higher Education institutions in Northern Ireland and India. We collect quantitative Likert ratings and qualitative comments from 1211 students on their awareness and perceptions of AI and investigate variations in attitudes toward AI across institutions and subject areas, as well as interactions between these variables with demographic variables (focusing on gender). We found the following: (a) while perceptions varied across institutions, responses for Computer Sciences students were similar, both in terms of topics and degree of positivity; and (b) after controlling for institution and subject area, we observed no effect of gender. These results are consistent with previous studies, which find that students' perceptions are predicted by prior experience; crucially, however, the results of this study contribute to the literature by identifying important interactions between key factors that can influence experience, revealing a more nuanced picture of students' perceptions and the role of experience. We consider the implications of these relations, and further considerations for the role of experience.",
    "source": "arXiv"
  },
  {
    "title": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations",
    "title_es": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations",
    "url": "https://arxiv.org/abs/2501.02409",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.02409v3 Announce Type: replace \nAbstract: Modern high-throughput biological datasets with thousands of perturbations provide the opportunity for large-scale discovery of causal graphs that represent the regulatory interactions between genes. Differentiable causal graphical models have been proposed to infer a gene regulatory network (GRN) from large scale interventional datasets, capturing the causal gene regulatory relationships from genetic perturbations. However, existing models are limited in their expressivity and scalability while failing to address the dynamic nature of biological processes such as cellular differentiation. We propose PerturbODE, a novel framework that incorporates biologically informative neural ordinary differential equations (neural ODEs) to model cell state trajectories under perturbations and derive the causal GRN from the neural ODE's parameters. We demonstrate PerturbODE's efficacy in trajectory prediction and GRN inference across simulated and real over-expression datasets.",
    "source": "arXiv"
  },
  {
    "title": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding",
    "title_es": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding",
    "url": "https://arxiv.org/abs/2501.06117",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.06117v3 Announce Type: replace \nAbstract: Spoken language understanding (SLU) is indispensable for half of all living languages that lack a formal writing system. Unlike for high-resource languages, for these languages, we cannot offload semantic understanding of speech to the cascade of automatic speech recognition (ASR) and text-based large language models (LLMs). Even if low-resource languages possess a writing system, ASR for these languages remains unreliable due to limited bimodal speech and text training data. Nonetheless, the evaluation of multilingual SLU is limited to shallow tasks such as intent classification or language identification. This is why we present Fleurs-SLU, a multilingual SLU benchmark that encompasses (i) 692 hours of speech for topical utterance classification in 102 languages and (ii) multiple-choice question answering via listening comprehension spanning 944 hours of speech across 92 languages. We extensively evaluate end-to-end speech classification models, cascaded systems that combine speech-to-text transcription with subsequent LLM-based classification, and multimodal speech-LLMs on Fleurs-SLU. Our results show that cascaded systems are more robust in multilingual SLU, though well-pretrained speech encoders can perform competitively in topical speech classification. Closed-source speech-LLMs match or surpass the performance of cascaded systems. We observe a strong correlation between robust multilingual ASR, effective speech-to-text translation, and strong multilingual SLU, indicating mutual benefits between acoustic and semantic speech representations.",
    "source": "arXiv"
  },
  {
    "title": "Double reflections Assisted RIS Deployment and Energy-efficient Group Selection in mmWaves D2D Communication",
    "title_es": "Double reflections Assisted RIS Deployment and Energy-efficient Group Selection in mmWaves D2D Communication",
    "url": "https://arxiv.org/abs/2501.08599",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.08599v2 Announce Type: replace \nAbstract: Reconfigurable intelligent surfaces (RISs) offer a viable way to improve the performance of multi-hop device-to-device (D2D) communication. However, due to the substantial propagation and penetration losses of the millimeter waves (mmWaves), a direct line of sight (LoS) link and close proximity of a device pair are required for a high data rate. Static obstacles like trees and buildings can easily impede the direct LoS connectivity between a device pair. Hence, RIS placement plays a crucial role in establishing an indirect LoS link between them. Therefore, in this work, we propose a set cover-based RIS deployment strategy for both single and double RIS-assisted D2D communication. In particular, we have demonstrated that permitting reflections via two consecutive RISs can greatly lower the RIS density in the environment, preventing resource waste and enabling the service of more obstructed device pairs. After the RIS deployment, for information transfer, we also propose an energy-efficient group selection criteria. Moreover, we prove that sometimes double reflections are more beneficial than single reflection, which is counter-intuitive. Numerical results show that our approach outperforms a random and a recent deployment strategy.",
    "source": "arXiv"
  },
  {
    "title": "Characterization of GPU TEE Overheads in Distributed Data Parallel ML Training",
    "title_es": "Characterization of GPU TEE Overheads in Distributed Data Parallel ML Training",
    "url": "https://arxiv.org/abs/2501.11771",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.11771v3 Announce Type: replace \nAbstract: Confidential computing (CC) or trusted execution enclaves (TEEs) is now the most common approach to enable secure computing in the cloud. The recent introduction of GPU TEEs by NVIDIA enables machine learning (ML) models to be trained without leaking model weights or data to the cloud provider. However, the potential performance implications of using GPU TEEs for ML training are not well characterized. In this work, we present an in-depth characterization study on performance overhead associated with running distributed data parallel (DDP) ML training with GPU Trusted Execution Environments (TEE).\n  Our study reveals the performance challenges in DDP training within GPU TEEs. DDP uses ring-all-reduce, a well-known approach, to aggregate gradients from multiple devices. Ring all-reduce consists of multiple scatter-reduce and all-gather operations. In GPU TEEs only the GPU package (GPU and HBM memory) is trusted. Hence, any data communicated outside the GPU packages must be encrypted and authenticated for confidentiality and integrity verification. Hence, each phase of the ring-all-reduce requires encryption and message authentication code (MAC) generation from the sender, and decryption and MAC authentication on the receiver. As the number of GPUs participating in DDP increases, the overhead of secure inter-GPU communication during ring-all-reduce grows proportionally. Additionally, larger models lead to more asynchronous all-reduce operations, exacerbating the communication cost. Our results show that with four GPU TEEs, depending on the model that is being trained, the runtime per training iteration increases by an average of 8x and up to a maximum of 41.6x compared to DDP training without TEE.",
    "source": "arXiv"
  },
  {
    "title": "Nautilus: Locality-aware Autoencoder for Scalable Mesh Generation",
    "title_es": "Nautilus: Locality-aware Autoencoder for Scalable Mesh Generation",
    "url": "https://arxiv.org/abs/2501.14317",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.14317v5 Announce Type: replace \nAbstract: Triangle meshes are fundamental to 3D applications, enabling efficient modification and rasterization while maintaining compatibility with standard rendering pipelines. However, current automatic mesh generation methods typically rely on intermediate representations that lack the continuous surface quality inherent to meshes. Converting these representations into meshes produces dense, suboptimal outputs. Although recent autoregressive approaches demonstrate promise in directly modeling mesh vertices and faces, they are constrained by the limitation in face count, scalability, and structural fidelity. To address these challenges, we propose Nautilus, a locality-aware autoencoder for artist-like mesh generation that leverages the local properties of manifold meshes to achieve structural fidelity and efficient representation. Our approach introduces a novel tokenization algorithm that preserves face proximity relationships and compresses sequence length through locally shared vertices and edges, enabling the generation of meshes with an unprecedented scale of up to 5,000 faces. Furthermore, we develop a Dual-stream Point Conditioner that provides multi-scale geometric guidance, ensuring global consistency and local structural fidelity by capturing fine-grained geometric features. Extensive experiments demonstrate that Nautilus significantly outperforms state-of-the-art methods in both fidelity and scalability. The project page is at https://nautilusmeshgen.github.io.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision",
    "title_es": "Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision",
    "url": "https://arxiv.org/abs/2501.15119",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.15119v2 Announce Type: replace \nAbstract: Existing computer vision processing pipeline acquires visual information using an image sensor that captures pixel information in the Bayer pattern. The raw sensor data are then processed using an image signal processor (ISP) that first converts Bayer pixel data to RGB on a pixel by pixel basis, followed by video convolutional network (VCN) processing on a frame by frame basis. Both ISP and VCN are computationally expensive with high power consumption and latency. In this paper, we propose a novel framework that eliminates the ISP and leverages motion estimation to accelerate video vision tasks directly in the Bayer domain. We introduce Motion Estimation-based Video Convolution (MEVC), which integrates sliding-window motion estimation into each convolutional layer, enabling prediction and residual-based refinement that reduces redundant computations across frames. This design bridges the structural gap between block-based motion estimation and spatial convolution, enabling accurate, low-cost processing. Our end-to-end pipeline supports raw Bayer input and achieves over 70\\% reduction in FLOPs with minimal accuracy degradation across video semantic segmentation, depth estimation, and object detection benchmarks, using both synthetic Bayer-converted and real Bayer video datasets. This framework generalizes across convolution-based models and marks the first effective reuse of motion estimation for accelerating video computer vision directly from raw sensor data.",
    "source": "arXiv"
  },
  {
    "title": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization",
    "title_es": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization",
    "url": "https://arxiv.org/abs/2501.18475",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.18475v2 Announce Type: replace \nAbstract: Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) has become a highly efficient approach for downstream tasks, particularly in scenarios with limited computational resources. However, applying LoRA techniques to quantized LLMs poses unique challenges due to the reduced representational precision of quantized weights. In this paper, we introduce CLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplistic initialization strategy designed to overcome these challenges. Our approach focuses on minimizing the layer-wise discrepancy between the original LLM and its quantized counterpart with LoRA components during initialization. By leveraging a small calibration dataset, CLoQ quantizes a pre-trained LLM and determines the optimal LoRA components for each layer, ensuring a strong foundation for subsequent fine-tuning. A key contribution of this work is a novel theoretical result that enables the accurate and closed-form construction of these optimal LoRA components. We validate the efficacy of CLoQ across multiple tasks such as language generation, arithmetic reasoning, and commonsense reasoning, demonstrating that it consistently outperforms existing LoRA fine-tuning methods for quantized LLMs, especially at ultra low-bit widths.",
    "source": "arXiv"
  },
  {
    "title": "NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning",
    "title_es": "NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning",
    "url": "https://arxiv.org/abs/2502.00372",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.00372v3 Announce Type: replace \nAbstract: Visual Grounding (VG) tasks, such as referring expression detection and segmentation tasks are important for linking visual entities to context, especially in complex reasoning tasks that require detailed query interpretation. This paper explores VG beyond basic perception, highlighting challenges for methods that require reasoning like human cognition. Recent advances in large language methods (LLMs) and Vision-Language methods (VLMs) have improved abilities for visual comprehension, contextual understanding, and reasoning. These methods are mainly split into end-to-end and compositional methods, with the latter offering more flexibility. Compositional approaches that integrate LLMs and foundation models show promising performance but still struggle with complex reasoning with language-based logical representations. To address these limitations, we propose NAVER, a compositional visual grounding method that integrates explicit probabilistic logic reasoning within a finite-state automaton, equipped with a self-correcting mechanism. This design improves robustness and interpretability in inference through explicit logic reasoning. Our results show that NAVER achieves SoTA performance comparing to recent end-to-end and compositional baselines. The code is available at https://github.com/ControlNet/NAVER .",
    "source": "arXiv"
  },
  {
    "title": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "title_es": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "url": "https://arxiv.org/abs/2502.01618",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.01618v5 Announce Type: replace \nAbstract: Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4-16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work. Code, videos, and further information available at https://probabilistic-inference-scaling.github.io.",
    "source": "arXiv"
  },
  {
    "title": "Delayed Feedback Modeling with Influence Functions",
    "title_es": "Delayed Feedback Modeling with Influence Functions",
    "url": "https://arxiv.org/abs/2502.01669",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.01669v2 Announce Type: replace \nAbstract: In online advertising under the cost-per-conversion (CPA) model, accurate conversion rate (CVR) prediction is crucial. A major challenge is delayed feedback, where conversions may occur long after user interactions, leading to incomplete recent data and biased model training. Existing solutions partially mitigate this issue but often rely on auxiliary models, making them computationally inefficient and less adaptive to user interest shifts. We propose IF-DFM, an \\underline{I}nfluence \\underline{F}unction-empowered for \\underline{D}elayed \\underline{F}eedback \\underline{M}odeling which estimates the impact of newly arrived and delayed conversions on model parameters, enabling efficient updates without full retraining. By reformulating the inverse Hessian-vector product as an optimization problem, IF-DFM achieves a favorable trade-off between scalability and effectiveness. Experiments on benchmark datasets show that IF-DFM outperforms prior methods in both accuracy and adaptability.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Distributed Optimization under Heavy-Tailed Noise",
    "title_es": "Efficient Distributed Optimization under Heavy-Tailed Noise",
    "url": "https://arxiv.org/abs/2502.04164",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.04164v2 Announce Type: replace \nAbstract: Distributed optimization has become the default training paradigm in modern machine learning due to the growing scale of models and datasets. To mitigate communication overhead, local updates are often applied before global aggregation, resulting in a nested optimization approach with inner and outer steps. However, heavy-tailed stochastic gradient noise remains a significant challenge, particularly in attention-based models, hindering effective training. In this work, we propose TailOPT, an efficient framework designed to address heavy-tailed noise by leveraging adaptive optimization or clipping techniques. We establish convergence guarantees for the TailOPT framework under heavy-tailed noise with potentially unbounded gradient variance and local updates. Among its variants, we highlight a memory and communication efficient instantiation which we call $Bi^2Clip$, which performs coordinate-wise clipping at both the inner and outer optimizers, achieving adaptive-like performance (e.g., Adam) without the cost of maintaining or transmitting additional gradient statistics. Empirically, TailOPT, including $Bi^2Clip$, demonstrates superior performance on several language tasks and models, outperforming state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "On Event-Triggered Resilient Consensus Using Auxiliary Layer",
    "title_es": "On Event-Triggered Resilient Consensus Using Auxiliary Layer",
    "url": "https://arxiv.org/abs/2502.07470",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.07470v2 Announce Type: replace \nAbstract: Due to its design simplicity, auxiliary layer-based resilient control is widely discussed in the literature to mitigate the effects of False Data Injection (FDI) attacks. However, the increased communication burden due to additional communication links for connecting an extra layer is often overlooked in the literature. This paper bridges this gap by considering an event-triggered approach for inter-layer communication between the physical layer (containing actual agents) and the auxiliary layer (containing virtual agents) for the resilient state consensus in a multi-agent system. We provide state-based and dynamic event-triggering mechanisms, the former being the motivation for the latter. The exclusion of Zeno behavior is established by proving positive minimum inter-event time (MIET). Extensive simulation and experimental results are provided to illustrate the proposed methodology.",
    "source": "arXiv"
  },
  {
    "title": "Measuring Diversity in Synthetic Datasets",
    "title_es": "Measuring Diversity in Synthetic Datasets",
    "url": "https://arxiv.org/abs/2502.08512",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.08512v3 Announce Type: replace \nAbstract: Large language models (LLMs) are widely adopted to generate synthetic datasets for various natural language processing (NLP) tasks, such as text classification and summarization. However, accurately measuring the diversity of these synthetic datasets-an aspect crucial for robust model performance-remains a significant challenge. In this paper, we introduce DCScore, a novel method for measuring synthetic dataset diversity from a classification perspective. Specifically, DCScore formulates diversity evaluation as a sample classification task, leveraging mutual relationships among samples. We further provide theoretical verification of the diversity-related axioms satisfied by DCScore, highlighting its role as a principled diversity evaluation method. Experimental results on synthetic datasets reveal that DCScore enjoys a stronger correlation with multiple diversity pseudo-truths of evaluated datasets, underscoring its effectiveness. Moreover, both empirical and theoretical evidence demonstrate that DCScore substantially reduces computational costs compared to existing methods. Code is available at: https://github.com/bluewhalelab/dcscore.",
    "source": "arXiv"
  },
  {
    "title": "A New Query Expansion Approach via Agent-Mediated Dialogic Inquiry",
    "title_es": "A New Query Expansion Approach via Agent-Mediated Dialogic Inquiry",
    "url": "https://arxiv.org/abs/2502.08557",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.08557v3 Announce Type: replace \nAbstract: Query expansion is widely used in Information Retrieval (IR) to improve search outcomes by supplementing initial queries with richer information. While recent Large Language Model (LLM) based methods generate pseudo-relevant content and expanded terms via multiple prompts, they often yield homogeneous, narrow expansions that lack the diverse context needed to retrieve relevant information. In this paper, we propose AMD: a new Agent-Mediated Dialogic Framework that engages in a dialogic inquiry involving three specialized roles: (1) a Socratic Questioning Agent reformulates the initial query into three sub-questions, with each question inspired by a specific Socratic questioning dimension, including clarification, assumption probing, and implication probing, (2) a Dialogic Answering Agent generates pseudo-answers, enriching the query representation with multiple perspectives aligned to the user's intent, and (3) a Reflective Feedback Agent evaluates and refines these pseudo-answers, ensuring that only the most relevant and informative content is retained. By leveraging a multi-agent process, AMD effectively crafts richer query representations through inquiry and feedback refinement. Extensive experiments on benchmarks including BEIR and TREC demonstrate that our framework outperforms previous methods, offering a robust solution for retrieval tasks.",
    "source": "arXiv"
  },
  {
    "title": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks",
    "title_es": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks",
    "url": "https://arxiv.org/abs/2502.08644",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.08644v5 Announce Type: replace \nAbstract: The brain rapidly adapts to new contexts and learns from limited data, a coveted characteristic that artificial intelligence (AI) algorithms struggle to mimic. Inspired by the mechanical oscillatory rhythms of neural cells, we developed a learning paradigm utilizing link strength oscillations, where learning is associated with the coordination of these oscillations. Link oscillations can rapidly change coordination, allowing the network to sense and adapt to subtle contextual changes without supervision. The network becomes a generalist AI architecture, capable of predicting dynamics of multiple contexts including unseen ones. These results make our paradigm a powerful starting point for novel models of cognition. Because our paradigm is agnostic to specifics of the neural network, our study opens doors for introducing rapid adaptive learning into leading AI models.",
    "source": "arXiv"
  },
  {
    "title": "Robustness tests for biomedical foundation models should tailor to specifications",
    "title_es": "Robustness tests for biomedical foundation models should tailor to specifications",
    "url": "https://arxiv.org/abs/2502.10374",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.10374v3 Announce Type: replace \nAbstract: The rise of biomedical foundation models creates new hurdles in model testing and authorization, given their broad capabilities and susceptibility to complex distribution shifts. We suggest tailoring robustness tests according to task-dependent priorities and propose to integrate granular notions of robustness in a predefined specification to guide implementation. Our approach facilitates the standardization of robustness assessments in the model lifecycle and connects abstract AI regulatory frameworks with concrete testing procedures.",
    "source": "arXiv"
  },
  {
    "title": "Boosting Cross-problem Generalization in Diffusion-Based Neural Combinatorial Solver via Inference Time Adaptation",
    "title_es": "Boosting Cross-problem Generalization in Diffusion-Based Neural Combinatorial Solver via Inference Time Adaptation",
    "url": "https://arxiv.org/abs/2502.12188",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.12188v3 Announce Type: replace \nAbstract: Diffusion-based Neural Combinatorial Optimization (NCO) has demonstrated effectiveness in solving NP-complete (NPC) problems by learning discrete diffusion models for solution generation, eliminating hand-crafted domain knowledge. Despite their success, existing NCO methods face significant challenges in both cross-scale and cross-problem generalization, and high training costs compared to traditional solvers. While recent studies on diffusion models have introduced training-free guidance approaches that leverage pre-defined guidance functions for conditional generation, such methodologies have not been extensively explored in combinatorial optimization. To bridge this gap, we propose a training-free inference time adaptation framework (DIFU-Ada) that enables both the zero-shot cross-problem transfer and cross-scale generalization capabilities of diffusion-based NCO solvers without requiring additional training. We provide theoretical analysis that helps understanding the cross-problem transfer capability. Our experimental results demonstrate that a diffusion solver, trained exclusively on the Traveling Salesman Problem (TSP), can achieve competitive zero-shot transfer performance across different problem scales on TSP variants, such as Prize Collecting TSP (PCTSP) and the Orienteering Problem (OP), through inference time adaptation.",
    "source": "arXiv"
  },
  {
    "title": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint",
    "title_es": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint",
    "url": "https://arxiv.org/abs/2502.16770",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.16770v2 Announce Type: replace \nAbstract: Fine-tuning pre-trained Large Language Models (LLMs) for specialized tasks incurs substantial computational and data costs. While model merging offers a training-free solution to integrate multiple task-specific models, existing methods suffer from safety-utility conflicts where enhanced general capabilities degrade safety safeguards. We identify two root causes: $\\textbf{neuron misidentification}$ due to simplistic parameter magnitude-based selection, and $\\textbf{cross-task neuron interference}$ during merging. To address these challenges, we propose $\\textbf{LED-Merging}$, a three-stage framework that $\\textbf{L}$ocates task-specific neurons via gradient-based attribution, dynamically $\\textbf{E}$lects critical neurons through multi-model importance fusion, and $\\textbf{D}$isjoints conflicting updates through parameter isolation. Extensive experiments on Llama-3-8B, Mistral-7B, and Llama2-13B demonstrate that LED-Merging effectively reduces harmful response rates, showing a 31.4\\% decrease on Llama-3-8B-Instruct on HarmBench, while simultaneously preserving 95\\% of utility performance, such as achieving 52.39\\% accuracy on GSM8K. LED-Merging resolves safety-utility conflicts and provides a lightweight, training-free paradigm for constructing reliable multi-task LLMs. Code is available at $\\href{https://github.com/MqLeet/LED-Merging}{GitHub}$.",
    "source": "arXiv"
  },
  {
    "title": "A Market for Accuracy: Classification under Competition",
    "title_es": "A Market for Accuracy: Classification under Competition",
    "url": "https://arxiv.org/abs/2502.18052",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.18052v2 Announce Type: replace \nAbstract: Machine learning models play a key role for service providers looking to gain market share in consumer markets. However, traditional learning approaches do not take into account the existence of additional providers, who compete with each other for consumers. Our work aims to study learning in this market setting, as it affects providers, consumers, and the market itself. We begin by analyzing such markets through the lens of the learning objective, and show that accuracy cannot be the only consideration. We then propose a method for classification under competition, so that a learner can maximize market share in the presence of competitors. We show that our approach benefits the providers as well as the consumers, and find that the timing of market entry and model updates can be crucial. We display the effectiveness of our approach across a range of domains, from simple distributions to noisy datasets, and show that the market as a whole remains stable by converging quickly to an equilibrium.",
    "source": "arXiv"
  },
  {
    "title": "Learning Classifiers That Induce Markets",
    "title_es": "Learning Classifiers That Induce Markets",
    "url": "https://arxiv.org/abs/2502.20012",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.20012v3 Announce Type: replace \nAbstract: When learning is used to inform decisions about humans, such as for loans, hiring, or admissions, this can incentivize users to strategically modify their features, at a cost, to obtain positive predictions. The common assumption is that the function governing costs is exogenous, fixed, and predetermined. We challenge this assumption, and assert that costs can emerge as a result of deploying a classifier. Our idea is simple: when users seek positive predictions, this creates demand for important features; and if features are available for purchase, then a market will form, and competition will give rise to prices. We extend the strategic classification framework to support this notion, and study learning in a setting where a classifier can induce a market for features. We present an analysis of the learning task, devise an algorithm for computing market prices, propose a differentiable learning framework, and conduct experiments to explore our novel setting and approach.",
    "source": "arXiv"
  },
  {
    "title": "Generative Active Adaptation for Drifting and Imbalanced Network Intrusion Detection",
    "title_es": "Generative Active Adaptation for Drifting and Imbalanced Network Intrusion Detection",
    "url": "https://arxiv.org/abs/2503.03022",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.03022v3 Announce Type: replace \nAbstract: Machine learning has shown promise in network intrusion detection systems, yet its performance often degrades due to concept drift and imbalanced data. These challenges are compounded by the labor-intensive process of labeling network traffic, especially when dealing with evolving and rare attack types, which makes preparing the right data for adaptation difficult. To address these issues, we propose a generative active adaptation framework that minimizes labeling effort while enhancing model robustness. Our approach employs density-aware dataset prior selection to identify the most informative samples for annotation, and leverages deep generative models to conditionally synthesize diverse samples, thereby augmenting the training set and mitigating the effects of concept drift. We evaluate our end-to-end framework \\NetGuard on both simulated IDS data and a real-world ISP dataset, demonstrating significant improvements in intrusion detection performance. Our method boosts the overall F1-score from 0.60 (without adaptation) to 0.86. Rare attacks such as Infiltration, Web Attack, and FTP-BruteForce, which originally achieved F1 scores of 0.001, 0.04, and 0.00, improve to 0.30, 0.50, and 0.71, respectively, with generative active adaptation in the CIC-IDS 2018 dataset. Our framework effectively enhances rare attack detection while reducing labeling costs, making it a scalable and practical solution for intrusion detection.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Parallel Execution of Blockchain Transactions Leveraging Conflict Specifications",
    "title_es": "Efficient Parallel Execution of Blockchain Transactions Leveraging Conflict Specifications",
    "url": "https://arxiv.org/abs/2503.03203",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.03203v2 Announce Type: replace \nAbstract: Parallel execution of smart contract transactions in large multicore architectures is critical for higher efficiency and improved throughput. The main bottleneck for maximizing the throughput of a node through parallel execution is transaction conflict resolution: when two transactions interact with the same data, like an account balance, their order matters. Imagine one transaction sends tokens from account A to account B, and another tries to send tokens from account B to account C. If the second transaction happens before the first one, the token balance in account B might be wrong, causing the entire system to break. Conflicts like these must be managed carefully, or you end up with an inconsistent, unusable blockchain state.\n  Traditional software transactional memory (STM) has been identified as a possible abstraction for the concurrent execution of transactions within a block, with Block-STM pioneering its application for efficient blockchain transaction processing on multicore validator nodes. This paper presents a parallel execution methodology that leverages conflict specification information of the transactions for block transactional memory (BTM) algorithms. Our experimental analysis, conducted over synthetic transactional workloads and real-world blocks, demonstrates that BTMs leveraging conflict specifications outperform their plain counterparts on both EVM and MoveVM. Our proposed BTM implementations achieve up to 1.75x speedup over sequential execution and outperform the state-of-the-art Parallel-EVM (PEVM) execution by up to 1.33x across synthetic workloads.",
    "source": "arXiv"
  },
  {
    "title": "MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for Domain Generalized Stereo Matching",
    "title_es": "MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for Domain Generalized Stereo Matching",
    "url": "https://arxiv.org/abs/2503.04376",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.04376v2 Announce Type: replace \nAbstract: Despite the significant advances in domain generalized stereo matching, existing methods still exhibit domain-specific preferences when transferring from synthetic to real domains, hindering their practical applications in complex and diverse scenarios. The probability distributions predicted by the stereo network naturally encode rich similarity and uncertainty information. Inspired by this observation, we propose to extract these two types of dark knowledge from the pre-trained network to model intuitive multi-modal ground-truth distributions for both edge and non-edge regions. To mitigate the inherent domain preferences of a single network, we adopt network ensemble and further distinguish between objective and biased knowledge in the Laplace parameter space. Finally, the objective knowledge and the original disparity labels are jointly modeled as a mixture of Laplacians to provide fine-grained supervision for the stereo network training. Extensive experiments demonstrate that: (1) Our method is generic and effectively improves the generalization of existing networks. (2) PCWNet with our method achieves the state-of-the-art generalization performance on both KITTI 2015 and 2012 datasets. (3) Our method outperforms existing methods in comprehensive ranking across four popular real-world datasets.",
    "source": "arXiv"
  },
  {
    "title": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)",
    "title_es": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)",
    "url": "https://arxiv.org/abs/2503.04798",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.04798v2 Announce Type: replace \nAbstract: We present Scalable Multi-Agent Realistic Testbed (SMART), a realistic and efficient software tool for evaluating Multi-Agent Path Finding (MAPF) algorithms. MAPF focuses on planning collision-free paths for a group of agents. While state-ofthe-art MAPF algorithms can plan paths for hundreds of robots in seconds, they often rely on simplified robot models, making their real-world performance unclear. Researchers typically lack access to hundreds of physical robots in laboratory settings to evaluate the algorithms. Meanwhile, industrial professionals who lack expertise in MAPF require an easy-to-use simulator to efficiently test and understand the performance of MAPF algorithms in their specific settings. SMART fills this gap with several advantages: (1) SMART uses physics-engine-based simulators to create realistic simulation environments, accounting for complex real-world factors such as robot kinodynamics and execution uncertainties, (2) SMART uses an execution monitor framework based on the Action Dependency Graph, facilitating seamless integration with various MAPF algorithms and robot models, and (3) SMART scales to thousands of robots. The code is publicly available at https://github.com/smart-mapf/smart.",
    "source": "arXiv"
  },
  {
    "title": "Robotic Ultrasound-Guided Femoral Artery Reconstruction of Anatomically-Representative Phantoms",
    "title_es": "Robotic Ultrasound-Guided Femoral Artery Reconstruction of Anatomically-Representative Phantoms",
    "url": "https://arxiv.org/abs/2503.06795",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.06795v2 Announce Type: replace \nAbstract: Femoral artery access is essential for numerous clinical procedures, including diagnostic angiography, therapeutic catheterization, and emergency interventions. Despite its critical role, successful vascular access remains challenging due to anatomical variability, overlying adipose tissue, and the need for precise ultrasound (US) guidance. Needle placement errors can result in severe complications, thereby limiting the procedure to highly skilled clinicians operating in controlled hospital environments. While robotic systems have shown promise in addressing these challenges through autonomous scanning and vessel reconstruction, clinical translation remains limited due to reliance on simplified phantom models that fail to capture human anatomical complexity. In this work, we present a method for autonomous robotic US scanning of bifurcated femoral arteries, and validate it on five vascular phantoms created from real patient computed tomography (CT) data. Additionally, we introduce a video-based deep learning US segmentation network tailored for vascular imaging, enabling improved 3D arterial reconstruction. The proposed network achieves a Dice score of 89.21% and an Intersection over Union of 80.54% on a new vascular dataset. The reconstructed artery centerline is evaluated against ground truth CT data, showing an average L2 error of 0.91+/-0.70 mm, with an average Hausdorff distance of 4.36+/-1.11mm. This study is the first to validate an autonomous robotic system for US scanning of the femoral artery on a diverse set of patient-specific phantoms, introducing a more advanced framework for evaluating robotic performance in vascular imaging and intervention.",
    "source": "arXiv"
  },
  {
    "title": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking",
    "title_es": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking",
    "url": "https://arxiv.org/abs/2503.07516",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.07516v3 Announce Type: replace \nAbstract: Referring Multi-Object Tracking (RMOT) aims to localize target trajectories in videos specified by natural language expressions. Despite recent progress, the intrinsic relationship between the two subtasks of tracking and referring in RMOT has not been fully studied. In this paper, we present a systematic analysis of their interdependence, revealing that current two-stage Referring-by-Tracking (RBT) frameworks remain fundamentally limited by insufficient modeling of subtask interactions and inflexible reliance on semantic alignment modules like CLIP. To this end, we propose JustHook, a novel two-stage RBT framework where a Hook module is firstly designed to redefine the linkage between subtasks. The Hook is built centered on grid sampling at the feature-level and is used for context-aware target feature extraction. Moreover, we propose a Parallel Combined Decoder (PCD) that learns in a unified joint feature space rather than relying on pre-defined cross-modal embeddings. Our design not only enhances the interpretability and modularity but also significantly improves the generalization. Extensive experiments on Refer-KITTI, Refer-KITTI-V2, and Refer-Dance demonstrate that JustHook achieves state-of-the-art performance, improving the HOTA by +6.9\\% on Refer-KITTI-V2 with superior efficiency. Code will be available soon.",
    "source": "arXiv"
  },
  {
    "title": "Continual Learning for Multiple Modalities",
    "title_es": "Continual Learning for Multiple Modalities",
    "url": "https://arxiv.org/abs/2503.08064",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.08064v2 Announce Type: replace \nAbstract: Continual learning aims to learn knowledge of tasks observed in sequential time steps while mitigating the forgetting of previously learned knowledge. Existing methods were designed to learn a single modality (e.g., image) over time, which limits their applicability in scenarios involving multiple modalities. In this work, we propose a novel continual learning framework that accommodates multiple modalities (image, video, audio, depth, and text). We train a model to align various modalities with text, leveraging its rich semantic information. However, this increases the risk of forgetting previously learned knowledge, exacerbated by the differing input traits across tasks. To alleviate the overwriting of previous knowledge of modalities, we propose a framework that consolidates intra-modal knowledge while incorporating relevant inter-modal information. This is achieved by self-regulating shifts in learned representations to gradually integrating novel knowledge into the information retained across modalities. Simultaneously, it mitigates inter-modal interference by selectively integrating knowledge from previously encountered modalities based on their mutual relevance. Furthermore, we introduce a strategy to re-align modality embeddings, effectively addressing biased alignment between modalities. We evaluate the proposed method in a wide range of continual learning scenarios using multiple datasets with different modalities. Extensive experiments demonstrate that ours outperforms existing methods in the scenarios, regardless of whether the identity of the modality is given.",
    "source": "arXiv"
  },
  {
    "title": "From Actions to Words: Towards Abstractive-Textual Policy Summarization in RL",
    "title_es": "From Actions to Words: Towards Abstractive-Textual Policy Summarization in RL",
    "url": "https://arxiv.org/abs/2503.10509",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.10509v2 Announce Type: replace \nAbstract: Policies generated by Reinforcement Learning (RL) algorithms are difficult to explain to users, as they emerge from the interaction of complex reward structures and neural network representations. Consequently, analyzing and predicting agent behavior can be challenging, undermining user trust in real-world applications. To facilitate user understanding, current methods for global policy summarization typically rely on videos that demonstrate agent behavior in a subset of world states. However, users can only watch a limited number of demonstrations, constraining their understanding. Moreover, these methods place the burden of interpretation on users by presenting raw behaviors rather than synthesizing them into coherent patterns. To resolve these issues, we introduce SySLLM (Synthesized Summary using Large Language Models), advocating for a new paradigm of abstractive-textual policy explanations. By leveraging Large Language Models (LLMs)-which possess extensive world knowledge and pattern synthesis capabilities-SySLLM generates textual summaries that provide structured and comprehensible explanations of agent policies. SySLLM demonstrates that LLMs can interpret spatio-temporally structured descriptions of state-action trajectories from an RL agent and generate valuable policy insights in a zero-shot setting, without any prior knowledge or fine-tuning. Our evaluation shows that SySLLM captures key insights, such as goal preferences and exploration strategies, that were also identified by human experts. Furthermore, in a large-scale user study (with 200 participants), SySLLM summaries were preferred over demonstration-based summaries (HIGHLIGHTS) by a clear majority (75.5%) of participants.",
    "source": "arXiv"
  },
  {
    "title": "Discontinuous Galerkin discretization of conservative dynamical low-rank approximation schemes for the Vlasov-Poisson equation",
    "title_es": "Discontinuous Galerkin discretization of conservative dynamical low-rank approximation schemes for the Vlasov-Poisson equation",
    "url": "https://arxiv.org/abs/2503.10562",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.10562v2 Announce Type: replace \nAbstract: A numerical dynamical low-rank approximation (DLRA) scheme for the solution of the Vlasov-Poisson equation is presented. Based on the formulation of the DLRA equations as Friedrichs' systems in a continuous setting, it combines recently proposed conservative DLRA methods with a discontinuous Galerkin discretization. The resulting scheme is shown to ensure mass and momentum conservation at the discrete level. In addition, a new formulation of the conservative integrator is proposed which facilitates a projector splitting integrator. Numerical experiments validate our approach in one- and two-dimensional simulations of Landau damping. As a demonstration of feasibility, it is also shown that the rank-adaptive unconventional integrator can be combined with mesh adaptivity.",
    "source": "arXiv"
  },
  {
    "title": "TikZero: Zero-Shot Text-Guided Graphics Program Synthesis",
    "title_es": "TikZero: Zero-Shot Text-Guided Graphics Program Synthesis",
    "url": "https://arxiv.org/abs/2503.11509",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.11509v3 Announce Type: replace \nAbstract: Automatically synthesizing figures from text captions is a compelling capability. However, achieving high geometric precision and editability requires representing figures as graphics programs in languages like TikZ, and aligned training data (i.e., graphics programs with captions) remains scarce. Meanwhile, large amounts of unaligned graphics programs and captioned raster images are more readily available. We reconcile these disparate data sources by presenting TikZero, which decouples graphics program generation from text understanding by using image representations as an intermediary bridge. It enables independent training on graphics programs and captioned images and allows for zero-shot text-guided graphics program synthesis during inference. We show that our method substantially outperforms baselines that can only operate with caption-aligned graphics programs. Furthermore, when leveraging caption-aligned graphics programs as a complementary training signal, TikZero matches or exceeds the performance of much larger models, including commercial systems like GPT-4o. Our code, datasets, and select models are publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning",
    "title_es": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning",
    "url": "https://arxiv.org/abs/2503.11655",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.11655v3 Announce Type: replace \nAbstract: Large language models (LLMs) have transformed sentiment analysis, yet balancing accuracy, efficiency, and explainability remains a critical challenge. This study presents the first comprehensive evaluation of DeepSeek-R1--an open-source reasoning model--against OpenAI's GPT-4o and GPT-4o-mini. We test the full 671B model and its distilled variants, systematically documenting few-shot learning curves. Our experiments show DeepSeek-R1 achieves a 91.39\\% F1 score on 5-class sentiment and 99.31\\% accuracy on binary tasks with just 5 shots, an eightfold improvement in few-shot efficiency over GPT-4o. Architecture-specific distillation effects emerge, where a 32B Qwen2.5-based model outperforms the 70B Llama-based variant by 6.69 percentage points. While its reasoning process reduces throughput, DeepSeek-R1 offers superior explainability via transparent, step-by-step traces, establishing it as a powerful, interpretable open-source alternative.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Fault Detection and Isolation in an All-Electric Auxiliary Power Unit (APU) Gas Generator by Utilizing Starter/Generator Signal",
    "title_es": "Enhancing Fault Detection and Isolation in an All-Electric Auxiliary Power Unit (APU) Gas Generator by Utilizing Starter/Generator Signal",
    "url": "https://arxiv.org/abs/2503.14986",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.14986v2 Announce Type: replace \nAbstract: This study proposes a novel paradigm for enhancing fault detection and isolation (FDI) of gas generators in all-electric auxiliary power unit (APU) by utilizing shaft power information from the starter/generator. First, we conduct a pioneering investigation into the challenges and opportunities for FDI brought about by APU electrification. Our analysis reveals that the electrification of APU opens up new possibilities for utilizing shaft power estimates from starter/generator to improve gas generator FDI. We then provide comprehensive theoretical and analytical evidence demonstrating why, how, and to what extent, the shaft power information from the starter/generator can fundamentally enhance the estimation accuracy of system states and health parameters of the gas generator, while also identifying the key factors influencing these improvements in FDI performance. The effectiveness of the proposed paradigm and its theoretical foundations are validated through extensive Monte Carlo simulations. Furthermore, through comprehensive comparative analysis with state-of-the-art gas generator fault diagnosis methods, our experimental results not only demonstrate the superior performance of the proposed approach but also validate that the diagnostic capabilities of existing advanced FDI techniques can be substantially enhanced by incorporating shaft power information. And the observed performance improvement patterns strongly align with our theoretical analysis, verifying both the effectiveness and guiding significance of our theoretical framework. These research findings provide a unique perspective in answering three fundamental questions: why joint fault diagnosis of the starter/generator and gas generator is essential, how it can be implemented, and what factors determine its effectiveness, thereby opening up promising new avenues for FDI technologies in all-electric APU systems.",
    "source": "arXiv"
  },
  {
    "title": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache",
    "title_es": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache",
    "url": "https://arxiv.org/abs/2503.18773",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.18773v2 Announce Type: replace \nAbstract: The rise of long-context Large Language Models (LLMs) amplifies memory and bandwidth demands during autoregressive decoding, as the Key-Value (KV) cache grows with each generated token. Low-bit KV-cache quantization (e.g., 4-bit or 2-bit) can reduce memory footprint while preserving accuracy, but existing systems suffer from slow decoding due to their exclusive reliance on CUDA cores, neglecting Tensor Cores (the primary source of compute on modern GPUs). We present BitDecoding, a new long-context LLM inference system with a low-bit KV cache. BitDecoding enables efficient low-bit KV-cache decoding by cooperatively leveraging CUDA cores and Tensor Cores. It introduces methods for automatically inducing optimized layouts to exploit Tensor Cores, along with warp-level parallelization strategies for dequantization. For unified system support, BitDecoding includes a query transformation module supporting diverse attention variants, a quantization kernel that supports both tensor-wise and channel-wise scaling used in various quantization algorithms with high performance, and a dequantization kernel with a software-defined pipeline to coordinate CUDA and Tensor Cores execution for mixed-precision operations. Evaluated on RTX 4090, A100, and H100, BitDecoding accelerates decoding by up to 7.5x, 4.8x, and 8.9x, respectively, over FP16 FlashDecoding-v2, and surpasses the state-of-the-art low-bit system QServe by up to 4.3x. On LLaMA-3.1-8B with a 128K context, BitDecoding reduces single-batch decoding latency by 3x, showing substantial improvements for long-context generation. The code is available at https://github.com/DD-DuDa/BitDecoding.",
    "source": "arXiv"
  },
  {
    "title": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models",
    "title_es": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models",
    "url": "https://arxiv.org/abs/2503.19530",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.19530v3 Announce Type: replace \nAbstract: Popular PEFT methods reduce trainable parameter count for fine-tuning by parameterizing new low-rank or sparse trainable weights in parallel to the frozen pre-trained weights $W$. However, these weights are trained from scratch, and there exists a performance gap between these methods and full fine-tuning, especially in low-budget settings. We introduce VectorFit, a new way of parameterization that efficiently utilizes the existing knowledge embedded in $W$ by adaptively training their singular vectors and biases. We show that utilizing the structural and transformational properties of $W$ in this way can lead to high-rank incremental weight matrices $\\Delta W$, comparable to that of full fine-tuning. VectorFit delivers superior results with 9$\\boldsymbol\\times$ fewer trainable parameters than the leading PEFT methods. Through comprehensive experiments across 19 datasets covering a wide range of language and vision tasks such as natural language understanding and generation, question answering, image classification, and image generation, we demonstrate that VectorFit surpasses baselines in terms of performance as a function of parameter-efficiency.",
    "source": "arXiv"
  },
  {
    "title": "TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion",
    "title_es": "TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion",
    "url": "https://arxiv.org/abs/2503.20839",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.20839v2 Announce Type: replace \nAbstract: Quadrupedal locomotion via Reinforcement Learning (RL) is commonly addressed using the teacher-student paradigm, where a privileged teacher guides a proprioceptive student policy. However, key challenges such as representation misalignment between privileged teacher and proprioceptive-only student, covariate shift due to behavioral cloning, and lack of deployable adaptation; lead to poor generalization in real-world scenarios. We propose Teacher-Aligned Representations via Contrastive Learning (TAR), a framework that leverages privileged information with self-supervised contrastive learning to bridge this gap. By aligning representations to a privileged teacher in simulation via contrastive objectives, our student policy learns structured latent spaces and exhibits robust generalization to Out-of-Distribution (OOD) scenarios, surpassing the fully privileged \"Teacher\". Results showed accelerated training by 2x compared to state-of-the-art baselines to achieve peak performance. OOD scenarios showed better generalization by 40% on average compared to existing methods. Moreover, TAR transitions seamlessly into learning during deployment without requiring privileged states, setting a new benchmark in sample-efficient, adaptive locomotion and enabling continual fine-tuning in real-world scenarios. Open-source code and videos are available at https://amrmousa.com/TARLoco/.",
    "source": "arXiv"
  },
  {
    "title": "Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models",
    "title_es": "Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models",
    "url": "https://arxiv.org/abs/2503.23714",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.23714v2 Announce Type: replace \nAbstract: Instruction tuning is crucial for enabling Large Language Models (LLMs) to solve real-world tasks. Prior work has shown the effectiveness of instruction-tuning data synthesized solely from LLMs, raising a fundamental question: Do we still need human-originated signals for instruction tuning? This work answers the question affirmatively: we build state-of-the-art instruction-tuning datasets sourced from human-written instructions, by simply pairing them with LLM-generated responses. LLMs fine-tuned on our datasets consistently outperform those fine-tuned on existing ones. Our data construction approach can be easily adapted to other languages; we build datasets for Japanese and confirm that LLMs tuned with our data reach state-of-the-art performance. Analyses suggest that instruction-tuning in a new language allows LLMs to follow instructions, while the tuned models exhibit a notable lack of culture-specific knowledge in that language. The datasets and fine-tuned models will be publicly available. Our datasets, synthesized with open-weight LLMs, are openly distributed under permissive licenses, allowing for diverse use cases.",
    "source": "arXiv"
  },
  {
    "title": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving",
    "title_es": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving",
    "url": "https://arxiv.org/abs/2503.24381",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2503.24381v2 Announce Type: replace \nAbstract: We introduce UniOcc, a comprehensive, unified benchmark and toolkit for occupancy forecasting (i.e., predicting future occupancies based on historical information) and occupancy prediction (i.e., predicting current-frame occupancy from camera images. UniOcc unifies the data from multiple real-world datasets (i.e., nuScenes, Waymo) and high-fidelity driving simulators (i.e., CARLA, OpenCOOD), providing 2D/3D occupancy labels and annotating innovative per-voxel flows. Unlike existing studies that rely on suboptimal pseudo labels for evaluation, UniOcc incorporates novel evaluation metrics that do not depend on ground-truth labels, enabling robust assessment on additional aspects of occupancy quality. Through extensive experiments on state-of-the-art models, we demonstrate that large-scale, diverse training data and explicit flow information significantly enhance occupancy prediction and forecasting performance. Our data and code are available at https://uniocc.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "Incompressible Optimal Transport and Applications in Fluid Mixing",
    "title_es": "Incompressible Optimal Transport and Applications in Fluid Mixing",
    "url": "https://arxiv.org/abs/2504.01109",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.01109v2 Announce Type: replace \nAbstract: The problem of incompressible fluid mixing arises in numerous engineering applications and has been well-studied over the years, yet many open questions remain. This paper aims to address the question \"what do efficient flow fields for mixing look like, and how do they behave?\" We approach this question by developing a framework which is inspired by the dynamic and geometric approach to optimal mass transport. Specifically, we formulate the fluid mixing problem as an optimal control problem where the dynamics are given by the continuity equation together with an incompressibility constraint. We show that within this framework, the set of reachable fluid configurations can formally be endowed with the structure of an infinite-dimensional Riemannian manifold, with a metric which is induced by the control effort, and that flow fields which are maximally efficient at mixing correspond to geodesics in this Riemannian space.",
    "source": "arXiv"
  },
  {
    "title": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning",
    "title_es": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning",
    "url": "https://arxiv.org/abs/2504.01400",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.01400v2 Announce Type: replace \nAbstract: Tool learning, which allows Large Language Models (LLMs) to leverage external tools for solving complex user tasks, has emerged as a promising avenue for extending model capabilities. However, existing approaches primarily focus on data synthesis for fine-tuning LLMs to invoke tools effectively, largely ignoring how to fully stimulate the potential of the model. In this paper, we propose ToolACE-R, a novel framework that includes both model-aware iterative training and adaptive refinement for tool learning. ToolACE-R features a model-aware iterative training procedure that progressively adjust training samples based on the model's evolving capabilities to maximize its potential. Additionally, it incorporates self-refinement training corpus which emphasizes LLM's ability to iteratively refine their tool calls, optimizing performance without requiring external feedback. Furthermore, we introduce adaptive self-refinement mechanism for efficient test-time scaling, where the trained model can autonomously determine when to stop the process based on iterative self-refinement. We conduct extensive experiments across several benchmark datasets, showing that ToolACE-R achieves competitive performance compared to advanced API-based models. The performance of tool invocation can be further improved efficiently through adaptive self-refinement. These results highlight the effectiveness and generalizability of ToolACE-R, offering a promising direction for more efficient and scalable tool learning.",
    "source": "arXiv"
  },
  {
    "title": "CoTAL: Human-in-the-Loop Prompt Engineering for Generalizable Formative Assessment Scoring",
    "title_es": "CoTAL: Human-in-the-Loop Prompt Engineering for Generalizable Formative Assessment Scoring",
    "url": "https://arxiv.org/abs/2504.02323",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.02323v3 Announce Type: replace \nAbstract: Large language models (LLMs) have created new opportunities to assist teachers and support student learning. While researchers have explored various prompt engineering approaches in educational contexts, the degree to which these approaches generalize across domains--such as science, computing, and engineering--remains underexplored. In this paper, we introduce Chain-of-Thought Prompting + Active Learning (CoTAL), an LLM-based approach to formative assessment scoring that (1) leverages Evidence-Centered Design (ECD) to align assessments and rubrics with curriculum goals, (2) applies human-in-the-loop prompt engineering to automate response scoring, and (3) incorporates chain-of-thought (CoT) prompting and teacher and student feedback to iteratively refine questions, rubrics, and LLM prompts. Our findings demonstrate that CoTAL improves GPT-4's scoring performance across domains, achieving gains of up to 38.9% over a non-prompt-engineered baseline (i.e., without labeled examples, chain-of-thought prompting, or iterative refinement). Teachers and students judge CoTAL to be effective at scoring and explaining responses, and their feedback produces valuable insights that enhance grading accuracy and explanation quality.",
    "source": "arXiv"
  },
  {
    "title": "Scaling Open-Vocabulary Action Detection",
    "title_es": "Scaling Open-Vocabulary Action Detection",
    "url": "https://arxiv.org/abs/2504.03096",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.03096v4 Announce Type: replace \nAbstract: In this work, we focus on scaling open-vocabulary action detection. Existing approaches for action detection are predominantly limited to closed-set scenarios and rely on complex, parameter-heavy architectures. Extending these models to the open-vocabulary setting poses two key challenges: (1) the lack of large-scale datasets with many action classes for robust training, and (2) parameter-heavy adaptations to a pretrained vision-language contrastive model to convert it for detection, risking overfitting the additional non-pretrained parameters to base action classes. Firstly, we introduce an encoder-only multimodal model for video action detection, reducing the reliance on parameter-heavy additions for video action detection. Secondly, we introduce a simple weakly supervised training strategy to exploit an existing closed-set action detection dataset for pretraining. Finally, we depart from the ill-posed base-to-novel benchmark used by prior works in open-vocabulary action detection and devise a new benchmark to evaluate on existing closed-set action detection datasets without ever using them for training, showing novel results to serve as baselines for future work. Our code is available at https://siatheindochinese.github.io/sia_act_page/ .",
    "source": "arXiv"
  },
  {
    "title": "OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM",
    "title_es": "OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM",
    "url": "https://arxiv.org/abs/2504.04801",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.04801v3 Announce Type: replace \nAbstract: Despite the remarkable progress of multimodal large language models (MLLMs), they continue to face challenges in achieving competitive performance on ordinal regression (OR; a.k.a. ordinal classification). To address this issue, this paper presents OrderChain, a novel and general prompting paradigm that improves the ordinal understanding ability of MLLMs by specificity and commonality modeling. Specifically, our OrderChain consists of a set of task-aware prompts to facilitate the specificity modeling of diverse OR tasks and a new range optimization Chain-of-Thought (RO-CoT), which learns a commonality way of thinking about OR tasks by uniformly decomposing them into multiple small-range optimization subtasks. Further, we propose a category recursive division (CRD) method to generate instruction candidate category prompts to support RO-CoT automatic optimization. Comprehensive experiments show that LLaVA model with our OrderChain improves baseline LLaVA significantly on diverse OR datasets, e.g., from 47.5\\% to 93.2\\% accuracy on the Adience dataset for age estimation, and from 30.0\\% to 85.7\\% accuracy on the Diabetic Retinopathy dataset. Notably, LLaVA with our OrderChain also remarkably outperforms state-of-the-art methods by 27% on accuracy and 0.24 on MAE on the Adience dataset. To our best knowledge, our OrderChain is the first work that augments MLLMs for OR tasks, and the effectiveness is witnessed across a spectrum of OR datasets. Project Page: https://order-chain.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal Trajectory Prediction",
    "title_es": "MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal Trajectory Prediction",
    "url": "https://arxiv.org/abs/2504.05059",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.05059v3 Announce Type: replace \nAbstract: Accurate vehicle trajectory prediction is critical for safe and efficient autonomous driving, especially in mixed traffic environments when both human-driven and autonomous vehicles co-exist. However, uncertainties introduced by inherent driving behaviors -- such as acceleration, deceleration, and left and right maneuvers -- pose significant challenges for reliable trajectory prediction. We introduce a Maneuver-Intention-Aware Transformer (MIAT) architecture, which integrates a maneuver intention awareness control mechanism with spatiotemporal interaction modeling to enhance long-horizon trajectory predictions. We systematically investigate the impact of varying awareness of maneuver intention on both short- and long-horizon trajectory predictions. Evaluated on the real-world NGSIM dataset and benchmarked against various transformer- and LSTM-based methods, our approach achieves an improvement of up to 4.7% in short-horizon predictions and a 1.6% in long-horizon predictions compared to other intention-aware benchmark methods. Moreover, by leveraging intention awareness control mechanism, MIAT realizes an 11.1% performance boost in long-horizon predictions, with a modest drop in short-horizon performance. The source code and datasets are available at https://github.com/cpraskoti/MIAT.",
    "source": "arXiv"
  },
  {
    "title": "RobustDexGrasp: Robust Dexterous Grasping of General Objects",
    "title_es": "RobustDexGrasp: Robust Dexterous Grasping of General Objects",
    "url": "https://arxiv.org/abs/2504.05287",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.05287v3 Announce Type: replace \nAbstract: The ability to robustly grasp a variety of objects is essential for dexterous robots. In this paper, we present a framework for zero-shot dynamic dexterous grasping using single-view visual inputs, designed to be resilient to various disturbances. Our approach utilizes a hand-centric object shape representation based on dynamic distance vectors between finger joints and object surfaces. This representation captures the local shape around potential contact regions rather than focusing on detailed global object geometry, thereby enhancing generalization to shape variations and uncertainties. To address perception limitations, we integrate a privileged teacher policy with a mixed curriculum learning approach, allowing the student policy to effectively distill grasping capabilities and explore for adaptation to disturbances. Trained in simulation, our method achieves success rates of 97.0% across 247,786 simulated objects and 94.6% across 512 real objects, demonstrating remarkable generalization. Quantitative and qualitative results validate the robustness of our policy against various disturbances.",
    "source": "arXiv"
  },
  {
    "title": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes",
    "title_es": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes",
    "url": "https://arxiv.org/abs/2504.06866",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.06866v3 Announce Type: replace \nAbstract: Robust grasping in cluttered environments remains an open challenge in robotics. While benchmark datasets have significantly advanced deep learning methods, they mainly focus on simplistic scenes with light occlusion and insufficient diversity, limiting their applicability to practical scenarios. We present GraspClutter6D, a large-scale real-world grasping dataset featuring: (1) 1,000 highly cluttered scenes with dense arrangements (14.1 objects/scene, 62.6\\% occlusion), (2) comprehensive coverage across 200 objects in 75 environment configurations (bins, shelves, and tables) captured using four RGB-D cameras from multiple viewpoints, and (3) rich annotations including 736K 6D object poses and 9.3B feasible robotic grasps for 52K RGB-D images. We benchmark state-of-the-art segmentation, object pose estimation, and grasp detection methods to provide key insights into challenges in cluttered environments. Additionally, we validate the dataset's effectiveness as a training resource, demonstrating that grasping networks trained on GraspClutter6D significantly outperform those trained on existing datasets in both simulation and real-world experiments. The dataset, toolkit, and annotation tools are publicly available on our project website: https://sites.google.com/view/graspclutter6d.",
    "source": "arXiv"
  },
  {
    "title": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models",
    "title_es": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models",
    "url": "https://arxiv.org/abs/2504.08329",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.08329v3 Announce Type: replace \nAbstract: Electronic health record (EHR) foundation models have been an area ripe for exploration with their improved performance in various medical tasks. Despite the rapid advances, there exists a fundamental limitation: Processing unseen medical codes out of vocabulary. This problem limits the generalizability of EHR foundation models and the integration of models trained with different vocabularies. To alleviate this problem, we propose a set of novel medical concept representations (MedRep) for EHR foundation models based on the observational medical outcome partnership (OMOP) common data model (CDM). For concept representation learning, we enrich the information of each concept with a minimal definition through large language model (LLM) prompts and complement the text-based representations through the graph ontology of OMOP vocabulary. Our approach outperforms the vanilla EHR foundation model and the model with a previously introduced medical code tokenizer in diverse prediction tasks. We also demonstrate the generalizability of MedRep through external validation.",
    "source": "arXiv"
  },
  {
    "title": "An Empirical Study of Production Incidents in Generative AI Cloud Services",
    "title_es": "An Empirical Study of Production Incidents in Generative AI Cloud Services",
    "url": "https://arxiv.org/abs/2504.08865",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.08865v2 Announce Type: replace \nAbstract: The ever-increasing demand for generative artificial intelligence (GenAI) has motivated cloud-based GenAI services such as Azure OpenAI Service and Amazon Bedrock. Like any large-scale cloud service, failures are inevitable in cloud-based GenAI services, resulting in user dissatisfaction and significant monetary losses. However, GenAI cloud services, featured by their massive parameter scales, hardware demands, and usage patterns, present unique challenges, including generated content quality issues and privacy concerns, compared to traditional cloud services. To understand the production reliability of GenAI cloud services, we analyzed production incidents from a leading GenAI cloud service provider spanning in the past four years. Our study (1) presents the general characteristics of GenAI cloud service incidents at different stages of the incident life cycle; (2) identifies the symptoms and impacts of these incidents on GenAI cloud service quality and availability; (3) uncovers why these incidents occurred and how they were resolved; (4) discusses open research challenges in terms of incident detection, triage, and mitigation, and sheds light on potential solutions.",
    "source": "arXiv"
  },
  {
    "title": "What metric to optimize for suppressing instability in a Vlasov-Poisson system?",
    "title_es": "What metric to optimize for suppressing instability in a Vlasov-Poisson system?",
    "url": "https://arxiv.org/abs/2504.10435",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.10435v3 Announce Type: replace \nAbstract: Stabilizing plasma dynamics is an important task in green energy generation via fusion. A common strategy is to introduce an external field to prevent the plasma distribution from becoming turbulent. However, finding such external fields efficiently remains an open question, even for simplified models such as the Vlasov-Poisson (VP) system. In this work, we present an integrated method where we first perform an analytical derivation of the VP system's dispersion relation to construct a high-quality initial guess for the stabilizing field. This analytically-derived field is then used to initialize a PDE-constrained optimization loop that refines the control to a local optimum. Through extensive numerical experiments, we demonstrate that objective functions evaluated only at the target time-when stable plasma is desired-lead to highly non-convex optimization landscapes, making the global minimum difficult to locate. This behavior arises regardless of the choice of loss function (e.g., KL divergence or electric energy). In contrast, integrating the loss function over time yields a landscape with a convex basin near the global minimum, facilitating convergence. Furthermore, when using electric energy as the objective, the landscape outside this basin is dominated by flat, unphysical local minima, highlighting the critical importance of our analytical approach for generating an initial guess that lies within the global minimum's basin of attraction.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Client-oriented Federated Graph Learning",
    "title_es": "Rethinking Client-oriented Federated Graph Learning",
    "url": "https://arxiv.org/abs/2504.14188",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.14188v2 Announce Type: replace \nAbstract: As a new distributed graph learning paradigm, Federated Graph Learning (FGL) facilitates collaborative model training across local systems while preserving data privacy.\n  We review existing FGL approaches and categorize their optimization mechanisms into:\n  (1) Server-Client (S-C), where clients upload local model parameters for server-side aggregation and global updates;\n  (2) Client-Client (C-C), which allows direct exchange of information between clients and customizing their local training process.\n  We reveal that C-C shows superior potential due to its refined communication structure.\n  However, existing C-C methods broadcast redundant node representations, incurring high communication costs and privacy risks at the node level. To this end, we propose FedC4, which combines graph Condensation with C-C Collaboration optimization. Specifically, FedC4 employs graph condensation technique to refine the knowledge of each client's graph into a few synthetic embeddings instead of transmitting node-level knowledge. Moreover, FedC4 introduces three novel modules that allow the source client to send distinct node representations tailored to the target client's graph properties. Experiments on eight public real-world datasets show that FedC4 outperforms state-of-the-art baselines in both task performance and communication cost. Our code is now available on https://github.com/Ereshkigal1/FedC4.",
    "source": "arXiv"
  },
  {
    "title": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory",
    "title_es": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory",
    "url": "https://arxiv.org/abs/2504.14325",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.14325v3 Announce Type: replace \nAbstract: Letting AI agents interact in multi-agent applications adds a layer of complexity to the interpretability and prediction of AI outcomes, with profound implications for their trustworthy adoption in research and society. Game theory offers powerful models to capture and interpret strategic interaction among agents, but requires the support of reproducible, standardized and user-friendly IT frameworks to enable comparison and interpretation of results. To this end, we present FAIRGAME, a Framework for AI Agents Bias Recognition using Game Theory. We describe its implementation and usage, and we employ it to uncover biased outcomes in popular games among AI agents, depending on the employed Large Language Model (LLM) and used language, as well as on the personality trait or strategic knowledge of the agents. Overall, FAIRGAME allows users to reliably and easily simulate their desired games and scenarios and compare the results across simulation campaigns and with game-theoretic predictions, enabling the systematic discovery of biases, the anticipation of emerging behavior out of strategic interplays, and empowering further research into strategic decision-making using LLM agents.",
    "source": "arXiv"
  },
  {
    "title": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering",
    "title_es": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering",
    "url": "https://arxiv.org/abs/2504.14493",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.14493v4 Announce Type: replace \nAbstract: Leveraging large language models in real-world settings often entails a need to utilize domain-specific data and tools in order to follow the complex regulations that need to be followed for acceptable use. Within financial sectors, modern enterprises increasingly rely on Retrieval-Augmented Generation (RAG) systems to address complex compliance requirements in financial document workflows. However, existing solutions struggle to account for the inherent heterogeneity of data (e.g., text, tables, diagrams) and evolving nature of regulatory standards used in financial filings, leading to compromised accuracy in critical information extraction. We propose the FinSage framework as a solution, utilizing a multi-aspect RAG framework tailored for regulatory compliance analysis in multi-modal financial documents. FinSage introduces three innovative components: (1) a multi-modal pre-processing pipeline that unifies diverse data formats and generates chunk-level metadata summaries, (2) a multi-path sparse-dense retrieval system augmented with query expansion (HyDE) and metadata-aware semantic search, and (3) a domain-specialized re-ranking module fine-tuned via Direct Preference Optimization (DPO) to prioritize compliance-critical content. Extensive experiments demonstrate that FinSage achieves an impressive recall of 92.51% on 75 expert-curated questions derived from surpasses the best baseline method on the FinanceBench question answering datasets by 24.06% in accuracy. Moreover, FinSage has been successfully deployed as financial question-answering agent in online meetings, where it has already served more than 1,200 people.",
    "source": "arXiv"
  },
  {
    "title": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting",
    "title_es": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting",
    "url": "https://arxiv.org/abs/2504.15485",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.15485v2 Announce Type: replace \nAbstract: Recognizing and reasoning about occluded (partially or fully hidden) objects is vital to understanding visual scenes, as occlusions frequently occur in real-world environments and act as obstacles for spatial comprehension. To test models' ability to reason about multiple occluded objects, we introduce a novel task, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which requires a model to count objects arranged in a pattern by inferring how the pattern continues behind an occluder (an object which blocks parts of the scene). CAPTURe requires both recognizing visual patterns and reasoning, making it a useful testbed for evaluating vision-language models (VLMs) on whether they understand occluded patterns and possess spatial understanding skills. By requiring models to reason about occluded objects, CAPTURe also tests VLMs' ability to form world models that would allow them to fill in missing information. CAPTURe consists of two parts: (1) CAPTURe-real, with manually filtered images of real objects in patterns and (2) CAPTURe-synthetic, a controlled diagnostic with generated patterned images. We evaluate four strong VLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models struggle to count on both occluded and unoccluded patterns. Crucially, we find that models perform worse with occlusion, suggesting that VLMs are also deficient in inferring unseen spatial relationships: even the strongest VLMs like GPT-4o fail to count with occlusion. In contrast, we find that humans achieve very little error on CAPTURe. We also find that providing auxiliary information of occluded object locations increases performance, underscoring that the model error comes both from an inability to handle occlusion as well as difficulty in counting in images. Code and data: https://github.com/atinpothiraj/CAPTURe",
    "source": "arXiv"
  },
  {
    "title": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design",
    "title_es": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design",
    "url": "https://arxiv.org/abs/2504.17493",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.17493v3 Announce Type: replace \nAbstract: Conventional time-series forecasting methods typically aim to minimize overall prediction error, without accounting for the varying importance of different forecast ranges in downstream applications. We propose a training methodology that enables forecasting models to adapt their focus to application-specific regions of interest at inference time, without retraining. The approach partitions the prediction space into fine-grained segments during training, which are dynamically reweighted and aggregated to emphasize the target range specified by the application. Unlike prior methods that predefine these ranges, our framework supports flexible, on-demand adjustments. Experiments on standard benchmarks and a newly collected wireless communication dataset demonstrate that our method not only improves forecast accuracy within regions of interest but also yields measurable gains in downstream task performance. These results highlight the potential for closer integration between predictive modeling and decision-making in real-world systems.",
    "source": "arXiv"
  },
  {
    "title": "Two Means to an End Goal: Connecting Explainability and Contestability in the Regulation of Public Sector AI",
    "title_es": "Two Means to an End Goal: Connecting Explainability and Contestability in the Regulation of Public Sector AI",
    "url": "https://arxiv.org/abs/2504.18236",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.18236v3 Announce Type: replace \nAbstract: Explainability and its emerging counterpart contestability have become important normative and design principles for trustworthy AI as they enable users and subjects to understand and challenge AI decisions. However, realizing these principles is difficult, as they assume different meanings in technical, legal, and organizational dimensions of AI regulation. To resolve this conceptual polysemy, in this paper, we present the findings of an interview study with 14 experts to examine the intersection and implementation of explainability and contestability, and their understanding in different research communities. We outline differentiations between descriptive and normative explainability, judicial and non-judicial channels of contestation, and individual and collective contestation action. We further describe the main points of friction in the realization of both principles, including the alignment between top-down and bottom-up regulation, the assignment of responsibility, and the need for interdisciplinary collaboration. Lastly, we formulate three recommendations for AI policy to implement both principles through a Regulation by Design perspective. We believe our contributions can inform policy-making and regulation of these core principles and enable more effective and equitable design, development, and deployment of trustworthy public AI systems.",
    "source": "arXiv"
  },
  {
    "title": "Vision Transformers in Precision Agriculture: A Comprehensive Survey",
    "title_es": "Vision Transformers in Precision Agriculture: A Comprehensive Survey",
    "url": "https://arxiv.org/abs/2504.21706",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.21706v4 Announce Type: replace \nAbstract: Detecting plant diseases is a crucial aspect of modern agriculture, as it plays a key role in maintaining crop health and increasing overall yield. Traditional approaches, though still valuable, often rely on manual inspection or conventional machine learning techniques, both of which face limitations in scalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as a promising alternative, offering advantages such as improved handling of long-range dependencies and better scalability for visual tasks. This review explores the application of ViTs in precision agriculture, covering a range of tasks. We begin by introducing the foundational architecture of ViTs and discussing their transition from Natural Language Processing (NLP) to Computer Vision. The discussion includes the concept of inductive bias in traditional models like Convolutional Neural Networks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive review of recent literature, focusing on key methodologies, datasets, and performance metrics. This study also includes a comparative analysis of CNNs and ViTs, along with a review of hybrid models and performance enhancements. Technical challenges such as data requirements, computational demands, and model interpretability are addressed, along with potential solutions. Finally, we outline future research directions and technological advancements that could further support the integration of ViTs in real-world agricultural settings. Our goal with this study is to offer practitioners and researchers a deeper understanding of how ViTs are poised to transform smart and precision agriculture.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints",
    "title_es": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints",
    "url": "https://arxiv.org/abs/2505.02640",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.02640v2 Announce Type: replace \nAbstract: Internet of Things (IoT) systems increasingly operate in environments where devices must respond in real time while managing fluctuating resource constraints, including energy and bandwidth. Yet, current approaches often fall short in addressing scenarios where operational constraints evolve over time. To address these limitations, we propose a novel Budgeted Multi-Armed Bandit framework tailored for IoT applications with dynamic operational limits. Our model introduces a decaying violation budget, which permits limited constraint violations early in the learning process and gradually enforces stricter compliance over time. We present the Budgeted Upper Confidence Bound (UCB) algorithm, which adaptively balances performance optimization and compliance with time-varying constraints. We provide theoretical guarantees showing that Budgeted UCB achieves sublinear regret and logarithmic constraint violations over the learning horizon. Extensive simulations in a wireless communication setting show that our approach achieves faster adaptation and better constraint satisfaction than standard online learning methods. These results highlight the framework's potential for building adaptive, resource-aware IoT systems.",
    "source": "arXiv"
  },
  {
    "title": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free",
    "title_es": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free",
    "url": "https://arxiv.org/abs/2505.03810",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.03810v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) face deployment challenges due to high computational costs, and while Post-Training Quantization (PTQ) offers a solution, existing rotation-based methods struggle at very low bit-widths like 2-bit. We introduce a novel, training-free approach to construct an improved rotation matrix, addressing the limitations of current methods. The key contributions include leveraging the Walsh-Hadamard transform with sequency ordering, which clusters similar frequency components to reduce quantization error compared to standard Hadamard matrices, significantly improving performance. Furthermore, we propose a Grouped Sequency-arranged Rotation (GSR) using block-diagonal matrices with smaller Walsh blocks, effectively isolating outlier impacts and achieving performance comparable to optimization-based methods without requiring any training. Our method demonstrates robust performance on reasoning tasks and Perplexity (PPL) score on WikiText-2. Our method also enhances results even when applied over existing learned rotation techniques.",
    "source": "arXiv"
  },
  {
    "title": "Responsible Machine Learning via Mixed-Integer Optimization",
    "title_es": "Responsible Machine Learning via Mixed-Integer Optimization",
    "url": "https://arxiv.org/abs/2505.05857",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.05857v2 Announce Type: replace \nAbstract: In the last few decades, Machine Learning (ML) has achieved significant success across domains ranging from healthcare, sustainability, and the social sciences, to criminal justice and finance. But its deployment in increasingly sophisticated, critical, and sensitive areas affecting individuals, the groups they belong to, and society as a whole raises critical concerns around fairness, transparency and robustness, among others. As the complexity and scale of ML systems and of the settings in which they are deployed grow, so does the need for responsible ML methods that address these challenges while providing guaranteed performance in deployment.\n  Mixed-integer optimization (MIO) offers a powerful framework for embedding responsible ML considerations directly into the learning process while maintaining performance. For example, it enables learning of inherently transparent models that can conveniently incorporate fairness or other domain specific constraints. This tutorial paper provides an accessible and comprehensive introduction to this topic discussing both theoretical and practical aspects. It outlines some of the core principles of responsible ML, their importance in applications, and the practical utility of MIO for building ML models that align with these principles. Through examples and mathematical formulations, it illustrates practical strategies and available tools for efficiently solving MIO problems for responsible ML. It concludes with a discussion on current limitations and open research questions, providing suggestions for future work.",
    "source": "arXiv"
  },
  {
    "title": "Identifying Causal Direction via Variational Bayesian Compression",
    "title_es": "Identifying Causal Direction via Variational Bayesian Compression",
    "url": "https://arxiv.org/abs/2505.07503",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.07503v4 Announce Type: replace \nAbstract: Telling apart the cause and effect between two random variables with purely observational data is a challenging problem that finds applications in various scientific disciplines. A key principle utilized in this task is the algorithmic Markov condition, which postulates that the joint distribution, when factorized according to the causal direction, yields a more succinct codelength compared to the anti-causal direction. Previous approaches approximate these codelengths by relying on simple functions or Gaussian processes (GPs) with easily evaluable complexity, compromising between model fitness and computational complexity. To address these limitations, we propose leveraging the variational Bayesian learning of neural networks as an interpretation of the codelengths. This allows the improvement of model fitness, while maintaining the succinctness of the codelengths, and the avoidance of the significant computational complexity of the GP-based approaches. Extensive experiments on both synthetic and real-world benchmarks in cause-effect identification demonstrate the effectiveness of our proposed method, showing promising performance enhancements on several datasets in comparison to most related methods.",
    "source": "arXiv"
  },
  {
    "title": "Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection",
    "title_es": "Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection",
    "url": "https://arxiv.org/abs/2505.08561",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.08561v2 Announce Type: replace \nAbstract: Masked video modeling~(MVM) has emerged as a highly effective pre-training strategy for visual foundation models, whereby the model reconstructs masked spatiotemporal tokens using information from visible tokens. However, a key challenge in such approaches lies in selecting an appropriate masking strategy. Previous studies have explored predefined masking techniques, including random and tube-based masking, as well as approaches that leverage key motion priors, optical flow and semantic cues from externally pre-trained models. In this work, we introduce a novel and generalizable Trajectory-Aware Adaptive Token Sampler (TATS), which models the motion dynamics of tokens and can be seamlessly integrated into the masked autoencoder (MAE) framework to select motion-centric tokens in videos. Additionally, we propose a unified training strategy that enables joint optimization of both MAE and TATS from scratch using Proximal Policy Optimization (PPO). We show that our model allows for aggressive masking without compromising performance on the downstream task of action recognition while also ensuring that the pre-training remains memory efficient. Extensive experiments of the proposed approach across four benchmarks, including Something-Something v2, Kinetics-400, UCF101, and HMDB51, demonstrate the effectiveness, transferability, generalization, and efficiency of our work compared to other state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation",
    "title_es": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation",
    "url": "https://arxiv.org/abs/2505.11528",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.11528v3 Announce Type: replace \nAbstract: Predictive manipulation has recently gained considerable attention in the Embodied AI community due to its potential to improve robot policy performance by leveraging predicted states. However, generating accurate future visual states of robot-object interactions from world models remains a well-known challenge, particularly in achieving high-quality pixel-level representations. To this end, we propose LaDi-WM, a world model that predicts the latent space of future states using diffusion modeling. Specifically, LaDi-WM leverages the well-established latent space aligned with pre-trained Visual Foundation Models (VFMs), which comprises both geometric features (DINO-based) and semantic features (CLIP-based). We find that predicting the evolution of the latent space is easier to learn and more generalizable than directly predicting pixel-level images. Building on LaDi-WM, we design a diffusion policy that iteratively refines output actions by incorporating forecasted states, thereby generating more consistent and accurate results. Extensive experiments on both synthetic and real-world benchmarks demonstrate that LaDi-WM significantly enhances policy performance by 27.9\\% on the LIBERO-LONG benchmark and 20\\% on the real-world scenario. Furthermore, our world model and policies achieve impressive generalizability in real-world experiments.",
    "source": "arXiv"
  },
  {
    "title": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference",
    "title_es": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference",
    "url": "https://arxiv.org/abs/2505.13109",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.13109v2 Announce Type: replace \nAbstract: Large language models (LLMs) have been widely deployed with rapidly expanding context windows to support increasingly demanding applications. However, long contexts pose significant deployment challenges, primarily due to the KV cache whose size grows proportionally with context length. While KV cache compression methods are proposed to address this issue, KV dropping methods incur considerable accuracy loss, and KV retrieval methods suffer from significant efficiency bottlenecks. We propose FreeKV, an algorithm-system co-optimization framework to enhance KV retrieval efficiency while preserving accuracy. On the algorithm side, FreeKV introduces speculative retrieval to shift the KV selection and recall processes out of the critical path, combined with fine-grained correction to ensure accuracy. On the system side, FreeKV employs hybrid KV layouts across CPU and GPU memory to eliminate fragmented data transfers, and leverages double-buffered streamed recall to further improve efficiency. Experiments demonstrate that FreeKV achieves near-lossless accuracy across various scenarios and models, delivering up to 13$\\times$ speedup compared to SOTA KV retrieval methods.",
    "source": "arXiv"
  },
  {
    "title": "PiT: Progressive Diffusion Transformer",
    "title_es": "PiT: Progressive Diffusion Transformer",
    "url": "https://arxiv.org/abs/2505.13219",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.13219v5 Announce Type: replace \nAbstract: Diffusion Transformers (DiTs) achieve remarkable performance within image generation via the transformer architecture. Conventionally, DiTs are constructed by stacking serial isotropic global modeling transformers, which face significant quadratic computational cost. However, through empirical analysis, we find that DiTs do not rely as heavily on global information as previously believed. In fact, most layers exhibit significant redundancy in global computation. Additionally, conventional attention mechanisms suffer from low-frequency inertia, limiting their efficiency. To address these issues, we propose Pseudo Shifted Window Attention (PSWA), which fundamentally mitigates global attention redundancy. PSWA achieves moderate global-local information through window attention. It further utilizes a high-frequency bridging branch to simulate shifted window operations, which both enrich the high-frequency information and strengthen inter-window connections. Furthermore, we propose the Progressive Coverage Channel Allocation (PCCA) strategy that captures high-order attention without additional computational cost. Based on these innovations, we propose a series of Pseudo Progressive Diffusion Transformer (PiT). Our extensive experiments show their superior performance; for example, our proposed PiT-L achieves 54% FID improvement over DiT-XL/2 while using less computation.",
    "source": "arXiv"
  },
  {
    "title": "Unraveling the iterative CHAD",
    "title_es": "Unraveling the iterative CHAD",
    "url": "https://arxiv.org/abs/2505.15002",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.15002v2 Announce Type: replace \nAbstract: Combinatory Homomorphic Automatic Differentiation (CHAD) was originally formulated as a semantics-driven source-to-source transformation for reverse-mode AD of total (terminating) functional programs. In this work, we extend CHAD to encompass programs featuring constructs such as partial (potentially non-terminating) operations, data-dependent conditionals (e.g., real-valued tests), and iteration constructs (i.e. while-loops), while maintaining CHAD's core principle of structure-preserving semantics.\n  A central contribution is the introduction of iteration-extensive indexed categories, which provide a principled integration of iteration into dependently typed programming languages. This integration is achieved by requiring that iteration in the base category lifts to parameterized initial algebras in the indexed category, yielding an op-fibred iterative structure that models while-loops and other iteration constructs in the total category, which corresponds to the category of containers of our dependently typed language.\n  Through the idea of iteration-extensive indexed categories, we extend the CHAD transformation to looping programs as the unique structure-preserving functor in a suitable sense. Specifically, it is the unique iterative Freyd category morphism from the iterative Freyd category corresponding to the source language to the category of containers obtained from the target language, such that each primitive operation is mapped to its (transposed) derivative. We establish the correctness of this extended transformation via the universal property of the syntactic categorical model of the source language, showing that the differentiated programs compute correct reverse-mode derivatives of their originals.",
    "source": "arXiv"
  },
  {
    "title": "MAPS: A Multilingual Benchmark for Global Agent Performance and Security",
    "title_es": "MAPS: A Multilingual Benchmark for Global Agent Performance and Security",
    "url": "https://arxiv.org/abs/2505.15935",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.15935v2 Announce Type: replace \nAbstract: Agentic AI systems, which build on Large Language Models (LLMs) and interact with tools and memory, have rapidly advanced in capability and scope. Yet, since LLMs have been shown to struggle in multilingual settings, typically resulting in lower performance and reduced safety, agentic systems risk inheriting these limitations. This raises concerns about the accessibility of such systems, as users interacting in languages other than English may encounter unreliable or security-critical agent behavior. Despite growing interest in evaluating agentic AI, existing benchmarks focus exclusively on English, leaving multilingual settings unexplored. To address this gap, we propose MAPS, a multilingual benchmark suite designed to evaluate agentic AI systems across diverse languages and tasks. MAPS builds on four widely used agentic benchmarks - GAIA (real-world tasks), SWE-bench (code generation), MATH (mathematical reasoning), and the Agent Security Benchmark (security). We translate each dataset into eleven diverse languages, resulting in 805 unique tasks and 9,660 total language-specific instances - enabling a systematic analysis of the multilingual effect on AI agents' performance and robustness. Empirically, we observe degradation in both performance and security when transitioning from English to other languages, with severity varying by task and correlating with the amount of translated input. Building on these findings, we provide actionable recommendations to guide agentic AI systems development and assessment under multilingual settings. This work establishes the first standardized evaluation framework for multilingual agentic AI, encouraging future research towards equitable, reliable, and accessible agentic AI. MAPS benchmark suite is publicly available at https://huggingface.co/datasets/Fujitsu-FRE/MAPS",
    "source": "arXiv"
  },
  {
    "title": "On the Two Paths Theorem and the Two Disjoint Paths Problem",
    "title_es": "On the Two Paths Theorem and the Two Disjoint Paths Problem",
    "url": "https://arxiv.org/abs/2505.16431",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.16431v2 Announce Type: replace \nAbstract: A tuple (s1,t1,s2,t2) of vertices in a simple undirected graph is 2-linked when there are two vertex-disjoint paths respectively from s1 to t1 and s2 to t2. A graph is 2-linked when all such tuples are 2-linked. We give a new and simple proof of the ``two paths theorem'', a characterisation of edge-maximal graphs which are not 2-linked as webs: particular near triangulations filled with cliques. Our proof works by generalising the theorem, replacing the four vertices above by an arbitrary tuple; it does not require major theorems such as Kuratowski's or Menger's theorems. Instead it follows an inductive characterisation of generalised webs via parallel composition, a graph operation consisting in taking a disjoint union before identifying some pairs of vertices. We use the insights provided by this proof to design a simple O(nm) recursive algorithm for the ``two vertex-disjoint paths'' problem. This algorithm is constructive in that it returns either two disjoint paths, or an embedding of the input graph into a web.",
    "source": "arXiv"
  },
  {
    "title": "Swedish Whispers; Leveraging a Massive Speech Corpus for Swedish Speech Recognition",
    "title_es": "Swedish Whispers; Leveraging a Massive Speech Corpus for Swedish Speech Recognition",
    "url": "https://arxiv.org/abs/2505.17538",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.17538v2 Announce Type: replace \nAbstract: This work presents a suite of fine-tuned Whisper models for Swedish, trained on a dataset of unprecedented size and variability for this mid-resourced language. As languages of smaller sizes are often underrepresented in multilingual training datasets, substantial improvements in performance can be achieved by fine-tuning existing multilingual models, as shown in this work. This work reports an overall improvement across model sizes compared to OpenAI's Whisper evaluated on Swedish. Most notably, we report an average 47% reduction in WER comparing our best performing model to OpenAI's whisper-large-v3, in evaluations across FLEURS, Common Voice, and NST.",
    "source": "arXiv"
  },
  {
    "title": "Security Concerns for Large Language Models: A Survey",
    "title_es": "Security Concerns for Large Language Models: A Survey",
    "url": "https://arxiv.org/abs/2505.18889",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.18889v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) such as ChatGPT and its competitors have caused a revolution in natural language processing, but their capabilities also introduce new security vulnerabilities. This survey provides a comprehensive overview of these emerging concerns, categorizing threats into several key areas: prompt injection and jailbreaking; adversarial attacks, including input perturbations and data poisoning; misuse by malicious actors to generate disinformation, phishing emails, and malware; and the worrisome risks inherent in autonomous LLM agents. Recently, a significant focus is increasingly being placed on the latter, exploring goal misalignment, emergent deception, self-preservation instincts, and the potential for LLMs to develop and pursue covert, misaligned objectives, a behavior known as scheming, which may even persist through safety training. We summarize recent academic and industrial studies from 2022 to 2025 that exemplify each threat, analyze proposed defenses and their limitations, and identify open challenges in securing LLM-based applications. We conclude by emphasizing the importance of advancing robust, multi-layered security strategies to ensure LLMs are safe and beneficial.",
    "source": "arXiv"
  },
  {
    "title": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting",
    "title_es": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting",
    "url": "https://arxiv.org/abs/2505.20469",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.20469v2 Announce Type: replace \nAbstract: Recent advances in 3D reconstruction techniques and vision-language models have fueled significant progress in 3D semantic understanding, a capability critical to robotics, autonomous driving, and virtual/augmented reality. However, methods that rely on 2D priors are prone to a critical challenge: cross-view semantic inconsistencies induced by occlusion, image blur, and view-dependent variations. These inconsistencies, when propagated via projection supervision, deteriorate the quality of 3D Gaussian semantic fields and introduce artifacts in the rendered outputs. To mitigate this limitation, we propose CCL-LGS, a novel framework that enforces view-consistent semantic supervision by integrating multi-view semantic cues. Specifically, our approach first employs a zero-shot tracker to align a set of SAM-generated 2D masks and reliably identify their corresponding categories. Next, we utilize CLIP to extract robust semantic encodings across views. Finally, our Contrastive Codebook Learning (CCL) module distills discriminative semantic features by enforcing intra-class compactness and inter-class distinctiveness. In contrast to previous methods that directly apply CLIP to imperfect masks, our framework explicitly resolves semantic conflicts while preserving category discriminability. Extensive experiments demonstrate that CCL-LGS outperforms previous state-of-the-art methods. Our project page is available at https://epsilontl.github.io/CCL-LGS/.",
    "source": "arXiv"
  },
  {
    "title": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling",
    "title_es": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling",
    "url": "https://arxiv.org/abs/2505.22107",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.22107v4 Announce Type: replace \nAbstract: Transformer-based large language models (LLMs) excel in natural language processing tasks by capturing long-range dependencies through self-attention mechanisms. However, long-context modeling faces significant computational inefficiencies due to \\textit{redundant} attention computations: while attention weights are often \\textit{sparse}, all tokens consume \\textit{equal} computational resources. In this paper, we reformulate traditional probabilistic sequence modeling as a \\textit{supervised learning task}, enabling the separation of relevant and irrelevant tokens and providing a clearer understanding of redundancy. Based on this reformulation, we theoretically analyze attention sparsity, revealing that only a few tokens significantly contribute to predictions. Building on this, we formulate attention optimization as a linear coding problem and propose a \\textit{group coding strategy}, theoretically showing its ability to improve robustness against random noise and enhance learning efficiency. Motivated by this, we propose \\textit{Dynamic Group Attention} (DGA), which leverages the group coding to explicitly reduce redundancy by aggregating less important tokens during attention computation. Empirical results show that our DGA significantly reduces computational costs while maintaining competitive performance.Code is available at https://github.com/bolixinyu/DynamicGroupAttention.",
    "source": "arXiv"
  },
  {
    "title": "Evaluation of Cultural Competence of Vision-Language Models",
    "title_es": "Evaluation of Cultural Competence of Vision-Language Models",
    "url": "https://arxiv.org/abs/2505.22793",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.22793v2 Announce Type: replace \nAbstract: Modern vision-language models (VLMs) often fail at cultural competency evaluations and benchmarks. Given the diversity of applications built upon VLMs, there is renewed interest in understanding how they encode cultural nuances. While individual aspects of this problem have been studied, we still lack a comprehensive framework for systematically identifying and annotating the nuanced cultural dimensions present in images for VLMs. This position paper argues that foundational methodologies from visual culture studies (cultural studies, semiotics, and visual studies) are necessary for cultural analysis of images. Building upon this review, we propose a set of five frameworks, corresponding to cultural dimensions, that must be considered for a more complete analysis of the cultural competencies of VLMs.",
    "source": "arXiv"
  },
  {
    "title": "Point or Line? Using Line-based Representation for Panoptic Symbol Spotting in CAD Drawings",
    "title_es": "Point or Line? Using Line-based Representation for Panoptic Symbol Spotting in CAD Drawings",
    "url": "https://arxiv.org/abs/2505.23395",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.23395v2 Announce Type: replace \nAbstract: We study the task of panoptic symbol spotting, which involves identifying both individual instances of countable things and the semantic regions of uncountable stuff in computer-aided design (CAD) drawings composed of vector graphical primitives. Existing methods typically rely on image rasterization, graph construction, or point-based representation, but these approaches often suffer from high computational costs, limited generality, and loss of geometric structural information. In this paper, we propose VecFormer, a novel method that addresses these challenges through line-based representation of primitives. This design preserves the geometric continuity of the original primitive, enabling more accurate shape representation while maintaining a computation-friendly structure, making it well-suited for vector graphic understanding tasks. To further enhance prediction reliability, we introduce a Branch Fusion Refinement module that effectively integrates instance and semantic predictions, resolving their inconsistencies for more coherent panoptic outputs. Extensive experiments demonstrate that our method establishes a new state-of-the-art, achieving 91.1 PQ, with Stuff-PQ improved by 9.6 and 21.2 points over the second-best results under settings with and without prior information, respectively, highlighting the strong potential of line-based representation as a foundation for vector graphic understanding.",
    "source": "arXiv"
  },
  {
    "title": "Reinforcement Learning with Random Time Horizons",
    "title_es": "Reinforcement Learning with Random Time Horizons",
    "url": "https://arxiv.org/abs/2506.00962",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.00962v2 Announce Type: replace \nAbstract: We extend the standard reinforcement learning framework to random time horizons. While the classical setting typically assumes finite and deterministic or infinite runtimes of trajectories, we argue that multiple real-world applications naturally exhibit random (potentially trajectory-dependent) stopping times. Since those stopping times typically depend on the policy, their randomness has an effect on policy gradient formulas, which we (mostly for the first time) derive rigorously in this work both for stochastic and deterministic policies. We present two complementary perspectives, trajectory or state-space based, and establish connections to optimal control theory. Our numerical experiments demonstrate that using the proposed formulas can significantly improve optimization convergence compared to traditional approaches.",
    "source": "arXiv"
  },
  {
    "title": "Optimistic critics can empower small actors",
    "title_es": "Optimistic critics can empower small actors",
    "url": "https://arxiv.org/abs/2506.01016",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.01016v3 Announce Type: replace \nAbstract: Actor-critic methods have been central to many of the recent advances in deep reinforcement learning. The most common approach is to use symmetric architectures, whereby both actor and critic have the same network topology and number of parameters. However, recent works have argued for the advantages of asymmetric setups, specifically with the use of smaller actors. We perform broad empirical investigations and analyses to better understand the implications of this and find that, in general, smaller actors result in performance degradation and overfit critics. Our analyses suggest poor data collection, due to value underestimation, as one of the main causes for this behavior, and further highlight the crucial role the critic can play in alleviating this pathology. We explore techniques to mitigate the observed value underestimation, which enables further research in asymmetric actor-critic methods.",
    "source": "arXiv"
  },
  {
    "title": "Data Pruning by Information Maximization",
    "title_es": "Data Pruning by Information Maximization",
    "url": "https://arxiv.org/abs/2506.01701",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.01701v2 Announce Type: replace \nAbstract: In this paper, we present InfoMax, a novel data pruning method, also known as coreset selection, designed to maximize the information content of selected samples while minimizing redundancy. By doing so, InfoMax enhances the overall informativeness of the coreset. The information of individual samples is measured by importance scores, which capture their influence or difficulty in model learning. To quantify redundancy, we use pairwise sample similarities, based on the premise that similar samples contribute similarly to the learning process. We formalize the coreset selection problem as a discrete quadratic programming (DQP) task, with the objective of maximizing the total information content, represented as the sum of individual sample contributions minus the redundancies introduced by similar samples within the coreset. To ensure practical scalability, we introduce an efficient gradient-based solver, complemented by sparsification techniques applied to the similarity matrix and dataset partitioning strategies. This enables InfoMax to seamlessly scale to datasets with millions of samples. Extensive experiments demonstrate the superior performance of InfoMax in various data pruning tasks, including image classification, vision-language pre-training, and instruction tuning for large language models. Code is available at https://github.com/hrtan/InfoMax.",
    "source": "arXiv"
  },
  {
    "title": "The Vampire Diary",
    "title_es": "The Vampire Diary",
    "url": "https://arxiv.org/abs/2506.03030",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.03030v2 Announce Type: replace \nAbstract: During the past decade of continuous development, the theorem prover Vampire has become an automated solver for the combined theories of commonly-used data structures. Vampire now supports arithmetic, induction, and higher-order logic. These advances have been made to meet the demands of software verification, enabling Vampire to effectively complement SAT/SMT solvers and aid proof assistants. We explain how best to use Vampire in practice and review the main changes Vampire has undergone since its last tool presentation, focusing on the engineering principles and design choices we made during this process.",
    "source": "arXiv"
  },
  {
    "title": "Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation",
    "title_es": "Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation",
    "url": "https://arxiv.org/abs/2506.06818",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.06818v3 Announce Type: replace \nAbstract: While promptable segmentation (\\textit{e.g.}, SAM) has shown promise for various segmentation tasks, it still requires manual visual prompts for each object to be segmented. In contrast, task-generic promptable segmentation aims to reduce the need for such detailed prompts by employing only a task-generic prompt to guide segmentation across all test samples. However, when applied to Camouflaged Object Segmentation (COS), current methods still face two critical issues: 1) \\textit{\\textbf{semantic ambiguity in getting instance-specific text prompts}}, which arises from insufficient discriminative cues in holistic captions, leading to foreground-background confusion; 2) \\textit{\\textbf{semantic discrepancy combined with spatial separation in getting instance-specific visual prompts}}, which results from global background sampling far from object boundaries with low feature correlation, causing SAM to segment irrelevant regions. To address the issues above, we propose \\textbf{RDVP-MSD}, a novel training-free test-time adaptation framework that synergizes \\textbf{R}egion-constrained \\textbf{D}ual-stream \\textbf{V}isual \\textbf{P}rompting (RDVP) via \\textbf{M}ultimodal \\textbf{S}tepwise \\textbf{D}ecomposition Chain of Thought (MSD-CoT). MSD-CoT progressively disentangles image captions to eliminate semantic ambiguity, while RDVP injects spatial constraints into visual prompting and independently samples visual prompts for foreground and background points, effectively mitigating semantic discrepancy and spatial separation. Without requiring any training or supervision, RDVP-MSD achieves a state-of-the-art segmentation result on multiple COS benchmarks and delivers a faster inference speed than previous methods, demonstrating significantly improved accuracy and efficiency. The codes will be available at \\href{https://github.com/ycyinchao/RDVP-MSD}{https://github.com/ycyinchao/RDVP-MSD}",
    "source": "arXiv"
  },
  {
    "title": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods",
    "title_es": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods",
    "url": "https://arxiv.org/abs/2506.10236",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.10236v2 Announce Type: replace \nAbstract: In this work, we demonstrate that certain machine unlearning methods may fail under straightforward prompt attacks. We systematically evaluate eight unlearning techniques across three model families using output-based, logit-based, and probe analysis to assess the extent to which supposedly unlearned knowledge can be retrieved. While methods like RMU and TAR exhibit robust unlearning, ELM remains vulnerable to specific prompt attacks (e.g., prepending Hindi filler text to the original prompt recovers 57.3% accuracy). Our logit analysis further indicates that unlearned models are unlikely to hide knowledge through changes in answer formatting, given the strong correlation between output and logit accuracy. These findings challenge prevailing assumptions about unlearning effectiveness and highlight the need for evaluation frameworks that can reliably distinguish between genuine knowledge removal and superficial output suppression. To facilitate further research, we publicly release our evaluation framework to easily evaluate prompting techniques to retrieve unlearned knowledge.",
    "source": "arXiv"
  },
  {
    "title": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning",
    "title_es": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning",
    "url": "https://arxiv.org/abs/2506.11049",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.11049v4 Announce Type: replace \nAbstract: As unmanned aerial vehicles (UAVs) become increasingly prevalent in both consumer and defense applications, the need for reliable, modality-specific classification systems grows in urgency. This paper addresses the challenge of data scarcity in UAV audio classification by expanding on prior work through the integration of pre-trained deep learning models, parameter-efficient fine-tuning (PEFT) strategies, and targeted data augmentation techniques. Using a custom dataset of 3,100 UAV audio clips (15,500 seconds) spanning 31 distinct drone types, we evaluate the performance of transformer-based and convolutional neural network (CNN) architectures under various fine-tuning configurations. Experiments were conducted with five-fold cross-validation, assessing accuracy, training efficiency, and robustness. Results show that full fine-tuning of the EfficientNet-B0 model with three augmentations achieved the highest validation accuracy (95.95), outperforming both the custom CNN and transformer-based models like AST. These findings suggest that combining lightweight architectures with PEFT and well-chosen augmentations provides an effective strategy for UAV audio classification on limited datasets. Future work will extend this framework to multimodal UAV classification using visual and radar telemetry.",
    "source": "arXiv"
  },
  {
    "title": "PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation",
    "title_es": "PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation",
    "url": "https://arxiv.org/abs/2506.11170",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.11170v2 Announce Type: replace \nAbstract: Multivariate time series data, collected across various fields such as manufacturing and wearable technology, exhibit states at multiple levels of granularity, from coarse-grained system behaviors to fine-grained, detailed events. Effectively segmenting and integrating states across these different granularities is crucial for tasks like predictive maintenance and performance optimization. However, existing time series segmentation methods face two key challenges: (1) the inability to handle multiple levels of granularity within a unified model, and (2) limited adaptability to new, evolving patterns in dynamic environments. To address these challenges, we propose PromptTSS, a novel framework for time series segmentation with multi-granularity states. PromptTSS uses a unified model with a prompting mechanism that leverages label and boundary information to guide segmentation, capturing both coarse- and fine-grained patterns while adapting dynamically to unseen patterns. Experiments show PromptTSS improves accuracy by 24.49% in multi-granularity segmentation, 17.88% in single-granularity segmentation, and up to 599.24% in transfer learning, demonstrating its adaptability to hierarchical states and evolving time series dynamics. Our code is available at https://github.com/blacksnail789521/PromptTSS.",
    "source": "arXiv"
  },
  {
    "title": "Fast Convergence for High-Order ODE Solvers in Diffusion Probabilistic Models",
    "title_es": "Fast Convergence for High-Order ODE Solvers in Diffusion Probabilistic Models",
    "url": "https://arxiv.org/abs/2506.13061",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.13061v3 Announce Type: replace \nAbstract: Diffusion probabilistic models generate samples by learning to reverse a noise-injection process that transforms data into noise. A key development is the reformulation of the reverse sampling process as a deterministic probability flow ordinary differential equation (ODE), which allows for efficient sampling using high-order numerical solvers. Unlike traditional time integrator analysis, the accuracy of this sampling procedure depends not only on numerical integration errors but also on the approximation quality and regularity of the learned score function, as well as their interaction. In this work, we present a rigorous convergence analysis of deterministic samplers derived from probability flow ODEs for general forward processes with arbitrary variance schedules. Specifically, we develop and analyze $p$-th order (exponential) Runge-Kutta schemes, under the practical assumption that the first and second derivatives of the learned score function are bounded. We prove that the total variation distance between the generated and target distributions can be bounded as \\begin{align*}\n  O\\bigl(d^{\\frac{7}{4}}\\varepsilon_{\\text{score}}^{\\frac{1}{2}} +d(dH_{\\max})^p\\bigr), \\end{align*} where $\\varepsilon^2_{\\text{score}}$ denotes the $L^2$ error in the score function approximation, $d$ is the data dimension, and $H_{\\max}$ represents the maximum solver step size. Numerical experiments on benchmark datasets further confirm that the derivatives of the learned score function are bounded in practice.",
    "source": "arXiv"
  },
  {
    "title": "Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Images",
    "title_es": "Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Images",
    "url": "https://arxiv.org/abs/2506.13307",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.13307v2 Announce Type: replace \nAbstract: We present a framework for adapting a large pretrained latent diffusion model to high-resolution Synthetic Aperture Radar (SAR) image generation. The approach enables controllable synthesis and the creation of rare or out-of-distribution scenes beyond the training set. Rather than training a task-specific small model from scratch, we adapt an open-source text-to-image foundation model to the SAR modality, using its semantic prior to align prompts with SAR imaging physics (side-looking geometry, slant-range projection, and coherent speckle with heavy-tailed statistics). Using a 100k-image SAR dataset, we compare full fine-tuning and parameter-efficient Low-Rank Adaptation (LoRA) across the UNet diffusion backbone, the Variational Autoencoder (VAE), and the text encoders. Evaluation combines (i) statistical distances to real SAR amplitude distributions, (ii) textural similarity via Gray-Level Co-occurrence Matrix (GLCM) descriptors, and (iii) semantic alignment using a SAR-specialized CLIP model. Our results show that a hybrid strategy-full UNet tuning with LoRA on the text encoders and a learned token embedding-best preserves SAR geometry and texture while maintaining prompt fidelity. The framework supports text-based control and multimodal conditioning (e.g., segmentation maps, TerraSAR-X, or optical guidance), opening new paths for large-scale SAR scene data augmentation and unseen scenario simulation in Earth observation.",
    "source": "arXiv"
  },
  {
    "title": "TD3Net: A temporal densely connected multi-dilated convolutional network for lipreading",
    "title_es": "TD3Net: A temporal densely connected multi-dilated convolutional network for lipreading",
    "url": "https://arxiv.org/abs/2506.16073",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.16073v3 Announce Type: replace \nAbstract: The word-level lipreading approach typically employs a two-stage framework with separate frontend and backend architectures to model dynamic lip movements. Each component has been extensively studied, and in the backend architecture, temporal convolutional networks (TCNs) have been widely adopted in state-of-the-art methods. Recently, dense skip connections have been introduced in TCNs to mitigate the limited density of the receptive field, thereby improving the modeling of complex temporal representations. However, their performance remains constrained owing to potential information loss regarding the continuous nature of lip movements, caused by blind spots in the receptive field. To address this limitation, we propose TD3Net, a temporal densely connected multi-dilated convolutional network that combines dense skip connections and multi-dilated temporal convolutions as the backend architecture. TD3Net covers a wide and dense receptive field without blind spots by applying different dilation factors to skip-connected features. Experimental results on a word-level lipreading task using two large publicly available datasets, Lip Reading in the Wild (LRW) and LRW-1000, indicate that the proposed method achieves performance comparable to state-of-the-art methods. It achieved higher accuracy with fewer parameters and lower floating-point operations compared to existing TCN-based backend architectures. Moreover, visualization results suggest that our approach effectively utilizes diverse temporal features while preserving temporal continuity, presenting notable advantages in lipreading systems. The code is available at our GitHub repository (https://github.com/Leebh-kor/TD3Net).",
    "source": "arXiv"
  },
  {
    "title": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability",
    "title_es": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability",
    "url": "https://arxiv.org/abs/2506.18248",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.18248v4 Announce Type: replace \nAbstract: Generative adversarial attacks train a perturbation generator on a white-box surrogate model and subsequently apply the crafted perturbations to unseen black-box victim models. In contrast to iterative attacks, these methods deliver superior inference-time efficiency, scalability, and transferability; however, up until now, existing studies have not fully exploited the representational capacity of generative models to preserve and harness semantic information. Specifically, the intermediate activations of the generator encode rich semantic features--object boundaries and coarse shapes--that remain under-exploited, thereby limiting the alignment of perturbations with object-salient regions which are critical for adversarial transferability. To remedy this, we introduce a semantic structure-aware attack framework based on the Mean Teacher, which serves as a temporally smoothed feature reference. With this smoothed reference, we further direct semantic consistency between the early-layer activations in the student and those of the semantically rich teacher by feature distillation. By anchoring perturbation synthesis to the semantically salient early intermediate blocks within the generator based on empirical findings, our method guides progressive adversarial perturbation on regions that substantially enhance adversarial transferability. We conduct extensive experiments over diverse models, domains and tasks to demonstrate consistent improvements relative to state-of-the-art generative attacks, comprehensively evaluated using conventional metrics and our newly proposed Accidental Correction Rate (ACR).",
    "source": "arXiv"
  },
  {
    "title": "VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory",
    "title_es": "VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory",
    "url": "https://arxiv.org/abs/2506.18903",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.18903v3 Announce Type: replace \nAbstract: We propose a novel memory module for building video generators capable of interactively exploring environments. Previous approaches have achieved similar results either by out-painting 2D views of a scene while incrementally reconstructing its 3D geometry-which quickly accumulates errors-or by using video generators with a short context window, which struggle to maintain scene coherence over the long term. To address these limitations, we introduce Surfel-Indexed View Memory (VMem), a memory module that remembers past views by indexing them geometrically based on the 3D surface elements (surfels) they have observed. VMem enables efficient retrieval of the most relevant past views when generating new ones. By focusing only on these relevant views, our method produces consistent explorations of imagined environments at a fraction of the computational cost required to use all past views as context. We evaluate our approach on challenging long-term scene synthesis benchmarks and demonstrate superior performance compared to existing methods in maintaining scene coherence and camera control.",
    "source": "arXiv"
  },
  {
    "title": "Discrepancy-Aware Graph Mask Auto-Encoder",
    "title_es": "Discrepancy-Aware Graph Mask Auto-Encoder",
    "url": "https://arxiv.org/abs/2506.19343",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.19343v2 Announce Type: replace \nAbstract: Masked Graph Auto-Encoder, a powerful graph self-supervised training paradigm, has recently shown superior performance in graph representation learning. Existing works typically rely on node contextual information to recover the masked information. However, they fail to generalize well to heterophilic graphs where connected nodes may be not similar, because they focus only on capturing the neighborhood information and ignoring the discrepancy information between different nodes, resulting in indistinguishable node representations. In this paper, to address this issue, we propose a Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE). It obtains more distinguishable node representations by reconstructing the discrepancy information of neighboring nodes during the masking process. We conduct extensive experiments on 17 widely-used benchmark datasets. The results show that our DGMAE can effectively preserve the discrepancies of nodes in low-dimensional space. Moreover, DGMAE significantly outperforms state-of-the-art graph self-supervised learning methods on three graph analytic including tasks node classification, node clustering, and graph classification, demonstrating its remarkable superiority. The code of DGMAE is available at https://github.com/zhengziyu77/DGMAE.",
    "source": "arXiv"
  },
  {
    "title": "Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos",
    "title_es": "Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos",
    "url": "https://arxiv.org/abs/2506.19445",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.19445v3 Announce Type: replace \nAbstract: We introduce the largest real-world image deblurring dataset constructed from smartphone slow-motion videos. Using 240 frames captured over one second, we simulate realistic long-exposure blur by averaging frames to produce blurry images, while using the temporally centered frame as the sharp reference. Our dataset contains over 42,000 high-resolution blur-sharp image pairs, making it approximately 10 times larger than widely used datasets, with 8 times the amount of different scenes, including indoor and outdoor environments, with varying object and camera motions. We benchmark multiple state-of-the-art (SOTA) deblurring models on our dataset and observe significant performance degradation, highlighting the complexity and diversity of our benchmark. Our dataset serves as a challenging new benchmark to facilitate robust and generalizable deblurring models.",
    "source": "arXiv"
  },
  {
    "title": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study",
    "title_es": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study",
    "url": "https://arxiv.org/abs/2506.19794",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.19794v4 Announce Type: replace \nAbstract: Large Language Models (LLMs) hold promise in automating data analysis tasks, yet open-source models face significant limitations in these kinds of reasoning-intensive scenarios. In this work, we investigate strategies to enhance the data analysis capabilities of open-source LLMs. By curating a seed dataset of diverse, realistic scenarios, we evaluate model behavior across three core dimensions: data understanding, code generation, and strategic planning. Our analysis reveals three key findings: (1) Strategic planning quality serves as the primary determinant of model performance; (2) Interaction design and task complexity significantly influence reasoning capabilities; (3) Data quality demonstrates a greater impact than diversity in achieving optimal performance. We leverage these insights to develop a data synthesis methodology, demonstrating significant improvements in open-source LLMs' analytical reasoning capabilities. Code is available at https://github.com/zjunlp/DataMind.",
    "source": "arXiv"
  },
  {
    "title": "From Data Center IoT Telemetry to Data Analytics Chatbots -- Virtual Knowledge Graph is All You Need",
    "title_es": "From Data Center IoT Telemetry to Data Analytics Chatbots -- Virtual Knowledge Graph is All You Need",
    "url": "https://arxiv.org/abs/2506.22267",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.22267v2 Announce Type: replace \nAbstract: Industry 5.0 demands IoT systems that support seamless human-machine collaboration, yet current IoT data analysis requires deep domain, deployment, and query expertise. We show that combining Large Language Models (LLMs) with Knowledge Graphs (KGs) enables natural language access to heterogeneous IoT data. Focusing on data center IoT telemetry, we introduce a rule-based Virtual Knowledge Graph (VKG) construction process and an on-premise LLM inference service to create an end-to-end Data Analytics (DA) chatbot. Our system dynamically generates VKGs per query and translates user input into SPARQL, achieving 92.5% accuracy (vs. 25% for LLM-to-NoSQL) while reducing latency by 85% (20.36s to 3.03s) and keeping VKG sizes under 179 MiB. This work demonstrates that VKG-powered LLM interfaces deliver accurate, low-latency, and relationship-aware access to large-scale telemetry, bridging the gap between users and complex IoT systems in Industry 5.0.",
    "source": "arXiv"
  },
  {
    "title": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models",
    "title_es": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models",
    "url": "https://arxiv.org/abs/2506.22493",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.22493v3 Announce Type: replace \nAbstract: Political Compass Test (PCT) or similar questionnaires have been used to quantify LLM's political leanings. Building on a recent line of work that examines the validity of PCT tests, we demonstrate that variation in standard generation parameters does not significantly impact the models' PCT scores. However, external factors such as prompt variations and fine-tuning individually and in combination affect the same. Finally, we demonstrate that when models are fine-tuned on text datasets with higher political content than others, the PCT scores are not differentially affected. This calls for a thorough investigation into the validity of PCT and similar tests, as well as the mechanism by which political leanings are encoded in LLMs.",
    "source": "arXiv"
  },
  {
    "title": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models",
    "title_es": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2506.23009",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2506.23009v3 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) have achieved remarkable visual reasoning abilities in natural images, text-rich documents, and graphic designs. However, their ability to interpret music sheets remains underexplored. To bridge this gap, we introduce MusiXQA, the first comprehensive dataset for evaluating and advancing MLLMs in music sheet understanding. MusiXQA features high-quality synthetic music sheets generated via MusiXTeX, with structured annotations covering note pitch and duration, chords, clefs, key/time signatures, and text, enabling diverse visual QA tasks. Through extensive evaluations, we reveal significant limitations of current state-of-the-art MLLMs in this domain. Beyond benchmarking, we developed Phi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant performance gains over GPT-based methods. The proposed dataset and model establish a foundation for future advances in MLLMs for music sheet understanding. Code, data, and model will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning",
    "title_es": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning",
    "url": "https://arxiv.org/abs/2507.01006",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.01006v4 Announce Type: replace \nAbstract: We present GLM-4.1V-Thinking and GLM-4.5V, a family of vision-language models (VLMs) designed to advance general-purpose multimodal understanding and reasoning. In this report, we share our key findings in the development of the reasoning-centric training framework. We first develop a capable vision foundation model with significant potential through large-scale pre-training, which arguably sets the upper bound for the final performance. We then propose Reinforcement Learning with Curriculum Sampling (RLCS) to unlock the full potential of the model, leading to comprehensive capability enhancement across a diverse range of tasks, including STEM problem solving, video understanding, content recognition, coding, grounding, GUI-based agents, and long document interpretation. In a comprehensive evaluation across 42 public benchmarks, GLM-4.5V achieves state-of-the-art performance on nearly all tasks among open-source models of similar size, and demonstrates competitive or even superior results compared to closed-source models such as Gemini-2.5-Flash on challenging tasks including Coding and GUI Agents. Meanwhile, the smaller GLM-4.1V-9B-Thinking remains highly competitive-achieving superior results to the much larger Qwen2.5-VL-72B on 29 benchmarks. We open-source both GLM-4.1V-9B-Thinking and GLM-4.5V. Code, models and more information are released at https://github.com/zai-org/GLM-V.",
    "source": "arXiv"
  },
  {
    "title": "AF-MAT: Aspect-aware Flip-and-Fuse xLSTM for Aspect-based Sentiment Analysis",
    "title_es": "AF-MAT: Aspect-aware Flip-and-Fuse xLSTM for Aspect-based Sentiment Analysis",
    "url": "https://arxiv.org/abs/2507.01213",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.01213v2 Announce Type: replace \nAbstract: Aspect-based Sentiment Analysis (ABSA) is a crucial NLP task that extracts fine-grained opinions and sentiments from text, such as product reviews and customer feedback. Existing methods often trade off efficiency for performance: traditional LSTM or RNN models struggle to capture long-range dependencies, transformer-based methods are computationally costly, and Mamba-based approaches rely on CUDA and weaken local dependency modeling. The recently proposed Extended Long Short-Term Memory (xLSTM) model offers a promising alternative by effectively capturing long-range dependencies through exponential gating and enhanced memory variants, sLSTM for modeling local dependencies, and mLSTM for scalable, parallelizable memory. However, xLSTM's application in ABSA remains unexplored. To address this, we introduce Aspect-aware Flip-and-Fuse xLSTM (AF-MAT), a framework that leverages xLSTM's strengths. AF-MAT features an Aspect-aware matrix LSTM (AA-mLSTM) mechanism that introduces a dedicated aspect gate, enabling the model to selectively emphasize tokens semantically relevant to the target aspect during memory updates. To model multi-scale context, we incorporate a FlipMix block that sequentially applies a partially flipped Conv1D (pf-Conv1D) to capture short-range dependencies in reverse order, followed by a fully flipped mLSTM (ff-mLSTM) to model long-range dependencies via full sequence reversal. Additionally, we propose MC2F, a lightweight Multihead Cross-Feature Fusion based on mLSTM gating, which dynamically fuses AA-mLSTM outputs (queries and keys) with FlipMix outputs (values) for adaptive representation integration. Experiments on three benchmark datasets demonstrate that AF-MAT outperforms state-of-the-art baselines, achieving higher accuracy in ABSA tasks.",
    "source": "arXiv"
  },
  {
    "title": "Constant-Approximate and Constant-Strategyproof Two-Facility Location",
    "title_es": "Constant-Approximate and Constant-Strategyproof Two-Facility Location",
    "url": "https://arxiv.org/abs/2507.04485",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.04485v3 Announce Type: replace \nAbstract: We study deterministic mechanisms for the two-facility location problem. Given the reported locations of n agents on the real line, such a mechanism specifies where to build the two facilities. The single-facility variant of this problem admits a simple strategyproof mechanism that minimizes social cost. For two facilities, however, it is known that any strategyproof mechanism is $\\Omega(n)$-approximate. We seek to circumvent this strong lower bound by relaxing the problem requirements. Following other work in the facility location literature, we consider a relaxed form of strategyproofness in which no agent can lie and improve their outcome by more than a constant factor. Because the aforementioned $\\Omega(n)$ lower bound generalizes easily to constant-strategyproof mechanisms, we introduce a second relaxation: Allowing the facilities (but not the agents) to be located in the plane. Our first main result is a natural mechanism for this relaxation that is constant-approximate and constant-strategyproof. A characteristic of this mechanism is that a small change in the input profile can produce a large change in the solution. Motivated by this observation, and also by results in the facility reallocation literature, our second main result is a constant-approximate, constant-strategyproof, and Lipschitz continuous mechanism.",
    "source": "arXiv"
  },
  {
    "title": "MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding",
    "title_es": "MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding",
    "url": "https://arxiv.org/abs/2507.06071",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.06071v4 Announce Type: replace \nAbstract: Audio-driven emotional 3D facial animation aims to generate synchronized lip movements and vivid facial expressions. However, most existing approaches focus on static and predefined emotion labels, limiting their diversity and naturalness. To address these challenges, we propose MEDTalk, a novel framework for fine-grained and dynamic emotional talking head generation. Our approach first disentangles content and emotion embedding spaces from motion sequences using a carefully designed cross-reconstruction process, enabling independent control over lip movements and facial expressions. Beyond conventional audio-driven lip synchronization, we integrate audio and speech text, predicting frame-wise intensity variations and dynamically adjusting static emotion features to generate realistic emotional expressions. Furthermore, to enhance control and personalization, we incorporate multimodal inputs-including text descriptions and reference expression images-to guide the generation of user-specified facial expressions. With MetaHuman as the priority, our generated results can be conveniently integrated into the industrial production pipeline. The code is available at: https://github.com/SJTU-Lucy/MEDTalk.",
    "source": "arXiv"
  },
  {
    "title": "Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits",
    "title_es": "Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits",
    "url": "https://arxiv.org/abs/2507.06535",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.06535v2 Announce Type: replace \nAbstract: Graph representation learning on Analog-Mixed Signal (AMS) circuits is crucial for various downstream tasks, e.g., parasitic estimation. However, the scarcity of design data, the unbalanced distribution of labels, and the inherent diversity of circuit implementations pose significant challenges to learning robust and transferable circuit representations. To address these limitations, we propose CircuitGCL, a novel graph contrastive learning framework that integrates representation scattering and label rebalancing to enhance transferability across heterogeneous circuit graphs. CircuitGCL employs a self-supervised strategy to learn topology-invariant node embeddings through hyperspherical representation scattering, eliminating dependency on large-scale data. Simultaneously, balanced mean squared error (BMSE) and balanced softmax cross-entropy (BSCE) losses are introduced to mitigate label distribution disparities between circuits, enabling robust and transferable parasitic estimation. Evaluated on parasitic capacitance estimation (edge-level task) and ground capacitance classification (node-level task) across TSMC 28nm AMS designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the $R^2$ improvement of $33.64\\% \\sim 44.20\\%$ for edge regression and F1-score gain of $0.9\\times \\sim 2.1\\times$ for node classification. Our code is available at https://github.com/ShenShan123/CircuitGCL.",
    "source": "arXiv"
  },
  {
    "title": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision",
    "title_es": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision",
    "url": "https://arxiv.org/abs/2507.06639",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.06639v2 Announce Type: replace \nAbstract: In digital pathology, whole-slide images (WSIs) are often difficult to handle due to their gigapixel scale, so most approaches train patch encoders via self-supervised learning (SSL) and then aggregate the patch-level embeddings via multiple instance learning (MIL) or slide encoders for downstream tasks. However, patch-level SSL may overlook complex domain-specific features that are essential for biomarker prediction, such as mutation status and molecular characteristics, as SSL methods rely only on basic augmentations selected for natural image domains on small patch-level area. Moreover, SSL methods remain less data efficient than fully supervised approaches, requiring extensive computational resources and datasets to achieve competitive performance. To address these limitations, we present EXAONE Path 2.0, a pathology foundation model that learns patch-level representations under direct slide-level supervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves state-of-the-art average performance across 10 biomarker prediction tasks, demonstrating remarkable data efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Detec\\c{c}\\~ao de Conflitos Sem\\^anticos com Testes Gerados por LLM",
    "title_es": "Detec\\c{c}\\~ao de Conflitos Sem\\^anticos com Testes Gerados por LLM",
    "url": "https://arxiv.org/abs/2507.06762",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.06762v2 Announce Type: replace \nAbstract: Semantic conflicts arise when a developer introduces changes to a codebase that unintentionally affect the behavior of changes integrated in parallel by other developers. Traditional merge tools are unable to detect such conflicts, so complementary tools like SMAT have been proposed. SMAT relies on generating and executing unit tests: if a test fails on the base version, passes on a developer's modified version, but fails again after merging with another developer's changes, a semantic conflict is indicated. While SMAT is effective at detecting conflicts, it suffers from a high rate of false negatives, partly due to the limitations of unit test generation tools such as Randoop and Evosuite. To investigate whether large language models (LLMs) can overcome these limitations, we propose and integrate a new test generation tool based on Code Llama 70B into SMAT. We explore the model's ability to generate tests using different interaction strategies, prompt contents, and parameter configurations. Our evaluation uses two samples: a benchmark with simpler systems from related work, and a more significant sample based on complex, real-world systems. We assess the effectiveness of the new SMAT extension in detecting conflicts. Results indicate that, although LLM-based test generation remains challenging and computationally expensive in complex scenarios, there is promising potential for improving semantic conflict detection.",
    "source": "arXiv"
  },
  {
    "title": "Common Data Properties Limit Object-Attribute Binding in CLIP",
    "title_es": "Common Data Properties Limit Object-Attribute Binding in CLIP",
    "url": "https://arxiv.org/abs/2507.07985",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.07985v2 Announce Type: replace \nAbstract: Contrastive vision-language models like CLIP are used for a large variety of applications, such as zero-shot classification or as vision encoder for multi-modal models. Despite their popularity, their representations show major limitations. For instance, CLIP models learn bag-of-words representations and, as a consequence, fail to distinguish whether an image is of ``a yellow submarine and a blue bus'' or ``a blue submarine and a yellow bus''. Previous attempts to fix this issue added hard negatives during training or modified the architecture, but failed to resolve the problem in its entirety. We suspect that the missing insights to solve the binding problem for CLIP are hidden in arguably the most important part of learning algorithms: the data. In this work, we fill this gap by rigorously identifying the influence of data properties on CLIP's ability to learn binding using a synthetic dataset. We find that common properties of natural data such as low attribute density, incomplete captions, and the saliency bias, a tendency of human captioners to describe the object that is ``most salient'' to them, have a detrimental effect on binding performance. In contrast to common belief, we find that neither scaling the batch size, i.e., implicitly adding more hard negatives, nor explicitly creating hard negatives enables CLIP to learn reliable binding. Only when the data expresses our identified data properties does CLIP learn almost perfect binding.",
    "source": "arXiv"
  },
  {
    "title": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation",
    "title_es": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation",
    "url": "https://arxiv.org/abs/2507.08307",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.08307v3 Announce Type: replace \nAbstract: Audio-driven talking head generation holds significant potential for film production. While existing 3D methods have advanced motion modeling and content synthesis, they often produce rendering artifacts, such as motion blur, temporal jitter, and local penetration, due to limitations in representing stable, fine-grained motion fields. Through systematic analysis, we reformulate talking head generation into a unified framework comprising three steps: video preprocessing, motion representation, and rendering reconstruction. This framework underpins our proposed M2DAO-Talker, which addresses current limitations via multi-granular motion decoupling and alternating optimization. Specifically, we devise a novel 2D portrait preprocessing pipeline to extract frame-wise deformation control conditions (motion region segmentation masks, and camera parameters) to facilitate motion representation. To ameliorate motion modeling, we elaborate a multi-granular motion decoupling strategy, which independently models non-rigid (oral and facial) and rigid (head) motions for improved reconstruction accuracy. Meanwhile, a motion consistency constraint is developed to ensure head-torso kinematic consistency, thereby mitigating penetration artifacts caused by motion aliasing. In addition, an alternating optimization strategy is designed to iteratively refine facial and oral motion parameters, enabling more realistic video generation. Experiments across multiple datasets show that M2DAO-Talker achieves state-of-the-art performance, with the 2.43 dB PSNR improvement in generation quality and 0.64 gain in user-evaluated video realness versus TalkingGaussian while with 150 FPS inference speed. Our project homepage is https://m2dao-talker.github.io/M2DAO-Talk.github.io.",
    "source": "arXiv"
  },
  {
    "title": "On Lattice Isomorphism Problems for Lattices from LCD Codes over Finite Rings",
    "title_es": "On Lattice Isomorphism Problems for Lattices from LCD Codes over Finite Rings",
    "url": "https://arxiv.org/abs/2507.09257",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.09257v3 Announce Type: replace \nAbstract: These days, post-quantum cryptography based on the lattice isomorphism problem has been proposed. Ducas-Gibbons introduced the hull attack, which solves the lattice isomorphism problem for lattices obtained by Construction A from an LCD code over a finite field. Using this attack, they showed that the lattice isomorphism problem for such lattices can be reduced to the lattice isomorphism problem with the trivial lattice $\\mathbb{Z}^n$ and the graph isomorphism problem. While the previous work by Ducas-Gibbons only considered lattices constructed by a code over a \\textit{finite field}, this paper considers lattices constructed by a code over a \\textit{finite ring} $\\mathbb{Z}/k\\mathbb{Z}$, which is a more general case. In particular, when $k$ is odd, an odd prime power, or not divisible by $4$, we show that the lattice isomorphism problem can be reduced to the lattice isomorphism problem for $\\mathbb{Z}^n$ and the graph isomorphism problem.",
    "source": "arXiv"
  },
  {
    "title": "Rule-based Generation of de Bruijn Sequences: Memory and Learning",
    "title_es": "Rule-based Generation of de Bruijn Sequences: Memory and Learning",
    "url": "https://arxiv.org/abs/2507.09764",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.09764v2 Announce Type: replace \nAbstract: We investigate binary sequences generated by non-Markovian rules with memory length $\\mu$, similar to those adopted in Elementary Cellular Automata. This generation procedure is equivalente to a shift register and certain rules produce sequences with maximal periods, known as de Bruijn sequences. We introduce a novel methodology for generating de Bruijn sequences that combines: (i) a set of derived properties that significantly reduce the space of feasible generating rules, and (ii) a neural network-based classifier that identifies which rules produce de Bruijn sequences. Experiments for large values of $\\mu$ demonstrate the approach's effectiveness and computational efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Meanings are like Onions: a Layered Approach to Metaphor Processing",
    "title_es": "Meanings are like Onions: a Layered Approach to Metaphor Processing",
    "url": "https://arxiv.org/abs/2507.10354",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.10354v2 Announce Type: replace \nAbstract: Metaphorical meaning is not a flat mapping between concepts, but a complex cognitive phenomenon that integrates multiple levels of interpretation. In this paper, we propose a stratified model of metaphor processing that treats meaning as an onion: a multi-layered structure comprising (1) content analysis, (2) conceptual blending, and (3) pragmatic intentionality. This three-dimensional framework allows for a richer and more cognitively grounded approach to metaphor interpretation in computational systems. At the first level, metaphors are annotated through basic conceptual elements. At the second level, we model conceptual combinations, linking components to emergent meanings. Finally, at the third level, we introduce a pragmatic vocabulary to capture speaker intent, communicative function, and contextual effects, aligning metaphor understanding with pragmatic theories. By unifying these layers into a single formal framework, our model lays the groundwork for computational methods capable of representing metaphorical meaning beyond surface associations, toward deeper, more context-sensitive reasoning.",
    "source": "arXiv"
  },
  {
    "title": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks",
    "title_es": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks",
    "url": "https://arxiv.org/abs/2507.10535",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.10535v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have significantly advanced the state-of-the-art in various coding tasks. Beyond directly answering user queries, LLMs can also serve as judges, assessing and comparing the quality of responses generated by other models. Such an evaluation capability is crucial both for benchmarking different LLMs and for improving response quality through response ranking. However, despite the growing adoption of the LLM-as-a-Judge paradigm, its effectiveness in coding scenarios remains underexplored due to the absence of dedicated benchmarks. To address this gap, we introduce CodeJudgeBench, a benchmark explicitly designed to evaluate the performance of LLM-as-a-Judge models across three critical coding tasks: code generation, code repair, and unit test generation. Through comprehensive benchmarking of 26 LLM-as-a-Judge models, we find that recent thinking models significantly outperform non-thinking models on our carefully designed code judging tasks. Notably, even relatively small thinking models, such as Qwen3-8B, can outperform specially trained LLM-as-a-Judge models up to 70B in size. Nevertheless, all models still exhibit significant randomness in their judgment of coding tasks. For pairwise judging tasks, simply changing the order in which responses are presented can substantially impact accuracy. In addition, when judging code and unit tests written by different LLMs, LLM-as-a-Judge models also show variance in performance. This sensitivity raises concerns about the reliability and consistency of LLM-as-a-Judge in coding scenarios. Lastly, we study optimal prompting strategies for LLM-as-a-Judge. We find that using pair-wise comparison outperforms scalar point-wise judging. Furthermore, retaining comments and reasoning in the full, unprocessed LLM response leads to improved judge performance.",
    "source": "arXiv"
  },
  {
    "title": "Warehouse Spatial Question Answering with LLM Agent",
    "title_es": "Warehouse Spatial Question Answering with LLM Agent",
    "url": "https://arxiv.org/abs/2507.10778",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.10778v2 Announce Type: replace \nAbstract: Spatial understanding has been a challenging task for existing Multi-modal Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM finetuning to enhance MLLM's spatial understanding ability. In this paper, we present a data-efficient approach. We propose a LLM agent system with strong and advanced spatial reasoning ability, which can be used to solve the challenging spatial question answering task in complex indoor warehouse scenarios. Our system integrates multiple tools that allow the LLM agent to conduct spatial reasoning and API tools interaction to answer the given complicated spatial question. Extensive evaluations on the 2025 AI City Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that our system achieves high accuracy and efficiency in tasks such as object retrieval, counting, and distance estimation. The code is available at: https://github.com/hsiangwei0903/SpatialAgent",
    "source": "arXiv"
  },
  {
    "title": "Class-Proportional Coreset Selection for Difficulty-Separable Data",
    "title_es": "Class-Proportional Coreset Selection for Difficulty-Separable Data",
    "url": "https://arxiv.org/abs/2507.10904",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.10904v2 Announce Type: replace \nAbstract: High-quality training data is essential for building reliable and efficient machine learning systems. One-shot coreset selection addresses this by pruning the dataset while maintaining or even improving model performance, often relying on training-dynamics-based data difficulty scores. However, most existing methods implicitly assume class-wise homogeneity in data difficulty, overlooking variation in data difficulty across different classes. In this work, we challenge this assumption by showing that, in domains such as network intrusion detection and medical imaging, data difficulty often clusters by class. We formalize this as class-difficulty separability and introduce the Class Difficulty Separability Coefficient (CDSC) as a quantitative measure. We demonstrate that high CDSC values correlate with performance degradation in class-agnostic coreset methods, which tend to overrepresent easy majority classes while neglecting rare but informative ones. To address this, we introduce class-proportional variants of multiple sampling strategies. Evaluated on five diverse datasets spanning security and medical domains, our methods consistently achieve state-of-the-art performance. For instance, on CTU-13, at an extreme 99% pruning rate, a class-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows remarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and recall 0.19%. In contrast, the class-agnostic CCS baseline, the next best method, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and 4.11% in recall. We further show that aggressive pruning enhances generalization in noisy, imbalanced, and large-scale datasets. Our results underscore that explicitly modeling class-difficulty separability leads to more effective, robust, and generalizable data pruning, particularly in high-stakes scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication",
    "title_es": "Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication",
    "url": "https://arxiv.org/abs/2507.13470",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.13470v2 Announce Type: replace \nAbstract: Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \\subseteq V$ of $|S| = n^{\\sigma}$ (for some $0 \\le \\sigma \\le 1$) designated sources, the $S \\times V$ reachability problem is to compute the sets $\\mathcal V_s$ of vertices reachable from $s$, for every $s \\in S$. Naive centralized algorithms run BFS/DFS from each source in $O(m \\cdot n^{\\sigma})$ time or compute $G$'s transitive closure in $\\hat O(n^{\\omega})$ time, where $\\omega \\le 2.371552\\ldots$ is the matrix multiplication exponent. Thus, the best known bound is $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$. Leveraging shortcut constructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a centralized algorithm with running time $\\hat O(n^{1 + \\frac{2}{3} \\omega(\\sigma)})$, where $\\omega(\\sigma)$ is the rectangular matrix multiplication exponent. Using current estimates on $\\omega(\\sigma)$, our exponent improves upon $\\min \\{2 + \\sigma, \\omega \\}$ for $\\tilde \\sigma \\leq \\sigma \\leq 0.53$, where $1/3 < \\tilde \\sigma < 0.3336$ is a universal constant.\n  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel algorithms for $S \\times V$ reachability on graphs admitting balanced recursive separators of size $n^{\\rho}$ for $\\rho < 1$, requiring polylogarithmic time and work $n^{\\max \\{\\omega \\rho, 2\\rho + \\sigma \\} + o(1)}$. We significantly improve, extend, and generalize Cohen's result. First, our parallel algorithm for graphs with small recursive separators has lower work complexity than Cohen's in boraod paramater ranges. Second, we generalize our algorithm to graphs of treewidth at most $n^{\\rho}$ ($\\rho < 1$) and provide a centralized algorithm that outperforms existing bounds for $S \\times V$ reachability on such graphs. We also do this for some other graph familes with small separators. Finally, we extend these results to $(1 + \\epsilon)$-approximate distance computation.",
    "source": "arXiv"
  },
  {
    "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base",
    "title_es": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base",
    "url": "https://arxiv.org/abs/2507.14189",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.14189v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in various applications. However, their use as writing assistants in specialized domains like finance, medicine, and law is often hampered by a lack of deep domain-specific knowledge and a tendency to hallucinate. Existing solutions, such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency across multiple retrieval steps, while online search-based methods often degrade quality due to unreliable web content. To address these challenges, we introduce DeepWriter, a customizable, multimodal, long-form writing assistant that operates on a curated, offline knowledge base. DeepWriter leverages a novel pipeline that involves task decomposition, outline generation, multimodal retrieval, and section-by-section composition with reflection. By deeply mining information from a structured corpus and incorporating both textual and visual elements, DeepWriter generates coherent, factually grounded, and professional-grade documents. We also propose a hierarchical knowledge representation to enhance retrieval efficiency and accuracy. Our experiments on financial report generation demonstrate that DeepWriter produces high-quality, verifiable articles that surpasses existing baselines in factual accuracy and generated content quality.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models",
    "title_es": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models",
    "url": "https://arxiv.org/abs/2507.14976",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.14976v2 Announce Type: replace \nAbstract: Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent generalization abilities. However, adapting these large-scale models to downstream tasks while preserving their generalization capabilities remains challenging. Although prompt learning methods have shown promise, they suffer from two fundamental bottlenecks that limit generalization: (a) modality isolation, and (b) hierarchical semantic decay. To address these limitations, we propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that establishes bidirectional knowledge flow between text and vision modalities, enabling them to refine their semantics mutually. HiCroPL routes knowledge flows by leveraging the complementary strengths of text and vision. In early layers, text prompts inject relatively clear semantics into visual prompts through a hierarchical knowledge mapper, enhancing the representation of low-level visual semantics. In later layers, visual prompts encoding specific task-relevant objects flow back to refine text prompts, enabling deeper alignment. Crucially, our hierarchical knowledge mapper allows representations at multi-scales to be fused, ensuring that deeper representations retain transferable shallow semantics thereby enhancing generalization. We further introduce a lightweight layer-specific knowledge proxy to enable efficient cross-modal interactions. Extensive evaluations across four tasks demonstrate HiCroPL's superior performance, achieving state-of-the-art results on 11 benchmarks with significant improvements. Code is available at: https://github.com/zzeoZheng/HiCroPL.",
    "source": "arXiv"
  },
  {
    "title": "MAP Estimation with Denoisers: Convergence Rates and Guarantees",
    "title_es": "MAP Estimation with Denoisers: Convergence Rates and Guarantees",
    "url": "https://arxiv.org/abs/2507.15397",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.15397v2 Announce Type: replace \nAbstract: Denoiser models have become powerful tools for inverse problems, enabling the use of pretrained networks to approximate the score of a smoothed prior distribution. These models are often used in heuristic iterative schemes aimed at solving Maximum a Posteriori (MAP) optimisation problems, where the proximal operator of the negative log-prior plays a central role. In practice, this operator is intractable, and practitioners plug in a pretrained denoiser as a surrogate-despite the lack of general theoretical justification for this substitution. In this work, we show that a simple algorithm, closely related to several used in practice, provably converges to the proximal operator under a log-concavity assumption on the prior $p$. We show that this algorithm can be interpreted as a gradient descent on smoothed proximal objectives. Our analysis thus provides a theoretical foundation for a class of empirically successful but previously heuristic methods.",
    "source": "arXiv"
  },
  {
    "title": "Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding",
    "title_es": "Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding",
    "url": "https://arxiv.org/abs/2507.15604",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.15604v2 Announce Type: replace \nAbstract: As the availability of cobots increases, it is essential to address the needs of users with little to no programming knowledge to operate such systems efficiently. Programming concepts often use intuitive interaction modalities, such as hand guiding, to address this. When programming in-contact motions, such frameworks require knowledge of the robot tool's payload inertial parameters (PIP) in addition to the demonstrated velocities and forces to ensure effective hybrid motion-force control. This paper aims to enable non-expert users to program in-contact motions more efficiently by eliminating the need for a dedicated PIP calibration, thereby enabling flexible robot tool changes. Since demonstrated tasks generally also contain motions with non-contact, our approach uses these parts to estimate the robot's PIP using established estimation techniques. The results show that the estimation of the payload's mass is accurate, whereas the center of mass and the inertia tensor are affected by noise and a lack of excitation. Overall, these findings show the feasibility of PIP estimation during hand guiding but also highlight the need for sufficient payload accelerations for an accurate estimation.",
    "source": "arXiv"
  },
  {
    "title": "Optimizing Force Signals from Human Demonstrations of In-Contact Motions",
    "title_es": "Optimizing Force Signals from Human Demonstrations of In-Contact Motions",
    "url": "https://arxiv.org/abs/2507.15608",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.15608v2 Announce Type: replace \nAbstract: For non-robot-programming experts, kinesthetic guiding can be an intuitive input method, as robot programming of in-contact tasks is becoming more prominent. However, imprecise and noisy input signals from human demonstrations pose problems when reproducing motions directly or using the signal as input for machine learning methods. This paper explores optimizing force signals to correspond better to the human intention of the demonstrated signal. We compare different signal filtering methods and propose a peak detection method for dealing with first-contact deviations in the signal. The evaluation of these methods considers a specialized error criterion between the input and the human-intended signal. In addition, we analyze the critical parameters' influence on the filtering methods. The quality for an individual motion could be increased by up to \\SI{20}{\\percent} concerning the error criterion. The proposed contribution can improve the usability of robot programming and the interaction between humans and robots.",
    "source": "arXiv"
  },
  {
    "title": "Competitive Algorithms for Multi-Agent Ski-Rental Problems",
    "title_es": "Competitive Algorithms for Multi-Agent Ski-Rental Problems",
    "url": "https://arxiv.org/abs/2507.15727",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.15727v2 Announce Type: replace \nAbstract: This paper introduces a novel multi-agent ski-rental problem that generalizes the classical ski-rental dilemma to a group setting where agents incur individual and shared costs. In our model, each agent can either rent at a fixed daily cost, or purchase a pass at an individual cost, with an additional third option of a discounted group pass available to all. We consider scenarios in which agents' active days differ, leading to dynamic states as agents drop out of the decision process. To address this problem from different perspectives, we define three distinct competitive ratios: overall, state-dependent, and individual rational. For each objective, we design and analyze optimal deterministic and randomized policies. Our deterministic policies employ state-aware threshold functions that adapt to the dynamic states, while our randomized policies sample and resample thresholds from tailored state-aware distributions. The analysis reveals that symmetric policies, in which all agents use the same threshold, outperform asymmetric ones. Our results provide competitive ratio upper and lower bounds and extend classical ski-rental insights to multi-agent settings, highlighting both theoretical and practical implications for group decision-making under uncertainty.",
    "source": "arXiv"
  },
  {
    "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization",
    "title_es": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization",
    "url": "https://arxiv.org/abs/2507.15758",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.15758v2 Announce Type: replace \nAbstract: Large reasoning models have achieved remarkable performance through extended chain-of-thought sequences, yet this computational freedom leads to excessive token generation even for simple problems. We present Length-Adaptive Policy Optimization (LAPO), a novel framework that transforms reasoning length control from an external constraint into an intrinsic model capability. Unlike existing approaches that impose rigid limits or rely on post-hoc interventions, LAPO enables models to internalize an understanding of appropriate reasoning depth through a two-stage reinforcement learning process. In the first stage, models learn natural reasoning patterns by discovering the statistical distribution of successful solution lengths. The second stage leverages these patterns as meta-cognitive guidance, embedding them directly within the model's reasoning context to ensure inference-time flexibility. Experiments on mathematical reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9% while improving accuracy by 2.3%. Our analysis reveals that models trained with LAPO develop emergent abilities to allocate computational resources based on problem complexity, achieving efficient reasoning without sacrificing quality.",
    "source": "arXiv"
  },
  {
    "title": "Smooth Games of Configuration in the Linear-Quadratic Setting",
    "title_es": "Smooth Games of Configuration in the Linear-Quadratic Setting",
    "url": "https://arxiv.org/abs/2507.16611",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.16611v2 Announce Type: replace \nAbstract: Dynamic game theory offers a toolbox for formalizing and solving for both cooperative and non-cooperative strategies in multi-agent scenarios. However, the optimal configuration of such games remains largely unexplored. While there is existing literature on the parametrization of dynamic games, little research examines this parametrization from a strategic perspective where each agent's configuration choice is influenced by the decisions of others. In this work, we introduce the concept of a game of configuration, providing a framework for the strategic fine-tuning of differential games. We define a game of configuration as a two-stage game within the setting of finite-horizon, affine-quadratic, AQ, differential games. In the first stage, each player chooses their corresponding configuration parameter, which will impact their dynamics and costs in the second stage. We provide the subgame perfect solution concept and a method for computing first stage cost gradients over the configuration space. This then allows us to formulate a gradient-based method for searching for local solutions to the configuration game, as well as provide necessary conditions for equilibrium configurations over their downstream (second stage) trajectories. We conclude by demonstrating the effectiveness of our approach in example AQ systems, both zero-sum and general-sum.",
    "source": "arXiv"
  },
  {
    "title": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning",
    "title_es": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning",
    "url": "https://arxiv.org/abs/2507.19712",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.19712v2 Announce Type: replace \nAbstract: In this paper, we explore mission assignment and task offloading in an Open Radio Access Network (Open RAN)-based intelligent transportation system (ITS), where autonomous vehicles leverage mobile edge computing for efficient processing. Existing studies often overlook the intricate interdependencies between missions and the costs associated with offloading tasks to edge servers, leading to suboptimal decision-making. To bridge this gap, we introduce Oranits, a novel system model that explicitly accounts for mission dependencies and offloading costs while optimizing performance through vehicle cooperation. To achieve this, we propose a twofold optimization approach. First, we develop a metaheuristic-based evolutionary computing algorithm, namely the Chaotic Gaussian-based Global ARO (CGG-ARO), serving as a baseline for one-slot optimization. Second, we design an enhanced reward-based deep reinforcement learning (DRL) framework, referred to as the Multi-agent Double Deep Q-Network (MA-DDQN), that integrates both multi-agent coordination and multi-action selection mechanisms, significantly reducing mission assignment time and improving adaptability over baseline methods. Extensive simulations reveal that CGG-ARO improves the number of completed missions and overall benefit by approximately 7.1% and 7.7%, respectively. Meanwhile, MA-DDQN achieves even greater improvements of 11.0% in terms of mission completions and 12.5% in terms of the overall benefit. These results highlight the effectiveness of Oranits in enabling faster, more adaptive, and more efficient task processing in dynamic ITS environments.",
    "source": "arXiv"
  },
  {
    "title": "Synthesis Benchmarks for Automated Reasoning",
    "title_es": "Synthesis Benchmarks for Automated Reasoning",
    "url": "https://arxiv.org/abs/2507.19827",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.19827v3 Announce Type: replace \nAbstract: Program synthesis is the task of constructing a program conforming to a given specification. We focus on deductive synthesis, and in particular on synthesis problems with specifications given as $\\forall\\exists$-formulas, expressing the existence of an output corresponding to any input. So far there has been no canonical benchmark set for deductive synthesis using the $\\forall\\exists$-format and supporting the so-called uncomputable symbol restriction. This work presents such a data set, composed by complementing existing benchmarks by new ones. Our data set is dynamically growing and should motivate future developments in the theory and practice of automating synthesis.",
    "source": "arXiv"
  },
  {
    "title": "FedABC: Attention-Based Client Selection for Federated Learning with Long-Term View",
    "title_es": "FedABC: Attention-Based Client Selection for Federated Learning with Long-Term View",
    "url": "https://arxiv.org/abs/2507.20871",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.20871v2 Announce Type: replace \nAbstract: Native AI support is a key objective in the evolution of 6G networks, with Federated Learning (FL) emerging as a promising paradigm. FL allows decentralized clients to collaboratively train an AI model without directly sharing their data, preserving privacy. Clients train local models on private data and share model updates, which a central server aggregates to refine the global model and redistribute it for the next iteration. However, client data heterogeneity slows convergence and reduces model accuracy, and frequent client participation imposes communication and computational burdens. To address these challenges, we propose FedABC, an innovative client selection algorithm designed to take a long-term view in managing data heterogeneity and optimizing client participation. Inspired by attention mechanisms, FedABC prioritizes informative clients by evaluating both model similarity and each model's unique contributions to the global model. Moreover, considering the evolving demands of the global model, we formulate an optimization problem to guide FedABC throughout the training process. Following the \"later-is-better\" principle, FedABC adaptively adjusts the client selection threshold, encouraging greater participation in later training stages. Extensive simulations on CIFAR-10 demonstrate that FedABC significantly outperforms existing approaches in model accuracy and client participation efficiency, achieving comparable performance with 32% fewer clients than the classical FL algorithm FedAvg, and 3.5% higher accuracy with 2% fewer clients than the state-of-the-art. This work marks a step toward deploying FL in heterogeneous, resource-constrained environments, thereby supporting native AI capabilities in 6G networks.",
    "source": "arXiv"
  },
  {
    "title": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?",
    "title_es": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?",
    "url": "https://arxiv.org/abs/2507.21817",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.21817v3 Announce Type: replace \nAbstract: Automated vulnerability detection research has made substantial progress, yet its real-world impact remains limited. Current vulnerability datasets suffer from issues including label inaccuracy rates of 20-71%, extensive duplication, and poor coverage of critical CWE types. These issues create a significant \"generalization gap\" where models achieve misleading self-testing performance (measured on held-out data from the same dataset for training) by exploiting spurious correlations rather than learning true vulnerability patterns. Our analysis reveals that many models experience substantial performance drops of up to 33% when evaluated on independent data, with some performing close to random guessing. To address these limitations, we present a three-part solution. First, we introduce a manually curated test dataset, BenchVul, covering the MITRE Top 25 Most Dangerous CWEs. Second, we construct a high-quality training dataset, TitanVul, comprising 38,863 functions by aggregating seven public sources and applying deduplication and validation using a novel multi-agent LLM framework. Third, we propose a Realistic Vulnerability Generation (RVG) framework, which synthesizes context-aware vulnerability examples for underrepresented but critical CWE types through simulated development workflows. Our evaluation shows the strengths of each component in closing the generalization gap. First, BenchVul shows the limitations of self-testing: models trained on existing datasets, such as BigVul and CVEfixes, experience performance drops on BenchVul (from 0.776 to 0.519 and from 0.713 to 0.607). Second, training models on TitanVul demonstrates improved generalization, with model performance increasing from 0.584 when evaluated on the same dataset to 0.767 when tested on BenchVul. Third, supplementing TitanVul with RVG-generated data yields further gains, increasing model performance by 14.0% to 0.874.",
    "source": "arXiv"
  },
  {
    "title": "Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition",
    "title_es": "Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition",
    "url": "https://arxiv.org/abs/2507.21977",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.21977v3 Announce Type: replace \nAbstract: Micro-Actions (MAs) are an important form of non-verbal communication in social interactions, with potential applications in human emotional analysis. However, existing methods in Micro-Action Recognition often overlook the inherent subtle changes in MAs, which limits the accuracy of distinguishing MAs with subtle changes. To address this issue, we present a novel Motion-guided Modulation Network (MMN) that implicitly captures and modulates subtle motion cues to enhance spatial-temporal representation learning. Specifically, we introduce a Motion-guided Skeletal Modulation module (MSM) to inject motion cues at the skeletal level, acting as a control signal to guide spatial representation modeling. In parallel, we design a Motion-guided Temporal Modulation module (MTM) to incorporate motion information at the frame level, facilitating the modeling of holistic motion patterns in micro-actions. Finally, we propose a motion consistency learning strategy to aggregate the motion cues from multi-scale features for micro-action classification. Experimental results on the Micro-Action 52 and iMiGUE datasets demonstrate that MMN achieves state-of-the-art performance in skeleton-based micro-action recognition, underscoring the importance of explicitly modeling subtle motion cues. The code will be available at https://github.com/momiji-bit/MMN.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making",
    "title_es": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making",
    "url": "https://arxiv.org/abs/2507.22365",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.22365v2 Announce Type: replace \nAbstract: In settings where human decision-making relies on AI input, both the predictive accuracy of the AI system and the reliability of its confidence estimates influence decision quality. We highlight the role of AI metacognitive sensitivity -- its ability to assign confidence scores that accurately distinguish correct from incorrect predictions -- and introduce a theoretical framework for assessing the joint impact of AI's predictive accuracy and metacognitive sensitivity in hybrid decision-making settings. Our analysis identifies conditions under which an AI with lower predictive accuracy but higher metacognitive sensitivity can enhance the overall accuracy of human decision making. Finally, a behavioral experiment confirms that greater AI metacognitive sensitivity improves human decision performance. Together, these findings underscore the importance of evaluating AI assistance not only by accuracy but also by metacognitive sensitivity, and of optimizing both to achieve superior decision outcomes.",
    "source": "arXiv"
  },
  {
    "title": "Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring",
    "title_es": "Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring",
    "url": "https://arxiv.org/abs/2507.22369",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.22369v2 Announce Type: replace \nAbstract: Classroom behavior monitoring is a critical aspect of educational research, with significant implications for student engagement and learning outcomes. Recent advancements in Visual Question Answering (VQA) models offer promising tools for automatically analyzing complex classroom interactions from video recordings. In this paper, we investigate the applicability of several state-of-the-art open-source VQA models, including LLaMA2, LLaMA3, QWEN3, and NVILA, in the context of classroom behavior analysis. To facilitate rigorous evaluation, we introduce our BAV-Classroom-VQA dataset derived from real-world classroom video recordings at the Banking Academy of Vietnam. We present the methodology for data collection, annotation, and benchmark the performance of the selected VQA models on this dataset. Our initial experimental results demonstrate that all four models achieve promising performance levels in answering behavior-related visual questions, showcasing their potential in future classroom analytics and intervention systems.",
    "source": "arXiv"
  },
  {
    "title": "On the Definition of Intelligence",
    "title_es": "On the Definition of Intelligence",
    "url": "https://arxiv.org/abs/2507.22423",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.22423v2 Announce Type: replace \nAbstract: To engineer AGI, we should first capture the essence of intelligence in a species-agnostic form that can be evaluated, while being sufficiently general to encompass diverse paradigms of intelligent behavior, including reinforcement learning, generative models, classification, analogical reasoning, and goal-directed decision-making. We propose a general criterion based on \\textit{entity fidelity}: Intelligence is the ability, given entities exemplifying a concept, to generate entities exemplifying the same concept. We formalise this intuition as \\(\\varepsilon\\)-concept intelligence: it is \\(\\varepsilon\\)-intelligent with respect to a concept if no chosen admissible distinguisher can separate generated entities from original entities beyond tolerance \\(\\varepsilon\\). We present the formal framework, outline empirical protocols, and discuss implications for evaluation, safety, and generalization.",
    "source": "arXiv"
  },
  {
    "title": "A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks",
    "title_es": "A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks",
    "url": "https://arxiv.org/abs/2507.22733",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.22733v2 Announce Type: replace \nAbstract: Structure and continuous motion estimation from point correspondences is a fundamental problem in computer vision that has been powered by well-known algorithms such as the familiar 5-point or 8-point algorithm. However, despite their acclaim, these algorithms are limited to processing point correspondences originating from a pair of views each one representing an instantaneous capture of the scene. Yet, in the case of rolling shutter cameras, or more recently, event cameras, this synchronization breaks down. In this work, we present a unified approach for structure and linear motion estimation from 2D point correspondences with arbitrary timestamps, from an arbitrary set of views. By formulating the problem in terms of first-order dynamics and leveraging a constant velocity motion model, we derive a novel, linear point incidence relation allowing for the efficient recovery of both linear velocity and 3D points with predictable degeneracies and solution multiplicities. Owing to its general formulation, it can handle correspondences from a wide range of sensing modalities such as global shutter, rolling shutter, and event cameras, and can even combine correspondences from different collocated sensors. We validate the effectiveness of our solver on both simulated and real-world data, where we show consistent improvement across all modalities when compared to recent approaches. We believe our work opens the door to efficient structure and motion estimation from asynchronous data. Code can be found at https://github.com/suhang99/AsyncTrack-Motion-Solver.",
    "source": "arXiv"
  },
  {
    "title": "TextQuests: How Good are LLMs at Text-Based Video Games?",
    "title_es": "TextQuests: How Good are LLMs at Text-Based Video Games?",
    "url": "https://arxiv.org/abs/2507.23701",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.23701v3 Announce Type: replace \nAbstract: Evaluating AI agents within complex, interactive environments that mirror real-world challenges is critical for understanding their practical capabilities. While existing agent benchmarks effectively assess skills like tool use or performance on structured tasks, they often do not fully capture an agent's ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. To enable a more accurate assessment of AI agents in challenging exploratory environments, we introduce TextQuests, a benchmark based on the Infocom suite of interactive fiction games. These text-based adventures, which can take human players over 30 hours and require hundreds of precise actions to solve, serve as an effective proxy for evaluating AI agents on focused, stateful tasks. The benchmark is specifically designed to assess an LLM agent's capacity for self-contained problem-solving by precluding the use of external tools, thereby focusing on intrinsic long-context reasoning capabilities in an exploratory environment characterized by the need for trial-and-error learning and sustained problem-solving within a single interactive session. We release TextQuests at https://textquests.ai.",
    "source": "arXiv"
  },
  {
    "title": "iSafetyBench: A video-language benchmark for safety in industrial environment",
    "title_es": "iSafetyBench: A video-language benchmark for safety in industrial environment",
    "url": "https://arxiv.org/abs/2508.00399",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.00399v2 Announce Type: replace \nAbstract: Recent advances in vision-language models (VLMs) have enabled impressive generalization across diverse video understanding tasks under zero-shot settings. However, their capabilities in high-stakes industrial domains-where recognizing both routine operations and safety-critical anomalies is essential-remain largely underexplored. To address this gap, we introduce iSafetyBench, a new video-language benchmark specifically designed to evaluate model performance in industrial environments across both normal and hazardous scenarios. iSafetyBench comprises 1,100 video clips sourced from real-world industrial settings, annotated with open-vocabulary, multi-label action tags spanning 98 routine and 67 hazardous action categories. Each clip is paired with multiple-choice questions for both single-label and multi-label evaluation, enabling fine-grained assessment of VLMs in both standard and safety-critical contexts. We evaluate eight state-of-the-art video-language models under zero-shot conditions. Despite their strong performance on existing video benchmarks, these models struggle with iSafetyBench-particularly in recognizing hazardous activities and in multi-label scenarios. Our results reveal significant performance gaps, underscoring the need for more robust, safety-aware multimodal models for industrial applications. iSafetyBench provides a first-of-its-kind testbed to drive progress in this direction. The dataset is available at: https://github.com/iSafetyBench/data.",
    "source": "arXiv"
  },
  {
    "title": "MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval",
    "title_es": "MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval",
    "url": "https://arxiv.org/abs/2508.00579",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.00579v2 Announce Type: replace \nAbstract: The multi-modal long-context document question-answering task aims to locate and integrate multi-modal evidences (such as texts, tables, charts, images, and layouts) distributed across multiple pages, for question understanding and answer generation. The existing methods can be categorized into Large Vision-Language Model (LVLM)-based and Retrieval-Augmented Generation (RAG)-based methods. However, the former were susceptible to hallucinations, while the latter struggled for inter-modal disconnection and cross-page fragmentation. To address these challenges, a novel multi-modal RAG model, named MMRAG-DocQA, was proposed, leveraging both textual and visual information across long-range pages to facilitate accurate question answering. A hierarchical indexing method with the integration of flattened in-page chunks and topological cross-page chunks was designed to jointly establish in-page multi-modal associations and long-distance cross-page dependencies. By means of joint similarity evaluation and large language model (LLM)-based re-ranking, a multi-granularity semantic retrieval method, including the page-level parent page retrieval and document-level summary retrieval, was proposed to foster multi-modal evidence connection and long-distance evidence integration and reasoning. Experimental results performed on public datasets, MMLongBench-Doc and LongDocURL, demonstrated the superiority of our MMRAG-DocQA method in understanding and answering modality-rich and multi-page documents.",
    "source": "arXiv"
  },
  {
    "title": "PromptSafe: Gated Prompt Tuning for Safe Text-to-Image Generation",
    "title_es": "PromptSafe: Gated Prompt Tuning for Safe Text-to-Image Generation",
    "url": "https://arxiv.org/abs/2508.01272",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.01272v2 Announce Type: replace \nAbstract: Text-to-image (T2I) models have demonstrated remarkable generative capabilities but remain vulnerable to producing not-safe-for-work (NSFW) content, such as violent or explicit imagery. While recent moderation efforts have introduced soft prompt-guided tuning by appending defensive tokens to the input, these approaches often rely on large-scale curated image-text datasets and apply static, one-size-fits-all defenses at inference time. However, this results not only in high computational cost and degraded benign image quality, but also in limited adaptability to the diverse and nuanced safety requirements of real-world prompts. To address these challenges, we propose PromptSafe, a gated prompt tuning framework that combines a lightweight, text-only supervised soft embedding with an inference-time gated control network. Instead of training on expensive image-text datasets, we first rewrite unsafe prompts into semantically aligned but safe alternatives using an LLM, constructing an efficient text-only training corpus. Based on this, we optimize a universal soft prompt that repels unsafe and attracts safe embeddings during the diffusion denoising process. To avoid over-suppressing benign prompts, we introduce a gated mechanism that adaptively adjusts the defensive strength based on estimated prompt toxicity, thereby aligning defense intensity with prompt risk and ensuring strong protection for harmful inputs while preserving benign generation quality. Extensive experiments across multiple benchmarks and T2I models show that PromptSafe achieves a SOTA unsafe generation rate (2.36%), while preserving high benign fidelity. Furthermore, PromptSafe demonstrates strong generalization to unseen harmful categories, robust transferability across diffusion model architectures, and resilience under adaptive adversarial attacks, highlighting its practical value for safe and scalable deployment.",
    "source": "arXiv"
  },
  {
    "title": "Marco-Voice Technical Report",
    "title_es": "Marco-Voice Technical Report",
    "url": "https://arxiv.org/abs/2508.02038",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.02038v4 Announce Type: replace \nAbstract: This paper presents a multifunctional speech synthesis system that integrates voice cloning and emotion control speech synthesis within a unified framework. The goal of this work is to address longstanding challenges in achieving highly expressive, controllable, and natural speech generation that faithfully preserves speaker identity across diverse linguistic and emotional contexts. Our approach introduces an effective speaker-emotion disentanglement mechanism with in-batch contrastive learning, enabling independent manipulation of speaker identity and eemotional style, as well as rotational emotional embedding integration method for smooth emotion control. To support comprehensive training and evaluation, we construct CSEMOTIONS, a high-quality emotional speech dataset containing 10 hours of Mandarin speech from six professional speakers across seven emotional categories. Extensive experiments demonstrate that our system, Marco-Voice, achieves substantial improvements in both objective and subjective metrics. Comprehensive evaluations and analysis were conducted, results show that MarcoVoice delivers competitive performance in terms of speech clarity and emotional richness, representing a substantial advance in the field of expressive neural speech synthesis. Our code and dataset are publicly available at https://github.com/AIDC-AI/Marco-Voice and https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS respectively.",
    "source": "arXiv"
  },
  {
    "title": "MedVLThinker: Simple Baselines for Multimodal Medical Reasoning",
    "title_es": "MedVLThinker: Simple Baselines for Multimodal Medical Reasoning",
    "url": "https://arxiv.org/abs/2508.02669",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.02669v2 Announce Type: replace \nAbstract: Large Reasoning Models (LRMs) have introduced a new paradigm in AI by enabling models to ``think before responding\" via chain-of-thought reasoning. However, the absence of open and reproducible recipes for building reasoning-centric medical LMMs hinders community-wide research, analysis, and comparison. In this paper, we present MedVLThinker, a suite of simple yet strong baselines. Our fully open recipe consists of: (1) systematic data curation for both text-only and image-text medical data, filtered according to varying levels of reasoning difficulty, and (2) two training paradigms: Supervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement Learning with Verifiable Rewards (RLVR) based on final answer correctness. Across extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six medical QA benchmarks, we find that RLVR consistently and significantly outperforms SFT. Additionally, under the RLVR framework, a key, counter-intuitive finding is that training on our curated text-only reasoning data provides a more substantial performance boost than training on multimodal image-text data. Our best open 7B model, trained using the RLVR recipe on text-only data, establishes a new state-of-the-art on existing public VQA benchmarks, surpassing all previous open-source medical LMMs. Furthermore, scaling our model to 32B achieves performance on par with the proprietary GPT-4o. We release all curated data, models, and code to provide the community with a strong, open foundation for future research in multimodal medical reasoning.",
    "source": "arXiv"
  },
  {
    "title": "Unifying Locality of KANs and Feature Drift Compensation Projection for Data-free Replay based Continual Face Forgery Detection",
    "title_es": "Unifying Locality of KANs and Feature Drift Compensation Projection for Data-free Replay based Continual Face Forgery Detection",
    "url": "https://arxiv.org/abs/2508.03189",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.03189v2 Announce Type: replace \nAbstract: The rapid advancements in face forgery techniques necessitate that detectors continuously adapt to new forgery methods, thus situating face forgery detection within a continual learning paradigm. However, when detectors learn new forgery types, their performance on previous types often degrades rapidly, a phenomenon known as catastrophic forgetting. Kolmogorov-Arnold Networks (KANs) utilize locally plastic splines as their activation functions, enabling them to learn new tasks by modifying only local regions of the functions while leaving other areas unaffected. Therefore, they are naturally suitable for addressing catastrophic forgetting. However, KANs have two significant limitations: 1) the splines are ineffective for modeling high-dimensional images, while alternative activation functions that are suitable for images lack the essential property of locality; 2) in continual learning, when features from different domains overlap, the mapping of different domains to distinct curve regions always collapses due to repeated modifications of the same regions. In this paper, we propose a KAN-based Continual Face Forgery Detection (KAN-CFD) framework, which includes a Domain-Group KAN Detector (DG-KD) and a data-free replay Feature Separation strategy via KAN Drift Compensation Projection (FS-KDCP). DG-KD enables KANs to fit high-dimensional image inputs while preserving locality and local plasticity. FS-KDCP avoids the overlap of the KAN input spaces without using data from prior tasks. Experimental results demonstrate that the proposed method achieves superior performance while notably reducing forgetting.",
    "source": "arXiv"
  },
  {
    "title": "BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models",
    "title_es": "BadBlocks: Low-Cost and Stealthy Backdoor Attacks Tailored for Text-to-Image Diffusion Models",
    "url": "https://arxiv.org/abs/2508.03221",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.03221v2 Announce Type: replace \nAbstract: In recent years, Diffusion models have achieved remarkable progress in the field of image generation. However, recent studies have shown that diffusion models are susceptible to backdoor attacks, in which attackers can manipulate the output by injecting covert triggers such as specific visual patterns or textual phrases into the training dataset. Fortunately, with the continuous advancement of defense techniques, defenders have become increasingly capable of identifying and mitigating most backdoor attacks using visual inspection and neural network-based detection methods. However, in this paper, we identify a novel type of backdoor threat that is more lightweight and covert than existing approaches, which we name BadBlocks, requires only about 30 of the computational resources and 20 GPU time typically needed by previous backdoor attacks, yet it successfully injects backdoors and evades the most advanced defense frameworks. BadBlocks enables attackers to selectively contaminate specific blocks within the UNet architecture of diffusion models while maintaining normal functionality in the remaining components. Experimental results demonstrate that BadBlocks achieves a high attack success rate and low perceptual quality loss , even under extremely constrained computational resources and GPU time. Moreover, BadBlocks is able to bypass existing defense frameworks, especially the attention-based backdoor detection method, highlighting it as a novel and noteworthy threat. Ablation studies further demonstrate that effective backdoor injection does not require fine-tuning the entire network and highlight the pivotal role of certain neural network layers in backdoor mapping. Overall, BadBlocks significantly reduces the barrier to conducting backdoor attacks in all aspects. It enables attackers to inject backdoors into large-scale diffusion models even using consumer-grade GPUs.",
    "source": "arXiv"
  },
  {
    "title": "EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation",
    "title_es": "EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation",
    "url": "https://arxiv.org/abs/2508.03497",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.03497v2 Announce Type: replace \nAbstract: Instruction-based garment editing enables precise image modifications via natural language, with broad applications in fashion design and customization. Unlike general editing tasks, it requires understanding garment-specific semantics and attribute dependencies. However, progress is limited by the scarcity of high-quality instruction-image pairs, as manual annotation is costly and hard to scale. While MLLMs have shown promise in automated data synthesis, their application to garment editing is constrained by imprecise instruction modeling and a lack of fashion-specific supervisory signals. To address these challenges, we present an automated pipeline for constructing a garment editing dataset. We first define six editing instruction categories aligned with real-world fashion workflows to guide the generation of balanced and diverse instruction-image triplets. Second, we introduce Fashion Edit Score, a semantic-aware evaluation metric that captures semantic dependencies between garment attributes and provides reliable supervision during construction. Using this pipeline, we construct a total of 52,257 candidate triplets and retain 20,596 high-quality triplets to build EditGarment, the first instruction-based dataset tailored to standalone garment editing. The project page is https://yindq99.github.io/EditGarment-project/.",
    "source": "arXiv"
  },
  {
    "title": "Self-Questioning Language Models",
    "title_es": "Self-Questioning Language Models",
    "url": "https://arxiv.org/abs/2508.03682",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.03682v3 Announce Type: replace \nAbstract: Can large language models improve without external data -- by generating their own questions and answers? We hypothesize that a pre-trained language model can improve its reasoning skills given only a single prompt specifying the topic (e.g., algebra word problems) and asking the model to generate its own questions. To do this, we propose Self-Questioning Language Models (SQLM): an asymmetric self-play framework where a proposer is given the topic and generates a question for a solver, who tries to answer it. Both the proposer and solver are trained via reinforcement learning. The proposer receives a reward if the problem is not too easy or too difficult, and the solver receives a reward based on majority voting, a proxy for correctness in the absence of ground-truth answers. For coding, the proposer can instead generate unit tests which are used for verification. We study this asymmetric self-play framework on three benchmarks: three-digit multiplication, algebra problems from the OMEGA benchmark, and programming problems from Codeforces. By continually generating more interesting problems and attempting to solve them, language models can improve on downstream benchmarks without access to any curated training datasets.",
    "source": "arXiv"
  },
  {
    "title": "MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning",
    "title_es": "MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning",
    "url": "https://arxiv.org/abs/2508.04549",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.04549v2 Announce Type: replace \nAbstract: Marine videos present significant challenges for video understanding due to the dynamics of marine objects and the surrounding environment, camera motion, and the complexity of underwater scenes. Existing video captioning datasets, typically focused on generic or human-centric domains, often fail to generalize to the complexities of the marine environment and gain insights about marine life. To address these limitations, we propose a two-stage marine object-oriented video captioning pipeline. We introduce a comprehensive video understanding benchmark that leverages the triplets of video, text, and segmentation masks to facilitate visual grounding and captioning, leading to improved marine video understanding and analysis, and marine video generation. Additionally, we highlight the effectiveness of video splitting in order to detect salient object transitions in scene changes, which significantly enrich the semantics of captioning content. Our dataset and code have been released at https://msc.hkustvgd.com.",
    "source": "arXiv"
  },
  {
    "title": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference",
    "title_es": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference",
    "url": "https://arxiv.org/abs/2508.04586",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.04586v3 Announce Type: replace \nAbstract: Artificial Intelligence (AI) conferences are essential for advancing research, sharing knowledge, and fostering academic community. However, their rapid expansion has rendered the centralized conference model increasingly unsustainable. This paper offers a data-driven diagnosis of a structural crisis that threatens the foundational goals of scientific dissemination, equity, and community well-being. We identify four key areas of strain: (1) scientifically, with per-author publication rates more than doubling over the past decade to over 4.5 papers annually; (2) environmentally, with the carbon footprint of a single conference exceeding the daily emissions of its host city; (3) psychologically, with 71% of online community discourse reflecting negative sentiment and 35% referencing mental health concerns; and (4) logistically, with attendance at top conferences such as NeurIPS 2024 beginning to outpace venue capacity. These pressures point to a system that is misaligned with its core mission. In response, we propose the Community-Federated Conference (CFC) model, which separates peer review, presentation, and networking into globally coordinated but locally organized components, offering a more sustainable, inclusive, and resilient path forward for AI research.",
    "source": "arXiv"
  },
  {
    "title": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction",
    "title_es": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction",
    "url": "https://arxiv.org/abs/2508.05294",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.05294v2 Announce Type: replace \nAbstract: Foundation models, including large language models (LLMs) and vision-language models (VLMs), have recently enabled novel approaches to robot autonomy and human-robot interfaces. In parallel, vision-language-action models (VLAs) or large behavior models (LBMs) are increasing the dexterity and capabilities of robotic systems. This survey paper focuses on those works advancing towards agentic applications and architectures. This includes initial efforts exploring GPT-style interfaces to tooling, as well as more complex system where AI agents are coordinators, planners, perception actors, or generalist interfaces. Such agentic architectures allow robots to reason over natural language instructions, invoke APIs, plan task sequences, or assist in operations and diagnostics. In addition to peer-reviewed research, due to the fast-evolving nature of the field, we highlight and include community-driven projects, ROS packages, and industrial frameworks that show emerging trends. We propose a taxonomy for classifying model integration approaches and present a comparative analysis of the role that agents play in different solutions in today's literature.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging AI to Accelerate Medical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods",
    "title_es": "Leveraging AI to Accelerate Medical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods",
    "url": "https://arxiv.org/abs/2508.05519",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.05519v2 Announce Type: replace \nAbstract: Clinical trial data cleaning represents a critical bottleneck in drug development, with manual review processes struggling to manage exponentially increasing data volumes and complexity. This paper presents Octozi, an artificial intelligence-assisted platform that combines large language models with domain-specific heuristics to transform medical data review. In a controlled experimental study with experienced medical reviewers (n=10), we demonstrate that AI assistance increased data cleaning throughput by 6.03-fold while simultaneously decreasing cleaning errors from 54.67% to 8.48% (a 6.44-fold improvement). Crucially, the system reduced false positive queries by 15.48-fold, minimizing unnecessary site burden. Economic analysis of a representative Phase III oncology trial reveals potential cost savings of $5.1 million, primarily driven by accelerated database lock timelines (5-day reduction saving $4.4M), improved medical review efficiency ($420K savings), and reduced query management burden ($288K savings). These improvements were consistent across reviewers regardless of experience level, suggesting broad applicability. Our findings indicate that AI-assisted approaches can address fundamental inefficiencies in clinical trial operations, potentially accelerating drug development timelines such as database lock by 33% while maintaining regulatory compliance and significantly reducing operational costs. This work establishes a framework for integrating AI into safety-critical clinical workflows and demonstrates the transformative potential of human-AI collaboration in pharmaceutical clinical trials.",
    "source": "arXiv"
  },
  {
    "title": "iFairy: the First 2-bit Complex LLM with All Parameters in $\\{\\pm1, \\pm i\\}$",
    "title_es": "iFairy: the First 2-bit Complex LLM with All Parameters in $\\{\\pm1, \\pm i\\}$",
    "url": "https://arxiv.org/abs/2508.05571",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.05571v2 Announce Type: replace \nAbstract: Quantization-Aware Training (QAT) integrates quantization into the training loop, enabling LLMs to learn robust low-bit representations, and is widely recognized as one of the most promising research directions. All current QAT research focuses on minimizing quantization error on full-precision models, where the full-precision accuracy acts as an upper bound (accuracy ceiling). No existing method has even attempted to surpass this ceiling. To break this ceiling, we propose a new paradigm: raising the ceiling (full-precision model), and then still quantizing it efficiently into 2 bits. We propose Fairy$\\pm i$, the first 2-bit quantization framework for complex-valued LLMs. Specifically, our method leverages the representational advantages of the complex domain to boost full-precision accuracy. We map weights to the fourth roots of unity $\\{\\pm1, \\pm i\\}$, forming a perfectly symmetric and information-theoretically optimal 2-bit representation. Importantly, each quantized weight has either a zero real or imaginary part, enabling multiplication-free inference using only additions and element swaps. Experimental results show that Fairy$\\pm i$ outperforms the ceiling of existing 2-bit quantization approaches in terms of both PPL and downstream tasks, while maintaining strict storage and compute efficiency. This work opens a new direction for building highly accurate and practical LLMs under extremely low-bit constraints.",
    "source": "arXiv"
  },
  {
    "title": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle",
    "title_es": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle",
    "url": "https://arxiv.org/abs/2508.05612",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.05612v2 Announce Type: replace \nAbstract: Reinforcement learning (RL) has emerged as an effective post-training paradigm for enhancing the reasoning capabilities of multimodal large language model (MLLM). However, current RL pipelines often suffer from training inefficiencies caused by two underexplored issues: Advantage Collapsing, where most advantages in a batch concentrate near zero, and Rollout Silencing, where the proportion of rollouts contributing non-zero gradients diminishes over time. These issues lead to suboptimal gradient updates and hinder long-term learning efficiency. To address these issues, we propose Shuffle-R1, a simple yet principled framework that improves RL fine-tuning efficiency by dynamically restructuring trajectory sampling and batch composition. It introduces (1) Pairwise Trajectory Sampling, which selects high-contrast trajectories with large advantages to improve gradient signal quality, and (2) Advantage-based Trajectory Shuffle, which increases exposure of valuable rollouts through informed batch reshuffling. Experiments across multiple reasoning benchmarks show that our framework consistently outperforms strong RL baselines with minimal overhead. These results highlight the importance of data-centric adaptations for more efficient RL training in MLLM.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging large language models for SQL behavior-based database intrusion detection",
    "title_es": "Leveraging large language models for SQL behavior-based database intrusion detection",
    "url": "https://arxiv.org/abs/2508.05690",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.05690v2 Announce Type: replace \nAbstract: Database systems are extensively used to store critical data across various domains. However, the frequency of abnormal database access behaviors, such as database intrusion by internal and external attacks, continues to rise. Internal masqueraders often have greater organizational knowledge, making it easier to mimic employee behavior effectively. In contrast, external masqueraders may behave differently due to their lack of familiarity with the organization. Current approaches lack the granularity needed to detect anomalies at the operational level, frequently misclassifying entire sequences of operations as anomalies, even though most operations are likely to represent normal behavior. On the other hand, some anomalous behaviors often resemble normal activities, making them difficult for existing detection methods to identify. This paper introduces a two-tiered anomaly detection approach for Structured Query Language (SQL) using the Bidirectional Encoder Representations from Transformers (BERT) model, specifically DistilBERT, a more efficient, pre-trained version. Our method combines both unsupervised and supervised machine learning techniques to accurately identify anomalous activities while minimizing the need for data labeling. First, the unsupervised method uses ensemble anomaly detectors that flag embedding vectors distant from learned normal patterns of typical user behavior across the database (out-of-scope queries). Second, the supervised method uses fine-tuned transformer-based models to detect internal attacks with high precision (in-scope queries), using role-labeled classification, even on limited labeled SQL data. Our findings make a significant contribution by providing an effective solution for safeguarding critical database systems from sophisticated threats.",
    "source": "arXiv"
  },
  {
    "title": "A Graph-Based Framework for Exploring Mathematical Patterns in Physics: A Proof of Concept",
    "title_es": "A Graph-Based Framework for Exploring Mathematical Patterns in Physics: A Proof of Concept",
    "url": "https://arxiv.org/abs/2508.05724",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.05724v2 Announce Type: replace \nAbstract: The vast corpus of physics equations forms an implicit network of mathematical relationships that traditional analysis cannot fully explore. This work introduces a graph-based framework combining neural networks with symbolic analysis to systematically discover and validate mathematical patterns across physics domains. Starting from 659 equations, we performed rigorous semantic disambiguation to resolve notational polysemy affecting 213 equations, then focused on 400 advanced physics equations by excluding elementary mechanics to emphasize inter-branch connections of modern physics. This corpus was represented as a weighted knowledge graph where a Graph Attention Network achieved 97.4% AUC in link prediction, significantly outperforming classical baselines. The framework's primary value emerges from its dual capability: generating hypotheses and auditing knowledge. First, it functions as a hypothesis generator, producing hundreds of candidate cross-domain connections, from blackbody radiation coupled with Navier-Stokes equations to radioactive decay linked with electromagnetic induction. Second, through symbolic analysis of 30 equation clusters, it serves as a computational auditor that verified established theory consistencies, synthesized the Magnetic Reynolds Number from electromagnetic-fluid coupling, and revealed how even parsing errors could potentially point toward legitimate research like analog gravity. This proof-of-concept intentionally over-generates candidates to ensure comprehensive exploration of mathematical possibility space. Even tautologies and errors serve scientific purposes: redundancy identification and knowledge base quality assessment. The system transforms the intractable combinatorial space into a filtered stream of mathematical patterns for human interpretation.",
    "source": "arXiv"
  },
  {
    "title": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning",
    "title_es": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.05977",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.05977v2 Announce Type: replace \nAbstract: In the domain of scientific machine learning, designing effective reward functions remains a challenge in reinforcement learning (RL), particularly in environments where task goals are difficult to specify numerically. Reward functions in existing work are predominantly based on heuristics, manual engineering, or task-specific tuning. In this work, we introduce a semantically aligned reinforcement learning method where rewards are computed by aligning the current state with a target semantic instruction using a Sentence-Bidirectional Encoder Representations from Transformers (SBERT). Instead of relying on manually defined reward functions, the policy receives feedback based on the reward, which is a cosine similarity between the goal textual description and the statement description in the episode. We evaluated our approach in several environments and showed that semantic reward can guide learning to achieve competitive control behavior, even in the absence of hand-crafted reward functions. Our study demonstrates a correlation between the language embedding space and the conventional Euclidean space. This framework opens new horizons for aligning agent behavior with natural language goals and lays the groundwork for a more seamless integration of larger language models (LLMs) and fluid control applications.",
    "source": "arXiv"
  },
  {
    "title": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning",
    "title_es": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning",
    "url": "https://arxiv.org/abs/2508.06259",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.06259v2 Announce Type: replace \nAbstract: Current multimodal large language models (MLLMs) still face significant challenges in complex visual tasks (e.g., spatial understanding, fine-grained perception). Prior methods have tried to incorporate visual reasoning, however, they fail to leverage attention correction with spatial cues to iteratively refine their focus on prompt-relevant regions. In this paper, we introduce SIFThinker, a spatially-aware \"think-with-images\" framework that mimics human visual perception. Specifically, SIFThinker enables attention correcting and image region focusing by interleaving depth-enhanced bounding boxes and natural language. Our contributions are twofold: First, we introduce a reverse-expansion-forward-inference strategy that facilitates the generation of interleaved image-text chains of thought for process-level supervision, which in turn leads to the construction of the SIF-50K dataset. Besides, we propose GRPO-SIF, a reinforced training paradigm that integrates depth-informed visual grounding into a unified reasoning pipeline, teaching the model to dynamically correct and focus on prompt-relevant regions. Extensive experiments demonstrate that SIFThinker outperforms state-of-the-art methods in spatial understanding and fine-grained visual perception, while maintaining strong general capabilities, highlighting the effectiveness of our method. Code: https://github.com/zhangquanchen/SIFThinker.",
    "source": "arXiv"
  },
  {
    "title": "Blockchain-Enabled Federated Learning",
    "title_es": "Blockchain-Enabled Federated Learning",
    "url": "https://arxiv.org/abs/2508.06406",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.06406v3 Announce Type: replace \nAbstract: Blockchain-enabled federated learning (BCFL) addresses fundamental challenges of trust, privacy, and coordination in collaborative AI systems. This chapter provides comprehensive architectural analysis of BCFL systems through a systematic four-dimensional taxonomy examining coordination structures, consensus mechanisms, storage architectures, and trust models. We analyze design patterns from blockchain-verified centralized coordination to fully decentralized peer-to-peer networks, evaluating trade-offs in scalability, security, and performance. Through detailed examination of consensus mechanisms designed for federated learning contexts, including Proof of Quality and Proof of Federated Learning, we demonstrate how computational work can be repurposed from arbitrary cryptographic puzzles to productive machine learning tasks. The chapter addresses critical storage challenges by examining multi-tier architectures that balance blockchain's transaction constraints with neural networks' large parameter requirements while maintaining cryptographic integrity. A technical case study of the TrustMesh framework illustrates practical implementation considerations in BCFL systems through distributed image classification training, demonstrating effective collaborative learning across IoT devices with highly non-IID data distributions while maintaining complete transparency and fault tolerance. Analysis of real-world deployments across healthcare consortiums, financial services, and IoT security applications validates the practical viability of BCFL systems, achieving performance comparable to centralized approaches while providing enhanced security guarantees and enabling new models of trustless collaborative intelligence.",
    "source": "arXiv"
  },
  {
    "title": "Sample-efficient LLM Optimization with Reset Replay",
    "title_es": "Sample-efficient LLM Optimization with Reset Replay",
    "url": "https://arxiv.org/abs/2508.06412",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.06412v2 Announce Type: replace \nAbstract: Recent advancements in post-training Large Language Models (LLMs), particularly through Reinforcement Learning (RL) and preference optimization methods, are key drivers for enhancing their reasoning capabilities. However, these methods are often plagued by low sample efficiency and a susceptibility to primacy bias, where overfitting to initial experiences degrades policy quality and damages the learning process. To address these challenges, we introduce LLM optimization with Reset Replay (LoRR), a general and powerful plugin designed to enhance sample efficiency in any preference-based optimization framework. LoRR core mechanism enables training at a high replay number, maximizing the utility of each collected data batch. To counteract the risk of overfitting inherent in high-replay training, LoRR incorporates a periodic reset strategy with reusing initial data, which preserves network plasticity. Furthermore, it leverages a hybrid optimization objective, combining supervised fine-tuning (SFT) and preference-based losses to further bolster data exploitation. Our extensive experiments demonstrate that LoRR significantly boosts the performance of various preference optimization methods on both mathematical and general reasoning benchmarks. Notably, an iterative DPO approach augmented with LoRR achieves comparable performance on challenging math tasks, outperforming some complex and computationally intensive RL-based algorithms. These findings highlight that LoRR offers a practical, sample-efficient, and highly effective paradigm for LLM finetuning, unlocking greater performance from limited data.",
    "source": "arXiv"
  },
  {
    "title": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking",
    "title_es": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking",
    "url": "https://arxiv.org/abs/2508.06445",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.06445v2 Announce Type: replace \nAbstract: The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns for journalistic integrity and authorship. This study examines AI-generated content across over 40,000 news articles from major, local, and college news media, in various media formats. Using three advanced AI-text detectors (e.g., Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of GenAI use in recent years, especially in local and college news. Sentence-level analysis reveals LLMs are often used in the introduction of news, while conclusions usually written manually. Linguistic analysis shows GenAI boosts word richness and readability but lowers formality, leading to more uniform writing styles, particularly in local media.",
    "source": "arXiv"
  },
  {
    "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities",
    "title_es": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities",
    "url": "https://arxiv.org/abs/2508.06800",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.06800v2 Announce Type: replace \nAbstract: Missing modalities have recently emerged as a critical research direction in multimodal emotion recognition (MER). Conventional approaches typically address this issue through missing modality reconstruction. However, these methods fail to account for variations in reconstruction difficulty across different samples, consequently limiting the model's ability to handle hard samples effectively. To overcome this limitation, we propose a novel Hardness-Aware Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates in two key stages: first, it estimates the hardness level of each sample, and second, it strategically emphasizes hard samples during training to enhance model performance on these challenging instances. Specifically, we first introduce a Multi-view Hardness Evaluation mechanism that quantifies reconstruction difficulty by considering both Direct Hardness (modality reconstruction errors) and Indirect Hardness (cross-modal mutual information). Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy that dynamically adjusts the training curriculum by retrieving samples with similar semantic information and balancing the learning focus between easy and hard instances. Extensive experiments on benchmark datasets demonstrate that HARDY-MER consistently outperforms existing methods in missing-modality scenarios. Our code will be made publicly available at https://github.com/HARDY-MER/HARDY-MER.",
    "source": "arXiv"
  },
  {
    "title": "S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision",
    "title_es": "S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision",
    "url": "https://arxiv.org/abs/2508.06995",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.06995v2 Announce Type: replace \nAbstract: Recent self-supervised image segmentation models have achieved promising performance on semantic segmentation and class-agnostic instance segmentation. However, their pretraining schedule is multi-stage, requiring a time-consuming pseudo-masks generation process between each training epoch. This time-consuming offline process not only makes it difficult to scale with training dataset size, but also leads to sub-optimal solutions due to its discontinuous optimization routine. To solve these, we first present a novel pseudo-mask algorithm, Fast Universal Agglomerative Pooling (UniAP). Each layer of UniAP can identify groups of similar nodes in parallel, allowing to generate both semantic-level and instance-level and multi-granular pseudo-masks within ens of milliseconds for one image. Based on the fast UniAP, we propose the Scalable Self-Supervised Universal Segmentation (S2-UniSeg), which employs a student and a momentum teacher for continuous pretraining. A novel segmentation-oriented pretext task, Query-wise Self-Distillation (QuerySD), is proposed to pretrain S2-UniSeg to learn the local-to-global correspondences. Under the same setting, S2-UniSeg outperforms the SOTA UnSAM model, achieving notable improvements of AP+6.9 on COCO, AR+11.1 on UVO, PixelAcc+4.5 on COCOStuff-27, RQ+8.0 on Cityscapes. After scaling up to a larger 2M-image subset of SA-1B, S2-UniSeg further achieves performance gains on all four benchmarks. Our code and pretrained models are available at https://github.com/bio-mlhui/S2-UniSeg",
    "source": "arXiv"
  },
  {
    "title": "EventRR: Event Referential Reasoning for Referring Video Object Segmentation",
    "title_es": "EventRR: Event Referential Reasoning for Referring Video Object Segmentation",
    "url": "https://arxiv.org/abs/2508.07171",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.07171v2 Announce Type: replace \nAbstract: Referring Video Object Segmentation (RVOS) aims to segment out the object in a video referred by an expression. Current RVOS methods view referring expressions as unstructured sequences, neglecting their crucial semantic structure essential for referent reasoning. Besides, in contrast to image-referring expressions whose semantics focus only on object attributes and object-object relations, video-referring expressions also encompass event attributes and event-event temporal relations. This complexity challenges traditional structured reasoning image approaches. In this paper, we propose the Event Referential Reasoning (EventRR) framework. EventRR decouples RVOS into object summarization part and referent reasoning part. The summarization phase begins by summarizing each frame into a set of bottleneck tokens, which are then efficiently aggregated in the video-level summarization step to exchange the global cross-modal temporal context. For reasoning part, EventRR extracts semantic eventful structure of a video-referring expression into highly expressive Referential Event Graph (REG), which is a single-rooted directed acyclic graph. Guided by topological traversal of REG, we propose Temporal Concept-Role Reasoning (TCRR) to accumulate the referring score of each temporal query from REG leaf nodes to root node. Each reasoning step can be interpreted as a question-answer pair derived from the concept-role relations in REG. Extensive experiments across four widely recognized benchmark datasets, show that EventRR quantitatively and qualitatively outperforms state-of-the-art RVOS methods. Code is available at https://github.com/bio-mlhui/EventRR",
    "source": "arXiv"
  },
  {
    "title": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback",
    "title_es": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback",
    "url": "https://arxiv.org/abs/2508.07178",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.07178v2 Announce Type: replace \nAbstract: Accurate personalized headline generation hinges on precisely capturing user interests from historical behaviors. However, existing methods neglect personalized-irrelevant click noise in entire historical clickstreams, which may lead to hallucinated headlines that deviate from genuine user preferences. In this paper, we reveal the detrimental impact of click noise on personalized generation quality through rigorous analysis in both user and news dimensions. Based on these insights, we propose a novel Personalized Headline Generation framework via Denoising Fake Interests from Implicit Feedback (PHG-DIF). PHG-DIF first employs dual-stage filtering to effectively remove clickstream noise, identified by short dwell times and abnormal click bursts, and then leverages multi-level temporal fusion to dynamically model users' evolving and multi-faceted interests for precise profiling. Moreover, we release DT-PENS, a new benchmark dataset comprising the click behavior of 1,000 carefully curated users and nearly 10,000 annotated personalized headlines with historical dwell time annotations. Extensive experiments demonstrate that PHG-DIF substantially mitigates the adverse effects of click noise and significantly improves headline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our framework implementation and dataset are available at https://github.com/liukejin-up/PHG-DIF.",
    "source": "arXiv"
  },
  {
    "title": "Semantic-Enhanced Time-Series Forecasting via Large Language Models",
    "title_es": "Semantic-Enhanced Time-Series Forecasting via Large Language Models",
    "url": "https://arxiv.org/abs/2508.07697",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.07697v2 Announce Type: replace \nAbstract: Time series forecasting plays a significant role in finance, energy, meteorology, and IoT applications. Recent studies have leveraged the generalization capabilities of large language models (LLMs) to adapt to time series forecasting, achieving promising performance. However, existing studies focus on token-level modal alignment, instead of bridging the intrinsic modality gap between linguistic knowledge structures and time series data patterns, greatly limiting the semantic representation. To address this issue, we propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent periodicity and anomalous characteristics of time series to embed into the semantic space to enhance the token embedding. This process enhances the interpretability of tokens for LLMs, thereby activating the potential of LLMs for temporal sequence analysis. Moreover, existing Transformer-based LLMs excel at capturing long-range dependencies but are weak at modeling short-term anomalies in time-series data. Hence, we propose a plugin module embedded within self-attention that models long-term and short-term dependencies to effectively adapt LLMs to time-series analysis. Our approach freezes the LLM and reduces the sequence dimensionality of tokens, greatly reducing computational consumption. Experiments demonstrate the superiority performance of our SE-LLM against the state-of-the-art (SOTA) methods.",
    "source": "arXiv"
  },
  {
    "title": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer",
    "title_es": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer",
    "url": "https://arxiv.org/abs/2508.07970",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.07970v2 Announce Type: replace \nAbstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent paradigm for training large language models and multimodal systems. Despite notable advances enabled by existing RLHF training frameworks, significant challenges remain in scaling to complex multimodal workflows and adapting to dynamic workloads. In particular, current systems often encounter limitations related to controller scalability when managing large models, as well as inefficiencies in orchestrating intricate RLHF pipelines, especially in scenarios that require dynamic sampling and resource allocation. In this paper, we introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple, scalable, and balanced RLHF training framework specifically designed to address these challenges. WeChat-YATT features a parallel controller programming model that enables flexible and efficient orchestration of complex RLHF workflows, effectively mitigating the bottlenecks associated with centralized controller architectures and facilitating scalability in large-scale data scenarios. In addition, we propose a dynamic placement schema that adaptively partitions computational resources and schedules workloads, thereby significantly reducing hardware idle time and improving GPU utilization under variable training conditions. We evaluate WeChat-YATT across a range of experimental scenarios, demonstrating that it achieves substantial improvements in throughput compared to state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been successfully deployed to train models supporting WeChat product features for a large-scale user base, underscoring its effectiveness and robustness in real-world applications.We have open-source WeChat-YATT at https://www.github.com/tencent/WeChat-YATT.",
    "source": "arXiv"
  },
  {
    "title": "On Understanding of the Dynamics of Model Capacity in Continual Learning",
    "title_es": "On Understanding of the Dynamics of Model Capacity in Continual Learning",
    "url": "https://arxiv.org/abs/2508.08052",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08052v2 Announce Type: replace \nAbstract: The stability-plasticity dilemma, closely related to a neural network's (NN) capacity-its ability to represent tasks-is a fundamental challenge in continual learning (CL). Within this context, we introduce CL's effective model capacity (CLEMC) that characterizes the dynamic behavior of the stability-plasticity balance point. We develop a difference equation to model the evolution of the interplay between the NN, task data, and optimization procedure. We then leverage CLEMC to demonstrate that the effective capacity-and, by extension, the stability-plasticity balance point is inherently non-stationary. We show that regardless of the NN architecture or optimization method, a NN's ability to represent new tasks diminishes when incoming task distributions differ from previous ones. We conduct extensive experiments to support our theoretical findings, spanning a range of architectures-from small feedforward network and convolutional networks to medium-sized graph neural networks and transformer-based large language models with millions of parameters.",
    "source": "arXiv"
  },
  {
    "title": "TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning",
    "title_es": "TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning",
    "url": "https://arxiv.org/abs/2508.08098",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08098v2 Announce Type: replace \nAbstract: This paper introduces TBAC-UniImage, a novel unified model for multimodal understanding and generation. We achieve this by deeply integrating a pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal Large Language Model (MLLM). Previous diffusion-based unified models face two primary limitations. One approach uses only the MLLM's final hidden state as the generative condition. This creates a shallow connection, as the generator is isolated from the rich, hierarchical representations within the MLLM's intermediate layers. The other approach, pretraining a unified generative architecture from scratch, is computationally expensive and prohibitive for many researchers. To overcome these issues, our work explores a new paradigm. Instead of relying on a single output, we use representations from multiple, diverse layers of the MLLM as generative conditions for the diffusion model. This method treats the pre-trained generator as a ladder, receiving guidance from various depths of the MLLM's understanding process. Consequently, TBAC-UniImage achieves a much deeper and more fine-grained unification of understanding and generation.",
    "source": "arXiv"
  },
  {
    "title": "Reinforcement Learning in Vision: A Survey",
    "title_es": "Reinforcement Learning in Vision: A Survey",
    "url": "https://arxiv.org/abs/2508.08189",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08189v2 Announce Type: replace \nAbstract: Recent advances at the intersection of reinforcement learning (RL) and visual intelligence have enabled agents that not only perceive complex visual scenes but also reason, generate, and act within them. This survey offers a critical and up-to-date synthesis of the field. We first formalize visual RL problems and trace the evolution of policy-optimization strategies from RLHF to verifiable reward paradigms, and from Proximal Policy Optimization to Group Relative Policy Optimization. We then organize more than 200 representative works into four thematic pillars: multi-modal large language models, visual generation, unified model frameworks, and vision-language-action models. For each pillar we examine algorithmic design, reward engineering, benchmark progress, and we distill trends such as curriculum-driven training, preference-aligned diffusion, and unified reward modeling. Finally, we review evaluation protocols spanning set-level fidelity, sample-level preference, and state-level stability, and we identify open challenges that include sample efficiency, generalization, and safe deployment. Our goal is to provide researchers and practitioners with a coherent map of the rapidly expanding landscape of visual RL and to highlight promising directions for future inquiry. Resources are available at: https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.",
    "source": "arXiv"
  },
  {
    "title": "A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies",
    "title_es": "A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies",
    "url": "https://arxiv.org/abs/2508.08231",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08231v2 Announce Type: replace \nAbstract: Public-sector bureaucracies seek to reap the benefits of artificial intelligence (AI), but face important concerns about accountability and transparency when using AI systems. In particular, perception or actuality of AI agency might create ethics sinks - constructs that facilitate dissipation of responsibility when AI systems of disputed moral status interface with bureaucratic structures. Here, we reject the notion that ethics sinks are a necessary consequence of introducing AI systems into bureaucracies. Rather, where they appear, they are the product of structural design decisions across both the technology and the institution deploying it. We support this claim via a systematic application of conceptions of moral agency in AI ethics to Weberian bureaucracy. We establish that it is both desirable and feasible to render AI systems as tools for the generation of organizational transparency and legibility, which continue the processes of Weberian rationalization initiated by previous waves of digitalization. We present a three-point Moral Agency Framework for legitimate integration of AI in bureaucratic structures: (a) maintain clear and just human lines of accountability, (b) ensure humans whose work is augmented by AI systems can verify the systems are functioning correctly, and (c) introduce AI only where it doesn't inhibit the capacity of bureaucracies towards either of their twin aims of legitimacy and stewardship. We suggest that AI introduced within this framework can not only improve efficiency and productivity while avoiding ethics sinks, but also improve the transparency and even the legitimacy of a bureaucracy.",
    "source": "arXiv"
  },
  {
    "title": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs",
    "title_es": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs",
    "url": "https://arxiv.org/abs/2508.08285",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08285v2 Announce Type: replace \nAbstract: Large language models (LLMs) have revolutionized natural language processing, yet their tendency to hallucinate poses serious challenges for reliable deployment. Despite numerous hallucination detection methods, their evaluations often rely on ROUGE, a metric based on lexical overlap that misaligns with human judgments. Through comprehensive human studies, we demonstrate that while ROUGE exhibits high recall, its extremely low precision leads to misleading performance estimates. In fact, several established detection methods show performance drops of up to 45.9\\% when assessed using human-aligned metrics like LLM-as-Judge. Moreover, our analysis reveals that simple heuristics based on response length can rival complex detection techniques, exposing a fundamental flaw in current evaluation practices. We argue that adopting semantically aware and robust evaluation frameworks is essential to accurately gauge the true performance of hallucination detection methods, ultimately ensuring the trustworthiness of LLM outputs.",
    "source": "arXiv"
  },
  {
    "title": "Re:Verse -- Can Your VLM Read a Manga?",
    "title_es": "Re:Verse -- Can Your VLM Read a Manga?",
    "url": "https://arxiv.org/abs/2508.08508",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08508v2 Announce Type: replace \nAbstract: Current Vision Language Models (VLMs) demonstrate a critical gap between surface-level recognition and deep narrative reasoning when processing sequential visual storytelling. Through a comprehensive investigation of manga narrative understanding, we reveal that while recent large multimodal models excel at individual panel interpretation, they systematically fail at temporal causality and cross-panel cohesion, core requirements for coherent story comprehension. We introduce a novel evaluation framework that combines fine-grained multimodal annotation, cross-modal embedding analysis, and retrieval-augmented assessment to systematically characterize these limitations.\n  Our methodology includes (i) a rigorous annotation protocol linking visual elements to narrative structure through aligned light novel text, (ii) comprehensive evaluation across multiple reasoning paradigms, including direct inference and retrieval-augmented generation, and (iii) cross-modal similarity analysis revealing fundamental misalignments in current VLMs' joint representations. Applying this framework to Re:Zero manga across 11 chapters with 308 annotated panels, we conduct the first systematic study of long-form narrative understanding in VLMs through three core evaluation axes: generative storytelling, contextual dialogue grounding, and temporal reasoning. Our findings demonstrate that current models lack genuine story-level intelligence, struggling particularly with non-linear narratives, character consistency, and causal inference across extended sequences. This work establishes both the foundation and practical methodology for evaluating narrative intelligence, while providing actionable insights into the capability of deep sequential understanding of Discrete Visual Narratives beyond basic recognition in Multimodal Models.\n  Project Page: https://re-verse.vercel.app",
    "source": "arXiv"
  },
  {
    "title": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework",
    "title_es": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework",
    "url": "https://arxiv.org/abs/2508.08535",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08535v2 Announce Type: replace \nAbstract: Wireless Body Area Networks (WBANs) enable continuous monitoring of physiological signals for applications ranging from chronic disease management to emergency response. Recent advances in 6G communications, post-quantum cryptography, and energy harvesting have the potential to enhance WBAN performance. However, integrating these technologies into a unified, adaptive system remains a challenge. This paper surveys some of the most well-known Wireless Body Area Network (WBAN) architectures, routing strategies, and security mechanisms, identifying key gaps in adaptability, energy efficiency, and quantum-resistant security. We propose a novel Large Language Model-driven adaptive WBAN framework in which a Large Language Model acts as a cognitive control plane, coordinating routing, physical layer selection, micro-energy harvesting, and post-quantum security in real time. Our review highlights the limitations of current heuristic-based designs and outlines a research agenda for resource-constrained, 6G-ready medical systems. This approach aims to enable ultra-reliable, secure, and self-optimizing WBANs for next-generation mobile health applications.",
    "source": "arXiv"
  },
  {
    "title": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction",
    "title_es": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction",
    "url": "https://arxiv.org/abs/2508.08543",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08543v2 Announce Type: replace \nAbstract: Achieving accurate traffic prediction is a fundamental but crucial task in the development of current intelligent transportation systems.Most of the mainstream methods that have made breakthroughs in traffic prediction rely on spatio-temporal graph neural networks, spatio-temporal attention mechanisms, etc. The main challenges of the existing deep learning approaches are that they either depend on a complete traffic network structure or require intricate model designs to capture complex spatio-temporal dependencies. These limitations pose significant challenges for the efficient deployment and operation of deep learning models on large-scale datasets. To address these challenges, we propose a cost-effective graph-free Multilayer Perceptron (MLP) based model M3-Net for traffic prediction. Our proposed model not only employs time series and spatio-temporal embeddings for efficient feature processing but also first introduces a novel MLP-Mixer architecture with a mixture of experts (MoE) mechanism. Extensive experiments conducted on multiple real datasets demonstrate the superiority of the proposed model in terms of prediction performance and lightweight deployment.",
    "source": "arXiv"
  },
  {
    "title": "Yan: Foundational Interactive Video Generation",
    "title_es": "Yan: Foundational Interactive Video Generation",
    "url": "https://arxiv.org/abs/2508.08601",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08601v3 Announce Type: replace \nAbstract: We present Yan, a foundational framework for interactive video generation, covering the entire pipeline from simulation and generation to editing. Specifically, Yan comprises three core modules. AAA-level Simulation: We design a highly-compressed, low-latency 3D-VAE coupled with a KV-cache-based shift-window denoising inference process, achieving real-time 1080P/60FPS interactive simulation. Multi-Modal Generation: We introduce a hierarchical autoregressive caption method that injects game-specific knowledge into open-domain multi-modal video diffusion models (VDMs), then transforming the VDM into a frame-wise, action-controllable, real-time infinite interactive video generator. Notably, when the textual and visual prompts are sourced from different domains, the model demonstrates strong generalization, allowing it to blend and compose the style and mechanics across domains flexibly according to user prompts. Multi-Granularity Editing: We propose a hybrid model that explicitly disentangles interactive mechanics simulation from visual rendering, enabling multi-granularity video content editing during interaction through text. Collectively, Yan offers an integration of these modules, pushing interactive video generation beyond isolated capabilities toward a comprehensive AI-driven interactive creation paradigm, paving the way for the next generation of creative tools, media, and entertainment. The project page is: https://greatx3.github.io/Yan/.",
    "source": "arXiv"
  },
  {
    "title": "Interpretable Reward Model via Sparse Autoencoder",
    "title_es": "Interpretable Reward Model via Sparse Autoencoder",
    "url": "https://arxiv.org/abs/2508.08746",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08746v2 Announce Type: replace \nAbstract: Large language models (LLMs) have been widely deployed across numerous fields. Reinforcement Learning from Human Feedback (RLHF) leverages reward models (RMs) as proxies for human preferences to align LLM behaviors with human values, making the accuracy, reliability, and interpretability of RMs critical for effective alignment. However, traditional RMs lack interpretability, offer limited insight into the reasoning behind reward assignments, and are inflexible toward user preference shifts. While recent multidimensional RMs aim for improved interpretability, they often fail to provide feature-level attribution and require costly annotations. To overcome these limitations, we introduce the Sparse Autoencoder-enhanced Reward Model (SARM), a novel architecture that integrates a pretrained Sparse Autoencoder (SAE) into a reward model. SARM maps the hidden activations of LLM-based RM into an interpretable, sparse, and monosemantic feature space, from which a scalar head aggregates feature activations to produce transparent and conceptually meaningful reward scores. Empirical evaluations demonstrate that SARM facilitates direct feature-level attribution of reward assignments, allows dynamic adjustment to preference shifts, and achieves superior alignment performance compared to conventional reward models. Our code is available at https://github.com/schrieffer-z/sarm.",
    "source": "arXiv"
  },
  {
    "title": "Never Compromise to Vulnerabilities: A Comprehensive Survey on AI Governance",
    "title_es": "Never Compromise to Vulnerabilities: A Comprehensive Survey on AI Governance",
    "url": "https://arxiv.org/abs/2508.08789",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08789v3 Announce Type: replace \nAbstract: The rapid advancement of AI has expanded its capabilities across domains, yet introduced critical technical vulnerabilities, such as algorithmic bias and adversarial sensitivity, that pose significant societal risks, including misinformation, inequity, security breaches, physical harm, and eroded public trust. These challenges highlight the urgent need for robust AI governance. We propose a comprehensive framework integrating technical and societal dimensions, structured around three interconnected pillars: Intrinsic Security (system reliability), Derivative Security (real-world harm mitigation), and Social Ethics (value alignment and accountability). Uniquely, our approach unifies technical methods, emerging evaluation benchmarks, and policy insights to promote transparency, accountability, and trust in AI systems. Through a systematic review of over 300 studies, we identify three core challenges: (1) the generalization gap, where defenses fail against evolving threats; (2) inadequate evaluation protocols that overlook real-world risks; and (3) fragmented regulations leading to inconsistent oversight. These shortcomings stem from treating governance as an afterthought, rather than a foundational design principle, resulting in reactive, siloed efforts that fail to address the interdependence of technical integrity and societal trust. To overcome this, we present an integrated research agenda that bridges technical rigor with social responsibility. Our framework offers actionable guidance for researchers, engineers, and policymakers to develop AI systems that are not only robust and secure but also ethically aligned and publicly trustworthy. The accompanying repository is available at https://github.com/ZTianle/Awesome-AI-SG.",
    "source": "arXiv"
  },
  {
    "title": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them",
    "title_es": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them",
    "url": "https://arxiv.org/abs/2508.08855",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08855v2 Announce Type: replace \nAbstract: Understanding biases and stereotypes encoded in the weights of Large Language Models (LLMs) is crucial for developing effective mitigation strategies. Biased behaviour is often subtle and non-trivial to isolate, even when deliberately elicited, making systematic analysis and debiasing particularly challenging. To address this, we introduce BiasGym, a simple, cost-effective, and generalizable framework for reliably injecting, analyzing, and mitigating conceptual associations within LLMs. BiasGym consists of two components: BiasInject, which injects specific biases into the model via token-based fine-tuning while keeping the model frozen, and BiasScope, which leverages these injected signals to identify and steer the components responsible for biased behavior. Our method enables consistent bias elicitation for mechanistic analysis, supports targeted debiasing without degrading performance on downstream tasks, and generalizes to biases unseen during token-based fine-tuning. We demonstrate the effectiveness of BiasGym in reducing real-world stereotypes (e.g., people from Italy being `reckless drivers') and in probing fictional associations (e.g., people from a fictional country having `blue skin'), showing its utility for both safety interventions and interpretability research.",
    "source": "arXiv"
  },
  {
    "title": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs",
    "title_es": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs",
    "url": "https://arxiv.org/abs/2508.08895",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08895v2 Announce Type: replace \nAbstract: The increasing scale and complexity of large language models (LLMs) pose significant inference latency challenges, primarily due to their autoregressive decoding paradigm characterized by the sequential nature of next-token prediction. By re-examining the outputs of autoregressive models, we observed that some segments exhibit parallelizable structures, which we term intrinsic parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel decoding) can significantly improve the overall inference speed of LLMs. In this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which addresses two core challenges: automated construction of parallelizable data and efficient parallel decoding mechanism. More specifically, we introduce a non-invasive pipeline that automatically extracts and validates parallelizable structures from the responses of autoregressive models. To empower efficient adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which enables seamless transitions between serial and parallel decoding modes while maintaining a reusable KV cache, maximizing computational efficiency. Extensive evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical Reasoning, demonstrate that ASPD achieves unprecedented performance in both effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up to 3.19x speedup (1.85x on average) while maintaining response quality within 1% difference compared to autoregressive models, realizing significant acceleration without compromising generation quality. Our framework sets a groundbreaking benchmark for efficient LLM parallel inference, paving the way for its deployment in latency-sensitive applications such as AI-powered customer service bots and answer retrieval engines.",
    "source": "arXiv"
  },
  {
    "title": "Compass-Thinker-7B Technical Report",
    "title_es": "Compass-Thinker-7B Technical Report",
    "url": "https://arxiv.org/abs/2508.08909",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08909v2 Announce Type: replace \nAbstract: Recent R1-Zero-like research further demonstrates that reasoning extension has given large language models (LLMs) unprecedented reasoning capabilities, and Reinforcement Learning is the core technology to elicit its complex reasoning. However, conducting RL experiments directly on hyperscale models involves high computational costs and resource demands, posing significant risks. We propose the Compass-Thinker-7B model, which aims to explore the potential of Reinforcement Learning with less computational resources and costs, and provides insights for further research into RL recipes for larger models. Compass-Thinker-7B is trained from an open source model through a specially designed Reinforcement Learning Pipeline. We curate a dataset of 30k verifiable mathematics problems for the Reinforcement Learning Pipeline. By configuring data and training settings with different difficulty distributions for different stages, the potential of the model is gradually released and the training efficiency is improved. Extensive evaluations show that Compass-Thinker-7B possesses exceptional reasoning potential, and achieves superior performance on mathematics compared to the same-sized RL model. Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B achieves 40% accuracy.",
    "source": "arXiv"
  },
  {
    "title": "OpenCUA: Open Foundations for Computer-Use Agents",
    "title_es": "OpenCUA: Open Foundations for Computer-Use Agents",
    "url": "https://arxiv.org/abs/2508.09123",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09123v2 Announce Type: replace \nAbstract: Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.",
    "source": "arXiv"
  },
  {
    "title": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA",
    "title_es": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA",
    "url": "https://arxiv.org/abs/2508.09146",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09146v2 Announce Type: replace \nAbstract: The binary exponential backoff scheme is widely used in WiFi 7 and still incurs poor throughput performance under dynamic channel environments. Recent model-based approaches (e.g., non-persistent and $p$-persistent CSMA) simply optimize backoff strategies under a known and fixed node density, still leading to a large throughput loss due to inaccurate node density estimation. This paper is the first to propose LLM transformer-based in-context learning (ICL) theory for optimizing channel access. We design a transformer-based ICL optimizer to pre-collect collision-threshold data examples and a query collision case. They are constructed as a prompt as the input for the transformer to learn the pattern, which then generates a predicted contention window threshold (CWT). To train the transformer for effective ICL, we develop an efficient algorithm and guarantee a near-optimal CWT prediction within limited training steps. As it may be hard to gather perfect data examples for ICL in practice, we further extend to allow erroneous data input in the prompt. We prove that our optimizer maintains minimal prediction and throughput deviations from the optimal values. Experimental results on NS-3 further demonstrate our approach's fast convergence and near-optimal throughput over existing model-based and DRL-based approaches under unknown node densities.",
    "source": "arXiv"
  },
  {
    "title": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving",
    "title_es": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.09158",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09158v2 Announce Type: replace \nAbstract: Autonomous driving faces significant challenges in achieving human-like iterative decision-making, which continuously generates, evaluates, and refines trajectory proposals. Current generation-evaluation frameworks isolate trajectory generation from quality assessment, preventing iterative refinement essential for planning, while reinforcement learning methods collapse multi-dimensional preferences into scalar rewards, obscuring critical trade-offs and yielding scalarization bias.To overcome these issues, we present EvaDrive, a novel multi-objective reinforcement learning framework that establishes genuine closed-loop co-evolution between trajectory generation and evaluation via adversarial optimization. EvaDrive frames trajectory planning as a multi-round adversarial game. In this game, a hierarchical generator continuously proposes candidate paths by combining autoregressive intent modeling for temporal causality with diffusion-based refinement for spatial flexibility. These proposals are then rigorously assessed by a trainable multi-objective critic that explicitly preserves diverse preference structures without collapsing them into a single scalarization bias.This adversarial interplay, guided by a Pareto frontier selection mechanism, enables iterative multi-round refinement, effectively escaping local optima while preserving trajectory diversity.Extensive experiments on NAVSIM and Bench2Drive benchmarks demonstrate SOTA performance, achieving 94.9 PDMS on NAVSIM v1 (surpassing DiffusionDrive by 6.8, DriveSuprim by 5.0, and TrajHF by 0.9) and 64.96 Driving Score on Bench2Drive. EvaDrive generates diverse driving styles via dynamic weighting without external preference data, introducing a closed-loop adversarial framework for human-like iterative decision-making, offering a novel scalarization-free trajectory optimization approach.",
    "source": "arXiv"
  },
  {
    "title": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection",
    "title_es": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.09178",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09178v2 Announce Type: replace \nAbstract: Industrial anomaly detection is a critical component of modern manufacturing, yet the scarcity of defective samples restricts traditional detection methods to scenario-specific applications. Although Vision-Language Models (VLMs) demonstrate significant advantages in generalization capabilities, their performance in industrial anomaly detection remains limited. To address this challenge, we propose IAD-R1, a universal post-training framework applicable to VLMs of different architectures and parameter scales, which substantially enhances their anomaly detection capabilities. IAD-R1 employs a two-stage training strategy: the Perception Activation Supervised Fine-Tuning (PA-SFT) stage utilizes a meticulously constructed high-quality Chain-of-Thought dataset (Expert-AD) for training, enhancing anomaly perception capabilities and establishing reasoning-to-answer correlations; the Structured Control Group Relative Policy Optimization (SC-GRPO) stage employs carefully designed reward functions to achieve a capability leap from \"Anomaly Perception\" to \"Anomaly Interpretation\". Experimental results demonstrate that IAD-R1 achieves significant improvements across 7 VLMs, the largest improvement was on the DAGM dataset, with average accuracy 43.3% higher than the 0.5B baseline. Notably, the 0.5B parameter model trained with IAD-R1 surpasses commercial models including GPT-4.1 and Claude-Sonnet-4 in zero-shot settings, demonstrating the effectiveness and superiority of IAD-R1. The dataset, code, and all model weights will be publicly available at https://github.com/Yanhui-Lee/IAD-R1.",
    "source": "arXiv"
  },
  {
    "title": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality",
    "title_es": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality",
    "url": "https://arxiv.org/abs/2508.09185",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09185v2 Announce Type: replace \nAbstract: Augmented Reality (AR) enriches perception by overlaying virtual elements on the physical world. Due to its growing popularity, cognitive attacks that alter AR content to manipulate users' semantic perception have received increasing attention. Existing detection methods often focus on visual changes, which are restricted to pixel- or image-level processing and lack semantic reasoning capabilities, or they rely on pre-trained vision-language models (VLMs), which function as black-box approaches with limited interpretability. In this paper, we present CADAR, a novel neurosymbolic approach for cognitive attack detection in AR. It fuses multimodal vision-language inputs using neural VLMs to obtain a symbolic perception-graph representation, incorporating prior knowledge, salience weighting, and temporal correlations. The model then enables particle-filter based statistical reasoning -- a sequential Monte Carlo method -- to detect cognitive attacks. Thus, CADAR inherits the adaptability of pre-trained VLM and the interpretability and reasoning rigor of particle filtering. Experiments on an extended AR cognitive attack dataset show accuracy improvements of up to 10.7% over strong baselines on challenging AR attack scenarios, underscoring the promise of neurosymbolic methods for effective and interpretable cognitive attack detection.",
    "source": "arXiv"
  },
  {
    "title": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method",
    "title_es": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method",
    "url": "https://arxiv.org/abs/2508.09202",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09202v2 Announce Type: replace \nAbstract: Facial expression recognition (FER) models are employed in many video-based affective computing applications, such as human-computer interaction and healthcare monitoring. However, deep FER models often struggle with subtle expressions and high inter-subject variability, limiting their performance in real-world applications. To improve their performance, source-free domain adaptation (SFDA) methods have been proposed to personalize a pretrained source model using only unlabeled target domain data, thereby avoiding data privacy, storage, and transmission constraints. This paper addresses a challenging scenario where source data is unavailable for adaptation, and only unlabeled target data consisting solely of neutral expressions is available. SFDA methods are not typically designed to adapt using target data from only a single class. Further, using models to generate facial images with non-neutral expressions can be unstable and computationally intensive. In this paper, personalized feature translation (PFT) is proposed for SFDA. Unlike current image translation methods for SFDA, our lightweight method operates in the latent space. We first pre-train the translator on the source domain data to transform the subject-specific style features from one source subject into another. Expression information is preserved by optimizing a combination of expression consistency and style-aware objectives. Then, the translator is adapted on neutral target data, without using source data or image synthesis. By translating in the latent space, PFT avoids the complexity and noise of face expression generation, producing discriminative embeddings optimized for classification. Using PFT eliminates the need for image synthesis, reduces computational overhead (using a lightweight translator), and only adapts part of the model, making the method efficient compared to image-based translation.",
    "source": "arXiv"
  },
  {
    "title": "Biased AI improves human decision-making but reduces trust",
    "title_es": "Biased AI improves human decision-making but reduces trust",
    "url": "https://arxiv.org/abs/2508.09297",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09297v2 Announce Type: replace \nAbstract: Current AI systems minimize risk by enforcing ideological neutrality, yet this may introduce automation bias by suppressing cognitive engagement in human decision-making. We conducted randomized trials with 2,500 participants to test whether culturally biased AI enhances human decision-making. Participants interacted with politically diverse GPT-4o variants on information evaluation tasks. Partisan AI assistants enhanced human performance, increased engagement, and reduced evaluative bias compared to non-biased counterparts, with amplified benefits when participants encountered opposing views. These gains carried a trust penalty: participants underappreciated biased AI and overcredited neutral systems. Exposing participants to two AIs whose biases flanked human perspectives closed the perception-performance gap. These findings complicate conventional wisdom about AI neutrality, suggesting that strategic integration of diverse cultural biases may foster improved and resilient human decision-making.",
    "source": "arXiv"
  },
  {
    "title": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation",
    "title_es": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation",
    "url": "https://arxiv.org/abs/2508.09299",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09299v2 Announce Type: replace \nAbstract: Weather forecasting plays a vital role in disaster preparedness, agriculture, and resource management, yet current centralized forecasting systems are increasingly strained by security vulnerabilities, limited scalability, and susceptibility to single points of failure. To address these challenges, we propose a decentralized weather forecasting framework that integrates Federated Learning (FL) with blockchain technology. FL enables collaborative model training without exposing sensitive local data; this approach enhances privacy and reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures transparent and dependable verification of model updates. To further enhance the system's security, we introduce a reputation-based voting mechanism that assesses the trustworthiness of submitted models while utilizing the Interplanetary File System (IPFS) for efficient off-chain storage. Experimental results demonstrate that our approach not only improves forecasting accuracy but also enhances system resilience and scalability, making it a viable candidate for deployment in real-world, security-critical environments.",
    "source": "arXiv"
  },
  {
    "title": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models",
    "title_es": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models",
    "url": "https://arxiv.org/abs/2508.09403",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09403v2 Announce Type: replace \nAbstract: Expanding the abbreviated column names of tables, such as \"esal\" to \"employee salary\", is critical for numerous downstream data tasks. This problem arises in enterprises, domain sciences, government agencies, and more. In this paper we make three contributions that significantly advances the state of the art. First, we show that synthetic public data used by prior work has major limitations, and we introduce 4 new datasets in enterprise/science domains, with real-world abbreviations. Second, we show that accuracy measures used by prior work seriously undercount correct expansions, and we propose new synonym-aware measures that capture accuracy much more accurately. Finally, we develop Columbo, a powerful LLM-based solution that exploits context, rules, chain-of-thought reasoning, and token-level analysis. Extensive experiments show that Columbo significantly outperforms NameGuess, the current most advanced solution, by 4-29%, over 5 datasets. Columbo has been used in production on EDI, a major data portal for environmental sciences.",
    "source": "arXiv"
  },
  {
    "title": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis",
    "title_es": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis",
    "url": "https://arxiv.org/abs/2508.09458",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09458v2 Announce Type: replace \nAbstract: Knowledge syntheses (literature reviews) are essential to health professions education (HPE), consolidating findings to advance theory and practice. However, they are labor-intensive, especially during data extraction. Artificial Intelligence (AI)-assisted extraction promises efficiency but raises concerns about accuracy, making it critical to distinguish AI 'hallucinations' (fabricated content) from legitimate interpretive differences. We developed an extraction platform using large language models (LLMs) to automate data extraction and compared AI to human responses across 187 publications and 17 extraction questions from a published scoping review. AI-human, human-human, and AI-AI consistencies were measured using interrater reliability (categorical) and thematic similarity ratings (open-ended). Errors were identified by comparing extracted responses to source publications. AI was highly consistent with humans for concrete, explicitly stated questions (e.g., title, aims) and lower for questions requiring subjective interpretation or absent in text (e.g., Kirkpatrick's outcomes, study rationale). Human-human consistency was not higher than AI-human and showed the same question-dependent variability. Discordant AI-human responses (769/3179 = 24.2%) were mostly due to interpretive differences (18.3%); AI inaccuracies were rare (1.51%), while humans were nearly three times more likely to state inaccuracies (4.37%). Findings suggest AI variability depends more on interpretability than hallucination. Repeating AI extraction can identify interpretive complexity or ambiguity, refining processes before human review. AI can be a transparent, trustworthy partner in knowledge synthesis, though caution is needed to preserve critical human insights.",
    "source": "arXiv"
  },
  {
    "title": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts",
    "title_es": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts",
    "url": "https://arxiv.org/abs/2508.09476",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09476v2 Announce Type: replace \nAbstract: Current video generation models struggle with identity preservation under large facial angles, primarily facing two challenges: the difficulty in exploring an effective mechanism to integrate identity features into DiT structure, and the lack of targeted coverage of large facial angles in existing open-source video datasets. To address these, we present two key innovations. First, we introduce a Mixture of Facial Experts (MoFE) that dynamically combines complementary cues from three specialized experts, each designed to capture distinct but mutually reinforcing aspects of facial attributes. The identity expert captures cross-pose identity-sensitive features, the semantic expert extracts high-level visual semantxics, and the detail expert preserves pixel-level features (e.g., skin texture, color gradients). Furthermore, to mitigate dataset limitations, we have tailored a data processing pipeline centered on two key aspects: Face Constraints and Identity Consistency. Face Constraints ensure facial angle diversity and a high proportion of facial regions, while Identity Consistency preserves coherent person-specific features across temporal sequences, collectively addressing the scarcity of large facial angles and identity-stable training data in existing datasets. Leveraging this pipeline, we have curated and refined a Large Face Angles (LFA) Dataset from existing open-source human video datasets, comprising 460K video clips with annotated facial angles. Experimental results on the LFA benchmark demonstrate that our method, empowered by the LFA dataset, significantly outperforms prior SOTA methods in face similarity, face FID, and CLIP semantic alignment. The code and dataset will be made publicly available at https://github.com/rain152/LFA-Video-Generation.",
    "source": "arXiv"
  },
  {
    "title": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking",
    "title_es": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking",
    "url": "https://arxiv.org/abs/2508.09524",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09524v2 Announce Type: replace \nAbstract: In this paper, we present the first systematic investigation and quantification of Similar Object Interference (SOI), a long-overlooked yet critical bottleneck in Single Object Tracking (SOT). Through controlled Online Interference Masking (OIM) experiments, we quantitatively demonstrate that eliminating interference sources leads to substantial performance improvements (AUC gains up to 4.35) across all SOTA trackers, directly validating SOI as a primary constraint for robust tracking and highlighting the feasibility of external cognitive guidance. Building upon these insights, we adopt natural language as a practical form of external guidance, and construct SOIBench-the first semantic cognitive guidance benchmark specifically targeting SOI challenges. It automatically mines SOI frames through multi-tracker collective judgment and introduces a multi-level annotation protocol to generate precise semantic guidance texts. Systematic evaluation on SOIBench reveals a striking finding: existing vision-language tracking (VLT) methods fail to effectively exploit semantic cognitive guidance, achieving only marginal improvements or even performance degradation (AUC changes of -0.26 to +0.71). In contrast, we propose a novel paradigm employing large-scale vision-language models (VLM) as external cognitive engines that can be seamlessly integrated into arbitrary RGB trackers. This approach demonstrates substantial improvements under semantic cognitive guidance (AUC gains up to 0.93), representing a significant advancement over existing VLT methods. We hope SOIBench will serve as a standardized evaluation platform to advance semantic cognitive tracking research and contribute new insights to the tracking research community.",
    "source": "arXiv"
  },
  {
    "title": "Iterative Volume Fusion for Asymmetric Stereo Matching",
    "title_es": "Iterative Volume Fusion for Asymmetric Stereo Matching",
    "url": "https://arxiv.org/abs/2508.09543",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09543v2 Announce Type: replace \nAbstract: Stereo matching is vital in 3D computer vision, with most algorithms assuming symmetric visual properties between binocular visions. However, the rise of asymmetric multi-camera systems (e.g., tele-wide cameras) challenges this assumption and complicates stereo matching. Visual asymmetry disrupts stereo matching by affecting the crucial cost volume computation. To address this, we explore the matching cost distribution of two established cost volume construction methods in asymmetric stereo. We find that each cost volume experiences distinct information distortion, indicating that both should be comprehensively utilized to solve the issue. Based on this, we propose the two-phase Iterative Volume Fusion network for Asymmetric Stereo matching (IVF-AStereo). Initially, the aggregated concatenation volume refines the correlation volume. Subsequently, both volumes are fused to enhance fine details. Our method excels in asymmetric scenarios and shows robust performance against significant visual asymmetry. Extensive comparative experiments on benchmark datasets, along with ablation studies, confirm the effectiveness of our approach in asymmetric stereo with resolution and color degradation.",
    "source": "arXiv"
  },
  {
    "title": "CS-Agent: LLM-based Community Search via Dual-agent Collaboration",
    "title_es": "CS-Agent: LLM-based Community Search via Dual-agent Collaboration",
    "url": "https://arxiv.org/abs/2508.09549",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09549v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks, yet their application to graph structure analysis, particularly in community search, remains underexplored. Community search, a fundamental task in graph analysis, aims to identify groups of nodes with dense interconnections, which is crucial for understanding the macroscopic structure of graphs. In this paper, we propose GraphCS, a comprehensive benchmark designed to evaluate the performance of LLMs in community search tasks. Our experiments reveal that while LLMs exhibit preliminary potential, they frequently fail to return meaningful results and suffer from output bias. To address these limitations, we introduce CS-Agent, a dual-agent collaborative framework to enhance LLM-based community search. CS-Agent leverages the complementary strengths of two LLMs acting as Solver and Validator. Through iterative feedback and refinement, CS-Agent dynamically refines initial results without fine-tuning or additional training. After the multi-round dialogue, Decider module selects the optimal community. Extensive experiments demonstrate that CS-Agent significantly improves the quality and stability of identified communities compared to baseline methods. To our knowledge, this is the first work to apply LLMs to community search, bridging the gap between LLMs and graph analysis while providing a robust and adaptive solution for real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization",
    "title_es": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization",
    "url": "https://arxiv.org/abs/2508.09560",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09560v2 Announce Type: replace \nAbstract: Visual geo-localization for drones faces critical degradation under weather perturbations, \\eg, rain and fog, where existing methods struggle with two inherent limitations: 1) Heavy reliance on limited weather categories that constrain generalization, and 2) Suboptimal disentanglement of entangled scene-weather features through pseudo weather categories. We present WeatherPrompt, a multi-modality learning paradigm that establishes weather-invariant representations through fusing the image embedding with the text context. Our framework introduces two key contributions: First, a Training-free Weather Reasoning mechanism that employs off-the-shelf large multi-modality models to synthesize multi-weather textual descriptions through human-like reasoning. It improves the scalability to unseen or complex weather, and could reflect different weather strength. Second, to better disentangle the scene and weather feature, we propose a multi-modality framework with the dynamic gating mechanism driven by the text embedding to adaptively reweight and fuse visual features across modalities. The framework is further optimized by the cross-modal objectives, including image-text contrastive learning and image-text matching, which maps the same scene with different weather conditions closer in the respresentation space. Extensive experiments validate that, under diverse weather conditions, our method achieves competitive recall rates compared to state-of-the-art drone geo-localization methods. Notably, it improves Recall@1 by +13.37\\% under night conditions and by 18.69\\% under fog and snow conditions.",
    "source": "arXiv"
  },
  {
    "title": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs",
    "title_es": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs",
    "url": "https://arxiv.org/abs/2508.09584",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09584v2 Announce Type: replace \nAbstract: Despite rapid advances, Large Vision-Language Models (LVLMs) still suffer from hallucinations, i.e., generating content inconsistent with input or established world knowledge, which correspond to faithfulness and factuality hallucinations, respectively. Prior studies primarily evaluate faithfulness hallucination at a rather coarse level (e.g., object-level) and lack fine-grained analysis. Additionally, existing benchmarks often rely on costly manual curation or reused public datasets, raising concerns about scalability and data leakage. To address these limitations, we propose an automated data construction pipeline that produces scalable, controllable, and diverse evaluation data. We also design a hierarchical hallucination induction framework with input perturbations to simulate realistic noisy scenarios. Integrating these designs, we construct SHALE, a Scalable HALlucination Evaluation benchmark designed to assess both faithfulness and factuality hallucinations via a fine-grained hallucination categorization scheme. SHALE comprises over 30K image-instruction pairs spanning 12 representative visual perception aspects for faithfulness and 6 knowledge domains for factuality, considering both clean and noisy scenarios. Extensive experiments on over 20 mainstream LVLMs reveal significant factuality hallucinations and high sensitivity to semantic perturbations.",
    "source": "arXiv"
  },
  {
    "title": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation",
    "title_es": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation",
    "url": "https://arxiv.org/abs/2508.09626",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09626v2 Announce Type: replace \nAbstract: In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS), traditional methods struggle to address semantic ambiguity caused by scale variations and structural occlusions in aerial images. This limits their segmentation accuracy and consistency. To tackle these challenges, we propose a novel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian point drop module, which integrates semantic confidence estimation with a learnable sparsity mechanism based on the Hard Concrete distribution. This module effectively eliminates redundant and semantically ambiguous Gaussian points, enhancing both segmentation performance and representation compactness. Furthermore, SAD-Splat incorporates a high-confidence pseudo-label generation pipeline. It leverages 2D foundation models to enhance supervision when ground-truth labels are limited, thereby further improving segmentation accuracy. To advance research in this domain, we introduce a challenging benchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse real-world aerial scenes with sparse annotations. Experimental results demonstrate that SAD-Splat achieves an excellent balance between segmentation accuracy and representation compactness. It offers an efficient and scalable solution for 3D aerial scene understanding.",
    "source": "arXiv"
  },
  {
    "title": "Preacher: Paper-to-Video Agentic System",
    "title_es": "Preacher: Paper-to-Video Agentic System",
    "url": "https://arxiv.org/abs/2508.09632",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09632v2 Announce Type: replace \nAbstract: The paper-to-video task converts a research paper into a structured video abstract, distilling key concepts, methods, and conclusions into an accessible, well-organized format. While state-of-the-art video generation models demonstrate potential, they are constrained by limited context windows, rigid video duration constraints, limited stylistic diversity, and an inability to represent domain-specific knowledge. To address these limitations, we introduce Preacher, the first paper-to-video agentic system. Preacher employs a topdown approach to decompose, summarize, and reformulate the paper, followed by bottom-up video generation, synthesizing diverse video segments into a coherent abstract. To align cross-modal representations, we define key scenes and introduce a Progressive Chain of Thought (P-CoT) for granular, iterative planning. Preacher successfully generates high-quality video abstracts across five research fields, demonstrating expertise beyond current video generation models. Code will be released at: https://github.com/GenVerse/Paper2Video",
    "source": "arXiv"
  },
  {
    "title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts",
    "title_es": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts",
    "url": "https://arxiv.org/abs/2508.09848",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09848v2 Announce Type: replace \nAbstract: We introduce PRELUDE, a benchmark for evaluating long-context understanding through the task of determining whether a character's prequel story is consistent with the canonical narrative of the original book. Our task poses a stronger demand for global comprehension and deep reasoning than existing benchmarks -- as the prequels are not part of the original story, assessing their plausibility typically requires searching and integrating information that is only indirectly related. Empirically, 88% of instances require evidence from multiple parts of the narrative. Experimental results highlight the challenge of our task: in-context learning, RAG and in-domain training with state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans by >15%. A further human study reveals that models often produce correct answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy compared to humans. These findings underscore the substantial room for improvement in long-context understanding and reasoning.",
    "source": "arXiv"
  },
  {
    "title": "Mathematical Computation and Reasoning Errors by Large Language Models",
    "title_es": "Mathematical Computation and Reasoning Errors by Large Language Models",
    "url": "https://arxiv.org/abs/2508.09932",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09932v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are increasingly utilized in AI-driven educational instruction and assessment, particularly within mathematics education. The capability of LLMs to generate accurate answers and detailed solutions for math problem-solving tasks is foundational for ensuring reliable and precise feedback and assessment in math education practices. Our study focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1, DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including arithmetic, algebra, and number theory, and identifies step-level reasoning errors within their solutions. Instead of relying on standard benchmarks, we intentionally build math tasks (via item models) that are challenging for LLMs and prone to errors. The accuracy of final answers and the presence of errors in individual solution steps were systematically analyzed and coded. Both single-agent and dual-agent configurations were tested. It is observed that the reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly perfect accuracy across all three math task categories. Analysis of errors revealed that procedural slips were the most frequent and significantly impacted overall performance, while conceptual misunderstandings were less frequent. Deploying dual-agent configurations substantially improved overall performance. These findings offer actionable insights into enhancing LLM performance and underscore effective strategies for integrating LLMs into mathematics education, thereby advancing AI-driven instructional practices and assessment precision.",
    "source": "arXiv"
  },
  {
    "title": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering",
    "title_es": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering",
    "url": "https://arxiv.org/abs/2508.09956",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09956v2 Announce Type: replace \nAbstract: Large language models (LLMs) such as GPT-5 integrate advanced reasoning capabilities that may improve performance on complex medical question-answering tasks. For this latest generation of reasoning models, the configurations that maximize both accuracy and cost-efficiency have yet to be established. We evaluated 12 configurations of OpenAI's GPT-5 series (three model tiers across four reasoning effort settings) alongside o1-high, o3-high, and GPT-4o, using 260 closed-access multiple-choice questions from the American Academy of Ophthalmology Basic Clinical Science Course (BCSC) dataset. The primary outcome was multiple-choice accuracy; secondary outcomes included head-to-head ranking via a Bradley-Terry model, rationale quality assessment using a reference-anchored, pairwise LLM-as-a-judge framework, and analysis of accuracy-cost trade-offs using token-based cost estimates. GPT-5-high achieved the highest accuracy (0.965; 95% CI, 0.942-0.985), outperforming all GPT-5-nano variants (P < .001), o1-high (P = .04), and GPT-4o (P < .001), but not o3-high (0.958; 95% CI, 0.931-0.981). GPT-5-high ranked first in both accuracy (1.66x stronger than o3-high) and rationale quality (1.11x stronger than o3-high). Cost-accuracy analysis identified several GPT-5 configurations on the Pareto frontier, with GPT-5-mini-low offering the most favorable low-cost, high-performance balance. These results benchmark GPT-5 on a high-quality ophthalmology dataset, demonstrate the influence of reasoning effort on accuracy, and introduce an autograder framework for scalable evaluation of LLM-generated answers against reference standards in ophthalmology.",
    "source": "arXiv"
  },
  {
    "title": "Continuous Parallel Relaxation for Finding Diverse Solutions in Combinatorial Optimization Problems",
    "title_es": "Continuous Parallel Relaxation for Finding Diverse Solutions in Combinatorial Optimization Problems",
    "url": "https://arxiv.org/abs/2402.02190",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2402.02190v3 Announce Type: replace-cross \nAbstract: Finding the optimal solution is often the primary goal in combinatorial optimization (CO). However, real-world applications frequently require diverse solutions rather than a single optimum, particularly in two key scenarios. The first scenario occurs in real-world applications where strictly enforcing every constraint is neither necessary nor desirable. Allowing minor constraint violations can often lead to more cost-effective solutions. This is typically achieved by incorporating the constraints as penalty terms in the objective function, which requires careful tuning of penalty parameters. The second scenario involves cases where CO formulations tend to oversimplify complex real-world factors, such as domain knowledge, implicit trade-offs, or ethical considerations. To address these challenges, generating (i) penalty-diversified solutions by varying penalty intensities and (ii) variation-diversified solutions with distinct structural characteristics provides valuable insights, enabling practitioners to post-select the most suitable solution for their specific needs. However, efficiently discovering these diverse solutions is more challenging than finding a single optimal one. This study introduces Continual Parallel Relaxation Annealing (CPRA), a computationally efficient framework for unsupervised-learning (UL)-based CO solvers that generates diverse solutions within a single training run. CPRA leverages representation learning and parallelization to automatically discover shared representations, substantially accelerating the search for these diverse solutions. Numerical experiments demonstrate that CPRA outperforms existing UL-based solvers in generating these diverse solutions while significantly reducing computational costs.",
    "source": "arXiv"
  },
  {
    "title": "Hypothesis Spaces for Deep Learning",
    "title_es": "Hypothesis Spaces for Deep Learning",
    "url": "https://arxiv.org/abs/2403.03353",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2403.03353v3 Announce Type: replace-cross \nAbstract: This paper introduces a hypothesis space for deep learning based on deep neural networks (DNNs). By treating a DNN as a function of two variables - the input variable and the parameter variable - we consider the set of DNNs where the parameter variable belongs to a space of weight matrices and biases determined by a prescribed depth and layer widths. To construct a Banach space of functions of the input variable, we take the weak* closure of the linear span of this DNN set. We prove that the resulting Banach space is a reproducing kernel Banach space (RKBS) and explicitly construct its reproducing kernel. Furthermore, we investigate two learning models - regularized learning and the minimum norm interpolation (MNI) problem - within the RKBS framework by establishing representer theorems. These theorems reveal that the solutions to these learning problems can be expressed as a finite sum of kernel expansions based on training data.",
    "source": "arXiv"
  },
  {
    "title": "A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set",
    "title_es": "A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set",
    "url": "https://arxiv.org/abs/2405.20124",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2405.20124v2 Announce Type: replace-cross \nAbstract: The state-of-the-art methods for estimating high-dimensional covariance matrices all shrink the eigenvalues of the sample covariance matrix towards a data-insensitive shrinkage target. The underlying shrinkage transformation is either chosen heuristically - without compelling theoretical justification - or optimally in view of restrictive distributional assumptions. In this paper, we propose a principled approach to construct covariance estimators without imposing restrictive assumptions. That is, we study distributionally robust covariance estimation problems that minimize the worst-case Frobenius error with respect to all data distributions close to a nominal distribution, where the proximity of distributions is measured via a divergence on the space of covariance matrices. We identify mild conditions on this divergence under which the resulting minimizers represent shrinkage estimators. We show that the corresponding shrinkage transformations are intimately related to the geometrical properties of the underlying divergence. We also prove that our robust estimators are efficiently computable and asymptotically consistent and that they enjoy finite-sample performance guarantees. We exemplify our general methodology by synthesizing explicit estimators induced by the Kullback-Leibler, Fisher-Rao, and Wasserstein divergences. Numerical experiments based on synthetic and real data show that our robust estimators are competitive with state-of-the-art estimators.",
    "source": "arXiv"
  },
  {
    "title": "A Parametric Contextual Online Learning Theory of Brokerage",
    "title_es": "A Parametric Contextual Online Learning Theory of Brokerage",
    "url": "https://arxiv.org/abs/2407.01566",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2407.01566v2 Announce Type: replace-cross \nAbstract: We study the role of contextual information in the online learning problem of brokerage between traders. In this sequential problem, at each time step, two traders arrive with secret valuations about an asset they wish to trade. The learner (a broker) suggests a trading (or brokerage) price based on contextual data about the asset and the market conditions. Then, the traders reveal their willingness to buy or sell based on whether their valuations are higher or lower than the brokerage price. A trade occurs if one of the two traders decides to buy and the other to sell, i.e., if the broker's proposed price falls between the smallest and the largest of their two valuations. We design algorithms for this problem and prove optimal theoretical regret guarantees under various standard assumptions.",
    "source": "arXiv"
  },
  {
    "title": "Extending DD-$\\alpha$AMG on heterogeneous machines",
    "title_es": "Extending DD-$\\alpha$AMG on heterogeneous machines",
    "url": "https://arxiv.org/abs/2407.08092",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2407.08092v3 Announce Type: replace-cross \nAbstract: Multigrid solvers are the standard in modern scientific computing simulations. Domain Decomposition Aggregation-Based Algebraic Multigrid, also known as the DD-$\\alpha$AMG solver, is a successful realization of an algebraic multigrid solver for lattice quantum chromodynamics. Its CPU implementation has made it possible to construct, for some particular discretizations, simulations otherwise computationally unfeasible, and furthermore it has motivated the development and improvement of other algebraic multigrid solvers in the area. From an existing version of DD-$\\alpha$AMG already partially ported via CUDA to run some finest-level operations of the multigrid solver on Nvidia GPUs, we translate the CUDA code here by using HIP to run on the ORISE supercomputer. We moreover extend the smoothers available in DD-$\\alpha$AMG, paying particular attention to Richardson smoothing, which in our numerical experiments has led to a multigrid solver faster than smoothing with GCR and only 10% slower compared to SAP smoothing. Then we port the odd-even-preconditioned versions of GMRES and Richardson via CUDA. Finally, we extend some computationally intensive coarse-grid operations via advanced vectorization.",
    "source": "arXiv"
  },
  {
    "title": "Online Distributional Regression",
    "title_es": "Online Distributional Regression",
    "url": "https://arxiv.org/abs/2407.08750",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2407.08750v3 Announce Type: replace-cross \nAbstract: Large-scale streaming data are common in modern machine learning applications and have led to the development of online learning algorithms. Many fields, such as supply chain management, weather and meteorology, energy markets, and finance, have pivoted towards using probabilistic forecasts. This results in the need not only for accurate learning of the expected value but also for learning the conditional heteroskedasticity and conditional moments. Against this backdrop, we present a methodology for online estimation of regularized, linear distributional models. The proposed algorithm is based on a combination of recent developments for the online estimation of LASSO models and the well-known GAMLSS framework. We provide a case study on day-ahead electricity price forecasting, in which we show the competitive performance of the incremental estimation combined with strongly reduced computational effort. Our algorithms are implemented in a computationally efficient Python package ondil.",
    "source": "arXiv"
  },
  {
    "title": "Sharp Generalization for Nonparametric Regression in Interpolation Space by Over-Parameterized Neural Networks Trained with Preconditioned Gradient Descent and Early-Stopping",
    "title_es": "Sharp Generalization for Nonparametric Regression in Interpolation Space by Over-Parameterized Neural Networks Trained with Preconditioned Gradient Descent and Early-Stopping",
    "url": "https://arxiv.org/abs/2407.11353",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2407.11353v2 Announce Type: replace-cross \nAbstract: We study nonparametric regression using an over-parameterized two-layer neural networks trained with algorithmic guarantees in this paper. We consider the setting where the training features are drawn uniformly from the unit sphere in $\\RR^d$, and the target function lies in an interpolation space commonly studied in statistical learning theory. We demonstrate that training the neural network with a novel Preconditioned Gradient Descent (PGD) algorithm, equipped with early stopping, achieves a sharp regression rate of $\\cO(n^{-\\frac{2\\alpha s'}{2\\alpha s'+1}})$ when the target function is in the interpolation space $\\bth{\\cH_K}^{s'}$ with $s' \\ge 3$. This rate is even sharper than the currently known nearly-optimal rate of $\\cO(n^{-\\frac{2\\alpha s'}{2\\alpha s'+1}})\\log^2(1/\\delta)$, where $n$ is the size of the training data and $\\delta \\in (0,1)$ is a small probability. This rate is also sharper than the standard kernel regression rate of $\\cO(n^{-\\frac{2\\alpha}{2\\alpha+1}})$ obtained under the regular Neural Tangent Kernel (NTK) regime when training the neural network with the vanilla gradient descent (GD), where $2\\alpha = d/(d-1)$. Our analysis is based on two key technical contributions. First, we present a principled decomposition of the network output at each PGD step into a function in the reproducing kernel Hilbert space (RKHS) of a newly induced integral kernel, and a residual function with small $L^{\\infty}$-norm. Second, leveraging this decomposition, we apply local Rademacher complexity theory to tightly control the complexity of the function class comprising all the neural network functions obtained in the PGD iterates. Our results further suggest that PGD enables the neural network to escape the linear NTK regime and achieve improved generalization, as it effectively induces a new kernel termed the integral kernel, compared to the regular NTK arising from the vanilla GD.",
    "source": "arXiv"
  },
  {
    "title": "Evaluation of Speech Foundation Models for ASR on Child-Adult Conversations in Autism Diagnostic Sessions",
    "title_es": "Evaluation of Speech Foundation Models for ASR on Child-Adult Conversations in Autism Diagnostic Sessions",
    "url": "https://arxiv.org/abs/2409.16135",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2409.16135v2 Announce Type: replace-cross \nAbstract: Reliable transcription of child-adult conversations in clinical settings is crucial for diagnosing developmental disorders like Autism. Recent advances in deep learning and availability of large scale transcribed data has led to development of speech foundation models that have shown dramatic improvements in ASR performance. However, their performance on conversational child-adult interactions remains underexplored. In this work, we provide a comprehensive evaluation of ASR performance on a dataset containing child-adult interactions from autism diagnostic sessions, using Whisper, Wav2Vec2, HuBERT, and WavLM. We find that speech foundation models show a noticeable performance drop (15-20% absolute WER) for child speech compared to adult speech in the conversational setting. Then, we fine-tune the best-performing zero-shot model (Whisper-large) using LoRA in a low-resource setting, yielding 8% and 13% absolute WER improvements for child and adult speech, respectively.",
    "source": "arXiv"
  },
  {
    "title": "A Two-Stage Learning-to-Defer Approach for Multi-Task Learning",
    "title_es": "A Two-Stage Learning-to-Defer Approach for Multi-Task Learning",
    "url": "https://arxiv.org/abs/2410.15729",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2410.15729v5 Announce Type: replace-cross \nAbstract: The Two-Stage Learning-to-Defer (L2D) framework has been extensively studied for classification and, more recently, regression tasks. However, many real-world applications require solving both tasks jointly in a multi-task setting. We introduce a novel Two-Stage L2D framework for multi-task learning that integrates classification and regression through a unified deferral mechanism. Our method leverages a two-stage surrogate loss family, which we prove to be both Bayes-consistent and $(\\mathcal{G}, \\mathcal{R})$-consistent, ensuring convergence to the Bayes-optimal rejector. We derive explicit consistency bounds tied to the cross-entropy surrogate and the $L_1$-norm of agent-specific costs, and extend minimizability gap analysis to the multi-expert two-stage regime. We also make explicit how shared representation learning -- commonly used in multi-task models -- affects these consistency guarantees. Experiments on object detection and electronic health record analysis demonstrate the effectiveness of our approach and highlight the limitations of existing L2D methods in multi-task scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Quantum fault tolerance with constant-space and logarithmic-time overheads",
    "title_es": "Quantum fault tolerance with constant-space and logarithmic-time overheads",
    "url": "https://arxiv.org/abs/2411.03632",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2411.03632v2 Announce Type: replace-cross \nAbstract: In a model of fault-tolerant quantum computation with quick and noiseless polyloglog-time auxiliary classical computation, we construct a fault tolerance protocol with constant-space and $\\widetilde{O}(\\log N)$-time overhead, where $\\widetilde{O}(\\cdot)$ hides sub-polylog factors. Our construction utilizes constant-rate quantum locally testable codes (qLTC), new fault-tolerant gadgets on qLTCs and qLDPC codes, and a new analysis framework. In particular, 1) we develop a new simple and self-contained construction of magic state distillation for qubits using qudit quantum Reed-Solomon codes with $(\\log \\frac{1}{\\varepsilon})^{\\gamma}$ spacetime overhead, where $\\gamma \\rightarrow 0$. 2) We prove that the recent family of almost-good qLTCs of Dinur-Lin-Vidick admit parallel single-shot decoders against adversarial errors of weight scaling with the code distance. 3) We develop logical state preparation and logical gate procedures with $\\widetilde{O}(1)$-spacetime overhead on qLTCs. 4) To combine these ingredients, we introduce a new framework of fault tolerance analysis called the weight enumerator formalism. The framework permits easy formal composition of fault-tolerant gadgets, so we expect it to be of independent interest. Our work gives the lowest spacetime overhead to date, which, for the first time, matches that of classical fault tolerance up to sub-polylog factors. We conjecture this is optimal up to sub-polylog factors.",
    "source": "arXiv"
  },
  {
    "title": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis",
    "title_es": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis",
    "url": "https://arxiv.org/abs/2412.02012",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.02012v3 Announce Type: replace-cross \nAbstract: Due to their large sizes, volumetric scans and whole-slide pathology images (WSIs) are often processed by extracting embeddings from local regions and then an aggregator makes predictions from this set. However, current methods require post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize small yet clinically crucial details. To address these limitations, we introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap generation as an inductive bias. Starting from pre-trained feature maps, INSIGHT employs a detection module with small convolutional kernels to capture fine details and a context module with a broader receptive field to suppress local false positives. The resulting internal heatmap highlights diagnostically relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art classification results and high weakly-labeled semantic segmentation performance. Project website and code are available at: https://zhangdylan83.github.io/ewsmia/",
    "source": "arXiv"
  },
  {
    "title": "Bootstrapping, Autonomous Testing, and Initialization System for Si/SiGe Multi-quantum Dot Devices",
    "title_es": "Bootstrapping, Autonomous Testing, and Initialization System for Si/SiGe Multi-quantum Dot Devices",
    "url": "https://arxiv.org/abs/2412.07676",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.07676v3 Announce Type: replace-cross \nAbstract: Semiconductor quantum dot (QD) devices have become central to advancements in spin-based quantum computing. However, the increasing complexity of modern QD devices makes calibration and control -- particularly at elevated temperatures -- a bottleneck to progress, highlighting the need for robust and scalable autonomous solutions. A major hurdle arises from trapped charges within the oxide layers, which induce random offset voltage shifts on gate electrodes, with a standard deviation of approximately 83~\\si{\\milli\\volt} of variation within state-of-the-art present-day devices. Efficient characterization and tuning of large arrays of QD qubits depend on choices of automated protocols. Here, we introduce a physically intuitive framework for a bootstrapping, autonomous testing, and initialization system (BATIS) designed to streamline QD device evaluation and calibration. BATIS navigates high-dimensional gate voltage spaces, automating essential steps such as leakage testing, formation of all current channels, and gate characterization in the presence of trapped charges. For forming the current channels, BATIS follows a non-standard approach that requires a single set of measurements regardless of the number of channels. Demonstrated at $1.3$~\\si{\\kelvin} on a quad-QD Si/Si$_x$Ge$_{1-x}$ device, BATIS eliminates the need for deep cryogenic environments during initial device diagnostics, significantly enhancing scalability and reducing setup times. By requiring only minimal prior knowledge of the device architecture, BATIS represents a platform-agnostic solution, adaptable to various QD systems, which bridges a critical gap in QD autotuning.",
    "source": "arXiv"
  },
  {
    "title": "Using machine learning to inform harvest control rule design in complex fishery settings",
    "title_es": "Using machine learning to inform harvest control rule design in complex fishery settings",
    "url": "https://arxiv.org/abs/2412.12400",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.12400v2 Announce Type: replace-cross \nAbstract: In fishery science, harvest management of size-structured stochastic populations is a long-standing and difficult problem. Rectilinear precautionary policies based on biomass and harvesting reference points have now become a standard approach to this problem. While these standard feedback policies are adapted from analytical or dynamic programming solutions assuming relatively simple ecological dynamics, they are often applied to more complicated ecological settings in the real world. In this paper we explore the problem of designing harvest control rules for partially observed, age-structured, spasmodic fish populations using tools from reinforcement learning (RL) and Bayesian optimization. Our focus is on the case of Walleye fisheries in Alberta, Canada, whose highly variable recruitment dynamics have perplexed managers and ecologists. We optimized and evaluated policies using several complementary performance metrics. The main questions we addressed were: 1. How do standard policies based on reference points perform relative to numerically optimized policies? 2. Can an observation of mean fish weight, in addition to stock biomass, aid policy decisions?",
    "source": "arXiv"
  },
  {
    "title": "Bi-Sparse Unsupervised Feature Selection",
    "title_es": "Bi-Sparse Unsupervised Feature Selection",
    "url": "https://arxiv.org/abs/2412.16819",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2412.16819v2 Announce Type: replace-cross \nAbstract: To deal with high-dimensional unlabeled datasets in many areas, principal component analysis (PCA) has become a rising technique for unsupervised feature selection (UFS). However, most existing PCA-based methods only consider the structure of datasets by embedding a single sparse regularization or constraint on the transformation matrix. In this paper, we introduce a novel bi-sparse method called BSUFS to improve the performance of UFS. The core idea of BSUFS is to incorporate $\\ell_{2,p}$-norm and $\\ell_q$-norm into the classical PCA, which enables our method to select relevant features and filter out irrelevant noises, thereby obtaining discriminative features. Here, the parameters $p$ and $q$ are within the range of $[0, 1)$. Therefore, BSUFS not only constructs a unified framework for bi-sparse optimization, but also includes some existing works as special cases. To solve the resulting non-convex model, we propose an efficient proximal alternating minimization (PAM) algorithm using Stiefel manifold optimization and sparse optimization techniques. In addition, the computational complexity analysis is presented. Extensive numerical experiments on synthetic and real-world datasets demonstrate the effectiveness of our proposed BSUFS. The results reveal the advantages of bi-sparse optimization in feature selection and show its potential for other fields in image processing. Our code is available at https://github.com/xianchaoxiu/BSUFS.",
    "source": "arXiv"
  },
  {
    "title": "Structures preserved by primitive actions of $S_\\omega$",
    "title_es": "Structures preserved by primitive actions of $S_\\omega$",
    "url": "https://arxiv.org/abs/2501.03789",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2501.03789v3 Announce Type: replace-cross \nAbstract: We present a dichotomy for structures $A$ that are preserved by primitive actions of $S_{\\omega} = \\text{Sym}({\\mathbb N})$: such a structure primitively positively constructs all finite structures and the constraint satisfaction problem is NP-complete, or the constraint satisfaction problem for $A$ is in P. To prove our result, we study the first-order reducts of the Johnson graph $J(k)$, for $k \\geq 2$, whose automorphism group $G$ equals the action of $\\text{Sym}({\\mathbb N})$ on the set $V$ of $k$-element subsets of $\\mathbb N$. We use the fact that $J(k)$ has a finitely bounded homogeneous Ramsey expansion and that $G$ is a maximal closed subgroup of $\\text{Sym}(V)$.",
    "source": "arXiv"
  },
  {
    "title": "Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and Guarantees",
    "title_es": "Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and Guarantees",
    "url": "https://arxiv.org/abs/2502.01027",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2502.01027v3 Announce Type: replace-cross \nAbstract: Two-stage Learning-to-Defer (L2D) enables optimal task delegation by assigning each input to either a fixed main model or one of several offline experts, supporting reliable decision-making in complex, multi-agent environments. However, existing L2D frameworks assume clean inputs and are vulnerable to adversarial perturbations that can manipulate query allocation--causing costly misrouting or expert overload. We present the first comprehensive study of adversarial robustness in two-stage L2D systems. We introduce two novel attack strategie--untargeted and targeted--which respectively disrupt optimal allocations or force queries to specific agents. To defend against such threats, we propose SARD, a convex learning algorithm built on a family of surrogate losses that are provably Bayes-consistent and $(\\mathcal{R}, \\mathcal{G})$-consistent. These guarantees hold across classification, regression, and multi-task settings. Empirical results demonstrate that SARD significantly improves robustness under adversarial attacks while maintaining strong clean performance, marking a critical step toward secure and trustworthy L2D deployment.",
    "source": "arXiv"
  },
  {
    "title": "Hyperflux: Pruning Reveals the Importance of Weights",
    "title_es": "Hyperflux: Pruning Reveals the Importance of Weights",
    "url": "https://arxiv.org/abs/2504.05349",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.05349v2 Announce Type: replace-cross \nAbstract: Network pruning is used to reduce inference latency and power consumption in large neural networks. However, most existing methods use ad-hoc heuristics, lacking much insight and justified mainly by empirical results. We introduce Hyperflux, a conceptually grounded L0 pruning approach that estimates each weight's importance through its flux, the gradient's response to the weight's removal. A global pressure term continuously drives all weights toward pruning, with those critical for accuracy being automatically regrown based on their flux. We postulate several properties that naturally follow from our framework and experimentally validate each of them. One such property is the relationship between final sparsity and pressure, for which we derive a generalized scaling-law equation that is used to design our sparsity-controlling scheduler. Empirically, we demonstrate state-of-the-art results with ResNet-50 and VGG-19 on CIFAR-10 and CIFAR-100.",
    "source": "arXiv"
  },
  {
    "title": "Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of reservoir recurrent neural networks",
    "title_es": "Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of reservoir recurrent neural networks",
    "url": "https://arxiv.org/abs/2504.19657",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2504.19657v3 Announce Type: replace-cross \nAbstract: Reservoir computing is a powerful framework for real-time information processing, characterized by its high computational ability and quick learning, with applications ranging from machine learning to biological systems. In this paper, we investigate how the computational ability of reservoir recurrent neural networks (RNNs) scales with an increasing number of readout neurons. First, we demonstrate that the memory capacity of a reservoir RNN scales sublinearly with the number of readout neurons. To elucidate this observation, we develop a theoretical framework for analytically deriving memory capacity that incorporates the effect of neuronal correlations, which have been ignored in prior theoretical work for analytical simplicity. Our theory successfully relates the sublinear scaling of memory capacity to the strength of neuronal correlations. Furthermore, we show this principle holds across diverse types of RNNs, even those beyond the direct applicability of our theory. Next, we numerically investigate the scaling behavior of nonlinear computational ability, which, alongside memory capacity, is crucial for overall computational performance. Our numerical simulations reveal that as memory capacity growth becomes sublinear, increasing the number of readout neurons successively enables nonlinear processing at progressively higher polynomial orders. Our theoretical framework suggests that neuronal correlations govern not only memory capacity but also the sequential growth of nonlinear computational capabilities. Our findings establish a foundation for designing scalable and cost-effective reservoir computing, providing novel insights into the interplay among neuronal correlations, linear memory, and nonlinear processing.",
    "source": "arXiv"
  },
  {
    "title": "Rough sets semantics for the three-valued extension of first-order Priest's da Costa logic",
    "title_es": "Rough sets semantics for the three-valued extension of first-order Priest's da Costa logic",
    "url": "https://arxiv.org/abs/2505.09302",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.09302v2 Announce Type: replace-cross \nAbstract: We provide a rough sets semantics for the three-valued extension of first-order Priest's da Costa logic, which we studied in [Castiglioni, J.L. and Ertola-Biraben, R.C. Modalities combining two negations. {\\em Journal of Logic and Computation} 11:341--356, 2024]. This semantics follows the usual pattern of the semantics for first-order classical logic.",
    "source": "arXiv"
  },
  {
    "title": "Sequential QCQP for Bilevel Optimization with Line Search",
    "title_es": "Sequential QCQP for Bilevel Optimization with Line Search",
    "url": "https://arxiv.org/abs/2505.14647",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.14647v2 Announce Type: replace-cross \nAbstract: Bilevel optimization involves a hierarchical structure where one problem is nested within another, leading to complex interdependencies between levels. We propose a single-loop, tuning-free algorithm that guarantees anytime feasibility, i.e., approximate satisfaction of the lower-level optimality condition, while ensuring descent of the upper-level objective. At each iteration, a convex quadratically-constrained quadratic program (QCQP) with a closed-form solution yields the search direction, followed by a backtracking line search inspired by control barrier functions to ensure safe, uniformly positive step sizes. The resulting method is scalable, requires no hyperparameter tuning, and converges under mild local regularity assumptions. We establish an O(1/k) ergodic convergence rate in terms of a first-order stationary metric and demonstrate the algorithm's effectiveness on representative bilevel tasks.",
    "source": "arXiv"
  },
  {
    "title": "Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing",
    "title_es": "Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing",
    "url": "https://arxiv.org/abs/2505.16332",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2505.16332v2 Announce Type: replace-cross \nAbstract: Quantum optimization is the most mature quantum computing technology to date, providing a promising approach towards efficiently solving complex combinatorial problems. Methods such as adiabatic quantum computing (AQC) have been employed in recent years on important optimization problems across various domains. In deep learning, deep neural networks (DNN) have reached immense sizes to support new predictive capabilities. Optimization of large-scale models is critical for sustainable deployment, but becomes increasingly challenging with ever-growing model sizes and complexity. While quantum optimization is suitable for solving complex problems, its application to DNN optimization is not straightforward, requiring thorough reformulation for compatibility with commercially available quantum devices. In this work, we explore the potential of adopting AQC for fine-grained pruning-quantization of convolutional neural networks. We rework established heuristics to formulate model compression as a quadratic unconstrained binary optimization (QUBO) problem, and assess the solution space offered by commercial quantum annealing devices. Through our exploratory efforts of reformulation, we demonstrate that AQC can achieve effective compression of practical DNN models. Experiments demonstrate that adiabatic quantum computing (AQC) not only outperforms classical algorithms like genetic algorithms and reinforcement learning in terms of time efficiency but also excels at identifying global optima.",
    "source": "arXiv"
  },
  {
    "title": "EvRWKV: A Continuous Interactive RWKV Framework for Effective Event-Guided Low-Light Image Enhancement",
    "title_es": "EvRWKV: A Continuous Interactive RWKV Framework for Effective Event-Guided Low-Light Image Enhancement",
    "url": "https://arxiv.org/abs/2507.03184",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.03184v2 Announce Type: replace-cross \nAbstract: Capturing high-quality visual content under low-light conditions remains a challenging problem due to severe noise and underexposure, which degrade the performance of downstream applications. Traditional frame-based low-light image enhancement methods often amplify noise or fail to preserve structural details. Event cameras, offering high dynamic range and microsecond temporal resolution by asynchronously capturing brightness changes, emerge as a promising complement for low-light imaging. However, existing fusion methods fail to fully exploit this synergy, either by forcing modalities into a shared representation too early or by losing vital low-level correlations through isolated processing. To address these challenges, we propose EvRWKV, a novel framework that enables continuous cross-modal interaction through dual-domain processing. Our approach incorporates a Cross-RWKV module, leveraging the Receptance Weighted Key Value (RWKV) architecture for fine-grained temporal and cross-modal fusion, and an Event Image Spectral Fusion Enhancer (EISFE) module, which jointly performs adaptive frequency-domain noise suppression and spatial-domain deformable convolution alignment. This continuous interaction maintains feature consistency from low-level textures to high-level semantics. Extensive qualitative and quantitative evaluations on real-world low-light datasets (SDE, SDSD, RELED) demonstrate that EvRWKV achieves state-of-the-art performance, effectively enhancing image quality by suppressing noise, restoring structural details, and improving visual clarity in challenging low-light conditions.",
    "source": "arXiv"
  },
  {
    "title": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration",
    "title_es": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration",
    "url": "https://arxiv.org/abs/2507.08162",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.08162v2 Announce Type: replace-cross \nAbstract: Red-blood-cell lysis (HC50) is the principal safety barrier for antimicrobial-peptide (AMP) therapeutics, yet existing models only say \"toxic\" or \"non-toxic.\" AmpLyze closes this gap by predicting the actual HC50 value from sequence alone and explaining the residues that drive toxicity. The model couples residue-level ProtT5/ESM2 embeddings with sequence-level descriptors in dual local and global branches, aligned by a cross-attention module and trained with log-cosh loss for robustness to assay noise. The optimal AmpLyze model reaches a PCC of 0.756 and an MSE of 0.987, outperforming classical regressors and the state-of-the-art. Ablations confirm that both branches are essential, and cross-attention adds a further 1% PCC and 3% MSE improvement. Expected-Gradients attributions reveal known toxicity hotspots and suggest safer substitutions. By turning hemolysis assessment into a quantitative, sequence-based, and interpretable prediction, AmpLyze facilitates AMP design and offers a practical tool for early-stage toxicity screening.",
    "source": "arXiv"
  },
  {
    "title": "MIRRAMS: Learning Robust Tabular Models under Unseen Missingness Shifts",
    "title_es": "MIRRAMS: Learning Robust Tabular Models under Unseen Missingness Shifts",
    "url": "https://arxiv.org/abs/2507.08280",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2507.08280v2 Announce Type: replace-cross \nAbstract: The presence of missing values often reflects variations in data collection policies, which may shift across time or locations, even when the underlying feature distribution remains stable. Such shifts in the missingness distribution between training and test inputs pose a significant challenge to achieving robust predictive performance. In this study, we propose a novel deep learning framework designed to address this challenge, particularly in the common yet challenging scenario where the test-time dataset is unseen. We begin by introducing a set of mutual information-based conditions, called MI robustness conditions, which guide the prediction model to extract label-relevant information. This promotes robustness against distributional shifts in missingness at test-time. To enforce these conditions, we design simple yet effective loss terms that collectively define our final objective, called MIRRAMS. Importantly, our method does not rely on any specific missingness assumption such as MCAR, MAR, or MNAR, making it applicable to a broad range of scenarios. Furthermore, it can naturally extend to cases where labels are also missing in training data, by generalizing the framework to a semi-supervised learning setting. Extensive experiments across multiple benchmark tabular datasets demonstrate that MIRRAMS consistently outperforms existing state-of-the-art baselines and maintains stable performance under diverse missingness conditions. Moreover, it achieves superior performance even in fully observed settings, highlighting MIRRAMS as a powerful, off-the-shelf framework for general-purpose tabular learning.",
    "source": "arXiv"
  },
  {
    "title": "Composable Quantum Fault-Tolerance",
    "title_es": "Composable Quantum Fault-Tolerance",
    "url": "https://arxiv.org/abs/2508.08246",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.08246v2 Announce Type: replace-cross \nAbstract: Proving threshold theorems for fault-tolerant quantum computation is a burdensome endeavor with many moving parts that come together in relatively formulaic but lengthy ways. It is difficult and rare to combine elements from multiple papers into a single formal threshold proof, due to the use of different measures of fault-tolerance. In this work, we introduce composable fault-tolerance, a framework that decouples the probabilistic analysis of the noise distribution from the combinatorial analysis of circuit correctness, and enables threshold proofs to compose independently analyzed gadgets easily and rigorously. Within this framework, we provide a library of standard and commonly used gadgets such as memory and logic implemented by constant-depth circuits for quantum low-density parity check codes and distillation. As sample applications, we explicitly write down a threshold proof for computation with surface code and re-derive the constant space-overhead fault-tolerant scheme of Gottesman using gadgets from this library. We expect that future fault-tolerance proofs may focus on the analysis of novel techniques while leaving the standard components to the composable fault-tolerance framework, with the formal proof following the intuitive ``napkin math'' exactly.",
    "source": "arXiv"
  },
  {
    "title": "Optimization-Free Fast Optimal Control: Bang-Ride Property, Monotonicity, and Applications to Fast Battery Charging",
    "title_es": "Optimization-Free Fast Optimal Control: Bang-Ride Property, Monotonicity, and Applications to Fast Battery Charging",
    "url": "https://arxiv.org/abs/2508.09010",
    "published": "2025-08-15T04:00:00.000Z",
    "date": "2025-08-15",
    "content_es": "arXiv:2508.09010v2 Announce Type: replace-cross \nAbstract: Single-input fast optimal control problems, which aim to achieve the optimal objective as fast as possible, occur in various real-world applications. In the case of fast battery charging, the associated optimal control problem becomes computationally challenging when detailed battery models are used. A recent heuristic optimization-free algorithm can significantly reduce the computational cost and provide an approximate solution, consistent with many heuristic input profiles in practice. These heuristic solutions have several special properties: They follow a bang-ride pattern that always activates a constraint and applies the maximum feasible input. This work investigates when the above properties arise in the optimal input, and ultimately, when the heuristic input profiles satisfy necessary optimality conditions. By exploiting Pontryagin's maximum principle (PMP), we show that the optimal control is bang-ride under regularity conditions on constraint switching and local controllability of the system. Moreover, the special type of bang-ride behavior, i.e., applying the maximum feasible input, arises under the monotonicity of the system, objective function, and restricted sensitivity of the constraints. These results provide a theoretical justification for a class of charging heuristics and the fast optimization-free algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Leading a lab, and all it entails",
    "title_es": "Leading a lab, and all it entails",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady7700",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 690-690, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The Sisyphean quest for scientific certainty",
    "title_es": "The Sisyphean quest for scientific certainty",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea4594",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 691-691, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Predicting fusion ignition at the National Ignition Facility with physics-informed deep learning",
    "title_es": "Predicting fusion ignition at the National Ignition Facility with physics-informed deep learning",
    "url": "https://www.science.org/doi/abs/10.1126/science.adm8201",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 727-731, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Observation of many-body dynamical localization",
    "title_es": "Observation of many-body dynamical localization",
    "url": "https://www.science.org/doi/abs/10.1126/science.adn8625",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 716-719, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Breast milk IgG engages the mouse neonatal immune system to instruct responses to gut antigens",
    "title_es": "Breast milk IgG engages the mouse neonatal immune system to instruct responses to gut antigens",
    "url": "https://www.science.org/doi/abs/10.1126/science.ado5294",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Platelets sequester extracellular DNA, capturing tumor-derived and free fetal DNA",
    "title_es": "Platelets sequester extracellular DNA, capturing tumor-derived and free fetal DNA",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp3971",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Cross-species implementation of an innate courtship behavior by manipulation of the sex-determinant gene",
    "title_es": "Cross-species implementation of an innate courtship behavior by manipulation of the sex-determinant gene",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp5831",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 747-752, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Mitochondria protect against an intracellular pathogen by restricting access to folate",
    "title_es": "Mitochondria protect against an intracellular pathogen by restricting access to folate",
    "url": "https://www.science.org/doi/abs/10.1126/science.adr6326",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Enantioconvergent benzylic C(sp3)‒N coupling with a copper-substituted nonheme enzyme",
    "title_es": "Enantioconvergent benzylic C(sp3)‒N coupling with a copper-substituted nonheme enzyme",
    "url": "https://www.science.org/doi/abs/10.1126/science.adt5986",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 741-746, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Hierarchical chiral supramolecular assemblies with strong and invertible chiroptical properties",
    "title_es": "Hierarchical chiral supramolecular assemblies with strong and invertible chiroptical properties",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu0296",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Modulation of methyl–coenzyme M reductase expression alters the isotopic composition of microbial methane",
    "title_es": "Modulation of methyl–coenzyme M reductase expression alters the isotopic composition of microbial methane",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu2098",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 711-715, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Early germline sequestration in a basidiomycete fungus",
    "title_es": "Early germline sequestration in a basidiomycete fungus",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu8580",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 720-723, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Linalool-triggered plant-soil feedback drives defense adaptation in dense maize plantings",
    "title_es": "Linalool-triggered plant-soil feedback drives defense adaptation in dense maize plantings",
    "url": "https://www.science.org/doi/abs/10.1126/science.adv6675",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Solution-phase stabilization of a cyclocarbon by catenane formation",
    "title_es": "Solution-phase stabilization of a cyclocarbon by catenane formation",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady6054",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 708-710, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Diffraction of helium and hydrogen atoms through single-layer graphene",
    "title_es": "Diffraction of helium and hydrogen atoms through single-layer graphene",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx5679",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 724-726, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Artificial farnesol epoxidase enables a concise synthesis of meroterpenoids",
    "title_es": "Artificial farnesol epoxidase enables a concise synthesis of meroterpenoids",
    "url": "https://www.science.org/doi/abs/10.1126/science.adt2096",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 732-735, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Scalable emulation of protein equilibrium ensembles with generative deep learning",
    "title_es": "Scalable emulation of protein equilibrium ensembles with generative deep learning",
    "url": "https://www.science.org/doi/abs/10.1126/science.adv9817",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "How I learned to ride",
    "title_es": "How I learned to ride",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb3342",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 754-754, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "In Other Journals",
    "title_es": "In Other Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb3932",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 696-697, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The scent of a crowd",
    "title_es": "The scent of a crowd",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz7633",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 680-681, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Seeing with atoms",
    "title_es": "Seeing with atoms",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz7660",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 682-682, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Setting the table for immune tolerance",
    "title_es": "Setting the table for immune tolerance",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8687",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 684-685, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Mitochondria hoard folate to starve a parasite",
    "title_es": "Mitochondria hoard folate to starve a parasite",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea0875",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 685-686, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The ins and outs of circulating DNA",
    "title_es": "The ins and outs of circulating DNA",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea0555",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 683-684, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "West Philippine Sea dispute threatens sea life",
    "title_es": "West Philippine Sea dispute threatens sea life",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx9555",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 694-694, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Risks of ending US science-policy training",
    "title_es": "Risks of ending US science-policy training",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz0737",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 692-692, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Editor’s Note",
    "title_es": "Editor’s Note",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea4953",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 692-692, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Addressing Southeast Asia’s plastic pollution",
    "title_es": "Addressing Southeast Asia’s plastic pollution",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx7543",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 693-693, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Erratum for the Research Article “Flux-induced topological superconductivity in full-shell nanowires” by S. Vaitiekėnas et al.",
    "title_es": "Erratum for the Research Article “Flux-induced topological superconductivity in full-shell nanowires” by S. Vaitiekėnas et al.",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea6837",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Erratum for the Research Article “Improving metrology with quantum scrambling” by Z. Li et al.",
    "title_es": "Erratum for the Research Article “Improving metrology with quantum scrambling” by Z. Li et al.",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2349",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Beyond lab animals",
    "title_es": "Beyond lab animals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb3933",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 676-679, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "NIH weighs controversial overhaul of HIV budget",
    "title_es": "NIH weighs controversial overhaul of HIV budget",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb4272",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 668-669, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Twist on PET unlocks hidden signals",
    "title_es": "Twist on PET unlocks hidden signals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb4273",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 670-671, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Correction in Science rekindles debate over Microsoft’s quantum computing research",
    "title_es": "Correction in Science rekindles debate over Microsoft’s quantum computing research",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb4274",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 672-673, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Europe eyes civilian science funding for defense research",
    "title_es": "Europe eyes civilian science funding for defense research",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb4275",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 673-674, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Trump moves to politicize decisions on science grants",
    "title_es": "Trump moves to politicize decisions on science grants",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb4276",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 675-675, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Robots that share our spaces require proprioception and a sense of touch",
    "title_es": "Robots that share our spaces require proprioception and a sense of touch",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea2492",
    "published": "2025-08-14T07:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Scientists’ role in defending democracy",
    "title_es": "Scientists’ role in defending democracy",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea9328",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 667-667, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Climate-smart biofuel policy as a pathway to decarbonize agriculture",
    "title_es": "Climate-smart biofuel policy as a pathway to decarbonize agriculture",
    "url": "https://www.science.org/doi/abs/10.1126/science.adw6739",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 687-689, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "In Science Journals",
    "title_es": "In Science Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb3931",
    "published": "2025-08-14T06:00:16.000Z",
    "date": "2025-08-14",
    "content_es": "Science, Volume 389, Issue 6761, Page 695-697, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Mysterious coffee species turns out to be a blend",
    "title_es": "Mysterious coffee species turns out to be a blend",
    "url": "https://www.nature.com/articles/d41586-025-02562-2",
    "published": "2025-08-14T00:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Mysterious coffee species turns out to be a blend",
    "source": "Nature"
  },
  {
    "title": "Summer 2025 is roasting hot: these charts show why it matters",
    "title_es": "Summer 2025 is roasting hot: these charts show why it matters",
    "url": "https://www.nature.com/articles/d41586-025-02553-3",
    "published": "2025-08-14T00:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Summer 2025 is roasting hot: these charts show why it matters",
    "source": "Nature"
  },
  {
    "title": "A mind–reading brain implant that comes with password protection",
    "title_es": "A mind–reading brain implant that comes with password protection",
    "url": "https://www.nature.com/articles/d41586-025-02589-5",
    "published": "2025-08-14T00:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "A mind–reading brain implant that comes with password protection",
    "source": "Nature"
  },
  {
    "title": "Controversial quantum-computing paper gets hefty correction — but concerns linger",
    "title_es": "Controversial quantum-computing paper gets hefty correction — but concerns linger",
    "url": "https://www.nature.com/articles/d41586-025-02587-7",
    "published": "2025-08-14T00:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Controversial quantum-computing paper gets hefty correction — but concerns linger",
    "source": "Nature"
  },
  {
    "title": "Brazilian PhD students opt out of US research opportunities",
    "title_es": "Brazilian PhD students opt out of US research opportunities",
    "url": "https://www.nature.com/articles/d41586-025-02486-x",
    "published": "2025-08-14T00:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Brazilian PhD students opt out of US research opportunities",
    "source": "Nature"
  },
  {
    "title": "Brain editing now ‘closer to reality’: the gene-altering tools tackling deadly disorders",
    "title_es": "Brain editing now ‘closer to reality’: the gene-altering tools tackling deadly disorders",
    "url": "https://www.nature.com/articles/d41586-025-02578-8",
    "published": "2025-08-14T00:00:00.000Z",
    "date": "2025-08-14",
    "content_es": "Brain editing now ‘closer to reality’: the gene-altering tools tackling deadly disorders",
    "source": "Nature"
  },
  {
    "title": "Publisher Correction: Liquid–liquid interfacial tension stabilized Li-metal batteries",
    "title_es": "Publisher Correction: Liquid–liquid interfacial tension stabilized Li-metal batteries",
    "url": "https://www.nature.com/articles/s41586-025-09504-y",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Publisher Correction: Liquid–liquid interfacial tension stabilized Li-metal batteries",
    "source": "Nature"
  },
  {
    "title": "Spatial correlation in economic analysis of climate change",
    "title_es": "Spatial correlation in economic analysis of climate change",
    "url": "https://www.nature.com/articles/s41586-025-09206-5",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Spatial correlation in economic analysis of climate change",
    "source": "Nature"
  },
  {
    "title": "Sun-powered flyers could explore the mysterious mesosphere",
    "title_es": "Sun-powered flyers could explore the mysterious mesosphere",
    "url": "https://www.nature.com/articles/d41586-025-02582-y",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Sun-powered flyers could explore the mysterious mesosphere",
    "source": "Nature"
  },
  {
    "title": "Astronomers gave up this comet for dead ― but they were wrong",
    "title_es": "Astronomers gave up this comet for dead ― but they were wrong",
    "url": "https://www.nature.com/articles/d41586-025-02561-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Astronomers gave up this comet for dead ― but they were wrong",
    "source": "Nature"
  },
  {
    "title": "Rubber planting and deforestation",
    "title_es": "Rubber planting and deforestation",
    "url": "https://www.nature.com/articles/s41586-025-08848-9",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Rubber planting and deforestation",
    "source": "Nature"
  },
  {
    "title": "Y. Wang et al. reply",
    "title_es": "Y. Wang et al. reply",
    "url": "https://www.nature.com/articles/s41586-025-08849-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Y. Wang et al. reply",
    "source": "Nature"
  },
  {
    "title": "Accuracy of rubber-related deforestation maps",
    "title_es": "Accuracy of rubber-related deforestation maps",
    "url": "https://www.nature.com/articles/s41586-025-08847-w",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Accuracy of rubber-related deforestation maps",
    "source": "Nature"
  },
  {
    "title": "Acidic oxygen reduction by single-atom Fe catalysts on curved supports",
    "title_es": "Acidic oxygen reduction by single-atom Fe catalysts on curved supports",
    "url": "https://www.nature.com/articles/s41586-025-09364-6",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Acidic oxygen reduction by single-atom Fe catalysts on curved supports",
    "source": "Nature"
  },
  {
    "title": "The geologic history of marine dissolved organic carbon from iron oxides",
    "title_es": "The geologic history of marine dissolved organic carbon from iron oxides",
    "url": "https://www.nature.com/articles/s41586-025-09383-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "The geologic history of marine dissolved organic carbon from iron oxides",
    "source": "Nature"
  },
  {
    "title": "New discoveries of Australopithecus and Homo from Ledi-Geraru, Ethiopia",
    "title_es": "New discoveries of Australopithecus and Homo from Ledi-Geraru, Ethiopia",
    "url": "https://www.nature.com/articles/s41586-025-09390-4",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "New discoveries of Australopithecus and Homo from Ledi-Geraru, Ethiopia",
    "source": "Nature"
  },
  {
    "title": "Expanding the cytokine receptor alphabet reprograms T cells into diverse states",
    "title_es": "Expanding the cytokine receptor alphabet reprograms T cells into diverse states",
    "url": "https://www.nature.com/articles/s41586-025-09393-1",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Expanding the cytokine receptor alphabet reprograms T cells into diverse states",
    "source": "Nature"
  },
  {
    "title": "NASP modulates histone turnover to drive PARP inhibitor resistance",
    "title_es": "NASP modulates histone turnover to drive PARP inhibitor resistance",
    "url": "https://www.nature.com/articles/s41586-025-09414-z",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "NASP modulates histone turnover to drive PARP inhibitor resistance",
    "source": "Nature"
  },
  {
    "title": "Clone copy number diversity is linked to survival in lung cancer",
    "title_es": "Clone copy number diversity is linked to survival in lung cancer",
    "url": "https://www.nature.com/articles/s41586-025-09398-w",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Clone copy number diversity is linked to survival in lung cancer",
    "source": "Nature"
  },
  {
    "title": "Bending the curve of land degradation to achieve global environmental goals",
    "title_es": "Bending the curve of land degradation to achieve global environmental goals",
    "url": "https://www.nature.com/articles/s41586-025-09365-5",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Bending the curve of land degradation to achieve global environmental goals",
    "source": "Nature"
  },
  {
    "title": "Establishment of chromatin architecture interplays with embryo hypertranscription",
    "title_es": "Establishment of chromatin architecture interplays with embryo hypertranscription",
    "url": "https://www.nature.com/articles/s41586-025-09400-5",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Establishment of chromatin architecture interplays with embryo hypertranscription",
    "source": "Nature"
  },
  {
    "title": "Multiple oestradiol functions inhibit ferroptosis and acute kidney injury",
    "title_es": "Multiple oestradiol functions inhibit ferroptosis and acute kidney injury",
    "url": "https://www.nature.com/articles/s41586-025-09389-x",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Multiple oestradiol functions inhibit ferroptosis and acute kidney injury",
    "source": "Nature"
  },
  {
    "title": "Human emissions drive recent trends in North Pacific climate variations",
    "title_es": "Human emissions drive recent trends in North Pacific climate variations",
    "url": "https://www.nature.com/articles/s41586-025-09368-2",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Human emissions drive recent trends in North Pacific climate variations",
    "source": "Nature"
  },
  {
    "title": "Elementary 3D organization of active and silenced E. coli genome",
    "title_es": "Elementary 3D organization of active and silenced E. coli genome",
    "url": "https://www.nature.com/articles/s41586-025-09396-y",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Elementary 3D organization of active and silenced E. coli genome",
    "source": "Nature"
  },
  {
    "title": "The genomic origin of the unique chaetognath body plan",
    "title_es": "The genomic origin of the unique chaetognath body plan",
    "url": "https://www.nature.com/articles/s41586-025-09403-2",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "The genomic origin of the unique chaetognath body plan",
    "source": "Nature"
  },
  {
    "title": "Delocalized electrolyte design enables 600 Wh kg−1 lithium metal pouch cells",
    "title_es": "Delocalized electrolyte design enables 600 Wh kg−1 lithium metal pouch cells",
    "url": "https://www.nature.com/articles/s41586-025-09382-4",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Delocalized electrolyte design enables 600 Wh kg−1 lithium metal pouch cells",
    "source": "Nature"
  },
  {
    "title": "n-Type thermoelectric elastomers",
    "title_es": "n-Type thermoelectric elastomers",
    "url": "https://www.nature.com/articles/s41586-025-09387-z",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "n-Type thermoelectric elastomers",
    "source": "Nature"
  },
  {
    "title": "Calving-driven fjord dynamics resolved by seafloor fibre sensing",
    "title_es": "Calving-driven fjord dynamics resolved by seafloor fibre sensing",
    "url": "https://www.nature.com/articles/s41586-025-09347-7",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Calving-driven fjord dynamics resolved by seafloor fibre sensing",
    "source": "Nature"
  },
  {
    "title": "Countrywide natural experiment links built environment to physical activity",
    "title_es": "Countrywide natural experiment links built environment to physical activity",
    "url": "https://www.nature.com/articles/s41586-025-09321-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Countrywide natural experiment links built environment to physical activity",
    "source": "Nature"
  },
  {
    "title": "Large riverbed sediment flux sustained for a decade after an earthquake&#xa0;",
    "title_es": "Large riverbed sediment flux sustained for a decade after an earthquake&#xa0;",
    "url": "https://www.nature.com/articles/s41586-025-09354-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Large riverbed sediment flux sustained for a decade after an earthquake&#xa0;",
    "source": "Nature"
  },
  {
    "title": "Photophoretic flight of perforated structures in near-space conditions",
    "title_es": "Photophoretic flight of perforated structures in near-space conditions",
    "url": "https://www.nature.com/articles/s41586-025-09281-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Photophoretic flight of perforated structures in near-space conditions",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Why some places on our bodies heal without scars",
    "title_es": "Daily briefing: Why some places on our bodies heal without scars",
    "url": "https://www.nature.com/articles/d41586-025-02632-5",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Daily briefing: Why some places on our bodies heal without scars",
    "source": "Nature"
  },
  {
    "title": "Watch rappelling robots dive into a lava tube — for science",
    "title_es": "Watch rappelling robots dive into a lava tube — for science",
    "url": "https://www.nature.com/articles/d41586-025-02585-9",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Watch rappelling robots dive into a lava tube — for science",
    "source": "Nature"
  },
  {
    "title": "These tiny flyers levitate on the Sun’s heat alone",
    "title_es": "These tiny flyers levitate on the Sun’s heat alone",
    "url": "https://www.nature.com/articles/d41586-025-02576-w",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "These tiny flyers levitate on the Sun’s heat alone",
    "source": "Nature"
  },
  {
    "title": "Many planets might be born with orbits misaligned from the spin of their stars",
    "title_es": "Many planets might be born with orbits misaligned from the spin of their stars",
    "url": "https://www.nature.com/articles/d41586-025-02536-4",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Many planets might be born with orbits misaligned from the spin of their stars",
    "source": "Nature"
  },
  {
    "title": "Null empathy",
    "title_es": "Null empathy",
    "url": "https://www.nature.com/articles/d41586-025-02489-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Null empathy",
    "source": "Nature"
  },
  {
    "title": "A humidity measure that accounts for redistribution of water across the landscape",
    "title_es": "A humidity measure that accounts for redistribution of water across the landscape",
    "url": "https://www.nature.com/articles/d41586-025-02539-1",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "A humidity measure that accounts for redistribution of water across the landscape",
    "source": "Nature"
  },
  {
    "title": "Just how bad will climate change get? The only way to know is to fund basic research",
    "title_es": "Just how bad will climate change get? The only way to know is to fund basic research",
    "url": "https://www.nature.com/articles/d41586-025-02508-8",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Just how bad will climate change get? The only way to know is to fund basic research",
    "source": "Nature"
  },
  {
    "title": "The perplexing body plan of arrow worms decoded",
    "title_es": "The perplexing body plan of arrow worms decoded",
    "url": "https://www.nature.com/articles/d41586-025-02423-y",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "The perplexing body plan of arrow worms decoded",
    "source": "Nature"
  },
  {
    "title": "Levitating platform could ride sunlight into the ‘ignorosphere’",
    "title_es": "Levitating platform could ride sunlight into the ‘ignorosphere’",
    "url": "https://www.nature.com/articles/d41586-025-02355-7",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Levitating platform could ride sunlight into the ‘ignorosphere’",
    "source": "Nature"
  },
  {
    "title": "How to thrive as a Latin American researcher abroad",
    "title_es": "How to thrive as a Latin American researcher abroad",
    "url": "https://www.nature.com/articles/d41586-025-02297-0",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "How to thrive as a Latin American researcher abroad",
    "source": "Nature"
  },
  {
    "title": "Is gravity quantum? Experiments could finally probe one of physics’ biggest questions",
    "title_es": "Is gravity quantum? Experiments could finally probe one of physics’ biggest questions",
    "url": "https://www.nature.com/articles/d41586-025-02509-7",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Is gravity quantum? Experiments could finally probe one of physics’ biggest questions",
    "source": "Nature"
  },
  {
    "title": "Octopus motion in the ocean tracked by a deep-sea 3D camera",
    "title_es": "Octopus motion in the ocean tracked by a deep-sea 3D camera",
    "url": "https://www.nature.com/articles/d41586-025-02542-6",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Octopus motion in the ocean tracked by a deep-sea 3D camera",
    "source": "Nature"
  },
  {
    "title": "Oestrogen defends against kidney damage caused by iron-dependent cell death",
    "title_es": "Oestrogen defends against kidney damage caused by iron-dependent cell death",
    "url": "https://www.nature.com/articles/d41586-025-02422-z",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Oestrogen defends against kidney damage caused by iron-dependent cell death",
    "source": "Nature"
  },
  {
    "title": "Air pollution could be reduced by incentivizing local government officials to control crop burning",
    "title_es": "Air pollution could be reduced by incentivizing local government officials to control crop burning",
    "url": "https://www.nature.com/articles/d41586-025-02545-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Air pollution could be reduced by incentivizing local government officials to control crop burning",
    "source": "Nature"
  },
  {
    "title": "Science Translational Medicine: Una técnica de imagen disponible en hospitales y usada en cáncer mejora el seguimiento y tratamiento de la aterosclerosis  ",
    "title_es": "Science Translational Medicine: Una técnica de imagen disponible en hospitales y usada en cáncer mejora el seguimiento y tratamiento de la aterosclerosis  ",
    "url": "https://www.cnic.es/es/noticias/science-translational-medicine-tecnica-imagen-disponible-hospitales-usada-cancer-mejora",
    "published": "2025-08-13T18:00:47.000Z",
    "date": "2025-08-13",
    "content_es": "12/08/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nEl 18FDG-PET es una técnica de tomografía por emisión de positrones que mide la  cantidad de energía que consumen las células del cuerpo\n\n\n\nUna investigación realizada en el Centro Nacional de Investigaciones Cardiovasculares (CNIC) demuestra que el 18FDG-PET, una técnica de imagen utilizada habitualmente para otras patologías y que mide la energía que consumen las células del cuerpo, también permite monitorizar la actividad de la aterosclerosis midiendo el metabolismo celular de las placas. El hallazgo, publicado en Science Translational Medicine, podría mejorar el seguimiento de esta enfermedad y acelerar el desarrollo de nuevos tratamientos.\nLa aterosclerosis, causa principal de la mayoría de los infartos e ictus, es una enfermedad silenciosa que progresa durante años sin causar síntomas. Se caracteriza por la acumulación de placas de lípidos, células y otras sustancias en las paredes de las arterias, que pueden obstruir el flujo sanguíneo o romperse repentinamente, provocando eventos cardiovasculares graves. Aunque existen tratamientos eficaces para frenar su avance, sigue siendo difícil evaluar con precisión si una intervención médica está funcionando en los pacientes.\nEl 18FDG-PET es una técnica de tomografía por emisión de positrones que utiliza un derivado de la glucosa marcado radiactivamente para detectar la actividad metabólica de los tejidos.\nEn este nuevo estudio, los autores muestran que la señal detectada en un examen de 18FDG-PET refleja el metabolismo celular de las lesiones ateroscleróticas y no únicamente la presencia de inflamación, como se pensaba hasta ahora.\nPara llegar a esta conclusión, el equipo desarrolló un modelo experimental de aterosclerosis avanzada en animales transgénicos, cuya enfermedad pudo revertirse parcialmente mediante una intervención dietética y farmacológica similar a la aplicada en los pacientes.\n\nDurante el proceso de regresión de la enfermedad, la señal obtenida por 18FDG-PET disminuyó de manera significativa, paralelamente a la reducción de genes relacionados con el metabolismo de la glucosa en diversos tipos celulares de la placa, incluidos macrófagos, linfocitos y células musculares lisas.\n“La técnica 18FDG-PET refleja el nivel de actividad de las células de la lesión aterosclerótica, y por tanto puede servir como una herramienta sensible para evaluar el efecto de tratamientos o el riesgo de progresión de la enfermedad”, explica Paula Nogales, investigadora del CNIC y autora principal del trabajo, junto a Jacob Bentzon, líder del grupo en el CNIC y la Universidad de Aarhus (Dinamarca).\nEste hallazgo abre la puerta a aprovechar una técnica ya disponible en muchos hospitales para mejorar el seguimiento clínico de la aterosclerosis y acelerar el desarrollo de nuevos tratamientos dirigidos a esta enfermedad silenciosa pero potencialmente mortal.\nEste trabajo ha recibido financiación del European Research Council (ERC) en el marco del programa de investigación e innovación Horizon 2020 de la Unión Europea; del Ministerio de Economía, Industria y Competitividad (MEIC), con cofinanciación del Fondo Europeo de Desarrollo Regional (FEDER); del Instituto de Salud Carlos III con cofinanciación FEDER/Europa (“Una manera de hacer Europa”); de la Comunidad de Madrid, y de la Fundación ”la Caixa” (AtheroConvergence).\n\nNogales, P., Velasco, C., González-Cintado, L., Sharysh, D., Mota-Cobián, A., Izquierdo-Serrano, R., Torroja, C., del Rio-Aledo, D., Morales-Cano, D., Mota, R. A., Benguría, A., Dopazo, A., Sánchez-Cabo, F., Vázquez, J., España, S., Carramolino, L., Mateo, J., & Bentzon, J. F. (2025). Atherosclerotic disease activity is associated with glycolytic enzyme expression across multiple cell types and is trackable by FDG-PET. Science Translational Medicine. https://doi.org/10.1126/scitranslmed.ado6467",
    "source": "CNIC"
  },
  {
    "title": "Science Translational Medicine: A hospital imaging technique used in cancer care improves the monitoring and treatment of atherosclerosis",
    "title_es": "Science Translational Medicine: A hospital imaging technique used in cancer care improves the monitoring and treatment of atherosclerosis",
    "url": "https://www.cnic.es/es/node/235897",
    "published": "2025-08-13T18:00:47.000Z",
    "date": "2025-08-13",
    "content_es": "12/08/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nEl 18FDG-PET is a type of positron emission tomography that measures how much energy the body’s cells consume.\n\n\n\nScientists at the Centro Nacional de Investigaciones Cardiovasculares (CNIC) have shown that 18FDG-PET, an imaging technique widely used to study other conditions, can also be used to monitor atherosclerosis by measuring cellular metabolism within arterial plaques. The findings, published in Science Translational Medicine, could improve the clinical management of this disease and accelerate the development of new treatments.\nAtherosclerosis—the underlying cause of most heart attacks and strokes—is a silent disease that progresses over many years without symptoms. The disease is characterized by the accumulation of fatty deposits, cells, and other materials in the walls of arteries, where they reduce blood flow and can eventually rupture, triggering serious cardiovascular events. While treatments are available to slow disease progression, it is still difficult to determine if a treatment is working in individual patients.\n18FDG-PET (fluorodeoxyglucose positron emission tomography) is a nuclear imaging technique that uses a radioactively labeled glucose analog to detect tissue metabolic activity.\nThe new study demonstrates that the 18FDG-PET signal reflects the metabolic activity of atherosclerotic plaques, rather than merely indicating inflammation, as was previously believed.\nTo reach this conclusion, the research team developed an experimental model of advanced atherosclerosis in genetically modified animals and was able to partially reverse disease progression using a diet and drug-based intervention similar to strategies used in clinical care.\n\nAs the disease regressed, the 18FDG-PET signal declined in parallel with the reduced expression of genes linked to glucose metabolism in various plaque cell types, including macrophages, lymphocytes, and smooth muscle cells.\n“The 18FDG-PET signal reflects the activity level of the cells within atherosclerotic lesions and can therefore serve as a sensitive tool for evaluating treatment efficacy and disease progression risk,” explains CNIC researcher Paula Nogales, lead author of the study together with Jacob Bentzon, of Aarhus University (Denmark) and head of the Experimental Pathology of Atherosclerosis group at the CNIC.\nThis discovery opens the door to using a widely available hospital imaging technique to improve clinical monitoring of atherosclerosis and speed the development of new therapies for this silent but potentially deadly disease.\nThe study received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme; the Spanish Ministry of Economy, Industry, and Competitiveness (MEIC), with co-funding from the European Regional Development Fund (FEDER); the Instituto de Salud Carlos III, with FEDER/EU co-funding; the Madrid regional government; and the “la Caixa” Foundation (AtheroConvergence).\n\nNogales, P., Velasco, C., González-Cintado, L., Sharysh, D., Mota-Cobián, A., Izquierdo-Serrano, R., Torroja, C., del Rio-Aledo, D., Morales-Cano, D., Mota, R. A., Benguría, A., Dopazo, A., Sánchez-Cabo, F., Vázquez, J., España, S., Carramolino, L., Mateo, J., & Bentzon, J. F. (2025). Atherosclerotic disease activity is associated with glycolytic enzyme expression across multiple cell types and is trackable by FDG-PET. Science Translational Medicine. https://doi.org/10.1126/scitranslmed.ado6467",
    "source": "CNIC"
  },
  {
    "title": "Use AI in the classroom to bring problems to life",
    "title_es": "Use AI in the classroom to bring problems to life",
    "url": "https://www.nature.com/articles/d41586-025-02571-1",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Use AI in the classroom to bring problems to life",
    "source": "Nature"
  },
  {
    "title": "Organs on chips could make biomedical research more equitable",
    "title_es": "Organs on chips could make biomedical research more equitable",
    "url": "https://www.nature.com/articles/d41586-025-02569-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Organs on chips could make biomedical research more equitable",
    "source": "Nature"
  },
  {
    "title": "Europe must safeguard climate data following NASA cuts",
    "title_es": "Europe must safeguard climate data following NASA cuts",
    "url": "https://www.nature.com/articles/d41586-025-02572-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Europe must safeguard climate data following NASA cuts",
    "source": "Nature"
  },
  {
    "title": "Study how screen time affects circadian rhythms",
    "title_es": "Study how screen time affects circadian rhythms",
    "url": "https://www.nature.com/articles/d41586-025-02570-2",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Study how screen time affects circadian rhythms",
    "source": "Nature"
  },
  {
    "title": "How Paris dealt with lightning in the Age of Enlightenment",
    "title_es": "How Paris dealt with lightning in the Age of Enlightenment",
    "url": "https://www.nature.com/articles/d41586-025-02429-6",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "How Paris dealt with lightning in the Age of Enlightenment",
    "source": "Nature"
  },
  {
    "title": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "title_es": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "url": "https://www.nature.com/articles/d41586-025-02354-8",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "source": "Nature"
  },
  {
    "title": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "title_es": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "url": "https://www.nature.com/articles/d41586-025-02548-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "source": "Nature"
  },
  {
    "title": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "title_es": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "url": "https://www.nature.com/articles/d41586-025-02510-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Bird flu is ‘everywhere’ on dairy farms",
    "title_es": "Daily briefing: Bird flu is ‘everywhere’ on dairy farms",
    "url": "https://www.nature.com/articles/d41586-025-02579-7",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Daily briefing: Bird flu is ‘everywhere’ on dairy farms",
    "source": "Nature"
  },
  {
    "title": "AI content is tainting preprints: how moderators are fighting back",
    "title_es": "AI content is tainting preprints: how moderators are fighting back",
    "url": "https://www.nature.com/articles/d41586-025-02469-y",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "AI content is tainting preprints: how moderators are fighting back",
    "source": "Nature"
  },
  {
    "title": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "title_es": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "url": "https://www.nature.com/articles/d41586-025-02450-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "source": "Nature"
  },
  {
    "title": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "title_es": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "url": "https://www.nature.com/articles/d41586-025-02507-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "source": "Nature"
  },
  {
    "title": "Tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro!",
    "title_es": "Tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro!",
    "url": "https://www.cnio.es/noticias/nuevas-tesis-doctorales-en-el-cnio-enhorabuena-a-quienes-hacen-la-ciencia-del-futuro/",
    "published": "2025-08-12T18:11:56.000Z",
    "date": "2025-08-12",
    "content_es": "Charles Darwin ponía sus esperanzas en «naturalistas jóvenes y emergentes» que sabrían apreciar sus rompedoras ideas; a los veteranos no aspiraba a convencerlos, porque sus mentes «están repletas de datos que durante muchos años han sido analizados desde un punto de vista opuesto al mío», escribió en El Origen de las Especies–. El físico Max […]\nLa entrada Tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro! se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "title_es": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "url": "https://www.nature.com/articles/s41586-025-09407-y",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "source": "Nature"
  },
  {
    "title": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "title_es": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "url": "https://www.nature.com/articles/s41586-025-09485-y",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "source": "Nature"
  },
  {
    "title": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "title_es": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "url": "https://www.nature.com/articles/s41586-025-09464-3",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "source": "Nature"
  },
  {
    "title": "How does agricultural land become forest? I trek to find out",
    "title_es": "How does agricultural land become forest? I trek to find out",
    "url": "https://www.nature.com/articles/d41586-025-02517-7",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "How does agricultural land become forest? I trek to find out",
    "source": "Nature"
  },
  {
    "title": "How Indigenous values permeate my chemistry teaching and research",
    "title_es": "How Indigenous values permeate my chemistry teaching and research",
    "url": "https://www.nature.com/articles/d41586-025-02568-w",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "How Indigenous values permeate my chemistry teaching and research",
    "source": "Nature"
  },
  {
    "title": "Six questions to ask before jumping into a spreadsheet",
    "title_es": "Six questions to ask before jumping into a spreadsheet",
    "url": "https://www.nature.com/articles/d41586-025-02511-z",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Six questions to ask before jumping into a spreadsheet",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Political officials could control US federal science grants",
    "title_es": "Daily briefing: Political officials could control US federal science grants",
    "url": "https://www.nature.com/articles/d41586-025-02573-z",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Daily briefing: Political officials could control US federal science grants",
    "source": "Nature"
  },
  {
    "title": "Swift bricks, ancient tattoos and more: Books in brief",
    "title_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "url": "https://www.nature.com/articles/d41586-025-02556-0",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "source": "Nature"
  },
  {
    "title": "How animal paw pads got their toughness",
    "title_es": "How animal paw pads got their toughness",
    "url": "https://www.nature.com/articles/d41586-025-02474-1",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "How animal paw pads got their toughness",
    "source": "Nature"
  },
  {
    "title": "Can creativity in science be learnt? These researchers think so",
    "title_es": "Can creativity in science be learnt? These researchers think so",
    "url": "https://www.nature.com/articles/d41586-025-01913-3",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Can creativity in science be learnt? These researchers think so",
    "source": "Nature"
  },
  {
    "title": "Trump order gives political appointees vast powers over research grants",
    "title_es": "Trump order gives political appointees vast powers over research grants",
    "url": "https://www.nature.com/articles/d41586-025-02557-z",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Trump order gives political appointees vast powers over research grants",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: US researchers fight back on key climate report",
    "title_es": "Daily briefing: US researchers fight back on key climate report",
    "url": "https://www.nature.com/articles/d41586-025-02567-x",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Daily briefing: US researchers fight back on key climate report",
    "source": "Nature"
  },
  {
    "title": "Decolonize scientific institutions, don’t just diversify them",
    "title_es": "Decolonize scientific institutions, don’t just diversify them",
    "url": "https://www.nature.com/articles/d41586-025-02516-8",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Decolonize scientific institutions, don’t just diversify them",
    "source": "Nature"
  },
  {
    "title": "A rude awakening",
    "title_es": "A rude awakening",
    "url": "https://www.nature.com/articles/d41586-025-02488-9",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "A rude awakening",
    "source": "Nature"
  },
  {
    "title": "Globally recognized island is losing its trademark glaciers",
    "title_es": "Globally recognized island is losing its trademark glaciers",
    "url": "https://www.nature.com/articles/d41586-025-02473-2",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Globally recognized island is losing its trademark glaciers",
    "source": "Nature"
  },
  {
    "title": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "title_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "url": "https://www.nature.com/articles/d41586-025-02505-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "source": "Nature"
  },
  {
    "title": "How researcher visa curbs threaten science careers",
    "title_es": "How researcher visa curbs threaten science careers",
    "url": "https://www.nature.com/articles/d41586-025-02293-4",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "How researcher visa curbs threaten science careers",
    "source": "Nature"
  },
  {
    "title": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "title_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "url": "https://www.nature.com/articles/d41586-025-02512-y",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "source": "Nature"
  },
  {
    "title": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "title_es": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "url": "https://www.cnic.es/es/node/235736",
    "published": "2025-08-01T12:08:23.000Z",
    "date": "2025-08-01",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDr. Claudia Monaco, Kennedy Institute of Rheumatology, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, University of Oxford, UK\n\n\n\nClaudia Monacoo trained as a cardiologist and PhD with Professor Attilio Maseri at the Catholic University of Rome, Italy, before moving to the Kennedy Institute of Rheumatology, Imperial College London to work with Professor Marc Feldmann. She moved to the University of Oxford in 2011, where she became Professor of Cardiovascular Inflammation. Her group was the first to establish innovative experimental methodology for the isolation, culture and targeting of live cells from human atheroma lesions. Her work allowed the elegant characterization of the inflammatory and synthetic properties of human atherosclerosis, establishing toll-like receptors as important activators of innate immunity in atherosclerosis. The Cardiovascular Inflammation Team is now focused on interpreting the functional diversity of immune cells in atherosclerosis with single cell biology techniques and devise strategies for their selective targeting.\n\nWhat is the role of macrophages in the development of atherosclerosis, and how has our understanding of their function evolved?\n\nWe are focused, in particular, on macrophages and what their function is in atherosclerosis. I think it’s quite interesting, because different types of macrophages have different functions in the development of atherosclerosis. Before, we thought that all macrophages were bad—that all macrophages and the whole immune system were actually promoting atherosclerosis. But now we know the picture is much more complex than that.\nIt’s very related to what macrophages are, where they’re seeded, and how they establish themselves in specific niches. There are some macrophages, like the lipid-associated macrophages, that definitely promote disease. But there are others—vascular macrophages that are already present within the vessel wall—that actually act like guardians of the artery and are protective.\nI think it’s very important—this direction we’re going in, toward more targeted therapies. The idea is not to block all macrophages, because some are actually your friends. You need to look after them, especially the ones in the artery, while others are really pushing things toward a dangerous, disease-promoting path. This duality is really important, especially from a therapeutic perspective. That’s why we’re so fixated on understanding this better.\n\nAnd how can you tell the difference between the “good” macrophages and the ones you want to block? What kind of techniques do you use?\n\nWe use single-cell biology a lot. We’re not yet in the clinical space, but we’ve identified good markers. If those markers prove reliable, it would be easy to translate this into new tools to look at different macrophages in vivo. There’s also the potential to tailor imaging—not just therapeutics, but also how we visualize these macrophages.\nThe key idea we want to get across is that there isn’t just “one” macrophage type. We always said that macrophages are very pleiotropic—that they can take on different phenotypes—but that didn’t always seem to matter because we thought they all eventually just changed into each other. But actually, that’s not quite true.\nThere is some dynamic flexibility, yes, but it's quite reproducible which path they take. They really adapt specifically to their environment. For example, in the adventitia, they adopt a very specific phenotype, and in the intima, a different one. And these phenotypes remain pretty stable during atherosclerosis, and also in health and disease. They’re not just switching randomly between states, they’re adapting in a niche-specific way, just like cells in any other organ. That’s important because it means we can start visualizing and treating patients differently more precisely.\n\nYou mentioned you're still in the experimental phase and not yet in clinical trials. How far is immunotherapy for cardiovascular disease?\n\nI think there have been some early trials, and there are more and more now that are targeting inflammation in atherosclerosis. It’s really a booming field. We waited a long time to get here. The field was slow to move in this direction because so much focus was on lowering cholesterol, which is of course important—but inflammation wasn’t really explored until recently.\nStudies like the CANTOS trial and others have started targeting cytokines, and I think we are going in the right direction. But progress is still very slow. One big reason is the lack of imaging tools. Imaging is only now reaching the level where we can maybe use it instead of relying on hard cardiovascular outcomes in trials.\nIf you look at cancer, for example, you can track things much faster, look at the size of the tumor, and see how the patient is responding. Same for diseases like rheumatoid arthritis, where you can scan the joints or use PET imaging. Those imaging methods have been around for decades, and they’ve made it possible to run smaller trials that are either based on imaging or give you very clear, early outcomes.\nBut with cardiovascular disease, we still have to look at how patients are doing over 5, 10 years. That’s a big challenge. These trials are very expensive, especially because biologic drugs cost so much. So pharmaceutical companies need to make a huge financial commitment. The more we can improve imaging, the more we’ll be able to run meaningful trials that evaluate new biologics or targeted agents, like nanotechnology-based ones.\nI think evolution isn’t just about immunology, it’s also about how we study this in the real world. Other fields can run smaller trials to understand how things work and then move on to larger outcome trials. But here, with trials like the CANTOS trial—which involved over 10,000 patients and a very expensive biologic—that kind of scale is almost unheard of in other diseases like rheumatoid arthritis.\nSo yes, the challenges are really at the clinical stage—how we bring all this incredible knowledge about the immune system into cardiovascular medicine. The real barrier is economic.\n\nYou’re a cardiologist—you worked in Rome for many years, and then you moved to Oxford. You trained as a cardiologist, and then you also shifted into doing experiments and research. How do you combine these two areas?\n\nWell, combining clinical duties and research is one of the biggest challenges you can attempt to do.  I think if you’re doing clinical research—like outcomes-based research or imaging studies—then it’s easier to combine with clinical work. But if you’re developing science at the molecular level, it’s much harder to do both. At least I couldn’t manage it as well as I would have liked.\nThere’s a big divide between what we think we know and what we actually know. We have this concept of how atherosclerosis develops, how the immune system contributes—but in reality, we don’t really understand the specific mechanisms at play. I felt that, to bridge this gap, I had to go back to the basics. That meant not only using experimental models but also working with human samples. I saw a huge opportunity in single-cell biology has been a big opportunity—for all of us—to understand human immunology at a very detailed level. Because if we only look at mice, then the gap between mouse and human, and then from preclinical to clinical stages, is massive.\nFor example, we really need access to human vascular tissue. But as cardiologists, we’ve moved so much toward percutaneous approaches to the coronary arteries, so we don’t actually remove them anymore. That’s why I work a lot with vascular surgeons. They still operate in a way that allows us to obtain human tissue—but that might not last. Even vascular surgery is moving more and more toward stenting, which means we’ll eventually lose the ability to get that tissue. We have this narrow window of opportunity where we can still work with tissue from patients, and I felt I had to take it. I’m very vocal about this having a short window before vascular surgery becomes entirely percutaneous, \n\nIt seems like improvements in clinical treatment are making things harder for basic science in a way.\n\nExactly. It’s advancing, but at the same time, it means that now we have this critical window. I always say vascular surgeons do research, collect tissue, because we need to analyze what the cells are really doing. Just relying on blood studies, on systemic inflammation, doesn’t tell us much about what’s happening in the atherosclerotic artery. The immune cells inside the artery are very different in their programming compared to circulating cells in the blood.\nMost cells come from the blood—but there are also some embryonic macrophages that form inside the artery and never circulate. And even the ones that come from the blood and stay in the artery for 10 years, they acquire very specialized instructions. You can take monocytes from blood and run as many blood tests as you want—but that doesn’t tell you what’s actually happening inside the artery.\nThey behave differently, they look different, they’ve changed their shape and function completely. This creates a gap in what we can understand—it seems like we’re missing something in these studies . We can’t see all the different effects a drug might have if we only look at peripheral blood. I think the real answers are also in the vascular tissue, in the atherosclerotic plaque itself. We need to go as close to the source as possible—to find real targets, and to see the real effects of drugs on atherosclerotic tissue.\nBecause a lot of clinical trials have targeted systemic inflammation. But that’s not the same as inflammation within the plaque. The drivers of plaque inflammation may be different.\nWe know systemic inflammation is a risk factor, yes, but what you see in the blood isn’t necessarily what’s happening in the plaque. We often assume it is—because it’s convenient. But in cardiovascular disease, especially cardiology, we never actually look at the plaque. We look at the lumen. Intravascular ultrasound (IVUS) is the only way to get a glimpse of the arterial wall. Experimentally, we might look at blood from the heart in very complex ways—but we’re still mainly looking at circulating markers. We’re not really studying the tissue itself.\n\n\nAs a cardiologist with experience of treating patients, do you think your clinical background influences the kinds of research questions you ask?\n\nYes. And there are two things that help me a lot, I think. And that’s why I never stop clinics, even though they told me several times to stop clinics. I think I... I don’t like to stop the clinics because I enjoy that interaction.\nI think, being a scientist, your rewards are very long-term. If you’re a doctor, the rewards are quite immediate, because the patient is happier, yes—you can give the treatment. So, I think it gives me a lot of motivation to serve the patient. But at the same time, I think research is also a good way to serve patients.\nBecause as a clinician I’ve learned a lot from basic scientists. They’re much better at developing techniques at the bench, and so I have great respect for my scientific colleagues. But sometimes, as a clinician, you can see what really matters. And it makes you particularly attached to a specific disease, you know? Basic scientists are sometimes across fields. This study gives me the determination and the drive to really try and solve atherosclerosis.",
    "source": "CNIC"
  },
  {
    "title": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "title_es": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "url": "https://www.cnic.es/es/noticias/dra-claudia-monaco-enfermedades-cardiovasculares-pensamos-que-sabemos-mucho-pero-realidad",
    "published": "2025-08-01T11:49:01.000Z",
    "date": "2025-08-01",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDra. Claudia Monaco:  Instituto Kennedy de Reumatología, Departamento Nuffield de Ortopedia, Reumatología y Ciencias Musculoesqueléticas, Universidad de Oxford, Reino Unido\n\n\n\nClaudia Monaco se formó como cardióloga y doctoró con el profesor Attilio Maseri en la Universidad Católica de Roma, Italia, antes de trasladarse al Instituto Kennedy de Reumatología del Imperial College de Londres para trabajar con el profesor Marc Feldmann. En 2011 se trasladó a la Universidad de Oxford, donde se convirtió en profesora de Inflamación Cardiovascular. Su grupo fue el primero en establecer una metodología experimental innovadora para el aislamiento, cultivo y selección de células vivas de lesiones ateromatosas humanas. Su trabajo permitió caracterizar de forma elegante las propiedades inflamatorias y sintéticas de la aterosclerosis humana, estableciendo los receptores toll-like como activadores importantes de la inmunidad innata en la aterosclerosis. Su grupo de inflamación cardiovascular se centra ahora en interpretar la diversidad funcional de las células inmunitarias en la aterosclerosis con técnicas de biología celular única y en diseñar estrategias para su selección selectiva.\n\n¿Cuál es el papel de los macrófagos en el desarrollo de la aterosclerosis y cómo ha evolucionado nuestra comprensión de su función?\n\nNos centramos, en particular, en los macrófagos y en cuál es su función en la aterosclerosis. Es muy interesante porque los diferentes tipos de macrófagos tienen diferentes funciones en el desarrollo de la aterosclerosis. Antes pensábamos que todos los macrófagos eran malos, que todos los macrófagos y todo el sistema inmunitario favorecían la aterosclerosis. Pero ahora sabemos que el panorama es mucho más complejo.\nEstá muy relacionado con lo que son los macrófagos, dónde se siembran y cómo se establecen en nichos específicos. Hay algunos macrófagos, como los macrófagos asociados a los lípidos, que sin duda favorecen la enfermedad. Pero hay otros, los macrófagos vasculares que ya están presentes en la pared de los vasos, que en realidad actúan como guardianes de la arteria y la protegen.\nCreo que es muy importante la dirección que estamos tomando, hacia terapias más específicas. La idea no es bloquear todos los macrófagos, porque algunos son realmente nuestros aliados. Hay que cuidarlos, especialmente los que se encuentran en las arterias, mientras que otros realmente empujan hacia un camino peligroso que favorece la enfermedad. Esta dualidad es muy importante, especialmente desde el punto de vista terapéutico. Por eso estamos tan obsesionadas con comprenderlo mejor.\n\n¿Cómo se puede distinguir entre los macrófagos «buenos» y los que se quieren bloquear? ¿Qué tipo de técnicas se utilizan?\n\nUtilizamos mucho la biología unicelular. Aún no estamos en el ámbito clínico, pero hemos identificado buenos marcadores. Si esos marcadores resultan fiables, sería fácil traducirlos en nuevas herramientas para observar diferentes macrófagos in vivo. También existe la posibilidad de adaptar las imágenes, no solo las terapéuticas, sino también la forma en que visualizamos estos macrófagos.\nLa idea clave que queremos transmitir es que no existe un único tipo de macrófago. Siempre hemos dicho que los macrófagos son muy pleiotrópicos, es decir, que pueden adoptar diferentes fenotipos, pero eso no siempre parecía importar porque pensábamos que, al final, todos se transformaban unos en otros. Pero, en realidad, eso no es del todo cierto.\nHay cierta flexibilidad dinámica, sí, pero la trayectoria que siguen es bastante reproducible. Se adaptan específicamente a su entorno. Por ejemplo, en la adventicia adoptan un fenotipo muy específico, y en la íntima, otro diferente. Y estos fenotipos se mantienen bastante estables durante la aterosclerosis, así como en la salud y la enfermedad. No cambian aleatoriamente entre estados, sino que se adaptan de forma específica a cada nicho, al igual que las células de cualquier otro órgano. Esto es importante porque significa que podemos empezar a visualizar y tratar a los pacientes de forma diferente y más precisa.\n\nHa mencionado que aún se encuentra en la fase experimental y que aún no se han realizado ensayos clínicos. ¿En qué punto se encuentra la inmunoterapia para las enfermedades cardiovasculares?\n\nCreo que se han realizado algunos ensayos preliminares y ahora hay cada vez más estudios que se centran en la inflamación en la aterosclerosis. Es un campo en auge. Hemos esperado mucho tiempo para llegar hasta aquí. El campo tardó en avanzar en esta dirección porque se prestaba mucha atención a la reducción del colesterol, lo cual es importante, por supuesto, pero la inflamación no se ha explorado realmente hasta hace poco.\nEstudios como el ensayo CANTOS y otros han comenzado a centrarse en las citocinas, y creo que vamos en la dirección correcta. Pero el progreso sigue siendo muy lento. Una de las principales razones es la falta de herramientas de imagen. Las técnicas de imagen están alcanzando ahora un nivel en el que quizá podamos utilizarlas en lugar de basarnos en los resultados cardiovasculares de los ensayos.\nSi nos fijamos en el cáncer, por ejemplo, se puede hacer un seguimiento mucho más rápido, observar el tamaño del tumor y ver cómo responde el paciente. Lo mismo ocurre con enfermedades como la artritis reumatoide, en las que se pueden escanear las articulaciones o utilizar imágenes PET. Estos métodos de imagen llevan décadas utilizándose y han permitido realizar ensayos más pequeños basados en imágenes o que ofrecen resultados muy claros y tempranos.\nSin embargo, en el caso de las enfermedades cardiovasculares, todavía tenemos que observar cómo evolucionan los pacientes a lo largo de 5 o 10 años. Eso supone un gran reto. Estos ensayos son muy caros, sobre todo porque los medicamentos biológicos cuestan mucho. Por lo tanto, las empresas farmacéuticas deben asumir un enorme compromiso financiero. Cuanto más mejoremos las imágenes, más podremos realizar ensayos significativos que evalúen nuevos productos biológicos o agentes dirigidos, como los basados en la nanotecnología.\nCreo que la evolución no se limita a la inmunología, sino que también tiene que ver con cómo estudiamos esto en el mundo real. Otros campos pueden realizar ensayos más pequeños para comprender cómo funcionan las cosas y luego pasar a ensayos de resultados más amplios. Pero aquí, con ensayos como el CANTOS, en el que participaron más de 10.000 pacientes y se utilizó un fármaco biológico muy caro, ese tipo de escala es casi inaudito en otras enfermedades como la artritis reumatoide.\nAsí que sí, los retos se encuentran realmente en la fase clínica: cómo trasladar todos estos increíbles conocimientos sobre el sistema inmunitario a la medicina cardiovascular. La verdadera barrera es económica.\n\nUsted es cardióloga, trabajó en Roma durante muchos años y luego se trasladó a Oxford. Se formó como cardióloga y luego también pasó a dedicarse a la experimentación y la investigación. ¿Cómo combina estas dos áreas?\n\nCombinar las tareas clínicas y la investigación es uno de los mayores retos a los que te puedes enfrentar.  Creo que, si una se dedica a la investigación clínica, como la investigación basada en resultados o los estudios de imagen, es más fácil combinarla con el trabajo clínico. Pero si se trabaja más en el desarrollo científico a nivel molecular, es mucho más difícil compaginar ambas cosas. Al menos yo no pude hacerlo tan bien como me hubiera gustado.\n Existe una gran diferencia entre lo que creemos saber y lo que realmente sabemos. Tenemos una idea de cómo se desarrolla la aterosclerosis, cómo contribuye el sistema inmunitario, pero en realidad no entendemos los mecanismos específicos que intervienen. Sentí que, para salvar esta brecha, tenía que volver a lo básico. Eso significaba no solo utilizar modelos experimentales, sino también trabajar con muestras humanas. Vi una gran oportunidad en la biología de células individuales, que ha sido una gran oportunidad para todos nosotros para comprender la inmunología humana a un nivel muy detallado. Porque si solo nos fijamos en los ratones, la brecha entre estos y los seres humanos, y luego entre las etapas preclínicas y clínicas, es enorme.\nPor ejemplo, realmente necesitamos acceso al tejido vascular humano. Pero como cardiólogos, hemos avanzado tanto hacia los abordajes percutáneos de las arterias coronarias que ya no las extirpamos. Por eso trabajo mucho con cirujanos vasculares. Ellos siguen operando de una manera que nos permite obtener tejido humano, pero eso podría no durar mucho tiempo. Incluso la cirugía vascular se está orientando cada vez más hacia la implantación de stents, lo que significa que, con el tiempo, perderemos la capacidad de obtener ese tejido. Tenemos una ventana de oportunidad muy estrecha en la que todavía podemos trabajar con tejido de pacientes, y sentí que tenía que aprovecharla. Soy muy clara al afirmar que tenemos poco tiempo antes de que la cirugía vascular se vuelva completamente percutánea, lo que, por supuesto, es un avance, pero también nos priva de la oportunidad de estudiar tejidos humanos reales.\n\nParece que las mejoras en el tratamiento clínico están dificultando en cierto modo la ciencia básica.\n\nExactamente. Está avanzando, pero al mismo tiempo significa que ahora tenemos esta ventana crítica. Siempre digo que los cirujanos vasculares investigan y recogen tejido porque necesitamos analizar lo que realmente hacen las células. Basarnos únicamente en los análisis de sangre y en la inflamación sistémica no nos dice mucho sobre lo que está sucediendo en la arteria aterosclerótica. Las células inmunitarias del interior de la arteria son muy diferentes en su programación en comparación con las células circulantes en la sangre.\nLa mayoría de las células provienen de la sangre, pero también hay algunos macrófagos embrionarios que se forman dentro de la arteria y nunca circulan. E incluso los que provienen de la sangre y permanecen en la arteria durante 10 años, adquieren instrucciones muy especializadas. Se pueden extraer monocitos de la sangre y realizar tantos análisis de sangre como se desee, pero eso no revela lo que realmente ocurre dentro de la arteria.\nSe comportan de manera diferente, tienen un aspecto diferente, han cambiado completamente su forma y función. Esto crea una brecha en lo que podemos entender, parece que nos estamos perdiendo algo en estos estudios. No podemos ver todos los diferentes efectos que puede tener un fármaco si solo miramos la sangre periférica. Creo que las respuestas reales también se encuentran en el tejido vascular, en la propia placa aterosclerótica. Tenemos que acercarnos lo más posible a la fuente para encontrar los objetivos reales y ver los efectos reales de los fármacos en el tejido aterosclerótico.\nPorque muchos ensayos clínicos se han centrado en la inflamación sistémica. Pero eso no es lo mismo que la inflamación dentro de la placa. Los factores que provocan la inflamación de la placa pueden ser diferentes.\nSabemos que la inflamación sistémica es un factor de riesgo, sí, pero lo que se ve en la sangre no es necesariamente lo que ocurre en la placa. A menudo asumimos que lo es, porque es conveniente. Pero en las enfermedades cardiovasculares, especialmente en cardiología, nunca miramos realmente la placa. Miramos la luz. La ecografía intravascular (IVUS) es la única forma de echar un vistazo a la pared arterial.\nDesde el punto de vista experimental, podemos analizar la sangre del corazón de formas muy complejas, pero seguimos centrándonos principalmente en los marcadores circulantes. En realidad, no estamos estudiando el tejido en sí.\n\nComo cardióloga con experiencia en el tratamiento de pacientes, ¿cree que su experiencia clínica influye en el tipo de preguntas de investigación que se plantea?\n\nSí. Y hay dos cosas que me ayudan mucho. Por eso nunca dejo de ejercer en la clínica, aunque me han dicho varias veces que lo haga. Creo que... no me gusta dejar la clínica porque disfruto de esa interacción.\nComo científica, las recompensas son a muy largo plazo. Si eres médico, las recompensas son bastante inmediatas, porque el paciente está más contento si puedes darle el tratamiento. Por lo tanto, creo que me motiva mucho atender al paciente. Pero, al mismo tiempo, pienso que la investigación también es una buena forma de atender a los pacientes.\nPorque, como médico, he aprendido mucho de los científicos básicos. Son mucho mejores desarrollando técnicas en el laboratorio, por lo que siento un gran respeto por mis colegas científicos. Pero a veces, como médico clínico, puedes ver lo que realmente importa. Y eso te hace sentir especialmente vinculado a una enfermedad concreta. Los científicos básicos a veces abarcan varios campos. Este estudio me da la determinación y el impulso para intentar resolver realmente la aterosclerosis.\n\n\n¿De niña, se imaginó dedicándose a la ciencia o la medicina y, finalmente, a la investigación?\n\nSiempre quise ser médico. De niña era un poco enfermiza, así que probablemente estuve muy expuesta al entorno médico. Por eso, siempre decía que quería ser médico. Pero luego decepcioné a mi padre a largo plazo, porque él pensaba que me convertiría en médico, no sé, un médico generalista, y así podría tenerme muy cerca de su casa. Pero en cambio, mi carrera me llevó al extranjero. No creo que él estuviera muy contento con mi marcha.\nEn particular, cuando era joven no quería ser científica. Me fascinaban los médicos. Probablemente tenía ese sentido de ayudar a la gente, de servir a la gente. Para mí eso es muy importante. Aprendí todo sobre cardiología en Italia, con el profesor Attilio Maseri, que fue un gran precursor en este campo: la activación de las células inmunitarias, especialmente en el síndrome coronario agudo. Aprendí mucho de él y sigo llevando esa huella en mi trabajo.\nTambién trabajé con otros buenos mentores en el Reino Unido, como el profesor Mark Feldman, y aprendí mucho de él sobre el sistema inmunitario y cómo detener la inflamación. Hago todo lo posible por seguir los pasos de estos dos gigantes para comprender el funcionamiento del sistema inmunitario en las arterias, tanto en la salud como en la enfermedad.\nMe encuentro en un entorno de reumatología e inmunología que también realiza investigaciones cardiovasculares. Puedo permanecer entre ambos campos, lo que me beneficia enormemente, ya que siempre estoy en la interfaz entre los inmunólogos y los especialistas cardiovasculares. Y creo que esto es algo bastante único. Es bastante difícil de replicar en todas partes.\nAhora, la inmunología cardiovascular se está consolidando cada vez más y habrá cada vez más interfaces de este tipo. Como la que hay aquí, en el CNIC, donde hay más interfaces de este tipo. Así que todo esto se está formando. Este es el futuro.\nCuando empecé, no se podía hacer esta combinación en ningún sitio. Por lo tanto, mis opciones estaban bastante limitadas. Ahora, tal vez podría plantearme mudarme a algún lugar de Europa, Estados Unidos, volver a Italia, si hay una estructura de financiación que permita el mismo nivel. Pero, por supuesto, ya sabes, en este momento hay problemas con la financiación en todos los países. Así que es un poco optimista. No iría a Italia solo por ir a Italia. El trabajo es muy importante para mí y necesito tener la combinación adecuada para mudarme a cualquier lugar.\n\nQuizás, primero podría venir aquí para investigar en el CNIC.\n\nSí, exactamente. ¿Por qué no? ¿Por qué no?\n\nHa mencionado que ha tenido muy buenos mentores en su carrera, y supongo que todavía los tiene. Pero ahora también asume esa función de mentoría con los estudiantes en su laboratorio. Entonces, ¿qué diferencias encuentra entre cuando era joven y estos jóvenes estudiantes de hoy?\n\nEsta es una pregunta difícil, porque es una pregunta en la que se pueden tomar dos caminos completamente diferentes. Uno sería: antes trabajábamos mucho más duro, y eso me molesta. No me agradan las personas que siguen ese camino. No me gusta decirlo, pero al final yo también lo sigo: antes nos quedábamos en el laboratorio hasta tarde...\nCreo que los nuevos estudiantes tienen una capacidad mucho mayor. Las nuevas generaciones son más completas en el sentido de que no quieren perderse por completo en el trabajo o la investigación, y creo que esto es algo positivo para sus vidas, sin duda. Considero que ese cambio es muy importante. Quizás porque en Oxford existe la tradición de que hay que tener una vida social en la universidad. Organizan actividades. Intentan crear un entorno en el que los estudiantes, incluso los de posgrado, puedan socializar si lo desean. Me gusta esa cultura. Y esto es típico de Oxford, y me encanta.\nPorque pueden hacer muchas cosas que yo no hice. Ya sabes, en nuestra época, existía la idea de que había que negarse a uno mismo, dedicarse a la disciplina sin límites, y creo que eso no es bueno a largo plazo.\nPero yo diría que las nuevas generaciones suelen conocer muy bien su tema, pero quizá no amplían sus horizontes tanto como deberían, no sienten curiosidad por otras disciplinas. Y yo lucho mucho contra eso. Ya sabes, se meten de lleno en su área, obtienen el doctorado, hacen la defensa de la tesis y solo saben eso. Ahora hay muchas áreas de interés a nuestro alcance. Probablemente, como consecuencia, perdieron muchas cosas. Pero siempre intento decirles que es importante ver cómo evolucionan otros campos. Quizás haya una idea que necesites. Quizás haya un camino que no habías pensado, pero que es importante en el cáncer y quizás también lo sea en las enfermedades cardiovasculares.\nSiempre pienso que, si estás en la interfaz entre dos campos, avanzas más rápido. Porque puedes aprender, otros colegas pueden inspirarte. Así que no te fijes solo en lo tuyo.\nY otra cosa que siempre les digo es que creo que, en las enfermedades cardiovasculares, pensamos que sabemos mucho. Pero en realidad, no es así. Y siempre tenemos que revisar las pruebas.\n\nEs posible que tengan una nueva forma, diferente, de ver sus vidas y sus carreras.\n\nSí, pero también, incluso en el campo del conocimiento de la aterosclerosis, siempre enseñamos a los estudiantes: así es como evoluciona la aterosclerosis. En realidad, las pruebas para nuestro modelo siempre son muy dispersas. Porque pueden estar en ratones o en otro sistema. Pero cómo es en los seres humanos, realmente no lo sabemos. Así que estad siempre preparados para cuestionar vuestras suposiciones. No sigáis siempre lo que os dicen los demás. Debéis tener vuestras propias ideas. Y siempre tenéis que desafiar el paradigma.",
    "source": "CNIC"
  },
  {
    "title": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "title_es": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "url": "https://www.cnio.es/noticias/un-investigador-del-cnio-desarrolla-una-prueba-capaz-de-detectar-tumores-en-estadios-iniciales-con-una-muestra-de-sangre/",
    "published": "2025-07-31T10:48:44.000Z",
    "date": "2025-07-31",
    "content_es": "Los métodos actuales para diagnosticar el cáncer se basan en identificar marcadores –moléculas que indican un estado o proceso determinado del organismo– que provienen del tumor o de proteínas asociadas a él. Como es lógico, esos marcadores son más abundantes cuando el tumor ya se ha desarrollado de forma significativa. Y, cuanto más avanzado el […]\nLa entrada Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "CNIC en la Noche Europea de los Investigadores 2025",
    "title_es": "CNIC en la Noche Europea de los Investigadores 2025",
    "url": "https://www.cnic.es/es/noticias/cnic-noche-europea-investigadores-2025",
    "published": "2025-07-17T22:35:42.000Z",
    "date": "2025-07-17",
    "content_es": "14/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nVen al CNIC el próximo viernes 26 de septiembre con motivo de la XVI Noche Europea de los Investigadores de Madrid. Podrás participar en distintas actividades que te acercarán a la investigación que se realiza en el centro.\nLa Noche Europea de los Investigadores en el CNIC es una oportunidad de sumergirte en el emocionante mundo de la ciencia y la innovación. Desde experimentos asombrosos hasta conferencias inspiradoras, CNIC te brindará una ventana a los descubrimientos más recientes y las maravillas de la tecnología.\nPara asistir es necesario inscribirse en el siguiente link: https://www.cnic.es/es/solicitud-inscripcion-xvi-noche-europea-investigadores \nLa inscripción se abre el lunes 15 de septiembre a partir de las 9:00 hrs.\nTodas las actividades se llevarán a cabo en el Centro Nacional de Investigaciones Cardiovasculares (CNIC): C. de Melchor Fernández Almagro, 3, 28029 Madrid.\nInformación actividades:\n10:30 - 12:30 h. Enfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nPúblico: juvenil (desde 12 años) y adultos.\nEl principal objetivo de esta actividad es sensibilizar sobre los muchos desafíos que enfrentan los pacientes con enfermedades raras, y explicar cómo la investigación básica, utilizando modelos animales adecuados, es esencial para avanzar en la comprensión de estas enfermedades y encontrar terapias potenciales que permitan aliviar o curar a estos pacientes. Con este propósito, se organizan dos actividades: una charla de divulgación en lenguaje accesible; y una demostración en el laboratorio que permitirá a las personas participantes familiarizarse con técnicas utilizadas rutinariamente en la investigación básica para responder preguntas científicas relevantes en el estudio de enfermedades raras.\n10:30 - 13:30 h. ¿Cómo late nuestro corazón? Grupo: Silvia Priori.\nPúblico: juvenil (desde 12 años) y adultos.\nEsta actividad tiene como objetivo explicar cómo late el corazón, desde el nivel subcelular hasta el órgano completo, así como el desarrollo de una arritmia cardíaca dependiente del calcio. Estos temas se explicarán de forma sencilla y amena para que las personas participantes los conozcan de la mano de nuestras investigadoras e investigadores.  \n12:00 - 13:30 h. ¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\nPúblico: juvenil (14-18 años).\nLas personas participantes en esta actividad tendrán la oportunidad de conocer la relación entre el cáncer y el corazón desde el acercamiento al proyecto de investigación RESILIENCE, destinado a mejorar la vida de los pacientes con cáncer. La actividad consistirá en un workshop donde las personas participantes conocerán la aplicación de la tecnología (resonancia magnética cardíaca, ecocardiografía y tomografía cardíaca) y la innovación en este ensayo clínico, así como una mesa redonda donde se compartirán experiencias y se resolverán dudas.\n14:30 - 16:00 h. ¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\nPúblico: infantil (6 – 12 años).\nSe realizará una pequeña presentación sobre las diferencias de flujo sanguíneo laminar y oscilatorio en el contexto de aterosclerosis (con nuestros personajes de dibujos LAMI y OSCI); se hará un juego con preguntas básicas sobre la presentación donde las personas participantes ganarán piezas para montar su propia máquina de flujo laminar y oscilatorio; y habrá una demostración con una adaptación similar de las máquinas que se usan en el laboratorio para estimular las células a los dos tipos de flujo, con el uso de colorante alimentario y purpurina para que se puedan ver los diferentes patrones.\nDos turnos: 11:00-11:45 h (turno 1), 11:45-12.30 h (turno 2).   \n16:00 - 17:30 h. Taller de extracción de ADN. Grupo: Enrique Lara\nPúblico: infantil (8 – 12 años).\n¿Alguna vez te has preguntado qué podéis tener en común los plátanos y tú? ¡Los dos tenéis ADN! Os presentamos una actividad rápida, fácil y divertida, en la que vais a aprender a extraer el ADN de un plátano. Para ello usaremos ingredientes que cualquiera de vosotros tenéis en casa, así podéis sorprender al resto de la familia montando un pequeño laboratorio y ejerciendo de investigadores, ¿estáis dispuestos?\nTres turnos: 16:00 - 16:30 h (Turno 1), 16:30 - 17:00 h (Turno 2), 17:00 - 17:30 h (Turno 3).\n16:00 - 18:00 h. Modelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nPúblico: Infantil (desde 6 años), juvenil y adultos.\nEsta actividad comenzará con una breve charla introductoria para seguir con la preparación de áreas temáticas en el laboratorio especializadas en una cardiopatía congénita concreta, donde se explicarán en detalle sus rasgos morfológicos y cómo afectan a la salud humana. Las personas participantes realizarán una tinción histológica en la que podrán observar corazones de ratón y observarán, de manera práctica, las malformaciones explicadas en la charla de introducción. Con esto esperamos acercar a grandes rasgos lo que se hace en el laboratorio y la relevancia de la investigación básica y traslacional en el contexto de la cardiología.\n16:30 - 18:00 h. Cuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nPúblico: juvenil (desde 15 años) y adultos.\nEsta actividad consta de dos partes. Una primera en la que se les dará a las personas que participan una charla divulgativa adaptada a la edad del público, en la que se expondrá la importancia de los factores de riesgo cardiovasculares en el desarrollo de ciertas patologías relacionadas con el cerebro, así como el ictus o demencias. Posteriormente tendrá lugar una visita guiada en pequeños grupos al laboratorio del grupo donde se mostrarán diferentes técnicas empleadas de rutina en un laboratorio de neurociencia.\n17:00 - 18:00 h. El escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nPúblico: juvenil (desde 12 años) y adultos.\nEn este escape room científico, las personas participantes deberán usar su ingenio para resolver pruebas, enigmas o puzles y abrir un candado. Si lo logran, ¡descubrirán el secreto de la PCR y ganarán una recompensa final! De esta manera, a través de retos colaborativos inspirados en la biología molecular, las personas que jueguen aprenden conceptos clave de genética en un entorno lúdico y educativo.\n17:00 - 19:00 h. Da color a tu plato: convierte a tu corazón en un superhéroe con ritmo: Grupos: José Antonio Enríquez y David Sancho.\nPúblico: infantil (6-12 años).\nEn esta actividad interactiva se construirá un estetoscopio con materiales simples y reciclados (globos, tubos de plástico y botellas usadas), que las personas participantes podrán llevarse a casa. Con él, exploraremos cómo suena nuestro propio corazón, aprendiendo de manera directa y divertida sobre el ritmo cardíaco en condiciones de reposo y después del ejercicio, así como su importancia para la salud. Posteriormente se visualizará en una maqueta humana de poliespán a tamaño real cómo es nuestro sistema circulatorio, cómo la sangre llega a nuestro corazón y cómo alteraciones de la circulación pueden ocasionar ciertas patologías, como es la ateroesclerosis. También tendremos la oportunidad de ver cómo es nuestra sangre cuando tiene un exceso de grasa.  Ambas visualizaciones permitirán comprender por qué es fundamental, evitar el sedentarismo y cuidar nuestros hábitos alimenticios desde una edad temprana para prevenir enfermedades cardiovasculares.\n18:00 - 19:00 h. Diseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nPúblico: adultos (mayores de 18 años).\nEn esta actividad cinco participantes visualizarán con gafas de realidad mixta la estructura dinámica de proteínas y sus ligandos, entendiendo como se produce el efecto de un medicamento. Otros cinco participantes trabajarán en un ordenador cada uno en el proyecto colaborativo https://foldingathome.org. Las personas participantes irán terminando y saliendo, y un nuevo participante entrará para sustituirlos.\nFinanciación y menciones necesarias\n En todas las actividades:\n\nEl CNIC recibe apoyo del Instituto de Salud Carlos III (ISCIII), del Ministerio de Ciencia, Innovación y Universidades (MICIU) y es un Centro de Excelencia Severo Ochoa. Estas actividades han sido posibles gracias a los programas de investigación de CNIC: Programa Nuevos mecanismos de aterosclerosis, Programa Homeostasis miocárdica y daño cardiaco, Programa de Regeneración cardiovascular, Programa Nuevos mecanismos arritmogénicos, Programa Factores de riesgo cardiovascular y salud cerebral, Programa de Promoción de la salud cardiovascular, Programa de Desarrollo tecnológico, financiados por la ayuda CEX2020-001041-S por el MICIU/AEI/10.13039/501100011033.\n\nFinanciado por la Unión Europea. Las opiniones y puntos de vista expresados solo comprometen a su(s) autor(es) y no reflejan necesariamente los de la Unión Europea o los de la European Research Executive Agency (EREA). Ni la Unión Europea ni la EREA pueden ser considerados responsables de ellos.\nNIGHTMADRID es un proyecto de divulgación científica, coordinado por la Fundación madri+d y financiado por la Unión Europea dentro del Programa Horizonte Europa, bajo las acciones Marie Skłodowska-Curie con el acuerdo de subvención nº101.162.110\n\n\nMenciones específicas de cada actividad:\nEnfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nProject PID2022-141211OB-I00, funded by MCIU/AEI/10.13039/501100011033 y por FEDER, UE:\n\nProject “AC22/00020\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union NextGenerationEU:\n\n\nGRUPO CIBERCV CB16/11/00405\n\nProject \"FI23/00229\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union.\n\n\n¿Cómo late nuestro corazón?Grupo: Silvia Priori.\nEl proyecto que ha dado lugar a los resultados mostrados en esta actividad ha recibido el apoyo de la Fundación “la Caixa”, según el acuerdo LCF/PR/HR21-00233.\n\n¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\n\nThis project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No GA-945118\n\nEsta actividad es parte de la ayuda ICT2021-006950, financiada por MICIU y por la Unión Europea NextGenerationEU/PRTR\n\nGRUPO CIBERCV CB16/11/00358\n\n¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\n\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGrant PID2023-146414OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nEsta actividad se (co)financiará con cargo a programa de actividades de I+D entre grupos de Investigación con número de referencia TEC-2024/TEC-158 y acrónimo TecNanoBio-CM, subvencionado por la Comunidad de Madrid en la convocatoria de ayudas destinadas a la realización de programas de actividades de I+D entre grupos de investigación de la Comunidad de Madrid en Tecnologías 2024.\n\nEl proyecto de investigación Caveolin-1-dependent stromal remodeling: a potential novel target for cancer immunotherapy” Modalidad de temática general (Ref. PROYE20089DELP) y el proyecto Immunomechanics: a new paradigm for understanding cancer immune infiltration and improving immunotherapy Modalidad Investigador AECC 2024 (Ref. INVES245874LOLO) financiado por la Asociación Española Contra el Cáncer (AECC).\n\nThe project leading to these results has received funding from “la Caixa” Foundation, under agreement LCF/PR/HR20/52400015\n\nGrant JDC2022-049775-I funded by MICIU/AEI/ 10.13039/501100011033 by the “European Union NextGenerationEU/PRTR”\n\nAyuda FPU21/04003 financiada por:\n\nGrant PRE2021-097318 and PREP2023-001367 funded by MICIU/AEI /10.13039/501100011033 and “ESF+”\n\nFinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2024-TL/SAL-GL-32882 de la convocatoria 2024 de ayudas para la contratación de Ayudantes de Investigación y Técnicos de Laboratorio 2024 y cofinanciadas con el Fondo Social Europeo Plus (FSE+)\n\nco-funded by the European Union’s Horizon Europe research and innovation programme (Cure and Heart Brain project) under the Marie Skłodowska-Curie grant agreement No GA-101126521\n\nTaller de extracción de ADN. Grupo: Enrique Lara\nProyecto TED2021-129774B-C22 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nAyuda PRE2021-100726 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nProyecto PLEC2022-009235 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto PID2021-124629OB-I00 financiado por MICIU/ AEI /10.13039/501100011033/ y por FEDER Una manera de hacer Europa\n\nAyuda PRE2019-087458 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nThis project has received funding from the Horizon Europe Framework Programme (HORIZON) under the call EIC Pathfinder Challenges 2022 and with Project 101115416 — DCM-NEXT\nEl contrato del técnico está cofinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2023-TL/SAL-GL-28706 de la convocatoria 2023 de ayudas para la contratación de ayudantes de investigación y técnicos de laboratorio y cofinanciado en un 40% por el Fondo Social Europeo Plus (FSE+), 2021-2027.\n\n \nGRUPO CIBERCV CB16/11/00432\n\nModelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nLa Caixa “Cardiogenomics”, Plan Nacional, CIBERCV, Leducq foundation\nGrant PID2022-136942OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nFunding from ”la Caixa” Foundation under the project code LCF/PR/HR23/52430011\n\nGrant from the Leducq Foundation for Cardiovascular Research- TNE-24VD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGRUPO CIBERCV CB16/11/00399\n\nAyuda PRE2020-092102 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nAyudas PRE2022-102314 y PREP2022-000716 financiadas por MICIU/AEI /10.13039/501100011033 y por FSE+\nAyuda JDC2023-051982-I financiada por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda FPU18/01054 financiada por el Ministerio de Ciencia, Innovación y Universidades\n\nFinanciado a través de la Ayuda a la contratación de personal investigador predoctoral del año 2023 de la CAM con Expediente PIPF-2023/SAL-GL-29818\n\nCuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nGrant PID2022-140616OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nGrants from the Leducq Foundation for Cardiovascular Research-TNE-19CVD01 and TNE-21CVD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nAyudas PRE2021-099443, PREP2022-000650 y PRE2022-104379 financiadas por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda a la contratación de personal investigador predoctoral del año 2022 de la CAM con Expediente PIPF-2022/SAL-GL-26119\n\nSupport of a fellowship from the ”la Caixa” Foundation (ID 100010434). The fellowship code is LCF/BQ/DI22/11940002”.\n\nEl escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nAssociated funded projects that require dissemination (if applies). Logos and mentions:\n\nUE0EIC2201-HORIZON-EIC-2022_DCM-NEXT\n\nERN-Guard-Heart\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\n \nGRUPO CIBERCV CB16/11/00432\n\nDa color a tu plato: convierte a tu corazón en un superhéroe con ritmo. Grupos: José Antonio Enríquez y David Sancho\n\nJosé Antonio Enríquez:\n\nCentro de Investigación Biomédica en Red de Fragilidad y Envejecimiento Saludable (CIBERFES), Instituto de Salud Carlos III.\nGRUPO CIBERFES CB16/10/00289\n\nProyecto TED2021-131611B-I00 financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under the proposal n° 101198761 MINTRAF\n \n \nProyecto PID2021-127988OB-I00 financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430010\n\n\nDavid Sancho:\n\nProyecto CPP2021-008310 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009762 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\n \nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under grant agreement No 101158245.\n\nThis work was supported by the grant PRYGN246642SANC from the Scientific Foundation of the Spanish Association Against Cancer.\n\nThis work was supported by WORLWIDE CANCER RESEARCH 25-0080.\n\nProyecto PID2022-137712OB-I00 financiado por MICIU/AEI/10.13039/501100011033 y por FEDER, UE\n\nPROGRAMAS DE ACTIVIDADES DE I+D ENTRE GRUPOS DE INVESTIGACIÓN de la Comunidad de Madrid - BIOMEDICINA 2022 coordinado por la Dra. Almudena R Ramiro”-EXPEDIENTE: S2022/BMD-7333. Proyecto titulado “Estrategias inmunomoduladoras en el remodelado vascular: nuevas perspectivas diagnósticas y terapéuticas, acrónimo: INMUNOVAR”. IP del Grupo INMUNOBIOL.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR22/52420019.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430012\n\nProject “UNderstanding Lipid ImmunoMetabolIsm To trEat Disease, acronym: UNLIMITED” (MSCA-Doctoral Network) has received funding from the European Union’s Horizon 2024 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 101227259 \n\nDiseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nAyudas TED2021-132296B-C54 y TED2021-131611B-I00, financiadas por MICIU/ AEI/10.13039/501100011033/ y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009668, financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/PRTR (Plan de Recuperación, Transformación y Resiliencia)\n\nAyuda BIOMARCADORES DE PRECISION PARA LA MEJORA DEL DIAGNOSTICO Y TRATAMIENTO DE LA ENFERMEDAD INFLAMATORIA DEL MIOCARDIO (PreMyo) con expediente PMP22/00105, financiado con fondos públicos por el Instituto de Salud Carlos III y cofinanciado por Unión Europea – NextGenerationEU\n\nAyuda Plan de Formación en Inteligencia Artificial y Big Data para la salud Cardiovascular (CardiotrAIning) con Ref. SOLI/2024/0524/00240212 financiado por los fondos europeos NextGenerationEU en el marco del Plan de Recuperación, Transformación y Resiliencia a través de la iniciativa de los programas de atracción y retención de talento \n\nGRUPO CIBERCV CB22/11/00021\n\nProyecto PID2022-141527OB-I00 financiado por MCIN/AEI/10.13039/501100011033 y por FEDER, UE;\n\nAyuda EQC2024-008195-P financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe EU4Health Programme 2021-2027 under Grant Agreement 101126953. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or European Health and Digital Executive Agency (HADEA). Neither the European Union nor the granting authority can be held responsible for them.\n\nProyecto ALGORITMOS DE INTELIGENCIA ARTIFICIAL PARA PREDECIR EL RIESGO CARDIOVASCULAR, EN-PESA financiado por el Mecanismo de Recuperación y Resiliencia de la Unión Europea-Next Generation, en el marco de la convocatoria “Solicitud de Proyectos de I+D de Excelencia en Inteligencia Artificial de la Secretaría de Estado de Digitalización e Inteligencia Artificial”",
    "source": "CNIC"
  },
  {
    "title": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "title_es": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "url": "https://www.cnio.es/noticias/nuevo-ensayo-clinico-contra-el-cancer-de-piel-mas-frecuente-con-un-compuesto-derivado-de-descubrimientos-del-cnio/",
    "published": "2025-07-15T09:39:59.000Z",
    "date": "2025-07-15",
    "content_es": "Hace unos 15 años, en 2009, el equipo de la investigadora del Centro Nacional de Investigaciones Oncológicas (CNIO) Marisol Soengas descubrió una nueva forma de matar células tumorales: hacerles creer que han sido infectadas por un virus. Desarrollaron un compuesto, denominado BO-110, con una forma de actuación muy novedosa porque inducía la autodigestión de las […]\nLa entrada Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "title_es": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "url": "https://www.cnic.es/es/node/235399",
    "published": "2025-07-14T11:31:24.000Z",
    "date": "2025-07-14",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nA new study led by the CNIC has identified imidazole propionate (ImP), a metabolite produced by gut bacteria, as a driver of atherosclerosis— as a driver of atherosclerosis, the disease behind most heart attacks and strokes\n\n\n\nCardiovascular disease remains the world’s leading cause of death, and often originates in atherosclerosis, a chronic condition in which inflammation and fat deposits cause arteries to harden and narrow. Although clinical practice already targets causal factors like high cholesterol, hypertension, and smoking, detecting atherosclerosis in its early stages continues to be a significant challenge.\nNow, researchers at the Spanish National Center for Cardiovascular Research (CNIC) have identified a gut microbiota–derived metabolite, imidazole propionate (ImP), that appears in the blood during the early stages of active atherosclerosis.\n‘This metabolite is uniquely produced by intestinal bacteria,’ explains CNIC researcher Annalaura Mastrangelo, one of the study’s two first authors. ‘Our study shows that its presence in the bloodstream is associated with the development of active atherosclerosis in people who otherwise appear healthy.’\nThe discovery offers a promising alternative to current diagnostic tools, which typically involve costly and complex imaging techniques. ‘Detecting this blood marker offers a major advantage because current diagnostic tools rely on advanced imaging techniques that are complex, expensive, and not covered by public health systems. Blood levels of ImP provide a diagnostic marker that could help identify apparently healthy individuals with active atherosclerosis, and thus enable earlier treatment.’ says Mastrangelo.\nBut the discovery goes even further. Co–first author Iñaki Robles-Vera explains: ‘We not only observed elevated ImP levels in people with atherosclerosis, but also showed that ImP itself is a causal agent of the disease. In animal models of atherosclerosis, ImP administration led to the formation of arterial plaques. It does this by activating the imidazoline receptor type 1 (I1R), which increases systemic inflammation and promotes atherosclerosis development.’\nDavid Sancho, head of the CNIC Immunobiology Laboratory, lead author on the study and ERC grantee notes that ‘this discovery is important because it opens the way to a completely new line of treatment.’\nThe study shows that blocking the I1R receptor in animal models prevented plaque formation and slowed disease progression, even when the animals were fed a high-cholesterol diet. ‘This suggests that future treatment could combine I1R blockade with cholesterol-lowering drugs to produce a synergistic effect that prevents atherosclerosis development,’ explains Sancho.\n‘These findings open new possibilities for the early detection and personalised treatment of atherosclerosis,’ he continues. ‘Instead of focusing solely on cholesterol and other classic risk factors, we may soon be able to analyse blood for ImP as an early warning signal. At the CNIC, we are also working to develop drugs that block the detrimental effects of ImP.’\n\nThe CNIC-led study was conducted through extensive collaboration with researchers at multiple national and international centres: Mount Sinai Fuster Heart Hospital and the Icahn School of Medicine at Mount Sinai (New York, USA); the Fundación Jiménez Díaz Health Research Institute; the Universidad Autónoma de Madrid; the Spanish cardiovascular research network (CIBER-CV); the University of Gothenburg (Sweden); the University of Athens (Greece); Inmunotek S.L.; the University of Michigan (USA); Hospital de La Princesa; the Center for Metabolomics and Bioanalysis (CEMBIO) from Universidad CEU San Pablo; the University of Heidelberg (Germany); and the Sols-Morreale Biomedical Research Institute (IIBM-CSIC). \nThe study was supported by funding from the European Research Council (Consolidator and Proof of concept grants), Spanish Ministry of Science, Innovation, and Universities; the Spanish State Research Agency; the European Union’s NextGeneration funding mechanism; and the “la Caixa” Foundation.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D., Sancho, D., et al. (2025). Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature. https://doi.org/10.1038/s41586-025-09263-w",
    "source": "CNIC"
  },
  {
    "title": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "title_es": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "url": "https://www.cnic.es/es/noticias/nature-descubren-un-metabolito-microbiota-intestinal-que-favorece-aterosclerosis-podria",
    "published": "2025-07-14T11:08:07.000Z",
    "date": "2025-07-14",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nUn estudio liderado por el CNIC desvela que el propionato de imidazol, un metabolito producido por la microbiota intestinal, induce aterosclerosis, una enfermedad que puede desencadenar la obstrucción de las arterias que causa los infartos o accidentes cerebrovasculares\n\n\n\nLas enfermedades cardiovasculares son la principal causa de muerte global y suelen originarse en la aterosclerosis, un endurecimiento y estrechamiento de las arterias por inflamación y acumulación de grasa en la pared arterial. Aunque se controlan factores causales como colesterol, hipertensión o tabaquismo, la detección temprana de la enfermedad es necesaria. Los nuevos resultados liderados por el Centro Nacional de Investigaciones Cardiovasculares (CNIC) y publicados en la revista Nature han identificado que un metabolito generado por bacterias intestinales, el propionato de imidazol (ImP), se detecta en sangre de modo temprano en la aterosclerosis activa. El estudio ha contado con el apoyo de la Fundación “la Caixa” en su Convocatoria CaixaResearch de Investigación en Salud con 967.620,20 €.\nEste metabolito, “está producido exclusivamente por bacterias del intestino”, explica Annalaura Mastrangelo, investigadora del CNIC y primera autora del estudio. “En este trabajo hemos visto que su presencia en sangre se relaciona con el desarrollo de aterosclerosis activa en personas aparentemente sanas”.\nLo relevante de este hallazgo, destaca Mastrangelo, es que “detectar este marcador en sangre representa una gran ventaja dado que las pruebas actuales requieren técnicas de imagen avanzada complejas y costosas que no están cubiertas por la seguridad social. Los niveles de ImP en sangre ofrecen un marcador con valor diagnóstico para facilitar la identificación de personas sanas que tienen aterosclerosis activa y posibilitar su tratamiento temprano”.\n\nPero el hallazgo va más allá. Iñaki Robles-Vera, también primer autor del estudio, añade: “No solo observamos que el ImP está elevado en personas con aterosclerosis, sino que es un agente causal de la enfermedad. El consumo de ImP provocó la aparición de placas en las arterias en modelos animales de aterosclerosis. El ImP activa el receptor imidazolínico de tipo 1 (I1R) generando un aumento de la inflamación sistémica que contribuye al desarrollo de la aterosclerosis”.\nPara David Sancho, jefe del laboratorio de Inmunobiología y líder del estudio, “este descubrimiento es importante porque abre una nueva vía de tratamiento”.\nEn la investigación que se publica en ‘Nature’, añade, se ha visto que, el uso de bloqueantes del receptor I1R previene la inducción de aterosclerosis por ImP y reduce la progresión de aterosclerosis en modelos de ratón donde se induce la enfermedad con dieta alta en colesterol. “Esto abre la posibilidad futura de un tratamiento combinado del bloqueo de I1R junto al bloqueo de la producción de colesterol para lograr un efecto que esperamos que sea sinérgico y que prevenga el desarrollo de aterosclerosis”, asegura David Sancho.\nEstos hallazgos, agrega, “abren nuevas posibilidades para el diagnóstico precoz y el tratamiento personalizado y temprano de la aterosclerosis. Así, en lugar de centrarse únicamente en el colesterol y otros factores clásicos, se podría en el futuro analizar la presencia de ImP en sangre como señal de riesgo. En el CNIC estamos trabajando para desarrollar fármacos que bloqueen los efectos perjudiciales de ImP”.\n\nEste trabajo ha sido liderado por el CNIC pero representa una colaboración global a nivel nacional e internacional, con la participación de instituciones como Mount Sinai Fuster Heart Hospital, Icahn School of Medicine at Mount Sinai en Nueva York (EEUU); Instituto de investigación Sanitaria Fundación Jiménez Díaz; Universidad Autónoma de Madrid; Centro de Investigación biomédica en red de enfermedades cardiovasculares (CIBER-CV); Universidad de Gotemburgo (Suecia); Universidad de Atenas (Grecia);  Inmunotek S.L; Universidad de  Michigan (EEUU);  Hospital de La Princesa; Centro de Metabolómica y Bioanálisis (CEMBIO), de la Universidad CEU San Pablo; Universidad de Heidelberg (Alemania), y el  Instituto de Investigaciones Biomédicas Sols-Morreale IIBM-CSIC.\nEste proyecto ha recibido financiación del European Research Council (ayudas Consolidator y Proof of Concept: 2016-Consolidator Grant 725091; ERC-2023-PoC); Ministerio de Ciencia, Innovación y Universidades; Agencia Estatal de Investigación; Unión Europea a través de NextGeneration, y la Fundación “la Caixa”.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D. Sancho, D., et al. Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature (2025). https://doi.org/10.1038/s41586-025-09263-w",
    "source": "CNIC"
  },
  {
    "title": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "title_es": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "url": "https://www.cnic.es/es/noticias/ocho-mejores-estudiantes-bachillerato-espana-participan-programa-acercate",
    "published": "2025-07-11T12:07:09.000Z",
    "date": "2025-07-11",
    "content_es": "11/07/2025\n\n\nSobre el CNIC\nFormación\n\n\n\n\n\n\n\n\nEl objetivo del Programa Acércate es atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular\n\n\n\nUn año más, ocho de los mejores estudiantes de bachillerato de España han participado el programa ACÉRCATE, que organiza el Centro Nacional de Investigaciones Cardiovasculares (CNIC) dentro de su Plan de Formación CNIC-Joven. El objetivo de este plan, una apuesta personal del director general del centro, el Dr. Valentín Fuster, es “atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular”.\nLa convocatoria, abierta a bachilleres de todo el territorio nacional, se ha resuelto este año a favor de 6 alumnas y 2 alumnos de los más de 50 que reunían los requisitos y solicitaron participar en el programa. Este año las personas que participan en el programa proceden de Asturias, Extremadura, Galicia, Comunidad de Madrid, Castilla y León, Comunidad Valenciana y Andalucía.\nIncluyendo a los de esta convocatoria, en total ya han participado en el programa 136 estudiantes. Los jóvenes estudiantes, además de participar en el día a día de un centro de excelencia en investigación como el CNIC, han compartido sus experiencias y sus dudas con los investigadores del centro, pero también con el Dr. Fuster, director del CNIC. El Dr. Fuster considera que empezar el programa de formación en etapas educativas tan tempranas es clave para atraer a los investigadores del futuro porque los jóvenes son el “futuro de la investigación en nuestro país”.\nLas personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024\nEn esta ocasión, las personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024 (Concurso de la Unión Europea para Jóvenes Científicos), un certamen internacional que reconoce los mejores proyectos científicos de jóvenes de entre 14 y 20 años. Kvasnovska, fue seleccionada por su proyecto individual de biomedicina titulado «Biomarcadores potenciales de la inflamación crónica relacionada con la edad».\nLos participantes del programa Acércate al CNIC comparten una gran ilusión por vivir una experiencia enriquecedora que les permita acercarse al mundo real de la investigación biomédica. Así, Alba García Peña quiere profundizar en biomedicina para orientar su futuro profesional. María García Manchado, apasionada por la cardiología, desea conocer de cerca el trabajo investigador, mientras que Lucas Gómez Sánchez espera familiarizarse con el laboratorio y la tecnología aplicada a la medicina.\nLuka Pesich, por su parte, busca reforzar sus conocimientos y habilidades prácticas en biomedicina y Sofía Requena Skalska está interesada en el funcionamiento interno de los grupos de investigación y la conexión entre ciencia y práctica clínica.\nDescubrir el día a día en un laboratorio y confirmar su vocación científica es lo que espera Laura Sánchez Rodríguez, mientras que Carmen Vico Guerra valora la oportunidad de crecer personal y académicamente en un entorno de excelencia.\nPor último, Sara Baldo Muñiz espera comprender de forma directa la labor investigadora y aprender tanto de profesionales como de otros estudiantes con intereses afines.\nTecnología más puntera\nEste programa es el que se dirige a la captación de talento más joven de todos los de formación que hay en el CNIC. El apoyo sostenido de la Fundación Pro CNIC es indispensable para que, año tras año, pueda seguir celebrándose y captando el talento desde la etapa más precoz. “Estamos muy satisfechos de este concepto que comenzamos hace ya más de 20 años”, añade el Dr. Fuster. Y, concluye, “así, si tienen ese ‘gusanillo’ de la investigación, los animamos a seguir adelante”.\nAccede aquí al álbum de fotos de esta convocatoria\nSara Baldó Muñiz \n\nSara cursó sus estudios en el IES Velázquez de Madrid y ha decidido estudiar Bioquímica en la Universidad Autónoma de Madrid. Desde pequeña, ha sentido una fuerte atracción por la investigación científica, impulsada por su curiosidad innata y su deseo de comprender cómo funciona el mundo. \nAlba García Peña \n\nAlba cursó Bachillerato en el IES Álvaro Cunqueiro de Vigo y comenzará el próximo curso la carrera de Biotecnología en la Universidad de Santiago de Compostela. Eligió esta opción porque integra varias disciplinas científicas —Matemáticas, Física, Química y Biología— y le permitirá especializarse más adelante en áreas vinculadas a la investigación biosanitaria. \nMaría García Manchado \n\nMaría estudió en el IES San José de Villanueva de la Serena, Badajoz. Ha optado por estudiar Medicina en la Universidad de Extremadura. Desde niña ha sentido una gran pasión por el conocimiento, que la llevó a interesarse especialmente por Biología y Matemáticas.\nLucas Gómez Sánchez \n\nLucas estudió en el IES Ramiro de Maeztu de Madrid y ahora estudiará Ingeniería Biomédica en la Universidad Carlos III de Madrid. Su curiosidad científica comenzó a los 8 años, participando en actividades como la Noche de los Investigadores y la Semana de la Ciencia. \nLuka Pesich \n\nLuka curso Bachillerato en el Colegio Patrocinio San José de Estepona, Málaga. Ahora iniciará sus estudios en Ciencias Biológicas y Químicas en la Universidad de Limerick (Irlanda), con la intención de especializarse en genética. Su interés por la ciencia fue creciendo de forma natural, motivado por su amor por la naturaleza. \nSofía Requena Skalska \n\nSofía estudió en el CEU San Pablo Valencia de Puerto de Sagunto, Valencia. Sofía cursó parte de su formación secundaria en Quebec, donde tuvo su primer contacto directo con la investigación científica mediante prácticas de laboratorio. Posteriormente, el Bachillerato Internacional fortaleció su interés en la biología y el cuerpo humano. \nLaura Sánchez Rodríguez \n\nLaura estudió en el Colegio Salesiano Santo Ángel de Avilés, Asturias. Empezará el próximo curso la carrera de Biotecnología en la Universidad de Oviedo. Su interés por la ciencia surgió a través de proyectos escolares y viajes STEAM organizados por su centro educativo.\nCarmen Vico Guerra \n\nCarmen cursó Bachillerato en el IES Zorrilla de Valladolid. El próximo cursó comenzará a estudiar Biomedicina y Terapias Avanzadas en la Universidad de Valladolid. Su pasión por la ciencia comenzó en la infancia, cuando pasaba horas hojeando atlas de anatomía y viendo programas divulgativos.",
    "source": "CNIC"
  },
  {
    "title": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "title_es": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "url": "https://www.cnio.es/noticias/un-estudio-pionero-desvela-nuevos-mecanismos-geneticos-implicados-en-tumores-raros-de-cabeza-y-cuello/",
    "published": "2025-07-10T13:50:44.000Z",
    "date": "2025-07-10",
    "content_es": "Los paragangliomas y feocromocitomas son tumores neuroendocrinos muy raros (entre 3 y 8 casos por millón de habitantes) que aparecen en cabeza, cuello y torso, o en las glándulas suprarrenales, y que pueden diseminarse a otros órganos. Cerca de la mitad están causados por alteraciones genéticas heredadas, mutaciones que interesa mucho descubrir: conocerlas permite encontrar familiares portadores de […]\nLa entrada Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "title_es": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "url": "https://www.cnic.es/es/noticias/dr-miguel-torres-premio-nacional-genetica-2025-por-su-contribucion-al-desarrollo-terapias",
    "published": "2025-07-09T09:22:45.000Z",
    "date": "2025-07-09",
    "content_es": "09/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nLa Sociedad Española de Genética (SEG) reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa.\n\n\n\nEl investigador Miguel Torres Sánchez, coordinador del Programa de Regeneración Cardiovascular e investigador principal del grupo “Control Genético del Desarrollo y Regeneración de Órganos” en el Centro Nacional de Investigaciones Cardiovasculares (CNIC), ha sido galardonado con el Premio Nacional de Genética 2025 en la modalidad aplicada, otorgado por la Sociedad Española de Genética (SEG).\nEl jurado reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa, destacando especialmente su trabajo sobre cómo la actividad de los genes regula los procesos de regionalización durante el desarrollo embrionario.\nSus investigaciones han permitido desentrañar mecanismos genéticos implicados en el control de la calidad y la regeneración de órganos, sentando así las bases científicas para el desarrollo de terapias regenerativas dirigidas al corazón y al sistema vascular.\nEl fallo también resalta la proyección internacional del Dr. Torres y el alto impacto de sus publicaciones científicas, que lo sitúan como una figura de referencia en el campo de la biomedicina regenerativa.\nEl Dr. Torres lidera desde el CNIC una de las líneas de investigación más innovadoras en medicina regenerativa, con el objetivo de desarrollar nuevas estrategias terapéuticas que permitan reparar los tejidos dañados tras un infarto u otras patologías cardiovasculares, una de las principales causas de muerte en el mundo.\nProyecto REACTIVA\nEntre otros proyectos, el Dr. Torres dirige el proyecto REACTIVA, seleccionado para recibir una prestigiosa ERC Advanced Grant, financiación que respalda una línea de investigación innovadora centrada en la regeneración del tejido cardíaco, con el objetivo de abrir nuevas vías hacia terapias regenerativas del corazón.\nEl Premio Nacional de Genética, financiado por la Fundación Pryconsa, representa uno de los más altos reconocimientos a la excelencia investigadora en genética en nuestro país. Con él, la Sociedad Española de Genética desea rendir homenaje a la destacada trayectoria científica del Dr. Torres, su compromiso con el avance del conocimiento y el impacto significativo que su trabajo ha tenido en la comunidad científica.\nEste galardón, señala Teresa Roldán Arjona, Presidenta de la Sociedad Española de Genética, “enaltece no solo los logros personales del Dr. Torres, sino también a la institución a la que representa y al conjunto de la comunidad genética”.\nLos Premios Nacionales de Genética, impulsados por la SEG, distinguen cada año trayectorias científicas sobresalientes tanto en investigación básica como aplicada. Junto a Miguel Torres, el jurado ha premiado en la modalidad básica a Amparo Latorre Castillo, catedrática de Genética en la Universidad de València, por su pionera labor en el estudio de la variabilidad del ADN mitocondrial y los procesos evolutivos de simbiosis.",
    "source": "CNIC"
  },
  {
    "title": "Premio a la unidad de cáncer pediátrico del CNIO",
    "title_es": "Premio a la unidad de cáncer pediátrico del CNIO",
    "url": "https://www.cnio.es/noticias/premio-a-la-unidad-de-cancer-pediatrico-del-cnio/",
    "published": "2025-07-07T10:27:25.000Z",
    "date": "2025-07-07",
    "content_es": "Las terapias CAR-T son un tipo de inmunoterapia personalizada en que las células defensivas del paciente son modificadas en el laboratorio para reforzar su capacidad de reconocer y destruir las células tumorales. Su uso, cada vez más frecuente en adultos, es aún reducido en pediatría. La Sociedad Europea de Oncología Pediátrica ha alertado ya de […]\nLa entrada Premio a la unidad de cáncer pediátrico del CNIO se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "title_es": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "url": "https://www.cnio.es/noticias/gracias-a-nuestros-amigos-y-amigas-por-ayudarnos-a-acabar-con-el-cancer/",
    "published": "2025-07-07T07:59:05.000Z",
    "date": "2025-07-07",
    "content_es": "“La clave para frenar el cáncer podría estar en la comunicación entre proteínas. Pero sinceramente, creo que la verdadera clave está en nuestra comunicación, en cómo compartimos, cuestionamos y colaboramos; si seguimos manteniendo este diálogo abierto, creo que llegará el día en que realmente entendamos el cáncer… y lo detengamos”, dijo en la Jornada de […]\nLa entrada Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "title_es": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "url": "https://www.cnio.es/noticias/el-cnio-celebra-la-solidaridad-de-sus-amigos-as-clave-para-atraer-talento-y-avanzar-en-la-investigacion-del-cancer/",
    "published": "2025-07-04T11:09:50.000Z",
    "date": "2025-07-04",
    "content_es": "Una parte importante del conocimiento que genera el Centro Nacional de Investigaciones Oncológicas (CNIO), y que se orienta a mejorar la prevención, el diagnóstico y el tratamiento del cáncer, es fruto de la generosidad. La generosidad de las personas, empresas y fundaciones que realizan donaciones al centro a través del programa ‘Amigos/as del CNIO’.  Desde que se estableció, en 2015, todos los fondos […]\nLa entrada El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Strong interactions and isospin symmetry breaking in a supermoiré lattice",
    "title_es": "Strong interactions and isospin symmetry breaking in a supermoiré lattice",
    "url": "https://www.science.org/doi/abs/10.1126/science.adl2544",
    "published": "2025-07-03T05:59:00.000Z",
    "date": "2025-07-03",
    "content_es": "Science, Volume 389, Issue 6761, Page 736-740, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "title_es": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "url": "https://www.cnic.es/es/node/235158",
    "published": "2025-07-02T09:04:18.000Z",
    "date": "2025-07-02",
    "content_es": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nCNIC researchers have uncovered the evolutionary logic of the OxPhos system—the cell’s “engine”—and developed a tool to detect mutations that cause mitochondrial disease\n\n\n\nMitochondria are the body’s “energy factories,” and their proper function is essential for life. Inside mitochondria, a set of complexes called the oxidative phosphorylation (OxPhos) system acts like a biochemical assembly line, transforming oxygen and nutrients into usable energy.\nNow, the study, led by the GENOXPHOS group at the Spanish National Centre for Cardiovascular Research (CNIC) and the Biomedical Research Networking Centre in the area of Frailty and Healthy Ageing (CIBERFES), and directed by Dr. José Antonio Enríquez, has revealed how this system evolved over millions of years—from the first vertebrates to modern humans. “Understanding this evolution helps explain why some genetic mutations cause rare but serious diseases that affect the OxPhos system,” say José Luis Cabrera lead author of the article, whose research is supported by the ‘la Caixa’ Foundation.\nPublished in Cell Genomics, the study describes the molecular evolutionary strategies of the OxPhos system, the main site of metabolic and energy integration in the cell. It also shows how this information can be used to identify mutations that cause disease.\nWorking in collaboration with Fátima Sánchez-Cabo, head of the CNIC Computational Systems Biomedicine group, the researchers analyzed the interaction between the two types of DNA that encode OxPhos proteins: nuclear DNA (inherited from both parents) and mitochondrial DNA (inherited only from the mother).\nThe OxPhos system, explains José Antonio Enríquez—head of the CNIC Functional Genetics of the Oxidative Phosphorylation System (GENOXPHOS) group—comprises five large protein complexes: four that transport electrons and one, called ATP synthase, that produces ATP, the cell’s molecular “fuel.”\n“These complexes can work individually or in combination, depending on the cell’s energy needs. Together, they are made up of 103 proteins encoded by two different genomes: nuclear and mitochondrial,” Enríquez explains. “While nuclear DNA changes slowly over time and gains variation through genetic mixing during reproduction, mitochondrial DNA evolves much more rapidly but is passed only through the maternal line.”\nDr. Cabrera adds that the proteins encoded by mitochondrial DNA form the core of the respiratory complexes, “so proper function depends on precise compatibility between the nuclear and mitochondrial components.”\nThe study also introduces an innovative new tool: ConScore, a predictive index that assesses the clinical relevance of mutations in the 103 OxPhos proteins. “ConScore is based on the evolutionary divergence of these proteins across vertebrates—including primates and other mammals—and complements human population genetic data,” says Enríquez.\nThe authors affirm that ConScore provides a new framework for interpreting potentially pathogenic mutations, opening the door to improved diagnosis and treatment of mitochondrial diseases.\nUltimately, the researchers conclude, this study not only advances our understanding of how human cells evolved, but also brings us closer to new solutions for patients with rare genetic disease.\nThe study has received funding from the European Union's NextGenerationEU/Recovery, Transformation and Resilience Plan/PRTR, CIBERFES; Fundación ‘la Caixa’,Human Frontier Science Fundation; Severo Ochoa grant awarded by MICIU/AEI and the European Social Fund (ESF invests in your future).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "source": "CNIC"
  },
  {
    "title": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "title_es": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "url": "https://www.cnio.es/noticias/los-danos-en-el-adn-derivados-de-la-contaminacion-atmosferica-podrian-contribuir-al-cancer-de-pulmon-en-personas-no-fumadoras-halla-un-estudio/",
    "published": "2025-07-02T15:17:44.000Z",
    "date": "2025-07-02",
    "content_es": "Una cuarta parte de los casos de cáncer de pulmón se dan en personas que no han fumado nunca. ¿Cuál es la causa de estos cánceres? Un estudio que analiza las alteraciones genéticas (mutaciones) en tumores de 871 personas no fumadoras de cuatro continentes apunta a la contaminación atmosférica como una de las posibles causas. […]\nLa entrada Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "title_es": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "url": "https://www.cnio.es/noticias/roger-castells-graells-recibe-el-premio-hawk-biosystems-de-la-sociedad-espanola-de-biofisica/",
    "published": "2025-06-27T13:52:15.000Z",
    "date": "2025-06-27",
    "content_es": "El investigador Roger Castells-Graells, del Centro Nacional de Investigaciones Oncológicas (CNIO), ha recibido el premio “Hawk Biosystems”, que otorga la Sociedad de Biofísica de España (SBE) en el marco de su XVIII Congreso Internacional. Castells-Graells se incorporó recientemente al CNIO para dirigir el nuevo Grupo de Diseño Biomolecular y Nanomedicina Estructural, dedicado a crear nanopartículas […]\nLa entrada Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "title_es": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "url": "https://www.cnio.es/noticias/mariano-barbacid-premio-valor-anadido-a-la-ciencia-e-investigacion/",
    "published": "2025-06-26T13:42:59.000Z",
    "date": "2025-06-26",
    "content_es": "Mariano Barbacid, descubridor del primer oncogén humano, ha recibido el Premio Valor Añadido a la Ciencia e Investigación, que reconoce la “labor de cultivo y perfeccionamiento de la investigación, descubrimiento e invención”. Los Premios Valor Añadido son una iniciativa de la Fundación Transforma España, en colaboración con BBVA, para «impulsar el reconocimiento de la aportación […]\nLa entrada Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "The proteome of the late Middle Pleistocene Harbin individual",
    "title_es": "The proteome of the late Middle Pleistocene Harbin individual",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu9677",
    "published": "2025-06-18T03:00:00.000Z",
    "date": "2025-06-18",
    "content_es": "Science, Volume 389, Issue 6761, Page 704-707, August 2025.",
    "source": "Science.org"
  }
]