[
  {
    "title": "Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction",
    "title_es": "Comprobación semiautomatizada de hechos en portugués: Enriquecimiento de corpus mediante recuperación con extracción de afirmaciones",
    "url": "https://arxiv.org/abs/2508.06495",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06495v1 Tipo de anuncio: nuevo\nResumen: La acelerada difusión de la desinformación a menudo supera la capacidad de comprobación manual de los hechos, lo que pone de relieve la urgente necesidad de sistemas semiautomatizados de comprobación de hechos (SAFC). En el contexto de la lengua portuguesa, existe una notable escasez de conjuntos de datos disponibles públicamente que integren evidencias externas, un componente esencial para desarrollar sistemas robustos de AFC, ya que muchos de los recursos existentes se centran únicamente en la clasificación basada en características intrínsecas del texto. Esta tesis aborda esta carencia desarrollando, aplicando y analizando una metodología para enriquecer corpus de noticias en portugués (Fake.Br, COVID19.BR, MuMiN-PT) con evidencias externas. El enfoque simula el proceso de verificación de un usuario, empleando Large Language Models (LLMs, específicamente Gemini 1.5 Flash) para extraer la afirmación principal de los textos y APIs de motores de búsqueda (Google Search API, Google FactCheck Claims Search API) para recuperar documentos externos relevantes (evidencia). Además, se introduce un marco de validación y preprocesamiento de datos, incluida la detección de casi duplicados, para mejorar la calidad de los corpus de base.",
    "source": "arXiv"
  },
  {
    "title": "Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG",
    "title_es": "Med-GRIM: VQA médico mejorado de disparo cero mediante gráfico multimodal RAG integrado en el indicador",
    "url": "https://arxiv.org/abs/2508.06496",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06496v1 Tipo de anuncio: nuevo\nResumen: Un conjunto de codificadores multimodales entrenados y modelos de visión-lenguaje (VLMs) se ha convertido en un enfoque estándar para las tareas de respuesta a preguntas visuales (VQA). Sin embargo, estos modelos a menudo no producen respuestas con la precisión detallada necesaria para aplicaciones complejas y específicas de un dominio, como el VQA médico. Nuestro modelo de representación, BIND: BLIVA Integrated with Dense Encoding (BLIVA integrada con codificación densa), amplía los trabajos multimodales anteriores al perfeccionar el espacio de incrustación conjunta mediante codificaciones densas basadas en testigos de consulta e inspiradas en técnicas de preentrenamiento contrastivo. Este codificador refinado alimenta Med-GRIM, un modelo diseñado para tareas médicas de VQA que aprovecha la recuperación basada en grafos y la ingeniería de consultas para integrar conocimientos específicos del dominio. En lugar de depender de un ajuste preciso de los modelos de visión y lenguaje en conjuntos de datos específicos, Med-GRIM aplica un flujo de trabajo modular y de bajo coste computacional con pequeños modelos de lenguaje (SLM) en aras de la eficiencia. Med-GRIM emplea la recuperación basada en instrucciones para inyectar de forma dinámica los conocimientos pertinentes, garantizando tanto la precisión como la solidez de sus respuestas. Al asignar distintas funciones a cada agente dentro del sistema VQA, Med-GRIM consigue un gran rendimiento del modelo lingüístico a una fracción del coste computacional. Además, para apoyar la investigación escalable en aplicaciones médicas multimodales de disparo cero, presentamos DermaGraph, un nuevo conjunto de datos Graph-RAG que comprende diversas afecciones dermatológicas. Este conjunto de datos facilita la consulta tanto multimodal como unimodal. El código y el conjunto de datos están disponibles en: https://github.com/Rakesh-123-cryp/Med-GRIM.git",
    "source": "arXiv"
  },
  {
    "title": "Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models",
    "title_es": "Generación dinámica basada en la recuperación aumentada para el reconocimiento de entidades biomédicas con nombre en pocas tomas mediante modelos de lenguaje de gran tamaño.",
    "url": "https://arxiv.org/abs/2508.06504",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06504v1 Tipo de anuncio: nuevo\nResumen: El reconocimiento biomédico de entidades con nombre (NER) es una tarea de gran utilidad en el procesamiento del lenguaje natural (NLP), y los modelos de lenguaje de gran tamaño (LLMs) son prometedores, especialmente en entornos con pocos datos (es decir, datos de entrenamiento limitados). En este artículo, abordamos los retos de rendimiento de los LLM para la NER biomédica de pocos disparos mediante la investigación de una estrategia dinámica que implica la generación de recuperación aumentada (RAG). En nuestro enfoque, los ejemplos de aprendizaje en contexto anotados se seleccionan en función de sus similitudes con los textos de entrada, y la indicación se actualiza dinámicamente para cada instancia durante la inferencia. Implementamos y optimizamos técnicas de ingeniería de indicaciones estáticas y dinámicas y las evaluamos en cinco conjuntos de datos biomédicos de NER. El prompting estático con componentes estructurados aumentó la puntuación F1 media en un 12% para GPT-4 y en un 11% para GPT-3.5 y LLaMA 3-70B, en comparación con el prompting estático básico. Los métodos de recuperación TF-IDF y SBERT obtuvieron los mejores resultados, con una mejora de las puntuaciones F1 medias del 7,3% y el 5,6% en las configuraciones de 5 y 10 disparos, respectivamente. Estos resultados ponen de relieve la utilidad de los avisos adaptables al contexto a través de la RAG para la recuperación de datos biomédicos.",
    "source": "arXiv"
  },
  {
    "title": "DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation",
    "title_es": "DiTalker: Un marco unificado basado en DiT para la animación de retratos de alta calidad y con estilos de habla controlables",
    "url": "https://arxiv.org/abs/2508.06511",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06511v1 Tipo de anuncio: nuevo\nResumen: La animación de retratos tiene como objetivo sintetizar vídeos hablados a partir de un rostro de referencia estático, condicionado por pistas de audio y de estilo (por ejemplo, emoción y poses de la cabeza), garantizando al mismo tiempo una sincronización labial precisa y una reproducción fiel de los estilos de habla. Los métodos existentes de animación de retratos basados en la difusión se centran principalmente en la sincronización labial o en la transformación de emociones estáticas, y a menudo pasan por alto estilos dinámicos como los movimientos de la cabeza. Además, la mayoría de estos métodos se basan en una arquitectura U-Net dual, que preserva la coherencia de la identidad pero genera una sobrecarga computacional adicional. Con este fin, proponemos DiTalker, un marco unificado basado en DiT para la animación de retratos controlable por el estilo de habla. Diseñamos un módulo de codificación estilo-emoción que emplea dos ramas separadas: una rama de estilo que extrae información de estilo específica de la identidad (por ejemplo, poses y movimientos de la cabeza), y una rama de emoción que extrae características de emoción independientes de la identidad. Además, introducimos un módulo de fusión de audio y estilo que disocia los estilos de audio y habla mediante dos capas paralelas de atención cruzada, utilizando estas características para guiar el proceso de animación. Para mejorar la calidad de los resultados, adoptamos y modificamos dos restricciones de optimización: una para mejorar la sincronización labial y otra para preservar los detalles de identidad y fondo. Extensos experimentos demuestran la superioridad de DiTalker en términos de sincronización labial y controlabilidad del estilo de habla. Página del proyecto: https://thenameishope.github.io/DiTalker/",
    "source": "arXiv"
  },
  {
    "title": "Accessibility Literacy: Increasing accessibility awareness among young content creators",
    "title_es": "Alfabetización en accesibilidad: aumentar la conciencia de accesibilidad entre los jóvenes creadores de contenidos",
    "url": "https://arxiv.org/abs/2508.06512",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06512v1 Tipo de anuncio: nuevo\nResumen: La proliferación de contenidos audiovisuales y web ha creado una creciente necesidad de educación en accesibilidad a los medios en diversos campos. Sin embargo, la accesibilidad sigue siendo una prioridad baja en los planes de estudio universitarios. Este proyecto explora la viabilidad de una experiencia de aprendizaje alternativa dirigida a aumentar la alfabetización en accesibilidad de los jóvenes creadores de contenidos, tomando la accesibilidad web como caso de estudio. Proponemos un minimódulo que utiliza materiales de formación sencillos y fáciles de usar, como infografías y cuestionarios breves, y que puede incorporarse fácilmente a los programas educativos junto con los cursos existentes. Se realizó una encuesta para investigar los conocimientos sobre accesibilidad de los participantes antes y después de la formación. Los resultados muestran que, en general, los jóvenes creadores de contenidos tienen conocimientos limitados sobre accesibilidad, pero incluso una breve exposición a los materiales de accesibilidad contribuyó a cambiar sus percepciones. Después de la formación, los participantes se mostraron más dispuestos a aplicar herramientas de accesibilidad en sus contenidos, aunque la forma de hacerlo variaba en función del tipo de contenido y su finalidad. Esto sugiere que las intervenciones pequeñas pero específicas podrían ser una alternativa para integrar la formación en accesibilidad en la educación formal de diversas disciplinas. Aunque algunas respuestas reflejaban rastros del modelo médico de la discapacidad y una visión particularista de la accesibilidad, ésta se reconoció como importante para aumentar la inclusión, mejorar los contenidos y conformar una sociedad más justa.",
    "source": "arXiv"
  },
  {
    "title": "BigTokDetect: A Clinically-Informed Vision-Language Model Framework for Detecting Pro-Bigorexia Videos on TikTok",
    "title_es": "BigTokDetect: Un modelo de visión y lenguaje clínicamente informado para detectar vídeos pro-bigorexia en TikTok",
    "url": "https://arxiv.org/abs/2508.06515",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06515v1 Tipo de anuncio: nuevo\nResumen: Las plataformas de medios sociales tienen cada vez más dificultades para detectar contenidos nocivos que promueven comportamientos dismórficos musculares, en particular contenidos pro-gigorexia que afectan desproporcionadamente a los adolescentes varones. A diferencia de la detección tradicional de trastornos alimentarios centrada en el \"ideal de delgadez\", el material pro-gigorexia se disfraza de contenido legítimo de fitness a través de complejas combinaciones multimodales de pantallas visuales, lenguaje codificado y mensajes de motivación que evaden los sistemas de detección basados en texto. Abordamos este reto desarrollando BigTokDetect, un marco de detección clínicamente informado para identificar contenido pro-bigorexia en TikTok. Presentamos BigTok, el primer conjunto de datos multimodal anotado por expertos de más de 2.200 vídeos de TikTok etiquetados por psicólogos clínicos y psiquiatras en cinco categorías principales que abarcan imagen corporal, nutrición, ejercicio, suplementos y masculinidad. Mediante una evaluación exhaustiva de los modelos de lenguaje visual más avanzados, logramos una precisión del 0,829% en la clasificación de categorías primarias y del 0,690% en la detección de subcategorías a través de ajustes específicos del dominio. Nuestros estudios de ablación demuestran que la fusión multimodal mejora el rendimiento entre un 5 y un 10% con respecto a los enfoques basados únicamente en texto, siendo las características de vídeo las que proporcionan las señales más discriminativas. Estos resultados establecen nuevos puntos de referencia para la detección multimodal de contenidos nocivos y proporcionan las herramientas informáticas y el marco metodológico necesarios para la moderación escalable de contenidos en ámbitos especializados de la salud mental.",
    "source": "arXiv"
  },
  {
    "title": "AutoMashup: Automatic Music Mashups Creation",
    "title_es": "AutoMashup: Creación automática de mashups musicales",
    "url": "https://arxiv.org/abs/2508.06516",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06516v1 Tipo de anuncio: nuevo\nResumen: Presentamos AutoMashup, un sistema para la creación automática de mashups basado en la separación de fuentes, el análisis musical y la estimación de compatibilidad. Proponemos el uso de COCOLA para evaluar la compatibilidad entre los tallos separados e investigar si los modelos de audio pre-entrenados de propósito general (CLAP y MERT) pueden apoyar la estimación de tiro cero de la compatibilidad de pares de pistas. Nuestros resultados muestran que la compatibilidad de los mashups es asimétrica -depende del papel asignado a cada pista (voz o acompañamiento)- y que las incrustaciones actuales no consiguen reproducir la coherencia perceptiva medida por COCOLA. Estos resultados subrayan las limitaciones de las representaciones de audio de uso general para estimar la compatibilidad en la creación de mashups.",
    "source": "arXiv"
  },
  {
    "title": "Frequency Prior Guided Matching: A Data Augmentation Approach for Generalizable Semi-Supervised Polyp Segmentation",
    "title_es": "Emparejamiento guiado por frecuencias previas: un enfoque de aumento de datos para la segmentación de pólipos semisupervisada generalizable",
    "url": "https://arxiv.org/abs/2508.06517",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06517v1 Tipo de anuncio: nuevo\nResumen: La segmentación automatizada de pólipos es esencial para el diagnóstico precoz del cáncer colorrectal, sin embargo, el desarrollo de modelos robustos sigue siendo un reto debido a la limitación de datos anotados y la degradación significativa del rendimiento bajo el cambio de dominio. Aunque el aprendizaje semisupervisado (SSL) reduce los requisitos de anotación, los métodos existentes se basan en aumentos genéricos que ignoran las propiedades estructurales específicas de los pólipos, lo que resulta en una pobre generalización a nuevos centros y dispositivos de imagen. Para solucionar este problema, presentamos el Frequency Prior Guided Matching (FPGM), un novedoso marco de aumento basado en un descubrimiento clave: los bordes de los pólipos muestran una firma de frecuencia notablemente coherente en diversos conjuntos de datos. FPGM aprovecha esta regularidad intrínseca en un proceso de dos etapas. En primer lugar, aprende una frecuencia independiente del dominio a partir de las regiones de los bordes de los pólipos etiquetados. A continuación, realiza perturbaciones espectrales basadas en principios en las imágenes no etiquetadas, alineando sus espectros de amplitud con esta prioridad aprendida y conservando la información de fase para mantener la integridad estructural. Esta alineación específica normaliza las variaciones texturales específicas del dominio, obligando así al modelo a aprender la estructura anatómica generalizable subyacente. Validado en seis conjuntos de datos públicos, FPGM establece un nuevo estado del arte frente a diez métodos competidores. Demuestra una excepcional capacidad de generalización sin disparos, logrando más de un 10% de ganancia absoluta en la puntuación Dice en escenarios de escasez de datos. Al mejorar significativamente la robustez entre dominios, FPGM presenta una potente solución para la segmentación de pólipos clínicamente desplegable bajo supervisión limitada.",
    "source": "arXiv"
  },
  {
    "title": "Automated Seam Folding and Sewing Machine on Pleated Pants for Apparel Manufacturing",
    "title_es": "Máquina automatizada de plegado y cosido de costuras en pantalones plisados para la confección de prendas de vestir",
    "url": "https://arxiv.org/abs/2508.06518",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06518v1 Tipo de anuncio: nuevo\nResumen: La investigación aplicada consiste en el diseño y desarrollo de una máquina automatizada de plegado y cosido de pantalones plisados. Representa un avance significativo a la hora de abordar los retos asociados a los procesos de cosido manual. Los métodos tradicionales para la creación de pliegues requieren mucha mano de obra, son propensos a inconsistencias y requieren altos niveles de habilidad, por lo que la automatización es una necesidad crítica en la industria de la confección. Esta investigación explora la viabilidad técnica y las ventajas operativas de integrar tecnologías avanzadas en la producción de prendas de vestir, centrándose en la creación de una máquina automatizada capaz de realizar operaciones precisas de plegado y cosido y de eliminar la operación de marcado.\n  La máquina propuesta incorpora características clave como un mecanismo de plegado de precisión integrado en la unidad de costura automatizada con capacidad de supervisión en tiempo real. Los resultados demuestran mejoras notables: el tiempo de mano de obra estándar se ha reducido en un 93%, pasando de 117 segundos por pieza a sólo 8 segundos con el sistema automatizado. Del mismo modo, el tiempo de la maquinaria mejoró un 73%, y la tasa de producción total aumentó un 72%. Estas mejoras se traducen en una reducción del tiempo de ciclo de 117 segundos por pieza a unos impresionantes 33 segundos, lo que permite a los fabricantes satisfacer la demanda de los clientes con mayor rapidez. Al eliminar los procesos de marcado manual, la máquina no sólo reduce los costes de mano de obra, sino que también minimiza los residuos gracias a la formación uniforme de pliegues. Esta automatización se alinea con las tendencias de la industria hacia la sostenibilidad y la eficiencia, reduciendo potencialmente el impacto medioambiental al disminuir los residuos de material y el consumo de energía.",
    "source": "arXiv"
  },
  {
    "title": "Optimization of Flip-Landing Trajectories for Starship based on a Deep Learned Simulator",
    "title_es": "Optimización de trayectorias de aterrizaje para naves estelares basada en un simulador de aprendizaje profundo",
    "url": "https://arxiv.org/abs/2508.06520",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06520v1 Tipo de anuncio: nuevo\nResumen: Proponemos un marco de optimización diferenciable para el diseño de trayectorias de volteo y aterrizaje de naves espaciales reutilizables, ejemplificadas por el vehículo Starship. Una red neuronal profunda, entrenada con datos CFD de alta fidelidad, predice las fuerzas y momentos aerodinámicos, y está estrechamente acoplada con un solucionador de dinámica de cuerpo rígido diferenciable. Esto permite una optimización de la trayectoria de extremo a extremo basada en gradientes sin linealización ni relajación convexa. El marco maneja los límites de los actuadores y las restricciones de aterrizaje terminal, produciendo secuencias de control optimizadas y físicamente consistentes. Tanto la diferenciación automática estándar como los ODE neuronales se aplican para soportar despliegues de horizonte largo. Los resultados demuestran la eficacia del marco para modelar y optimizar maniobras complejas con elevadas no linealidades. Este trabajo sienta las bases para futuras ampliaciones que incluyan la aerodinámica inestable, las interacciones de la pluma y el diseño de guiado inteligente.",
    "source": "arXiv"
  },
  {
    "title": "Stinger Robot: A Self-Bracing Robotic Platform for Autonomous Drilling in Confined Underground Environments",
    "title_es": "Robot Stinger: Una plataforma robótica autoportante para la perforación autónoma en entornos subterráneos confinados",
    "url": "https://arxiv.org/abs/2508.06521",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06521v1 Tipo de anuncio: nuevo\nResumen: La creciente demanda de materias primas críticas ha revitalizado el interés por las minas subterráneas abandonadas, que plantean retos extremos para la maquinaria de perforación convencional debido a los entornos confinados, desestructurados y sin infraestructuras. Este artículo presenta el robot Stinger, una novedosa plataforma robótica compacta diseñada específicamente para la perforación autónoma de alta fuerza en este tipo de entornos. El robot cuenta con un mecanismo de tres patas con autobloqueo mecánico que permite un anclaje estable a las superficies irregulares de los túneles. Una innovación clave reside en su estrategia de control de bucle cerrado sensible a la fuerza, que permite la interacción de la fuerza con entornos no estructurados durante el apuntalamiento y la perforación. Implementada como una máquina de estados finitos en ROS 2, la política de control adapta dinámicamente el despliegue de las patas en función de la información de contacto en tiempo real y los umbrales de carga, garantizando la estabilidad sin soportes externos. Demostramos, mediante simulación y pruebas preliminares de hardware, que el robot Stinger puede estabilizarse y perforar de forma autónoma en condiciones hasta ahora inaccesibles para las máquinas mineras actuales. Este trabajo constituye la primera arquitectura robótica validada que integra el arriostramiento distribuido de fuerzas y la perforación autónoma en entornos subterráneos, sentando las bases para futuras operaciones mineras colaborativas mediante sistemas robóticos modulares.",
    "source": "arXiv"
  },
  {
    "title": "CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models",
    "title_es": "CarbonScaling: Ampliación de las leyes de escala neuronal para la huella de carbono en grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.06524",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06524v1 Tipo de anuncio: nuevo\nResumen: Las leyes de escalado neuronal han impulsado el desarrollo de modelos lingüísticos (LLM) cada vez más grandes al vincular las mejoras en la precisión con el crecimiento en el número de parámetros, el tamaño del conjunto de datos y la computación. Sin embargo, estas leyes pasan por alto las emisiones de carbono que aumentan exponencialmente con el tamaño del LLM. Este artículo presenta \\textit{CarbonScaling}, un marco analítico que amplía las leyes de escalado neuronal para incorporar tanto el carbono operativo como el carbono incorporado en el entrenamiento de los LLM. Mediante la integración de modelos de escalado neuronal, evolución del hardware de la GPU, optimización del paralelismo y estimación del carbono, \\textit{CarbonScaling} conecta cuantitativamente la precisión del modelo con la huella de carbono. Los resultados muestran que, aunque se mantiene una relación de ley de potencias entre la precisión y el carbono, las ineficiencias del mundo real aumentan significativamente el factor de escalado. El escalado de la tecnología de hardware reduce las emisiones de carbono en el caso de modelos pequeños y medianos, pero ofrece rendimientos decrecientes en el caso de LLM extremadamente grandes debido a la sobrecarga de las comunicaciones y a la infrautilización de las GPU. Las optimizaciones de la formación -especialmente el agresivo escalado del tamaño crítico de los lotes- ayudan a paliar esta ineficiencia. \\textit{CarbonScaling} ofrece información clave para entrenar LLM más sostenibles y eficientes en términos de emisiones de carbono.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models Facilitate Vision Reflection in Image Classification",
    "title_es": "Los grandes modelos lingüísticos facilitan la reflexión visual en la clasificación de imágenes",
    "url": "https://arxiv.org/abs/2508.06525",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06525v1 Tipo de anuncio: nuevo\nResumen: Este trabajo presenta varios hallazgos novedosos sobre la explicabilidad del reflejo de la visión en grandes modelos multimodales (LMMs). En primer lugar, mostramos que pedir a un LMM que verifique la predicción de un modelo de visión especializado puede mejorar la precisión del reconocimiento, incluso en puntos de referencia como ImageNet, a pesar de la evidencia previa de que los LMM suelen tener un rendimiento inferior al de los codificadores de visión dedicados. En segundo lugar, analizamos el comportamiento interno del reflejo de la visión y descubrimos que el conector visión-lenguaje asigna características visuales a conceptos textuales explícitos, lo que permite al modelo de lenguaje razonar sobre la verosimilitud de la predicción utilizando conocimientos de sentido común. Además, observamos que la sustitución de un gran número de tokens de visión por sólo unos pocos tokens de texto sigue permitiendo a LLaVA generar respuestas similares, lo que sugiere que los LMM pueden basarse principalmente en un conjunto compacto de representaciones textuales destiladas en lugar de en características de visión brutas. En tercer lugar, mostramos que un conector sin entrenamiento puede mejorar el rendimiento de los LMM en tareas de reconocimiento de grano fino, sin un extenso entrenamiento de alineación de características. En conjunto, estos hallazgos ofrecen nuevas perspectivas sobre la explicabilidad de los modelos de visión-lenguaje y sugieren que la reflexión de la visión es una estrategia prometedora para lograr un reconocimiento visual robusto e interpretable.",
    "source": "arXiv"
  },
  {
    "title": "PiKV: KV Cache Management System for Mixture of Experts",
    "title_es": "PiKV: Sistema de Gestión de Caché KV para Mezcla de Expertos",
    "url": "https://arxiv.org/abs/2508.06526",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06526v1 Tipo de anuncio: nuevo\nResumen: A medida que los modelos lingüísticos de gran tamaño siguen aumentando tanto en tamaño como en longitud de contexto, el coste de memoria y comunicación del almacenamiento en caché de claves-valores (KV) se ha convertido en un importante cuello de botella en la inferencia multi-GPU y multi-nodos. Mientras que las arquitecturas basadas en MoE dispersan el cálculo entre los expertos, las cachés KV correspondientes siguen siendo densas y sincronizadas globalmente, lo que supone una sobrecarga significativa.\n  Presentamos \\textbf{PiKV}, un marco de servicio de caché KV paralelo y distribuido adaptado a la arquitectura MoE. PiKV utiliza \\textit{expert-sharded KV storage} para repartir las cachés entre las GPU, \\textit{PiKV routing} para reducir el acceso de token a KV, y \\textit{PiKV Scheduling} para retener de forma adaptativa las entradas relevantes para la consulta. Para reducir aún más el uso de memoria, PiKV integra módulos \\textit{PiKV Compression} en el proceso de almacenamiento en caché para su aceleración.\n  PiKV está disponible públicamente como una biblioteca de software de código abierto: \\https://github.com/NoakLiu/PiKV. Los detalles de los experimentos están registrados en \\href{https://github.com/NoakLiu/PiKV/blob/main/downstream_tasks/README.md}{https://github.com/NoakLiu/PiKV/Experimental\\_Results}. También tenemos PiKV integrado con Nvidia kvpress para la aceleración, los detalles ver \\href{https://github.com/NoakLiu/PiKVpress}{https://github.com/NoakLiu/PiKVpress}. PiKV sigue siendo un proyecto vivo, con el objetivo de convertirse en un sistema integral de gestión de caché KV para arquitecturas MoE.",
    "source": "arXiv"
  },
  {
    "title": "A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition",
    "title_es": "Un marco que combina CNN 3D y transformador para el reconocimiento de comportamientos basado en vídeo",
    "url": "https://arxiv.org/abs/2508.06528",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06528v1 Tipo de anuncio: nuevo\nResumen: El reconocimiento de comportamientos basado en vídeo es esencial en campos como la seguridad pública, la vigilancia inteligente y la interacción persona-ordenador. Las redes neuronales convolucionales 3D (CNN 3D) tradicionales capturan eficazmente las características espaciotemporales locales, pero tienen dificultades para modelar las dependencias de largo alcance. Por el contrario, los Transformers destacan en el aprendizaje de información contextual global, pero se enfrentan a retos con altos costes computacionales. Para abordar estas limitaciones, proponemos un marco híbrido que combina las arquitecturas 3D CNN y Transformer. El módulo 3D CNN extrae características espaciotemporales de bajo nivel, mientras que el módulo Transformer captura dependencias temporales de largo alcance, con un mecanismo de fusión que integra ambas representaciones. Evaluado en conjuntos de datos de referencia, el modelo propuesto supera a las CNN 3D tradicionales y a los Transformers autónomos, logrando una mayor precisión de reconocimiento con una complejidad manejable. Los estudios de ablación validan aún más los puntos fuertes complementarios de los dos módulos. Este marco híbrido ofrece una solución eficaz y escalable para el reconocimiento de comportamientos basado en vídeo.",
    "source": "arXiv"
  },
  {
    "title": "RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving",
    "title_es": "RMT-PPAD: aprendizaje multitarea en tiempo real para la percepción panóptica en la conducción autónoma",
    "url": "https://arxiv.org/abs/2508.06529",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06529v1 Tipo de anuncio: nuevo\nResumen: Los sistemas de conducción autónoma dependen de la percepción panóptica de la conducción que requiere tanto precisión como rendimiento en tiempo real. En este trabajo proponemos RMT-PPAD, un modelo multitarea en tiempo real basado en transformadores que realiza conjuntamente la detección de objetos, la segmentación de áreas conducibles y la segmentación de líneas de carril. Introducimos un módulo ligero, un control de puerta con un adaptador para fusionar de forma adaptativa características compartidas y específicas de la tarea, aliviando eficazmente la transferencia negativa entre tareas. Además, diseñamos un decodificador de segmentación adaptativo para aprender automáticamente los pesos sobre las características multiescala durante la fase de entrenamiento. Esto evita el diseño manual de estructuras específicas para las distintas tareas de segmentación. También identificamos y resolvemos la inconsistencia entre las etiquetas de entrenamiento y de prueba en la segmentación de líneas de carril. Esto permite una evaluación más justa. Los experimentos realizados con el conjunto de datos BDD100K demuestran que RMT-PPAD consigue resultados de vanguardia con un mAP50 del 84,9% y un Recall del 95,4% para la detección de objetos, un mIoU del 92,6% para la segmentación de zonas transitables y un IoU del 56,8% y una precisión del 84,7% para la segmentación de líneas de carril. La velocidad de inferencia alcanza los 32,6 FPS. Además, introducimos escenarios reales para evaluar el rendimiento de RMT-PPAD en la práctica. Los resultados muestran que RMT-PPAD ofrece un rendimiento estable. Los códigos fuente y los modelos preentrenados están disponibles en https://github.com/JiayuanWang-JW/RMT-PPAD.",
    "source": "arXiv"
  },
  {
    "title": "What Makes \"Good\" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?",
    "title_es": "¿Qué distractores son \"buenos\" para evaluar la alucinación de objetos en grandes modelos de visión-lenguaje?",
    "url": "https://arxiv.org/abs/2508.06530",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06530v1 Tipo de anuncio: nuevo\nResumen: Los Large Vision-Language Models (LVLMs), potenciados por el éxito de los Large Language Models (LLMs), han alcanzado un rendimiento impresionante en todos los dominios. A pesar de los grandes avances en LVLMs, todavía sufren del problema de la alucinación de objetos no disponibles, que tiende a generar objetos inconsistentes con el contenido de la imagen. La prueba de referencia más utilizada, Polling-based Object Probing Evaluation (POPE), evalúa este problema mediante el muestreo de categorías negativas en función de estadísticas a nivel de categoría, \\textit{e.}, frecuencias de categoría y co-ocurrencia. Sin embargo, con el continuo avance de los LVLMs, el benchmark POPE ha mostrado una eficacia decreciente en la evaluación de la alucinación de objetos, ya que emplea una estrategia de muestreo simplista que pasa por alto la información específica de la imagen y restringe los distractores únicamente a las categorías negativas de objetos. En este trabajo, introducimos la evaluación comparativa Hallucination searching-based Object Probing Evaluation (HOPE), cuyo objetivo es generar los distractores más engañosos (\\textit{i.}, objetos inexistentes o descripciones incorrectas de la imagen) que pueden desencadenar la alucinación en los LVLM, lo que sirve como medio para evaluar de forma más rigurosa su inmunidad a la alucinación. Para explorar la información específica de la imagen, la búsqueda de alucinaciones basada en el contenido aprovecha el preentrenamiento contrastivo de lenguaje-imagen (CLIP) para aproximarse al comportamiento predictivo de los LVLM seleccionando como distractores los objetos negativos con mayor probabilidad de predicción. Para ampliar el alcance de la evaluación de alucinaciones, la búsqueda de alucinaciones basada en descripciones construye distractores altamente engañosos emparejando objetos verdaderos con descripciones falsas. Los resultados experimentales muestran que HOPE reduce la precisión en al menos un 9\\% y hasta un 23\\% en varios LVLM de última generación, superando significativamente a POPE en la detección de vulnerabilidades de alucinación. El código está disponible en https://github.com/xiemk/HOPE.",
    "source": "arXiv"
  },
  {
    "title": "The Art of Breaking Words: Rethinking Multilingual Tokenizer Design",
    "title_es": "El arte de romper palabras: Replanteamiento del diseño de tokenizadores multilingües",
    "url": "https://arxiv.org/abs/2508.06533",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06533v1 Tipo de anuncio: nuevo\nResumen: Mientras que la arquitectura del modelo y los objetivos de entrenamiento están bien estudiados, la tokenización, especialmente en contextos multilingües, sigue siendo un aspecto relativamente descuidado en el desarrollo de modelos de grandes lenguas (LLM). Los tokenizadores existentes suelen presentar una elevada relación token/palabra, un uso ineficiente de la longitud del contexto y una inferencia más lenta. Presentamos un estudio sistemático que relaciona el tamaño del vocabulario, las reglas de pretokenización y la composición del corpus de entrenamiento tanto con la eficiencia de la relación token/palabra como con la calidad del modelo. Para fundamentar nuestro análisis en un contexto lingüístico diverso, realizamos experimentos exhaustivos con escrituras índicas, que presentan retos únicos debido a su gran diversidad y complejidad ortográfica. A partir de los resultados de estos análisis, proponemos un nuevo algoritmo de composición de datos que equilibra los datos multilingües para la formación del tokenizador. Nuestras observaciones sobre las estrategias de pretokenización mejoran significativamente el rendimiento del modelo, y nuestro algoritmo de composición de datos reduce la relación media token/palabra en aproximadamente un 6% con respecto al enfoque convencional de aleatorización de datos. Nuestro tokenizador mejora en más de un 40% la relación media token/palabra con respecto a los modelos Indic multilingües más avanzados. Esta mejora se traduce en ganancias apreciables tanto en el rendimiento del modelo como en la velocidad de inferencia. Esto pone de relieve que la tokenización, junto con la arquitectura y los objetivos de formación, es una palanca fundamental para construir LLM multilingües eficientes y escalables.",
    "source": "arXiv"
  },
  {
    "title": "MetAdv: A Unified and Interactive Adversarial Testing Platform for Autonomous Driving",
    "title_es": "MetAdv: Una plataforma unificada e interactiva de pruebas adversariales para la conducción autónoma",
    "url": "https://arxiv.org/abs/2508.06534",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06534v1 Tipo de anuncio: nuevo\nResumen: Evaluar y asegurar la robustez frente a adversarios de los sistemas de conducción autónoma (AD) es un reto crítico y no resuelto. Este artículo presenta MetAdv, una novedosa plataforma de pruebas adversariales que permite una evaluación realista, dinámica e interactiva mediante la estrecha integración de la simulación virtual con la retroalimentación física del vehículo. En su núcleo, MetAdv establece una caja de arena híbrida virtual-física, dentro de la cual diseñamos un entorno de pruebas de bucle cerrado de tres capas con evolución dinámica de pruebas adversariales. Esta arquitectura facilita la evaluación de adversarios de extremo a extremo, desde la generación unificada de adversarios de alto nivel, pasando por la interacción basada en simulación de nivel medio, hasta la ejecución de bajo nivel en vehículos físicos. Además, MetAdv soporta un amplio espectro de tareas de EA, paradigmas algorítmicos (por ejemplo, tuberías modulares de aprendizaje profundo, aprendizaje de extremo a extremo, modelos de visión-lenguaje). Admite el modelado flexible de vehículos en 3D y transiciones fluidas entre entornos simulados y físicos, con compatibilidad integrada para plataformas comerciales como Apollo y Tesla. Una característica clave de MetAdv es su capacidad humana: además de la configuración flexible del entorno para una evaluación más personalizada, permite la captura en tiempo real de señales fisiológicas y comentarios sobre el comportamiento de los conductores, ofreciendo nuevas perspectivas sobre la confianza hombre-máquina en condiciones adversas. Creemos que MetAdv puede ofrecer un marco escalable y unificado para la evaluación de adversarios, allanando el camino hacia una AD más segura.",
    "source": "arXiv"
  },
  {
    "title": "Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification",
    "title_es": "Aprendizaje por transferencia con EfficientNet para una clasificación precisa de células leucémicas",
    "url": "https://arxiv.org/abs/2508.06535",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06535v1 Tipo de anuncio: nuevo\nResumen: La clasificación precisa de la leucemia linfoblástica aguda (LLA) a partir de imágenes de frotis de sangre periférica es esencial para el diagnóstico precoz y la planificación eficaz del tratamiento. Este estudio investiga el uso del aprendizaje por transferencia con redes neuronales convolucionales (CNN) preentrenadas para mejorar el rendimiento del diagnóstico. Para abordar el desequilibrio de clases en el conjunto de datos de 3.631 imágenes hematológicas y 7.644 imágenes de LLA, aplicamos amplias técnicas de aumento de datos para crear un conjunto de entrenamiento equilibrado de 10.000 imágenes por clase. Se evaluaron varios modelos, entre ellos ResNet50, ResNet101 y las variantes B0, B1 y B3 de EfficientNet. EfficientNet-B3 obtuvo los mejores resultados, con una puntuación F1 del 94,30%, una precisión del 92,02% y un AUC del 94,79%, superando a los métodos anteriores en el reto C-NMCC. Estos resultados demuestran la eficacia de combinar el aumento de datos con modelos avanzados de aprendizaje por transferencia, en particular EfficientNet-B3, en el desarrollo de herramientas de diagnóstico precisas y sólidas para la detección de neoplasias hematológicas.",
    "source": "arXiv"
  },
  {
    "title": "Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset",
    "title_es": "Evaluación comparativa de modelos de detección de objetos basados en aprendizaje profundo en un conjunto de datos de imágenes de astrofotografía con características deficientes",
    "url": "https://arxiv.org/abs/2508.06537",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06537v1 Tipo de anuncio: nuevo\nResumen: Los modelos de detección de objetos suelen entrenarse en conjuntos de datos como ImageNet, COCO y PASCAL VOC, que se centran en objetos cotidianos. Sin embargo, éstos carecen de la dispersión de señal que se encuentra en dominios no comerciales. MobilTelesco, un conjunto de datos de astrofotografía basado en teléfonos inteligentes, aborda este problema proporcionando imágenes dispersas del cielo nocturno. Comparamos con él varios modelos de detección y destacamos los retos que plantea en condiciones de escasez de características.",
    "source": "arXiv"
  },
  {
    "title": "Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots",
    "title_es": "Aprendizaje simbólico de modelos interpretables de orden reducido para robots cuadrúpedos que saltan",
    "url": "https://arxiv.org/abs/2508.06538",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06538v1 Tipo de anuncio: nuevo\nResumen: Los modelos de orden reducido son esenciales para la planificación del movimiento y el control de robots cuadrúpedos, ya que simplifican dinámicas complejas a la vez que preservan comportamientos críticos. Este trabajo presenta una metodología novedosa para derivar tales modelos dinámicos interpretables, específicamente para el salto. Capturamos la dinámica de salto no lineal de alta dimensión en un espacio latente de baja dimensión proponiendo una arquitectura de aprendizaje que combina la Identificación Esparcida de Dinámica No Lineal (SINDy) con priores estructurales físicos sobre la dinámica de salto. Nuestro enfoque demuestra una precisión superior al modelo tradicional de péndulo invertido accionado por resorte (aSLIP) y se valida mediante experimentos de simulación y hardware con diferentes estrategias de salto.",
    "source": "arXiv"
  },
  {
    "title": "Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems",
    "title_es": "Múltiples de supervivencia autoorganizadas: Una teoría para el descubrimiento no supervisado de estructuras de pronóstico en sistemas biológicos",
    "url": "https://arxiv.org/abs/2508.06539",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06539v1 Tipo de anuncio: nuevo\nResumen: La supervivencia se modela tradicionalmente como una tarea de aprendizaje supervisado, que depende de etiquetas de resultados curadas y covariables fijas. Este trabajo rechaza esa premisa. Propone que la supervivencia no es un objetivo anotado externamente, sino una consecuencia geométrica: una propiedad emergente de la curvatura y el flujo inherentes al espacio de estado biológico. Desarrollamos una teoría de Manifolds de Supervivencia Auto-Organizados (SOSM), en la que las dinámicas relevantes para la supervivencia surgen de flujos geodésicos de baja curvatura en manifolds latentes conformados por restricciones biológicas internas. Se introduce un funcional de energía de supervivencia basado en la minimización de la curvatura geodésica y se demuestra que induce estructuras en las que el pronóstico se alinea con la estabilidad del flujo geométrico. Derivamos formulaciones discretas y continuas del objetivo y probamos resultados teóricos que demuestran la aparición y convergencia de trayectorias alineadas con la supervivencia en condiciones biológicamente plausibles. El marco establece conexiones con la eficiencia termodinámica, el flujo de entropía, la curvatura de Ricci y el transporte óptimo, fundamentando la modelización de la supervivencia en la ley física. La salud, la enfermedad, el envejecimiento y la muerte se reformulan como transiciones geométricas de fase en la estructura del múltiple. Esta teoría ofrece una base universal, libre de etiquetas, para modelar la supervivencia como una propiedad de la forma, no de la anotación, tendiendo un puente entre el aprendizaje automático, la biofísica y la propia geometría de la vida.",
    "source": "arXiv"
  },
  {
    "title": "AMP-based Joint Activity Detection and Channel Estimation for Massive Grant-Free Access in OFDM-based Wideband Systems",
    "title_es": "Detección conjunta de actividad y estimación de canal basadas en AMP para acceso masivo libre de subvenciones en sistemas de banda ancha basados en OFDM",
    "url": "https://arxiv.org/abs/2508.06540",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06540v1 Tipo de anuncio: nuevo\nResumen: Para realizar el acceso libre de concesión basado en multiplexación por división ortogonal de frecuencias (OFDM) para sistemas de banda ancha bajo desvanecimiento selectivo en frecuencia, los métodos existentes de detección de actividad de dispositivos y estimación de canal necesitan una mejora sustancial de la precisión o una reducción del tiempo de cálculo. En este artículo pretendemos resolver este problema. En primer lugar, presentamos un modelo exacto de señal en el dominio del tiempo para el acceso libre basado en OFDM bajo desvanecimiento selectivo en frecuencia. A continuación, presentamos un problema de detección de actividad de dispositivos basado en el máximo a posteriori (MAP) y dos problemas de estimación de canal basados en el mínimo error cuadrático medio (MMSE). El problema de detección de actividad de dispositivos basado en MAP y uno de los problemas de estimación de canal basado en MMSE se formulan por primera vez. A continuación, construimos un nuevo grafo factorial que captura las estadísticas exactas de los canales en el dominio del tiempo y las actividades de los dispositivos. Basándonos en él, proponemos dos algoritmos basados en el paso aproximado de mensajes (AMP), AMP-A-EC y AMP-A-AC, para resolver aproximadamente el problema de detección de actividad de dispositivos basado en MAP y dos problemas de estimación de canal basados en MMSE. Los dos algoritmos propuestos alivian el problema de convergencia inherente al AMP cuando la longitud del piloto es menor o comparable al número de dispositivos activos. A continuación, analizamos la probabilidad de error de AMP-A-EC de la detección de actividad y el error cuadrático medio (MSE) de la estimación de canal mediante evolución de estado y demostramos que AMP-A-AC tiene la menor complejidad computacional (en término dominante). Por último, los resultados numéricos muestran el rendimiento superior de los dos algoritmos basados en AMP propuestos y sus respectivas regiones preferentes, revelando sus valores significativos para el acceso sin subvención basado en OFDM.",
    "source": "arXiv"
  },
  {
    "title": "MILD: Multi-Layer Diffusion Strategy for Complex and Precise Multi-IP Aware Human Erasing",
    "title_es": "MILD: estrategia de difusión multicapa para el borrado humano complejo y preciso con conciencia multiIP",
    "url": "https://arxiv.org/abs/2508.06543",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06543v1 Tipo de anuncio: nuevo\nResumen: Los últimos años han sido testigos del éxito de los modelos de difusión en tareas de personalización de imágenes. Los trabajos anteriores han logrado avances notables en el borrado orientado al ser humano mediante la guía explícita de máscaras y el inpainting consciente de la semántica. Sin embargo, se enfrentan a complejos escenarios multiIP que implican oclusiones humano-humano, enredos humano-objeto e interferencias de fondo. Estos problemas se deben principalmente a 1) Limitaciones del conjunto de datos, ya que los conjuntos de datos existentes rara vez cubren oclusiones densas, fondos camuflados e interacciones diversas; 2) Falta de desacoplamiento espacial, donde las instancias de primer plano no se pueden desentrañar de manera efectiva, lo que limita la restauración limpia del fondo. En este trabajo, presentamos un conjunto de datos de borrado humano multiIP de alta calidad con diversas variaciones de pose y fondos complejos. A continuación, proponemos la difusión multicapa (MILD), una novedosa estrategia que descompone la generación en rutas separadas semánticamente para cada instancia y el fondo. Para mejorar la comprensión centrada en el ser humano, introducimos Human Morphology Guidance, que integra la pose, el análisis sintáctico y las relaciones espaciales. Además, presentamos la Atención Espacialmente Modulada para guiar mejor el flujo de atención. Extensos experimentos demuestran que MILD supera a los métodos más avanzados en las exigentes pruebas de borrado humano.",
    "source": "arXiv"
  },
  {
    "title": "Historical Prediction Attention Mechanism based Trajectory Forecasting for Proactive Work Zone Safety in a Digital Twin Environment",
    "title_es": "Mecanismo de atención a la predicción histórica basado en la previsión de trayectorias para la seguridad proactiva de zonas de trabajo en un entorno de gemelos digitales",
    "url": "https://arxiv.org/abs/2508.06544",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06544v1 Tipo de anuncio: nuevo\nResumen: Los sistemas de seguridad proactivos tienen como objetivo mitigar los riesgos mediante la anticipación de posibles conflictos entre vehículos y permitir la intervención temprana para evitar accidentes relacionados con las zonas de trabajo. Este estudio presenta un sistema proactivo de alerta de seguridad en zonas de trabajo habilitado para infraestructuras que aprovecha un entorno Digital Twin, integrando datos multisensor en tiempo real, mapas detallados de alta definición (HD) y un modelo de predicción de trayectoria basado en mecanismos de atención a la predicción histórica. Utilizando un entorno de co-simulación que combina los simuladores Simulation of Urban MObility (SUMO) y CAR Learning to Act (CARLA), junto con los mapas HD de Lanelet2 y el modelo Historical Prediction Network (HPNet), demostramos la eficacia de la predicción de trayectorias y la generación de alertas tempranas para interacciones de vehículos en zonas de obras de autopistas. Para evaluar la precisión de las trayectorias predichas, utilizamos dos métricas estándar: Error de Desplazamiento Medio Conjunto (ADE) y Error de Desplazamiento Final Conjunto (FDE). En concreto, el modelo HPNet habilitado para infraestructuras demuestra un rendimiento superior en los conjuntos de datos de zonas de trabajo generados a partir del entorno de simulación conjunta, alcanzando un FDE conjunto mínimo de 0,3228 metros y un ADE conjunto mínimo de 0,1327 metros, inferiores a los valores de referencia de los conjuntos de datos Argoverse (minJointFDE: 1,0986 m, minJointADE: 0,7612 m) e Interaction (minJointFDE: 0,8231 m, minJointADE: 0,2548 m). Además, nuestra aplicación proactiva de generación de alertas de seguridad, que utiliza recuadros delimitadores de vehículos y modelado probabilístico de conflictos, demuestra su capacidad para emitir alertas de posibles conflictos entre vehículos.",
    "source": "arXiv"
  },
  {
    "title": "Statistical Confidence Rescoring for Robust 3D Scene Graph Generation from Multi-View Images",
    "title_es": "Rescate estadístico de la confianza para la generación robusta de gráficos de escenas 3D a partir de imágenes multivista",
    "url": "https://arxiv.org/abs/2508.06546",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06546v1 Tipo de anuncio: nuevo\nResumen: Los métodos modernos de estimación de grafos semánticos 3D utilizan anotaciones 3D para predecir con precisión objetos, predicados y relaciones. En ausencia de representaciones 3D reales, exploramos el uso de imágenes RGB multivista para abordar esta tarea. A fin de obtener características robustas para una estimación precisa del grafo de la escena, debemos superar la ruidosa geometría reconstruida basada en pseudopuntos a partir de mapas de profundidad predichos y reducir la cantidad de ruido de fondo presente en las características de las imágenes multivista. La clave está en enriquecer las características de nodos y bordes con información semántica y espacial precisa y mediante relaciones de vecindad. Obtenemos máscaras semánticas para guiar la agregación de características con el fin de filtrar las características de fondo y diseñamos un método novedoso para incorporar información de nodos vecinos para ayudar a la robustez de nuestras estimaciones de gráficos de escena. Además, aprovechamos las priores estadísticas explícitas calculadas a partir de las estadísticas resumidas de entrenamiento para refinar las predicciones de nodos y bordes basándonos en su vecindad de un salto. Nuestros experimentos demuestran que nuestro método supera a los métodos actuales que utilizan únicamente imágenes multivista como entrada inicial. La página de nuestro proyecto está disponible en https://qixun1.github.io/projects/SCRSSG.",
    "source": "arXiv"
  },
  {
    "title": "A tutorial note on collecting simulated data for vision-language-action models",
    "title_es": "Nota tutorial sobre la recopilación de datos simulados para modelos de visión-lenguaje-acción",
    "url": "https://arxiv.org/abs/2508.06547",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06547v1 Tipo de anuncio: nuevo\nResumen: Los sistemas robóticos tradicionales suelen descomponer la inteligencia en módulos independientes para la visión por ordenador, el procesamiento del lenguaje natural y el control del movimiento. Los modelos Visión-Lenguaje-Acción (VLA) transforman fundamentalmente este enfoque al emplear una única red neuronal que puede procesar simultáneamente observaciones visuales, comprender instrucciones humanas y emitir directamente acciones robóticas, todo ello dentro de un marco unificado. Sin embargo, estos sistemas dependen en gran medida de conjuntos de datos de entrenamiento de alta calidad que puedan captar las complejas relaciones entre las observaciones visuales, las instrucciones lingüísticas y las acciones robóticas. Este tutorial revisa tres sistemas representativos: el marco de simulación PyBullet para la generación flexible de datos personalizados, el conjunto de referencia LIBERO para la definición y evaluación de tareas estandarizadas, y la colección de conjuntos de datos RT-X para la adquisición de datos a gran escala de múltiples robots. Demostramos los enfoques de generación de conjuntos de datos en la simulación PyBullet y la recopilación de datos personalizados dentro de LIBERO, y proporcionamos una visión general de las características y funciones del conjunto de datos RT-X para la adquisición de datos multi-robot a gran escala.",
    "source": "arXiv"
  },
  {
    "title": "Factor Augmented Supervised Learning with Text Embeddings",
    "title_es": "Aprendizaje supervisado aumentado por factores con incrustación de texto",
    "url": "https://arxiv.org/abs/2508.06548",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06548v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos lingüísticos (LLM) generan embebimientos de texto a partir de datos textuales, produciendo representaciones vectoriales que capturan el significado semántico y las relaciones contextuales de las palabras. Sin embargo, la alta dimensionalidad de estas incrustaciones a menudo impide la eficiencia y aumenta el coste computacional en tareas posteriores. Para solucionar este problema, proponemos el Aprendizaje AutoEncodificador-Aumentado con Texto (AEALT), un marco supervisado y aumentado por factores que incorpora la reducción de dimensiones directamente en los flujos de trabajo LLM preentrenados. En primer lugar, extraemos las incrustaciones de los documentos de texto; a continuación, las pasamos por un autocodificador aumentado supervisado para aprender factores latentes de baja dimensión y relevantes para la tarea. Al modelar la estructura no lineal de las incrustaciones complejas, AEALT supera los enfoques convencionales de aprendizaje profundo que se basan en incrustaciones sin procesar. Validamos su amplia aplicabilidad con extensos experimentos en tareas de clasificación, detección de anomalías y predicción utilizando múltiples conjuntos de datos públicos del mundo real. Los resultados numéricos demuestran que AEALT ofrece ganancias sustanciales tanto sobre las incrustaciones de vainilla como sobre varios métodos estándar de reducción de dimensión.",
    "source": "arXiv"
  },
  {
    "title": "Generative Bid Shading in Real-Time Bidding Advertising",
    "title_es": "Sombreado generativo de ofertas en la publicidad de pujas en tiempo real",
    "url": "https://arxiv.org/abs/2508.06550",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06550v1 Tipo de anuncio: nuevo\nResumen: El sombreado de ofertas desempeña un papel crucial en las pujas en tiempo real (RTB), ya que ajusta de forma adaptativa la oferta para evitar que los anunciantes gasten más de la cuenta. Los métodos convencionales de dos etapas, que primero modelan el panorama de las pujas y luego optimizan el excedente utilizando técnicas de investigación operativa, se ven limitados por supuestos unimodales que no se adaptan a curvas de excedente no convexas y son vulnerables a errores en cascada en flujos de trabajo secuenciales. Además, los actuales modelos de discretización de valores continuos ignoran la dependencia entre intervalos discretos, lo que reduce la capacidad de corrección de errores del modelo, mientras que el sesgo de selección de muestras en los escenarios de licitación plantea nuevos retos para la predicción. Para resolver estos problemas, este artículo presenta el modelo Generative Bid Shading~(GBS), que consta de dos componentes principales: (1) un modelo generativo de extremo a extremo que utiliza un enfoque autorregresivo para generar ratios de sombreado mediante residuos escalonados, capturando complejas dependencias de valor sin depender de priores predefinidos; y (2) un sistema de alineación de preferencias de recompensa, que incorpora una red dinámica jerárquica con conciencia de canal~(CHNet) como modelo de recompensa para extraer características de grano fino, junto con módulos para la optimización de excedentes y la alineación de recompensas de utilidad de exploración, optimizando en última instancia los excedentes a corto y largo plazo mediante la optimización de políticas relativas de grupo~(GRPO). Experimentos exhaustivos en pruebas A/B tanto offline como online validan la eficacia de GBS. Además, GBS se ha desplegado en la plataforma DSP de Meituan, que atiende miles de millones de solicitudes de pujas al día.",
    "source": "arXiv"
  },
  {
    "title": "Slice or the Whole Pie? Utility Control for AI Models",
    "title_es": "¿Rebanada o todo el pastel? Control de la utilidad de los modelos de IA",
    "url": "https://arxiv.org/abs/2508.06551",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06551v1 Tipo de anuncio: nuevo\nResumen: El entrenamiento de redes neuronales profundas (DNNs) se ha convertido en una tarea cada vez más intensiva en recursos, que requiere grandes volúmenes de datos etiquetados, potencia computacional sustancial, y considerables esfuerzos de ajuste para lograr un rendimiento óptimo en diversos casos de uso. Aunque los modelos preentrenados ofrecen un punto de partida útil, adaptarlos a las necesidades específicas del usuario suele exigir una gran personalización y una sobrecarga de la infraestructura. Este reto aumenta cuando un único modelo debe ser compatible con diversas aplicaciones con distintos requisitos de rendimiento. Las soluciones tradicionales suelen implicar la formación de múltiples versiones del modelo para satisfacer distintos requisitos, lo que puede resultar ineficaz y difícil de mantener. Para superar este reto, proponemos NNObfuscator, un novedoso mecanismo de control de utilidades que permite a los modelos de IA modificar dinámicamente su rendimiento en función de condiciones predefinidas. Es distinto de los métodos tradicionales, que necesitan modelos distintos para cada usuario. En su lugar, NNObfuscator permite adaptar un único modelo en tiempo real, dándole acceso controlado a múltiples niveles de rendimiento. Este mecanismo permite a los propietarios de los modelos establecer un acceso escalonado, garantizando que los usuarios de nivel gratuito reciban un nivel básico de rendimiento, mientras que los usuarios premium se benefician de capacidades mejoradas. Este enfoque mejora la asignación de recursos, reduce los cálculos innecesarios y favorece modelos de negocio sostenibles en el despliegue de la IA. Para validar nuestro enfoque, llevamos a cabo experimentos en múltiples tareas, incluyendo la clasificación de imágenes, la segmentación semántica y la generación de texto a imagen, utilizando modelos bien establecidos como ResNet, DeepLab, VGG16, FCN y Stable Diffusion. Los resultados experimentales muestran que NNObfuscator consigue que el modelo sea más adaptable, de modo que un único modelo entrenado puede manejar una amplia gama de tareas sin necesidad de realizar muchos cambios.",
    "source": "arXiv"
  },
  {
    "title": "Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection",
    "title_es": "Conjunto de datos de Deepfake con diversidad de edades: Reducción de la brecha de edad en la detección de deepfakes",
    "url": "https://arxiv.org/abs/2508.06552",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06552v1 Tipo de anuncio: nuevo\nResumen: Los retos asociados a la detección de deepfakes están aumentando significativamente con los últimos avances en tecnología y la creciente popularidad de los vídeos e imágenes de deepfakes. A pesar de la presencia de numerosos modelos de detección, el sesgo demográfico en el conjunto de datos deepfake sigue siendo en gran medida sin abordar. Este artículo se centra en la mitigación del sesgo específico de la edad en el conjunto de datos de deepfake mediante la introducción de un conjunto de datos de deepfake de edad diversa que mejorará la equidad entre los grupos de edad. El conjunto de datos se construye a través de un proceso modular que incorpora los conjuntos de datos de deepfake existentes Celeb-DF, FaceForensics++ y UTKFace, y la creación de datos sintéticos para llenar los vacíos de distribución de edad. La eficacia y la generalizabilidad de este conjunto de datos se evalúan utilizando tres modelos de detección de deepfake: XceptionNet, EfficientNet y LipForensics. Las métricas de evaluación, que incluyen AUC, pAUC y EER, revelaron que los modelos entrenados en el conjunto de datos de diversidad de edades demostraron un rendimiento más justo en todos los grupos de edad, una precisión general mejorada y una mayor generalización en todos los conjuntos de datos. Este estudio aporta un conjunto de datos de deepfake reproducible y sensible a la imparcialidad y un modelo de canalización que puede servir de base para futuras investigaciones en la detección de deepfake más imparcial. El conjunto de datos completo y el código de implementación están disponibles en https://github.com/unishajoshi/age-diverse-deepfake-detection.",
    "source": "arXiv"
  },
  {
    "title": "Static and Plugged: Make Embodied Evaluation Simple",
    "title_es": "Estática y Enchufada: Simplificar la evaluación incorporada",
    "url": "https://arxiv.org/abs/2508.06553",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06553v1 Tipo de anuncio: nuevo\nResumen: La inteligencia incorporada está avanzando rápidamente, lo que impulsa la necesidad de una evaluación eficiente. Las pruebas actuales suelen basarse en entornos simulados interactivos o en configuraciones del mundo real, que son costosas, fragmentadas y difíciles de escalar. Para hacer frente a esta situación, presentamos StaticEmbodiedBench, una prueba de rendimiento plug-and-play que permite la evaluación unificada mediante representaciones estáticas de escenas. Abarca 42 escenarios distintos y 8 dimensiones básicas, y permite una evaluación escalable y exhaustiva a través de una interfaz sencilla. Además, evaluamos 19 modelos de visión-lenguaje (VLM) y 11 modelos de visión-lenguaje-acción (VLA), estableciendo la primera clasificación estática unificada para la inteligencia incorporada. Además, publicamos un subconjunto de 200 muestras de nuestro benchmark para acelerar el desarrollo de la inteligencia incorporada.",
    "source": "arXiv"
  },
  {
    "title": "AquaChat++: LLM-Assisted Multi-ROV Inspection for Aquaculture Net Pens with Integrated Battery Management and Thruster Fault Tolerance",
    "title_es": "AquaChat++: Inspección multiROV asistida por LLM para corrales de acuicultura con gestión integrada de baterías y tolerancia a fallos del propulsor",
    "url": "https://arxiv.org/abs/2508.06554",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06554v1 Tipo de anuncio: nuevo\nResumen: La inspección de los corrales de redes de acuicultura es esencial para garantizar la integridad estructural y el funcionamiento sostenible de los sistemas de piscicultura en alta mar. Los métodos tradicionales, que suelen basarse en sistemas operados manualmente o con un solo ROV, ofrecen una adaptabilidad limitada a las restricciones en tiempo real, como el consumo de energía, los fallos de hardware y las condiciones dinámicas bajo el agua. En este artículo se presenta AquaChat++, un novedoso marco de inspección multi-ROV que utiliza modelos de lenguaje amplio (LLM) para permitir la planificación adaptativa de misiones, la ejecución coordinada de tareas y el control tolerante a fallos en entornos acuícolas complejos. El sistema propuesto consta de una arquitectura de dos capas. La capa de generación de planes de alto nivel emplea un LLM, como ChatGPT-4, para traducir comandos de usuario de lenguaje natural en planes de inspección simbólicos y multiagente. Un gestor de tareas asigna y programa dinámicamente las acciones entre los ROV en función de su estado en tiempo real y de las restricciones operativas, incluidos los fallos de los propulsores y los niveles de batería. La capa de control de bajo nivel garantiza un seguimiento preciso de la trayectoria e integra mecanismos de detección y compensación de fallos en los propulsores. Al incorporar retroalimentación en tiempo real y replanificación activada por eventos, AquaChat++ mejora la robustez del sistema y la eficiencia operativa. Los experimentos simulados en un entorno de acuicultura basado en la física demuestran una cobertura de inspección mejorada, un comportamiento eficiente desde el punto de vista energético y resistencia a los fallos de los actuadores. Estos resultados ponen de relieve el potencial de los marcos basados en LLM para respaldar operaciones robóticas submarinas escalables, inteligentes y autónomas dentro del sector de la acuicultura.",
    "source": "arXiv"
  },
  {
    "title": "StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback",
    "title_es": "StyleTailor: Hacia un estilismo de moda personalizado mediante retroalimentación jerárquica negativa",
    "url": "https://arxiv.org/abs/2508.06555",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06555v1 Tipo de anuncio: nuevo\nResumen: El avance de los agentes inteligentes ha revolucionado la resolución de problemas en diversos ámbitos, sin embargo, las soluciones para el estilismo de moda personalizado siguen siendo poco exploradas, lo que supone una inmensa promesa para la promoción de experiencias de compra. En este trabajo, presentamos StyleTailor, el primer marco de agentes colaborativos que unifica a la perfección el diseño personalizado de ropa, la recomendación de compras, la prueba virtual y la evaluación sistemática en un flujo de trabajo cohesivo. Con este fin, StyleTailor es pionero en un paradigma de refinamiento visual iterativo impulsado por la retroalimentación negativa multinivel, lo que permite una alineación adaptable y precisa del usuario. En concreto, nuestro marco cuenta con dos agentes principales, a saber, el diseñador para la selección personalizada de prendas y el consultor para la prueba virtual, cuyos resultados se perfeccionan progresivamente mediante una retroalimentación jerárquica del modelo de visión y lenguaje que abarca artículos individuales, conjuntos completos y la eficacia de la prueba. Los contraejemplos se agregan a los avisos negativos, formando un mecanismo de bucle cerrado que mejora la calidad de la recomendación. Para evaluar el rendimiento, introducimos un completo conjunto de evaluaciones que abarcan la coherencia del estilo, la calidad visual, la similitud facial y la valoración artística. Extensos experimentos demuestran que StyleTailor ofrece un rendimiento superior en la entrega de diseños y recomendaciones personalizados, superando a fuertes líneas de base sin retroalimentación negativa y estableciendo un nuevo punto de referencia para los sistemas inteligentes de moda.",
    "source": "arXiv"
  },
  {
    "title": "From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets",
    "title_es": "De la detección de errores de etiqueta a la corrección: Un marco modular y un punto de referencia para conjuntos de datos de detección de objetos",
    "url": "https://arxiv.org/abs/2508.06556",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06556v1 Tipo de anuncio: nuevo\nResumen: La detección de objetos ha avanzado rápidamente en los últimos años, impulsada por conjuntos de datos cada vez más grandes y diversos. Sin embargo, los errores de etiqueta, definidos como etiquetas que faltan, clasificación incorrecta o localización imprecisa, a menudo comprometen la calidad de estos conjuntos de datos. Esto puede tener un impacto significativo en los resultados del entrenamiento y las evaluaciones comparativas. Aunque en la actualidad existen varios métodos para detectar errores de etiquetado en los conjuntos de datos de detección de objetos, normalmente sólo se validan con puntos de referencia sintéticos o con una inspección manual limitada. Por lo tanto, la forma de corregir estos errores de forma sistemática y a gran escala sigue siendo un problema pendiente. Presentamos un marco semiautomatizado para la corrección de errores de etiquetado denominado REC$\\checkmark$D (Rechecked). Partiendo de detectores ya existentes, el marco combina sus propuestas de error con microtareas ligeras y financiadas por la comunidad. Estas tareas permiten a varios anotadores verificar de forma independiente cada cuadro delimitador candidato, y sus respuestas se agregan para estimar la ambigüedad y mejorar la calidad de las etiquetas. Para demostrar la eficacia de REC$\\checkmark$D, lo aplicamos a la clase peatonal del conjunto de datos KITTI. Nuestra revisión por crowdsourcing produce anotaciones corregidas de alta calidad, que indican una tasa de al menos el 24% de anotaciones inexactas o ausentes en las anotaciones originales. Este conjunto validado se publicará como una nueva referencia en el mundo real para la detección y corrección de errores de etiquetas. Demostramos que los métodos actuales de detección de errores de etiquetas, combinados con nuestro marco de corrección, pueden recuperar cientos de errores en el tiempo que tardaría una persona en anotar los recuadros delimitadores desde cero. Sin embargo, incluso los mejores métodos pasan por alto hasta el 66% de los errores reales y, con etiquetas de baja calidad, introducen más errores de los que detectan. Esto pone de manifiesto la urgente necesidad de seguir investigando, lo que ahora es posible gracias a nuestro sistema de referencia\".",
    "source": "arXiv"
  },
  {
    "title": "Communication-Learning Co-Design for Differentially Private Over-the-Air Federated Distillation",
    "title_es": "Co-diseño de comunicación-aprendizaje para destilación federada en el aire diferencialmente privada",
    "url": "https://arxiv.org/abs/2508.06557",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06557v1 Tipo de anuncio: nuevo\nResumen: El tamaño cada vez mayor de los modelos de aprendizaje desafía hoy en día la eficiencia de la comunicación y la preservación de la privacidad del aprendizaje federado tradicional (FL). En este trabajo, proponemos un nuevo marco de destilación federada por aire diferencialmente privado (DP), en el que los dispositivos inalámbricos (WDs) comparten periódicamente salidas de modelos perturbados por ruido con el servidor de parámetros aprovechando la propiedad de superposición de los canales de acceso múltiple. En consecuencia, la FD por aire permite la responsabilidad compartida de la preservación de la AD en las señales reveladas de baja dimensión entre los WD. Estudiamos el problema del co-diseño de la comunicación-aprendizaje en la FD por aire diferencialmente privada, con el objetivo de maximizar la tasa de convergencia del aprendizaje a la vez que se cumplen los requisitos de potencia de transmisión y DP de los WDs. El principal reto radica en la dificultad del análisis del aprendizaje y la privacidad en la FD por aire, junto con el fuerte acoplamiento entre las variables de decisión que abarcan dos escalas temporales. Para abordar este problema, primero derivamos la tasa de convergencia analítica del aprendizaje y las pérdidas de privacidad de los WD, a partir de las cuales se obtienen en formas cerradas el diseño óptimo del transceptor por ronda de FD y la decisión de las rondas de entrenamiento a largo plazo. Los resultados numéricos demuestran que el enfoque de FD por aire diferencialmente privado propuesto logra un mejor equilibrio entre aprendizaje y privacidad con una sobrecarga de comunicación muy reducida que los puntos de referencia de FL convencionales.",
    "source": "arXiv"
  },
  {
    "title": "On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications",
    "title_es": "On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications",
    "url": "https://arxiv.org/abs/2508.06558",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06558v1 Announce Type: new \nAbstract: Deploying deep learning models in clinical practice often requires leveraging multiple data modalities, such as images, text, and structured data, to achieve robust and trustworthy decisions. However, not all modalities are always available at inference time. In this work, we propose multimodal privileged knowledge distillation (MMPKD), a training strategy that utilizes additional modalities available solely during training to guide a unimodal vision model. Specifically, we used a text-based teacher model for chest radiographs (MIMIC-CXR) and a tabular metadata-based teacher model for mammography (CBIS-DDSM) to distill knowledge into a vision transformer student model. We show that MMPKD can improve the resulting attention maps' zero-shot capabilities of localizing ROI in input images, while this effect does not generalize across domains, as contrarily suggested by prior research.",
    "source": "arXiv"
  },
  {
    "title": "Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization",
    "title_es": "Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization",
    "url": "https://arxiv.org/abs/2508.06559",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06559v1 Announce Type: new \nAbstract: Pasur is a fishing card game played over six rounds and is played similarly to games such as Cassino and Scopa, and Bastra. This paper introduces a CUDA-accelerated computational framework for simulating Pasur, emphasizing efficient memory management. We use our framework to compute near-Nash equilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm for solving large imperfect-information games.\n  Solving Pasur presents unique challenges due to its intricate rules and the large size of its game tree. We handle rule complexity using PyTorch CUDA tensors and to address the memory-intensive nature of the game, we decompose the game tree into two key components: (1) actual game states, and (2) inherited scores from previous rounds. We construct the Full Game Tree by pairing card states with accumulated scores in the Unfolding Process. This design reduces memory overhead by storing only essential strategy values and node connections. To further manage computational complexity, we apply a round-by-round backward training strategy, starting from the final round and recursively propagating average utilities to earlier stages. Our approach constructs the complete game tree, which on average consists of over $10^9$ nodes. We provide detailed implementation snippets.\n  After computing a near-Nash equilibrium strategy, we train a tree-based model to predict these strategies for use during gameplay. We then estimate the fair value of each deck through large-scale self-play between equilibrium strategies by simulating, for instance, 10,000 games per matchup, executed in parallel using GPU acceleration.\n  Similar frameworks can be extended to other reinforcement learning algorithms where the action tree naturally decomposes into multiple rounds such as turn-based strategy games or sequential trading decisions in financial markets.",
    "source": "arXiv"
  },
  {
    "title": "Algorithmic Delegated Choice: An Annotated Reading List",
    "title_es": "Algorithmic Delegated Choice: An Annotated Reading List",
    "url": "https://arxiv.org/abs/2508.06562",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06562v1 Announce Type: new \nAbstract: The problem of delegated choice has been of long interest in economics and recently on computer science. We overview a list of papers on delegated choice problem, from classic works to recent papers with algorithmic perspectives.",
    "source": "arXiv"
  },
  {
    "title": "Assessing Engineering Student Perceptions of Introductory CS Courses in an Indian Context",
    "title_es": "Assessing Engineering Student Perceptions of Introductory CS Courses in an Indian Context",
    "url": "https://arxiv.org/abs/2508.06563",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06563v1 Announce Type: new \nAbstract: Understanding student perceptions of assessment is vital for designing inclusive and effective learning environments, especially in technical education. This study explores engineering students' perceptions of assessment practices in an introductory computer science/ programming course, and its associated laboratory within an Indian engineering institute context. A total of 318 first-year Bachelor of Technology students participated in a weekly 25-statement Likert-scale survey conducted over nine weeks. Using descriptive statistics and non-parametric tests (Mann-Whitney U and Kruskal-Wallis), the analysis reveals that students largely perceive lab assignments as effective learning activities and view exams and projects as authentic and skill-enhancing. Students appreciated the role of instructors in shaping course content and found teaching assistants to be approachable and helpful, despite some inconsistencies. The study also finds significant variations in students' academic performance and assessment perceptions based on prior programming experience, technology familiarity, gender, and academic branch. Notably, the performance data did not follow a Gaussian distribution, challenging common assumptions in grade modeling. A comparative analysis with European cohorts highlights both universal patterns and contextual differences, offering valuable insights for designing inclusive and equitable assessment strategies in programming education.",
    "source": "arXiv"
  },
  {
    "title": "Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC",
    "title_es": "Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC",
    "url": "https://arxiv.org/abs/2508.06564",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06564v1 Announce Type: new \nAbstract: Multimodal Emotion Recognition in Conversations remains a challenging task due to the complex interplay of textual, acoustic and visual signals. While recent models have improved performance via advanced fusion strategies, they often lack psychologically meaningful priors to guide multimodal alignment. In this paper, we revisit the use of CLIP and propose a novel Visual Emotion Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics into the fusion and classification process. Distinct from prior work that primarily utilizes CLIP's textual encoder, our approach leverages its image encoder to construct emotion-specific visual anchors based on facial exemplars. These anchors guide unimodal and multimodal features toward a perceptually grounded and psychologically aligned representation space, drawing inspiration from cognitive theories (prototypical emotion categories and multisensory integration). A stochastic anchor sampling strategy further enhances robustness by balancing semantic stability and intra-class diversity. Integrated into a dual-branch architecture with self-distillation, our VEGA-augmented model achieves sota performance on IEMOCAP and MELD. Code is available at: https://github.com/dkollias/VEGA.",
    "source": "arXiv"
  },
  {
    "title": "Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis",
    "title_es": "Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis",
    "url": "https://arxiv.org/abs/2508.06565",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06565v1 Announce Type: new \nAbstract: Integrating brain imaging data with clinical reports offers a valuable opportunity to leverage complementary multimodal information for more effective and timely diagnosis in practical clinical settings. This approach has gained significant attention in brain disorder research, yet a key challenge remains: how to effectively link objective imaging data with subjective text-based reports, such as doctors' notes. In this work, we propose a novel framework that aligns brain connectomes with clinical reports in a shared cross-modal latent space at both the subject and connectome levels, thereby enhancing representation learning. The key innovation of our approach is that we treat brain subnetworks as tokens of imaging data, rather than raw image patches, to align with word tokens in clinical reports. This enables a more efficient identification of system-level associations between neuroimaging findings and clinical observations, which is critical since brain disorders often manifest as network-level abnormalities rather than isolated regional alterations. We applied our method to mild cognitive impairment (MCI) using the ADNI dataset. Our approach not only achieves state-of-the-art predictive performance but also identifies clinically meaningful connectome-text pairs, offering new insights into the early mechanisms of Alzheimer's disease and supporting the development of clinically useful multimodal biomarkers.",
    "source": "arXiv"
  },
  {
    "title": "Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features",
    "title_es": "Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features",
    "url": "https://arxiv.org/abs/2508.06566",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06566v1 Announce Type: new \nAbstract: Surface material recognition is a key component in robotic perception and physical interaction, particularly when leveraging both tactile and visual sensory inputs. In this work, we propose Surformer v1, a transformer-based architecture designed for surface classification using structured tactile features and PCA-reduced visual embeddings extracted via ResNet-50. The model integrates modality-specific encoders with cross-modal attention layers, enabling rich interactions between vision and touch. Currently, state-of-the-art deep learning models for vision tasks have achieved remarkable performance. With this in mind, our first set of experiments focused exclusively on tactile-only surface classification. Using feature engineering, we trained and evaluated multiple machine learning models, assessing their accuracy and inference time. We then implemented an encoder-only Transformer model tailored for tactile features. This model not only achieved the highest accuracy but also demonstrated significantly faster inference time compared to other evaluated models, highlighting its potential for real-time applications. To extend this investigation, we introduced a multimodal fusion setup by combining vision and tactile inputs. We trained both Surformer v1 (using structured features) and Multimodal CNN (using raw images) to examine the impact of feature-based versus image-based multimodal learning on classification accuracy and computational efficiency. The results showed that Surformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while the Multimodal CNN achieved slightly higher accuracy but required significantly more inference time. These findings suggest Surformer v1 offers a compelling balance between accuracy, efficiency, and computational cost for surface material recognition.",
    "source": "arXiv"
  },
  {
    "title": "Robust and Agile Quadrotor Flight via Adaptive Unwinding-Free Quaternion Sliding Mode Control",
    "title_es": "Robust and Agile Quadrotor Flight via Adaptive Unwinding-Free Quaternion Sliding Mode Control",
    "url": "https://arxiv.org/abs/2508.06568",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06568v1 Announce Type: new \nAbstract: This paper presents a new adaptive sliding mode control (SMC) framework for quadrotors that achieves robust and agile flight under tight computational constraints. The proposed controller addresses key limitations of prior SMC formulations, including (i) the slow convergence and almost-global stability of $\\mathrm{SO(3)}$-based methods, (ii) the oversimplification of rotational dynamics in Euler-based controllers, (iii) the unwinding phenomenon in quaternion-based formulations, and (iv) the gain overgrowth problem in adaptive SMC schemes. Leveraging nonsmooth stability analysis, we provide rigorous global stability proofs for both the nonsmooth attitude sliding dynamics defined on $\\mathbb{S}^3$ and the position sliding dynamics. Our controller is computationally efficient and runs reliably on a resource-constrained nano quadrotor, achieving 250 Hz and 500 Hz refresh rates for position and attitude control, respectively. In an extensive set of hardware experiments with over 130 flight trials, the proposed controller consistently outperforms three benchmark methods, demonstrating superior trajectory tracking accuracy and robustness with relatively low control effort. The controller enables aggressive maneuvers such as dynamic throw launches, flip maneuvers, and accelerations exceeding 3g, which is remarkable for a 32-gram nano quadrotor. These results highlight promising potential for real-world applications, particularly in scenarios requiring robust, high-performance flight control under significant external disturbances and tight computational constraints.",
    "source": "arXiv"
  },
  {
    "title": "Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop",
    "title_es": "Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop",
    "url": "https://arxiv.org/abs/2508.06569",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06569v1 Announce Type: new \nAbstract: The history of science is punctuated by serendipitous discoveries, where unexpected observations, rather than targeted hypotheses, opened new fields of inquiry. While modern autonomous laboratories excel at accelerating hypothesis testing, their optimization for efficiency risks overlooking these crucial, unplanned findings. To address this gap, we introduce SciLink, an open-source, multi-agent artificial intelligence framework designed to operationalize serendipity in materials research by creating a direct, automated link between experimental observation, novelty assessment, and theoretical simulations. The framework employs a hybrid AI strategy where specialized machine learning models perform quantitative analysis of experimental data, while large language models handle higher-level reasoning. These agents autonomously convert raw data from materials characterization techniques into falsifiable scientific claims, which are then quantitatively scored for novelty against the published literature. We demonstrate the framework's versatility across diverse research scenarios, showcasing its application to atomic-resolution and hyperspectral data, its capacity to integrate real-time human expert guidance, and its ability to close the research loop by proposing targeted follow-up experiments. By systematically analyzing all observations and contextualizing them, SciLink provides a practical framework for AI-driven materials research that not only enhances efficiency but also actively cultivates an environment ripe for serendipitous discoveries, thereby bridging the gap between automated experimentation and open-ended scientific exploration.",
    "source": "arXiv"
  },
  {
    "title": "ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos",
    "title_es": "ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos",
    "url": "https://arxiv.org/abs/2508.06570",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06570v1 Announce Type: new \nAbstract: The existing research has primarily focused on text and image-based hate speech detection, video-based approaches remain underexplored. In this work, we introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate speech detection in videos. ImpliHateVid consists of 2,009 videos comprising 509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos, making it one of the first large-scale video datasets dedicated to implicit hate detection. We also propose a novel two-stage contrastive learning framework for hate speech detection in videos. In the first stage, we train modality-specific encoders for audio, text, and image using contrastive loss by concatenating features from the three encoders. In the second stage, we train cross-encoders using contrastive learning to refine multimodal representations. Additionally, we incorporate sentiment, emotion, and caption-based features to enhance implicit hate detection. We evaluate our method on two datasets, ImpliHateVid for implicit hate speech detection and another dataset for general hate speech detection in videos, HateMM dataset, demonstrating the effectiveness of the proposed multimodal contrastive learning for hateful content detection in videos and the significance of our dataset.",
    "source": "arXiv"
  },
  {
    "title": "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model",
    "title_es": "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model",
    "url": "https://arxiv.org/abs/2508.06571",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06571v1 Announce Type: new \nAbstract: Vision-Language-Action (VLA) models have demonstrated potential in autonomous driving. However, two critical challenges hinder their development: (1) Existing VLA architectures are typically based on imitation learning in open-loop setup which tends to capture the recorded behaviors in the dataset, leading to suboptimal and constrained performance, (2) Close-loop training relies heavily on high-fidelity sensor simulation, where domain gaps and computational inefficiencies pose significant barriers. In this paper, we introduce IRL-VLA, a novel close-loop Reinforcement Learning via \\textbf{I}nverse \\textbf{R}einforcement \\textbf{L}earning reward world model with a self-built VLA approach. Our framework proceeds in a three-stage paradigm: In the first stage, we propose a VLA architecture and pretrain the VLA policy via imitation learning. In the second stage, we construct a lightweight reward world model via inverse reinforcement learning to enable efficient close-loop reward computation. To further enhance planning performance, finally, we design specialized reward world model guidence reinforcement learning via PPO(Proximal Policy Optimization) to effectively balance the safety incidents, comfortable driving, and traffic efficiency. Our approach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that our framework will accelerate VLA research in close-loop autonomous driving.",
    "source": "arXiv"
  },
  {
    "title": "Teaching Introduction to Programming in the times of AI: A case study of a course re-design",
    "title_es": "Teaching Introduction to Programming in the times of AI: A case study of a course re-design",
    "url": "https://arxiv.org/abs/2508.06572",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06572v1 Announce Type: new \nAbstract: The integration of AI tools into programming education has become increasingly prevalent in recent years, transforming the way programming is taught and learned. This paper provides a review of the state-of-the-art AI tools available for teaching and learning programming, particularly in the context of introductory courses. It highlights the challenges on course design, learning objectives, course delivery and formative and summative assessment, as well as the misuse of such tools by the students. We discuss ways of re-designing an existing course, re-shaping assignments and pedagogy to address the current AI technologies challenges. This example can serve as a guideline for policies for institutions and teachers involved in teaching programming, aiming to maximize the benefits of AI tools while addressing the associated challenges and concerns.",
    "source": "arXiv"
  },
  {
    "title": "Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering",
    "title_es": "Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering",
    "url": "https://arxiv.org/abs/2508.06574",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06574v1 Announce Type: new \nAbstract: Detecting fraud in modern supply chains is a growing challenge, driven by the complexity of global networks and the scarcity of labeled data. Traditional detection methods often struggle with class imbalance and limited supervision, reducing their effectiveness in real-world applications. This paper proposes a novel two-phase learning framework to address these challenges. In the first phase, the Isolation Forest algorithm performs unsupervised anomaly detection to identify potential fraud cases and reduce the volume of data requiring further analysis. In the second phase, a self-training Support Vector Machine (SVM) refines the predictions using both labeled and high-confidence pseudo-labeled samples, enabling robust semi-supervised learning. The proposed method is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive real-world supply chain dataset with fraud indicators. It achieves an F1-score of 0.817 while maintaining a false positive rate below 3.0%. These results demonstrate the effectiveness and efficiency of combining unsupervised pre-filtering with semi-supervised refinement for supply chain fraud detection under real-world constraints, though we acknowledge limitations regarding concept drift and the need for comparison with deep learning approaches.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Safety Testing of Autonomous Vehicles via Adaptive Search over Crash-Derived Scenarios",
    "title_es": "Efficient Safety Testing of Autonomous Vehicles via Adaptive Search over Crash-Derived Scenarios",
    "url": "https://arxiv.org/abs/2508.06575",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06575v1 Announce Type: new \nAbstract: Ensuring the safety of autonomous vehicles (AVs) is paramount in their development and deployment. Safety-critical scenarios pose more severe challenges, necessitating efficient testing methods to validate AVs safety. This study focuses on designing an accelerated testing algorithm for AVs in safety-critical scenarios, enabling swift recognition of their driving capabilities. First, typical logical scenarios were extracted from real-world crashes in the China In-depth Mobility Safety Study-Traffic Accident (CIMSS-TA) database, obtaining pre-crash features through reconstruction. Second, Baidu Apollo, an advanced black-box automated driving system (ADS) is integrated to control the behavior of the ego vehicle. Third, we proposed an adaptive large-variable neighborhood-simulated annealing algorithm (ALVNS-SA) to expedite the testing process. Experimental results demonstrate a significant enhancement in testing efficiency when utilizing ALVNS-SA. It achieves an 84.00% coverage of safety-critical scenarios, with crash scenario coverage of 96.83% and near-crash scenario coverage of 92.07%. Compared to genetic algorithm (GA), adaptive large neighborhood-simulated annealing algorithm (ALNS-SA), and random testing, ALVNS-SA exhibits substantially higher coverage in safety-critical scenarios.",
    "source": "arXiv"
  },
  {
    "title": "GFlowNets for Learning Better Drug-Drug Interaction Representations",
    "title_es": "GFlowNets for Learning Better Drug-Drug Interaction Representations",
    "url": "https://arxiv.org/abs/2508.06576",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06576v1 Announce Type: new \nAbstract: Drug-drug interactions pose a significant challenge in clinical pharmacology, with severe class imbalance among interaction types limiting the effectiveness of predictive models. Common interactions dominate datasets, while rare but critical interactions remain underrepresented, leading to poor model performance on infrequent cases. Existing methods often treat DDI prediction as a binary problem, ignoring class-specific nuances and exacerbating bias toward frequent interactions. To address this, we propose a framework combining Generative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE) to generate synthetic samples for rare classes, improving model balance and generate effective and novel DDI pairs. Our approach enhances predictive performance across interaction types, ensuring better clinical reliability.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging LLMs for Privacy-Aware Predictions in Participatory Budgeting",
    "title_es": "Leveraging LLMs for Privacy-Aware Predictions in Participatory Budgeting",
    "url": "https://arxiv.org/abs/2508.06577",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06577v1 Announce Type: new \nAbstract: Participatory Budgeting (PB) empowers citizens to propose and vote on public investment projects. Yet, despite its democratic potential, PB initiatives often suffer from low participation rates, limiting their visibility and perceived legitimacy. In this work, we aim to strengthen PB elections in two key ways: by supporting project proposers in crafting better proposals, and by helping PB organizers manage large volumes of submissions in a transparent manner. We propose a privacy-preserving approach to predict which PB proposals are likely to be funded, using only their textual descriptions and anonymous historical voting records -- without relying on voter demographics or personally identifiable information. We evaluate the performance of GPT 4 Turbo in forecasting proposal outcomes across varying contextual scenarios, observing that the LLM's prior knowledge needs to be complemented by past voting data to obtain predictions reflecting real-world PB voting behavior. Our findings highlight the potential of AI-driven tools to support PB processes by improving transparency, planning efficiency, and civic engagement.",
    "source": "arXiv"
  },
  {
    "title": "Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs",
    "title_es": "Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs",
    "url": "https://arxiv.org/abs/2508.06583",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06583v1 Announce Type: new \nAbstract: The conversational capabilities of large language models hold significant promise for enabling scalable and interactive tutoring. While prior research has primarily examined their capacity for Socratic questioning, it often overlooks a critical dimension: adaptively guiding learners based on their cognitive states. This study shifts focus from mere question generation to the broader instructional guidance capability. We ask: Can LLMs emulate expert tutors who dynamically adjust strategies in response to learners' understanding? To investigate this, we propose GuideEval, a benchmark grounded in authentic educational dialogues that evaluates pedagogical guidance through a three-phase behavioral framework: (1) Perception, inferring learner states; (2) Orchestration, adapting instructional strategies; and (3) Elicitation, stimulating proper reflections. Empirical findings reveal that existing LLMs frequently fail to provide effective adaptive scaffolding when learners exhibit confusion or require redirection. Furthermore, we introduce a behavior-guided finetuning strategy that leverages behavior-prompted instructional dialogues, significantly enhancing guidance performance. By shifting the focus from isolated content evaluation to learner-centered interaction, our work advocates a more dialogic paradigm for evaluating Socratic LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Omni Geometry Representation Learning vs Large Language Models for Geospatial Entity Resolution",
    "title_es": "Omni Geometry Representation Learning vs Large Language Models for Geospatial Entity Resolution",
    "url": "https://arxiv.org/abs/2508.06584",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06584v1 Announce Type: new \nAbstract: The development, integration, and maintenance of geospatial databases rely heavily on efficient and accurate matching procedures of Geospatial Entity Resolution (ER). While resolution of points-of-interest (POIs) has been widely addressed, resolution of entities with diverse geometries has been largely overlooked. This is partly due to the lack of a uniform technique for embedding heterogeneous geometries seamlessly into a neural network framework. Existing neural approaches simplify complex geometries to a single point, resulting in significant loss of spatial information. To address this limitation, we propose Omni, a geospatial ER model featuring an omni-geometry encoder. This encoder is capable of embedding point, line, polyline, polygon, and multi-polygon geometries, enabling the model to capture the complex geospatial intricacies of the places being compared. Furthermore, Omni leverages transformer-based pre-trained language models over individual textual attributes of place records in an Attribute Affinity mechanism. The model is rigorously tested on existing point-only datasets and a new diverse-geometry geospatial ER dataset. Omni produces up to 12% (F1) improvement over existing methods.\n  Furthermore, we test the potential of Large Language Models (LLMs) to conduct geospatial ER, experimenting with prompting strategies and learning scenarios, comparing the results of pre-trained language model-based methods with LLMs. Results indicate that LLMs show competitive results.",
    "source": "arXiv"
  },
  {
    "title": "CountQA: How Well Do MLLMs Count in the Wild?",
    "title_es": "CountQA: How Well Do MLLMs Count in the Wild?",
    "url": "https://arxiv.org/abs/2508.06585",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06585v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in understanding visual scenes, yet they exhibit a critical lack in a fundamental cognitive skill: object counting. This blind spot severely limits their reliability in real-world applications. To date, this capability has been largely unevaluated in complex scenarios, as existing benchmarks either feature sparse object densities or are confined to specific visual domains, failing to test models under realistic conditions. Addressing this gap, we introduce CountQA, a challenging new benchmark designed to probe this deficiency. Comprising over 1,500 question-answer pairs, CountQA features real-world images with high object density, clutter, and occlusion. We investigate this weakness by evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the top-performing model achieves a mere 42.9% accuracy, with performance declining as object counts rise. By providing a dedicated benchmark to diagnose and rectify this core weakness, CountQA paves the way for a new generation of MLLMs that are not only descriptively fluent but also numerically grounded and spatially aware. We will open-source the dataset and code upon paper acceptance to foster further research.",
    "source": "arXiv"
  },
  {
    "title": "Hypergraph Neural Network with State Space Models for Node Classification",
    "title_es": "Hypergraph Neural Network with State Space Models for Node Classification",
    "url": "https://arxiv.org/abs/2508.06587",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06587v1 Announce Type: new \nAbstract: In recent years, graph neural networks (GNNs) have gained significant attention for node classification tasks on graph-structured data. However, traditional GNNs primarily focus on adjacency relationships between nodes, often overlooking the rich role-based characteristics that are crucial for learning more expressive node representations. Existing methods for capturing role-based features are largely unsupervised and fail to achieve optimal performance in downstream tasks. To address these limitations, we propose a novel hypergraph neural network with state space model (HGMN) that effectively integrates role-aware representations into GNNs and the state space model. HGMN utilizes hypergraph construction techniques to model higher-order relationships and combines role-based and adjacency-based representations through a learnable mamba transformer mechanism. By leveraging two distinct hypergraph construction methods-based on node degree and neighborhood levels, it strengthens the connections among nodes with similar roles, enhancing the model's representational power. Additionally, the inclusion of hypergraph convolution layers enables the model to capture complex dependencies within hypergraph structures. To mitigate the over-smoothing problem inherent in deep GNNs, we incorporate a residual network, ensuring improved stability and better feature propagation across layers. Extensive experiments conducted on one newly introduced dataset and four benchmark datasets demonstrate the superiority of HGMN. The model achieves significant performance improvements on node classification tasks compared to state-of-the-art GNN methods. These results highlight HGMN's ability to provide enriched node representations by effectively embedding role-based features alongside adjacency information, making it a versatile and powerful tool for a variety of graph-based learning applications.",
    "source": "arXiv"
  },
  {
    "title": "Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning",
    "title_es": "Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning",
    "url": "https://arxiv.org/abs/2508.06588",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06588v1 Announce Type: new \nAbstract: Vector Quantization (VQ) has recently emerged as a promising approach for learning discrete representations of graph-structured data. However, a fundamental challenge, i.e., codebook collapse, remains underexplored in the graph domain, significantly limiting the expressiveness and generalization of graph tokens.In this paper, we present the first empirical study showing that codebook collapse consistently occurs when applying VQ to graph data, even with mitigation strategies proposed in vision or language domains. To understand why graph VQ is particularly vulnerable to collapse, we provide a theoretical analysis and identify two key factors: early assignment imbalances caused by redundancy in graph features and structural patterns, and self-reinforcing optimization loops in deterministic VQ. To address these issues, we propose RGVQ, a novel framework that integrates graph topology and feature similarity as explicit regularization signals to enhance codebook utilization and promote token diversity. RGVQ introduces soft assignments via Gumbel-Softmax reparameterization, ensuring that all codewords receive gradient updates. In addition, RGVQ incorporates a structure-aware contrastive regularization to penalize the token co-assignments among similar node pairs. Extensive experiments demonstrate that RGVQ substantially improves codebook utilization and consistently boosts the performance of state-of-the-art graph VQ backbones across multiple downstream tasks, enabling more expressive and transferable graph token representations.",
    "source": "arXiv"
  },
  {
    "title": "A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis",
    "title_es": "A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis",
    "url": "https://arxiv.org/abs/2508.06589",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06589v1 Announce Type: new \nAbstract: Computer-aided diagnosis (CAD) systems play a crucial role in analyzing neuroimaging data for neurological and psychiatric disorders. However, small-sample studies suffer from low reproducibility, while large-scale datasets introduce confounding heterogeneity due to multiple disease subtypes being labeled under a single category. To address these challenges, we propose a novel federated learning framework tailored for neuroimaging CAD systems. Our approach includes a dynamic navigation module that routes samples to the most suitable local models based on latent subtype representations, and a meta-integration module that combines predictions from heterogeneous local models into a unified diagnostic output. We evaluated our framework using a comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100 healthy controls across multiple study cohorts. Experimental results demonstrate significant improvements in diagnostic accuracy and robustness compared to traditional methods. Specifically, our framework achieved an average accuracy of 74.06\\% across all tested sites, showcasing its effectiveness in handling subtype heterogeneity and enhancing model generalizability. Ablation studies further confirmed the importance of both the dynamic navigation and meta-integration modules in improving performance. By addressing data heterogeneity and subtype confounding, our framework advances reliable and reproducible neuroimaging CAD systems, offering significant potential for personalized medicine and clinical decision-making in neurology and psychiatry.",
    "source": "arXiv"
  },
  {
    "title": "Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials",
    "title_es": "Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials",
    "url": "https://arxiv.org/abs/2508.06591",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06591v1 Announce Type: new \nAbstract: Large language models (LLMs) have reshaped the research landscape by enabling new approaches to knowledge retrieval and creative ideation. Yet their application in discipline-specific experimental science, particularly in highly multi-disciplinary domains like materials science, remains limited. We present a first-of-its-kind framework that integrates generative AI with literature from hitherto-unconnected fields such as plant science, biomimetics, and materials engineering to extract insights and design experiments for materials. We focus on humidity-responsive systems such as pollen-based materials and Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and adaptive performance. Using a suite of AI tools, including a fine-tuned model (BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a Hierarchical Sampling strategy, we extract structure-property relationships and translate them into new classes of bioinspired materials. Structured inference protocols generate and evaluate hundreds of hypotheses from a single query, surfacing novel and experimentally tractable ideas. We validate our approach through real-world implementation: LLM-generated procedures, materials designs, and mechanical predictions were tested in the laboratory, culminating in the fabrication of a novel pollen-based adhesive with tunable morphology and measured shear strength, establishing a foundation for future plant-derived adhesive design. This work demonstrates how AI-assisted ideation can drive real-world materials design and enable effective human-AI collaboration.",
    "source": "arXiv"
  },
  {
    "title": "Towards Integrated Alignment",
    "title_es": "Towards Integrated Alignment",
    "url": "https://arxiv.org/abs/2508.06592",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06592v1 Announce Type: new \nAbstract: As AI adoption expands across human society, the problem of aligning AI models to match human preferences remains a grand challenge. Currently, the AI alignment field is deeply divided between behavioral and representational approaches, resulting in narrowly aligned models that are more vulnerable to increasingly deceptive misalignment threats. In the face of this fragmentation, we propose an integrated vision for the future of the field. Drawing on related lessons from immunology and cybersecurity, we lay out a set of design principles for the development of Integrated Alignment frameworks that combine the complementary strengths of diverse alignment approaches through deep integration and adaptive coevolution. We highlight the importance of strategic diversity - deploying orthogonal alignment and misalignment detection approaches to avoid homogeneous pipelines that may be \"doomed to success\". We also recommend steps for greater unification of the AI alignment research field itself, through cross-collaboration, open model weights and shared community resources.",
    "source": "arXiv"
  },
  {
    "title": "LLM Unlearning Without an Expert Curated Dataset",
    "title_es": "LLM Unlearning Without an Expert Curated Dataset",
    "url": "https://arxiv.org/abs/2508.06595",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06595v1 Announce Type: new \nAbstract: Modern large language models often encode sensitive, harmful, or copyrighted knowledge, raising the need for post-hoc unlearning-the ability to remove specific domains of knowledge from a model without full retraining. A major bottleneck in current unlearning pipelines is constructing effective forget sets-datasets that approximate the target domain and guide the model to forget it. In this work, we introduce a scalable, automated approach to generate high-quality forget sets using language models themselves. Our method synthesizes textbook-style data through a structured prompting pipeline, requiring only a domain name as input. Through experiments on unlearning biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic datasets consistently outperform the baseline synthetic alternatives and are comparable to the expert-curated ones. Additionally, ablation studies reveal that the multi-step generation pipeline significantly boosts data diversity, which in turn improves unlearning utility. Overall, our findings suggest that synthetic datasets offer a promising path toward practical, scalable unlearning for a wide range of emerging domains without the need for manual intervention. We release our code and dataset at https://github.com/xyzhu123/Synthetic_Textbook.",
    "source": "arXiv"
  },
  {
    "title": "BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent",
    "title_es": "BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent",
    "url": "https://arxiv.org/abs/2508.06600",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06600v1 Announce Type: new \nAbstract: Deep-Research agents, which integrate large language models (LLMs) with search tools, have shown success in improving the effectiveness of handling complex queries that require iterative search planning and reasoning over search results. Evaluations on current benchmarks like BrowseComp relies on black-box live web search APIs, have notable limitations in (1) fairness: dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep research methods; (2) transparency: lack of control over the document corpus makes it difficult to isolate retriever contributions. In other words, the current evaluations may compare a complete deep research system at a given time, but they do not foster well-controlled experiments to provide insights into the capability of underlying deep research LLMs. To address these challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp, employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus includes human-verified supporting documents and mined challenging negatives, enabling controlled experimentation. The benchmark is shown to be effective in distinguishing the performance of deep research systems. For instance, the open-source model Search-R1, when paired with the BM25 retriever, achieves 3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with fewer search calls. This benchmark allows comprehensive evaluation and disentangled analysis of deep research agents and retrieval methods, fostering insights into retrieval effectiveness, citation accuracy, and context engineering in Deep-Research system.",
    "source": "arXiv"
  },
  {
    "title": "Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs",
    "title_es": "Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs",
    "url": "https://arxiv.org/abs/2508.06601",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06601v1 Announce Type: new \nAbstract: Open-weight AI systems offer unique benefits, including enhanced transparency, open research, and decentralized access. However, they are vulnerable to tampering attacks which can efficiently elicit harmful behaviors by modifying weights or activations. Currently, there is not yet a robust science of open-weight model risk management. Existing safety fine-tuning methods and other post-training techniques have struggled to make LLMs resistant to more than a few dozen steps of adversarial fine-tuning. In this paper, we investigate whether filtering text about dual-use topics from training data can prevent unwanted capabilities and serve as a more tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable data filtering and show that it offers a tractable and effective method for minimizing biothreat proxy knowledge in LLMs. We pretrain multiple 6.9B-parameter models from scratch and find that they exhibit substantial resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M tokens of biothreat-related text -- outperforming existing post-training baselines by over an order of magnitude -- with no observed degradation to unrelated capabilities. However, while filtered models lack internalized dangerous knowledge, we find that they can still leverage such information when it is provided in context (e.g., via search tool augmentation), demonstrating a need for a defense-in-depth approach. Overall, these findings help to establish pretraining data curation as a promising layer of defense for open-weight AI systems.",
    "source": "arXiv"
  },
  {
    "title": "Local Diffusion Models and Phases of Data Distributions",
    "title_es": "Local Diffusion Models and Phases of Data Distributions",
    "url": "https://arxiv.org/abs/2508.06614",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06614v1 Announce Type: new \nAbstract: As a class of generative artificial intelligence frameworks inspired by statistical physics, diffusion models have shown extraordinary performance in synthesizing complicated data distributions through a denoising process gradually guided by score functions. Real-life data, like images, is often spatially structured in low-dimensional spaces. However, ordinary diffusion models ignore this local structure and learn spatially global score functions, which are often computationally expensive. In this work, we introduce a new perspective on the phases of data distributions, which provides insight into constructing local denoisers with reduced computational costs. We define two distributions as belonging to the same data distribution phase if they can be mutually connected via spatially local operations such as local denoisers. Then, we show that the reverse denoising process consists of an early trivial phase and a late data phase, sandwiching a rapid phase transition where local denoisers must fail. To diagnose such phase transitions, we prove an information-theoretic bound on the fidelity of local denoisers based on conditional mutual information, and conduct numerical experiments in a real-world dataset. This work suggests simpler and more efficient architectures of diffusion models: far from the phase transition point, we can use small local neural networks to compute the score function; global neural networks are only necessary around the narrow time interval of phase transitions. This result also opens up new directions for studying phases of data distributions, the broader science of generative artificial intelligence, and guiding the design of neural networks inspired by physics concepts.",
    "source": "arXiv"
  },
  {
    "title": "Iris RESTful Server and IrisTileSource: An Iris implementation for existing OpenSeaDragon viewers",
    "title_es": "Iris RESTful Server and IrisTileSource: An Iris implementation for existing OpenSeaDragon viewers",
    "url": "https://arxiv.org/abs/2508.06615",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06615v1 Announce Type: new \nAbstract: The Iris File Extension (IFE) is a low overhead performance-oriented whole slide image (WSI) file format designed to improve the image rendering experience for pathologists and simplify image management for system administrators. However, static hypertext transfer protocol (HTTP) file servers cannot natively stream subregions of high-resolution image files, such as the IFE. The majority of contemporary WSI viewer systems are designed as browser-based web applications and leverage OpenSeaDragon as the tile-based rendering framework. These systems convert WSI files to Deep Zoom Images (DZI) for compatibility with simple static HTTP file servers. In order to address this limitation, we have developed the Iris RESTful Server, a low-overhead HTTP server with a RESTful API that is natively compatible with the DICOMweb WADO-RS API. Written in C++ with Boost Beast HTTP and Asio networking libraries atop the public IFE libraries, the server offers both security and high performance. Testing shows that a single instance can handle over 5000 tile requests per second with a median latency of 21 ms on a private network. We also developed and merged a new OpenSeaDragon TileSource, compatible with the Iris RESTful API, into the next OpenSeaDragon release, enabling simple and immediate drop-in replacement of DZI images within WSI viewer stacks. Designed as a secure cross-origin resource sharing microservice, this architecture includes detailed deployment instructions for new or existing WSI workflows, and the public examples.restful.irisdigitialpathology.org subdomain is provided as a development tool to accelerate WSI web viewer development.",
    "source": "arXiv"
  },
  {
    "title": "Generative AI for Intent-Driven Network Management in 6G: A Case Study on Hierarchical Learning Approach",
    "title_es": "Generative AI for Intent-Driven Network Management in 6G: A Case Study on Hierarchical Learning Approach",
    "url": "https://arxiv.org/abs/2508.06616",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06616v1 Announce Type: new \nAbstract: With the emergence of 6G, mobile networks are becoming increasingly heterogeneous and dynamic, necessitating advanced automation for efficient management. Intent-Driven Networks (IDNs) address this by translating high-level intents into optimization policies. Large Language Models (LLMs) can enhance this process by understanding complex human instructions to enable adaptive, intelligent automation. Given the rapid advancements in Generative AI (GenAI), a comprehensive survey of LLM-based IDN architectures in disaggregated Radio Access Network (RAN) environments is both timely and critical. This article provides such a survey, along with a case study on a hierarchical learning-enabled IDN architecture that integrates GenAI across three key stages: intent processing, intent validation, and intent execution. Unlike most existing approaches that apply GenAI in the form of LLMs for intent processing only, we propose a hierarchical framework that introduces GenAI across all three stages of IDN. To demonstrate the effectiveness of the proposed IDN management architecture, we present a case study based on the latest GenAI architecture named Mamba. The case study shows how the proposed GenAI-driven architecture enhances network performance through intelligent automation, surpassing the performance of the conventional IDN architectures.",
    "source": "arXiv"
  },
  {
    "title": "Generalizing Scaling Laws for Dense and Sparse Large Language Models",
    "title_es": "Generalizing Scaling Laws for Dense and Sparse Large Language Models",
    "url": "https://arxiv.org/abs/2508.06617",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06617v1 Announce Type: new \nAbstract: Over the past few years, the size of language models has grown exponentially, as has the computational cost to train these large models. This rapid growth has motivated researchers to develop new techniques aimed at enhancing the efficiency of the training process. Despite these advancements, optimally predicting the model size or allocating optimal resources remains a challenge. Several efforts have addressed the challenge by proposing different scaling laws, but almost all of them are architecture-specific (dense or sparse). In this work we revisit existing scaling laws and propose a generalized scaling law to provide a unified framework that is applicable to both dense and sparse large language models. We evaluate and compare our proposed scaling law with existing scaling laws to demonstrate its effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "Asymmetric Network Games: $\\alpha$-Potential Function and Learning",
    "title_es": "Asymmetric Network Games: $\\alpha$-Potential Function and Learning",
    "url": "https://arxiv.org/abs/2508.06619",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06619v1 Announce Type: new \nAbstract: In a network game, players interact over a network and the utility of each player depends on his own action and on an aggregate of his neighbours' actions. Many real world networks of interest are asymmetric and involve a large number of heterogeneous players. This paper analyzes static network games using the framework of $\\alpha$-potential games. Under mild assumptions on the action sets (compact intervals) and the utility functions (twice continuously differentiable) of the players, we derive an expression for an inexact potential function of the game, called the $\\alpha$-potential function. Using such a function, we show that modified versions of the sequential best-response algorithm and the simultaneous gradient play algorithm achieve convergence of players' actions to a $2\\alpha$-Nash equilibrium. For linear-quadratic network games, we show that $\\alpha$ depends on the maximum asymmetry in the network and is well-behaved for a wide range of networks of practical interest. Further, we derive bounds on the social welfare of the $\\alpha$-Nash equilibrium corresponding to the maximum of the $\\alpha$-potential function, under suitable assumptions. We numerically illustrate the convergence of the proposed algorithms and properties of the learned $2\\alpha$-Nash equilibria.",
    "source": "arXiv"
  },
  {
    "title": "Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models",
    "title_es": "Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models",
    "url": "https://arxiv.org/abs/2508.06621",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06621v1 Announce Type: new \nAbstract: Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a learned token vocabulary with a detailed merge list. Recent work has shown that this merge list exposes a potential attack surface for extracting information about language model's training data. In this paper, we explore the downstream impact of BPE inference algorithms that do not rely on this merge list at all, and hence differ from the encoding process during BPE training. To address this question, we investigate two broad classes of BPE inference schemes that differ from BPE application during training: a) targeted deviation from merge-lists including random merge orders, and various corruptions of merge list involving deletion/truncation, and b) non-targeted BPE inference algorithms that do not depend on the merge list but focus on compressing the text either greedily or exactly. Extensive experiments across diverse language modeling tasks like accuracy-based QA benchmarks, machine translation, and open-ended generation reveal that while targeted deviation from the merge lists exhibits significant degradation in language model performance, the non-targeted merge-list-free inference algorithms result in minimal impact on downstream performance that is often much smaller than expected. These findings pave way for simpler and potentially more privacy-preserving tokenization schemes that do not catastrophically compromise model performance.",
    "source": "arXiv"
  },
  {
    "title": "Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels",
    "title_es": "Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels",
    "url": "https://arxiv.org/abs/2508.06622",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06622v1 Announce Type: new \nAbstract: We introduce ANTIDOTE, a new class of objectives for learning under noisy labels which are defined in terms of a relaxation over an information-divergence neighborhood. Using convex duality, we provide a reformulation as an adversarial training method that has similar computational cost to training with standard cross-entropy loss. We show that our approach adaptively reduces the influence of the samples with noisy labels during learning, exhibiting a behavior that is analogous to forgetting those samples. ANTIDOTE is effective in practical environments where label noise is inherent in the training data or where an adversary can alter the training labels. Extensive empirical evaluations on different levels of symmetric, asymmetric, human annotation, and real-world label noise show that ANTIDOTE outperforms leading comparable losses in the field and enjoys a time complexity that is very close to that of the standard cross entropy loss.",
    "source": "arXiv"
  },
  {
    "title": "ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification",
    "title_es": "ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification",
    "url": "https://arxiv.org/abs/2508.06623",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06623v1 Announce Type: new \nAbstract: The proliferation of digital news media necessitates robust methods for verifying content veracity, particularly regarding the consistency between visual and textual information. Traditional approaches often fall short in addressing the fine-grained cross-modal contextual consistency (FCCC) problem, which encompasses deeper alignment of visual narrative, emotional tone, and background information with text, beyond mere entity matching. To address this, we propose ContextGuard-LVLM, a novel framework built upon advanced Vision-Language Large Models (LVLMs) and integrating a multi-stage contextual reasoning mechanism. Our model is uniquely enhanced through reinforced or adversarial learning paradigms, enabling it to detect subtle contextual misalignments that evade zero-shot baselines. We extend and augment three established datasets (TamperedNews-Ent, News400-Ent, MMG-Ent) with new fine-grained contextual annotations, including \"contextual sentiment,\" \"visual narrative theme,\" and \"scene-event logical coherence,\" and introduce a comprehensive CTXT (Contextual Coherence) entity type. Extensive experiments demonstrate that ContextGuard-LVLM consistently outperforms state-of-the-art zero-shot LVLM baselines (InstructBLIP and LLaVA 1.5) across nearly all fine-grained consistency tasks, showing significant improvements in complex logical reasoning and nuanced contextual understanding. Furthermore, our model exhibits superior robustness to subtle perturbations and a higher agreement rate with human expert judgments on challenging samples, affirming its efficacy in discerning sophisticated forms of context detachment.",
    "source": "arXiv"
  },
  {
    "title": "VL-MedGuide: A Visual-Linguistic Large Model for Intelligent and Explainable Skin Disease Auxiliary Diagnosis",
    "title_es": "VL-MedGuide: A Visual-Linguistic Large Model for Intelligent and Explainable Skin Disease Auxiliary Diagnosis",
    "url": "https://arxiv.org/abs/2508.06624",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06624v1 Announce Type: new \nAbstract: Accurate diagnosis of skin diseases remains a significant challenge due to the complex and diverse visual features present in dermatoscopic images, often compounded by a lack of interpretability in existing purely visual diagnostic models. To address these limitations, this study introduces VL-MedGuide (Visual-Linguistic Medical Guide), a novel framework leveraging the powerful multi-modal understanding and reasoning capabilities of Visual-Language Large Models (LVLMs) for intelligent and inherently interpretable auxiliary diagnosis of skin conditions. VL-MedGuide operates in two interconnected stages: a Multi-modal Concept Perception Module, which identifies and linguistically describes dermatologically relevant visual features through sophisticated prompt engineering, and an Explainable Disease Reasoning Module, which integrates these concepts with raw visual information via Chain-of-Thought prompting to provide precise disease diagnoses alongside transparent rationales. Comprehensive experiments on the Derm7pt dataset demonstrate that VL-MedGuide achieves state-of-the-art performance in both disease diagnosis (83.55% BACC, 80.12% F1) and concept detection (76.10% BACC, 67.45% F1), surpassing existing baselines. Furthermore, human evaluations confirm the high clarity, completeness, and trustworthiness of its generated explanations, bridging the gap between AI performance and clinical utility by offering actionable, explainable insights for dermatological practice.",
    "source": "arXiv"
  },
  {
    "title": "CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation",
    "title_es": "CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation",
    "url": "https://arxiv.org/abs/2508.06625",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06625v1 Announce Type: new \nAbstract: We introduce a diffusion-based cross-domain image translator in the absence of paired training data. Unlike GAN-based methods, our approach integrates diffusion models to learn the image translation process, allowing for more coverable modeling of the data distribution and performance improvement of the cross-domain translation. However, incorporating the translation process within the diffusion process is still challenging since the two processes are not aligned exactly, i.e., the diffusion process is applied to the noisy signal while the translation process is conducted on the clean signal. As a result, recent diffusion-based studies employ separate training or shallow integration to learn the two processes, yet this may cause the local minimal of the translation optimization, constraining the effectiveness of diffusion models. To address the problem, we propose a novel joint learning framework that aligns the diffusion and the translation process, thereby improving the global optimality. Specifically, we propose to extract the image components with diffusion models to represent the clean signal and employ the translation process with the image components, enabling an end-to-end joint learning manner. On the other hand, we introduce a time-dependent translation network to learn the complex translation mapping, resulting in effective translation learning and significant performance improvement. Benefiting from the design of joint learning, our method enables global optimization of both processes, enhancing the optimality and achieving improved fidelity and structural consistency. We have conducted extensive experiments on RGB$\\leftrightarrow$RGB and diverse cross-modality translation tasks including RGB$\\leftrightarrow$Edge, RGB$\\leftrightarrow$Semantics and RGB$\\leftrightarrow$Depth, showcasing better generative performances than the state of the arts.",
    "source": "arXiv"
  },
  {
    "title": "Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record",
    "title_es": "Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record",
    "url": "https://arxiv.org/abs/2508.06627",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06627v1 Announce Type: new \nAbstract: Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and early detection remains a major clinical challenge due to the absence of specific symptoms and reliable biomarkers. In this work, we propose a new multimodal approach that integrates longitudinal diagnosis code histories and routinely collected laboratory measurements from electronic health records to detect PDAC up to one year prior to clinical diagnosis. Our method combines neural controlled differential equations to model irregular lab time series, pretrained language models and recurrent networks to learn diagnosis code trajectory representations, and cross-attention mechanisms to capture interactions between the two modalities. We develop and evaluate our approach on a real-world dataset of nearly 4,700 patients and achieve significant improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods. Furthermore, our model identifies diagnosis codes and laboratory panels associated with elevated PDAC risk, including both established and new biomarkers. Our code is available at https://github.com/MosbahAouad/EarlyPDAC-MML.",
    "source": "arXiv"
  },
  {
    "title": "A note on generating Voronoi cells with a given size distribution",
    "title_es": "A note on generating Voronoi cells with a given size distribution",
    "url": "https://arxiv.org/abs/2508.06630",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06630v1 Announce Type: new \nAbstract: This note describes a simple method to draw random points such that the cells of the corresponding Voronoi tesselation (approximately) satisfy a desired size distribution, for instance, follow a power law. The method is illustrated and numerically verified in two dimensions, and we also provide a simple implementation.",
    "source": "arXiv"
  },
  {
    "title": "CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition",
    "title_es": "CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition",
    "url": "https://arxiv.org/abs/2508.06632",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06632v1 Announce Type: new \nAbstract: Neural Radiance Fields (NeRF) have shown impressive performance in novel view synthesis, but challenges remain in rendering scenes with complex specular reflections and highlights. Existing approaches may produce blurry reflections due to entanglement between lighting and material properties, or encounter optimization instability when relying on physically-based inverse rendering. In this work, we present a neural rendering framework based on dynamic coefficient decomposition, aiming to improve the modeling of view-dependent appearance. Our approach decomposes complex appearance into a shared, static neural basis that encodes intrinsic material properties, and a set of dynamic coefficients generated by a Coefficient Network conditioned on view and illumination. A Dynamic Radiance Integrator then combines these components to synthesize the final radiance. Experimental results on several challenging benchmarks suggest that our method can produce sharper and more realistic specular highlights compared to existing techniques. We hope that this decomposition paradigm can provide a flexible and effective direction for modeling complex appearance in neural scene representations.",
    "source": "arXiv"
  },
  {
    "title": "Dual-Head Physics-Informed Graph Decision Transformer for Distribution System Restoration",
    "title_es": "Dual-Head Physics-Informed Graph Decision Transformer for Distribution System Restoration",
    "url": "https://arxiv.org/abs/2508.06634",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06634v1 Announce Type: new \nAbstract: Driven by recent advances in sensing and computing, deep reinforcement learning (DRL) technologies have shown great potential for addressing distribution system restoration (DSR) under uncertainty. However, their data-intensive nature and reliance on the Markov Decision Process (MDP) assumption limit their ability to handle scenarios that require long-term temporal dependencies or few-shot and zero-shot decision making. Emerging Decision Transformers (DTs), which leverage causal transformers for sequence modeling in DRL tasks, offer a promising alternative. However, their reliance on return-to-go (RTG) cloning and limited generalization capacity restricts their effectiveness in dynamic power system environments. To address these challenges, we introduce an innovative Dual-Head Physics-informed Graph Decision Transformer (DH-PGDT) that integrates physical modeling, structural reasoning, and subgoal-based guidance to enable scalable and robust DSR even in zero-shot or few-shot scenarios. DH-PGDT features a dual-head physics-informed causal transformer architecture comprising Guidance Head, which generates subgoal representations, and Action Head, which uses these subgoals to generate actions independently of RTG. It also incorporates an operational constraint-aware graph reasoning module that encodes power system topology and operational constraints to generate a confidence-weighted action vector for refining DT trajectories. This design effectively improves generalization and enables robust adaptation to unseen scenarios. While this work focuses on DSR, the underlying computing model of the proposed PGDT is broadly applicable to sequential decision making across various power system operations and other complex engineering domains.",
    "source": "arXiv"
  },
  {
    "title": "Using Imperfect Synthetic Data in Downstream Inference Tasks",
    "title_es": "Using Imperfect Synthetic Data in Downstream Inference Tasks",
    "url": "https://arxiv.org/abs/2508.06635",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06635v1 Announce Type: new \nAbstract: Predictions and generations from large language models are increasingly being explored as an aid to computational social science and human subject research in limited data regimes. While previous technical work has explored the potential to use model-predicted labels for unlabeled data in a principled manner, there is increasing interest in using large language models to generate entirely new synthetic samples (also termed as synthetic simulations), such as in responses to surveys. However, it is not immediately clear by what means practitioners can combine such data with real data and yet produce statistically valid conclusions upon them. In this work, we introduce a new estimator based on generalized method of moments, providing a hyperparameter-free solution with strong theoretical guarantees to address the challenge at hand. Surprisingly, we find that interactions between the moment residuals of synthetic data and those of real data can improve estimates of the target parameter. We empirically validate the finite-sample performance of our estimator across different regression tasks in computational social science applications, demonstrating large empirical gains.",
    "source": "arXiv"
  },
  {
    "title": "Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series",
    "title_es": "Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series",
    "url": "https://arxiv.org/abs/2508.06638",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06638v1 Announce Type: new \nAbstract: As time series data become increasingly prevalent in domains such as manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt to nonstationary environments where statistical properties shift over time. Traditional static thresholds are easily rendered obsolete by regime shifts, concept drift, or multi-scale changes. To address these challenges, we introduce and empirically evaluate two novel adaptive thresholding frameworks: Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence Segments (MACS). Both leverage statistical online learning and segmentation principles for local, contextually sensitive adaptation, maintaining guarantees on false alarm rates even under evolving distributions. Our experiments across Wafer Manufacturing benchmark datasets show significant F1-score improvement compared to traditional percentile and rolling quantile approaches. This work demonstrates that robust, statistically principled adaptive thresholds enable reliable, interpretable, and timely detection of diverse real-world anomalies.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Key-frame-based Micro-expression Recognition: A Robust and Accurate Framework Against Key-frame Errors",
    "title_es": "Rethinking Key-frame-based Micro-expression Recognition: A Robust and Accurate Framework Against Key-frame Errors",
    "url": "https://arxiv.org/abs/2508.06640",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06640v1 Announce Type: new \nAbstract: Micro-expression recognition (MER) is a highly challenging task in affective computing. With the reduced-sized micro-expression (ME) input that contains key information based on key-frame indexes, key-frame-based methods have significantly improved the performance of MER. However, most of these methods focus on improving the performance with relatively accurate key-frame indexes, while ignoring the difficulty of obtaining accurate key-frame indexes and the objective existence of key-frame index errors, which impedes them from moving towards practical applications. In this paper, we propose CausalNet, a novel framework to achieve robust MER facing key-frame index errors while maintaining accurate recognition. To enhance robustness, CausalNet takes the representation of the entire ME sequence as the input. To address the information redundancy brought by the complete ME range input and maintain accurate recognition, first, the Causal Motion Position Learning Module (CMPLM) is proposed to help the model locate the muscle movement areas related to Action Units (AUs), thereby reducing the attention to other redundant areas. Second, the Causal Attention Block (CAB) is proposed to deeply learn the causal relationships between the muscle contraction and relaxation movements in MEs. Empirical experiments have demonstrated that on popular ME benchmarks, the CausalNet has achieved robust MER under different levels of key-frame index noise. Meanwhile, it has surpassed state-of-the-art (SOTA) methods on several standard MER benchmarks when using the provided annotated key-frames. Code is available at https://github.com/tony19980810/CausalNet.",
    "source": "arXiv"
  },
  {
    "title": "Fractal Language Modelling by Universal Sequence Maps (USM)",
    "title_es": "Fractal Language Modelling by Universal Sequence Maps (USM)",
    "url": "https://arxiv.org/abs/2508.06641",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06641v1 Announce Type: new \nAbstract: Motivation: With the advent of Language Models using Transformers, popularized by ChatGPT, there is a renewed interest in exploring encoding procedures that numerically represent symbolic sequences at multiple scales and embedding dimensions. The challenge that encoding addresses is the need for mechanisms that uniquely retain contextual information about the succession of individual symbols, which can then be modeled by nonlinear formulations such as neural networks.\n  Context: Universal Sequence Maps(USM) are iterated functions that bijectively encode symbolic sequences onto embedded numerical spaces. USM is composed of two Chaos Game Representations (CGR), iterated forwardly and backwardly, that can be projected into the frequency domain (FCGR). The corresponding USM coordinates can be used to compute a Chebyshev distance metric as well as k-mer frequencies, without having to recompute the embedded numeric coordinates, and, paradoxically, allowing for non-integers values of k.\n  Results: This report advances the bijective fractal encoding by Universal Sequence Maps (USM) by resolving seeding biases affecting the iterated process. The resolution had two results, the first expected, the second an intriguing outcome: 1) full reconciliation of numeric positioning with sequence identity; and 2) uncovering the nature of USM as an efficient numeric process converging towards a steady state sequence embedding solution. We illustrate these results for genomic sequences because of the convenience of a planar representation defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless, the application to alphabet of arbitrary cardinality was found to be straightforward.",
    "source": "arXiv"
  },
  {
    "title": "Symbolic Execution in Practice: A Survey of Applications in Vulnerability, Malware, Firmware, and Protocol Analysis",
    "title_es": "Symbolic Execution in Practice: A Survey of Applications in Vulnerability, Malware, Firmware, and Protocol Analysis",
    "url": "https://arxiv.org/abs/2508.06643",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06643v1 Announce Type: new \nAbstract: Symbolic execution is a powerful program analysis technique that allows for the systematic exploration of all program paths. Path explosion, where the number of states to track becomes unwieldy, is one of the biggest challenges hindering symbolic execution's practical application. To combat this, researchers have employed various strategies to enable symbolic execution on complex software systems. This paper introduces a systematic taxonomy of these strategies, categorizing them into two primary approaches: Scope Reduction, which aims to reduce the scope of symbolic execution to manageable portions of code, and Guidance Heuristics, which steer the symbolic execution engine toward promising paths. Using this taxonomy as a lens, we survey applications of symbolic executions in several domains such as vulnerability analysis, malware analysis, firmware re-hosting, and network protocol analysis. Finally, we identify promising directions for future research, including the application of symbolic execution to real-time operating systems and modern, type-safe languages.",
    "source": "arXiv"
  },
  {
    "title": "Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN",
    "title_es": "Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN",
    "url": "https://arxiv.org/abs/2508.06647",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06647v1 Announce Type: new \nAbstract: Synthetic data generation has become essential for securely sharing and analyzing sensitive data sets. Traditional anonymization techniques, however, often fail to adequately preserve privacy. We introduce the Tabular Auto-Regressive Generative Network (TabularARGN), a neural network architecture specifically designed for generating high-quality synthetic tabular data. Using a discretization-based auto-regressive approach, TabularARGN achieves high data fidelity while remaining computationally efficient. We evaluate TabularARGN against existing synthetic data generation methods, showing competitive results in statistical similarity, machine learning utility, and detection robustness. We further perform an in-depth privacy evaluation using systematic membership-inference attacks, highlighting the robustness and effective privacy-utility balance of our approach.",
    "source": "arXiv"
  },
  {
    "title": "Measuring Stereotype and Deviation Biases in Large Language Models",
    "title_es": "Measuring Stereotype and Deviation Biases in Large Language Models",
    "url": "https://arxiv.org/abs/2508.06649",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06649v1 Announce Type: new \nAbstract: Large language models (LLMs) are widely applied across diverse domains, raising concerns about their limitations and potential risks. In this study, we investigate two types of bias that LLMs may display: stereotype bias and deviation bias. Stereotype bias refers to when LLMs consistently associate specific traits with a particular demographic group. Deviation bias reflects the disparity between the demographic distributions extracted from LLM-generated content and real-world demographic distributions. By asking four advanced LLMs to generate profiles of individuals, we examine the associations between each demographic group and attributes such as political affiliation, religion, and sexual orientation. Our experimental results show that all examined LLMs exhibit both significant stereotype bias and deviation bias towards multiple groups. Our findings uncover the biases that occur when LLMs infer user attributes and shed light on the potential harms of LLM-generated outputs.",
    "source": "arXiv"
  },
  {
    "title": "The Vertex-Attribute-Constrained Densest $k$-Subgraph Problem",
    "title_es": "The Vertex-Attribute-Constrained Densest $k$-Subgraph Problem",
    "url": "https://arxiv.org/abs/2508.06655",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06655v1 Announce Type: new \nAbstract: Dense subgraph mining is a fundamental technique in graph mining, commonly applied in fraud detection, community detection, product recommendation, and document summarization. In such applications, we are often interested in identifying communities, recommendations, or summaries that reflect different constituencies, styles or genres, and points of view. For this task, we introduce a new variant of the Densest $k$-Subgraph (D$k$S) problem that incorporates the attribute values of vertices. The proposed Vertex-Attribute-Constrained Densest $k$-Subgraph (VAC-D$k$S) problem retains the NP-hardness and inapproximability properties of the classical D$k$S. Nevertheless, we prove that a suitable continuous relaxation of VAC-D$k$S is tight and can be efficiently tackled using a projection-free Frank--Wolfe algorithm. We also present an insightful analysis of the optimization landscape of the relaxed problem. Extensive experimental results demonstrate the effectiveness of our proposed formulation and algorithm, and its ability to scale up to large graphs. We further elucidate the properties of VAC-D$k$S versus classical D$k$S in a political network mining application, where VAC-D$k$S identifies a balanced and more meaningful set of politicians representing different ideological camps, in contrast to the classical D$k$S solution which is unbalanced and rather mundane.",
    "source": "arXiv"
  },
  {
    "title": "Towards Robust Red-Green Watermarking for Autoregressive Image Generators",
    "title_es": "Towards Robust Red-Green Watermarking for Autoregressive Image Generators",
    "url": "https://arxiv.org/abs/2508.06656",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06656v1 Announce Type: new \nAbstract: In-generation watermarking for detecting and attributing generated content has recently been explored for latent diffusion models (LDMs), demonstrating high robustness. However, the use of in-generation watermarks in autoregressive (AR) image models has not been explored yet. AR models generate images by autoregressively predicting a sequence of visual tokens that are then decoded into pixels using a vector-quantized decoder. Inspired by red-green watermarks for large language models, we examine token-level watermarking schemes that bias the next-token prediction based on prior tokens. We find that a direct transfer of these schemes works in principle, but the detectability of the watermarks decreases considerably under common image perturbations. As a remedy, we propose two novel watermarking methods that rely on visual token clustering to assign similar tokens to the same set. Firstly, we investigate a training-free approach that relies on a cluster lookup table, and secondly, we finetune VAE encoders to predict token clusters directly from perturbed images. Overall, our experiments show that cluster-level watermarks improve robustness against perturbations and regeneration attacks while preserving image quality. Cluster classification further boosts watermark detectability, outperforming a set of baselines. Moreover, our methods offer fast verification runtime, comparable to lightweight post-hoc watermarking methods.",
    "source": "arXiv"
  },
  {
    "title": "In-Context Reinforcement Learning via Communicative World Models",
    "title_es": "In-Context Reinforcement Learning via Communicative World Models",
    "url": "https://arxiv.org/abs/2508.06659",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06659v1 Announce Type: new \nAbstract: Reinforcement learning (RL) agents often struggle to generalize to new tasks and contexts without updating their parameters, mainly because their learned representations and policies are overfit to the specifics of their training environments. To boost agents' in-context RL (ICRL) ability, this work formulates ICRL as a two-agent emergent communication problem and introduces CORAL (Communicative Representation for Adaptive RL), a framework that learns a transferable communicative context by decoupling latent representation learning from control. In CORAL, an Information Agent (IA) is pre-trained as a world model on a diverse distribution of tasks. Its objective is not to maximize task reward, but to build a world model and distill its understanding into concise messages. The emergent communication protocol is shaped by a novel Causal Influence Loss, which measures the effect that the message has on the next action. During deployment, the previously trained IA serves as a fixed contextualizer for a new Control Agent (CA), which learns to solve tasks by interpreting the provided communicative context. Our experiments demonstrate that this approach enables the CA to achieve significant gains in sample efficiency and successfully perform zero-shot adaptation with the help of pre-trained IA in entirely unseen sparse-reward environments, validating the efficacy of learning a transferable communicative representation.",
    "source": "arXiv"
  },
  {
    "title": "Convergence of Fast Policy Iteration in Markov Games and Robust MDPs",
    "title_es": "Convergence of Fast Policy Iteration in Markov Games and Robust MDPs",
    "url": "https://arxiv.org/abs/2508.06661",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06661v1 Announce Type: new \nAbstract: Markov games and robust MDPs are closely related models that involve computing a pair of saddle point policies. As part of the long-standing effort to develop efficient algorithms for these models, the Filar-Tolwinski (FT) algorithm has shown considerable promise. As our first contribution, we demonstrate that FT may fail to converge to a saddle point and may loop indefinitely, even in small games. This observation contradicts the proof of FT's convergence to a saddle point in the original paper. As our second contribution, we propose Residual Conditioned Policy Iteration (RCPI). RCPI builds on FT, but is guaranteed to converge to a saddle point. Our numerical results show that RCPI outperforms other convergent algorithms by several orders of magnitude.",
    "source": "arXiv"
  },
  {
    "title": "Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks",
    "title_es": "Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks",
    "url": "https://arxiv.org/abs/2508.06663",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06663v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) have shown strong performance on graph-structured data, but their reliance on graph connectivity often limits scalability and efficiency. Kolmogorov-Arnold Networks (KANs), a recent architecture with learnable univariate functions, offer strong nonlinear expressiveness and efficient inference. In this work, we integrate KANs into three popular GNN architectures-GAT, SGC, and APPNP-resulting in three new models: KGAT, KSGC, and KAPPNP. We further adopt a multi-teacher knowledge amalgamation framework, where knowledge from multiple KAN-based GNNs is distilled into a graph-independent KAN student model. Experiments on benchmark datasets show that the proposed models improve node classification accuracy, and the knowledge amalgamation approach significantly boosts student model performance. Our findings highlight the potential of KANs for enhancing GNN expressiveness and for enabling efficient, graph-free inference.",
    "source": "arXiv"
  },
  {
    "title": "Testing the Limits of Machine Translation from One Book",
    "title_es": "Testing the Limits of Machine Translation from One Book",
    "url": "https://arxiv.org/abs/2508.06665",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06665v1 Announce Type: new \nAbstract: Current state-of-the-art models demonstrate capacity to leverage in-context learning to translate into previously unseen language contexts. Tanzer et al. [2024] utilize language materials (e.g. a grammar) to improve translation quality for Kalamang using large language models (LLMs). We focus on Kanuri, a language that, despite having substantial speaker population, has minimal digital resources. We design two datasets for evaluation: one focused on health and humanitarian terms, and another containing generalized terminology, investigating how domain-specific tasks impact LLM translation quality.\n  By providing different combinations of language resources (grammar, dictionary, and parallel sentences), we measure LLM translation effectiveness, comparing results to native speaker translations and human linguist performance. We evaluate using both automatic metrics and native speaker assessments of fluency and accuracy.\n  Results demonstrate that parallel sentences remain the most effective data source, outperforming other methods in human evaluations and automatic metrics. While incorporating grammar improves over zero-shot translation, it fails as an effective standalone data source. Human evaluations reveal that LLMs achieve accuracy (meaning) more effectively than fluency (grammaticality).\n  These findings suggest LLM translation evaluation benefits from multidimensional assessment beyond simple accuracy metrics, and that grammar alone, without parallel sentences, does not provide sufficient context for effective domain-specific translation.",
    "source": "arXiv"
  },
  {
    "title": "Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis",
    "title_es": "Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis",
    "url": "https://arxiv.org/abs/2508.06668",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06668v1 Announce Type: new \nAbstract: Formal Concept Analysis (FCA) is a mathematical framework for knowledge representation and discovery. It performs a hierarchical clustering over a set of objects described by attributes, resulting in conceptual structures in which objects are organized depending on the attributes they share. These conceptual structures naturally highlight commonalities and variabilities among similar objects by categorizing them into groups which are then arranged by similarity, making it particularly appropriate for variability extraction and analysis. Despite the potential of FCA, determining which of its properties can be leveraged for variability-related tasks (and how) is not always straightforward, partly due to the mathematical orientation of its foundational literature. This paper attempts to bridge part of this gap by gathering a selection of properties of the framework which are essential to variability analysis, and how they can be used to interpret diverse variability information within the resulting conceptual structures.",
    "source": "arXiv"
  },
  {
    "title": "Do Biased Models Have Biased Thoughts?",
    "title_es": "Do Biased Models Have Biased Thoughts?",
    "url": "https://arxiv.org/abs/2508.06671",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06671v1 Announce Type: new \nAbstract: The impressive performance of language models is undeniable. However, the presence of biases based on gender, race, socio-economic status, physical appearance, and sexual orientation makes the deployment of language models challenging. This paper studies the effect of chain-of-thought prompting, a recent approach that studies the steps followed by the model before it responds, on fairness. More specifically, we ask the following question: \\textit{Do biased models have biased thoughts}? To answer our question, we conduct experiments on $5$ popular large language models using fairness metrics to quantify $11$ different biases in the model's thoughts and output. Our results show that the bias in the thinking steps is not highly correlated with the output bias (less than $0.6$ correlation with a $p$-value smaller than $0.001$ in most cases). In other words, unlike human beings, the tested models with biased decisions do not always possess biased thoughts.",
    "source": "arXiv"
  },
  {
    "title": "Zero-Shot Cellular Trajectory Map Matching",
    "title_es": "Zero-Shot Cellular Trajectory Map Matching",
    "url": "https://arxiv.org/abs/2508.06674",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06674v1 Announce Type: new \nAbstract: Cellular Trajectory Map-Matching (CTMM) aims to align cellular location sequences to road networks, which is a necessary preprocessing in location-based services on web platforms like Google Maps, including navigation and route optimization. Current approaches mainly rely on ID-based features and region-specific data to learn correlations between cell towers and roads, limiting their adaptability to unexplored areas. To enable high-accuracy CTMM without additional training in target regions, Zero-shot CTMM requires to extract not only region-adaptive features, but also sequential and location uncertainty to alleviate positioning errors in cellular data. In this paper, we propose a pixel-based trajectory calibration assistant for zero-shot CTMM, which takes advantage of transferable geospatial knowledge to calibrate pixelated trajectory, and then guide the path-finding process at the road network level. To enhance knowledge sharing across similar regions, a Gaussian mixture model is incorporated into VAE, enabling the identification of scenario-adaptive experts through soft clustering. To mitigate high positioning errors, a spatial-temporal awareness module is designed to capture sequential features and location uncertainty, thereby facilitating the inference of approximate user positions. Finally, a constrained path-finding algorithm is employed to reconstruct the road ID sequence, ensuring topological validity within the road network. This process is guided by the calibrated trajectory while optimizing for the shortest feasible path, thus minimizing unnecessary detours. Extensive experiments demonstrate that our model outperforms existing methods in zero-shot CTMM by 16.8\\%.",
    "source": "arXiv"
  },
  {
    "title": "Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation",
    "title_es": "Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation",
    "url": "https://arxiv.org/abs/2508.06676",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06676v1 Announce Type: new \nAbstract: With the increasing importance of protecting intellectual property in machine learning, watermarking techniques have gained significant attention. As advanced models are increasingly deployed in domains such as social network analysis, the need for robust model protection becomes even more critical. While existing watermarking methods have demonstrated effectiveness for conventional deep neural networks, they often fail to adapt to the novel architecture, Kolmogorov-Arnold Networks (KAN), which feature learnable activation functions. KAN holds strong potential for modeling complex relationships in network-structured data. However, their unique design also introduces new challenges for watermarking. Therefore, we propose a novel watermarking method, Discrete Cosine Transform-based Activation Watermarking (DCT-AW), tailored for KAN. Leveraging the learnable activation functions of KAN, our method embeds watermarks by perturbing activation outputs using discrete cosine transform, ensuring compatibility with diverse tasks and achieving task independence. Experimental results demonstrate that DCT-AW has a small impact on model performance and provides superior robustness against various watermark removal attacks, including fine-tuning, pruning, and retraining after pruning.",
    "source": "arXiv"
  },
  {
    "title": "Optimal Planning and Machine Learning for Responsive Tracking and Enhanced Forecasting of Wildfires using a Spacecraft Constellation",
    "title_es": "Optimal Planning and Machine Learning for Responsive Tracking and Enhanced Forecasting of Wildfires using a Spacecraft Constellation",
    "url": "https://arxiv.org/abs/2508.06687",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06687v1 Announce Type: new \nAbstract: We propose a novel concept of operations using optimal planning methods and machine learning (ML) to collect spaceborne data that is unprecedented for monitoring wildfires, process it to create new or enhanced products in the context of wildfire danger or spread monitoring, and assimilate them to improve existing, wildfire decision support tools delivered to firefighters within latency appropriate for time-critical applications. The concept is studied with respect to NASA's CYGNSS Mission, a constellation of passive microwave receivers that measure specular GNSS-R reflections despite clouds and smoke. Our planner uses a Mixed Integer Program formulation to schedule joint observation data collection and downlink for all satellites. Optimal solutions are found quickly that collect 98-100% of available observation opportunities. ML-based fire predictions that drive the planner objective are greater than 40% more correlated with ground truth than existing state-of-art. The presented case study on the TX Smokehouse Creek fire in 2024 and LA fires in 2025 represents the first high-resolution data collected by CYGNSS of active fires. Creation of Burnt Area Maps (BAM) using ML applied to the data during active fires and BAM assimilation into NASA's Weather Research and Forecasting Model using ML to broadcast fire spread are novel outcomes. BAM and CYGNSS obtained soil moisture are integrated for the first time into USGS fire danger maps. Inclusion of CYGNSS data in ML-based burn predictions boosts accuracy by 13%, and inclusion of high-resolution data boosts ML recall by another 15%. The proposed workflow has an expected latency of 6-30h, improving on the current delivery time of multiple days. All components in the proposed concept are shown to be computationally scalable and globally generalizable, with sustainability considerations such as edge efficiency and low latency on small devices.",
    "source": "arXiv"
  },
  {
    "title": "Diffeomorphic Neural Operator Learning",
    "title_es": "Diffeomorphic Neural Operator Learning",
    "url": "https://arxiv.org/abs/2508.06690",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06690v1 Announce Type: new \nAbstract: We present an operator learning approach for a class of evolution operators using a composition of a learned lift into the space of diffeomorphisms of the domain and the group action on the field space. In turn, this transforms the semigroup structure of the evolution operator into a corresponding group structure allowing time stepping be performed through composition on the space of diffeomorphisms rather than in the field space directly. This results in a number of structure-preserving properties related to preserving a relabelling symmetry of the dynamics as a hard constraint. We study the resolution properties of our approach, along with its connection to the techniques of diffeomorphic image registration. Numerical experiments on forecasting turbulent fluid dynamics are provided, demonstrating its conservative properties, non-diffusivity, and ability to capture anticipated statistical scaling relations at sub-grid scales. Our method provides an example of geometric operator learning and indicates a clear performance benefit from leveraging a priori known infinite-dimensional geometric structure.",
    "source": "arXiv"
  },
  {
    "title": "Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select",
    "title_es": "Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select",
    "url": "https://arxiv.org/abs/2508.06692",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06692v1 Announce Type: new \nAbstract: Federated Learning (FL) is a machine learning technique that often suffers from training instability due to the diverse nature of client data. Although utility-based client selection methods like Oort are used to converge by prioritizing high-loss clients, they frequently experience significant drops in accuracy during later stages of training. We propose a theoretical HeteRo-Select framework designed to maintain high performance and ensure long-term training stability. We provide a theoretical analysis showing that when client data is very different (high heterogeneity), choosing a smart subset of client participation can reduce communication more effectively compared to full participation. Our HeteRo-Select method uses a clear, step-by-step scoring system that considers client usefulness, fairness, update speed, and data variety. It also shows convergence guarantees under strong regularization. Our experimental results on the CIFAR-10 dataset under significant label skew ($\\alpha=0.1$) support the theoretical findings. The HeteRo-Select method performs better than existing approaches in terms of peak accuracy, final accuracy, and training stability. Specifically, HeteRo-Select achieves a peak accuracy of $74.75\\%$, a final accuracy of $72.76\\%$, and a minimal stability drop of $1.99\\%$. In contrast, Oort records a lower peak accuracy of $73.98\\%$, a final accuracy of $71.25\\%$, and a larger stability drop of $2.73\\%$. The theoretical foundations and empirical performance in our study make HeteRo-Select a reliable solution for real-world heterogeneous FL problems.",
    "source": "arXiv"
  },
  {
    "title": "A Tight Lower Bound for the Approximation Guarantee of Higher-Order Singular Value Decomposition",
    "title_es": "A Tight Lower Bound for the Approximation Guarantee of Higher-Order Singular Value Decomposition",
    "url": "https://arxiv.org/abs/2508.06693",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06693v1 Announce Type: new \nAbstract: We prove that the classic approximation guarantee for the higher-order singular value decomposition (HOSVD) is tight by constructing a tensor for which HOSVD achieves an approximation ratio of $N/(1+\\varepsilon)$, for any $\\varepsilon > 0$. This matches the upper bound of De Lathauwer et al. (2000a) and shows that the approximation ratio of HOSVD cannot be improved. Using a more advanced construction, we also prove that the approximation guarantees for the ST-HOSVD algorithm of Vannieuwenhoven et al. (2012) and higher-order orthogonal iteration (HOOI) of De Lathauwer et al. (2000b) are tight by showing that they can achieve their worst-case approximation ratio of $N / (1 + \\varepsilon)$, for any $\\varepsilon > 0$.",
    "source": "arXiv"
  },
  {
    "title": "When isometry and equivalence for skew constacyclic codes coincide",
    "title_es": "When isometry and equivalence for skew constacyclic codes coincide",
    "url": "https://arxiv.org/abs/2508.06695",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06695v1 Announce Type: new \nAbstract: We show that the notions of $(n,\\sigma)$-isometry and $(n,\\sigma)$-equivalence introduced by Ou-azzou et al coincide for most skew $(\\sigma,a)$-constacyclic codes of length $n$. To prove this, we show that all Hamming-weight-preserving homomorphisms between their ambient algebras must have degree one when those algebras are nonassociative. We work in the general setting of commutative base rings $S$. As a consequence, we propose new definitions of equivalence and isometry of skew constacyclic codes that exactly capture all Hamming-preserving isomorphisms, and lead to tighter classifications. In the process we determine homomorphisms between nonassociative Petit algebras, prioritizing the algebras $S[t;\\sigma]/S[t;\\sigma](t^n-a)$, which give rise to skew constacyclic codes.",
    "source": "arXiv"
  },
  {
    "title": "Learning More by Seeing Less: Line Drawing Pretraining for Efficient, Transferable, and Human-Aligned Vision",
    "title_es": "Learning More by Seeing Less: Line Drawing Pretraining for Efficient, Transferable, and Human-Aligned Vision",
    "url": "https://arxiv.org/abs/2508.06696",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06696v1 Announce Type: new \nAbstract: Despite remarkable progress in computer vision, modern recognition systems remain limited by their dependence on rich, redundant visual inputs. In contrast, humans can effortlessly understand sparse, minimal representations like line drawings - suggesting that structure, rather than appearance, underlies efficient visual understanding. In this work, we propose using line drawings as a structure-first pretraining modality to induce more compact and generalizable visual representations. We show that models pretrained on line drawings develop stronger shape bias, more focused attention, and greater data efficiency across classification, detection, and segmentation tasks. Notably, these models also exhibit lower intrinsic dimensionality, requiring significantly fewer principal components to capture representational variance - echoing the similar observation in low dimensional efficient representation in the brain. Beyond performance improvements, line drawing pretraining produces more compressible representations, enabling better distillation into lightweight student models. Students distilled from line-pretrained teachers consistently outperform those trained from color-supervised teachers, highlighting the benefits of structurally compact knowledge. Finally, we demonstrate that the pretraining with line-drawing can also be extended to unsupervised setting via our proposed method \"learning to draw\". Together, our results support the view that structure-first visual learning fosters efficiency, generalization, and human-aligned inductive biases - offering a simple yet powerful strategy for building more robust and adaptable vision systems.",
    "source": "arXiv"
  },
  {
    "title": "MMFformer: Multimodal Fusion Transformer Network for Depression Detection",
    "title_es": "MMFformer: Multimodal Fusion Transformer Network for Depression Detection",
    "url": "https://arxiv.org/abs/2508.06701",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06701v1 Announce Type: new \nAbstract: Depression is a serious mental health illness that significantly affects an individual's well-being and quality of life, making early detection crucial for adequate care and treatment. Detecting depression is often difficult, as it is based primarily on subjective evaluations during clinical interviews. Hence, the early diagnosis of depression, thanks to the content of social networks, has become a prominent research area. The extensive and diverse nature of user-generated information poses a significant challenge, limiting the accurate extraction of relevant temporal information and the effective fusion of data across multiple modalities. This paper introduces MMFformer, a multimodal depression detection network designed to retrieve depressive spatio-temporal high-level patterns from multimodal social media information. The transformer network with residual connections captures spatial features from videos, and a transformer encoder is exploited to design important temporal dynamics in audio. Moreover, the fusion architecture fused the extracted features through late and intermediate fusion strategies to find out the most relevant intermodal correlations among them. Finally, the proposed network is assessed on two large-scale depression detection datasets, and the results clearly reveal that it surpasses existing state-of-the-art approaches, improving the F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is made available publicly at https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.",
    "source": "arXiv"
  },
  {
    "title": "Emergence of Cooperation and Commitment in Optional Prisoner's Dilemma",
    "title_es": "Emergence of Cooperation and Commitment in Optional Prisoner's Dilemma",
    "url": "https://arxiv.org/abs/2508.06702",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06702v1 Announce Type: new \nAbstract: Commitment is a well-established mechanism for fostering cooperation in human society and multi-agent systems. However, existing research has predominantly focused on the commitment that neglects the freedom of players to abstain from an interaction, limiting their applicability to many real-world scenarios where participation is often voluntary. In this paper, we present a two-stage game model to investigate the evolution of commitment-based behaviours and cooperation within the framework of the optional Prisoner's Dilemma game. In the pre-game stage, players decide whether to accept a mutual commitment. Once in the game, they choose among cooperation, defection, or exiting, depending on the formation of a pre-game commitment. We find that optional participation boosts commitment acceptance but fails to foster cooperation, leading instead to widespread exit behaviour. To address this, we then introduce and compare two institutional incentive approaches: i) a strict one (STRICT-COM) that rewards only committed players who cooperate in the game, and ii) a flexible one (FLEXIBLE-COM) that rewards any committed players who do not defect in the game. The results reveal that, while the strict approach is demonstrably better for promoting cooperation as the flexible rule creates a loophole for an opportunistic exit after committing, the flexible rule offers an efficient alternative for enhancing social welfare when such opportunistic behaviour results in a high gain. This study highlights the limitations of relying solely on voluntary participation and commitment to resolving social dilemmas, emphasising the importance of well-designed institutional incentives to promote cooperation and social welfare effectively.",
    "source": "arXiv"
  },
  {
    "title": "Fourier Optics and Deep Learning Methods for Fast 3D Reconstruction in Digital Holography",
    "title_es": "Fourier Optics and Deep Learning Methods for Fast 3D Reconstruction in Digital Holography",
    "url": "https://arxiv.org/abs/2508.06703",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06703v1 Announce Type: new \nAbstract: Computer-generated holography (CGH) is a promising method that modulates user-defined waveforms with digital holograms. An efficient and fast pipeline framework is proposed to synthesize CGH using initial point cloud and MRI data. This input data is reconstructed into volumetric objects that are then input into non-convex Fourier optics optimization algorithms for phase-only hologram (POH) and complex-hologram (CH) generation using alternating projection, SGD, and quasi-Netwton methods. Comparison of reconstruction performance of these algorithms as measured by MSE, RMSE, and PSNR is analyzed as well as to HoloNet deep learning CGH. Performance metrics are shown to be improved by using 2D median filtering to remove artifacts and speckled noise during optimization.",
    "source": "arXiv"
  },
  {
    "title": "CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations",
    "title_es": "CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations",
    "url": "https://arxiv.org/abs/2508.06704",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06704v1 Announce Type: new \nAbstract: Species distribution models (SDMs) are widely used to predict species' geographic distributions, serving as critical tools for ecological research and conservation planning. Typically, SDMs relate species occurrences to environmental variables representing abiotic factors, such as temperature, precipitation, and soil properties. However, species distributions are also strongly influenced by biotic interactions with other species, which are often overlooked. While some methods partially address this limitation by incorporating biotic interactions, they often assume symmetrical pairwise relationships between species and require consistent co-occurrence data. In practice, species observations are sparse, and the availability of information about the presence or absence of other species varies significantly across locations. To address these challenges, we propose CISO, a deep learning-based method for species distribution modeling Conditioned on Incomplete Species Observations. CISO enables predictions to be conditioned on a flexible number of species observations alongside environmental variables, accommodating the variability and incompleteness of available biotic data. We demonstrate our approach using three datasets representing different species groups: sPlotOpen for plants, SatBird for birds, and a new dataset, SatButterfly, for butterflies. Our results show that including partial biotic information improves predictive performance on spatially separate test sets. When conditioned on a subset of species within the same dataset, CISO outperforms alternative methods in predicting the distribution of the remaining species. Furthermore, we show that combining observations from multiple datasets can improve performance. CISO is a promising ecological tool, capable of incorporating incomplete biotic information and identifying potential interactions between species from disparate taxa.",
    "source": "arXiv"
  },
  {
    "title": "Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets",
    "title_es": "Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets",
    "url": "https://arxiv.org/abs/2508.06706",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06706v1 Announce Type: new \nAbstract: Rule-based methods for knowledge graph completion provide explainable results but often require a significantly large number of rules to achieve competitive performance. This can hinder explainability due to overwhelmingly large rule sets. We discover rule contexts (meaningful subsets of rules that work together) from training data and use learned probability distribution (i.e. probabilistic circuits) over these rule contexts to more rapidly achieve performance of the full rule set. Our approach achieves a 70-96% reduction in number of rules used while outperforming baseline by up to 31$\\times$ when using equivalent minimal number of rules and preserves 91% of peak baseline performance even when comparing our minimal rule sets against baseline's full rule sets. We show that our framework is grounded in well-known semantics of probabilistic logic, does not require independence assumptions, and that our tractable inference procedure provides both approximate lower bounds and exact probability of a given query. The efficacy of our method is validated by empirical studies on 8 standard benchmark datasets where we show competitive performance by using only a fraction of the rules required by AnyBURL's standard inference method, the current state-of-the-art for rule-based knowledge graph completion. This work may have further implications for general probabilistic reasoning over learned sets of rules.",
    "source": "arXiv"
  },
  {
    "title": "Embedded Microcontrol for Photovoltaic Water Pumping System",
    "title_es": "Embedded Microcontrol for Photovoltaic Water Pumping System",
    "url": "https://arxiv.org/abs/2508.06708",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06708v1 Announce Type: new \nAbstract: We introduce a novel 3-axis solar tracker water pumping system. The charge generated from solar energy converted by the photovolatic panel (PV) cells is stored in a 12V battery that in turn powers two water diaphragm pumps using a solar charge controller that includes an MPPT algorithm that serves as a DC-DC converter. The system is analyzed from an embedded microcontroller and embedded software perspective using Arduino. The photovoltaic panel uses four light photocell resistors (LPRs) which measure solar light intensity. An ultrasonic sensor measures the water level in a reservoir water tank. If the water level is too low, water is pumped from one water tank to the reservoir tank. Using a soil moisture sensor, another water pump pumps water from the reservoir tank to the plant if water is needed. Circuit designs for the system are provided as well as the embedded software used. Simulation and experimental results are given.",
    "source": "arXiv"
  },
  {
    "title": "Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge",
    "title_es": "Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge",
    "url": "https://arxiv.org/abs/2508.06709",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06709v1 Announce Type: new \nAbstract: Large language models (LLMs) can serve as judges that offer rapid and reliable assessments of other LLM outputs. However, models may systematically assign overly favorable ratings to their own outputs, a phenomenon known as self-bias, which can distort evaluations of true model performance. Previous studies often conflate genuine differences in model quality with bias or incorrectly assume that evaluations from LLMs and humans follow the same rating distributions. In this work, we present a statistical framework that explicitly formalizes assumptions under which self-bias can be identified and estimated. Our method models the difference in the scoring distribution that LLM-as-a-judge assigns to its own completions compared to other models, while accounting for the underlying quality of the completions provided by an independent, third-party judge (e.g., humans). Our method reliably isolates and quantifies self-bias, even when models vary in ability, ensuring that genuine performance differences are not mistaken for self-bias. We conduct an empirical analysis of self-bias on a large dataset (>5000 prompt-completion pairs) consisting of expert human annotations and judgments from nine different LLM judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet, systematically assign higher scores to their own outputs. These models also display family-bias; systematically assigning higher ratings to outputs produced by other models of the same family. Our findings highlight potential pitfalls of using LLM judges and offer practical guidance to mitigate biases when interpreting automated evaluations.",
    "source": "arXiv"
  },
  {
    "title": "Restage4D: Reanimating Deformable 3D Reconstruction from a Single Video",
    "title_es": "Restage4D: Reanimating Deformable 3D Reconstruction from a Single Video",
    "url": "https://arxiv.org/abs/2508.06715",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06715v1 Announce Type: new \nAbstract: Creating deformable 3D content has gained increasing attention with the rise of text-to-image and image-to-video generative models. While these models provide rich semantic priors for appearance, they struggle to capture the physical realism and motion dynamics needed for authentic 4D scene synthesis. In contrast, real-world videos can provide physically grounded geometry and articulation cues that are difficult to hallucinate. One question is raised: \\textit{Can we generate physically consistent 4D content by leveraging the motion priors of the real-world video}? In this work, we explore the task of reanimating deformable 3D scenes from a single video, using the original sequence as a supervisory signal to correct artifacts from synthetic motion. We introduce \\textbf{Restage4D}, a geometry-preserving pipeline for video-conditioned 4D restaging. Our approach uses a video-rewinding training strategy to temporally bridge a real base video and a synthetic driving video via a shared motion representation. We further incorporate an occlusion-aware rigidity loss and a disocclusion backtracing mechanism to improve structural and geometry consistency under challenging motion. We validate Restage4D on DAVIS and PointOdyssey, demonstrating improved geometry consistency, motion quality, and 3D tracking performance. Our method not only preserves deformable structure under novel motion, but also automatically corrects errors introduced by generative models, revealing the potential of video prior in 4D restaging task. Source code and trained models will be released.",
    "source": "arXiv"
  },
  {
    "title": "GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning",
    "title_es": "GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning",
    "url": "https://arxiv.org/abs/2508.06716",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06716v1 Announce Type: new \nAbstract: Differentiable inductive logic programming (ILP) techniques have proven effective at finding approximate rule-based solutions to link prediction and node classification problems on knowledge graphs; however, the common assumption of chain-like rule structure can hamper the performance and interpretability of existing approaches. We introduce GLIDR, a differentiable rule learning method that models the inference of logic rules with more expressive syntax than previous methods. GLIDR uses a differentiable message passing inference algorithm that generalizes previous chain-like rule learning methods to allow rules with features like branches and cycles. GLIDR has a simple and expressive rule search space which is parameterized by a limit on the maximum number of free variables that may be included in a rule. Explicit logic rules can be extracted from the weights of a GLIDR model for use with symbolic solvers. We demonstrate that GLIDR can significantly outperform existing rule learning methods on knowledge graph completion tasks and even compete with embedding methods despite the inherent disadvantage of being a structure-only prediction method. We show that rules extracted from GLIDR retain significant predictive performance, and that GLIDR is highly robust to training data noise. Finally, we demonstrate that GLIDR can be chained with deep neural networks and optimized end-to-end for rule learning on arbitrary data modalities.",
    "source": "arXiv"
  },
  {
    "title": "Refactoring-Aware Patch Integration Across Structurally Divergent Java Forks",
    "title_es": "Refactoring-Aware Patch Integration Across Structurally Divergent Java Forks",
    "url": "https://arxiv.org/abs/2508.06718",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06718v1 Announce Type: new \nAbstract: While most forks on platforms like GitHub are short-lived and used for social collaboration, a smaller but impactful subset evolve into long-lived forks, referred to here as variants, that maintain independent development trajectories. Integrating bug-fix patches across such divergent variants poses challenges due to structural drift, including refactorings that rename, relocate, or reorganize code elements and obscure semantic correspondence. This paper presents an empirical study of patch integration failures in 14 divergent pair of variants and introduces RePatch, a refactoring-aware integration system for Java repositories. RePatch extends the RefMerge framework, originally designed for symmetric merges, by supporting asymmetric patch transfer. RePatch inverts refactorings in both the source and target to realign the patch context, applies the patch, and replays the transformations to preserve the intent of the variant. In our evaluation of 478 bug-fix pull requests, Git cherry-pick fails in 64.4% of cases due to structural misalignments, while RePatch successfully integrates 52.8% of the previously failing patches. These results highlight the limitations of syntax-based tools and the need for semantic reasoning in variant-aware patch propagation.",
    "source": "arXiv"
  },
  {
    "title": "Improved Obstacle Avoidance for Autonomous Robots with ORCA-FLC",
    "title_es": "Improved Obstacle Avoidance for Autonomous Robots with ORCA-FLC",
    "url": "https://arxiv.org/abs/2508.06722",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06722v1 Announce Type: new \nAbstract: Obstacle avoidance enables autonomous agents and robots to operate safely and efficiently in dynamic and complex environments, reducing the risk of collisions and damage. For a robot or autonomous system to successfully navigate through obstacles, it must be able to detect such obstacles. While numerous collision avoidance algorithms like the dynamic window approach (DWA), timed elastic bands (TEB), and reciprocal velocity obstacles (RVO) have been proposed, they may lead to suboptimal paths due to fixed weights, be computationally expensive, or have limited adaptability to dynamic obstacles in multi-agent environments. Optimal reciprocal collision avoidance (ORCA), which improves on RVO, provides smoother trajectories and stronger collision avoidance guarantees. We propose ORCA-FL to improve on ORCA by using fuzzy logic controllers (FLCs) to better handle uncertainty and imprecision for obstacle avoidance in path planning. Numerous multi-agent experiments are conducted and it is shown that ORCA-FL can outperform ORCA in reducing the number of collision if the agent has a velocity that exceeds a certain threshold. In addition, a proposed algorithm for improving ORCA-FL using fuzzy Q reinforcement learning (FQL) is detailed for optimizing and tuning FLCs.",
    "source": "arXiv"
  },
  {
    "title": "Secure and Decentralized Peer-to-Peer Energy Transactions using Blockchain Technology",
    "title_es": "Secure and Decentralized Peer-to-Peer Energy Transactions using Blockchain Technology",
    "url": "https://arxiv.org/abs/2508.06728",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06728v1 Announce Type: new \nAbstract: This paper presents an optimal peer-to-peer (P2P) energy transaction mechanism leveraging decentralized blockchain technology to enable a secure and scalable retail electricity market for the increasing penetration of distributed energy resources (DERs). A decentralized bidding strategy is proposed to maximize individual profits while collectively enhancing social welfare. The market design and transaction processes are simulated using the Ethereum testnet, demonstrating the blockchain network's capability to ensure secure, transparent, and sustainable P2P energy trading among DER participants.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis",
    "title_es": "Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis",
    "url": "https://arxiv.org/abs/2508.06729",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06729v1 Announce Type: new \nAbstract: Oral histories are vital records of lived experience, particularly within communities affected by systemic injustice and historical erasure. Effective and efficient analysis of their oral history archives can promote access and understanding of the oral histories. However, Large-scale analysis of these archives remains limited due to their unstructured format, emotional complexity, and high annotation costs. This paper presents a scalable framework to automate semantic and sentiment annotation for Japanese American Incarceration Oral History. Using LLMs, we construct a high-quality dataset, evaluate multiple models, and test prompt engineering strategies in historically sensitive contexts. Our multiphase approach combines expert annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We labeled 558 sentences from 15 narrators for sentiment and semantic classification, then evaluated zero-shot, few-shot, and RAG strategies. For semantic classification, ChatGPT achieved the highest F1 score (88.71%), followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models showing comparable results. The best prompt configurations were used to annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our findings show that LLMs can effectively perform semantic and sentiment annotation across large oral history collections when guided by well-designed prompts. This study provides a reusable annotation pipeline and practical guidance for applying LLMs in culturally sensitive archival analysis. By bridging archival ethics with scalable NLP techniques, this work lays the groundwork for responsible use of artificial intelligence in digital humanities and preservation of collective memory. GitHub: https://github.com/kc6699c/LLM4OralHistoryAnalysis.",
    "source": "arXiv"
  },
  {
    "title": "Reservoir computing with large valid prediction time for the Lorenz system",
    "title_es": "Reservoir computing with large valid prediction time for the Lorenz system",
    "url": "https://arxiv.org/abs/2508.06730",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06730v1 Announce Type: new \nAbstract: We study the dependence of the Valid Prediction Time (VPT) of Reservoir Computers (RCs) on hyperparameters including the regularization coefficient, reservoir size, and spectral radius. Under carefully chosen conditions, the RC can achieve approximately 70% of a benchmark performance, based on the output of a single prediction step used as initial conditions for the Lorenz equations. We report high VPT values (>30 Lyapunov times), as we are predicting a noiseless system where overfitting can be beneficial. While these conditions may not hold for noisy systems, they could still be useful for real-world applications with limited noise. Furthermore, utilizing knowledge of the Lyapunov exponent, we find that the VPT can be predicted by the error in the first few prediction steps, offering a computationally efficient evaluation method. We emphasize the importance of the numerical solver used to generate the Lorenz dataset and define a Valid Ground Truth Time (VGTT), during which the outputs of several common solvers agree. A VPT exceeding the VGTT is not meaningful, as a different solver could produce a different result. Lastly, we identify two spectral radius regimes that achieve large VPT: a small radius near zero, resulting in simple but stable operation, and a larger radius operating at the \"edge of chaos.\"",
    "source": "arXiv"
  },
  {
    "title": "ClimateSOM: A Visual Analysis Workflow for Climate Ensemble Datasets",
    "title_es": "ClimateSOM: A Visual Analysis Workflow for Climate Ensemble Datasets",
    "url": "https://arxiv.org/abs/2508.06732",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06732v1 Announce Type: new \nAbstract: Ensemble datasets are ever more prevalent in various scientific domains. In climate science, ensemble datasets are used to capture variability in projections under plausible future conditions including greenhouse and aerosol emissions. Each ensemble model run produces projections that are fundamentally similar yet meaningfully distinct. Understanding this variability among ensemble model runs and analyzing its magnitude and patterns is a vital task for climate scientists. In this paper, we present ClimateSOM, a visual analysis workflow that leverages a self-organizing map (SOM) and Large Language Models (LLMs) to support interactive exploration and interpretation of climate ensemble datasets. The workflow abstracts climate ensemble model runs - spatiotemporal time series - into a distribution over a 2D space that captures the variability among the ensemble model runs using a SOM. LLMs are integrated to assist in sensemaking of this SOM-defined 2D space, the basis for the visual analysis tasks. In all, ClimateSOM enables users to explore the variability among ensemble model runs, identify patterns, compare and cluster the ensemble model runs. To demonstrate the utility of ClimateSOM, we apply the workflow to an ensemble dataset of precipitation projections over California and the Northwestern United States. Furthermore, we conduct a short evaluation of our LLM integration, and conduct an expert review of the visual workflow and the insights from the case studies with six domain experts to evaluate our approach and its utility.",
    "source": "arXiv"
  },
  {
    "title": "Mitigating Distribution Shift in Graph-Based Android Malware Classification via Function Metadata and LLM Embeddings",
    "title_es": "Mitigating Distribution Shift in Graph-Based Android Malware Classification via Function Metadata and LLM Embeddings",
    "url": "https://arxiv.org/abs/2508.06734",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06734v1 Announce Type: new \nAbstract: Graph-based malware classifiers can achieve over 94% accuracy on standard Android datasets, yet we find they suffer accuracy drops of up to 45% when evaluated on previously unseen malware variants from the same family - a scenario where strong generalization would typically be expected. This highlights a key limitation in existing approaches: both the model architectures and their structure-only representations often fail to capture deeper semantic patterns. In this work, we propose a robust semantic enrichment framework that enhances function call graphs with contextual features, including function-level metadata and, when available, code embeddings derived from large language models. The framework is designed to operate under real-world constraints where feature availability is inconsistent, and supports flexible integration of semantic signals. To evaluate generalization under realistic domain and temporal shifts, we introduce two new benchmarks: MalNet-Tiny-Common and MalNet-Tiny-Distinct, constructed using malware family partitioning to simulate cross-family generalization and evolving threat behavior. Experiments across multiple graph neural network backbones show that our method improves classification performance by up to 8% under distribution shift and consistently enhances robustness when integrated with adaptation-based methods. These results offer a practical path toward building resilient malware detection systems in evolving threat environments.",
    "source": "arXiv"
  },
  {
    "title": "ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search",
    "title_es": "ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search",
    "url": "https://arxiv.org/abs/2508.06736",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06736v1 Announce Type: new \nAbstract: Solving Mixed-Integer Programming (MIP) problems often requires substantial computational resources due to their combinatorial nature. Parallelization has emerged as a critical strategy to accelerate solution times and enhance scalability to tackle large, complex instances. This paper investigates the parallelization capabilities of Balans, a recently proposed multi-armed bandits-based adaptive large neighborhood search for MIPs. While Balans's modular architecture inherently supports parallel exploration of diverse parameter configurations, this potential has not been thoroughly examined. To address this gap, we introduce ParBalans, an extension that leverages both solver-level and algorithmic-level parallelism to improve performance on challenging MIP instances. Our experimental results demonstrate that ParBalans exhibits competitive performance compared to the state-of-the-art commercial solver Gurobi, particularly on hard optimization benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Computable Poincar\\'e--Friedrichs constants for the $L^{p}$ de~Rham complex over convex domains and domains with shellable triangulations",
    "title_es": "Computable Poincar\\'e--Friedrichs constants for the $L^{p}$ de~Rham complex over convex domains and domains with shellable triangulations",
    "url": "https://arxiv.org/abs/2508.06741",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06741v1 Announce Type: new \nAbstract: We construct potentials for the exterior derivative, in particular, for the gradient, the curl, and the divergence operators, over domains with shellable triangulations. Notably, the class of shellable triangulations includes local patches (stars) in two or three dimensions. The operator norms of our potentials satisfy explicitly computable bounds that depend only on the geometry. We thus compute upper bounds for constants in Poincar\\'e--Friedrichs inequalities and lower bounds for the eigenvalues of vector Laplacians. As an additional result with independent standing, we establish Poincar\\'e--Friedrichs inequalities with computable constants for the $L^{p}$ de~Rham complex over bounded convex domains, derived as explicit operator norms of regularized Poincar\\'e and Bogovski\\u{\\i} potential operators. We express all our main results in the calculus of differential forms and treat the gradient, curl, and divergence operators as instances of the exterior derivative. Computational examples illustrate the theoretical findings.",
    "source": "arXiv"
  },
  {
    "title": "Learning Causal Structure Distributions for Robust Planning",
    "title_es": "Learning Causal Structure Distributions for Robust Planning",
    "url": "https://arxiv.org/abs/2508.06742",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06742v1 Announce Type: new \nAbstract: Structural causal models describe how the components of a robotic system interact. They provide both structural and functional information about the relationships that are present in the system. The structural information outlines the variables among which there is interaction. The functional information describes how such interactions work, via equations or learned models. In this paper we find that learning the functional relationships while accounting for the uncertainty about the structural information leads to more robust dynamics models which improves downstream planning, while using significantly lower computational resources. This in contrast with common model-learning methods that ignore the causal structure and fail to leverage the sparsity of interactions in robotic systems. We achieve this by estimating a causal structure distribution that is used to sample causal graphs that inform the latent-space representations in an encoder-multidecoder probabilistic model. We show that our model can be used to learn the dynamics of a robot, which together with a sampling-based planner can be used to perform new tasks in novel environments, provided an objective function for the new requirement is available. We validate our method using manipulators and mobile robots in both simulation and the real-world. Additionally, we validate the learned dynamics' adaptability and increased robustness to corrupted inputs and changes in the environment, which is highly desirable in challenging real-world robotics scenarios. Video: https://youtu.be/X6k5t7OOnNc.",
    "source": "arXiv"
  },
  {
    "title": "Analysis of Schedule-Free Nonconvex Optimization",
    "title_es": "Analysis of Schedule-Free Nonconvex Optimization",
    "url": "https://arxiv.org/abs/2508.06743",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06743v1 Announce Type: new \nAbstract: First-order methods underpin most large-scale learning algorithms, yet their classical convergence guarantees hinge on carefully scheduled step-sizes that depend on the total horizon $T$, which is rarely known in advance. The Schedule-Free (SF) method promises optimal performance with hyperparameters that are independent of $T$ by interpolating between Polyak--Ruppert averaging and momentum, but nonconvex analysis of SF has been limited or reliant on strong global assumptions. We introduce a robust Lyapunov framework that, under only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step descent inequality. This yields horizon-agnostic bounds in the nonconvex setting: $O(1/\\log T)$ for constant step + PR averaging, $O(\\log T/T)$ for a linearly growing step-size, and a continuum of $O(T^{-(1-\\alpha)})$ rates for polynomial averaging. We complement these proofs with Performance Estimation Problem (PEP) experiments that numerically validate our rates and suggest that our $O(1/\\log T)$ bound on the original nonconvex SF algorithm may tighten to $O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex optimization and charts future directions for optimal nonconvex rates.",
    "source": "arXiv"
  },
  {
    "title": "Robust-Sub-Gaussian Model Predictive Control for Safe Ultrasound-Image-Guided Robotic Spinal Surgery",
    "title_es": "Robust-Sub-Gaussian Model Predictive Control for Safe Ultrasound-Image-Guided Robotic Spinal Surgery",
    "url": "https://arxiv.org/abs/2508.06744",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06744v1 Announce Type: new \nAbstract: Safety-critical control using high-dimensional sensory feedback from optical data (e.g., images, point clouds) poses significant challenges in domains like autonomous driving and robotic surgery. Control can rely on low-dimensional states estimated from high-dimensional data. However, the estimation errors often follow complex, unknown distributions that standard probabilistic models fail to capture, making formal safety guarantees challenging. In this work, we introduce a novel characterization of these general estimation errors using sub-Gaussian noise with bounded mean. We develop a new technique for uncertainty propagation of proposed noise characterization in linear systems, which combines robust set-based methods with the propagation of sub-Gaussian variance proxies. We further develop a Model Predictive Control (MPC) framework that provides closed-loop safety guarantees for linear systems under the proposed noise assumption. We apply this MPC approach in an ultrasound-image-guided robotic spinal surgery pipeline, which contains deep-learning-based semantic segmentation, image-based registration, high-level optimization-based planning, and low-level robotic control. To validate the pipeline, we developed a realistic simulation environment integrating real human anatomy, robot dynamics, efficient ultrasound simulation, as well as in-vivo data of breathing motion and drilling force. Evaluation results in simulation demonstrate the potential of our approach for solving complex image-guided robotic surgery task while ensuring safety.",
    "source": "arXiv"
  },
  {
    "title": "Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism",
    "title_es": "Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism",
    "url": "https://arxiv.org/abs/2508.06746",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06746v1 Announce Type: new \nAbstract: With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in sensitive applications, such as urban monitoring, emergency response, and secure sensing, ensuring reliable connectivity and covert communication has become increasingly vital. However, dynamic mobility and exposure risks pose significant challenges. To tackle these challenges, this paper proposes a self-organizing UAV network framework combining Graph Diffusion-based Policy Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The GDPO method uses generative AI to dynamically generate sparse but well-connected topologies, enabling flexible adaptation to changing node distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game (SG)-based incentive mechanism guides self-interested UAVs to choose relay behaviors and neighbor links that support cooperation and enhance covert communication. Extensive experiments are conducted to validate the effectiveness of the proposed framework in terms of model convergence, topology generation quality, and enhancement of covert communication performance.",
    "source": "arXiv"
  },
  {
    "title": "Toward a Logic of Generalization about Visualization as a Decision Aid",
    "title_es": "Toward a Logic of Generalization about Visualization as a Decision Aid",
    "url": "https://arxiv.org/abs/2508.06751",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06751v1 Announce Type: new \nAbstract: Visualization as a discipline often grapples with generalization by reasoning about how study results on the efficacy of a tool in one context might apply to another context. This work offers an account of the logic of generalization in visualization research and argues that it struggles in particular with applications of visualization as a decision aid. We use decision theory to define the dimensions on which decision problems can vary, and we present an analysis of heterogeneity in scenarios where visualization supports decision-making. Our findings identify utility as a focal and under-examined concept in visualization research on decision-making, demonstrating how the visualization community's logic of generalization might benefit from using decision theory as a lens for understanding context variation.",
    "source": "arXiv"
  },
  {
    "title": "Pushing the Envelope of LLM Inference on AI-PC",
    "title_es": "Pushing the Envelope of LLM Inference on AI-PC",
    "url": "https://arxiv.org/abs/2508.06753",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06753v1 Announce Type: new \nAbstract: The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the perplexity and end-task performance of their full-precision counterparts using the same model size, is ushering in a new era of LLM inference for resource-constrained environments such as edge devices and AI PCs. While these quantization advances promise models that are more cost-effective in terms of latency, memory, throughput, and energy consumption, the computational efficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp) used to deploy them remains underexplored. In this work, we take a bottom-up approach: we first design and implement 1-bit and 2-bit microkernels optimized for modern CPUs, achieving peak computational efficiency across a variety of CPU platforms. We integrate these microkernels into a state-of-the-art LLM inference framework, namely PyTorch-TPP, and present end-to-end inference results with 2-bit models that outperform the current SOTA runtime bitnet.cpp by up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model inference. Our optimized runtime advances the state of LLM inference on AI PCs and edge devices, paving the way for efficient deployment of ultra-low-bit LLM models.",
    "source": "arXiv"
  },
  {
    "title": "A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks",
    "title_es": "A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks",
    "url": "https://arxiv.org/abs/2508.06754",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06754v1 Announce Type: new \nAbstract: We introduce a modular prompting framework that supports safer and more adaptive use of large language models (LLMs) across dynamic, user-centered tasks. Grounded in human learning theory, particularly the Zone of Proximal Development (ZPD), our method combines a natural language boundary prompt with a control schema encoded with fuzzy scaffolding logic and adaptation rules. This architecture enables LLMs to modulate behavior in response to user state without requiring fine-tuning or external orchestration. In a simulated intelligent tutoring setting, the framework improves scaffolding quality, adaptivity, and instructional alignment across multiple models, outperforming standard prompting baselines. Evaluation is conducted using rubric-based LLM graders at scale. While initially developed for education, the framework has shown promise in other interaction-heavy domains, such as procedural content generation for games. Designed for safe deployment, it provides a reusable methodology for structuring interpretable, goal-aligned LLM behavior in uncertain or evolving contexts.",
    "source": "arXiv"
  },
  {
    "title": "Many-Turn Jailbreaking",
    "title_es": "Many-Turn Jailbreaking",
    "url": "https://arxiv.org/abs/2508.06755",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06755v1 Announce Type: new \nAbstract: Current jailbreaking work on large language models (LLMs) aims to elicit unsafe outputs from given prompts. However, it only focuses on single-turn jailbreaking targeting one specific query. On the contrary, the advanced LLMs are designed to handle extremely long contexts and can thus conduct multi-turn conversations. So, we propose exploring multi-turn jailbreaking, in which the jailbroken LLMs are continuously tested on more than the first-turn conversation or a single target query. This is an even more serious threat because 1) it is common for users to continue asking relevant follow-up questions to clarify certain jailbroken details, and 2) it is also possible that the initial round of jailbreaking causes the LLMs to respond to additional irrelevant questions consistently. As the first step (First draft done at June 2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and closed-source models and provide novel insights into this new safety threat. By revealing this new vulnerability, we aim to call for community efforts to build safer LLMs and pave the way for a more in-depth understanding of jailbreaking LLMs.",
    "source": "arXiv"
  },
  {
    "title": "FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI",
    "title_es": "FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI",
    "url": "https://arxiv.org/abs/2508.06756",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06756v1 Announce Type: new \nAbstract: Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is essential for effective glioma management. Traditional methods rely on invasive tissue sampling, which may fail to capture a tumor's spatial heterogeneity. While deep learning models have shown promise in molecular profiling, their performance is often limited by scarce annotated data. In contrast, foundation deep learning models offer a more generalizable approach for glioma imaging biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch signals associated with IDH mutation. The model was trained and validated on a diverse, multi-center cohort of 1705 glioma patients from six public datasets. Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE and CMD modules are essential for improving predictive accuracy. By integrating large-scale pretraining and task-specific fine-tuning, FoundBioNet enables generalizable glioma characterization. This approach enhances diagnostic accuracy and interpretability, with the potential to enable more personalized patient care.",
    "source": "arXiv"
  },
  {
    "title": "VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions",
    "title_es": "VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions",
    "url": "https://arxiv.org/abs/2508.06757",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06757v1 Announce Type: new \nAbstract: Human pose and shape (HPS) estimation methods have been extensively studied, with many demonstrating high zero-shot performance on in-the-wild images and videos. However, these methods often struggle in challenging scenarios involving complex human poses or significant occlusions. Although some studies address 3D human pose estimation under occlusion, they typically evaluate performance on datasets that lack realistic or substantial occlusions, e.g., most existing datasets introduce occlusions with random patches over the human or clipart-style overlays, which may not reflect real-world challenges. To bridge this gap in realistic occlusion datasets, we introduce a novel benchmark dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed this dataset using advanced computer graphics rendering techniques, incorporating diverse real-world occlusion scenarios, clothing textures, and human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and quantitative improvements across multiple public datasets, as well as on the test split of our dataset, while comparing its performance with other state-of-the-art methods. Furthermore, we leveraged our dataset to enhance human detection performance under occlusion by fine-tuning an existing object detector, YOLO11, thus leading to a robust end-to-end HPS estimation system under occlusions. Overall, this dataset serves as a valuable resource for future research aimed at benchmarking methods designed to handle occlusions, offering a more realistic alternative to existing occlusion datasets. See the Project page for code and dataset:https://yashgarg98.github.io/VOccl3D-dataset/",
    "source": "arXiv"
  },
  {
    "title": "Understanding Privacy Norms Around LLM-Based Chatbots: A Contextual Integrity Perspective",
    "title_es": "Understanding Privacy Norms Around LLM-Based Chatbots: A Contextual Integrity Perspective",
    "url": "https://arxiv.org/abs/2508.06760",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06760v1 Announce Type: new \nAbstract: LLM-driven chatbots like ChatGPT have created large volumes of conversational data, but little is known about how user privacy expectations are evolving with this technology. We conduct a survey experiment with 300 US ChatGPT users to understand emerging privacy norms for sharing chatbot data. Our findings reveal a stark disconnect between user concerns and behavior: 82% of respondents rated chatbot conversations as sensitive or highly sensitive - more than email or social media posts - but nearly half reported discussing health topics and over one-third discussed personal finances with ChatGPT. Participants expressed strong privacy concerns (t(299) = 8.5, p < .01) and doubted their conversations would remain private (t(299) = -6.9, p < .01). Despite this, respondents uniformly rejected sharing personal data (search history, emails, device access) for improved services, even in exchange for premium features worth $200. To identify which factors influence appropriate chatbot data sharing, we presented participants with factorial vignettes manipulating seven contextual factors. Linear mixed models revealed that only the transmission factors such as informed consent, data anonymization, or the removal of personally identifiable information, significantly affected perceptions of appropriateness and concern for data access. Surprisingly, contextual factors including the recipient of the data (hospital vs. tech company), purpose (research vs. advertising), type of content, and geographic location did not show significant effects. Our results suggest that users apply consistent baseline privacy expectations to chatbot data, prioritizing procedural safeguards over recipient trustworthiness. This has important implications for emerging agentic AI systems that assume user willingness to integrate personal data across platforms.",
    "source": "arXiv"
  },
  {
    "title": "SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding",
    "title_es": "SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding",
    "url": "https://arxiv.org/abs/2508.06763",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06763v1 Announce Type: new \nAbstract: Multimodal large language models (MLLMs) have achieved remarkable progress across a range of vision-language tasks and demonstrate strong potential for traffic accident understanding. However, existing MLLMs in this domain primarily focus on coarse-grained image-level or video-level comprehension and often struggle to handle fine-grained visual details or localized scene components, limiting their applicability in complex accident scenarios. To address these limitations, we propose SafePLUG, a novel framework that empowers MLLMs with both Pixel-Level Understanding and temporal Grounding for comprehensive traffic accident analysis. SafePLUG supports both arbitrary-shaped visual prompts for region-aware question answering and pixel-level segmentation based on language instructions, while also enabling the recognition of temporally anchored events in traffic accident scenarios. To advance the development of MLLMs for traffic accident understanding, we curate a new dataset containing multimodal question-answer pairs centered on diverse accident scenarios, with detailed pixel-level annotations and temporal event boundaries. Experimental results show that SafePLUG achieves strong performance on multiple tasks, including region-based question answering, pixel-level segmentation, temporal event localization, and accident event understanding. These capabilities lay a foundation for fine-grained understanding of complex traffic scenes, with the potential to improve driving safety and enhance situational awareness in smart transportation systems. The code, dataset, and model checkpoints will be made publicly available at: https://zihaosheng.github.io/SafePLUG",
    "source": "arXiv"
  },
  {
    "title": "Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning",
    "title_es": "Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning",
    "url": "https://arxiv.org/abs/2508.06765",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06765v1 Announce Type: new \nAbstract: Collaboratively fine-tuning (FT) large language models (LLMs) over heterogeneous mobile devices fosters immense potential applications of personalized intelligence. However, such a vision faces critical system challenges. Conventional federated LLM FT approaches place prohibitive computational and memory burdens on mobile hardware, and their synchronous model aggregation protocols stall for slower devices. In this paper, we propose Fed MobiLLM, a novel design to facilitate efficient federated LLM FT across mobile devices with diverse computing/communication speeds and local model architectures. In particular, Fed MobiLLM implements a pioneering server-assisted federated side-tuning paradigm. Briefly, mobile devices perform lightweight forward propagation computations on local data using their frozen pre-scaled backbone LLMs, and then upload selected intermediate activations. The server trains a shared side-network independently, eliminating client-side backpropagation and enabling asynchronous updates. To bridge model heterogeneity across different devices, we introduce an adaptive layer-wise feature alignment method, which ensures consistent representations for collaboratively tuning a shared side network. Extensive experimental results demonstrate that Fed MobiLLM can maintain robust fine-tuning performance while achieving extremely low on-device memory, with at least 95.2% reduction in computation overhead, 93.2% reduction in communication costs and 5.1x faster convergence compared to existing methods, validating its efficacy for practical LLM adaptation over heterogeneous mobile devices.",
    "source": "arXiv"
  },
  {
    "title": "PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems",
    "title_es": "PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems",
    "url": "https://arxiv.org/abs/2508.06767",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06767v1 Announce Type: new \nAbstract: Digital Twins (DTs) are transforming industries through advanced data processing and analysis, positioning the world of DTs, Digital World, as a cornerstone of nextgeneration technologies including embodied AI. As robotics and automated systems scale, efficient data-sharing frameworks and robust algorithms become critical. We explore the pivotal role of data handling in next-gen networks, focusing on dynamics between application and network providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL) based multi-agent path finding (MAPF). By adopting a Centralized Training with Decentralized Execution (CTDE) framework and asynchronous actor-learner architectures, PANAMA accelerates training while enabling autonomous task execution by embodied AI. Our approach demonstrates superior pathfinding performance in accuracy, speed, and scalability compared to existing benchmarks. Through simulations, we highlight optimized data-sharing strategies for scalable, automated systems, ensuring resilience in complex, real-world environments. PANAMA bridges the gap between network-aware decision-making and robust multi-agent coordination, advancing the synergy between DTs, wireless networks, and AI-driven automation.",
    "source": "arXiv"
  },
  {
    "title": "DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging",
    "title_es": "DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging",
    "url": "https://arxiv.org/abs/2508.06768",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06768v1 Announce Type: new \nAbstract: Intraoperative ultrasound imaging provides real-time guidance during numerous surgical procedures, but its interpretation is complicated by noise, artifacts, and poor alignment with high-resolution preoperative MRI/CT scans. To bridge the gap between reoperative planning and intraoperative guidance, we present DiffUS, a physics-based, differentiable ultrasound renderer that synthesizes realistic B-mode images from volumetric imaging. DiffUS first converts MRI 3D scans into acoustic impedance volumes using a machine learning approach. Next, we simulate ultrasound beam propagation using ray tracing with coupled reflection-transmission equations. DiffUS formulates wave propagation as a sparse linear system that captures multiple internal reflections. Finally, we reconstruct B-mode images via depth-resolved echo extraction across fan-shaped acquisition geometry, incorporating realistic artifacts including speckle noise and depth-dependent degradation. DiffUS is entirely implemented as differentiable tensor operations in PyTorch, enabling gradient-based optimization for downstream applications such as slice-to-volume registration and volumetric reconstruction. Evaluation on the ReMIND dataset demonstrates DiffUS's ability to generate anatomically accurate ultrasound images from brain MRI data.",
    "source": "arXiv"
  },
  {
    "title": "A Portable Multi-GPU Solver for Collisional Plasmas with Coulombic Interactions",
    "title_es": "A Portable Multi-GPU Solver for Collisional Plasmas with Coulombic Interactions",
    "url": "https://arxiv.org/abs/2508.06771",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06771v1 Announce Type: new \nAbstract: We study parallel particle-in-cell (PIC) methods for low-temperature plasmas (LTPs), which discretize kinetic formulations that capture the time evolution of the probability density function of particles as a function of position and velocity. We use a kinetic description for electrons and a fluid approximation for heavy species. In this paper, we focus on GPU acceleration of algorithms for velocity-space interactions and in particular, collisions of electrons with neutrals, ions, and electrons. Our work has two thrusts. The first is algorithmic exploration and analysis. The second is examining the viability of rapid-prototyping implementations using Python-based HPC tools, in particular PyKokkos. We discuss several common PIC kernels and present performance results on NVIDIA Volta V100 and AMD MI250X GPUs. Overall, the MI250X is slightly faster for most kernels but shows more sensitivity to register pressure. We also report scaling results for a distributed memory implementation on up to 16 MPI ranks.",
    "source": "arXiv"
  },
  {
    "title": "Story Ribbons: Reimagining Storyline Visualizations with Large Language Models",
    "title_es": "Story Ribbons: Reimagining Storyline Visualizations with Large Language Models",
    "url": "https://arxiv.org/abs/2508.06772",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06772v1 Announce Type: new \nAbstract: Analyzing literature involves tracking interactions between characters, locations, and themes. Visualization has the potential to facilitate the mapping and analysis of these complex relationships, but capturing structured information from unstructured story data remains a challenge. As large language models (LLMs) continue to advance, we see an opportunity to use their text processing and analysis capabilities to augment and reimagine existing storyline visualization techniques. Toward this goal, we introduce an LLM-driven data parsing pipeline that automatically extracts relevant narrative information from novels and scripts. We then apply this pipeline to create Story Ribbons, an interactive visualization system that helps novice and expert literary analysts explore detailed character and theme trajectories at multiple narrative levels. Through pipeline evaluations and user studies with Story Ribbons on 36 literary works, we demonstrate the potential of LLMs to streamline narrative visualization creation and reveal new insights about familiar stories. We also describe current limitations of AI-based systems, and interaction motifs designed to address these issues.",
    "source": "arXiv"
  },
  {
    "title": "Methodology for Business Intelligence Solutions in Internet Banking Companies",
    "title_es": "Methodology for Business Intelligence Solutions in Internet Banking Companies",
    "url": "https://arxiv.org/abs/2508.06773",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06773v1 Announce Type: new \nAbstract: Business intelligence in the banking industry has been studied extensively in the last decade; however, business executives still do not perceive efficiency in the decision-making process since the management and treatment of information are very timeconsuming for the deliverer, generating costs in the process. On the other hand, there is no formal methodology for developing business intelligence solutions in this sector. This work aims to optimize decision-making in a business unit that works with internet banking companies, reducing the time, the number of people, and the costs involved in decision-making. To meet the objective, basic and applied research was conducted. The basic research allowed the construction of a new methodology from a study of critical success factors and approaches from the business intelligence literature. The applied research involved the implementation of a business intelligence solution applying the new methodology in a pre-experimental study. Thirty decision-making processes were analyzed using pre-test and post-test data. Tools such as a stopwatch and observation were used to collect and record data on time spent, the number of people, and the decision-making costs. This information was processed in the specialized Minitab18 statistical software, which allowed the observation and confirmation of relevant results regarding time reduction, the number of people, and the costs generated. Therefore, it was concluded that the business intelligence solution, applying the new methodology, optimized decision making in the business unit that works with internet banking for companies.",
    "source": "arXiv"
  },
  {
    "title": "Approximating High-Dimensional Earth Mover's Distance as Fast as Closest Pair",
    "title_es": "Approximating High-Dimensional Earth Mover's Distance as Fast as Closest Pair",
    "url": "https://arxiv.org/abs/2508.06774",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06774v1 Announce Type: new \nAbstract: We give a reduction from $(1+\\varepsilon)$-approximate Earth Mover's Distance (EMD) to $(1+\\varepsilon)$-approximate Closest Pair (CP). As a consequence, we improve the fastest known approximation algorithm for high-dimensional EMD. Here, given $p\\in [1, 2]$ and two sets of $n$ points $X,Y \\subseteq (\\mathbb R^d,\\ell_p)$, their EMD is the minimum cost of a perfect matching between $X$ and $Y$, where the cost of matching two vectors is their $\\ell_p$ distance. Further, CP is the basic problem of finding a pair of points realizing $\\min_{x \\in X, y\\in Y} ||x-y||_p$. Our contribution is twofold: we show that if a $(1+\\varepsilon)$-approximate CP can be computed in time $n^{2-\\phi}$, then a $1+O(\\varepsilon)$ approximation to EMD can be computed in time $n^{2-\\Omega(\\phi)}$; plugging in the fastest known algorithm for CP [Alman, Chan, Williams FOCS'16], we obtain a $(1+\\varepsilon)$-approximation algorithm for EMD running in time $n^{2-\\tilde{\\Omega}(\\varepsilon^{1/3})}$ for high-dimensional point sets, which improves over the prior fastest running time of $n^{2-\\Omega(\\varepsilon^2)}$ [Andoni, Zhang FOCS'23]. Our main technical contribution is a sublinear implementation of the Multiplicative Weights Update framework for EMD. Specifically, we demonstrate that the updates can be executed without ever explicitly computing or storing the weights; instead, we exploit the underlying geometric structure to perform the updates implicitly.",
    "source": "arXiv"
  },
  {
    "title": "Visualization Vibes: The Socio-Indexical Function of Visualization Design",
    "title_es": "Visualization Vibes: The Socio-Indexical Function of Visualization Design",
    "url": "https://arxiv.org/abs/2508.06775",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06775v1 Announce Type: new \nAbstract: In contemporary information ecologies saturated with misinformation, disinformation, and a distrust of science itself, public data communication faces significant hurdles. Although visualization research has broadened criteria for effective design, governing paradigms privilege the accurate and efficient transmission of data. Drawing on theory from linguistic anthropology, we argue that such approaches-focused on encoding and decoding propositional content-cannot fully account for how people engage with visualizations and why particular visualizations might invite adversarial or receptive responses. In this paper, we present evidence that data visualizations communicate not only semantic, propositional meaning$\\unicode{x2013}$meaning about data$\\unicode{x2013}$but also social, indexical meaning$\\unicode{x2013}$meaning beyond data. From a series of ethnographically-informed interviews, we document how readers make rich and varied assessments of a visualization's \"vibes\"$\\unicode{x2013}$inferences about the social provenance of a visualization based on its design features. Furthermore, these social attributions have the power to influence reception, as readers' decisions about how to engage with a visualization concern not only content, or even aesthetic appeal, but also their sense of alignment or disalignment with the entities they imagine to be involved in its production and circulation. We argue these inferences hinge on a function of human sign systems that has thus far been little studied in data visualization: socio-indexicality, whereby the formal features (rather than the content) of communication evoke social contexts, identities, and characteristics. Demonstrating the presence and significance of this socio-indexical function in visualization, this paper offers both a conceptual foundation and practical intervention for troubleshooting breakdowns in public data communication.",
    "source": "arXiv"
  },
  {
    "title": "Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift",
    "title_es": "Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift",
    "url": "https://arxiv.org/abs/2508.06776",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06776v1 Announce Type: new \nAbstract: We present Zero-Direction Probing (ZDP), a theory-only framework for detecting model drift from null directions of transformer activations without task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound for low-rank updates, and (iv) a logarithmic-regret guarantee for online null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with non-asymptotic tail bounds and a concentration inequality, yielding a-priori thresholds for drift under a Gaussian null model. These results show that monitoring right/left null spaces of layer activations and their Fisher geometry provides concrete, testable guarantees on representational change.",
    "source": "arXiv"
  },
  {
    "title": "Gender and Careers in Platform-Mediated Work: A Longitudinal Study of Online Freelancers",
    "title_es": "Gender and Careers in Platform-Mediated Work: A Longitudinal Study of Online Freelancers",
    "url": "https://arxiv.org/abs/2508.06778",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06778v1 Announce Type: new \nAbstract: We advance gender-inclusive research within the CSCW field by investigating the long-term gendered experiences of online freelancers on digital labor platforms. The prevalence of gender-based inequalities has attracted significant attention within the CSCW community. Yet, insights remain limited on how these inequalities shape workers' long-term experiences on digital labor platforms. Through a five-year longitudinal study of 105 freelancers on Upwork, we reveal persistent gender disparities that influence workers' long-term work and career trajectories, raising concerns about the sustainability of platform-mediated work. We advance the ongoing dialogue on gender inclusivity in the community by introducing the concepts of career disempowerment and platform-mediated motherhood penalty and by offering research and design implications for CSCW to foster more sustainable, equitable platform work environments for all genders.",
    "source": "arXiv"
  },
  {
    "title": "Learning a Vision-Based Footstep Planner for Hierarchical Walking Control",
    "title_es": "Learning a Vision-Based Footstep Planner for Hierarchical Walking Control",
    "url": "https://arxiv.org/abs/2508.06779",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06779v1 Announce Type: new \nAbstract: Bipedal robots demonstrate potential in navigating challenging terrains through dynamic ground contact. However, current frameworks often depend solely on proprioception or use manually designed visual pipelines, which are fragile in real-world settings and complicate real-time footstep planning in unstructured environments. To address this problem, we present a vision-based hierarchical control framework that integrates a reinforcement learning high-level footstep planner, which generates footstep commands based on a local elevation map, with a low-level Operational Space Controller that tracks the generated trajectories. We utilize the Angular Momentum Linear Inverted Pendulum model to construct a low-dimensional state representation to capture an informative encoding of the dynamics while reducing complexity. We evaluate our method across different terrain conditions using the underactuated bipedal robot Cassie and investigate the capabilities and challenges of our approach through simulation and hardware experiments.",
    "source": "arXiv"
  },
  {
    "title": "Modified Cubic B-spline Based Differential Quadrature Methods for Time-fractional Black-Scholes Equation",
    "title_es": "Modified Cubic B-spline Based Differential Quadrature Methods for Time-fractional Black-Scholes Equation",
    "url": "https://arxiv.org/abs/2508.06780",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06780v1 Announce Type: new \nAbstract: The time-fractional Black-Scholes equation (TFBSE) is intended to price the options for which the underlying price fluctuates within a correlated fractal transmission system. Although the TFBSE is an influential approach for grasping the long-term memory traits of financial markets, the non-local nature of fractional derivatives makes significant challenges in finding an accurate solution. We perform an efficient use of the differential quadrature method (DQM) based on modified cubic B-splines to solve the TFBSE governing European options. This paper constructs an algorithm by the combination of time fractional discretization using the finite difference method $L1$ and space discretization using the modified cubic B-spline-based differential quadrature method. Uniform meshes are considered for the discretization of both temporal and spatial domains. Theoretical stability has been established by finding an estimate for the maximum norm of the inverse operator regardless of the involvement of mesh parameters. We trigger the Neumann series theorem to obtain a uniform bound for the inverse operator under reasonable conditions on the mesh parameters. The numerical illustrations show that this implicit numerical method exhibits a fourth-order convergence in the space direction and the order $2-\\alpha$ in time. Moreover, we observe an enhancement in order of spatial convergence whenever $\\alpha$ tends to $0$. The results obtained are then compared with existing popular techniques to demonstrate the accuracy of modified cubic B-spline-based DQM.",
    "source": "arXiv"
  },
  {
    "title": "BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation",
    "title_es": "BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation",
    "url": "https://arxiv.org/abs/2508.06781",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06781v1 Announce Type: new \nAbstract: Neural sentence embedding models for dense retrieval typically rely on binary relevance labels, treating query-document pairs as either relevant or irrelevant. However, real-world relevance often exists on a continuum, and recent advances in large language models (LLMs) have made it feasible to scale the generation of fine-grained graded relevance labels. In this work, we propose BiXSE, a simple and effective pointwise training method that optimizes binary cross-entropy (BCE) over LLM-generated graded relevance scores. BiXSE interprets these scores as probabilistic targets, enabling granular supervision from a single labeled query-document pair per query. Unlike pairwise or listwise losses that require multiple annotated comparisons per query, BiXSE achieves strong performance with reduced annotation and compute costs by leveraging in-batch negatives. Extensive experiments across sentence embedding (MMTEB) and retrieval benchmarks (BEIR, TREC-DL) show that BiXSE consistently outperforms softmax-based contrastive learning (InfoNCE), and matches or exceeds strong pairwise ranking baselines when trained on LLM-supervised data. BiXSE offers a robust, scalable alternative for training dense retrieval models as graded relevance supervision becomes increasingly accessible.",
    "source": "arXiv"
  },
  {
    "title": "PROPS: Progressively Private Self-alignment of Large Language Models",
    "title_es": "PROPS: Progressively Private Self-alignment of Large Language Models",
    "url": "https://arxiv.org/abs/2508.06783",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06783v1 Announce Type: new \nAbstract: Alignment is a key step in developing Large Language Models (LLMs) using human feedback to ensure adherence to human values and societal norms. Dependence on human feedback raises privacy concerns about how much a labeler's preferences may reveal about their personal values, beliefs, and personality traits. Existing approaches, such as Differentially Private SGD (DP-SGD), provide rigorous privacy guarantees by privatizing gradients during fine-tuning and alignment but can provide more privacy than necessary as human preferences are tied only to labels of (prompt, response) pairs and can degrade model utility. This work focuses on LLM alignment with preference-level privacy, which preserves the privacy of preference labels provided by humans. We propose PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving alignment framework where privately aligned models in previous stages can serve as labelers for supplementing training data in the subsequent stages of alignment. We present theoretical guarantees for PROPS as well as comprehensive validation using multiple models (Pythia and GPT) and datasets (AlpacaEval, Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over existing methods while still providing high privacy. For the same privacy budget, alignment via PROPS can achieve up to 3x higher win-rates compared to DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based alignment.",
    "source": "arXiv"
  },
  {
    "title": "Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning",
    "title_es": "Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning",
    "url": "https://arxiv.org/abs/2508.06784",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06784v1 Announce Type: new \nAbstract: High-dimensional data, particularly in the form of high-order tensors, presents a major challenge in self-supervised learning. While MLP-based autoencoders (AE) are commonly employed, their dependence on flattening operations exacerbates the curse of dimensionality, leading to excessively large model sizes, high computational overhead, and challenging optimization for deep structural feature capture. Although existing tensor networks alleviate computational burdens through tensor decomposition techniques, most exhibit limited capability in learning non-linear relationships. To overcome these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder (MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear framework and employs a Pick-and-Unfold strategy, facilitating flexible per-mode encoding of high-order tensors via recursive unfold-encode-fold operations, effectively integrating tensor structural priors. Notably, MA-NTAE exhibits linear growth in computational complexity with tensor order and proportional growth with mode dimensions. Extensive experiments demonstrate MA-NTAE's performance advantages over standard AE and current tensor networks in compression and clustering tasks, which become increasingly pronounced for higher-order, higher-dimensional tensors.",
    "source": "arXiv"
  },
  {
    "title": "Quantifying Visualization Vibes: Measuring Socio-Indexicality at Scale",
    "title_es": "Quantifying Visualization Vibes: Measuring Socio-Indexicality at Scale",
    "url": "https://arxiv.org/abs/2508.06786",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06786v1 Announce Type: new \nAbstract: What impressions might readers form with visualizations that go beyond the data they encode? In this paper, we build on recent work that demonstrates the socio-indexical function of visualization, showing that visualizations communicate more than the data they explicitly encode. Bridging this with prior work examining public discourse about visualizations, we contribute an analytic framework for describing inferences about an artifact's social provenance. Via a series of attribution-elicitation surveys, we offer descriptive evidence that these social inferences: (1) can be studied asynchronously, (2) are not unique to a particular sociocultural group or a function of limited data literacy, and (3) may influence assessments of trust. Further, we demonstrate (4) how design features act in concert with the topic and underlying messages of an artifact's data to give rise to such 'beyond-data' readings. We conclude by discussing the design and research implications of inferences about social provenance, and why we believe broadening the scope of research on human factors in visualization to include sociocultural phenomena can yield actionable design recommendations to address urgent challenges in public data communication.",
    "source": "arXiv"
  },
  {
    "title": "Label Inference Attacks against Federated Unlearning",
    "title_es": "Label Inference Attacks against Federated Unlearning",
    "url": "https://arxiv.org/abs/2508.06789",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06789v1 Announce Type: new \nAbstract: Federated Unlearning (FU) has emerged as a promising solution to respond to the right to be forgotten of clients, by allowing clients to erase their data from global models without compromising model performance. Unfortunately, researchers find that the parameter variations of models induced by FU expose clients' data information, enabling attackers to infer the label of unlearning data, while label inference attacks against FU remain unexplored. In this paper, we introduce and analyze a new privacy threat against FU and propose a novel label inference attack, ULIA, which can infer unlearning data labels across three FU levels. To address the unique challenges of inferring labels via the models variations, we design a gradient-label mapping mechanism in ULIA that establishes a relationship between gradient variations and unlearning labels, enabling inferring labels on accumulated model variations. We evaluate ULIA on both IID and non-IID settings. Experimental results show that in the IID setting, ULIA achieves a 100% Attack Success Rate (ASR) under both class-level and client-level unlearning. Even when only 1% of a user's local data is forgotten, ULIA still attains an ASR ranging from 93% to 62.3%.",
    "source": "arXiv"
  },
  {
    "title": "Entendimento de Campanhas no Contexto da Aten\\c{c}\\~ao Prim\\'aria \\`a Sa\\'ude: Um Processo de Design Socialmente Consciente",
    "title_es": "Entendimento de Campanhas no Contexto da Aten\\c{c}\\~ao Prim\\'aria \\`a Sa\\'ude: Um Processo de Design Socialmente Consciente",
    "url": "https://arxiv.org/abs/2508.06791",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06791v1 Announce Type: new \nAbstract: This report presents the results of an exploratory analysis of the work context of Community Health Agents and Endemic Disease Control Agents in Primary Health Care (PHC), with a particular focus on Health Campaigns. To understand this context, the study adopted the Socially Aware Design framework, which employs artifacts and techniques to examine problem domains in a comprehensive and sociotechnical manner. Methods such as the Stakeholder Identification Diagram, Evaluation Frame, and Semiotic Framework were applied to identify stakeholders, anticipate challenges, and elicit social and technical requirements for the solution. Personas and Scenarios were also used to illustrate the potential impacts of a solution on various stakeholders and their life contexts within health campaigns. This report presents the analysis method, its application, and results, discussing the study's findings to inform the development of medium-fidelity prototypes for a PHC health campaign management solution.",
    "source": "arXiv"
  },
  {
    "title": "Geometry-Aware Spiking Graph Neural Network",
    "title_es": "Geometry-Aware Spiking Graph Neural Network",
    "url": "https://arxiv.org/abs/2508.06793",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06793v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) have demonstrated impressive capabilities in modeling graph-structured data, while Spiking Neural Networks (SNNs) offer high energy efficiency through sparse, event-driven computation. However, existing spiking GNNs predominantly operate in Euclidean space and rely on fixed geometric assumptions, limiting their capacity to model complex graph structures such as hierarchies and cycles. To overcome these limitations, we propose \\method{}, a novel Geometry-Aware Spiking Graph Neural Network that unifies spike-based neural dynamics with adaptive representation learning on Riemannian manifolds. \\method{} features three key components: a Riemannian Embedding Layer that projects node features into a pool of constant-curvature manifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that models membrane potential evolution and spiking behavior in curved spaces via geometry-consistent neighbor aggregation and curvature-based attention; and a Manifold Learning Objective that enables instance-wise geometry adaptation through jointly optimized classification and link prediction losses defined over geodesic distances. All modules are trained using Riemannian SGD, eliminating the need for backpropagation through time. Extensive experiments on multiple benchmarks show that GSG achieves superior accuracy, robustness, and energy efficiency compared to both Euclidean SNNs and manifold-based GNNs, establishing a new paradigm for curvature-aware, energy-efficient graph learning.",
    "source": "arXiv"
  },
  {
    "title": "Towards Practical Data-Dependent Memory-Hard Functions with Optimal Sustained Space Trade-offs in the Parallel Random Oracle Model",
    "title_es": "Towards Practical Data-Dependent Memory-Hard Functions with Optimal Sustained Space Trade-offs in the Parallel Random Oracle Model",
    "url": "https://arxiv.org/abs/2508.06795",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06795v1 Announce Type: new \nAbstract: Memory-Hard Functions (MHF) are a useful cryptographic primitive to build egalitarian proofs-of-work and to help protect low entropy secrets (e.g., user passwords) against brute-forces attacks. Ideally, we would like for a MHF to have the property that (1) an honest party can evaluate the function in sequential time $\\Omega(N)$, and (2) any parallel party that evaluates the function is forced to lockup $\\Omega(N)$ memory for $\\Omega(N)$ sequential steps. Unfortunately, this goal is not quite achievable, so prior work of Blocki and Holman [BH22] focused on designing MHFs with strong tradeoff guarantees between sustained-space complexity (SSC) and cumulative memory costs (CMC). However, their theoretical construction is not suitable for practical deployment due to the reliance on expensive constructions of combinatorial graphs. Furthermore, there is no formal justification for the heuristic use of the dynamic pebbling game in MHF analysis so we cannot rule out the possibility that there are more efficient attacks in the Parallel Random Oracle Model (PROM). Towards the goal of developing a practical MHF with provably strong SSC/CMC tradeoffs we develop a new MHF called EGSample which does not rely on expensive combinatorial constructions like [BH22]. In the dynamic pebbling model, we prove equivalent SSC/CMC tradeoffs for EGSample i.e., any the dynamic pebbling strategy either (1) locks up $\\Omega(N)$ memory for $\\Omega(N)$ steps, or (2) incurs cumulative memory cost at least $\\Omega(N^{3-\\epsilon})$. We also develop new techniques to directly establish SSC/CMC tradeoffs in the parallel random oracle model. In particular, we prove that {\\em any} PROM algorithm evaluating our MHF either (1) locks up $\\Omega(N)$ blocks of memory for $\\Omega(N)$ steps or (2) incurs cumulative memory cost at least $\\Omega(N^{2.5-\\epsilon})$.",
    "source": "arXiv"
  },
  {
    "title": "LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning",
    "title_es": "LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning",
    "url": "https://arxiv.org/abs/2508.06799",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06799v1 Announce Type: new \nAbstract: Digital Twins (DTs) offer powerful tools for managing complex infrastructure systems, but their effectiveness is often limited by challenges in integrating unstructured knowledge. Recent advances in Large Language Models (LLMs) bring new potential to address this gap, with strong abilities in extracting and organizing diverse textual information. We therefore propose LSDTs (LLM-Augmented Semantic Digital Twins), a framework that helps LLMs extract planning knowledge from unstructured documents like environmental regulations and technical guidelines, and organize it into a formal ontology. This ontology forms a semantic layer that powers a digital twin-a virtual model of the physical system-allowing it to simulate realistic, regulation-aware planning scenarios. We evaluate LSDTs through a case study of offshore wind farm planning in Maryland, including its application during Hurricane Sandy. Results demonstrate that LSDTs support interpretable, regulation-aware layout optimization, enable high-fidelity simulation, and enhance adaptability in infrastructure planning. This work shows the potential of combining generative AI with digital twins to support complex, knowledge-driven planning tasks.",
    "source": "arXiv"
  },
  {
    "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities",
    "title_es": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities",
    "url": "https://arxiv.org/abs/2508.06800",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06800v1 Announce Type: new \nAbstract: Missing modalities have recently emerged as a critical research direction in multimodal emotion recognition (MER). Conventional approaches typically address this issue through missing modality reconstruction. However, these methods fail to account for variations in reconstruction difficulty across different samples, consequently limiting the model's ability to handle hard samples effectively. To overcome this limitation, we propose a novel Hardness-Aware Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates in two key stages: first, it estimates the hardness level of each sample, and second, it strategically emphasizes hard samples during training to enhance model performance on these challenging instances. Specifically, we first introduce a Multi-view Hardness Evaluation mechanism that quantifies reconstruction difficulty by considering both Direct Hardness (modality reconstruction errors) and Indirect Hardness (cross-modal mutual information). Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy that dynamically adjusts the training curriculum by retrieving samples with similar semantic information and balancing the learning focus between easy and hard instances. Extensive experiments on benchmark datasets demonstrate that HARDY-MER consistently outperforms existing methods in missing-modality scenarios. Our code will be made publicly available at https://github.com/HARDY-MER/HARDY-MER.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Pedestrian Gesture Misrecognition: Insights from Vision-Language Model Reasoning",
    "title_es": "Understanding Pedestrian Gesture Misrecognition: Insights from Vision-Language Model Reasoning",
    "url": "https://arxiv.org/abs/2508.06801",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06801v1 Announce Type: new \nAbstract: Pedestrian gestures play an important role in traffic communication, particularly in interactions with autonomous vehicles (AVs), yet their subtle, ambiguous, and context-dependent nature poses persistent challenges for machine interpretation. This study investigates these challenges by using GPT-4V, a vision-language model, not as a performance benchmark but as a diagnostic tool to reveal patterns and causes of gesture misrecognition. We analysed a public dataset of pedestrian-vehicle interactions, combining manual video review with thematic analysis of the model's qualitative reasoning. This dual approach surfaced recurring factors influencing misrecognition, including gesture visibility, pedestrian behaviour, interaction context, and environmental conditions. The findings suggest practical considerations for gesture design, including the value of salience and contextual redundancy, and highlight opportunities to improve AV recognition systems through richer context modelling and uncertainty-aware interpretations. While centred on AV-pedestrian interaction, the method and insights are applicable to other domains where machines interpret human gestures, such as wearable AR and assistive technologies.",
    "source": "arXiv"
  },
  {
    "title": "SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection",
    "title_es": "SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection",
    "url": "https://arxiv.org/abs/2508.06803",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06803v1 Announce Type: new \nAbstract: Sarcasm detection is a crucial yet challenging Natural Language Processing task. Existing Large Language Model methods are often limited by single-perspective analysis, static reasoning pathways, and a susceptibility to hallucination when processing complex ironic rhetoric, which impacts their accuracy and reliability. To address these challenges, we propose **SEVADE**, a novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with **D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which utilizes a team of specialized agents grounded in linguistic theory to perform a multifaceted deconstruction of the text and generate a structured reasoning chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs the final classification based solely on this reasoning chain. This decoupled architecture is designed to mitigate the risk of hallucination by separating complex reasoning from the final judgment. Extensive experiments on four benchmark datasets demonstrate that our framework achieves state-of-the-art performance, with average improvements of **6.75%** in Accuracy and **6.29%** in Macro-F1 score.",
    "source": "arXiv"
  },
  {
    "title": "D3P: Dynamic Denoising Diffusion Policy via Reinforcement Learning",
    "title_es": "D3P: Dynamic Denoising Diffusion Policy via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06804",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06804v1 Announce Type: new \nAbstract: Diffusion policies excel at learning complex action distributions for robotic visuomotor tasks, yet their iterative denoising process poses a major bottleneck for real-time deployment. Existing acceleration methods apply a fixed number of denoising steps per action, implicitly treating all actions as equally important. However, our experiments reveal that robotic tasks often contain a mix of \\emph{crucial} and \\emph{routine} actions, which differ in their impact on task success. Motivated by this finding, we propose \\textbf{D}ynamic \\textbf{D}enoising \\textbf{D}iffusion \\textbf{P}olicy \\textbf{(D3P)}, a diffusion-based policy that adaptively allocates denoising steps across actions at test time. D3P uses a lightweight, state-aware adaptor to allocate the optimal number of denoising steps for each action. We jointly optimize the adaptor and base diffusion policy via reinforcement learning to balance task performance and inference efficiency. On simulated tasks, D3P achieves an averaged 2.2$\\times$ inference speed-up over baselines without degrading success. Furthermore, we demonstrate D3P's effectiveness on a physical robot, achieving a 1.9$\\times$ acceleration over the baseline.",
    "source": "arXiv"
  },
  {
    "title": "Edge Detection for Organ Boundaries via Top Down Refinement and SubPixel Upsampling",
    "title_es": "Edge Detection for Organ Boundaries via Top Down Refinement and SubPixel Upsampling",
    "url": "https://arxiv.org/abs/2508.06805",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06805v1 Announce Type: new \nAbstract: Accurate localization of organ boundaries is critical in medical imaging for segmentation, registration, surgical planning, and radiotherapy. While deep convolutional networks (ConvNets) have advanced general-purpose edge detection to near-human performance on natural images, their outputs often lack precise localization, a limitation that is particularly harmful in medical applications where millimeter-level accuracy is required. Building on a systematic analysis of ConvNet edge outputs, we propose a medically focused crisp edge detector that adapts a novel top-down backward refinement architecture to medical images (2D and volumetric). Our method progressively upsamples and fuses high-level semantic features with fine-grained low-level cues through a backward refinement pathway, producing high-resolution, well-localized organ boundaries. We further extend the design to handle anisotropic volumes by combining 2D slice-wise refinement with light 3D context aggregation to retain computational efficiency. Evaluations on several CT and MRI organ datasets demonstrate substantially improved boundary localization under strict criteria (boundary F-measure, Hausdorff distance) compared to baseline ConvNet detectors and contemporary medical edge/contour methods. Importantly, integrating our crisp edge maps into downstream pipelines yields consistent gains in organ segmentation (higher Dice scores, lower boundary errors), more accurate image registration, and improved delineation of lesions near organ interfaces. The proposed approach produces clinically valuable, crisp organ edges that materially enhance common medical-imaging tasks.",
    "source": "arXiv"
  },
  {
    "title": "Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation",
    "title_es": "Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation",
    "url": "https://arxiv.org/abs/2508.06806",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06806v1 Announce Type: new \nAbstract: Offline-to-online Reinforcement Learning (O2O RL) aims to perform online fine-tuning on an offline pre-trained policy to minimize costly online interactions. Existing work used offline datasets to generate data that conform to the online data distribution for data augmentation. However, generated data still exhibits a gap with the online data, limiting overall performance. To address this, we propose a new data augmentation approach, Classifier-Free Diffusion Generation (CFDG). Without introducing additional classifier training overhead, CFDG leverages classifier-free guidance diffusion to significantly enhance the generation quality of offline and online data with different distributions. Additionally, it employs a reweighting method to enable more generated data to align with the online data, enhancing performance while maintaining the agent's stability. Experimental results show that CFDG outperforms replaying the two data types or using a standard diffusion model to generate new data. Our method is versatile and can be integrated with existing offline-to-online RL algorithms. By implementing CFDG to popular methods IQL, PEX and APL, we achieve a notable 15% average improvement in empirical performance on the D4RL benchmark such as MuJoCo and AntMaze.",
    "source": "arXiv"
  },
  {
    "title": "Controlling tail risk in two-slope ski rental",
    "title_es": "Controlling tail risk in two-slope ski rental",
    "url": "https://arxiv.org/abs/2508.06809",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06809v1 Announce Type: new \nAbstract: We study the optimal solution to a general two-slope ski rental problem with a tail risk, i.e., the chance of the competitive ratio exceeding a value $\\gamma$ is bounded by $\\delta$. This extends the recent study of tail bounds for ski rental by [Dinitz et al. SODA 2024] to the two-slope version defined by [Lotker et al. IPL 2008]. In this version, even after \"buying,\" we must still pay a rental cost at each time step, though it is lower after buying. This models many real-world \"rent-or-buy\" scenarios where a one-time investment decreases (but does not eliminate) the per-time cost.\n  Despite this being a simple extension of the classical problem, we find that adding tail risk bounds creates a fundamentally different solution structure. For example, in our setting there is a possibility that we never buy in an optimal solution (which can also occur without tail bounds), but more strangely (and unlike the case without tail bounds or the classical case with tail bounds) we also show that the optimal solution might need to have nontrivial probabilities of buying even at finite points beyond the time corresponding to the buying cost. Moreover, in many regimes there does not exist a unique optimal solution. As our first contribution, we develop a series of structure theorems to characterize some features of optimal solutions.\n  The complex structure of optimal solutions makes it more difficult to develop an algorithm to compute such a solution. As our second contribution, we utilize our structure theorems to design two algorithms: one based on a greedy algorithm combined with binary search that is fast but yields arbitrarily close to optimal solutions, and a slower algorithm based on linear programming which computes exact optimal solutions.",
    "source": "arXiv"
  },
  {
    "title": "Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems",
    "title_es": "Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems",
    "url": "https://arxiv.org/abs/2508.06810",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06810v1 Announce Type: new \nAbstract: Recent advances in natural language processing (NLP) have contributed to the development of automated writing evaluation (AWE) systems that can correct grammatical errors. However, while these systems are effective at improving text, they are not optimally designed for language learning. They favor direct revisions, often with a click-to-fix functionality that can be applied without considering the reason for the correction. Meanwhile, depending on the error type, learners may benefit most from simple explanations and strategically indirect hints, especially on generalizable grammatical rules. To support the generation of such feedback, we introduce an annotation framework that models each error's error type and generalizability. For error type classification, we introduce a typology focused on inferring learners' knowledge gaps by connecting their errors to specific grammatical patterns. Following this framework, we collect a dataset of annotated learner errors and corresponding human-written feedback comments, each labeled as a direct correction or hint. With this data, we evaluate keyword-guided, keyword-free, and template-guided methods of generating feedback using large language models (LLMs). Human teachers examined each system's outputs, assessing them on grounds including relevance, factuality, and comprehensibility. We report on the development of the dataset and the comparative performance of the systems investigated.",
    "source": "arXiv"
  },
  {
    "title": "Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face",
    "title_es": "Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face",
    "url": "https://arxiv.org/abs/2508.06811",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06811v1 Announce Type: new \nAbstract: Many have observed that the development and deployment of generative machine learning (ML) and artificial intelligence (AI) models follow a distinctive pattern in which pre-trained models are adapted and fine-tuned for specific downstream tasks. However, there is limited empirical work that examines the structure of these interactions. This paper analyzes 1.86 million models on Hugging Face, a leading peer production platform for model development. Our study of model family trees -- networks that connect fine-tuned models to their base or parent -- reveals sprawling fine-tuning lineages that vary widely in size and structure. Using an evolutionary biology lens to study ML models, we use model metadata and model cards to measure the genetic similarity and mutation of traits over model families. We find that models tend to exhibit a family resemblance, meaning their genetic markers and traits exhibit more overlap when they belong to the same model family. However, these similarities depart in certain ways from standard models of asexual reproduction, because mutations are fast and directed, such that two `sibling' models tend to exhibit more similarity than parent/child pairs. Further analysis of the directional drifts of these mutations reveals qualitative insights about the open machine learning ecosystem: Licenses counter-intuitively drift from restrictive, commercial licenses towards permissive or copyleft licenses, often in violation of upstream license's terms; models evolve from multi-lingual compatibility towards english-only compatibility; and model cards reduce in length and standardize by turning, more often, to templates and automatically generated text. Overall, this work takes a step toward an empirically grounded understanding of model fine-tuning and suggests that ecological models and methods can yield novel scientific insights.",
    "source": "arXiv"
  },
  {
    "title": "Technical Report: Full-Stack Fine-Tuning for the Q Programming Language",
    "title_es": "Technical Report: Full-Stack Fine-Tuning for the Q Programming Language",
    "url": "https://arxiv.org/abs/2508.06813",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06813v1 Announce Type: new \nAbstract: Even though large language models are becoming increasingly capable, it is still unreasonable to expect them to excel at tasks that are under-represented on the Internet. Leveraging LLMs for specialized applications, particularly in niche programming languages and private domains, remains challenging and largely unsolved. In this work, we address this gap by presenting a comprehensive, open-source approach for adapting LLMs to the Q programming language, a popular tool in quantitative finance that is much less present on the Internet compared to Python, C, Java, and other ``mainstream\" languages and is therefore not a strong suit of general-purpose AI models. We introduce a new Leetcode style evaluation dataset for Q, benchmark major frontier models on the dataset, then do pretraining, supervised fine tuning, and reinforcement learning to train a suite of reasoning and non-reasoning models based on the Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our best model achieves a pass@1 accuracy of 59 percent on our Q benchmark, surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent. Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task. In addition to releasing models, code, and data, we provide a detailed blueprint for dataset construction, model pretraining, supervised fine-tuning, and reinforcement learning. Our methodology is broadly applicable, and we discuss how these techniques can be extended to other tasks, including those where evaluation may rely on soft or subjective signals.",
    "source": "arXiv"
  },
  {
    "title": "Metadata Management for AI-Augmented Data Workflows",
    "title_es": "Metadata Management for AI-Augmented Data Workflows",
    "url": "https://arxiv.org/abs/2508.06814",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06814v1 Announce Type: new \nAbstract: AI-augmented data workflows introduce complex governance challenges, as both human and model-driven processes generate, transform, and consume data artifacts. These workflows blend heterogeneous tools, dynamic execution patterns, and opaque model decisions, making comprehensive metadata capture difficult. In this work, we present TableVault, a metadata governance framework designed for human-AI collaborative data creation. TableVault records ingestion events, traces operation status, links execution parameters to their data origins, and exposes a standardized metadata layer. By combining database-inspired guarantees with AI-oriented design, such as declarative operation builders and lineage-aware references, TableVault supports transparency and reproducibility across mixed human-model pipelines. Through a document classification case study, we demonstrate how TableVault preserves detailed lineage and operational context, enabling robust metadata management, even in partially observable execution environments.",
    "source": "arXiv"
  },
  {
    "title": "DualResolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation",
    "title_es": "DualResolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation",
    "url": "https://arxiv.org/abs/2508.06816",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06816v1 Announce Type: new \nAbstract: Accurate segmentation of melanocytic tumors in dermoscopic images is a critical step for automated skin cancer screening and clinical decision support. Unlike natural scene segmentation, lesion delineation must reconcile subtle texture and color variations, frequent artifacts (hairs, rulers, bubbles), and a strong need for precise boundary localization to support downstream diagnosis. In this paper we introduce Our method, a novel ResNet inspired dual resolution architecture specifically designed for melanocytic tumor segmentation. Our method maintains a full resolution stream that preserves fine grained boundary information while a complementary pooled stream aggregates multi scale contextual cues for robust lesion recognition. The streams are tightly coupled by boundary aware residual connections that inject high frequency edge information into deep feature maps, and by a channel attention module that adapts color and texture sensitivity to dermoscopic appearance. To further address common imaging artifacts and the limited size of clinical datasets, we propose a lightweight artifact suppression block and a multi task training objective that combines a Dice Tversky segmentation loss with an explicit boundary loss and a contrastive regularizer for feature stability. The combined design yields pixel accurate masks without requiring heavy post processing or complex pre training protocols. Extensive experiments on public dermoscopic benchmarks demonstrate that Our method significantly improves boundary adherence and clinically relevant segmentation metrics compared to standard encoder decoder baselines, making it a practical building block for automated melanoma assessment systems.",
    "source": "arXiv"
  },
  {
    "title": "VesselRW: Weakly Supervised Subcutaneous Vessel Segmentation via Learned Random Walk Propagation",
    "title_es": "VesselRW: Weakly Supervised Subcutaneous Vessel Segmentation via Learned Random Walk Propagation",
    "url": "https://arxiv.org/abs/2508.06819",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06819v1 Announce Type: new \nAbstract: Accurate segmentation of subcutaneous vessels from clinical images is hampered by scarce, expensive ground truth and by low contrast, noisy appearance of vessels across patients and modalities. We present a novel weakly supervised training framework tailored for subcutaneous vessel segmentation that leverages inexpensive sparse annotations (e.g., centerline traces, dot markers, or short scribbles). Sparse labels are expanded into dense, probabilistic supervision via a differentiable random walk label propagation model whose transition weights incorporate image driven vesselness cues and tubular continuity priors. The propagation yields per-pixel hitting probabilities together with calibrated uncertainty estimates; these are incorporated into an uncertainty weighted loss to avoid over fitting to ambiguous regions. Crucially, the label-propagator is learned jointly with a CNN based segmentation predictor, enabling the system to discover vessel edges and continuity constraints without explicit edge supervision. We further introduce a topology aware regularizer that encourages centerline connectivity and penalizes spurious branches, improving clinical usability. In experiments on clinical subcutaneous imaging datasets, our method consistently outperforms naive training on sparse labels and conventional dense pseudo-labeling, producing more complete vascular maps and better calibrated uncertainty for downstream decision making. The approach substantially reduces annotation burden while preserving clinically relevant vessel topology.",
    "source": "arXiv"
  },
  {
    "title": "Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation",
    "title_es": "Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation",
    "url": "https://arxiv.org/abs/2508.06823",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06823v1 Announce Type: new \nAbstract: Exploring volumetric data is crucial for interpreting scientific datasets. However, selecting optimal viewpoints for effective navigation can be challenging, particularly for users without extensive domain expertise or familiarity with 3D navigation. In this paper, we propose a novel framework that leverages natural language interaction to enhance volumetric data exploration. Our approach encodes volumetric blocks to capture and differentiate underlying structures. It further incorporates a CLIP Score mechanism, which provides semantic information to the blocks to guide navigation. The navigation is empowered by a reinforcement learning framework that leverage these semantic cues to efficiently search for and identify desired viewpoints that align with the user's intent. The selected viewpoints are evaluated using CLIP Score to ensure that they best reflect the user queries. By automating viewpoint selection, our method improves the efficiency of volumetric data navigation and enhances the interpretability of complex scientific phenomena.",
    "source": "arXiv"
  },
  {
    "title": "AdjustAR: AI-Driven In-Situ Adjustment of Site-Specific Augmented Reality Content",
    "title_es": "AdjustAR: AI-Driven In-Situ Adjustment of Site-Specific Augmented Reality Content",
    "url": "https://arxiv.org/abs/2508.06826",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06826v1 Announce Type: new \nAbstract: Site-specific outdoor AR experiences are typically authored using static 3D models, but are deployed in physical environments that change over time. As a result, virtual content may become misaligned with its intended real-world referents, degrading user experience and compromising contextual interpretation. We present AdjustAR, a system that supports in-situ correction of AR content in dynamic environments using multimodal large language models (MLLMs). Given a composite image comprising the originally authored view and the current live user view from the same perspective, an MLLM detects contextual misalignments and proposes revised 2D placements for affected AR elements. These corrections are backprojected into 3D space to update the scene at runtime. By leveraging MLLMs for visual-semantic reasoning, this approach enables automated runtime corrections to maintain alignment with the authored intent as real-world target environments evolve.",
    "source": "arXiv"
  },
  {
    "title": "Who's the Evil Twin? Differential Auditing for Undesired Behavior",
    "title_es": "Who's the Evil Twin? Differential Auditing for Undesired Behavior",
    "url": "https://arxiv.org/abs/2508.06827",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06827v1 Announce Type: new \nAbstract: Detecting hidden behaviors in neural networks poses a significant challenge due to minimal prior knowledge and potential adversarial obfuscation. We explore this problem by framing detection as an adversarial game between two teams: the red team trains two similar models, one trained solely on benign data and the other trained on data containing hidden harmful behavior, with the performance of both being nearly indistinguishable on the benign dataset. The blue team, with limited to no information about the harmful behaviour, tries to identify the compromised model. We experiment using CNNs and try various blue team strategies, including Gaussian noise analysis, model diffing, integrated gradients, and adversarial attacks under different levels of hints provided by the red team. Results show high accuracy for adversarial-attack-based methods (100\\% correct prediction, using hints), which is very promising, whilst the other techniques yield more varied performance. During our LLM-focused rounds, we find that there are not many parallel methods that we could apply from our study with CNNs. Instead, we find that effective LLM auditing methods require some hints about the undesired distribution, which can then used in standard black-box and open-weight methods to probe the models further and reveal their misalignment. We open-source our auditing games (with the model and data) and hope that our findings contribute to designing better audits.",
    "source": "arXiv"
  },
  {
    "title": "Onsager Principle-Based Domain Embedding for Thermodynamically Consistent Cahn-Hilliard Model in Arbitrary Domain",
    "title_es": "Onsager Principle-Based Domain Embedding for Thermodynamically Consistent Cahn-Hilliard Model in Arbitrary Domain",
    "url": "https://arxiv.org/abs/2508.06830",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06830v1 Announce Type: new \nAbstract: The original Cahn-Hilliard model in an arbitrary domain with two prescribed boundary conditions is extended to a Cahn-Hilliard-type model in a larger, regular domain with homogeneous Neumann boundary conditions. The extension is based on the Onsager principle-based domain embedding (OPBDE) method, which has been developed as a systematic domain embedding framework to ensure thermodynamic consistency. By introducing a modified conservation law, the flux at the boundary of the original domain is incorporated into the conservation law as a source term. Our variational approach demonstrates that, even without a prior knowledge on the specific form of the rate of free energy pumped into the system, the Onsager principle remains an effective instrument in deriving the constitutive equation of the extended system. This approach clarifies the intrinsic structure of the extended model in the perspectives of free energy and its dissipation. Asymptotic analysis is carried out for the extended OPBDE Cahn-Hilliard model, demonstrating that the original Cahn-Hilliard model, including its boundary conditions, can be fully recovered. To validate our approach, a structure-preserving numerical scheme is developed to discretize the extended model. Numerical results show that the OPBDE Cahn-Hilliard model is accurate, effective, and robust, highlighting the capability of the OPBDE method in handling gradient flow problems in arbitrary domain geometries.",
    "source": "arXiv"
  },
  {
    "title": "Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification",
    "title_es": "Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification",
    "url": "https://arxiv.org/abs/2508.06831",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06831v1 Announce Type: new \nAbstract: Adapting person re-identification (reID) models to new target environments remains a challenging problem that is typically addressed using unsupervised domain adaptation (UDA) methods. Recent works show that when labeled data originates from several distinct sources (e.g., datasets and cameras), considering each source separately and applying multi-source domain adaptation (MSDA) typically yields higher accuracy and robustness compared to blending the sources and performing conventional UDA. However, state-of-the-art MSDA methods learn domain-specific backbone models or require access to source domain data during adaptation, resulting in significant growth in training parameters and computational cost. In this paper, a Source-free Adaptive Gated Experts (SAGE-reID) method is introduced for person reID. Our SAGE-reID is a cost-effective, source-free MSDA method that first trains individual source-specific low-rank adapters (LoRA) through source-free UDA. Next, a lightweight gating network is introduced and trained to dynamically assign optimal merging weights for fusion of LoRA experts, enabling effective cross-domain knowledge transfer. While the number of backbone parameters remains constant across source domains, LoRA experts scale linearly but remain negligible in size (<= 2% of the backbone), reducing both the memory consumption and risk of overfitting. Extensive experiments conducted on three challenging benchmarks: Market-1501, DukeMTMC-reID, and MSMT17 indicate that SAGE-reID outperforms state-of-the-art methods while being computationally efficient.",
    "source": "arXiv"
  },
  {
    "title": "Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges",
    "title_es": "Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges",
    "url": "https://arxiv.org/abs/2508.06832",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06832v1 Announce Type: new \nAbstract: The mainstream paradigm of remote sensing image interpretation has long been dominated by vision-centered models, which rely on visual features for semantic understanding. However, these models face inherent limitations in handling multi-modal reasoning, semantic abstraction, and interactive decision-making. While recent advances have introduced Large Language Models (LLMs) into remote sensing workflows, existing studies primarily focus on downstream applications, lacking a unified theoretical framework that explains the cognitive role of language. This review advocates a paradigm shift from vision-centered to language-centered remote sensing interpretation. Drawing inspiration from the Global Workspace Theory (GWT) of human cognition, We propose a language-centered framework for remote sensing interpretation that treats LLMs as the cognitive central hub integrating perceptual, task, knowledge and action spaces to enable unified understanding, reasoning, and decision-making. We first explore the potential of LLMs as the central cognitive component in remote sensing interpretation, and then summarize core technical challenges, including unified multimodal representation, knowledge association, and reasoning and decision-making. Furthermore, we construct a global workspace-driven interpretation mechanism and review how language-centered solutions address each challenge. Finally, we outline future research directions from four perspectives: adaptive alignment of multimodal data, task understanding under dynamic knowledge constraints, trustworthy reasoning, and autonomous interaction. This work aims to provide a conceptual foundation for the next generation of remote sensing interpretation systems and establish a roadmap toward cognition-driven intelligent geospatial analysis.",
    "source": "arXiv"
  },
  {
    "title": "Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning",
    "title_es": "Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06836",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06836v1 Announce Type: new \nAbstract: Cooperative multi-agent reinforcement learning (MARL) aims to coordinate multiple agents to achieve a common goal. A key challenge in MARL is credit assignment, which involves assessing each agent's contribution to the shared reward. Given the diversity of tasks, agents may perform different types of coordination, with rewards attributed to diverse and often overlapping agent subsets. In this work, we formalize the credit assignment level as the number of agents cooperating to obtain a reward, and address scenarios with multiple coexisting levels. We introduce a multi-level advantage formulation that performs explicit counterfactual reasoning to infer credits across distinct levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures agent contributions at multiple levels by integrating advantage functions that reason about individual, joint, and correlated actions. Utilizing an attention-based framework, MACA identifies correlated agent relationships and constructs multi-level advantages to guide policy learning. Comprehensive experiments on challenging Starcraft v1\\&v2 tasks demonstrate MACA's superior performance, underscoring its efficacy in complex credit assignment scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Towards Effective Prompt Stealing Attack against Text-to-Image Diffusion Models",
    "title_es": "Towards Effective Prompt Stealing Attack against Text-to-Image Diffusion Models",
    "url": "https://arxiv.org/abs/2508.06837",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06837v1 Announce Type: new \nAbstract: Text-to-Image (T2I) models, represented by DALL$\\cdot$E and Midjourney, have gained huge popularity for creating realistic images. The quality of these images relies on the carefully engineered prompts, which have become valuable intellectual property. While skilled prompters showcase their AI-generated art on markets to attract buyers, this business incidentally exposes them to \\textit{prompt stealing attacks}. Existing state-of-the-art attack techniques reconstruct the prompts from a fixed set of modifiers (i.e., style descriptions) with model-specific training, which exhibit restricted adaptability and effectiveness to diverse showcases (i.e., target images) and diffusion models.\n  To alleviate these limitations, we propose Prometheus, a training-free, proxy-in-the-loop, search-based prompt-stealing attack, which reverse-engineers the valuable prompts of the showcases by interacting with a local proxy model. It consists of three innovative designs. First, we introduce dynamic modifiers, as a supplement to static modifiers used in prior works. These dynamic modifiers provide more details specific to the showcases, and we exploit NLP analysis to generate them on the fly. Second, we design a contextual matching algorithm to sort both dynamic and static modifiers. This offline process helps reduce the search space of the subsequent step. Third, we interact with a local proxy model to invert the prompts with a greedy search algorithm. Based on the feedback guidance, we refine the prompt to achieve higher fidelity. The evaluation results show that Prometheus successfully extracts prompts from popular platforms like PromptBase and AIFrog against diverse victim models, including Midjourney, Leonardo.ai, and DALL$\\cdot$E, with an ASR improvement of 25.0\\%. We also validate that Prometheus is resistant to extensive potential defenses, further highlighting its severity in practice.",
    "source": "arXiv"
  },
  {
    "title": "Memory Enhanced Fractional-Order Dung Beetle Optimization for Photovoltaic Parameter Identification",
    "title_es": "Memory Enhanced Fractional-Order Dung Beetle Optimization for Photovoltaic Parameter Identification",
    "url": "https://arxiv.org/abs/2508.06841",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06841v1 Announce Type: new \nAbstract: Accurate parameter identification in photovoltaic (PV) models is crucial for performance evaluation but remains challenging due to their nonlinear, multimodal, and high-dimensional nature. Although the Dung Beetle Optimization (DBO) algorithm has shown potential in addressing such problems, it often suffers from premature convergence. To overcome these issues, this paper proposes a Memory Enhanced Fractional-Order Dung Beetle Optimization (MFO-DBO) algorithm that integrates three coordinated strategies. Firstly, fractional-order (FO) calculus introduces memory into the search process, enhancing convergence stability and solution quality. Secondly, a fractional-order logistic chaotic map improves population diversity during initialization. Thirdly, a chaotic perturbation mechanism helps elite solutions escape local optima. Numerical results on the CEC2017 benchmark suite and the PV parameter identification problem demonstrate that MFO-DBO consistently outperforms advanced DBO variants, CEC competition winners, FO-based optimizers, enhanced classical algorithms, and recent metaheuristics in terms of accuracy, robustness, convergence speed, while also maintaining an excellent balance between exploration and exploitation compared to the standard DBO algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Hybrid Machine Learning Framework for Predicting Geometric Deviations from 3D Surface Metrology",
    "title_es": "Hybrid Machine Learning Framework for Predicting Geometric Deviations from 3D Surface Metrology",
    "url": "https://arxiv.org/abs/2508.06845",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06845v1 Announce Type: new \nAbstract: This study addresses the challenge of accurately forecasting geometric deviations in manufactured components using advanced 3D surface analysis. Despite progress in modern manufacturing, maintaining dimensional precision remains difficult, particularly for complex geometries. We present a methodology that employs a high-resolution 3D scanner to acquire multi-angle surface data from 237 components produced across different batches. The data were processed through precise alignment, noise reduction, and merging techniques to generate accurate 3D representations. A hybrid machine learning framework was developed, combining convolutional neural networks for feature extraction with gradient-boosted decision trees for predictive modeling. The proposed system achieved a prediction accuracy of 0.012 mm at a 95% confidence level, representing a 73% improvement over conventional statistical process control methods. In addition to improved accuracy, the model revealed hidden correlations between manufacturing parameters and geometric deviations. This approach offers significant potential for automated quality control, predictive maintenance, and design optimization in precision manufacturing, and the resulting dataset provides a strong foundation for future predictive modeling research.",
    "source": "arXiv"
  },
  {
    "title": "Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators",
    "title_es": "Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators",
    "url": "https://arxiv.org/abs/2508.06846",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06846v1 Announce Type: new \nAbstract: Large language models (LLMs) are susceptible to generating inaccurate or false information, often referred to as \"hallucinations\" or \"confabulations.\" While several technical advancements have been made to detect hallucinated content by assessing the factuality of the model's responses, there is still limited research on how to effectively communicate this information to users. To address this gap, we conducted two scenario-based experiments with a total of 208 participants to systematically compare the effects of various design strategies for communicating factuality scores by assessing participants' ratings of trust, ease in validating response accuracy, and preference. Our findings reveal that participants preferred and trusted a design in which all phrases within a response were color-coded based on factuality scores. Participants also found it easier to validate accuracy of the response in this style compared to a baseline with no style applied. Our study offers practical design guidelines for LLM application developers and designers, aimed at calibrating user trust, aligning with user preferences, and enhancing users' ability to scrutinize LLM outputs.",
    "source": "arXiv"
  },
  {
    "title": "Towards Experience-Centered AI: A Framework for Integrating Lived Experience in Design and Development",
    "title_es": "Towards Experience-Centered AI: A Framework for Integrating Lived Experience in Design and Development",
    "url": "https://arxiv.org/abs/2508.06849",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06849v1 Announce Type: new \nAbstract: Lived experiences fundamentally shape how individuals interact with AI systems, influencing perceptions of safety, trust, and usability. While prior research has focused on developing techniques to emulate human preferences, and proposed taxonomies to categorize risks (such as psychological harms and algorithmic biases), these efforts have provided limited systematic understanding of lived human experiences or actionable strategies for embedding them meaningfully into the AI development lifecycle. This work proposes a framework for meaningfully integrating lived experience into the design and evaluation of AI systems. We synthesize interdisciplinary literature across lived experience philosophy, human-centered design, and human-AI interaction, arguing that centering lived experience can lead to models that more accurately reflect the retrospective, emotional, and contextual dimensions of human cognition. Drawing from a wide body of work across psychology, education, healthcare, and social policy, we present a targeted taxonomy of lived experiences with specific applicability to AI systems. To ground our framework, we examine three application domains (i) education, (ii) healthcare, and (iii) cultural alignment, illustrating how lived experience informs user goals, system expectations, and ethical considerations in each context. We further incorporate insights from AI system operators and human-AI partnerships to highlight challenges in responsibility allocation, mental model calibration, and long-term system adaptation. We conclude with actionable recommendations for developing experience-centered AI systems that are not only technically robust but also empathetic, context-aware, and aligned with human realities. This work offers a foundation for future research that bridges technical development with the lived experiences of those impacted by AI systems.",
    "source": "arXiv"
  },
  {
    "title": "MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams",
    "title_es": "MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams",
    "url": "https://arxiv.org/abs/2508.06851",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06851v1 Announce Type: new \nAbstract: Multimodal large language models (MLLMs), which integrate language and visual cues for problem-solving, are crucial for advancing artificial general intelligence (AGI). However, current benchmarks for measuring the intelligence of MLLMs suffer from limited scale, narrow coverage, and unstructured knowledge, offering only static and undifferentiated evaluations. To bridge this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark built from real-world K-12 exams spanning six disciplines with 141K instances and 6,225 knowledge points organized in a six-layer taxonomy. Covering five question formats with difficulty and year annotations, it enables comprehensive evaluation to capture the extent to which MLLMs perform over four dimensions: 1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts, and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation framework that introduces unfamiliar visual, textual, and question form shifts to challenge model generalization while improving benchmark objectivity and longevity by mitigating data contamination. We further evaluate knowledge-point reference-augmented generation (KP-RAG) to examine the role of knowledge in problem-solving. Key findings reveal limitations in current MLLMs in multiple aspects and provide guidance for enhancing model robustness, interpretability, and AI-assisted education.",
    "source": "arXiv"
  },
  {
    "title": "AGIC: Attention-Guided Image Captioning to Improve Caption Relevance",
    "title_es": "AGIC: Attention-Guided Image Captioning to Improve Caption Relevance",
    "url": "https://arxiv.org/abs/2508.06853",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06853v1 Announce Type: new \nAbstract: Despite significant progress in image captioning, generating accurate and descriptive captions remains a long-standing challenge. In this study, we propose Attention-Guided Image Captioning (AGIC), which amplifies salient visual regions directly in the feature space to guide caption generation. We further introduce a hybrid decoding strategy that combines deterministic and probabilistic sampling to balance fluency and diversity. To evaluate AGIC, we conduct extensive experiments on the Flickr8k and Flickr30k datasets. The results show that AGIC matches or surpasses several state-of-the-art models while achieving faster inference. Moreover, AGIC demonstrates strong performance across multiple evaluation metrics, offering a scalable and interpretable solution for image captioning.",
    "source": "arXiv"
  },
  {
    "title": "A Joint Sparse Self-Representation Learning Method for Multiview Clustering",
    "title_es": "A Joint Sparse Self-Representation Learning Method for Multiview Clustering",
    "url": "https://arxiv.org/abs/2508.06857",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06857v1 Announce Type: new \nAbstract: Multiview clustering (MC) aims to group samples using consistent and complementary information across various views. The subspace clustering, as a fundamental technique of MC, has attracted significant attention. In this paper, we propose a novel joint sparse self-representation learning model for MC, where a featured difference is the extraction of view-specific local information by introducing cardinality (i.e., $\\ell_0$-norm) constraints instead of Graph-Laplacian regularization. Specifically, under each view, cardinality constraints directly restrict the samples used in the self-representation stage to extract reliable local and global structure information, while the low-rank constraint aids in revealing a global coherent structure in the consensus affinity matrix during merging. The attendant challenge is that Augmented Lagrange Method (ALM)-based alternating minimization algorithms cannot guarantee convergence when applied directly to our nonconvex, nonsmooth model, thus resulting in poor generalization ability. To address it, we develop an alternating quadratic penalty (AQP) method with global convergence, where two subproblems are iteratively solved by closed-form solutions. Empirical results on six standard datasets demonstrate the superiority of our model and AQP method, compared to eight state-of-the-art algorithms.",
    "source": "arXiv"
  },
  {
    "title": "MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction",
    "title_es": "MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction",
    "url": "https://arxiv.org/abs/2508.06859",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06859v1 Announce Type: new \nAbstract: Timely and accurate severe weather warnings are critical for disaster mitigation. However, current forecasting systems remain heavily reliant on manual expert interpretation, introducing subjectivity and significant operational burdens. With the rapid development of AI technologies, the end-to-end \"AI weather station\" is gradually emerging as a new trend in predicting severe weather events. Three core challenges impede the development of end-to-end AI severe weather system: (1) scarcity of severe weather event samples; (2) imperfect alignment between high-dimensional meteorological data and textual warnings; (3) existing multimodal language models are unable to handle high-dimensional meteorological data and struggle to fully capture the complex dependencies across temporal sequences, vertical pressure levels, and spatial dimensions. To address these challenges, we introduce MP-Bench, the first large-scale temporal multimodal dataset for severe weather events prediction, comprising 421,363 pairs of raw multi-year meteorological data and corresponding text caption, covering a wide range of severe weather scenarios across China. On top of this dataset, we develop a meteorology multimodal large model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is designed to accommodate the unique characteristics of 4D meteorological data flow, incorporating three plug-and-play adaptive fusion modules that enable dynamic feature extraction and integration across temporal sequences, vertical pressure layers, and spatial dimensions. Extensive experiments on MP-Bench demonstrate that MMLM performs exceptionally well across multiple tasks, highlighting its effectiveness in severe weather understanding and marking a key step toward realizing automated, AI-driven weather forecasting systems. Our source code and dataset will be made publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach",
    "title_es": "Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach",
    "url": "https://arxiv.org/abs/2508.06863",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06863v1 Announce Type: new \nAbstract: Unmanned aerial vehicles (UAVs) have been recently utilized in multi-access edge computing (MEC) as edge servers. It is desirable to design UAVs' trajectories and user to UAV assignments to ensure satisfactory service to the users and energy efficient operation simultaneously. The posed optimization problem is challenging to solve because: (i) The formulated problem is non-convex, (ii) Due to the mobility of ground users, their future positions and channel gains are not known in advance, (iii) Local UAVs' observations should be communicated to a central entity that solves the optimization problem. The (semi-) centralized processing leads to communication overhead, communication/processing bottlenecks, lack of flexibility and scalability, and loss of robustness to system failures. To simultaneously address all these limitations, we advocate a fully decentralized setup with no centralized entity. Each UAV obtains its local observation and then communicates with its immediate neighbors only. After sharing information with neighbors, each UAV determines its next position via a locally run deep reinforcement learning (DRL) algorithm. None of the UAVs need to know the global communication graph. Two main components of our proposed solution are (i) Graph attention layers (GAT), and (ii) Experience and parameter sharing proximal policy optimization (EPS-PPO). Our proposed approach eliminates all the limitations of semi-centralized MADRL methods such as MAPPO and MA deep deterministic policy gradient (MADDPG), while guaranteeing a better performance than independent local DRLs such as in IPPO. Numerical results reveal notable performance gains in several different criteria compared to the existing MADDPG algorithm, demonstrating the potential for offering a better performance, while utilizing local communications only.",
    "source": "arXiv"
  },
  {
    "title": "Collaborative Computing Strategy Based SINS Prediction for Emergency UAVs Network",
    "title_es": "Collaborative Computing Strategy Based SINS Prediction for Emergency UAVs Network",
    "url": "https://arxiv.org/abs/2508.06864",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06864v1 Announce Type: new \nAbstract: In emergency scenarios, the dynamic and harsh conditions necessitate timely trajectory adjustments for drones, leading to highly dynamic network topologies and potential task failures. To address these challenges, a collaborative computing strategy based strapdown inertial navigation system (SINS) prediction for emergency UAVs network (EUN) is proposed, where a two-step weighted time expanded graph (WTEG) is constructed to deal with dynamic network topology changes. Furthermore, the task scheduling is formulated as a Directed Acyclic Graph (DAG) to WTEG mapping problem to achieve collaborative computing while transmitting among UAVs. Finally, the binary particle swarm optimization (BPSO) algorithm is employed to choose the mapping strategy that minimizes end-to-end processing latency. The simulation results validate that the collaborative computing strategy significantly outperforms both cloud and local computing in terms of latency. Moreover, the task success rate using SINS is substantially improved compared to approaches without prior prediction.",
    "source": "arXiv"
  },
  {
    "title": "Efficient iterative linearised solvers for numerical approximations of stochastic Stefan problems",
    "title_es": "Efficient iterative linearised solvers for numerical approximations of stochastic Stefan problems",
    "url": "https://arxiv.org/abs/2508.06867",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06867v1 Announce Type: new \nAbstract: We present iterative solvers to approximate the solution of numerical schemes for stochastic Stefan problems. After briefly talking about the convergence results, we tackle the question of efficient strategies for solving the nonlinear equation associated with this scheme. We explore several approaches, from a standard Newton technique to linearised solvers. The latter offer the advantage of using the same coefficient matrix of the linearised system in each nonlinear iteration, for all time steps, and across all realisations of the Brownian motions. As a consequence, the system can be factorised once and for all. Although the linearised approach has a slower convergence rate, our sensitivity analysis and the use of adaptive tolerance in both deterministic and stochastic cases provide valuable insights for choosing the most effective solver across various scenarii.",
    "source": "arXiv"
  },
  {
    "title": "VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding",
    "title_es": "VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding",
    "url": "https://arxiv.org/abs/2508.06869",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06869v1 Announce Type: new \nAbstract: Long video understanding presents a significant challenge to multimodal large language models (MLLMs) primarily due to the immense data scale. A critical and widely adopted strategy for making this task computationally tractable is keyframe retrieval, which seeks to identify a sparse set of video frames that are most salient to a given textual query. However, the efficacy of this approach is hindered by weak multimodal alignment between textual queries and visual content and fails to capture the complex temporal semantic information required for precise reasoning. To address this, we propose Visual-Subtitle Integeration(VSI), a multimodal keyframe search method that integrates subtitles, timestamps, and scene boundaries into a unified multimodal search process. The proposed method captures the visual information of video frames as well as the complementary textual information through a dual-stream search mechanism by Video Search Stream as well as Subtitle Match Stream, respectively, and improves the keyframe search accuracy through the interaction of the two search streams. Experimental results show that VSI achieve 40.00% key frame localization accuracy on the text-relevant subset of LongVideoBench and 68.48% accuracy on downstream long Video-QA tasks, surpassing competitive baselines by 20.35% and 15.79%, respectively. Furthermore, on the LongVideoBench, VSI achieved state-of-the-art(SOTA) in medium-to-long video-QA tasks, demonstrating the robustness and generalizability of the proposed multimodal search strategy.",
    "source": "arXiv"
  },
  {
    "title": "Text to Speech System for Meitei Mayek Script",
    "title_es": "Text to Speech System for Meitei Mayek Script",
    "url": "https://arxiv.org/abs/2508.06870",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06870v1 Announce Type: new \nAbstract: This paper presents the development of a Text-to-Speech (TTS) system for the Manipuri language\n  using the Meitei Mayek script. Leveraging Tacotron 2 and HiFi-GAN, we introduce a neural TTS\n  architecture adapted to support tonal phonology and under-resourced linguistic environments. We\n  develop a phoneme mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and\n  demonstrate intelligible and natural speech synthesis, validated through subjective and objective\n  metrics. This system lays the groundwork for linguistic preservation and technological inclusion of\n  Manipuri.",
    "source": "arXiv"
  },
  {
    "title": "Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning",
    "title_es": "Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06871",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06871v1 Announce Type: new \nAbstract: Plasticity loss, a diminishing capacity to adapt as training progresses, is a critical challenge in deep reinforcement learning. We examine this issue in multi-task reinforcement learning (MTRL), where higher representational flexibility is crucial for managing diverse and potentially conflicting task demands. We systematically explore how sparsification methods, particularly Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance plasticity and consequently improve performance in MTRL agents. We evaluate these approaches across distinct MTRL architectures (shared backbone, Mixture of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks, comparing against dense baselines, and a comprehensive range of alternative plasticity-inducing or regularization methods. Our results demonstrate that both GMP and SET effectively mitigate key indicators of plasticity degradation, such as neuron dormancy and representational collapse. These plasticity improvements often correlate with enhanced multi-task performance, with sparse agents frequently outperforming dense counterparts and achieving competitive results against explicit plasticity interventions. Our findings offer insights into the interplay between plasticity, network sparsity, and MTRL designs, highlighting dynamic sparsification as a robust but context-sensitive tool for developing more adaptable MTRL systems.",
    "source": "arXiv"
  },
  {
    "title": "Perceiving Slope and Acceleration: Evidence for Variable Tempo Sampling in Pitch-Based Sonification of Functions",
    "title_es": "Perceiving Slope and Acceleration: Evidence for Variable Tempo Sampling in Pitch-Based Sonification of Functions",
    "url": "https://arxiv.org/abs/2508.06872",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06872v1 Announce Type: new \nAbstract: Sonification offers a non-visual way to understand data, with pitch-based encodings being the most common. Yet, how well people perceive slope and acceleration-key features of data trends-remains poorly understood. Drawing on people's natural abilities to perceive tempo, we introduce a novel sampling method for pitch-based sonification to enhance the perception of slope and acceleration in univariate functions. While traditional sonification methods often sample data at uniform x-spacing, yielding notes played at a fixed tempo with variable pitch intervals (Variable Pitch Interval), our approach samples at uniform y-spacing, producing notes with consistent pitch intervals but variable tempo (Variable Tempo). We conducted psychoacoustic experiments to understand slope and acceleration perception across three sampling methods: Variable Pitch Interval, Variable Tempo, and a Continuous (no sampling) baseline. In slope comparison tasks, Variable Tempo was more accurate than the other methods when modulated by the magnitude ratio between slopes. For acceleration perception, just-noticeable differences under Variable Tempo were over 13 times finer than with other methods. Participants also commonly reported higher confidence, lower mental effort, and a stronger preference for Variable Tempo compared to other methods. This work contributes models of slope and acceleration perception across pitch-based sonification techniques, introduces Variable Tempo as a novel and preferred sampling method, and provides promising initial evidence that leveraging timing can lead to more sensitive, accurate, and precise interpretation of derivative-based data features.",
    "source": "arXiv"
  },
  {
    "title": "LWT-ARTERY-LABEL: A Lightweight Framework for Automated Coronary Artery Identification",
    "title_es": "LWT-ARTERY-LABEL: A Lightweight Framework for Automated Coronary Artery Identification",
    "url": "https://arxiv.org/abs/2508.06874",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06874v1 Announce Type: new \nAbstract: Coronary artery disease (CAD) remains the leading cause of death globally, with computed tomography coronary angiography (CTCA) serving as a key diagnostic tool. However, coronary arterial analysis using CTCA, such as identifying artery-specific features from computational modelling, is labour-intensive and time-consuming. Automated anatomical labelling of coronary arteries offers a potential solution, yet the inherent anatomical variability of coronary trees presents a significant challenge. Traditional knowledge-based labelling methods fall short in leveraging data-driven insights, while recent deep-learning approaches often demand substantial computational resources and overlook critical clinical knowledge. To address these limitations, we propose a lightweight method that integrates anatomical knowledge with rule-based topology constraints for effective coronary artery labelling. Our approach achieves state-of-the-art performance on benchmark datasets, providing a promising alternative for automated coronary artery labelling.",
    "source": "arXiv"
  },
  {
    "title": "ESNERA: Empirical and semantic named entity alignment for named entity dataset merging",
    "title_es": "ESNERA: Empirical and semantic named entity alignment for named entity dataset merging",
    "url": "https://arxiv.org/abs/2508.06877",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06877v1 Announce Type: new \nAbstract: Named Entity Recognition (NER) is a fundamental task in natural language processing. It remains a research hotspot due to its wide applicability across domains. Although recent advances in deep learning have significantly improved NER performance, they rely heavily on large, high-quality annotated datasets. However, building these datasets is expensive and time-consuming, posing a major bottleneck for further research. Current dataset merging approaches mainly focus on strategies like manual label mapping or constructing label graphs, which lack interpretability and scalability. To address this, we propose an automatic label alignment method based on label similarity. The method combines empirical and semantic similarities, using a greedy pairwise merging strategy to unify label spaces across different datasets. Experiments are conducted in two stages: first, merging three existing NER datasets into a unified corpus with minimal impact on NER performance; second, integrating this corpus with a small-scale, self-built dataset in the financial domain. The results show that our method enables effective dataset merging and enhances NER performance in the low-resource financial domain. This study presents an efficient, interpretable, and scalable solution for integrating multi-source NER corpora.",
    "source": "arXiv"
  },
  {
    "title": "NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective",
    "title_es": "NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective",
    "url": "https://arxiv.org/abs/2508.06878",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06878v1 Announce Type: new \nAbstract: Infrared small target detection and segmentation (IRSTDS) is a critical yet challenging task in defense and civilian applications, owing to the dim, shapeless appearance of targets and severe background clutter. Recent CNN-based methods have achieved promising target perception results, but they only focus on enhancing feature representation to offset the impact of noise, which results in the increased false alarms problem. In this paper, through analyzing the problem from the frequency domain, we pioneer in improving performance from noise suppression perspective and propose a novel noise-suppression feature pyramid network (NS-FPN), which integrates a low-frequency guided feature purification (LFP) module and a spiral-aware feature sampling (SFS) module into the original FPN structure. The LFP module suppresses the noise features by purifying high-frequency components to achieve feature enhancement devoid of noise interference, while the SFS module further adopts spiral sampling to fuse target-relevant features in feature fusion process. Our NS-FPN is designed to be lightweight yet effective and can be easily plugged into existing IRSTDS frameworks. Extensive experiments on the public IRSTDS datasets demonstrate that our method significantly reduces false alarms and achieves superior performance on IRSTDS tasks.",
    "source": "arXiv"
  },
  {
    "title": "Quo Vadis, Code Review? Exploring the Future of Code Review",
    "title_es": "Quo Vadis, Code Review? Exploring the Future of Code Review",
    "url": "https://arxiv.org/abs/2508.06879",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06879v1 Announce Type: new \nAbstract: Code review has long been a core practice in collaborative software engineering. In this research, we explore how practitioners reflect on code review today and what changes they anticipate in the near future. We then discuss the potential long-term risks of these anticipated changes for the evolution of code review and its role in collaborative software engineering.",
    "source": "arXiv"
  },
  {
    "title": "The ReQAP System for Question Answering over Personal Information",
    "title_es": "The ReQAP System for Question Answering over Personal Information",
    "url": "https://arxiv.org/abs/2508.06880",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06880v1 Announce Type: new \nAbstract: Personal information is abundant on users' devices, from structured data in calendar, shopping records or fitness tools, to unstructured contents in mail and social media posts. This works presents the ReQAP system that supports users with answers for complex questions that involve filters, joins and aggregation over heterogeneous sources. The unique trait of ReQAP is that it recursively decomposes questions and incrementally builds an operator tree for execution. Both the question interpretation and the individual operators make smart use of light-weight language models, with judicious fine-tuning. The demo showcases the rich functionality for advanced user questions, and also offers detailed tracking of how the answers are computed by the operators in the execution tree. Being able to trace answers back to the underlying sources is vital for human comprehensibility and user trust in the system.",
    "source": "arXiv"
  },
  {
    "title": "Conformal Prediction and Trustworthy AI",
    "title_es": "Conformal Prediction and Trustworthy AI",
    "url": "https://arxiv.org/abs/2508.06885",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06885v1 Announce Type: new \nAbstract: Conformal predictors are machine learning algorithms developed in the 1990's by Gammerman, Vovk, and their research team, to provide set predictions with guaranteed confidence level. Over recent years, they have grown in popularity and have become a mainstream methodology for uncertainty quantification in the machine learning community. From its beginning, there was an understanding that they enable reliable machine learning with well-calibrated uncertainty quantification. This makes them extremely beneficial for developing trustworthy AI, a topic that has also risen in interest over the past few years, in both the AI community and society more widely. In this article, we review the potential for conformal prediction to contribute to trustworthy AI beyond its marginal validity property, addressing problems such as generalization risk and AI governance. Experiments and examples are also provided to demonstrate its use as a well-calibrated predictor and for bias identification and mitigation.",
    "source": "arXiv"
  },
  {
    "title": "Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores",
    "title_es": "Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores",
    "url": "https://arxiv.org/abs/2508.06886",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06886v1 Announce Type: new \nAbstract: Persona-based dialogue generation is an important milestone towards building conversational artificial intelligence. Despite the ever-improving capabilities of large language models (LLMs), effectively integrating persona fidelity in conversations remains challenging due to the limited diversity in existing dialogue data. We propose a novel framework SBS (Score-Before-Speaking), which outperforms previous methods and yields improvements for both million and billion-parameter models. Unlike previous methods, SBS unifies the learning of responses and their relative quality into a single step. The key innovation is to train a dialogue model to correlate augmented responses with a quality score during training and then leverage this knowledge at inference. We use noun-based substitution for augmentation and semantic similarity-based scores as a proxy for response quality. Through extensive experiments with benchmark datasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training allows existing models to better capture a spectrum of persona-consistent dialogues. Our ablation studies also demonstrate that including scores in the input prompt during training is superior to conventional training setups. Code and further details are available at https://arpita2512.github.io/score_before_you_speak",
    "source": "arXiv"
  },
  {
    "title": "Multi-Modal Requirements Data-based Acceptance Criteria Generation using LLMs",
    "title_es": "Multi-Modal Requirements Data-based Acceptance Criteria Generation using LLMs",
    "url": "https://arxiv.org/abs/2508.06888",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06888v1 Announce Type: new \nAbstract: Acceptance criteria (ACs) play a critical role in software development by clearly defining the conditions under which a software feature satisfies stakeholder expectations. However, manually creating accurate, comprehensive, and unambiguous acceptance criteria is challenging, particularly in user interface-intensive applications, due to the reliance on domain-specific knowledge and visual context that is not always captured by textual requirements alone. To address these challenges, we propose RAGcceptance M2RE, a novel approach that leverages Retrieval-Augmented Generation (RAG) to generate acceptance criteria from multi-modal requirements data, including both textual documentation and visual UI information. We systematically evaluated our approach in an industrial case study involving an education-focused software system used by approximately 100,000 users. The results indicate that integrating multi-modal information significantly enhances the relevance, correctness, and comprehensibility of the generated ACs. Moreover, practitioner evaluations confirm that our approach effectively reduces manual effort, captures nuanced stakeholder intent, and provides valuable criteria that domain experts may overlook, demonstrating practical utility and significant potential for industry adoption. This research underscores the potential of multi-modal RAG techniques in streamlining software validation processes and improving development efficiency. We also make our implementation and a dataset available.",
    "source": "arXiv"
  },
  {
    "title": "Viewpoint-Tolerant Depth Perception for Shared Extended Space Experience on Wall-Sized Display",
    "title_es": "Viewpoint-Tolerant Depth Perception for Shared Extended Space Experience on Wall-Sized Display",
    "url": "https://arxiv.org/abs/2508.06889",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06889v1 Announce Type: new \nAbstract: We proposed viewpoint-tolerant shared depth perception without individual tracking by leveraging human cognitive compensation in universally 3D rendered images on a wall-sized display. While traditional 3D perception-enabled display systems have primarily focused on single-user scenarios-adapting rendering based on head and eye tracking the use of wall-sized displays to extend spatial experiences and support perceptually coherent multi-user interactions remains underexplored. We investigated the effects of virtual depths (dv) and absolute viewing distance (da) on human cognitive compensation factors (perceived distance difference, viewing angle threshold, and perceived presence) to construct the wall display-based eXtended Reality (XR) space. Results show that participants experienced a compelling depth perception even from off-center angles of 23 to 37 degrees, and largely increasing virtual depth worsens depth perception and presence factors, highlighting the importance of balancing extended depth of virtual space and viewing distance from the wall-sized display. Drawing on these findings, wall-sized displays in venues such as museums, galleries, and classrooms can evolve beyond 2D information sharing to offer immersive, spatially extended group experiences without individualized tracking or wearables.",
    "source": "arXiv"
  },
  {
    "title": "Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody",
    "title_es": "Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody",
    "url": "https://arxiv.org/abs/2508.06890",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06890v1 Announce Type: new \nAbstract: Emotional voice conversion (EVC) aims to modify the emotional style of speech while preserving its linguistic content. In practical EVC, controllability, the ability to independently control speaker identity and emotional style using distinct references, is crucial. However, existing methods often struggle to fully disentangle these attributes and lack the ability to model fine-grained emotional expressions such as temporal dynamics. We propose Maestro-EVC, a controllable EVC framework that enables independent control of content, speaker identity, and emotion by effectively disentangling each attribute from separate references. We further introduce a temporal emotion representation and an explicit prosody modeling with prosody augmentation to robustly capture and transfer the temporal dynamics of the target emotion, even under prosody-mismatched conditions. Experimental results confirm that Maestro-EVC achieves high-quality, controllable, and emotionally expressive speech synthesis.",
    "source": "arXiv"
  },
  {
    "title": "Fusion-Based Brain Tumor Classification Using Deep Learning and Explainable AI, and Rule-Based Reasoning",
    "title_es": "Fusion-Based Brain Tumor Classification Using Deep Learning and Explainable AI, and Rule-Based Reasoning",
    "url": "https://arxiv.org/abs/2508.06891",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06891v1 Announce Type: new \nAbstract: Accurate and interpretable classification of brain tumors from magnetic resonance imaging (MRI) is critical for effective diagnosis and treatment planning. This study presents an ensemble-based deep learning framework that combines MobileNetV2 and DenseNet121 convolutional neural networks (CNNs) using a soft voting strategy to classify three common brain tumor types: glioma, meningioma, and pituitary adenoma. The models were trained and evaluated on the Figshare dataset using a stratified 5-fold cross-validation protocol. To enhance transparency and clinical trust, the framework integrates an Explainable AI (XAI) module employing Grad-CAM++ for class-specific saliency visualization, alongside a symbolic Clinical Decision Rule Overlay (CDRO) that maps predictions to established radiological heuristics. The ensemble classifier achieved superior performance compared to individual CNNs, with an accuracy of 91.7%, precision of 91.9%, recall of 91.7%, and F1-score of 91.6%. Grad-CAM++ visualizations revealed strong spatial alignment between model attention and expert-annotated tumor regions, supported by Dice coefficients up to 0.88 and IoU scores up to 0.78. Clinical rule activation further validated model predictions in cases with distinct morphological features. A human-centered interpretability assessment involving five board-certified radiologists yielded high Likert-scale scores for both explanation usefulness (mean = 4.4) and heatmap-region correspondence (mean = 4.0), reinforcing the framework's clinical relevance. Overall, the proposed approach offers a robust, interpretable, and generalizable solution for automated brain tumor classification, advancing the integration of deep learning into clinical neurodiagnostics.",
    "source": "arXiv"
  },
  {
    "title": "Average Consensus with Dynamic Compression in Bandwidth-Limited Directed Networks",
    "title_es": "Average Consensus with Dynamic Compression in Bandwidth-Limited Directed Networks",
    "url": "https://arxiv.org/abs/2508.06893",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06893v1 Announce Type: new \nAbstract: In this paper, the average consensus problem has been considered for directed unbalanced networks under finite bit-rate communication. We propose the Push-Pull Average Consensus algorithm with Dynamic Compression (PP-ACDC) algorithm, a distributed consensus algorithm that deploys an adaptive quantization scheme and achieves convergence to the exact average without the need of global information. A preliminary numerical convergence analysis and simulation results corroborate the performance of PP-ACDC.",
    "source": "arXiv"
  },
  {
    "title": "Pushdown Reward Machines for Reinforcement Learning",
    "title_es": "Pushdown Reward Machines for Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06894",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06894v1 Announce Type: new \nAbstract: Reward machines (RMs) are automata structures that encode (non-Markovian) reward functions for reinforcement learning (RL). RMs can reward any behaviour representable in regular languages and, when paired with RL algorithms that exploit RM structure, have been shown to significantly improve sample efficiency in many domains. In this work, we present pushdown reward machines (pdRMs), an extension of reward machines based on deterministic pushdown automata. pdRMs can recognize and reward temporally extended behaviours representable in deterministic context-free languages, making them more expressive than reward machines. We introduce two variants of pdRM-based policies, one which has access to the entire stack of the pdRM, and one which can only access the top $k$ symbols (for a given constant $k$) of the stack. We propose a procedure to check when the two kinds of policies (for a given environment, pdRM, and constant $k$) achieve the same optimal expected reward. We then provide theoretical results establishing the expressive power of pdRMs, and space complexity results about the proposed learning problems. Finally, we provide experimental results showing how agents can be trained to perform tasks representable in deterministic context-free languages using pdRMs.",
    "source": "arXiv"
  },
  {
    "title": "BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models",
    "title_es": "BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2508.06895",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06895v1 Announce Type: new \nAbstract: Mainstream Multimodal Large Language Models (MLLMs) achieve visual understanding by using a vision projector to bridge well-pretrained vision encoders and large language models (LLMs). The inherent gap between visual and textual modalities makes the embeddings from the vision projector critical for visual comprehension. However, current alignment approaches treat visual embeddings as contextual cues and merely apply auto-regressive supervision to textual outputs, neglecting the necessity of introducing equivalent direct visual supervision, which hinders the potential finer alignment of visual embeddings. In this paper, based on our analysis of the refinement process of visual embeddings in the LLM's shallow layers, we propose BASIC, a method that utilizes refined visual embeddings within the LLM as supervision to directly guide the projector in generating initial visual embeddings. Specifically, the guidance is conducted from two perspectives: (i) optimizing embedding directions by reducing angles between initial and supervisory embeddings in semantic space; (ii) improving semantic matching by minimizing disparities between the logit distributions of both visual embeddings. Without additional supervisory models or artificial annotations, BASIC significantly improves the performance of MLLMs across a wide range of benchmarks, demonstrating the effectiveness of our introduced direct visual supervision.",
    "source": "arXiv"
  },
  {
    "title": "Decoupling Structural Heterogeneity from Functional Fairness in Complex Networks: A Theoretical Framework based on the Imbalance Metric",
    "title_es": "Decoupling Structural Heterogeneity from Functional Fairness in Complex Networks: A Theoretical Framework based on the Imbalance Metric",
    "url": "https://arxiv.org/abs/2508.06898",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06898v1 Announce Type: new \nAbstract: Performance evaluation of complex networks has traditionally focused on structural integrity or average transmission efficiency, perspectives that often overlook the dimension of functional fairness. This raises a central question: Under certain conditions, structurally heterogeneous networks can exhibit high functional fairness. To systematically address this issue, we introduce a new metric, Network Imbalance (I), designed to quantitatively assess end-to-end accessibility fairness from a perceived QoS perspective. By combining a tunable sigmoid function with a global Shannon entropy framework, the I metric quantifies the uniformity of connection experiences between all node pairs. We analyze the mathematical properties of this metric and validate its explanatory power on various classical network models. Our findings reveal that low imbalance (i.e., high functional fairness) can be achieved through two distinct mechanisms: one via topological symmetry (e.g., in a complete graph) and the other via extreme connection efficiency driven by structural inequality (e.g., in a scale-free network). This decoupling of structure and function provides a new theoretical perspective for network performance evaluation and offers an effective quantitative tool for balancing efficiency and fairness in network design.",
    "source": "arXiv"
  },
  {
    "title": "GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization",
    "title_es": "GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization",
    "url": "https://arxiv.org/abs/2508.06899",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06899v1 Announce Type: new \nAbstract: Local search is an important class of incomplete algorithms for solving Distributed Constraint Optimization Problems (DCOPs) but it often converges to poor local optima. While GDBA provides a comprehensive rule set to escape premature convergence, its empirical benefits remain marginal on general-valued problems. In this work, we systematically examine GDBA and identify three factors that potentially lead to its inferior performance, i.e., over-aggressive constraint violation conditions, unbounded penalty accumulation, and uncoordinated penalty updates. To address these issues, we propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs that incorporates an adaptive violation condition to selectively penalize constraints with high cost, a penalty evaporation mechanism to control the magnitude of penalization, and a synchronization scheme for coordinated penalty updates. We theoretically show that the penalty values are bounded, and agents play a potential game in our DGLS. Our extensive empirical results on various standard benchmarks demonstrate the great superiority of DGLS over state-of-the-art baselines. Particularly, compared to Damped Max-sum with high damping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance on general-valued problems, and outperforms it by significant margins (\\textbf{3.77\\%--66.3\\%}) on structured problems in terms of anytime results.",
    "source": "arXiv"
  },
  {
    "title": "Advancements in Chinese font generation since deep learning era: A survey",
    "title_es": "Advancements in Chinese font generation since deep learning era: A survey",
    "url": "https://arxiv.org/abs/2508.06900",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06900v1 Announce Type: new \nAbstract: Chinese font generation aims to create a new Chinese font library based on some reference samples. It is a topic of great concern to many font designers and typographers. Over the past years, with the rapid development of deep learning algorithms, various new techniques have achieved flourishing and thriving progress. Nevertheless, how to improve the overall quality of generated Chinese character images remains a tough issue. In this paper, we conduct a holistic survey of the recent Chinese font generation approaches based on deep learning. To be specific, we first illustrate the research background of the task. Then, we outline our literature selection and analysis methodology, and review a series of related fundamentals, including classical deep learning architectures, font representation formats, public datasets, and frequently-used evaluation metrics. After that, relying on the number of reference samples required to generate a new font, we categorize the existing methods into two major groups: many-shot font generation and few-shot font generation methods. Within each category, representative approaches are summarized, and their strengths and limitations are also discussed in detail. Finally, we conclude our paper with the challenges and future directions, with the expectation to provide some valuable illuminations for the researchers in this field.",
    "source": "arXiv"
  },
  {
    "title": "eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos",
    "title_es": "eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos",
    "url": "https://arxiv.org/abs/2508.06902",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06902v1 Announce Type: new \nAbstract: Short-form videos (SVs) have become a vital part of our online routine for acquiring and sharing information. Their multimodal complexity poses new challenges for video analysis, highlighting the need for video emotion analysis (VEA) within the community. Given the limited availability of SVs emotion data, we introduce eMotions, a large-scale dataset consisting of 27,996 videos with full-scale annotations. To ensure quality and reduce subjective bias, we emphasize better personnel allocation and propose a multi-stage annotation procedure. Additionally, we provide the category-balanced and test-oriented variants through targeted sampling to meet diverse needs. While there have been significant studies on videos with clear emotional cues (e.g., facial expressions), analyzing emotions in SVs remains a challenging task. The challenge arises from the broader content diversity, which introduces more distinct semantic gaps and complicates the representations learning of emotion-related features. Furthermore, the prevalence of audio-visual co-expressions in SVs leads to the local biases and collective information gaps caused by the inconsistencies in emotional expressions. To tackle this, we propose AV-CANet, an end-to-end audio-visual fusion network that leverages video transformer to capture semantically relevant representations. We further introduce the Local-Global Fusion Module designed to progressively capture the correlations of audio-visual features. Besides, EP-CE Loss is constructed to globally steer optimizations with tripolar penalties. Extensive experiments across three eMotions-related datasets and four public VEA datasets demonstrate the effectiveness of our proposed AV-CANet, while providing broad insights for future research. Moreover, we conduct ablation studies to examine the critical components of our method. Dataset and code will be made available at Github.",
    "source": "arXiv"
  },
  {
    "title": "A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation",
    "title_es": "A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation",
    "url": "https://arxiv.org/abs/2508.06904",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06904v1 Announce Type: new \nAbstract: Camouflaged Object Segmentation (COS) remains highly challenging due to the intrinsic visual similarity between target objects and their surroundings. While training-based COS methods achieve good performance, their performance degrades rapidly with increased annotation sparsity. To circumvent this limitation, recent studies have explored training-free COS methods, leveraging the Segment Anything Model (SAM) by automatically generating visual prompts from a single task-generic prompt (\\textit{e.g.}, \"\\textit{camouflaged animal}\") uniformly applied across all test images. However, these methods typically produce only semantic-level visual prompts, causing SAM to output coarse semantic masks and thus failing to handle scenarios with multiple discrete camouflaged instances effectively. To address this critical limitation, we propose a simple yet powerful \\textbf{I}nstance-\\textbf{A}ware \\textbf{P}rompting \\textbf{F}ramework (IAPF), the first training-free COS pipeline that explicitly converts a task-generic prompt into fine-grained instance masks. Specifically, the IAPF comprises three steps: (1) Text Prompt Generator, utilizing task-generic queries to prompt a Multimodal Large Language Model (MLLM) for generating image-specific foreground and background tags; (2) \\textbf{Instance Mask Generator}, leveraging Grounding DINO to produce precise instance-level bounding box prompts, alongside the proposed Single-Foreground Multi-Background Prompting strategy to sample region-constrained point prompts within each box, enabling SAM to yield a candidate instance mask; (3) Self-consistency Instance Mask Voting, which selects the final COS prediction by identifying the candidate mask most consistent across multiple candidate instance masks. Extensive evaluations on standard COS benchmarks demonstrate that the proposed IAPF significantly surpasses existing state-of-the-art training-free COS methods.",
    "source": "arXiv"
  },
  {
    "title": "MultiRef: Controllable Image Generation with Multiple Visual References",
    "title_es": "MultiRef: Controllable Image Generation with Multiple Visual References",
    "url": "https://arxiv.org/abs/2508.06905",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06905v1 Announce Type: new \nAbstract: Visual designers naturally draw inspiration from multiple visual references, combining diverse elements and aesthetic principles to create artwork. However, current image generative frameworks predominantly rely on single-source inputs -- either text prompts or individual reference images. In this paper, we focus on the task of controllable image generation using multiple visual references. We introduce MultiRef-bench, a rigorous evaluation framework comprising 990 synthetic and 1,000 real-world samples that require incorporating visual content from multiple reference images. The synthetic samples are synthetically generated through our data engine RefBlend, with 10 reference types and 33 reference combinations. Based on RefBlend, we further construct a dataset MultiRef containing 38k high-quality images to facilitate further research. Our experiments across three interleaved image-text models (i.e., OmniGen, ACE, and Show-o) and six agentic frameworks (e.g., ChatDiT and LLM + SD) reveal that even state-of-the-art systems struggle with multi-reference conditioning, with the best model OmniGen achieving only 66.6% in synthetic samples and 79.0% in real-world cases on average compared to the golden answer. These findings provide valuable directions for developing more flexible and human-like creative tools that can effectively integrate multiple sources of visual inspiration. The dataset is publicly available at: https://multiref.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification",
    "title_es": "MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification",
    "url": "https://arxiv.org/abs/2508.06908",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06908v1 Announce Type: new \nAbstract: Person re-identification (ReID) aims to retrieve the images of an interested person in the gallery images, with wide applications in medical rehabilitation, abnormal behavior detection, and public security. However, traditional person ReID models suffer from uni-modal capability, leading to poor generalization ability in multi-modal data, such as RGB, thermal, infrared, sketch images, textual descriptions, etc. Recently, the emergence of multi-modal large language models (MLLMs) shows a promising avenue for addressing this problem. Despite this potential, existing methods merely regard MLLMs as feature extractors or caption generators, which do not fully unleash their reasoning, instruction-following, and cross-modal understanding capabilities. To bridge this gap, we introduce MMReID-Bench, the first multi-task multi-modal benchmark specifically designed for person ReID. The MMReID-Bench includes 20,710 multi-modal queries and gallery images covering 10 different person ReID tasks. Comprehensive experiments demonstrate the remarkable capabilities of MLLMs in delivering effective and versatile person ReID. Nevertheless, they also have limitations in handling a few modalities, particularly thermal and infrared data. We hope MMReID-Bench can facilitate the community to develop more robust and generalizable multimodal foundation models for person ReID.",
    "source": "arXiv"
  },
  {
    "title": "Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection",
    "title_es": "Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection",
    "url": "https://arxiv.org/abs/2508.06913",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06913v1 Announce Type: new \nAbstract: The rapid advancement of large language models (LLMs) has resulted in increasingly sophisticated AI-generated content, posing significant challenges in distinguishing LLM-generated text from human-written language. Existing detection methods, primarily based on lexical heuristics or fine-tuned classifiers, often suffer from limited generalizability and are vulnerable to paraphrasing, adversarial perturbations, and cross-domain shifts. In this work, we propose SentiDetect, a model-agnostic framework for detecting LLM-generated text by analyzing the divergence in sentiment distribution stability. Our method is motivated by the empirical observation that LLM outputs tend to exhibit emotionally consistent patterns, whereas human-written texts display greater emotional variability. To capture this phenomenon, we define two complementary metrics: sentiment distribution consistency and sentiment distribution preservation, which quantify stability under sentiment-altering and semantic-preserving transformations. We evaluate SentiDetect on five diverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro, Claude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its superiority over state-of-the-art baselines, with over 16% and 11% F1 score improvements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover, SentiDetect also shows greater robustness to paraphrasing, adversarial attacks, and text length variations, outperforming existing detectors in challenging scenarios.",
    "source": "arXiv"
  },
  {
    "title": "QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting",
    "title_es": "QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting",
    "url": "https://arxiv.org/abs/2508.06915",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06915v1 Announce Type: new \nAbstract: Time series forecasting has become increasingly important to empower diverse applications with streaming data. Zero-shot time-series forecasting (ZSF), particularly valuable in data-scarce scenarios, such as domain transfer or forecasting under extreme conditions, is difficult for traditional models to deal with. While time series pre-trained models (TSPMs) have demonstrated strong performance in ZSF, they often lack mechanisms to dynamically incorporate external knowledge. Fortunately, emerging retrieval-augmented generation (RAG) offers a promising path for injecting such knowledge on demand, yet they are rarely integrated with TSPMs. To leverage the strengths of both worlds, we introduce RAG into TSPMs to enhance zero-shot time series forecasting. In this paper, we propose QuiZSF (Quick Zero-Shot Time Series Forecaster), a lightweight and modular framework that couples efficient retrieval with representation learning and model adaptation for ZSF. Specifically, we construct a hierarchical tree-structured ChronoRAG Base (CRB) for scalable time-series storage and domain-aware retrieval, introduce a Multi-grained Series Interaction Learner (MSIL) to extract fine- and coarse-grained relational features, and develop a dual-branch Model Cooperation Coherer (MCC) that aligns retrieved knowledge with two kinds of TSPMs: Non-LLM based and LLM based. Compared with contemporary baselines, QuiZSF, with Non-LLM based and LLM based TSPMs as base model, respectively, ranks Top1 in 75% and 87.5% of prediction settings, while maintaining high efficiency in memory and inference time.",
    "source": "arXiv"
  },
  {
    "title": "Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing",
    "title_es": "Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing",
    "url": "https://arxiv.org/abs/2508.06916",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06916v1 Announce Type: new \nAbstract: Text-to-image generation tasks have driven remarkable advances in diverse media applications, yet most focus on single-turn scenarios and struggle with iterative, multi-turn creative tasks. Recent dialogue-based systems attempt to bridge this gap, but their single-agent, sequential paradigm often causes intention drift and incoherent edits. To address these limitations, we present Talk2Image, a novel multi-agent system for interactive image generation and editing in multi-turn dialogue scenarios. Our approach integrates three key components: intention parsing from dialogue history, task decomposition and collaborative execution across specialized agents, and feedback-driven refinement based on a multi-view evaluation mechanism. Talk2Image enables step-by-step alignment with user intention and consistent image editing. Experiments demonstrate that Talk2Image outperforms existing baselines in controllability, coherence, and user satisfaction across iterative image generation and editing tasks.",
    "source": "arXiv"
  },
  {
    "title": "Vibration-Based Energy Metric for Restoring Needle Alignment in Autonomous Robotic Ultrasound",
    "title_es": "Vibration-Based Energy Metric for Restoring Needle Alignment in Autonomous Robotic Ultrasound",
    "url": "https://arxiv.org/abs/2508.06921",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06921v1 Announce Type: new \nAbstract: Precise needle alignment is essential for percutaneous needle insertion in robotic ultrasound-guided procedures. However, inherent challenges such as speckle noise, needle-like artifacts, and low image resolution make robust needle detection difficult, particularly when visibility is reduced or lost. In this paper, we propose a method to restore needle alignment when the ultrasound imaging plane and the needle insertion plane are misaligned. Unlike many existing approaches that rely heavily on needle visibility in ultrasound images, our method uses a more robust feature by periodically vibrating the needle using a mechanical system. Specifically, we propose a vibration-based energy metric that remains effective even when the needle is fully out of plane. Using this metric, we develop a control strategy to reposition the ultrasound probe in response to misalignments between the imaging plane and the needle insertion plane in both translation and rotation. Experiments conducted on ex-vivo porcine tissue samples using a dual-arm robotic ultrasound-guided needle insertion system demonstrate the effectiveness of the proposed approach. The experimental results show the translational error of 0.41$\\pm$0.27 mm and the rotational error of 0.51$\\pm$0.19 degrees.",
    "source": "arXiv"
  },
  {
    "title": "AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning",
    "title_es": "AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06924",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06924v1 Announce Type: new \nAbstract: Inspired by the success of reinforcement learning (RL) in refining large language models (LLMs), we propose AR-GRPO, an approach to integrate online RL training into autoregressive (AR) image generation models. We adapt the Group Relative Policy Optimization (GRPO) algorithm to refine the vanilla autoregressive models' outputs by carefully designed reward functions that evaluate generated images across multiple quality dimensions, including perceptual quality, realism, and semantic fidelity. We conduct comprehensive experiments on both class-conditional (i.e., class-to-image) and text-conditional (i.e., text-to-image) image generation tasks, demonstrating that our RL-enhanced framework significantly improves both the image quality and human preference of generated images compared to the standard AR baselines. Our results show consistent improvements across various evaluation metrics, establishing the viability of RL-based optimization for AR image generation and opening new avenues for controllable and high-quality image synthesis. The source codes and models are available at: https://github.com/Kwai-Klear/AR-GRPO.",
    "source": "arXiv"
  },
  {
    "title": "Integrating Rules and Semantics for LLM-Based C-to-Rust Translation",
    "title_es": "Integrating Rules and Semantics for LLM-Based C-to-Rust Translation",
    "url": "https://arxiv.org/abs/2508.06926",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06926v1 Announce Type: new \nAbstract: Automated translation of legacy C code into Rust aims to ensure memory safety while reducing the burden of manual migration. Early approaches in code translation rely on static rule-based methods, but they suffer from limited coverage due to dependence on predefined rule patterns. Recent works regard the task as a sequence-to-sequence problem by leveraging large language models (LLMs). Although these LLM-based methods are capable of reducing unsafe code blocks, the translated code often exhibits issues in following Rust rules and maintaining semantic consistency. On one hand, existing methods adopt a direct prompting strategy to translate the C code, which struggles to accommodate the syntactic rules between C and Rust. On the other hand, this strategy makes it difficult for LLMs to accurately capture the semantics of complex code. To address these challenges, we propose IRENE, an LLM-based framework that Integrates RulEs aNd sEmantics to enhance translation. IRENE consists of three modules: 1) a rule-augmented retrieval module that selects relevant translation examples based on rules generated from a static analyzer developed by us, thereby improving the handling of Rust rules; 2) a structured summarization module that produces a structured summary for guiding LLMs to enhance the semantic understanding of C code; 3) an error-driven translation module that leverages compiler diagnostics to iteratively refine translations. We evaluate IRENE on two datasets (xCodeEval, a public dataset, and HW-Bench, an industrial dataset provided by Huawei) and eight LLMs, focusing on translation accuracy and safety.",
    "source": "arXiv"
  },
  {
    "title": "Automated Formalization via Conceptual Retrieval-Augmented LLMs",
    "title_es": "Automated Formalization via Conceptual Retrieval-Augmented LLMs",
    "url": "https://arxiv.org/abs/2508.06931",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06931v1 Announce Type: new \nAbstract: Interactive theorem provers (ITPs) require manual formalization, which is labor-intensive and demands expert knowledge. While automated formalization offers a potential solution, it faces two major challenges: model hallucination (e.g., undefined predicates, symbol misuse, and version incompatibility) and the semantic gap caused by ambiguous or missing premises in natural language descriptions. To address these issues, we propose CRAMF, a Concept-driven Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances LLM-based autoformalization by retrieving formal definitions of core mathematical concepts, providing contextual grounding during code generation. However, applying retrieval-augmented generation (RAG) in this setting is non-trivial due to the lack of structured knowledge bases, the polymorphic nature of mathematical concepts, and the high precision required in formal retrieval. We introduce a framework for automatically constructing a concept-definition knowledge base from Mathlib4, the standard mathematical library for the Lean 4 theorem prover, indexing over 26,000 formal definitions and 1,000+ core mathematical concepts. To address conceptual polymorphism, we propose contextual query augmentation with domain- and application-level signals. In addition, we design a dual-channel hybrid retrieval strategy with reranking to ensure accurate and relevant definition retrieval. Experiments on miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding consistent improvements in translation accuracy, achieving up to 62.1% and an average of 29.9% relative improvement.",
    "source": "arXiv"
  },
  {
    "title": "CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing",
    "title_es": "CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing",
    "url": "https://arxiv.org/abs/2508.06937",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06937v1 Announce Type: new \nAbstract: Recent advances in text-to-image (T2I) models have enabled training-free regional image editing by leveraging the generative priors of foundation models. However, existing methods struggle to balance text adherence in edited regions, context fidelity in unedited areas, and seamless integration of edits. We introduce CannyEdit, a novel training-free framework that addresses these challenges through two key innovations: (1) Selective Canny Control, which masks the structural guidance of Canny ControlNet in user-specified editable regions while strictly preserving details of the source images in unedited areas via inversion-phase ControlNet information retention. This enables precise, text-driven edits without compromising contextual integrity. (2) Dual-Prompt Guidance, which combines local prompts for object-specific edits with a global target prompt to maintain coherent scene interactions. On real-world image editing tasks (addition, replacement, removal), CannyEdit outperforms prior methods like KV-Edit, achieving a 2.93 to 10.49 percent improvement in the balance of text adherence and context fidelity. In terms of editing seamlessness, user studies reveal only 49.2 percent of general users and 42.0 percent of AIGC experts identified CannyEdit's results as AI-edited when paired with real images without edits, versus 76.08 to 89.09 percent for competitor methods.",
    "source": "arXiv"
  },
  {
    "title": "Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction",
    "title_es": "Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction",
    "url": "https://arxiv.org/abs/2508.06939",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06939v1 Announce Type: new \nAbstract: Multimodal learning enables various machine learning tasks to benefit from diverse data sources, effectively mimicking the interplay of different factors in real-world applications, particularly in agriculture. While the heterogeneous nature of involved data modalities may necessitate the design of complex architectures, the model interpretability is often overlooked. In this study, we leverage the intrinsic explainability of Transformer-based models to explain multimodal learning networks, focusing on the task of crop yield prediction at the subfield level. The large datasets used cover various crops, regions, and years, and include four different input modalities: multispectral satellite and weather time series, terrain elevation maps and soil properties. Based on the self-attention mechanism, we estimate feature attributions using two methods, namely the Attention Rollout (AR) and Generic Attention (GA), and evaluate their performance against Shapley-based model-agnostic estimations, Shapley Value Sampling (SVS). Additionally, we propose the Weighted Modality Activation (WMA) method to assess modality attributions and compare it with SVS attributions. Our findings indicate that Transformer-based models outperform other architectures, specifically convolutional and recurrent networks, achieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field levels, respectively. AR is shown to provide more robust and reliable temporal attributions, as confirmed through qualitative and quantitative evaluation, compared to GA and SVS values. Information about crop phenology stages was leveraged to interpret the explanation results in the light of established agronomic knowledge. Furthermore, modality attributions revealed varying patterns across the two methods compared.[...]",
    "source": "arXiv"
  },
  {
    "title": "Generalized Samorodnitsky noisy function inequalities, with applications to error-correcting codes",
    "title_es": "Generalized Samorodnitsky noisy function inequalities, with applications to error-correcting codes",
    "url": "https://arxiv.org/abs/2508.06940",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06940v1 Announce Type: new \nAbstract: An inequality by Samorodnitsky states that if $f : \\mathbb{F}_2^n \\to \\mathbb{R}$ is a nonnegative boolean function, and $S \\subseteq [n]$ is chosen by randomly including each coordinate with probability a certain $\\lambda = \\lambda(q,\\rho) < 1$, then \\begin{equation}\n  \\log \\|T_\\rho f\\|_q \\leq \\mathbb{E}_{S} \\log \\|\\mathbb{E}(f|S)\\|_q\\;. \\end{equation} Samorodnitsky's inequality has several applications to the theory of error-correcting codes. Perhaps most notably, it can be used to show that \\emph{any} binary linear code (with minimum distance $\\omega(\\log n)$) that has vanishing decoding error probability on the BEC$(\\lambda)$ (binary erasure channel) also has vanishing decoding error on \\emph{all} memoryless symmetric channels with capacity above some $C = C(\\lambda)$.\n  Samorodnitsky determined the optimal $\\lambda = \\lambda(q,\\rho)$ for his inequality in the case that $q \\geq 2$ is an integer. In this work, we generalize the inequality to $f : \\Omega^n \\to \\mathbb{R}$ under any product probability distribution $\\mu^{\\otimes n}$ on $\\Omega^n$; moreover, we determine the optimal value of $\\lambda = \\lambda(q,\\mu,\\rho)$ for any real $q \\in [2,\\infty]$, $\\rho \\in [0,1]$, and distribution~$\\mu$. As one consequence, we obtain the aforementioned coding theory result for linear codes over \\emph{any} finite alphabet.",
    "source": "arXiv"
  },
  {
    "title": "CLAP: Coreference-Linked Augmentation for Passage Retrieval",
    "title_es": "CLAP: Coreference-Linked Augmentation for Passage Retrieval",
    "url": "https://arxiv.org/abs/2508.06941",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06941v1 Announce Type: new \nAbstract: Large Language Model (LLM)-based passage expansion has shown promise for enhancing first-stage retrieval, but often underperforms with dense retrievers due to semantic drift and misalignment with their pretrained semantic space. Beyond this, only a portion of a passage is typically relevant to a query, while the rest introduces noise--an issue compounded by chunking techniques that break coreference continuity. We propose Coreference-Linked Augmentation for Passage Retrieval (CLAP), a lightweight LLM-based expansion framework that segments passages into coherent chunks, resolves coreference chains, and generates localized pseudo-queries aligned with dense retriever representations. A simple fusion of global topical signals and fine-grained subtopic signals achieves robust performance across domains. CLAP yields consistent gains even as retriever strength increases, enabling dense retrievers to match or surpass second-stage rankers such as BM25 + MonoT5-3B, with up to 20.68% absolute nDCG@10 improvement. These improvements are especially notable in out-of-domain settings, where conventional LLM-based expansion methods relying on domain knowledge often falter. CLAP instead adopts a logic-centric pipeline that enables robust, domain-agnostic generalization.",
    "source": "arXiv"
  },
  {
    "title": "When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust \"APIs'' for Human-AI Interaction",
    "title_es": "When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust \"APIs'' for Human-AI Interaction",
    "url": "https://arxiv.org/abs/2508.06942",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06942v1 Announce Type: new \nAbstract: With the growing capabilities of large language models (LLMs), they are increasingly applied in areas like intelligent customer service, code generation, and knowledge management. Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction. To improve prompt quality, best practices for prompt engineering (PE) have been developed, including writing guidelines and templates. Building on this, we propose Controlled NL for Prompt (CNL-P), which not only incorporates PE best practices but also draws on key principles from software engineering (SE). CNL-P introduces precise grammar structures and strict semantic norms, further eliminating NL's ambiguity, allowing for a declarative but structured and accurate expression of user intent. This helps LLMs better interpret and execute the prompts, leading to more consistent and higher-quality outputs. We also introduce an NL2CNL-P conversion tool based on LLMs, enabling users to write prompts in NL, which are then transformed into CNL-P format, thus lowering the learning curve of CNL-P. In particular, we develop a linting tool that checks CNL-P prompts for syntactic and semantic accuracy, applying static analysis techniques to NL for the first time. Extensive experiments demonstrate that CNL-P enhances the quality of LLM responses through the novel and organic synergy of PE and SE. We believe that CNL-P can bridge the gap between emerging PE and traditional SE, laying the foundation for a new programming paradigm centered around NL.",
    "source": "arXiv"
  },
  {
    "title": "Class Unbiasing for Generalization in Medical Diagnosis",
    "title_es": "Class Unbiasing for Generalization in Medical Diagnosis",
    "url": "https://arxiv.org/abs/2508.06943",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06943v1 Announce Type: new \nAbstract: Medical diagnosis might fail due to bias. In this work, we identified class-feature bias, which refers to models' potential reliance on features that are strongly correlated with only a subset of classes, leading to biased performance and poor generalization on other classes. We aim to train a class-unbiased model (Cls-unbias) that mitigates both class imbalance and class-feature bias simultaneously. Specifically, we propose a class-wise inequality loss which promotes equal contributions of classification loss from positive-class and negative-class samples. We propose to optimize a class-wise group distributionally robust optimization objective-a class-weighted training objective that upweights underperforming classes-to enhance the effectiveness of the inequality loss under class imbalance. Through synthetic and real-world datasets, we empirically demonstrate that class-feature bias can negatively impact model performance. Our proposed method effectively mitigates both class-feature bias and class imbalance, thereby improving the model's generalization ability.",
    "source": "arXiv"
  },
  {
    "title": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance",
    "title_es": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance",
    "url": "https://arxiv.org/abs/2508.06944",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06944v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL), a process fraught with catastrophic forgetting and suboptimal trade-offs between imitation and exploration. Recent single-stage methods attempt to unify SFT and RL using heuristics, but lack a principled mechanism for dynamically balancing the two paradigms. In this paper, we reframe this challenge through the theoretical lens of \\textbf{implicit rewards}, viewing SFT and RL not as distinct methods but as complementary reward signals. We introduce \\textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel single-stage algorithm that learns the optimal balance between SFT's implicit, path-level reward and RL's explicit, outcome-based reward. The core of AMFT is a \\textbf{meta-gradient adaptive weight controller} that treats the SFT-RL balance as a learnable parameter, dynamically optimizing it to maximize long-term task performance. This forward-looking approach, regularized by policy entropy for stability, autonomously discovers an effective training curriculum. We conduct a comprehensive evaluation on challenging benchmarks spanning mathematical reasoning, abstract visual reasoning (General Points), and vision-language navigation (V-IRL). AMFT consistently establishes a new state-of-the-art and demonstrats superior generalization on out-of-distribution (OOD) tasks. Ablation studies and training dynamic analysis confirm that the meta-learning controller is crucial for AMFT's stability, sample efficiency, and performance, offering a more principled and effective paradigm for LLM alignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.",
    "source": "arXiv"
  },
  {
    "title": "Kairos: Low-latency Multi-Agent Serving with Shared LLMs and Excessive Loads in the Public Cloud",
    "title_es": "Kairos: Low-latency Multi-Agent Serving with Shared LLMs and Excessive Loads in the Public Cloud",
    "url": "https://arxiv.org/abs/2508.06948",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06948v1 Announce Type: new \nAbstract: Multi-agent applications utilize the advanced capabilities of large language models (LLMs) for intricate task completion through agent collaboration in a workflow. Under this situation, requests from different agents usually access the same shared LLM to perform different kinds of tasks, forcing the shared LLM to suffer excessive loads. However, existing works have low serving performance for these multi-agent applications, mainly due to the ignorance of inter-agent latency and resource differences for request scheduling. We therefore propose Kairos, a multi-agent orchestration system that optimizes end-to-end latency for multi-agent applications. Kairos consists of a workflow orchestrator, a workflow-aware priority scheduler, and a memory-aware dispatcher. The orchestrator collects agent-specific information for online workflow analysis. The scheduler decides the serving priority of the requests based on their latency characteristics to reduce the overall queuing. The dispatcher dispatches the requests to different LLM instances based on their memory demands to avoid GPU overloading. Experimental results show that Kairos reduces end-to-end latency by 17.8% to 28.4% compared to state-of-the-art works.",
    "source": "arXiv"
  },
  {
    "title": "Convergence Sans Synchronization",
    "title_es": "Convergence Sans Synchronization",
    "url": "https://arxiv.org/abs/2508.06949",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06949v1 Announce Type: new \nAbstract: We currently see a steady rise in the usage and size of multiprocessor systems, and so the community is evermore interested in developing fast parallel processing algorithms. However, most algorithms require a synchronization mechanism, which is costly in terms of computational resources and time. If an algorithm can be executed in asynchrony, then it can use all the available computation power, and the nodes can execute without being scheduled or locked. However, to show that an algorithm guarantees convergence in asynchrony, we need to generate the entire global state transition graph and check for the absence of cycles. This takes time exponential in the size of the global state space. In this dissertation, we present a theory that explains the necessary and sufficient properties of a multiprocessor algorithm that guarantees convergence even without synchronization. We develop algorithms for various problems that do not require synchronization. Additionally, we show for several existing algorithms that they can be executed without any synchronization mechanism. A significant theoretical benefit of our work is in proving that an algorithm can converge even in asynchrony. Our theory implies that we can make such conclusions about an algorithm, by only showing that the local state transition graph of a computing node forms a partial order, rather than generating the entire global state space and determining the absence of cycles in it. Thus, the complexity of rendering such proofs, formal or social, is phenomenally reduced. Experiments show a significant reduction in time taken to converge, when we compare the execution time of algorithms in the literature versus the algorithms that we design. We get similar results when we run an algorithm, that guarantees convergence in asynchrony, under a scheduler versus in asynchrony.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models Do Not Simulate Human Psychology",
    "title_es": "Large Language Models Do Not Simulate Human Psychology",
    "url": "https://arxiv.org/abs/2508.06950",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06950v1 Announce Type: new \nAbstract: Large Language Models (LLMs),such as ChatGPT, are increasingly used in research, ranging from simple writing assistance to complex data annotation tasks. Recently, some research has suggested that LLMs may even be able to simulate human psychology and can, hence, replace human participants in psychological studies. We caution against this approach. We provide conceptual arguments against the hypothesis that LLMs simulate human psychology. We then present empiric evidence illustrating our arguments by demonstrating that slight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs' and human responses, even for the recent CENTAUR model that was specifically fine-tuned on psychological responses. Additionally, different LLMs show very different responses to novel items, further illustrating their lack of reliability. We conclude that LLMs do not simulate human psychology and recommend that psychological researchers should treat LLMs as useful but fundamentally unreliable tools that need to be validated against human responses for every new application.",
    "source": "arXiv"
  },
  {
    "title": "SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work",
    "title_es": "SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work",
    "url": "https://arxiv.org/abs/2508.06951",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06951v1 Announce Type: new \nAbstract: Sign Language Production (SLP) is the task of generating sign language video from spoken language inputs. The field has seen a range of innovations over the last few years, with the introduction of deep learning-based approaches providing significant improvements in the realism and naturalness of generated outputs. However, the lack of standardized evaluation metrics for SLP approaches hampers meaningful comparisons across different systems. To address this, we introduce the first Sign Language Production Challenge, held as part of the third SLRTP Workshop at CVPR 2025. The competition's aims are to evaluate architectures that translate from spoken language sentences to a sequence of skeleton poses, known as Text-to-Pose (T2P) translation, over a range of metrics. For our evaluation data, we use the RWTH-PHOENIX-Weather-2014T dataset, a German Sign Language - Deutsche Gebardensprache (DGS) weather broadcast dataset. In addition, we curate a custom hidden test set from a similar domain of discourse. This paper presents the challenge design and the winning methodologies. The challenge attracted 33 participants who submitted 231 solutions, with the top-performing team achieving BLEU-1 scores of 31.40 and DTW-MJE of 0.0574. The winning approach utilized a retrieval-based framework and a pre-trained language model. As part of the workshop, we release a standardized evaluation network, including high-quality skeleton extraction-based keypoints establishing a consistent baseline for the SLP field, which will enable future researchers to compare their work against a broader range of methods.",
    "source": "arXiv"
  },
  {
    "title": "BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity",
    "title_es": "BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity",
    "url": "https://arxiv.org/abs/2508.06953",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06953v1 Announce Type: new \nAbstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method widely used in large language models (LLMs). It approximates the update of a pretrained weight matrix $W\\in\\mathbb{R}^{m\\times n}$ by the product of two low-rank matrices, $BA$, where $A \\in\\mathbb{R}^{r\\times n}$ and $B\\in\\mathbb{R}^{m\\times r} (r\\ll\\min\\{m,n\\})$. Increasing the dimension $r$ can raise the rank of LoRA weights (i.e., $BA$), which typically improves fine-tuning performance but also significantly increases the number of trainable parameters. In this paper, we propose Block Diversified Low-Rank Adaptation (BoRA), which improves the rank of LoRA weights with a small number of additional parameters. Specifically, BoRA treats the product $BA$ as a block matrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along the columns and rows, respectively (i.e., $A=[A_1,\\dots,A_b]$ and $B=[B_1,\\dots,B_b]^\\top$). Consequently, the product $BA$ becomes the concatenation of the block products $B_iA_j$ for $i,j\\in[b]$. To enhance the diversity of different block products, BoRA introduces a unique diagonal matrix $\\Sigma_{i,j} \\in \\mathbb{R}^{r\\times r}$ for each block multiplication, resulting in $B_i \\Sigma_{i,j} A_j$. By leveraging these block-wise diagonal matrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only requiring $b^2r$ additional parameters. Extensive experiments across multiple datasets and models demonstrate the superiority of BoRA, and ablation studies further validate its scalability.",
    "source": "arXiv"
  },
  {
    "title": "Your Thoughtful Opponent: Embracing Cognitive Conflict with Peer Agent",
    "title_es": "Your Thoughtful Opponent: Embracing Cognitive Conflict with Peer Agent",
    "url": "https://arxiv.org/abs/2508.06955",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06955v1 Announce Type: new \nAbstract: As complex societal issues continue to emerge, fostering democratic skills like valuing diverse perspectives and collaborative decision-making is increasingly vital in education. In this paper, we propose a Peer Agent (PA) system designed to simulate a deliberative conversational partner that induces socio-cognitive conflict within dilemma-based game play. Drawing on by the Inner Thoughts framework and grounded in value-sensitive discourse analysis, the PA actively participates in voice-based multi-party deliberation with human players. The system architecture consists of five core modules: Context Interpreter, Agent State Manager, Thought Generator, Thought Evaluator, and Thought Articulator.",
    "source": "arXiv"
  },
  {
    "title": "Neural Beam Field for Spatial Beam RSRP Prediction",
    "title_es": "Neural Beam Field for Spatial Beam RSRP Prediction",
    "url": "https://arxiv.org/abs/2508.06956",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06956v1 Announce Type: new \nAbstract: Accurately predicting beam-level reference signal received power (RSRP) is essential for beam management in dense multi-user wireless networks, yet challenging due to high measurement overhead and fast channel variations. This paper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for efficient and interpretable spatial beam RSRP prediction. Central to our approach is the introduction of the Multi-path Conditional Power Profile (MCPP), which bridges site-specific multipath propagation with antenna/beam configurations via closed-form analytical modeling. We adopt a decoupled ``blackbox-whitebox\" design: a Transformer-based deep neural network (DNN) learns the MCPP from sparse user measurements and positions, while a physics-inspired module analytically infers beam RSRP statistics. To improve convergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC) strategy that leverages ray-tracing priors and on-site calibration using RSRP data. Extensive simulations results demonstrate that NBF significantly outperforms conventional table-based channel knowledge maps (CKMs) and pure blackbox DNNs in prediction accuracy, training efficiency, and generalization, while maintaining a compact model size. The proposed framework offers a scalable and physically grounded solution for intelligent beam management in next-generation dense wireless networks.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification",
    "title_es": "Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification",
    "url": "https://arxiv.org/abs/2508.06959",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06959v1 Announce Type: new \nAbstract: The crux of resolving fine-grained visual classification (FGVC) lies in capturing discriminative and class-specific cues that correspond to subtle visual characteristics. Recently, frequency decomposition/transform based approaches have attracted considerable interests since its appearing discriminative cue mining ability. However, the frequency-domain methods are based on fixed basis functions, lacking adaptability to image content and unable to dynamically adjust feature extraction according to the discriminative requirements of different images. To address this, we propose a novel method for FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively enhances the representational capability of low-level details and high-level semantics in the spatial domain, breaking through the limitations of fixed scales in the frequency domain and improving the flexibility of multi-scale fusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor (SDE), which dynamically enhances subtle details such as edges and textures from shallow features, and the Salient Semantic Refiner (SSR), which learns semantically coherent and structure-aware refinement features from the high-level features guided by the enhanced shallow features. The SDE and SSR are cascaded stage-by-stage to progressively combine local details with global semantics. Extensive experiments demonstrate that our method achieves new state-of-the-art on four popular fine-grained image classification benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery",
    "title_es": "DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery",
    "url": "https://arxiv.org/abs/2508.06960",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06960v1 Announce Type: new \nAbstract: The rapid advancement of large language models has fundamentally shifted the bottleneck in AI development from computational power to data availability-with countless valuable datasets remaining hidden across specialized repositories, research appendices, and domain platforms. As reasoning capabilities and deep research methodologies continue to evolve, a critical question emerges: can AI agents transcend conventional search to systematically discover any dataset that meets specific user requirements, enabling truly autonomous demand-driven data curation? We introduce DatasetResearch, the first comprehensive benchmark evaluating AI agents' ability to discover and synthesize datasets from 208 real-world demands across knowledge-intensive and reasoning-intensive tasks. Our tri-dimensional evaluation framework reveals a stark reality: even advanced deep research systems achieve only 22% score on our challenging DatasetResearch-pro subset, exposing the vast gap between current capabilities and perfect dataset discovery. Our analysis uncovers a fundamental dichotomy-search agents excel at knowledge tasks through retrieval breadth, while synthesis agents dominate reasoning challenges via structured generation-yet both catastrophically fail on \"corner cases\" outside existing distributions. These findings establish the first rigorous baseline for dataset discovery agents and illuminate the path toward AI systems capable of finding any dataset in the digital universe. Our benchmark and comprehensive analysis provide the foundation for the next generation of self-improving AI systems and are publicly available at https://github.com/GAIR-NLP/DatasetResearch.",
    "source": "arXiv"
  },
  {
    "title": "MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair",
    "title_es": "MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair",
    "url": "https://arxiv.org/abs/2508.06963",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06963v1 Announce Type: new \nAbstract: Large Language Models (LLMs) face persistent and evolving trustworthiness issues, motivating developers to seek automated and flexible repair methods that enable convenient deployment across diverse scenarios. Existing repair methods like supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) are costly and slow, while prompt engineering lacks robustness and scalability. Representation engineering, which steers model behavior by injecting targeted concept vectors during inference, offers a lightweight, training-free alternative. However, current approaches depend on manually crafted samples and fixed steering strategies, limiting automation and adaptability. To overcome these challenges, we propose MASteer, the first end-to-end framework for trustworthiness repair in LLMs based on representation engineering. MASteer integrates two core components: AutoTester, a multi-agent system that generates diverse, high-quality steer samples tailored to developer needs; and AutoRepairer, which constructs adaptive steering strategies with anchor vectors for automated, context-aware strategy selection during inference. Experiments on standard and customized trustworthiness tasks show MASteer consistently outperforms baselines, improving metrics by 15.36% on LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model capabilities. MASteer demonstrates strong robustness, generalization, and practical value for scalable, efficient trustworthiness repair.",
    "source": "arXiv"
  },
  {
    "title": "Adversarial Video Promotion Against Text-to-Video Retrieval",
    "title_es": "Adversarial Video Promotion Against Text-to-Video Retrieval",
    "url": "https://arxiv.org/abs/2508.06964",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06964v1 Announce Type: new \nAbstract: Thanks to the development of cross-modal models, text-to-video retrieval (T2VR) is advancing rapidly, but its robustness remains largely unexamined. Existing attacks against T2VR are designed to push videos away from queries, i.e., suppressing the ranks of videos, while the attacks that pull videos towards selected queries, i.e., promoting the ranks of videos, remain largely unexplored. These attacks can be more impactful as attackers may gain more views/clicks for financial benefits and widespread (mis)information. To this end, we pioneer the first attack against T2VR to promote videos adversarially, dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement (MoRe) to capture the finer-grained, intricate interaction between visual and textual modalities to enhance black-box transferability. Comprehensive experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing datasets with over 10k videos, evaluated under 3 scenarios. All experiments are conducted in a multi-target setting to reflect realistic scenarios where attackers seek to promote the video regarding multiple queries simultaneously. We also evaluated our attacks for defences and imperceptibility. Overall, ViPro surpasses other baselines by over $30/10/4\\%$ for white/grey/black-box settings on average. Our work highlights an overlooked vulnerability, provides a qualitative analysis on the upper/lower bound of our attacks, and offers insights into potential counterplays. Code will be publicly available at https://github.com/michaeltian108/ViPro.",
    "source": "arXiv"
  },
  {
    "title": "Can Multitask Learning Enhance Model Explainability?",
    "title_es": "Can Multitask Learning Enhance Model Explainability?",
    "url": "https://arxiv.org/abs/2508.06966",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06966v1 Announce Type: new \nAbstract: Remote sensing provides satellite data in diverse types and formats. The usage of multimodal learning networks exploits this diversity to improve model performance, except that the complexity of such networks comes at the expense of their interpretability. In this study, we explore how modalities can be leveraged through multitask learning to intrinsically explain model behavior. In particular, instead of additional inputs, we use certain modalities as additional targets to be predicted along with the main task. The success of this approach relies on the rich information content of satellite data, which remains as input modalities. We show how this modeling context provides numerous benefits: (1) in case of data scarcity, the additional modalities do not need to be collected for model inference at deployment, (2) the model performance remains comparable to the multimodal baseline performance, and in some cases achieves better scores, (3) prediction errors in the main task can be explained via the model behavior in the auxiliary task(s). We demonstrate the efficiency of our approach on three datasets, including segmentation, classification, and regression tasks. Code available at git.opendfki.de/hiba.najjar/mtl_explainability/.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View",
    "title_es": "Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View",
    "url": "https://arxiv.org/abs/2508.06968",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06968v1 Announce Type: new \nAbstract: We present the first evaluation of fisheye-based 3D Gaussian Splatting methods, Fisheye-GS and 3DGUT, on real images with fields of view exceeding 180 degree. Our study covers both indoor and outdoor scenes captured with 200 degree fisheye cameras and analyzes how each method handles extreme distortion in real world settings. We evaluate performance under varying fields of view (200 degree, 160 degree, and 120 degree) to study the tradeoff between peripheral distortion and spatial coverage. Fisheye-GS benefits from field of view (FoV) reduction, particularly at 160 degree, while 3DGUT remains stable across all settings and maintains high perceptual quality at the full 200 degree view. To address the limitations of SfM-based initialization, which often fails under strong distortion, we also propose a depth-based strategy using UniK3D predictions from only 2-3 fisheye images per scene. Although UniK3D is not trained on real fisheye data, it produces dense point clouds that enable reconstruction quality on par with SfM, even in difficult scenes with fog, glare, or sky. Our results highlight the practical viability of fisheye-based 3DGS methods for wide-angle 3D reconstruction from sparse and distortion-heavy image inputs.",
    "source": "arXiv"
  },
  {
    "title": "Manipulator for people with limited abilities",
    "title_es": "Manipulator for people with limited abilities",
    "url": "https://arxiv.org/abs/2508.06969",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06969v1 Announce Type: new \nAbstract: The topic of this final qualification work was chosen due to the importance of developing robotic systems designed to assist people with disabilities. Advances in robotics and automation technologies have opened up new prospects for creating devices that can significantly improve the quality of life for these people. In this context, designing a robotic hand with a control system adapted to the needs of people with disabilities is a major scientific and practical challenge. This work addresses the problem of developing and manufacturing a four-degree-of-freedom robotic hand suitable for practical manipulation. Addressing this issue requires a comprehensive approach, encompassing the design of the hand's mechanical structure, the development of its control system, and its integration with a technical vision system and software based on the Robot Operating System (ROS).",
    "source": "arXiv"
  },
  {
    "title": "Blending Sequential Embeddings, Graphs, and Engineered Features: 4th Place Solution in RecSys Challenge 2025",
    "title_es": "Blending Sequential Embeddings, Graphs, and Engineered Features: 4th Place Solution in RecSys Challenge 2025",
    "url": "https://arxiv.org/abs/2508.06970",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06970v1 Announce Type: new \nAbstract: This paper describes the 4th-place solution by team ambitious for the RecSys Challenge 2025, organized by Synerise and ACM RecSys, which focused on universal behavioral modeling. The challenge objective was to generate user embeddings effective across six diverse downstream tasks. Our solution integrates (1) a sequential encoder to capture the temporal evolution of user interests, (2) a graph neural network to enhance generalization, (3) a deep cross network to model high-order feature interactions, and (4) performance-critical feature engineering.",
    "source": "arXiv"
  },
  {
    "title": "Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction",
    "title_es": "Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction",
    "url": "https://arxiv.org/abs/2508.06971",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06971v1 Announce Type: new \nAbstract: Quranic Question Answering presents unique challenges due to the linguistic complexity of Classical Arabic and the semantic richness of religious texts. In this paper, we propose a novel two-stage framework that addresses both passage retrieval and answer extraction. For passage retrieval, we ensemble fine-tuned Arabic language models to achieve superior ranking performance. For answer extraction, we employ instruction-tuned large language models with few-shot prompting to overcome the limitations of fine-tuning on small datasets. Our approach achieves state-of-the-art results on the Quran QA 2023 Shared Task, with a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of 0.669 for extraction, substantially outperforming previous methods. These results demonstrate that combining model ensembling and instruction-tuned language models effectively addresses the challenges of low-resource question answering in specialized domains.",
    "source": "arXiv"
  },
  {
    "title": "DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning",
    "title_es": "DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning",
    "url": "https://arxiv.org/abs/2508.06972",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06972v1 Announce Type: new \nAbstract: DSperse is a modular framework for distributed machine learning inference with strategic cryptographic verification. Operating within the emerging paradigm of distributed zero-knowledge machine learning, DSperse avoids the high cost and rigidity of full-model circuitization by enabling targeted verification of strategically chosen subcomputations. These verifiable segments, or \"slices\", may cover part or all of the inference pipeline, with global consistency enforced through audit, replication, or economic incentives. This architecture supports a pragmatic form of trust minimization, localizing zero-knowledge proofs to the components where they provide the greatest value. We evaluate DSperse using multiple proving systems and report empirical results on memory usage, runtime, and circuit behavior under sliced and unsliced configurations. By allowing proof boundaries to align flexibly with the model's logical structure, DSperse supports scalable, targeted verification strategies suited to diverse deployment needs.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models",
    "title_es": "Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models",
    "url": "https://arxiv.org/abs/2508.06974",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06974v1 Announce Type: new \nAbstract: 1-bit LLM quantization offers significant advantages in reducing storage and computational costs. However, existing methods typically train 1-bit LLMs from scratch, failing to fully leverage pre-trained models. This results in high training costs and notable accuracy degradation. We identify that the large gap between full precision and 1-bit representations makes direct adaptation difficult. In this paper, we introduce a consistent progressive training for both forward and backward, smoothly converting the floating-point weights into the binarized ones. Additionally, we incorporate binary-aware initialization and dual-scaling compensation to reduce the difficulty of progressive training and improve the performance. Experimental results on LLMs of various sizes demonstrate that our method outperforms existing approaches. Our results show that high-performance 1-bit LLMs can be achieved using pre-trained models, eliminating the need for expensive training from scratch.",
    "source": "arXiv"
  },
  {
    "title": "THz/RF Multi-Hop Routing Throughput: Performance, Optimization, and Application",
    "title_es": "THz/RF Multi-Hop Routing Throughput: Performance, Optimization, and Application",
    "url": "https://arxiv.org/abs/2508.06975",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06975v1 Announce Type: new \nAbstract: Terahertz (THz) communication offers a promising solution for high-throughput wireless systems. However, the severe path loss of THz signals raises concerns about its effectiveness compared to radio frequency (RF) communication. In this article, we establish the first stochastic geometry (SG)-based analytical framework for routing in THz systems. We develop a stepwise optimization approach to maximize throughput, including power allocation, relay selection, and number of hops design. Analytical expressions for throughput and coverage probability are derived under the SG framework, enabling low complexity and scalable performance evaluation. Numerical results show that the proposed stepwise-optimal routing strategies not only outperform existing SG-based methods but also approach the ideal upper bound. Moreover, we compare the throughput and coverage performance of THz and RF routing and demonstrate the applications of the proposed analytical framework and routing strategies in system parameter design and unmanned aerial vehicle networks.",
    "source": "arXiv"
  },
  {
    "title": "SSD Offloading for LLM Mixture-of-Experts Weights Considered Harmful in Energy Efficiency",
    "title_es": "SSD Offloading for LLM Mixture-of-Experts Weights Considered Harmful in Energy Efficiency",
    "url": "https://arxiv.org/abs/2508.06978",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06978v1 Announce Type: new \nAbstract: Large Language Models (LLMs) applying Mixture-of-Experts (MoE) scale to trillions of parameters but require vast memory, motivating a line of research to offload expert weights from fast-but-small DRAM (HBM) to denser Flash SSDs. While SSDs provide cost-effective capacity, their read energy per bit is substantially higher than that of DRAM. This paper quantitatively analyzes the energy implications of offloading MoE expert weights to SSDs during the critical decode stage of LLM inference. Our analysis, comparing SSD, CPU memory (DDR), and HBM storage scenarios for models like DeepSeek-R1, reveals that offloading MoE weights to current SSDs drastically increases per-token-generation energy consumption (e.g., by up to ~12x compared to the HBM baseline), dominating the total inference energy budget. Although techniques like prefetching effectively hide access latency, they cannot mitigate this fundamental energy penalty. We further explore future technological scaling, finding that the inherent sparsity of MoE models could potentially make SSDs energy-viable if Flash read energy improves significantly, roughly by an order of magnitude.",
    "source": "arXiv"
  },
  {
    "title": "Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model",
    "title_es": "Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model",
    "url": "https://arxiv.org/abs/2508.06980",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06980v1 Announce Type: new \nAbstract: With recent and rapid advancements in artificial intelligence (AI), understanding the foundation of purposeful behaviour in autonomous agents is crucial for developing safe and efficient systems. While artificial neural networks have dominated the path to AI, recent studies are exploring the potential of biologically based systems, such as networks of living biological neuronal networks. Along with promises of high power and data efficiency, these systems may also inform more explainable and biologically plausible models. In this work, we propose a framework rooted in active inference, a general theory of behaviour, to model decision-making in embodied agents. Using experiment-informed generative models, we simulate decision-making processes in a simulated game-play environment, mirroring experimental setups that use biological neurons. Our results demonstrate learning in these agents, providing insights into the role of memory-based learning and predictive planning in intelligent decision-making. This work contributes to the growing field of explainable AI by offering a biologically grounded and scalable approach to understanding purposeful behaviour in agents.",
    "source": "arXiv"
  },
  {
    "title": "Structure-Preserving Digital Twins via Conditional Neural Whitney Forms",
    "title_es": "Structure-Preserving Digital Twins via Conditional Neural Whitney Forms",
    "url": "https://arxiv.org/abs/2508.06981",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06981v1 Announce Type: new \nAbstract: We present a framework for constructing real-time digital twins based on structure-preserving reduced finite element models conditioned on a latent variable Z. The approach uses conditional attention mechanisms to learn both a reduced finite element basis and a nonlinear conservation law within the framework of finite element exterior calculus (FEEC). This guarantees numerical well-posedness and exact preservation of conserved quantities, regardless of data sparsity or optimization error. The conditioning mechanism supports real-time calibration to parametric variables, allowing the construction of digital twins which support closed loop inference and calibration to sensor data. The framework interfaces with conventional finite element machinery in a non-invasive manner, allowing treatment of complex geometries and integration of learned models with conventional finite element techniques.\n  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics, and a complex battery thermal runaway problem. The method achieves accurate predictions on complex geometries with sparse data (25 LES simulations), including capturing the transition to turbulence and achieving real-time inference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source implementation is available on GitHub.",
    "source": "arXiv"
  },
  {
    "title": "WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering",
    "title_es": "WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering",
    "url": "https://arxiv.org/abs/2508.06982",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06982v1 Announce Type: new \nAbstract: Forward and inverse rendering have emerged as key techniques for enabling understanding and reconstruction in the context of autonomous driving (AD). However, complex weather and illumination pose great challenges to this task. The emergence of large diffusion models has shown promise in achieving reasonable results through learning from 2D priors, but these models are difficult to control and lack robustness. In this paper, we introduce WeatherDiffusion, a diffusion-based framework for forward and inverse rendering on AD scenes with various weather and lighting conditions. Our method enables authentic estimation of material properties, scene geometry, and lighting, and further supports controllable weather and illumination editing through the use of predicted intrinsic maps guided by text descriptions. We observe that different intrinsic maps should correspond to different regions of the original image. Based on this observation, we propose Intrinsic map-aware attention (MAA) to enable high-quality inverse rendering. Additionally, we introduce a synthetic dataset (\\ie WeatherSynthetic) and a real-world dataset (\\ie WeatherReal) for forward and inverse rendering on AD scenes with diverse weather and lighting. Extensive experiments show that our WeatherDiffusion outperforms state-of-the-art methods on several benchmarks. Moreover, our method demonstrates significant value in downstream tasks for AD, enhancing the robustness of object detection and image segmentation in challenging weather scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Discovery Learning accelerates battery design evaluation",
    "title_es": "Discovery Learning accelerates battery design evaluation",
    "url": "https://arxiv.org/abs/2508.06985",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06985v1 Announce Type: new \nAbstract: Fast and reliable validation of novel designs in complex physical systems such as batteries is critical to accelerating technological innovation. However, battery research and development remain bottlenecked by the prohibitively high time and energy costs required to evaluate numerous new design candidates, particularly in battery prototyping and life testing. Despite recent progress in data-driven battery lifetime prediction, existing methods require labeled data of target designs to improve accuracy and cannot make reliable predictions until after prototyping, thus falling far short of the efficiency needed to enable rapid feedback for battery design. Here, we introduce Discovery Learning (DL), a scientific machine-learning paradigm that integrates active learning, physics-guided learning, and zero-shot learning into a human-like reasoning loop, drawing inspiration from learning theories in educational psychology. DL can learn from historical battery designs and actively reduce the need for prototyping, thus enabling rapid lifetime evaluation for unobserved material-design combinations without requiring additional data labeling. To test DL, we present 123 industrial-grade large-format lithium-ion pouch cells, spanning eight material-design combinations and diverse cycling protocols. Trained solely on public datasets of small-capacity cylindrical cells, DL achieves 7.2% test error in predicting the average cycle life under unknown device variability. This results in savings of 98% in time and 95% in energy compared to industrial practices. This work highlights the potential of uncovering insights from historical designs to inform and accelerate the development of next-generation battery technologies. DL represents a key advance toward efficient data-driven modeling and helps realize the promise of machine learning for accelerating scientific discovery and engineering innovation.",
    "source": "arXiv"
  },
  {
    "title": "UniMove: A Unified Model for Multi-city Human Mobility Prediction",
    "title_es": "UniMove: A Unified Model for Multi-city Human Mobility Prediction",
    "url": "https://arxiv.org/abs/2508.06986",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06986v1 Announce Type: new \nAbstract: Human mobility prediction is vital for urban planning, transportation optimization, and personalized services. However, the inherent randomness, non-uniform time intervals, and complex patterns of human mobility, compounded by the heterogeneity introduced by varying city structures, infrastructure, and population densities, present significant challenges in modeling. Existing solutions often require training separate models for each city due to distinct spatial representations and geographic coverage. In this paper, we propose UniMove, a unified model for multi-city human mobility prediction, addressing two challenges: (1) constructing universal spatial representations for effective token sharing across cities, and (2) modeling heterogeneous mobility patterns from varying city characteristics. We propose a trajectory-location dual-tower architecture, with a location tower for universal spatial encoding and a trajectory tower for sequential mobility modeling. We also design MoE Transformer blocks to adaptively select experts to handle diverse movement patterns. Extensive experiments across multiple datasets from diverse cities demonstrate that UniMove truly embodies the essence of a unified model. By enabling joint training on multi-city data with mutual data enhancement, it significantly improves mobility prediction accuracy by over 10.2\\%. UniMove represents a key advancement toward realizing a true foundational model with a unified architecture for human mobility. We release the implementation at https://github.com/tsinghua-fib-lab/UniMove/.",
    "source": "arXiv"
  },
  {
    "title": "Fixed-Time Voltage Regulation for Boost Converters via Unit-Safe Saturating Functions",
    "title_es": "Fixed-Time Voltage Regulation for Boost Converters via Unit-Safe Saturating Functions",
    "url": "https://arxiv.org/abs/2508.06987",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06987v1 Announce Type: new \nAbstract: This paper explores the voltage regulation challenges in boost converter systems, which are critical components in power electronics due to their ability to step up voltage levels efficiently. The proposed control algorithm ensures fixed-time stability, a desirable property that guarantees system stability within a fixed time frame regardless of initial conditions. To tackle the common chattering issues in conventional fixed-time control methods, a novel class of function families is introduced. State observers and adaptive parameters are utilized to manage the uncertainties associated with unknown load resistance. Furthermore, a new disturbance observer is developed using the proposed function family, and its advantages and limitations are illustrated through comparison with existing designs. Finally, both non-real-time and real-time simulations are conducted to validate the effectiveness and deployability of the proposed control algorithm.",
    "source": "arXiv"
  },
  {
    "title": "TADoc: Robust Time-Aware Document Image Dewarping",
    "title_es": "TADoc: Robust Time-Aware Document Image Dewarping",
    "url": "https://arxiv.org/abs/2508.06988",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06988v1 Announce Type: new \nAbstract: Flattening curved, wrinkled, and rotated document images captured by portable photographing devices, termed document image dewarping, has become an increasingly important task with the rise of digital economy and online working. Although many methods have been proposed recently, they often struggle to achieve satisfactory results when confronted with intricate document structures and higher degrees of deformation in real-world scenarios. Our main insight is that, unlike other document restoration tasks (e.g., deblurring), dewarping in real physical scenes is a progressive motion rather than a one-step transformation. Based on this, we have undertaken two key initiatives. Firstly, we reformulate this task, modeling it for the first time as a dynamic process that encompasses a series of intermediate states. Secondly, we design a lightweight framework called TADoc (Time-Aware Document Dewarping Network) to address the geometric distortion of document images. In addition, due to the inadequacy of OCR metrics for document images containing sparse text, the comprehensiveness of evaluation is insufficient. To address this shortcoming, we propose a new metric -- DLS (Document Layout Similarity) -- to evaluate the effectiveness of document dewarping in downstream tasks. Extensive experiments and in-depth evaluations have been conducted and the results indicate that our model possesses strong robustness, achieving superiority on several benchmarks with different document types and degrees of distortion.",
    "source": "arXiv"
  },
  {
    "title": "Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation",
    "title_es": "Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation",
    "url": "https://arxiv.org/abs/2508.06990",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06990v1 Announce Type: new \nAbstract: Semantic navigation requires an agent to navigate toward a specified target in an unseen environment. Employing an imaginative navigation strategy that predicts future scenes before taking action, can empower the agent to find target faster. Inspired by this idea, we propose SGImagineNav, a novel imaginative navigation framework that leverages symbolic world modeling to proactively build a global environmental representation. SGImagineNav maintains an evolving hierarchical scene graphs and uses large language models to predict and explore unseen parts of the environment. While existing methods solely relying on past observations, this imaginative scene graph provides richer semantic context, enabling the agent to proactively estimate target locations. Building upon this, SGImagineNav adopts an adaptive navigation strategy that exploits semantic shortcuts when promising and explores unknown areas otherwise to gather additional context. This strategy continuously expands the known environment and accumulates valuable semantic contexts, ultimately guiding the agent toward the target. SGImagineNav is evaluated in both real-world scenarios and simulation benchmarks. SGImagineNav consistently outperforms previous methods, improving success rate to 65.4 and 66.8 on HM3D and HSSD, and demonstrating cross-floor and cross-room navigation in real-world environments, underscoring its effectiveness and generalizability.",
    "source": "arXiv"
  },
  {
    "title": "A Comparative Study of Feature Selection in Tsetlin Machines",
    "title_es": "A Comparative Study of Feature Selection in Tsetlin Machines",
    "url": "https://arxiv.org/abs/2508.06991",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06991v1 Announce Type: new \nAbstract: Feature Selection (FS) is crucial for improving model interpretability, reducing complexity, and sometimes for enhancing accuracy. The recently introduced Tsetlin machine (TM) offers interpretable clause-based learning, but lacks established tools for estimating feature importance. In this paper, we adapt and evaluate a range of FS techniques for TMs, including classical filter and embedded methods as well as post-hoc explanation methods originally developed for neural networks (e.g., SHAP and LIME) and a novel family of embedded scorers derived from TM clause weights and Tsetlin automaton (TA) states. We benchmark all methods across 12 datasets, using evaluation protocols, like Remove and Retrain (ROAR) strategy and Remove and Debias (ROAD), to assess causal impact. Our results show that TM-internal scorers not only perform competitively but also exploit the interpretability of clauses to reveal interacting feature patterns. Simpler TM-specific scorers achieve similar accuracy retention at a fraction of the computational cost. This study establishes the first comprehensive baseline for FS in TM and paves the way for developing specialized TM-specific interpretability techniques.",
    "source": "arXiv"
  },
  {
    "title": "OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware",
    "title_es": "OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware",
    "url": "https://arxiv.org/abs/2508.06993",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06993v1 Announce Type: new \nAbstract: Medical applications demand segmentation of large inputs, like prostate MRIs, pathology slices, or videos of surgery. These inputs should ideally be inferred at once to provide the model with proper spatial or temporal context. When segmenting large inputs, the VRAM consumption of the GPU becomes the bottleneck. Architectures like UNets or Vision Transformers scale very poorly in VRAM consumption, resulting in patch- or frame-wise approaches that compromise global consistency and inference speed. The lightweight Neural Cellular Automaton (NCA) is a bio-inspired model that is by construction size-invariant. However, due to its local-only communication rules, it lacks global knowledge. We propose OctreeNCA by generalizing the neighborhood definition using an octree data structure. Our generalized neighborhood definition enables the efficient traversal of global knowledge. Since deep learning frameworks are mainly developed for large multi-layer networks, their implementation does not fully leverage the advantages of NCAs. We implement an NCA inference function in CUDA that further reduces VRAM demands and increases inference speed. Our OctreeNCA segments high-resolution images and videos quickly while occupying 90% less VRAM than a UNet during evaluation. This allows us to segment 184 Megapixel pathology slices or 1-minute surgical videos at once.",
    "source": "arXiv"
  },
  {
    "title": "Learning-Enabled Adaptive Power Capping Scheme for Cloud Data Centers",
    "title_es": "Learning-Enabled Adaptive Power Capping Scheme for Cloud Data Centers",
    "url": "https://arxiv.org/abs/2508.06994",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06994v1 Announce Type: new \nAbstract: The rapid growth of the digital economy and artificial intelligence has transformed cloud data centers into essential infrastructure with substantial energy consumption and carbon emission, necessitating effective energy management. However, existing methods face challenges such as incomplete information, uncertain parameters, and dynamic environments, which hinder their real-world implementation. This paper proposes an adaptive power capping framework tailored to cloud data centers. By dynamically setting the energy consumption upper bound, the power load of data centers can be reshaped to align with the electricity price or other market signals. To this end, we formulate the power capping problem as a partially observable Markov decision process. Subsequently, we develop an uncertainty-aware model-based reinforcement learning (MBRL) method to perceive the cloud data center operational environment and optimize power-capping decisions. By incorporating a two-stage uncertainty-aware optimization algorithm into the MBRL, we improve its adaptability to the ever-changing environment. Additionally, we derive the optimality gap of the proposed scheme under finite iterations, ensuring effective decisions under complex and uncertain scenarios. The numerical experiments validate the effectiveness of the proposed method using a cloud data center operational environment simulator built on real-world production traces from Alibaba, which demonstrates its potential as an efficient energy management solution for cloud data centers.",
    "source": "arXiv"
  },
  {
    "title": "S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision",
    "title_es": "S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision",
    "url": "https://arxiv.org/abs/2508.06995",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06995v1 Announce Type: new \nAbstract: Recent self-supervised image segmentation models have achieved promising performance on semantic segmentation and class-agnostic instance segmentation. However, their pretraining schedule is multi-stage, requiring a time-consuming pseudo-masks generation process between each training epoch. This time-consuming offline process not only makes it difficult to scale with training dataset size, but also leads to sub-optimal solutions due to its discontinuous optimization routine. To solve these, we first present a novel pseudo-mask algorithm, Fast Universal Agglomerative Pooling (UniAP). Each layer of UniAP can identify groups of similar nodes in parallel, allowing to generate both semantic-level and instance-level and multi-granular pseudo-masks within ens of milliseconds for one image. Based on the fast UniAP, we propose the Scalable Self-Supervised Universal Segmentation (S2-UniSeg), which employs a student and a momentum teacher for continuous pretraining. A novel segmentation-oriented pretext task, Query-wise Self-Distillation (QuerySD), is proposed to pretrain S2-UniSeg to learn the local-to-global correspondences. Under the same setting, S2-UniSeg outperforms the SOTA UnSAM model, achieving notable improvements of AP+6.9 on COCO, AR+11.1 on UVO, PixelAcc+4.5 on COCOStuff-27, RQ+8.0 on Cityscapes. After scaling up to a larger 2M-image subset of SA-1B, S2-UniSeg further achieves performance gains on all four benchmarks. Our code and pretrained models are available at https://github.com/bio-mlhui/S2-UniSeg",
    "source": "arXiv"
  },
  {
    "title": "Conformal Set-based Human-AI Complementarity with Multiple Experts",
    "title_es": "Conformal Set-based Human-AI Complementarity with Multiple Experts",
    "url": "https://arxiv.org/abs/2508.06997",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06997v1 Announce Type: new \nAbstract: Decision support systems are designed to assist human experts in classification tasks by providing conformal prediction sets derived from a pre-trained model. This human-AI collaboration has demonstrated enhanced classification performance compared to using either the model or the expert independently. In this study, we focus on the selection of instance-specific experts from a pool of multiple human experts, contrasting it with existing research that typically focuses on single-expert scenarios. We characterize the conditions under which multiple experts can benefit from the conformal sets. With the insight that only certain experts may be relevant for each instance, we explore the problem of subset selection and introduce a greedy algorithm that utilizes conformal sets to identify the subset of expert predictions that will be used in classifying an instance. This approach is shown to yield better performance compared to naive methods for human subset selection. Based on real expert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation study indicates that our proposed greedy algorithm achieves near-optimal subsets, resulting in improved classification performance among multiple experts.",
    "source": "arXiv"
  },
  {
    "title": "Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization",
    "title_es": "Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization",
    "url": "https://arxiv.org/abs/2508.07001",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07001v1 Announce Type: new \nAbstract: With wireless devices increasingly forming a unified smart network for seamless, user-friendly operations, random access (RA) medium access control (MAC) design is considered a key solution for handling unpredictable data traffic from multiple terminals. However, it remains challenging to design an effective RA-based MAC protocol to minimize collisions and ensure transmission fairness across the devices. While existing multi-agent reinforcement learning (MARL) approaches with centralized training and decentralized execution (CTDE) have been proposed to optimize RA performance, their reliance on centralized training and the significant overhead required for information collection can make real-world applications unrealistic. In this work, we adopt a fully decentralized MARL architecture, where policy learning does not rely on centralized tasks but leverages consensus-based information exchanges across devices. We design our MARL algorithm over an actor-critic (AC) network and propose exchanging only local rewards to minimize communication overhead. Furthermore, we provide a theoretical proof of global convergence for our approach. Numerical experiments show that our proposed MARL algorithm can significantly improve RA network performance compared to other baselines.",
    "source": "arXiv"
  },
  {
    "title": "EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events",
    "title_es": "EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events",
    "url": "https://arxiv.org/abs/2508.07003",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07003v1 Announce Type: new \nAbstract: Gaussian Splatting SLAM (GS-SLAM) offers a notable improvement over traditional SLAM methods, enabling photorealistic 3D reconstruction that conventional approaches often struggle to achieve. However, existing GS-SLAM systems perform poorly under persistent and severe motion blur commonly encountered in real-world scenarios, leading to significantly degraded tracking accuracy and compromised 3D reconstruction quality. To address this limitation, we propose EGS-SLAM, a novel GS-SLAM framework that fuses event data with RGB-D inputs to simultaneously reduce motion blur in images and compensate for the sparse and discrete nature of event streams, enabling robust tracking and high-fidelity 3D Gaussian Splatting reconstruction. Specifically, our system explicitly models the camera's continuous trajectory during exposure, supporting event- and blur-aware tracking and mapping on a unified 3D Gaussian Splatting scene. Furthermore, we introduce a learnable camera response function to align the dynamic ranges of events and images, along with a no-event loss to suppress ringing artifacts during reconstruction. We validate our approach on a new dataset comprising synthetic and real-world sequences with significant motion blur. Extensive experimental results demonstrate that EGS-SLAM consistently outperforms existing GS-SLAM systems in both trajectory accuracy and photorealistic 3D Gaussian Splatting reconstruction. The source code will be available at https://github.com/Chensiyu00/EGS-SLAM.",
    "source": "arXiv"
  },
  {
    "title": "Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments",
    "title_es": "Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments",
    "url": "https://arxiv.org/abs/2508.07006",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07006v1 Announce Type: new \nAbstract: Image-based personalized medicine has the potential to transform healthcare, particularly for diseases that exhibit heterogeneous progression such as Multiple Sclerosis (MS). In this work, we introduce the first treatment-aware spatio-temporal diffusion model that is able to generate future masks demonstrating lesion evolution in MS. Our voxel-space approach incorporates multi-modal patient data, including MRI and treatment information, to forecast new and enlarging T2 (NET2) lesion masks at a future time point. Extensive experiments on a multi-centre dataset of 2131 patient 3D MRIs from randomized clinical trials for relapsing-remitting MS demonstrate that our generative model is able to accurately predict NET2 lesion masks for patients across six different treatments. Moreover, we demonstrate our model has the potential for real-world clinical applications through downstream tasks such as future lesion count and location estimation, binary lesion activity classification, and generating counterfactual future NET2 masks for several treatments with different efficacies. This work highlights the potential of causal, image-based generative models as powerful tools for advancing data-driven prognostics in MS.",
    "source": "arXiv"
  },
  {
    "title": "A near-linear time approximation scheme for $(k,\\ell)$-median clustering under discrete Fr\\'echet distance",
    "title_es": "A near-linear time approximation scheme for $(k,\\ell)$-median clustering under discrete Fr\\'echet distance",
    "url": "https://arxiv.org/abs/2508.07008",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07008v1 Announce Type: new \nAbstract: A time series of complexity $m$ is a sequence of $m$ real valued measurements. The discrete Fr\\'echet distance $d_{dF}(x,y)$ is a distance measure between two time series $x$ and $y$ of possibly different complexity. Given a set of $n$ time series represented as $m$-dimensional vectors over the reals, the $(k,\\ell)$-median problem under discrete Fr\\'echet distance aims to find a set $C$ of $k$ time series of complexity $\\ell$ such that $$\\sum_{x\\in P} \\min_{c\\in C} d_{dF}(x,c)$$ is minimized. In this paper, we give the first near-linear time $(1+\\varepsilon)$-approximation algorithm for this problem when $\\ell$ and $\\varepsilon$ are constants but $k$ can be as large as $\\Omega(n)$. We obtain our result by introducing a new dimension reduction technique for discrete Fr\\'echet distance and then adapt an algorithm of Cohen-Addad et al. (J. ACM 2021) to work on the dimension-reduced input. As a byproduct we also improve the best coreset construction for $(k,\\ell)$-median under discrete Fr\\'echet distance (Cohen-Addad et al., SODA 2025) and show that its size can be independent of the number of input time series \\emph{ and } their complexity.",
    "source": "arXiv"
  },
  {
    "title": "Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems",
    "title_es": "Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems",
    "url": "https://arxiv.org/abs/2508.07009",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07009v1 Announce Type: new \nAbstract: Intelligent Reflecting Surfaces (IRSs) have potential for significant performance gains in next-generation wireless networks but face key challenges, notably severe double-pathloss and complex multi-user scheduling due to hardware constraints. Active IRSs partially address pathloss but still require efficient scheduling in cell-level multi-IRS multi-user systems, whereby the overhead/delay of channel state acquisition and the scheduling complexity both rise dramatically as the user density and channel dimensions increase. Motivated by these challenges, this paper proposes a novel scheduling framework based on neural Channel Knowledge Map (CKM), designing Transformer-based deep neural networks (DNNs) to predict ergodic spectral efficiency (SE) from historical channel/throughput measurements tagged with user positions. Specifically, two cascaded networks, LPS-Net and SE-Net, are designed to predict link power statistics (LPS) and ergodic SE accurately. We further propose a low-complexity Stable Matching-Iterative Balancing (SM-IB) scheduling algorithm. Numerical evaluations verify that the proposed neural CKM significantly enhances prediction accuracy and computational efficiency, while the SM-IB algorithm effectively achieves near-optimal max-min throughput with greatly reduced complexity.",
    "source": "arXiv"
  },
  {
    "title": "Narrative Memory in Machines: Multi-Agent Arc Extraction in Serialized TV",
    "title_es": "Narrative Memory in Machines: Multi-Agent Arc Extraction in Serialized TV",
    "url": "https://arxiv.org/abs/2508.07010",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07010v1 Announce Type: new \nAbstract: Serialized television narratives present significant analytical challenges due to their complex, temporally distributed storylines that necessitate sophisticated information management. This paper introduces a multi-agent system (MAS) designed to extract and analyze narrative arcs by implementing principles of computational memory architectures. The system conceptualizes narrative understanding through analogues of human memory: Large Language Models (LLMs) provide a form of semantic memory for general narrative patterns, while a vector database stores specific arc progressions as episodic memories. A multi-agent workflow simulates working memory processes to integrate these information types. Tested on the first season of Grey's Anatomy (ABC 2005-), the MAS identifies three arc types: Anthology (self-contained), Soap (relationship-focused), and Genre-Specific. These arcs and their episodic developments are stored in a vector database, facilitating structured analysis and semantic comparison. To bridge automation with critical interpretation, a graphical interface enables human oversight and refinement of the system's narrative memory. While demonstrating strong performance in identifying Anthology Arcs and character entities, the system's reliance on textual paratexts (episode summaries) revealed limitations in discerning overlapping arcs and opaque dynamics, underscoring the challenges in computational memory consolidation versus human holistic understanding. This memory-centric approach highlights the potential of combining AI-driven memory processing with human expertise. Beyond television, it offers promise for serialized written formats where narrative is entirely text-based. Future work will focus on integrating multimodal inputs to enrich episodic memory, refining memory integration mechanisms within the MAS, and expanding testing across diverse genres.",
    "source": "arXiv"
  },
  {
    "title": "HiMat: DiT-based Ultra-High Resolution SVBRDF Generation",
    "title_es": "HiMat: DiT-based Ultra-High Resolution SVBRDF Generation",
    "url": "https://arxiv.org/abs/2508.07011",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07011v1 Announce Type: new \nAbstract: Creating highly detailed SVBRDFs is essential for 3D content creation. The rise of high-resolution text-to-image generative models, based on diffusion transformers (DiT), suggests an opportunity to finetune them for this task. However, retargeting the models to produce multiple aligned SVBRDF maps instead of just RGB images, while achieving high efficiency and ensuring consistency across different maps, remains a challenge. In this paper, we introduce HiMat: a memory- and computation-efficient diffusion-based framework capable of generating native 4K-resolution SVBRDFs. A key challenge we address is maintaining consistency across different maps in a lightweight manner, without relying on training new VAEs or significantly altering the DiT backbone (which would damage its prior capabilities). To tackle this, we introduce the CrossStitch module, a lightweight convolutional module that captures inter-map dependencies through localized operations. Its weights are initialized such that the DiT backbone operation is unchanged before finetuning starts. HiMat enables generation with strong structural coherence and high-frequency details. Results with a large set of text prompts demonstrate the effectiveness of our approach for 4K SVBRDF generation. Further experiments suggest generalization to tasks such as intrinsic decomposition.",
    "source": "arXiv"
  },
  {
    "title": "Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach",
    "title_es": "Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach",
    "url": "https://arxiv.org/abs/2508.07015",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07015v1 Announce Type: new \nAbstract: The implicit hitting set (IHS) approach offers a general framework for solving computationally hard combinatorial optimization problems declaratively. IHS iterates between a decision oracle used for extracting sources of inconsistency and an optimizer for computing so-called hitting sets (HSs) over the accumulated sources of inconsistency. While the decision oracle is language-specific, the optimizers is usually instantiated through integer programming.\n  We explore alternative algorithmic techniques for hitting set optimization based on different ways of employing pseudo-Boolean (PB) reasoning as well as stochastic local search. We extensively evaluate the practical feasibility of the alternatives in particular in the context of pseudo-Boolean (0-1 IP) optimization as one of the most recent instantiations of IHS. Highlighting a trade-off between efficiency and reliability, while a commercial IP solver turns out to remain the most effective way to instantiate HS computations, it can cause correctness issues due to numerical instability; in fact, we show that exact HS computations instantiated via PB reasoning can be made competitive with a numerically exact IP solver. Furthermore, the use of PB reasoning as a basis for HS computations allows for obtaining certificates for the correctness of IHS computations, generally applicable to any IHS instantiation in which reasoning in the declarative language at hand can be captured in the PB-based proof format we employ.",
    "source": "arXiv"
  },
  {
    "title": "TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations",
    "title_es": "TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations",
    "url": "https://arxiv.org/abs/2508.07016",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07016v1 Announce Type: new \nAbstract: Time series forecasting is critical across various domains, such as weather, finance and real estate forecasting, as accurate forecasts support informed decision-making and risk mitigation. While recent deep learning models have improved predictive capabilities, they often overlook time-lagged cross-correlations between related sequences, which are crucial for capturing complex temporal relationships. To address this, we propose the Time-Lagged Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances forecasting accuracy by effectively integrating time-lagged cross-correlated sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW) algorithm to capture lagged correlations and a contrastive learning-based encoder to efficiently approximate SSDTW distances.\n  Experimental results on weather, finance and real estate time series datasets demonstrate the effectiveness of our framework. On the weather dataset, SSDTW reduces mean squared error (MSE) by 16.01% compared with single-sequence methods, while the contrastive learning encoder (CLE) further decreases MSE by 17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE reduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by 21.29% and 8.62%, respectively. Additionally, the contrastive learning approach decreases SSDTW computational time by approximately 99%, ensuring scalability and real-time applicability across multiple time series forecasting tasks.",
    "source": "arXiv"
  },
  {
    "title": "Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings",
    "title_es": "Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings",
    "url": "https://arxiv.org/abs/2508.07017",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07017v1 Announce Type: new \nAbstract: We propose Vec2Summ, a novel method for abstractive summarization that frames the task as semantic compression. Vec2Summ represents a document collection using a single mean vector in the semantic embedding space, capturing the central meaning of the corpus. To reconstruct fluent summaries, we perform embedding inversion -- decoding this mean vector into natural language using a generative language model. To improve reconstruction quality and capture some degree of topical variability, we introduce stochasticity by sampling from a Gaussian distribution centered on the mean. This approach is loosely analogous to bagging in ensemble learning, where controlled randomness encourages more robust and varied outputs. Vec2Summ addresses key limitations of LLM-based summarization methods. It avoids context-length constraints, enables interpretable and controllable generation via semantic parameters, and scales efficiently with corpus size -- requiring only $O(d + d^2)$ parameters. Empirical results show that Vec2Summ produces coherent summaries for topically focused, order-invariant corpora, with performance comparable to direct LLM summarization in terms of thematic coverage and efficiency, albeit with less fine-grained detail. These results underscore Vec2Summ's potential in settings where scalability, semantic control, and corpus-level abstraction are prioritized.",
    "source": "arXiv"
  },
  {
    "title": "TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders",
    "title_es": "TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders",
    "url": "https://arxiv.org/abs/2508.07020",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07020v1 Announce Type: new \nAbstract: Hyperspectral satellite imagery offers sub-30 m views of Earth in hundreds of contiguous spectral bands, enabling fine-grained mapping of soils, crops, and land cover. While self-supervised Masked Autoencoders excel on RGB and low-band multispectral data, they struggle to exploit the intricate spatial-spectral correlations in 200+ band hyperspectral images. We introduce TerraMAE, a novel HSI encoding framework specifically designed to learn highly representative spatial-spectral embeddings for diverse geospatial analyses. TerraMAE features an adaptive channel grouping strategy, based on statistical reflectance properties to capture spectral similarities, and an enhanced reconstruction loss function that incorporates spatial and spectral quality metrics. We demonstrate TerraMAE's effectiveness through superior spatial-spectral information preservation in high-fidelity image reconstruction. Furthermore, we validate its practical utility and the quality of its learned representations through strong performance on three key downstream geospatial tasks: crop identification, land cover classification, and soil texture prediction.",
    "source": "arXiv"
  },
  {
    "title": "DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents",
    "title_es": "DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents",
    "url": "https://arxiv.org/abs/2508.07021",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07021v1 Announce Type: new \nAbstract: The exponential growth of scientific literature in PDF format necessitates advanced tools for efficient and accurate document understanding, summarization, and content optimization. Traditional methods fall short in handling complex layouts and multimodal content, while direct application of Large Language Models (LLMs) and Vision-Language Large Models (LVLMs) lacks precision and control for intricate editing tasks. This paper introduces DocRefine, an innovative framework designed for intelligent understanding, content refinement, and automated summarization of scientific PDF documents, driven by natural language instructions. DocRefine leverages the power of advanced LVLMs (e.g., GPT-4o) by orchestrating a sophisticated multi-agent system comprising six specialized and collaborative agents: Layout & Structure Analysis, Multimodal Content Understanding, Instruction Decomposition, Content Refinement, Summarization & Generation, and Fidelity & Consistency Verification. This closed-loop feedback architecture ensures high semantic accuracy and visual fidelity. Evaluated on the comprehensive DocEditBench dataset, DocRefine consistently outperforms state-of-the-art baselines across various tasks, achieving overall scores of 86.7% for Semantic Consistency Score (SCS), 93.9% for Layout Fidelity Index (LFI), and 85.0% for Instruction Adherence Rate (IAR). These results demonstrate DocRefine's superior capability in handling complex multimodal document editing, preserving semantic integrity, and maintaining visual consistency, marking a significant advancement in automated scientific document processing.",
    "source": "arXiv"
  },
  {
    "title": "MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA",
    "title_es": "MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA",
    "url": "https://arxiv.org/abs/2508.07022",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07022v1 Announce Type: new \nAbstract: Knowledge editing (KE) provides a scalable approach for updating factual knowledge in large language models without full retraining. While previous studies have demonstrated effectiveness in general domains and medical QA tasks, little attention has been paid to KE in multimodal medical scenarios. Unlike text-only settings, medical KE demands integrating updated knowledge with visual reasoning to support safe and interpretable clinical decisions. To address this gap, we propose MultiMedEdit, the first benchmark tailored to evaluating KE in clinical multimodal tasks. Our framework spans both understanding and reasoning task types, defines a three-dimensional metric suite (reliability, generality, and locality), and supports cross-paradigm comparisons across general and domain-specific models. We conduct extensive experiments under single-editing and lifelong-editing settings. Results suggest that current methods struggle with generalization and long-tail reasoning, particularly in complex clinical workflows. We further present an efficiency analysis (e.g., edit latency, memory footprint), revealing practical trade-offs in real-world deployment across KE paradigms. Overall, MultiMedEdit not only reveals the limitations of current approaches but also provides a solid foundation for developing clinically robust knowledge editing techniques in the future.",
    "source": "arXiv"
  },
  {
    "title": "MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering",
    "title_es": "MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering",
    "url": "https://arxiv.org/abs/2508.07023",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07023v1 Announce Type: new \nAbstract: Complex Visual Question Answering (Complex VQA) tasks, which demand sophisticated multi-modal reasoning and external knowledge integration, present significant challenges for existing large vision-language models (LVLMs) often limited by their reliance on high-level global features. To address this, we propose MV-CoRe (Multimodal Visual-Conceptual Reasoning), a novel model designed to enhance Complex VQA performance through the deep fusion of diverse visual and linguistic information. MV-CoRe meticulously integrates global embeddings from pre-trained Vision Large Models (VLMs) and Language Large Models (LLMs) with fine-grained semantic-aware visual features, including object detection characteristics and scene graph representations. An innovative Multimodal Fusion Transformer then processes and deeply integrates these diverse feature sets, enabling rich cross-modal attention and facilitating complex reasoning. We evaluate MV-CoRe on challenging Complex VQA benchmarks, including GQA, A-OKVQA, and OKVQA, after training on VQAv2. Our experimental results demonstrate that MV-CoRe consistently outperforms established LVLM baselines, achieving an overall accuracy of 77.5% on GQA. Ablation studies confirm the critical contribution of both object and scene graph features, and human evaluations further validate MV-CoRe's superior factual correctness and reasoning depth, underscoring its robust capabilities for deep visual and conceptual understanding.",
    "source": "arXiv"
  },
  {
    "title": "Making Effective Decisions: Machine Learning and the Ecogame in 1970",
    "title_es": "Making Effective Decisions: Machine Learning and the Ecogame in 1970",
    "url": "https://arxiv.org/abs/2508.07027",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07027v1 Announce Type: new \nAbstract: This paper considers Ecogame, an innovative art project of 1970, whose creators believed in a positive vision of a technological future; an understanding, posited on cybernetics, of a future that could be participatory via digital means, and therefore more democratised. Using simulation and early machine learning techniques over a live network, Ecogame combined the power of visual art with cybernetic concepts of adaptation, feedback, and control to propose that behaviour had implications for the total system. It provides an historical precedent for contemporary AI-driven art about using AI in a more human-centred way.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation",
    "title_es": "Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation",
    "url": "https://arxiv.org/abs/2508.07028",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07028v1 Announce Type: new \nAbstract: Accurate endoscopic image segmentation on the polyps is critical for early colorectal cancer detection. However, this task remains challenging due to low contrast with surrounding mucosa, specular highlights, and indistinct boundaries. To address these challenges, we propose FOCUS-Med, which stands for Fusion of spatial and structural graph with attentional context-aware polyp segmentation in endoscopic medical imaging. FOCUS-Med integrates a Dual Graph Convolutional Network (Dual-GCN) module to capture contextual spatial and topological structural dependencies. This graph-based representation enables the model to better distinguish polyps from background tissues by leveraging topological cues and spatial connectivity, which are often obscured in raw image intensities. It enhances the model's ability to preserve boundaries and delineate complex shapes typical of polyps. In addition, a location-fused stand-alone self-attention is employed to strengthen global context integration. To bridge the semantic gap between encoder-decoder layers, we incorporate a trainable weighted fast normalized fusion strategy for efficient multi-scale aggregation. Notably, we are the first to introduce the use of a Large Language Model (LLM) to provide detailed qualitative evaluations of segmentation quality. Extensive experiments on public benchmarks demonstrate that FOCUS-Med achieves state-of-the-art performance across five key metrics, underscoring its effectiveness and clinical potential for AI-assisted colonoscopy.",
    "source": "arXiv"
  },
  {
    "title": "From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving",
    "title_es": "From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.07029",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07029v1 Announce Type: new \nAbstract: Learning robust driving policies from large-scale, real-world datasets is a central challenge in autonomous driving, as online data collection is often unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward approach to imitation learning, policies trained with BC are notoriously brittle and suffer from compounding errors in closed-loop execution. This work presents a comprehensive pipeline and a comparative study to address this limitation. We first develop a series of increasingly sophisticated BC baselines, culminating in a Transformer-based model that operates on a structured, entity-centric state representation. While this model achieves low imitation loss, we show that it still fails in long-horizon simulations. We then demonstrate that by applying a state-of-the-art Offline Reinforcement Learning algorithm, Conservative Q-Learning (CQL), to the same data and architecture, we can learn a significantly more robust policy. Using a carefully engineered reward function, the CQL agent learns a conservative value function that enables it to recover from minor errors and avoid out-of-distribution states. In a large-scale evaluation on 1,000 unseen scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a 3.2x higher success rate and a 7.4x lower collision rate than the strongest BC baseline, proving that an offline RL approach is critical for learning robust, long-horizon driving policies from static expert data.",
    "source": "arXiv"
  },
  {
    "title": "Generalized Quasi-Cyclic LDPC Codes: Design and Efficient Encoding",
    "title_es": "Generalized Quasi-Cyclic LDPC Codes: Design and Efficient Encoding",
    "url": "https://arxiv.org/abs/2508.07030",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07030v1 Announce Type: new \nAbstract: Generalized low-density parity-check (GLDPC) codes, where single parity-check constraints on the code bits are replaced with generalized constraints (an arbitrary linear code), are a promising class of codes for low-latency communication. The block error rate performance of the GLDPC codes, combined with a complementary outer code, has been shown to outperform a variety of state-of-the-art code and decoder designs with suitable lengths and rates for the 5G ultra-reliable low-latency communication (URLLC) regime. A major drawback of these codes is that it is not known how to construct appropriate polynomial matrices to encode them efficiently. In this paper, we analyze practical constructions of quasi-cyclic GLDPC (QC-GLDPC) codes and show how to construct polynomial generator matrices in various forms using minors of the polynomial matrix. The approach can be applied to fully generalized matrices or partially generalized (with mixed constraint node types) to find better performance/rate trade-offs. The resulting encoding matrices are presented in useful forms that facilitate efficient implementation. The rich substructure displayed also provides us with new methods of determining low weight codewords, providing lower and upper bounds on the minimum distance and often giving those of weight equal to the minimum distance. Based on the minors of the polynomial parity-check matrix, we also give a formula for the rank of any parity-check matrix representing a QC-LDPC or QC-GLDPC code, and hence, the dimension of the code. Finally, we show that by applying double graph-liftings, the code parameters can be improved without affecting the ability to obtain a polynomial generator matrix.",
    "source": "arXiv"
  },
  {
    "title": "Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities",
    "title_es": "Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities",
    "url": "https://arxiv.org/abs/2508.07031",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07031v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly applied to medical imaging tasks, including image interpretation and synthetic image generation. However, these models often produce hallucinations, which are confident but incorrect outputs that can mislead clinical decisions. This study examines hallucinations in two directions: image to text, where LLMs generate reports from X-ray, CT, or MRI scans, and text to image, where models create medical images from clinical prompts. We analyze errors such as factual inconsistencies and anatomical inaccuracies, evaluating outputs using expert informed criteria across imaging modalities. Our findings reveal common patterns of hallucination in both interpretive and generative tasks, with implications for clinical reliability. We also discuss factors contributing to these failures, including model architecture and training data. By systematically studying both image understanding and generation, this work provides insights into improving the safety and trustworthiness of LLM driven medical imaging systems.",
    "source": "arXiv"
  },
  {
    "title": "A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling",
    "title_es": "A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling",
    "url": "https://arxiv.org/abs/2508.07032",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07032v1 Announce Type: new \nAbstract: The long-term progression of neurodegenerative diseases is commonly conceptualized as a spatiotemporal diffusion process that consists of a graph diffusion process across the structural brain connectome and a localized reaction process within brain regions. However, modeling this progression remains challenging due to 1) the scarcity of longitudinal data obtained through irregular and infrequent subject visits and 2) the complex interplay of pathological mechanisms across brain regions and disease stages, where traditional models assume fixed mechanisms throughout disease progression. To address these limitations, we propose a novel stage-aware Mixture of Experts (MoE) framework that explicitly models how different contributing mechanisms dominate at different disease stages through time-dependent expert weighting.Data-wise, we utilize an iterative dual optimization method to properly estimate the temporal position of individual observations, constructing a co hort-level progression trajectory from irregular snapshots. Model-wise, we enhance the spatial component with an inhomogeneous graph neural diffusion model (IGND) that allows diffusivity to vary based on node states and time, providing more flexible representations of brain networks. We also introduce a localized neural reaction module to capture complex dynamics beyond standard processes.The resulting IGND-MoE model dynamically integrates these components across temporal states, offering a principled way to understand how stage-specific pathological mechanisms contribute to progression. The stage-wise weights yield novel clinical insights that align with literature, suggesting that graph-related processes are more influential at early stages, while other unknown physical processes become dominant later on.",
    "source": "arXiv"
  },
  {
    "title": "$\\mathcal{P}^3$: Toward Versatile Embodied Agents",
    "title_es": "$\\mathcal{P}^3$: Toward Versatile Embodied Agents",
    "url": "https://arxiv.org/abs/2508.07033",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07033v1 Announce Type: new \nAbstract: Embodied agents have shown promising generalization capabilities across diverse physical environments, making them essential for a wide range of real-world applications. However, building versatile embodied agents poses critical challenges due to three key issues: dynamic environment perception, open-ended tool usage, and complex multi-task planning. Most previous works rely solely on feedback from tool agents to perceive environmental changes and task status, which limits adaptability to real-time dynamics, causes error accumulation, and restricts tool flexibility. Furthermore, multi-task scheduling has received limited attention, primarily due to the inherent complexity of managing task dependencies and balancing competing priorities in dynamic and complex environments. To overcome these challenges, we introduce $\\mathcal{P}^3$, a unified framework that integrates real-time perception and dynamic scheduling. Specifically, $\\mathcal{P}^3$ enables 1) \\textbf Perceive relevant task information actively from the environment, 2) \\textbf Plug and utilize any tool without feedback requirement, and 3) \\textbf Plan multi-task execution based on prioritizing urgent tasks and dynamically adjusting task order based on dependencies. Extensive real-world experiments show that our approach bridges the gap between benchmarks and practical deployment, delivering highly transferable, general-purpose embodied agents. Code and data will be released soon.",
    "source": "arXiv"
  },
  {
    "title": "Nonconforming approximation methods for function reconstruction on general polygonal meshes via orthogonal polynomials",
    "title_es": "Nonconforming approximation methods for function reconstruction on general polygonal meshes via orthogonal polynomials",
    "url": "https://arxiv.org/abs/2508.07036",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07036v1 Announce Type: new \nAbstract: In this work, we introduce new families of nonconforming approximation methods for reconstructing functions on general polygonal meshes. These methods are defined using degrees of freedom based on weighted moments of orthogonal polynomials and can reproduce higher-degree polynomials. This setting naturally arises in applications where pointwise evaluations are unavailable and only integral measurements over subdomains are accessible. We develop a unisolvence theory and derive necessary and sufficient conditions for the associated approximation spaces to be unisolvent. Specifically, it is shown that unisolvence depends on the parity of the product of the polynomial degree~$m$ and the number of polygon edges~$N$. When this condition is not satisfied, we introduce an enrichment strategy involving an additional linear functional and a suitably designed enrichment function to ensure unisolvence. Numerical experiments confirm the accuracy of the proposed method.",
    "source": "arXiv"
  },
  {
    "title": "Differentiable Adaptive Kalman Filtering via Optimal Transport",
    "title_es": "Differentiable Adaptive Kalman Filtering via Optimal Transport",
    "url": "https://arxiv.org/abs/2508.07037",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07037v1 Announce Type: new \nAbstract: Learning-based filtering has demonstrated strong performance in non-linear dynamical systems, particularly when the statistics of noise are unknown. However, in real-world deployments, environmental factors, such as changing wind conditions or electromagnetic interference, can induce unobserved noise-statistics drift, leading to substantial degradation of learning-based methods. To address this challenge, we propose OTAKNet, the first online solution to noise-statistics drift within learning-based adaptive Kalman filtering. Unlike existing learning-based methods that perform offline fine-tuning using batch pointwise matching over entire trajectories, OTAKNet establishes a connection between the state estimate and the drift via one-step predictive measurement likelihood, and addresses it using optimal transport. This leverages OT's geometry - aware cost and stable gradients to enable fully online adaptation without ground truth labels or retraining. We compare OTAKNet against classical model-based adaptive Kalman filtering and offline learning-based filtering. The performance is demonstrated on both synthetic and real-world NCLT datasets, particularly under limited training data.",
    "source": "arXiv"
  },
  {
    "title": "3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS Compression",
    "title_es": "3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS Compression",
    "url": "https://arxiv.org/abs/2508.07038",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07038v1 Announce Type: new \nAbstract: 3D Gaussian Splatting (3DGS) enables real-time novel view synthesis with high visual fidelity, but its substantial storage requirements hinder practical deployment, prompting state-of-the-art (SOTA) 3DGS methods to incorporate compression modules. However, these 3DGS generative compression techniques introduce unique distortions lacking systematic quality assessment research. To this end, we establish 3DGS-VBench, a large-scale Video Quality Assessment (VQA) Dataset and Benchmark with 660 compressed 3DGS models and video sequences generated from 11 scenes across 6 SOTA 3DGS compression algorithms with systematically designed parameter levels. With annotations from 50 participants, we obtained MOS scores with outlier removal and validated dataset reliability. We benchmark 6 3DGS compression algorithms on storage efficiency and visual quality, and evaluate 15 quality assessment metrics across multiple paradigms. Our work enables specialized VQA model training for 3DGS, serving as a catalyst for compression and quality assessment research. The dataset is available at https://github.com/YukeXing/3DGS-VBench.",
    "source": "arXiv"
  },
  {
    "title": "SAGCNet: Spatial-Aware Graph Completion Network for Missing Slice Imputation in Population CMR Imaging",
    "title_es": "SAGCNet: Spatial-Aware Graph Completion Network for Missing Slice Imputation in Population CMR Imaging",
    "url": "https://arxiv.org/abs/2508.07041",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07041v1 Announce Type: new \nAbstract: Magnetic resonance imaging (MRI) provides detailed soft-tissue characteristics that assist in disease diagnosis and screening. However, the accuracy of clinical practice is often hindered by missing or unusable slices due to various factors. Volumetric MRI synthesis methods have been developed to address this issue by imputing missing slices from available ones. The inherent 3D nature of volumetric MRI data, such as cardiac magnetic resonance (CMR), poses significant challenges for missing slice imputation approaches, including (1) the difficulty of modeling local inter-slice correlations and dependencies of volumetric slices, and (2) the limited exploration of crucial 3D spatial information and global context. In this study, to mitigate these issues, we present Spatial-Aware Graph Completion Network (SAGCNet) to overcome the dependency on complete volumetric data, featuring two main innovations: (1) a volumetric slice graph completion module that incorporates the inter-slice relationships into a graph structure, and (2) a volumetric spatial adapter component that enables our model to effectively capture and utilize various forms of 3D spatial context. Extensive experiments on cardiac MRI datasets demonstrate that SAGCNet is capable of synthesizing absent CMR slices, outperforming competitive state-of-the-art MRI synthesis methods both quantitatively and qualitatively. Notably, our model maintains superior performance even with limited slice data.",
    "source": "arXiv"
  },
  {
    "title": "K-Dense Analyst: Towards Fully Automated Scientific Analysis",
    "title_es": "K-Dense Analyst: Towards Fully Automated Scientific Analysis",
    "url": "https://arxiv.org/abs/2508.07043",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07043v1 Announce Type: new \nAbstract: The complexity of modern bioinformatics analysis has created a critical gap between data generation and developing scientific insights. While large language models (LLMs) have shown promise in scientific reasoning, they remain fundamentally limited when dealing with real-world analytical workflows that demand iterative computation, tool integration and rigorous validation. We introduce K-Dense Analyst, a hierarchical multi-agent system that achieves autonomous bioinformatics analysis through a dual-loop architecture. K-Dense Analyst, part of the broader K-Dense platform, couples planning with validated execution using specialized agents to decompose complex objectives into executable, verifiable tasks within secure computational environments. On BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense Analyst achieves 29.2% accuracy, surpassing the best-performing language model (GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what is widely considered the most powerful LLM available. Remarkably, K-Dense Analyst achieves this performance using Gemini 2.5 Pro, which attains only 18.3% accuracy when used directly, demonstrating that our architectural innovations unlock capabilities far beyond the underlying model's baseline performance. Our insights demonstrate that autonomous scientific reasoning requires more than enhanced language models, it demands purpose-built systems that can bridge the gap between high-level scientific objectives and low-level computational execution. These results represent a significant advance toward fully autonomous computational biologists capable of accelerating discovery across the life sciences.",
    "source": "arXiv"
  },
  {
    "title": "Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption",
    "title_es": "Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption",
    "url": "https://arxiv.org/abs/2508.07044",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07044v1 Announce Type: new \nAbstract: In the era of generative AI, ensuring the privacy of music data presents unique challenges: unlike static artworks such as images, music data is inherently temporal and multimodal, and it is sampled, transformed, and remixed at an unprecedented scale. These characteristics make its core vector embeddings, i.e, the numerical representations of the music, highly susceptible to being learned, misused, or even stolen by models without accessing the original audio files. Traditional methods like copyright licensing and digital watermarking offer limited protection for these abstract mathematical representations, thus necessitating a stronger, e.g., cryptographic, approach to safeguarding the embeddings themselves. Standard encryption schemes, such as AES, render data unintelligible for computation, making such searches impossible. While Fully Homomorphic Encryption (FHE) provides a plausible solution by allowing arbitrary computations on ciphertexts, its substantial performance overhead remains impractical for large-scale vector similarity searches. Given this trade-off, we propose a more practical approach using Additive Homomorphic Encryption (AHE) for vector similarity search. The primary contributions of this paper are threefold: we analyze threat models unique to music information retrieval systems; we provide a theoretical analysis and propose an efficient AHE-based solution through inner products of music embeddings to deliver privacy-preserving similarity search; and finally, we demonstrate the efficiency and practicality of the proposed approach through empirical evaluation and comparison to FHE schemes on real-world MP3 files.",
    "source": "arXiv"
  },
  {
    "title": "From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline",
    "title_es": "From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline",
    "url": "https://arxiv.org/abs/2508.07045",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07045v1 Announce Type: new \nAbstract: Model predictive control (MPC) is a powerful strategy for planning and control in autonomous mobile robot navigation. However, ensuring safety in real-world deployments remains challenging due to the presence of disturbances and measurement noise. Existing approaches often rely on idealized assumptions, neglect the impact of noisy measurements, and simply heuristically guess unrealistic bounds. In this work, we present an efficient and modular robust MPC design pipeline that systematically addresses these limitations. The pipeline consists of an iterative procedure that leverages closed-loop experimental data to estimate disturbance bounds and synthesize a robust output-feedback MPC scheme. We provide the pipeline in the form of deterministic and reproducible code to synthesize the robust output-feedback MPC from data. We empirically demonstrate robust constraint satisfaction and recursive feasibility in quadrotor simulations using Gazebo.",
    "source": "arXiv"
  },
  {
    "title": "A novel interpolation-regression approach for function approximation on the disk and its application to cubature formulas",
    "title_es": "A novel interpolation-regression approach for function approximation on the disk and its application to cubature formulas",
    "url": "https://arxiv.org/abs/2508.07047",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07047v1 Announce Type: new \nAbstract: The interpolation-regression approximation is a powerful tool in numerical analysis for reconstructing functions defined on square or triangular domains from their evaluations at a regular set of nodes. The importance of this technique lies in its ability to avoid the Runge phenomenon. In this paper, we present a polynomial approximation method based on an interpolation-regression approach for reconstructing functions defined on disk domains from their evaluations at a general set of sampling points. Special attention is devoted to the selection of interpolation nodes to ensure numerical stability, particularly in the context of Zernike polynomials. As an application, the proposed method is used to derive accurate cubature formulas for numerical integration over the disk.",
    "source": "arXiv"
  },
  {
    "title": "Whisfusion: Parallel ASR Decoding via a Diffusion Transformer",
    "title_es": "Whisfusion: Parallel ASR Decoding via a Diffusion Transformer",
    "url": "https://arxiv.org/abs/2508.07048",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07048v1 Announce Type: new \nAbstract: Fast Automatic Speech Recognition (ASR) is critical for latency-sensitive applications such as real-time captioning and meeting transcription. However, truly parallel ASR decoding remains challenging due to the sequential nature of autoregressive (AR) decoders and the context limitations of non-autoregressive (NAR) methods. While modern ASR encoders can process up to 30 seconds of audio at once, AR decoders still generate tokens sequentially, creating a latency bottleneck. We propose Whisfusion, the first framework to fuse a pre-trained Whisper encoder with a text diffusion decoder. This NAR architecture resolves the AR latency bottleneck by processing the entire acoustic context in parallel at every decoding step. A lightweight cross-attention adapter trained via parameter-efficient fine-tuning (PEFT) bridges the two modalities. We also introduce a batch-parallel, multi-step decoding strategy that improves accuracy by increasing the number of candidates with minimal impact on speed. Fine-tuned solely on LibriSpeech (960h), Whisfusion achieves a lower WER than Whisper-tiny (8.3% vs. 9.7%), and offers comparable latency on short audio. For longer utterances (>20s), it is up to 2.6x faster than the AR baseline, establishing a new, efficient operating point for long-form ASR. The implementation and training scripts are available at https://github.com/taeyoun811/Whisfusion.",
    "source": "arXiv"
  },
  {
    "title": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability",
    "title_es": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability",
    "url": "https://arxiv.org/abs/2508.07050",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07050v1 Announce Type: new \nAbstract: Large Language Model (LLM) based listwise ranking has shown superior performance in many passage ranking tasks. With the development of Large Reasoning Models, many studies have demonstrated that step-by-step reasoning during test-time helps improve listwise ranking performance. However, due to the scarcity of reasoning-intensive training data, existing rerankers perform poorly in many complex ranking scenarios and the ranking ability of reasoning-intensive rerankers remains largely underdeveloped. In this paper, we first propose an automated reasoning-intensive training data synthesis framework, which sources training queries and passages from diverse domains and applies DeepSeek-R1 to generate high-quality training labels. A self-consistency data filtering mechanism is designed to ensure the data quality. To empower the listwise reranker with strong reasoning ability, we further propose a two-stage post-training approach, which includes a cold-start supervised fine-tuning (SFT) stage for reasoning pattern learning and a reinforcement learning (RL) stage for further ranking ability enhancement. During the RL stage, based on the nature of listwise ranking, we design a multi-view ranking reward, which is more effective than a ranking metric-based reward. Extensive experiments demonstrate that our trained reasoning-intensive reranker \\textbf{ReasonRank} outperforms existing baselines significantly and also achieves much lower latency than pointwise reranker Rank1. \\textbf{Through further experiments, our ReasonRank has achieved state-of-the-art (SOTA) performance 40.6 on the BRIGHT leaderboard\\footnote{https://brightbenchmark.github.io/}.} Our codes are available at https://github.com/8421BCD/ReasonRank.",
    "source": "arXiv"
  },
  {
    "title": "SPARE: Securing Progressive Web Applications Against Unauthorized Replications",
    "title_es": "SPARE: Securing Progressive Web Applications Against Unauthorized Replications",
    "url": "https://arxiv.org/abs/2508.07053",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07053v1 Announce Type: new \nAbstract: WebView applications are widely used in mobile applications to display web content directly within the app, enhancing user engagement by eliminating the need to open an external browser and providing a seamless experience. Progressive Web Applications (PWAs) further improve usability by combining the accessibility of web apps with the speed, offline capabilities, and responsiveness of native applications. However, malicious developers can exploit this technology by duplicating PWA web links to create counterfeit native apps, monetizing through user diversion. This unethical practice poses significant risks to users and the original application developers, underscoring the need for robust security measures to prevent unauthorized replication. Considering the one-way communication of Trusted Web Activity (a method for integrating web content into Android applications) and PWAs, we propose a query parameter-based practical security solution to defend against or mitigate such attacks. We analyze the vulnerabilities of our proposed security solution to assess its effectiveness and introduce advanced measures to address any identified weaknesses, presenting a comprehensive defense framework. As part of our work, we developed a prototype web application that secures PWAs from replication by embedding a combination of Unix timestamps and device identifiers into the query parameters. We evaluate the effectiveness of this defense strategy by simulating an advanced attack scenario. Additionally, we created a realistic dataset reflecting mobile app user behavior, modeled using a Zipfian distribution, to validate our framework.",
    "source": "arXiv"
  },
  {
    "title": "Membership and Memorization in LLM Knowledge Distillation",
    "title_es": "Membership and Memorization in LLM Knowledge Distillation",
    "url": "https://arxiv.org/abs/2508.07054",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07054v1 Announce Type: new \nAbstract: Recent advances in Knowledge Distillation (KD) aim to mitigate the high computational demands of Large Language Models (LLMs) by transferring knowledge from a large ''teacher'' to a smaller ''student'' model. However, students may inherit the teacher's privacy when the teacher is trained on private data. In this work, we systematically characterize and investigate membership and memorization privacy risks inherent in six LLM KD techniques. Using instruction-tuning settings that span seven NLP tasks, together with three teacher model families (GPT-2, LLAMA-2, and OPT), and various size student models, we demonstrate that all existing LLM KD approaches carry membership and memorization privacy risks from the teacher to its students. However, the extent of privacy risks varies across different KD techniques. We systematically analyse how key LLM KD components (KD objective functions, student training data and NLP tasks) impact such privacy risks. We also demonstrate a significant disagreement between memorization and membership privacy risks of LLM KD techniques. Finally, we characterize per-block privacy risk and demonstrate that the privacy risk varies across different blocks by a large margin.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Privacy Indicators in Extended Reality: Multimodal Design for Situationally Impaired Bystanders",
    "title_es": "Rethinking Privacy Indicators in Extended Reality: Multimodal Design for Situationally Impaired Bystanders",
    "url": "https://arxiv.org/abs/2508.07057",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07057v1 Announce Type: new \nAbstract: As Extended Reality (XR) devices become increasingly prevalent in everyday settings, they raise significant privacy concerns for bystanders: individuals in the vicinity of an XR device during its use, whom the device sensors may accidentally capture. Current privacy indicators, such as small LEDs, often presume that bystanders are attentive enough to interpret the privacy signals. However, these cues can be easily overlooked when bystanders are distracted or have limited vision. We define such individuals as situationally impaired bystanders. This study explores XR privacy indicator designs that are effective for situationally impaired bystanders. A focus group with eight participants was conducted to design five novel privacy indicators. We evaluated these designs through a user study with seven additional participants. Our results show that visual-only indicators, typical in commercial XR devices, received low ratings for perceived usefulness in impairment scenarios. In contrast, multimodal indicators were preferred in privacy-sensitive scenarios with situationally impaired bystanders. Ultimately, our results highlight the need to move toward adaptable, multimodal, and situationally aware designs that effectively support bystander privacy in everyday XR environments.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Problem Solving: Framing and Problem-Solution Co-Evolution in Data Visualization Design",
    "title_es": "Beyond Problem Solving: Framing and Problem-Solution Co-Evolution in Data Visualization Design",
    "url": "https://arxiv.org/abs/2508.07058",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07058v1 Announce Type: new \nAbstract: Visualization design is often described as the process of solving a well-defined problem by navigating a design space. While existing visualization design models have provided valuable structure and guidance, they tend to foreground technical problem-solving and underemphasize the interpretive, judgment-based aspects of design. In contrast, research in other design disciplines has emphasized the importance of framing--how designers define and redefine what the problem is--and the co-evolution of problem and solution spaces through reflective practice. These dimensions remain underexplored in visualization research, particularly from the perspective of expert practitioners. This paper investigates how visualization designers frame problems and navigate the dynamic interplay between problem understanding and solution development. We conducted a mixed-methods study with 11 expert practitioners using design challenges, diary entries, and semi-structured interviews. Through reflexive thematic analysis, we identified key strategies that participants used to frame problems, reframe them in response to evolving constraints or insights, and build bridges between problem and solution spaces. These included using metaphors, heuristics, sketching, primary generators, and reflective evaluation of failed or incomplete ideas. Our findings contribute an empirically grounded account of visualization design as a reflective, co-evolutionary practice, where framing is not a preliminary step but a continuous activity embedded in design. Participants often reshaped their understanding of the problem based on solution attempts, tool feedback, and ethical or narrative concerns. These insights extend current visualization design models and highlight the need for frameworks that better account for framing and interpretive judgment. (See paper for full abstract.)",
    "source": "arXiv"
  },
  {
    "title": "Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach",
    "title_es": "Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach",
    "url": "https://arxiv.org/abs/2508.07063",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07063v1 Announce Type: new \nAbstract: As AI systems become more integrated into daily life, the need for safer and more reliable moderation has never been greater. Large Language Models (LLMs) have demonstrated remarkable capabilities, surpassing earlier models in complexity and performance. Their evaluation across diverse tasks has consistently showcased their potential, enabling the development of adaptive and personalized agents. However, despite these advancements, LLMs remain prone to errors, particularly in areas requiring nuanced moral reasoning. They struggle with detecting implicit hate, offensive language, and gender biases due to the subjective and context-dependent nature of these issues. Moreover, their reliance on training data can inadvertently reinforce societal biases, leading to inconsistencies and ethical concerns in their outputs. To explore the limitations of LLMs in this role, we developed an experimental framework based on state-of-the-art (SOTA) models to assess human emotions and offensive behaviors. The framework introduces a unified benchmark dataset encompassing 49 distinct categories spanning the wide spectrum of human emotions, offensive and hateful text, and gender and racial biases. Furthermore, we introduced SafePhi, a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This research also highlights the critical domains where LLM moderators consistently underperformed, pressing the need to incorporate more heterogeneous and representative data with human-in-the-loop, for better model robustness and explainability.",
    "source": "arXiv"
  },
  {
    "title": "Unbiased Insights: Optimal Streaming Algorithms for $\\ell_p$ Sampling, the Forget Model, and Beyond",
    "title_es": "Unbiased Insights: Optimal Streaming Algorithms for $\\ell_p$ Sampling, the Forget Model, and Beyond",
    "url": "https://arxiv.org/abs/2508.07067",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07067v1 Announce Type: new \nAbstract: We study $\\ell_p$ sampling and frequency moment estimation in a single-pass insertion-only data stream. For $p \\in (0,2)$, we present a nearly space-optimal approximate $\\ell_p$ sampler that uses $\\widetilde{O}(\\log n \\log(1/\\delta))$ bits of space and for $p = 2$, we present a sampler with space complexity $\\widetilde{O}(\\log^2 n \\log(1/\\delta))$. This space complexity is optimal for $p \\in (0, 2)$ and improves upon prior work by a $\\log n$ factor. We further extend our construction to a continuous $\\ell_p$ sampler, which outputs a valid sample index at every point during the stream.\n  Leveraging these samplers, we design nearly unbiased estimators for $F_p$ in data streams that include forget operations, which reset individual element frequencies and introduce significant non-linear challenges. As a result, we obtain near-optimal algorithms for estimating $F_p$ for all $p$ in this model, originally proposed by Pavan, Chakraborty, Vinodchandran, and Meel [PODS'24], resolving all three open problems they posed.\n  Furthermore, we generalize this model to what we call the suffix-prefix deletion model, and extend our techniques to estimate entropy as a corollary of our moment estimation algorithms. Finally, we show how to handle arbitrary coordinate-wise functions during the stream, for any $g \\in \\mathbb{G}$, where $\\mathbb{G}$ includes all (linear or non-linear) contraction functions.",
    "source": "arXiv"
  },
  {
    "title": "SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages",
    "title_es": "SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages",
    "url": "https://arxiv.org/abs/2508.07069",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07069v1 Announce Type: new \nAbstract: Although numerous datasets have been developed to support dialogue systems, most existing chit-chat datasets overlook the cultural nuances inherent in natural human conversations. To address this gap, we introduce SEADialogues, a culturally grounded dialogue dataset centered on Southeast Asia, a region with over 700 million people and immense cultural diversity. Our dataset features dialogues in eight languages from six Southeast Asian countries, many of which are low-resource despite having sizable speaker populations. To enhance cultural relevance and personalization, each dialogue includes persona attributes and two culturally grounded topics that reflect everyday life in the respective communities. Furthermore, we release a multi-turn dialogue dataset to advance research on culturally aware and human-centric large language models, including conversational dialogue agents.",
    "source": "arXiv"
  },
  {
    "title": "$C^{\\infty}$ rational approximation and quasi-histopolation of functions with jumps through multinode Shepard functions",
    "title_es": "$C^{\\infty}$ rational approximation and quasi-histopolation of functions with jumps through multinode Shepard functions",
    "url": "https://arxiv.org/abs/2508.07070",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07070v1 Announce Type: new \nAbstract: Histopolation, or interpolation on segments, is a mathematical technique used to approximate a function $f$ over a given interval $I=[a,b]$ by exploiting integral information over a set of subintervals of $I$. Unlike classical polynomial interpolation, which is based on pointwise function evaluations, histopolation reconstructs a function using integral data. However, similar to classical polynomial interpolation, histopolation suffers from the well-known Runge phenomenon when integral data are based on a grid with many equispaced nodes, as well as the Gibbs phenomenon when approximating discontinuous functions. In contrast, quasi-histopolation is designed to relax the strict requirement of passing through all the given data points. This inherent flexibility can reduce the likelihood of oscillatory behavior using, for example, rational approximation operators. In this work, we introduce a $C^{\\infty}$ rational quasi-histopolation operator, for bounded (integrable) functions, which reconstruct a function by defeating both the Runge and Gibbs phenomena. A key element of our approach is to blend local histopolation polynomials on a few nodes using multinode Shepard functions as blending functions. Several numerical experiments demonstrate the accuracy of our method.",
    "source": "arXiv"
  },
  {
    "title": "The Fused Kernel Library: A C++ API to Develop Highly-Efficient GPU Libraries",
    "title_es": "The Fused Kernel Library: A C++ API to Develop Highly-Efficient GPU Libraries",
    "url": "https://arxiv.org/abs/2508.07071",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07071v1 Announce Type: new \nAbstract: Existing GPU libraries often struggle to fully exploit the parallel resources and on-chip memory (SRAM) of GPUs when chaining multiple GPU functions as individual kernels. While Kernel Fusion (KF) techniques like Horizontal Fusion (HF) and Vertical Fusion (VF) can mitigate this, current library implementations often require library developers to manually create fused kernels. Hence, library users rely on limited sets of pre-compiled or template-based fused kernels. This limits the use cases that can benefit from HF and VF and increases development costs. In order to solve these issues, we present a novel methodology for building GPU libraries that enables automatic on-demand HF and VF for arbitrary combinations of GPU library functions. Our methodology defines reusable, fusionable components that users combine via high-level programming interfaces. Leveraging C++17 metaprogramming features available in compilers like nvcc, our methodology generates a single and optimized fused kernel tailored to the user's specific sequence of operations at compile time, without needing a custom compiler or manual development and pre-compilation of kernel combinations. This approach abstracts low-level GPU complexities while maximizing GPU resource utilization and keeping intermediate data in SRAM. We provide an open-source implementation demonstrating significant speedups compared to traditional libraries in various benchmarks, validating the effectiveness of this methodology for improving GPU performance in the range of 2x to more than 1000x, while preserving high-level programmability.",
    "source": "arXiv"
  },
  {
    "title": "Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation",
    "title_es": "Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation",
    "url": "https://arxiv.org/abs/2508.07075",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07075v1 Announce Type: new \nAbstract: Large Language Models (LLMs) struggle with dynamic knowledge updates, especially when new information conflicts with deeply embedded facts. Such conflicting factual edits often lead to two critical issues: resistance to adopting the new fact and severe catastrophic forgetting of unrelated knowledge. This paper introduces and evaluates a novel \"unlearn-then-learn\" strategy for precise knowledge editing in LLMs, leveraging the parameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting and Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach is powered by an initial circuit localization phase that identifies and targets the specific internal components responsible for encoding the conflicting fact. Through a rigorous experimental methodology on microsoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically informed two-stage approach achieves near-perfect accuracy (98.50%) for the new, modulated fact while simultaneously effectively suppressing the original conflicting fact (96.00% forget rate). Critically, our strategy exhibits unprecedented localization (72.00% F_control accuracy), dramatically mitigating catastrophic forgetting observed in direct fine-tuning approaches (which showed as low as ~20% F_control accuracy), a direct benefit of our targeted interpretability-guided intervention. Furthermore, qualitative analysis reveals a nuanced mechanism of \"soft forgetting,\" where original knowledge is suppressed from default retrieval but remains latent and conditionally accessible, enhancing model safety and control. These findings represent a significant advancement towards precise, localized, and safe knowledge management in compact LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Application of association rule mining to assess forest species distribution in Italy considering abiotic and biotic factors",
    "title_es": "Application of association rule mining to assess forest species distribution in Italy considering abiotic and biotic factors",
    "url": "https://arxiv.org/abs/2508.07076",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07076v1 Announce Type: new \nAbstract: Biodiversity monitoring represents a pressing global priority, and assessing forest community composition plays a crucial role due to its influence on ecosystem functions. The spatial distribution of forest species becomes essential for understanding biodiversity dynamics, territorial planning, aiding nature conservation and enhancing ecosystem resilience amid global change. Association Rule Mining, commonly applied to other scientific contexts, is now innovatively adopted in the ecological field to explore the relationships among co-occurring plant species and extract hidden interpretable patterns, also with abiotic and biotic conditions. Multiple heterogeneous data sources were integrated through data preprocessing into a unique dataset, including georeferenced information about 151 plant species monitored within 6,784 plots across Italy and several bioclimatic indices, soil-related factors, and variables from earth observations. The Frequent Pattern Growth algorithm, used for association rule mining, provided interesting and encouraging findings, suggesting ecological rules among plant species and environmental conditions. Indeed, temperature seasonality between 650-700 and precipitation seasonality between 45-50 resulted very correlated with Picea abies (confidence = 90.9%, lift = 7.13). Patterns detected for Picea abies highlighted its ecological specificity, indicating a strong association with cold, highly seasonal environments, and particular plant communities. Some species appeared acting as community \"hubs\", frequently co-occurring with other species, suggesting ties to specific environmental or biotic conditions. These findings represent a valuable resource for future research, especially in regions with similar environmental settings and when prior ecological knowledge exists, also underlining the importance of publicly accessible, high-quality ecological data.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Decision Space Diversity in Multi-Objective Evolutionary Optimization for the Diet Problem",
    "title_es": "Enhancing Decision Space Diversity in Multi-Objective Evolutionary Optimization for the Diet Problem",
    "url": "https://arxiv.org/abs/2508.07077",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07077v1 Announce Type: new \nAbstract: Multi-objective evolutionary algorithms (MOEAs) are essential for solving complex optimization problems, such as the diet problem, where balancing conflicting objectives, like cost and nutritional content, is crucial. However, most MOEAs focus on optimizing solutions in the objective space, often neglecting the diversity of solutions in the decision space, which is critical for providing decision-makers with a wide range of choices. This paper introduces an approach that directly integrates a Hamming distance-based measure of uniformity into the selection mechanism of a MOEA to enhance decision space diversity. Experiments on a multi-objective formulation of the diet problem demonstrate that our approach significantly improves decision space diversity compared to NSGA-II, while maintaining comparable objective space performance. The proposed method offers a generalizable strategy for integrating decision space awareness into MOEAs.",
    "source": "arXiv"
  },
  {
    "title": "Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction",
    "title_es": "Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction",
    "url": "https://arxiv.org/abs/2508.07079",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07079v1 Announce Type: new \nAbstract: Safe navigation in pedestrian-rich environments remains a key challenge for autonomous robots. This work evaluates the integration of a deep learning-based Social-Implicit (SI) pedestrian trajectory predictor within a Model Predictive Control (MPC) framework on the physical Continental Corriere robot. Tested across varied pedestrian densities, the SI-MPC system is compared to a traditional Constant Velocity (CV) model in both open-loop prediction and closed-loop navigation. Results show that SI improves trajectory prediction - reducing errors by up to 76% in low-density settings - and enhances safety and motion smoothness in crowded scenes. Moreover, real-world deployment reveals discrepancies between open-loop metrics and closed-loop performance, as the SI model yields broader, more cautious predictions. These findings emphasize the importance of system-level evaluation and highlight the SI-MPC framework's promise for safer, more adaptive navigation in dynamic, human-populated environments.",
    "source": "arXiv"
  },
  {
    "title": "An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving",
    "title_es": "An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.07080",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07080v1 Announce Type: new \nAbstract: Highway on-ramp merging is of great challenge for autonomous vehicles (AVs), since they have to proactively interact with surrounding vehicles to enter the main road safely within limited time. However, existing decision-making algorithms fail to adequately address dynamic complexities and social acceptance of AVs, leading to suboptimal or unsafe merging decisions. To address this, we propose an evolutionary game-theoretic (EGT) merging decision-making framework, grounded in the bounded rationality of human drivers, which dynamically balances the benefits of both AVs and main-road vehicles (MVs). We formulate the cut-in decision-making process as an EGT problem with a multi-objective payoff function that reflects human-like driving preferences. By solving the replicator dynamic equation for the evolutionarily stable strategy (ESS), the optimal cut-in timing is derived, balancing efficiency, comfort, and safety for both AVs and MVs. A real-time driving style estimation algorithm is proposed to adjust the game payoff function online by observing the immediate reactions of MVs. Empirical results demonstrate that we improve the efficiency, comfort and safety of both AVs and MVs compared with existing game-theoretic and traditional planning approaches across multi-object metrics.",
    "source": "arXiv"
  },
  {
    "title": "TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree",
    "title_es": "TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree",
    "url": "https://arxiv.org/abs/2508.07083",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07083v1 Announce Type: new \nAbstract: 3D visual content streaming is a key technology for emerging 3D telepresence and AR/VR applications. One fundamental element underlying the technology is a versatile 3D representation that is capable of producing high-quality renders and can be efficiently compressed at the same time. Existing 3D representations like point clouds, meshes and 3D Gaussians each have limitations in terms of rendering quality, surface definition, and compressibility. In this paper, we present the Textured Surfel Octree (TeSO), a novel 3D representation that is built from point clouds but addresses the aforementioned limitations. It represents a 3D scene as cube-bounded surfels organized on an octree, where each surfel is further associated with a texture patch. By approximating a smooth surface with a large surfel at a coarser level of the octree, it reduces the number of primitives required to represent the 3D scene, and yet retains the high-frequency texture details through the texture map attached to each surfel. We further propose a compression scheme to encode the geometry and texture efficiently, leveraging the octree structure. The proposed textured surfel octree combined with the compression scheme achieves higher rendering quality at lower bit-rates compared to multiple point cloud and 3D Gaussian-based baselines.",
    "source": "arXiv"
  },
  {
    "title": "An Empirical Study on Method-Level Performance Evolution in Open-Source Java Projects",
    "title_es": "An Empirical Study on Method-Level Performance Evolution in Open-Source Java Projects",
    "url": "https://arxiv.org/abs/2508.07084",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07084v1 Announce Type: new \nAbstract: Performance is a critical quality attribute in software development, yet the impact of method-level code changes on performance evolution remains poorly understood. While developers often make intuitive assumptions about which types of modifications are likely to cause performance regressions or improvements, these beliefs lack empirical validation at a fine-grained level. We conducted a large-scale empirical study analyzing performance evolution in 15 mature open-source Java projects hosted on GitHub. Our analysis encompassed 739 commits containing 1,499 method-level code changes, using Java Microbenchmark Harness (JMH) for precise performance measurement and rigorous statistical analysis to quantify both the significance and magnitude of performance variations. We employed bytecode instrumentation to capture method-specific execution metrics and systematically analyzed four key aspects: temporal performance patterns, code change type correlations, developer and complexity factors, and domain-size interactions. Our findings reveal that 32.7% of method-level changes result in measurable performance impacts, with regressions occurring 1.3 times more frequently than improvements. Contrary to conventional wisdom, we found no significant differences in performance impact distributions across code change categories, challenging risk-stratified development strategies. Algorithmic changes demonstrate the highest improvement potential but carry substantial regression risk. Senior developers produce more stable changes with fewer extreme variations, while code complexity correlates with increased regression likelihood. Domain-size interactions reveal significant patterns, with web server + small projects exhibiting the highest performance instability. Our study provides empirical evidence for integrating automated performance testing into continuous integration pipelines.",
    "source": "arXiv"
  },
  {
    "title": "Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework",
    "title_es": "Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework",
    "url": "https://arxiv.org/abs/2508.07085",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07085v1 Announce Type: new \nAbstract: In applied machine learning, concept drift, which is either gradual or abrupt changes in data distribution, can significantly reduce model performance. Typical detection methods,such as statistical tests or reconstruction-based models,are generally reactive and not very sensitive to early detection. Our study proposes a hybrid framework consisting of Transformers and Autoencoders to model complex temporal dynamics and provide online drift detection. We create a distinct Trust Score methodology, which includes signals on (1) statistical and reconstruction-based drift metrics, more specifically, PSI, JSD, Transformer-AE error, (2) prediction uncertainty, (3) rules violations, and (4) trend of classifier error aligned with the combined metrics defined by the Trust Score. Using a time sequenced airline passenger data set with synthetic drift, our proposed model allows for a better detection of drift using as a whole and at different detection thresholds for both sensitivity and interpretability compared to baseline methods and provides a strong pipeline for drift detection in real time for applied machine learning. We evaluated performance using a time-sequenced airline passenger dataset having the gradually injected stimulus of drift in expectations,e.g. permuted ticket prices in later batches, broken into 10 time segments [1].In the data, our results support that the Transformation-Autoencoder detected drift earlier and with more sensitivity than the autoencoders commonly used in the literature, and provided improved modeling over more error rates and logical violations. Therefore, a robust framework was developed to reliably monitor concept drift.",
    "source": "arXiv"
  },
  {
    "title": "SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization",
    "title_es": "SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization",
    "url": "https://arxiv.org/abs/2508.07086",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07086v1 Announce Type: new \nAbstract: Voice anonymization protects speaker privacy by concealing identity while preserving linguistic and paralinguistic content. Self-supervised learning (SSL) representations encode linguistic features but preserve speaker traits. We propose a novel speaker-embedding-free framework called SEF-MK. Instead of using a single k-means model trained on the entire dataset, SEF-MK anonymizes SSL representations for each utterance by randomly selecting one of multiple k-means models, each trained on a different subset of speakers. We explore this approach from both attacker and user perspectives. Extensive experiments show that, compared to a single k-means model, SEF-MK with multiple k-means models better preserves linguistic and emotional content from the user's viewpoint. However, from the attacker's perspective, utilizing multiple k-means models boosts the effectiveness of privacy attacks. These insights can aid users in designing voice anonymization systems to mitigate attacker threats.",
    "source": "arXiv"
  },
  {
    "title": "SQL-Exchange: Transforming SQL Queries Across Domains",
    "title_es": "SQL-Exchange: Transforming SQL Queries Across Domains",
    "url": "https://arxiv.org/abs/2508.07087",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07087v1 Announce Type: new \nAbstract: We introduce SQL-Exchange, a framework for mapping SQL queries across different database schemas by preserving the source query structure while adapting domain-specific elements to align with the target schema. We investigate the conditions under which such mappings are feasible and beneficial, and examine their impact on enhancing the in-context learning performance of text-to-SQL systems as a downstream task. Our comprehensive evaluation across multiple model families and benchmark datasets--assessing structural alignment with source queries, execution validity on target databases, and semantic correctness--demonstrates that SQL-Exchange is effective across a wide range of schemas and query types. Our results further show that using mapped queries as in-context examples consistently improves text-to-SQL performance over using queries from the source schema.",
    "source": "arXiv"
  },
  {
    "title": "A brief introduction to matrix hydrodynamics",
    "title_es": "A brief introduction to matrix hydrodynamics",
    "url": "https://arxiv.org/abs/2508.07088",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07088v1 Announce Type: new \nAbstract: This survey gives a basic demonstration of matrix hydrodynamics; the field pioneered by V. Zeitlin, where 2-D incompressible fluids are spatially discretized via quantization theory.",
    "source": "arXiv"
  },
  {
    "title": "ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting",
    "title_es": "ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting",
    "url": "https://arxiv.org/abs/2508.07089",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07089v1 Announce Type: new \nAbstract: We introduce ForeSight, a novel joint detection and forecasting framework for vision-based 3D perception in autonomous vehicles. Traditional approaches treat detection and forecasting as separate sequential tasks, limiting their ability to leverage temporal cues. ForeSight addresses this limitation with a multi-task streaming and bidirectional learning approach, allowing detection and forecasting to share query memory and propagate information seamlessly. The forecast-aware detection transformer enhances spatial reasoning by integrating trajectory predictions from a multiple hypothesis forecast memory queue, while the streaming forecast transformer improves temporal consistency using past forecasts and refined detections. Unlike tracking-based methods, ForeSight eliminates the need for explicit object association, reducing error propagation with a tracking-free model that efficiently scales across multi-frame sequences. Experiments on the nuScenes dataset show that ForeSight achieves state-of-the-art performance, achieving an EPA of 54.9%, surpassing previous methods by 9.3%, while also attaining the best mAP and minADE among multi-view detection and forecasting models.",
    "source": "arXiv"
  },
  {
    "title": "BharatBBQ: A Multilingual Bias Benchmark for Question Answering in the Indian Context",
    "title_es": "BharatBBQ: A Multilingual Bias Benchmark for Question Answering in the Indian Context",
    "url": "https://arxiv.org/abs/2508.07090",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07090v1 Announce Type: new \nAbstract: Evaluating social biases in language models (LMs) is crucial for ensuring fairness and minimizing the reinforcement of harmful stereotypes in AI systems. Existing benchmarks, such as the Bias Benchmark for Question Answering (BBQ), primarily focus on Western contexts, limiting their applicability to the Indian context. To address this gap, we introduce BharatBBQ, a culturally adapted benchmark designed to assess biases in Hindi, English, Marathi, Bengali, Tamil, Telugu, Odia, and Assamese. BharatBBQ covers 13 social categories, including 3 intersectional groups, reflecting prevalent biases in the Indian sociocultural landscape. Our dataset contains 49,108 examples in one language that are expanded using translation and verification to 392,864 examples in eight different languages. We evaluate five multilingual LM families across zero and few-shot settings, analyzing their bias and stereotypical bias scores. Our findings highlight persistent biases across languages and social categories and often amplified biases in Indian languages compared to English, demonstrating the necessity of linguistically and culturally grounded benchmarks for bias evaluation.",
    "source": "arXiv"
  },
  {
    "title": "Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration",
    "title_es": "Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration",
    "url": "https://arxiv.org/abs/2508.07092",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07092v1 Announce Type: new \nAbstract: Collaborative 3D detection can substantially boost detection performance by allowing agents to exchange complementary information. It inherently results in a fundamental trade-off between detection performance and communication bandwidth. To tackle this bottleneck issue, we propose a novel hybrid collaboration that adaptively integrates two types of communication messages: perceptual outputs, which are compact, and raw observations, which offer richer information. This approach focuses on two key aspects: i) integrating complementary information from two message types and ii) prioritizing the most critical data within each type. By adaptively selecting the most critical set of messages, it ensures optimal perceptual information and adaptability, effectively meeting the demands of diverse communication scenarios.Building on this hybrid collaboration, we present \\texttt{HyComm}, a communication-efficient LiDAR-based collaborative 3D detection system. \\texttt{HyComm} boasts two main benefits: i) it facilitates adaptable compression rates for messages, addressing various communication requirements, and ii) it uses standardized data formats for messages. This ensures they are independent of specific detection models, fostering adaptability across different agent configurations. To evaluate HyComm, we conduct experiments on both real-world and simulation datasets: DAIR-V2X and OPV2V. HyComm consistently outperforms previous methods and achieves a superior performance-bandwidth trade-off regardless of whether agents use the same or varied detection models. It achieves a lower communication volume of more than 2,006$\\times$ and still outperforms Where2comm on DAIR-V2X in terms of AP50. The related code will be released.",
    "source": "arXiv"
  },
  {
    "title": "ScamDetect: Towards a Robust, Agnostic Framework to Uncover Threats in Smart Contracts",
    "title_es": "ScamDetect: Towards a Robust, Agnostic Framework to Uncover Threats in Smart Contracts",
    "url": "https://arxiv.org/abs/2508.07094",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07094v1 Announce Type: new \nAbstract: Smart contracts have transformed decentralized finance by enabling programmable, trustless transactions. However, their widespread adoption and growing financial significance have attracted persistent and sophisticated threats, such as phishing campaigns and contract-level exploits. Traditional transaction-based threat detection methods often expose sensitive user data and interactions, raising privacy and security concerns. In response, static bytecode analysis has emerged as a proactive mitigation strategy, identifying malicious contracts before they execute harmful actions.Building on this approach, we introduced PhishingHook, the first machine-learning-based framework for detecting phishing activities in smart contracts via static bytecode and opcode analysis, achieving approximately 90% detection accuracy. Nevertheless, two pressing challenges remain: (1) the increasing use of sophisticated bytecode obfuscation techniques designed to evade static analysis, and (2) the heterogeneity of blockchain environments requiring platform-agnostic solutions.This paper presents a vision for ScamDetect (Smart Contract Agnostic Malware Detector), a robust, modular, and platform-agnostic framework for smart contract malware detection. Over the next 2.5 years, ScamDetect will evolve in two stages: first, by tackling obfuscated Ethereum Virtual Machine (EVM) bytecode through graph neural network (GNN) analysis of control flow graphs (CFGs), leveraging GNNs' ability to capture complex structural patterns beyond opcode sequences; and second, by generalizing detection capabilities to emerging runtimes such as WASM. ScamDetect aims to enable proactive, scalable security for the future of decentralized ecosystems.",
    "source": "arXiv"
  },
  {
    "title": "Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust",
    "title_es": "Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust",
    "url": "https://arxiv.org/abs/2508.07095",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07095v1 Announce Type: new \nAbstract: Large language models are known to produce outputs that are plausible but factually incorrect. To prevent people from making erroneous decisions by blindly trusting AI, researchers have explored various ways of communicating factuality estimates in AI-generated outputs to end-users. However, little is known about whether revealing content estimated to be factually incorrect influences users' trust when compared to hiding it altogether. We tested four different ways of disclosing an AI-generated output with factuality assessments: transparent (highlights less factual content), attention (highlights factual content), opaque (removes less factual content), ambiguity (makes less factual content vague), and compared them with a baseline response without factuality information. We conducted a human subjects research (N = 148) using the strategies in question-answering scenarios. We found that the opaque and ambiguity strategies led to higher trust while maintaining perceived answer quality, compared to the other strategies. We discuss the efficacy of hiding presumably less factual content to build end-user trust.",
    "source": "arXiv"
  },
  {
    "title": "Realistic Evaluation of Impedance-Based RIS Modeling: Practical Insights and Applications",
    "title_es": "Realistic Evaluation of Impedance-Based RIS Modeling: Practical Insights and Applications",
    "url": "https://arxiv.org/abs/2508.07098",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07098v1 Announce Type: new \nAbstract: Reconfigurable Intelligent Surfaces (RISs) have emerged as a promising technology for next-generation wireless communications, offering energy-efficient control of electromagnetic (EM) waves. While conventional RIS models based on phase shifts and amplitude adjustments have been widely studied, they overlook complex EM phenomena such as mutual coupling, which are crucial for advanced wave manipulations. Recent efforts in EM-consistent modelling have provided more accurate representations of RIS behavior, highlighting challenges like structural scattering-an unwanted signal reflection that can lead to interference. In this paper, we analyze the impact of structural scattering in RIS architectures and compare traditional and EM-consistent models through full-wave simulations, thus providing practical insights on the realistic performance of current RIS designs. Our findings reveal the limitations of current modelling approaches in mitigating this issue, underscoring the need for new optimization strategies.",
    "source": "arXiv"
  },
  {
    "title": "Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning",
    "title_es": "Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning",
    "url": "https://arxiv.org/abs/2508.07101",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07101v1 Announce Type: new \nAbstract: Large reasoning models achieve strong performance through test-time scaling but incur substantial computational overhead, particularly from excessive token generation when processing short input prompts. While sparse attention mechanisms can reduce latency and memory usage, existing approaches suffer from significant accuracy degradation due to accumulated errors during long-generation reasoning. These methods generally require either high token retention rates or expensive retraining. We introduce LessIsMore, a training-free sparse attention mechanism for reasoning tasks, which leverages global attention patterns rather than relying on traditional head-specific local optimizations. LessIsMore aggregates token selections from local attention heads with recent contextual information, enabling unified cross-head token ranking for future decoding layers. This unified selection improves generalization and efficiency by avoiding the need to maintain separate token subsets per head. Evaluation across diverse reasoning tasks and benchmarks shows that LessIsMore preserves -- and in some cases improves -- accuracy while achieving a $1.1\\times$ average decoding speed-up compared to full attention. Moreover, LessIsMore attends to $2\\times$ fewer tokens without accuracy loss, achieving a $1.13\\times$ end-to-end speed-up compared to existing sparse attention methods.",
    "source": "arXiv"
  },
  {
    "title": "Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria",
    "title_es": "Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria",
    "url": "https://arxiv.org/abs/2508.07102",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07102v1 Announce Type: new \nAbstract: Generative modelling has seen significant advances through simulation-free paradigms such as Flow Matching, and in particular, the MeanFlow framework, which replaces instantaneous velocity fields with average velocities to enable efficient single-step sampling. In this work, we introduce a theoretical study on Second-Order MeanFlow, a novel extension that incorporates average acceleration fields into the MeanFlow objective. We first establish the feasibility of our approach by proving that the average acceleration satisfies a generalized consistency condition analogous to first-order MeanFlow, thereby supporting stable, one-step sampling and tractable loss functions. We then characterize its expressivity via circuit complexity analysis, showing that under mild assumptions, the Second-Order MeanFlow sampling process can be implemented by uniform threshold circuits within the $\\mathsf{TC}^0$ class. Finally, we derive provably efficient criteria for scalable implementation by leveraging fast approximate attention computations: we prove that attention operations within the Second-Order MeanFlow architecture can be approximated to within $1/\\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results lay the theoretical foundation for high-order flow matching models that combine rich dynamics with practical sampling efficiency.",
    "source": "arXiv"
  },
  {
    "title": "BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation",
    "title_es": "BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation",
    "url": "https://arxiv.org/abs/2508.07106",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07106v1 Announce Type: new \nAbstract: Functional Magnetic Resonance Imaging (fMRI) is an imaging technique widely used to study human brain activity. fMRI signals in areas across the brain transiently synchronise and desynchronise their activity in a highly structured manner, even when an individual is at rest. These functional connectivity dynamics may be related to behaviour and neuropsychiatric disease. To model these dynamics, temporal brain connectivity representations are essential, as they reflect evolving interactions between brain regions and provide insight into transient neural states and network reconfigurations. However, conventional graph neural networks (GNNs) often struggle to capture long-range temporal dependencies in dynamic fMRI data. To address this challenge, we propose BrainATCL, an unsupervised, nonparametric framework for adaptive temporal brain connectivity learning, enabling functional link prediction and age estimation. Our method dynamically adjusts the lookback window for each snapshot based on the rate of newly added edges. Graph sequences are subsequently encoded using a GINE-Mamba2 backbone to learn spatial-temporal representations of dynamic functional connectivity in resting-state fMRI data of 1,000 participants from the Human Connectome Project. To further improve spatial modeling, we incorporate brain structure and function-informed edge attributes, i.e., the left/right hemispheric identity and subnetwork membership of brain regions, enabling the model to capture biologically meaningful topological patterns. We evaluate our BrainATCL on two tasks: functional link prediction and age estimation. The experimental results demonstrate superior performance and strong generalization, including in cross-session prediction scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention",
    "title_es": "Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention",
    "url": "https://arxiv.org/abs/2508.07107",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07107v1 Announce Type: new \nAbstract: Accurate prediction of student performance is essential for timely academic intervention. However, most machine learning models in education are static and cannot adapt when new data, such as post-intervention outcomes, become available. To address this limitation, we propose a Feedback-Driven Decision Support System (DSS) with a closed-loop architecture that enables continuous model refinement. The system integrates a LightGBM-based regressor with incremental retraining, allowing educators to input updated student results, which automatically trigger model updates. This adaptive mechanism improves prediction accuracy by learning from real-world academic progress. The platform features a Flask-based web interface for real-time interaction and incorporates SHAP for explainability, ensuring transparency. Experimental results show a 10.7\\% reduction in RMSE after retraining, with consistent upward adjustments in predicted scores for intervened students. By transforming static predictors into self-improving systems, our approach advances educational analytics toward human-centered, data-driven, and responsive AI. The framework is designed for integration into LMS and institutional dashboards.",
    "source": "arXiv"
  },
  {
    "title": "Physical Design Exploration of a Wire-Friendly Domain-Specific Processor for Angstrom-Era Nodes",
    "title_es": "Physical Design Exploration of a Wire-Friendly Domain-Specific Processor for Angstrom-Era Nodes",
    "url": "https://arxiv.org/abs/2508.07110",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07110v1 Announce Type: new \nAbstract: This paper presents the physical design exploration of a domain-specific processor (DSIP) architecture targeted at machine learning (ML), addressing the challenges of interconnect efficiency in advanced Angstrom-era technologies. The design emphasizes reduced wire length and high core density by utilizing specialized memory structures and SIMD (Single Instruction, Multiple Data) units. Five configurations are synthesized and evaluated using the IMEC A10 nanosheet node PDK. Key physical design metrics are compared across configurations and against VWR2A, a state-of-the-art (SoA) DSIP baseline. Results show that our architecture achieves over 2x lower normalized wire length and more than 3x higher density than the SoA, with low variability in the metrics across all configurations, making it a promising solution for next-generation DSIP designs. These improvements are achieved with minimal manual layout intervention, demonstrating the architecture's intrinsic physical efficiency and potential for low-cost wire-friendly implementation.",
    "source": "arXiv"
  },
  {
    "title": "Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution",
    "title_es": "Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution",
    "url": "https://arxiv.org/abs/2508.07111",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07111v1 Announce Type: new \nAbstract: Large language models (LLMs) have achieved impressive performance, leading to their widespread adoption as decision-support tools in resource-constrained contexts like hiring and admissions. There is, however, scientific consensus that AI systems can reflect and exacerbate societal biases, raising concerns about identity-based harm when used in critical social contexts. Prior work has laid a solid foundation for assessing bias in LLMs by evaluating demographic disparities in different language reasoning tasks. In this work, we extend single-axis fairness evaluations to examine intersectional bias, recognizing that when multiple axes of discrimination intersect, they create distinct patterns of disadvantage. We create a new benchmark called WinoIdentity by augmenting the WinoBias dataset with 25 demographic markers across 10 attributes, including age, nationality, and race, intersected with binary gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns. Focusing on harms of omission due to underrepresentation, we investigate bias through the lens of uncertainty and propose a group (un)fairness metric called Coreference Confidence Disparity which measures whether models are more or less confident for some intersectional identities than others. We evaluate five recently published LLMs and find confidence disparities as high as 40% along various demographic attributes including body type, sexual orientation and socio-economic status, with models being most uncertain about doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly, coreference confidence decreases even for hegemonic or privileged markers, indicating that the recent impressive performance of LLMs is more likely due to memorization than logical reasoning. Notably, these are two independent failures in value alignment and validity that can compound to cause social harm.",
    "source": "arXiv"
  },
  {
    "title": "AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation",
    "title_es": "AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation",
    "url": "https://arxiv.org/abs/2508.07112",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07112v1 Announce Type: new \nAbstract: Lifting-based methods for 3D Human Pose Estimation (HPE), which predict 3D poses from detected 2D keypoints, often generalize poorly to new datasets and real-world settings. To address this, we propose \\emph{AugLift}, a simple yet effective reformulation of the standard lifting pipeline that significantly improves generalization performance without requiring additional data collection or sensors. AugLift sparsely enriches the standard input -- the 2D keypoint coordinates $(x, y)$ -- by augmenting it with a keypoint detection confidence score $c$ and a corresponding depth estimate $d$. These additional signals are computed from the image using off-the-shelf, pre-trained models (e.g., for monocular depth estimation), thereby inheriting their strong generalization capabilities. Importantly, AugLift serves as a modular add-on and can be readily integrated into existing lifting architectures.\n  Our extensive experiments across four datasets demonstrate that AugLift boosts cross-dataset performance on unseen datasets by an average of $10.1\\%$, while also improving in-distribution performance by $4.0\\%$. These gains are consistent across various lifting architectures, highlighting the robustness of our method. Our analysis suggests that these sparse, keypoint-aligned cues provide robust frame-level context, offering a practical way to significantly improve the generalization of any lifting-based pose estimation model. Code will be made publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning",
    "title_es": "Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning",
    "url": "https://arxiv.org/abs/2508.07114",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07114v1 Announce Type: new \nAbstract: In this work, we propose a new machine learning (ML) methodology to obtain more precise predictions for some parameters of interest in a given hypotheses testing problem. Our proposed method also allows ML models to have more discriminative power in cases where it is extremely challenging for state-of-the-art classifiers to have any level of accurate predictions. This method can also allow us to systematically decrease the error from ML models in their predictions. In this paper, we provide a mathematical motivation why Multiple Instance Learning (MIL) would have more predictive power over their single-instance counterparts. We support our theoretical claims by analyzing the behavior of the MIL models through their scaling behaviors with respect to the number of instances on which the model makes predictions. As a concrete application, we constrain Wilson coefficients of the Standard Model Effective Field Theory (SMEFT) using kinematic information from subatomic particle collision events at the Large Hadron Collider (LHC). We show that under certain circumstances, it might be possible to extract the theoretical maximum Fisher Information latent in a dataset.",
    "source": "arXiv"
  },
  {
    "title": "From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context",
    "title_es": "From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context",
    "url": "https://arxiv.org/abs/2508.07117",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07117v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over structured data, including text-attributed graphs, which are common in domains such as citation networks, social platforms, and knowledge graphs. GNNs are not inherently interpretable and thus, many explanation methods have been proposed. However, existing explanation methods often struggle to generate interpretable, fine-grained rationales, especially when node attributes include rich natural language. In this work, we introduce LOGIC, a lightweight, post-hoc framework that uses large language models (LLMs) to generate faithful and interpretable explanations for GNN predictions. LOGIC projects GNN node embeddings into the LLM embedding space and constructs hybrid prompts that interleave soft prompts with textual inputs from the graph structure. This enables the LLM to reason about GNN internal representations and produce natural language explanations along with concise explanation subgraphs. Our experiments across four real-world TAG datasets demonstrate that LOGIC achieves a favorable trade-off between fidelity and sparsity, while significantly improving human-centric metrics such as insightfulness. LOGIC sets a new direction for LLM-based explainability in graph learning by aligning GNN internals with human reasoning.",
    "source": "arXiv"
  },
  {
    "title": "DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit",
    "title_es": "DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit",
    "url": "https://arxiv.org/abs/2508.07118",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07118v1 Announce Type: new \nAbstract: DexFruit is a robotic manipulation framework that enables gentle, autonomous handling of fragile fruit and precise evaluation of damage. Many fruits are fragile and prone to bruising, thus requiring humans to manually harvest them with care. In this work, we demonstrate by using optical tactile sensing, autonomous manipulation of fruit with minimal damage can be achieved. We show that our tactile informed diffusion policies outperform baselines in both reduced bruising and pick-and-place success rate across three fruits: strawberries, tomatoes, and blackberries. In addition, we introduce FruitSplat, a novel technique to represent and quantify visual damage in high-resolution 3D representation via 3D Gaussian Splatting (3DGS). Existing metrics for measuring damage lack quantitative rigor or require expensive equipment. With FruitSplat, we distill a 2D strawberry mask as well as a 2D bruise segmentation mask into the 3DGS representation. Furthermore, this representation is modular and general, compatible with any relevant 2D model. Overall, we demonstrate a 92% grasping policy success rate, up to a 20% reduction in visual bruising, and up to an 31% improvement in grasp success rate on challenging fruit compared to our baselines across our three tested fruits. We rigorously evaluate this result with over 630 trials. Please checkout our website at https://dex-fruit.github.io .",
    "source": "arXiv"
  },
  {
    "title": "Compressibility Barriers to Neighborhood-Preserving Data Visualizations",
    "title_es": "Compressibility Barriers to Neighborhood-Preserving Data Visualizations",
    "url": "https://arxiv.org/abs/2508.07119",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07119v1 Announce Type: new \nAbstract: To what extent is it possible to visualize high-dimensional datasets in a two- or three-dimensional space? We reframe this question in terms of embedding $n$-vertex graphs (representing the neighborhood structure of the input points) into metric spaces of low doubling dimension $d$, in such a way that maintains the separation between neighbors and non-neighbors. This seemingly lax embedding requirement is surprisingly difficult to satisfy. Our investigation shows that an overwhelming fraction of graphs require $d = \\Omega(\\log n)$. Even when considering sparse regular graphs, the situation does not improve, as an overwhelming fraction of such graphs requires $d= \\Omega(\\log n / \\log\\log n)$. The landscape changes dramatically when embedding into normed spaces. In particular, all but a vanishing fraction of graphs demand $d=\\Theta(n)$. Finally, we study the implications of these results for visualizing data with intrinsic cluster structure. We find that graphs produced from a planted partition model with $k$ clusters on $n$ points typically require $d=\\Omega(\\log n)$, even when the cluster structure is salient. These results challenge the aspiration that constant-dimensional visualizations can faithfully preserve neighborhood structure.",
    "source": "arXiv"
  },
  {
    "title": "Distributionally Robust Control with Constraints on Linear Unidimensional Projections",
    "title_es": "Distributionally Robust Control with Constraints on Linear Unidimensional Projections",
    "url": "https://arxiv.org/abs/2508.07121",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07121v1 Announce Type: new \nAbstract: Distributionally robust control is a well-studied framework for optimal decision making under uncertainty, with the objective of minimizing an expected cost function over control actions, assuming the most adverse probability distribution from an ambiguity set. We consider an interpretable and expressive class of ambiguity sets defined by constraints on the expected value of functions of one-dimensional linear projections of the uncertain parameters. Prior work has shown that, under conditions, problems in this class can be reformulated as finite convex problems. In this work, we propose two iterative methods that can be used to approximately solve problems of this class in the general case. The first is an approximate algorithm based on best-response dynamics. The second is an approximate method that first reformulates the problem as a semi-infinite program and then solves a relaxation. We apply our methods to portfolio construction and trajectory planning scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks",
    "title_es": "Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks",
    "url": "https://arxiv.org/abs/2508.07122",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07122v1 Announce Type: new \nAbstract: This paper proposes a spatiotemporal graph neural network-based performance prediction algorithm to address the challenge of forecasting performance fluctuations in distributed backend systems with multi-level service call structures. The method abstracts system states at different time slices into a sequence of graph structures. It integrates the runtime features of service nodes with the invocation relationships among services to construct a unified spatiotemporal modeling framework. The model first applies a graph convolutional network to extract high-order dependency information from the service topology. Then it uses a gated recurrent network to capture the dynamic evolution of performance metrics over time. A time encoding mechanism is also introduced to enhance the model's ability to represent non-stationary temporal sequences. The architecture is trained in an end-to-end manner, optimizing the multi-layer nested structure to achieve high-precision regression of future service performance metrics. To validate the effectiveness of the proposed method, a large-scale public cluster dataset is used. A series of multi-dimensional experiments are designed, including variations in time windows and concurrent load levels. These experiments comprehensively evaluate the model's predictive performance and stability. The experimental results show that the proposed model outperforms existing representative methods across key metrics such as MAE, RMSE, and R2. It maintains strong robustness under varying load intensities and structural complexities. These results demonstrate the model's practical potential for backend service performance management tasks.",
    "source": "arXiv"
  },
  {
    "title": "Modelling Human Skin Morphology and Simulating Transdermal Transport of 50 Chemicals",
    "title_es": "Modelling Human Skin Morphology and Simulating Transdermal Transport of 50 Chemicals",
    "url": "https://arxiv.org/abs/2508.07123",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07123v1 Announce Type: new \nAbstract: People use various products containing chemical substances that can diffuse through the human skin barrier and reach deeper layers. Therefore, it is essential to understand the transport mechanisms of these chemicals. We developed computable skin meshes for different anatomical regions of young and old skin in two and three dimensions. Numerical methods were applied to simulate the permeation of 50 chemicals. Diffusion coefficients, partition coefficients, and molecular weights were key factors that influenced diffusion and absorption. These findings provide insights into permeation pathways that can support the development and optimization of pharmaceutical formulations.",
    "source": "arXiv"
  },
  {
    "title": "AerialDB: A Federated Peer-to-Peer Spatio-temporal Edge Datastore for Drone Fleets",
    "title_es": "AerialDB: A Federated Peer-to-Peer Spatio-temporal Edge Datastore for Drone Fleets",
    "url": "https://arxiv.org/abs/2508.07124",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07124v1 Announce Type: new \nAbstract: Recent years have seen an unprecedented growth in research that leverages the newest computing paradigm of Internet of Drones, comprising a fleet of connected Unmanned Aerial Vehicles (UAVs) used for a wide range of tasks such as monitoring and analytics in highly mobile and changing environments characteristic of disaster regions. Given that the typical data (i.e., videos and images) collected by the fleet of UAVs deployed in such scenarios can be considerably larger than what the onboard computers can process, the UAVs need to offload their data in real-time to the edge and the cloud for further processing. To that end, we present the design of AerialDB - a lightweight decentralized data storage and query system that can store and process time series data on a multi-UAV system comprising: A) a fleet of hundreds of UAVs fitted with onboard computers, and B) ground-based edge servers connected through a cellular link. Leveraging lightweight techniques for content-based replica placement and indexing of shards, AerialDB has been optimized for efficient processing of different possible combinations of typical spatial and temporal queries performed by real-world disaster management applications. Using containerized deployment spanning up to 400 drones and 80 edges, we demonstrate that AerialDB is able to scale efficiently while providing near real-time performance with different realistic workloads. Further, AerialDB comprises a decentralized and locality-aware distributed execution engine which provides graceful degradation of performance upon edge failures with relatively low latency while processing large spatio-temporal data. AerialDB exhibits comparable insertion performance and 100 times improvement in query performance against state-of-the-art baseline. Moreover, it exhibits a 10 times and 100 times improvement with insertion and query workloads respectively over the cloud baseline.",
    "source": "arXiv"
  },
  {
    "title": "Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning",
    "title_es": "Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning",
    "url": "https://arxiv.org/abs/2508.07126",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07126v1 Announce Type: new \nAbstract: Training reinforcement learning agents with human feedback is crucial when task objectives are difficult to specify through dense reward functions. While prior methods rely on offline trajectory comparisons to elicit human preferences, such data is unavailable in online learning scenarios where agents must adapt on the fly. Recent approaches address this by collecting real-time scalar feedback to guide agent behavior and train reward models for continued learning after human feedback becomes unavailable. However, scalar feedback is often noisy and inconsistent, limiting the accuracy and generalization of learned rewards. We propose Pref-GUIDE, a framework that transforms real-time scalar feedback into preference-based data to improve reward model learning for continual policy training. Pref-GUIDE Individual mitigates temporal inconsistency by comparing agent behaviors within short windows and filtering ambiguous feedback. Pref-GUIDE Voting further enhances robustness by aggregating reward models across a population of users to form consensus preferences. Across three challenging environments, Pref-GUIDE significantly outperforms scalar-feedback baselines, with the voting variant exceeding even expert-designed dense rewards. By reframing scalar feedback as structured preferences with population feedback, Pref-GUIDE offers a scalable and principled approach for harnessing human input in online reinforcement learning.",
    "source": "arXiv"
  },
  {
    "title": "How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?",
    "title_es": "How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?",
    "url": "https://arxiv.org/abs/2508.07127",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07127v1 Announce Type: new \nAbstract: Cardiovascular disease (CVD) prediction remains a tremendous challenge due to its multifactorial etiology and global burden of morbidity and mortality. Despite the growing availability of genomic and electrophysiological data, extracting biologically meaningful insights from such high-dimensional, noisy, and sparsely annotated datasets remains a non-trivial task. Recently, LLMs has been applied effectively to predict structural variations in biological sequences. In this work, we explore the potential of fine-tuned LLMs to predict cardiac diseases and SNPs potentially leading to CVD risk using genetic markers derived from high-throughput genomic profiling. We investigate the effect of genetic patterns associated with cardiac conditions and evaluate how LLMs can learn latent biological relationships from structured and semi-structured genomic data obtained by mapping genetic aspects that are inherited from the family tree. By framing the problem as a Chain of Thought (CoT) reasoning task, the models are prompted to generate disease labels and articulate informed clinical deductions across diverse patient profiles and phenotypes. The findings highlight the promise of LLMs in contributing to early detection, risk assessment, and ultimately, the advancement of personalized medicine in cardiac care.",
    "source": "arXiv"
  },
  {
    "title": "Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays",
    "title_es": "Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays",
    "url": "https://arxiv.org/abs/2508.07128",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07128v1 Announce Type: new \nAbstract: Generative image models have achieved remarkable progress in both natural and medical imaging. In the medical context, these techniques offer a potential solution to data scarcity-especially for low-prevalence anomalies that impair the performance of AI-driven diagnostic and segmentation tools. However, questions remain regarding the fidelity and clinical utility of synthetic images, since poor generation quality can undermine model generalizability and trust. In this study, we evaluate the effectiveness of state-of-the-art generative models-Generative Adversarial Networks (GANs) and Diffusion Models (DMs)-for synthesizing chest X-rays conditioned on four abnormalities: Atelectasis (AT), Lung Opacity (LO), Pleural Effusion (PE), and Enlarged Cardiac Silhouette (ECS). Using a benchmark composed of real images from the MIMIC-CXR dataset and synthetic images from both GANs and DMs, we conducted a reader study with three radiologists of varied experience. Participants were asked to distinguish real from synthetic images and assess the consistency between visual features and the target abnormality. Our results show that while DMs generate more visually realistic images overall, GANs can report better accuracy for specific conditions, such as absence of ECS. We further identify visual cues radiologists use to detect synthetic images, offering insights into the perceptual gaps in current models. These findings underscore the complementary strengths of GANs and DMs and point to the need for further refinement to ensure generative models can reliably augment training datasets for AI diagnostic systems.",
    "source": "arXiv"
  },
  {
    "title": "Toward AI Matching Policies in Homeless Services: A Qualitative Study with Policymakers",
    "title_es": "Toward AI Matching Policies in Homeless Services: A Qualitative Study with Policymakers",
    "url": "https://arxiv.org/abs/2508.07129",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07129v1 Announce Type: new \nAbstract: Artificial intelligence researchers have proposed various data-driven algorithms to improve the processes that match individuals experiencing homelessness to scarce housing resources. It remains unclear whether and how these algorithms are received or adopted by practitioners and what their corresponding consequences are. Through semi-structured interviews with 13 policymakers in homeless services in Los Angeles, we investigate whether such change-makers are open to the idea of integrating AI into the housing resource matching process, identifying where they see potential gains and drawbacks from such a system in issues of efficiency, fairness, and transparency. Our qualitative analysis indicates that, even when aware of various complicating factors, policymakers welcome the idea of an AI matching tool if thoughtfully designed and used in tandem with human decision-makers. Though there is no consensus as to the exact design of such an AI system, insights from policymakers raise open questions and design considerations that can be enlightening for future researchers and practitioners who aim to build responsible algorithmic systems to support decision-making in low-resource scenarios.",
    "source": "arXiv"
  },
  {
    "title": "\"Draw me a curator\" Examining the visual stereotyping of a cultural services profession by generative AI",
    "title_es": "\"Draw me a curator\" Examining the visual stereotyping of a cultural services profession by generative AI",
    "url": "https://arxiv.org/abs/2508.07132",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07132v1 Announce Type: new \nAbstract: Based on 230 visualisations, this paper examines the depiction of museum curators by the popular generative Artificial Intelligence (AI) model, ChatGPT4o. While the AI-generated representations do not reiterate popular stereotypes of curators as nerdy, conservative in dress and stuck in time rummaging through collections, they contrast sharply with real-world demographics. AI-generated imagery extremely underrepresents women (3.5% vs 49% to 72% in reality) and disregards ethnic communities other than Caucasian (0% vs 18% to 36%). It only over-represents young curators (79% vs approx. 27%) but also renders curators to resemble yuppie professionals or people featuring in fashion advertising. Stereotypical attributes are prevalent, with curators widely depicted as wearing beards and holding clipboards or digital tablets. The findings highlight biases in the generative AI image creation dataset, which is poised to shape an inaccurate portrayal of museum professionals if the images were to be taken uncritically at face value.",
    "source": "arXiv"
  },
  {
    "title": "A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs",
    "title_es": "A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs",
    "url": "https://arxiv.org/abs/2508.07134",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07134v1 Announce Type: new \nAbstract: Semi-Nonnegative Matrix Factorization (semi-NMF) extends classical Nonnegative Matrix Factorization (NMF) by allowing the basis matrix to contain both positive and negative entries, making it suitable for decomposing data with mixed signs. However, most existing semi-NMF algorithms are iterative, non-convex, and prone to local minima. In this paper, we propose a novel method that yields a globally optimal solution to the semi-NMF problem under the Frobenius norm, through an orthogonal decomposition derived from the scatter matrix of the input data. We rigorously prove that our solution attains the global minimum of the reconstruction error. Furthermore, we demonstrate that when the input matrix is nonnegative, our method often achieves lower reconstruction error than standard NMF algorithms, although unfortunately the basis matrix may not satisfy nonnegativity. In particular, in low-rank cases such as rank 1 or 2, our solution reduces exactly to a nonnegative factorization, recovering the NMF structure. We validate our approach through experiments on both synthetic data and the UCI Wine dataset, showing that our method consistently outperforms existing NMF and semi-NMF methods in terms of reconstruction accuracy. These results confirm that our globally optimal, non-iterative formulation offers both theoretical guarantees and empirical advantages, providing a new perspective on matrix factorization in optimization and data analysis.",
    "source": "arXiv"
  },
  {
    "title": "Canvas3D: Empowering Precise Spatial Control for Image Generation with Constraints from a 3D Virtual Canvas",
    "title_es": "Canvas3D: Empowering Precise Spatial Control for Image Generation with Constraints from a 3D Virtual Canvas",
    "url": "https://arxiv.org/abs/2508.07135",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07135v1 Announce Type: new \nAbstract: Generative AI (GenAI) has significantly advanced the ease and flexibility of image creation. However, it remains a challenge to precisely control spatial compositions, including object arrangement and scene conditions. To bridge this gap, we propose Canvas3D, an interactive system leveraging a 3D engine to enable precise spatial manipulation for image generation. Upon user prompt, Canvas3D automatically converts textual descriptions into interactive objects within a 3D engine-driven virtual canvas, empowering direct and precise spatial configuration. These user-defined arrangements generate explicit spatial constraints that guide generative models in accurately reflecting user intentions in the resulting images. We conducted a closed-end comparative study between Canvas3D and a baseline system. And an open-ended study to evaluate our system \"in the wild\". The result indicates that Canvas3D outperforms the baseline on spatial control, interactivity, and overall user experience.",
    "source": "arXiv"
  },
  {
    "title": "A Stable and Principled Loss Function for Direct Language Model Alignment",
    "title_es": "A Stable and Principled Loss Function for Direct Language Model Alignment",
    "url": "https://arxiv.org/abs/2508.07137",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07137v1 Announce Type: new \nAbstract: The alignment of large language models (LLMs) with human preferences is commonly achieved through Reinforcement Learning from Human Feedback (RLHF). Direct Preference Optimization (DPO) simplified this paradigm by establishing a direct mapping between the optimal policy and a reward function, eliminating the need for an explicit reward model. However, we argue that the DPO loss function is theoretically misaligned with its own derivation, as it promotes the indefinite maximization of a logits difference, which can lead to training instability and reward hacking. In this paper, we propose a novel loss function derived directly from the RLHF optimality condition. Our proposed loss targets a specific, finite value for the logits difference, which is dictated by the underlying reward, rather than its maximization. We provide a theoretical analysis, including a gradient-based comparison, to demonstrate that our method avoids the large gradients that plague DPO when the probability of dispreferred responses approaches zero. This inherent stability prevents reward hacking and leads to more effective alignment. We validate our approach by fine-tuning a Qwen2.5-7B model, showing significant win-rate improvements over a standard DPO baseline and achieving competitive performance against larger models like Llama-3.1-8B.",
    "source": "arXiv"
  },
  {
    "title": "Strategic Incentivization for Locally Differentially Private Federated Learning",
    "title_es": "Strategic Incentivization for Locally Differentially Private Federated Learning",
    "url": "https://arxiv.org/abs/2508.07138",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07138v1 Announce Type: new \nAbstract: In Federated Learning (FL), multiple clients jointly train a machine learning model by sharing gradient information, instead of raw data, with a server over multiple rounds. To address the possibility of information leakage in spite of sharing only the gradients, Local Differential Privacy (LDP) is often used. In LDP, clients add a selective amount of noise to the gradients before sending the same to the server. Although such noise addition protects the privacy of clients, it leads to a degradation in global model accuracy. In this paper, we model this privacy-accuracy trade-off as a game, where the sever incentivizes the clients to add a lower degree of noise for achieving higher accuracy, while the clients attempt to preserve their privacy at the cost of a potential loss in accuracy. A token based incentivization mechanism is introduced in which the quantum of tokens credited to a client in an FL round is a function of the degree of perturbation of its gradients. The client can later access a newly updated global model only after acquiring enough tokens, which are to be deducted from its balance. We identify the players, their actions and payoff, and perform a strategic analysis of the game. Extensive experiments were carried out to study the impact of different parameters.",
    "source": "arXiv"
  },
  {
    "title": "A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection",
    "title_es": "A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection",
    "url": "https://arxiv.org/abs/2508.07139",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07139v1 Announce Type: new \nAbstract: Ensuring LLM alignment is critical to information security as AI models become increasingly widespread and integrated in society. Unfortunately, many defenses against adversarial attacks and jailbreaking on LLMs cannot adapt quickly to new attacks, degrade model responses to benign prompts, or introduce significant barriers to scalable implementation. To mitigate these challenges, we introduce a real-time, self-tuning (RTST) moderator framework to defend against adversarial attacks while maintaining a lightweight training footprint. We empirically evaluate its effectiveness using Google's Gemini models against modern, effective jailbreaks. Our results demonstrate the advantages of an adaptive, minimally intrusive framework for jailbreak defense over traditional fine-tuning or classifier models.",
    "source": "arXiv"
  },
  {
    "title": "CMAMRNet: A Contextual Mask-Aware Network Enhancing Mural Restoration Through Comprehensive Mask Guidance",
    "title_es": "CMAMRNet: A Contextual Mask-Aware Network Enhancing Mural Restoration Through Comprehensive Mask Guidance",
    "url": "https://arxiv.org/abs/2508.07140",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07140v1 Announce Type: new \nAbstract: Murals, as invaluable cultural artifacts, face continuous deterioration from environmental factors and human activities. Digital restoration of murals faces unique challenges due to their complex degradation patterns and the critical need to preserve artistic authenticity. Existing learning-based methods struggle with maintaining consistent mask guidance throughout their networks, leading to insufficient focus on damaged regions and compromised restoration quality. We propose CMAMRNet, a Contextual Mask-Aware Mural Restoration Network that addresses these limitations through comprehensive mask guidance and multi-scale feature extraction. Our framework introduces two key components: (1) the Mask-Aware Up/Down-Sampler (MAUDS), which ensures consistent mask sensitivity across resolution scales through dedicated channel-wise feature selection and mask-guided feature fusion; and (2) the Co-Feature Aggregator (CFA), operating at both the highest and lowest resolutions to extract complementary features for capturing fine textures and global structures in degraded regions. Experimental results on benchmark datasets demonstrate that CMAMRNet outperforms state-of-the-art methods, effectively preserving both structural integrity and artistic details in restored murals. The code is available at~\\href{https://github.com/CXH-Research/CMAMRNet}{https://github.com/CXH-Research/CMAMRNet}.",
    "source": "arXiv"
  },
  {
    "title": "SketchConcept: Sketching-based Concept Recomposition for Product Design using Generative AI",
    "title_es": "SketchConcept: Sketching-based Concept Recomposition for Product Design using Generative AI",
    "url": "https://arxiv.org/abs/2508.07141",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07141v1 Announce Type: new \nAbstract: Conceptual product design requires designers to explore the design space of visual and functional concepts simultaneously. Sketching has long been adopted to empower concept exploration. However, current sketch-based design tools mostly emphasize visual design using emerging techniques. We present SketchConcept, a design support tool that decomposes design concepts into visual representations and functionality of concepts using sketches and textual descriptions. We propose a function-to-visual mapping workflow that maps the function descriptions generated by a Large Language Model to a component of the concept produced by image Generative Artificial Intelligence(GenAI). The function-to-visual mapping allows our system to leverage multimodal GenAI to decompose, generate, and edit the design concept to satisfy the overall function and behavior. We present multiple use cases enabled by SketchConcept to validate the workflow. Finally, we evaluated the efficacy and usability of our system with a two-session user study.",
    "source": "arXiv"
  },
  {
    "title": "SGD Convergence under Stepsize Shrinkage in Low-Precision Training",
    "title_es": "SGD Convergence under Stepsize Shrinkage in Low-Precision Training",
    "url": "https://arxiv.org/abs/2508.07142",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07142v1 Announce Type: new \nAbstract: Low-precision training has become essential for reducing the computational and memory costs of large-scale deep learning. However, quantization of gradients introduces both magnitude shrinkage and additive noise, which can alter the convergence behavior of stochastic gradient descent (SGD). In this work, we study the convergence of SGD under a gradient shrinkage model, where each stochastic gradient is scaled by a factor $q_k \\in (0,1]$ and perturbed by zero-mean quantization noise. We show that this shrinkage is equivalent to replacing the nominal stepsize $\\mu_k$ with an effective stepsize $\\mu_k q_k$, which slows convergence when $q_{\\min} < 1$. Under standard smoothness and bounded-variance assumptions, we prove that low-precision SGD still converges, but at a reduced rate determined by $q_{\\min}$, and with an increased asymptotic error floor due to quantization noise. We theoretically analyze how reduced numerical precision slows down training by modeling it as gradient shrinkage in the standard SGD convergence framework.",
    "source": "arXiv"
  },
  {
    "title": "Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens",
    "title_es": "Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens",
    "url": "https://arxiv.org/abs/2508.07143",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07143v1 Announce Type: new \nAbstract: Automatic Speech Recognition (ASR) systems now mediate countless human-technology interactions, yet research on their fairness implications remains surprisingly limited. This paper examines ASR bias through a philosophical lens, arguing that systematic misrecognition of certain speech varieties constitutes more than a technical limitation -- it represents a form of disrespect that compounds historical injustices against marginalized linguistic communities. We distinguish between morally neutral classification (discriminate1) and harmful discrimination (discriminate2), demonstrating how ASR systems can inadvertently transform the former into the latter when they consistently misrecognize non-standard dialects. We identify three unique ethical dimensions of speech technologies that differentiate ASR bias from other algorithmic fairness concerns: the temporal burden placed on speakers of non-standard varieties (\"temporal taxation\"), the disruption of conversational flow when systems misrecognize speech, and the fundamental connection between speech patterns and personal/cultural identity. These factors create asymmetric power relationships that existing technical fairness metrics fail to capture. The paper analyzes the tension between linguistic standardization and pluralism in ASR development, arguing that current approaches often embed and reinforce problematic language ideologies. We conclude that addressing ASR bias requires more than technical interventions; it demands recognition of diverse speech varieties as legitimate forms of expression worthy of technological accommodation. This philosophical reframing offers new pathways for developing ASR systems that respect linguistic diversity and speaker autonomy.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Pattern Alignment Learning for Pretraining Lightweight Human-Centric Vision Models",
    "title_es": "Dynamic Pattern Alignment Learning for Pretraining Lightweight Human-Centric Vision Models",
    "url": "https://arxiv.org/abs/2508.07144",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07144v1 Announce Type: new \nAbstract: Human-centric vision models (HVMs) have achieved remarkable generalization due to large-scale pretraining on massive person images. However, their dependence on large neural architectures and the restricted accessibility of pretraining data significantly limits their practicality in real-world applications. To address this limitation, we propose Dynamic Pattern Alignment Learning (DPAL), a novel distillation-based pretraining framework that efficiently trains lightweight HVMs to acquire strong generalization from large HVMs. In particular, human-centric visual perception are highly dependent on three typical visual patterns, including global identity pattern, local shape pattern and multi-person interaction pattern. To achieve generalizable lightweight HVMs, we firstly design a dynamic pattern decoder (D-PaDe), acting as a dynamic Mixture of Expert (MoE) model. It incorporates three specialized experts dedicated to adaptively extract typical visual patterns, conditioned on both input image and pattern queries. And then, we present three levels of alignment objectives, which aims to minimize generalization gap between lightweight HVMs and large HVMs at global image level, local pixel level, and instance relation level. With these two deliberate designs, the DPAL effectively guides lightweight model to learn all typical human visual patterns from large HVMs, which can generalize to various human-centric vision tasks. Extensive experiments conducted on 15 challenging datasets demonstrate the effectiveness of the DPAL. Remarkably, when employing PATH-B as the teacher, DPAL-ViT/Ti (5M parameters) achieves surprising generalizability similar to existing large HVMs such as PATH-B (84M) and Sapiens-L (307M), and outperforms previous distillation-based pretraining methods including Proteus-ViT/Ti (5M) and TinyMiM-ViT/Ti (5M) by a large margin.",
    "source": "arXiv"
  },
  {
    "title": "When Competition Helps: Achieving Optimal Traffic Flow with Multiple Autonomous Planners",
    "title_es": "When Competition Helps: Achieving Optimal Traffic Flow with Multiple Autonomous Planners",
    "url": "https://arxiv.org/abs/2508.07145",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07145v1 Announce Type: new \nAbstract: The inefficiency of selfish routing in congested networks is a classical problem in algorithmic game theory, often captured by the Price of Anarchy (i.e., the ratio between the social cost of decentralized decisions and that of a centrally optimized solution.) With the advent of autonomous vehicles, capable of receiving and executing centrally assigned routes, it is natural to ask whether their deployment can eliminate this inefficiency. At first glance, a central authority could simply compute an optimal traffic assignment and instruct each vehicle to follow its assigned path. However, this vision overlooks critical challenges: routes must be individually rational (no vehicle has an incentive to deviate), and in practice, multiple planning agents (e.g., different companies) may coexist and compete. Surprisingly, we show that such competition is not merely an obstacle but a necessary ingredient for achieving optimal outcomes. In this work, we design a routing mechanism that embraces competition and converges to an optimal assignment, starting from the classical Pigou network as a foundational case.",
    "source": "arXiv"
  },
  {
    "title": "Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction",
    "title_es": "Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction",
    "url": "https://arxiv.org/abs/2508.07146",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07146v1 Announce Type: new \nAbstract: Predicting pedestrian motion trajectories is critical for the path planning and motion control of autonomous vehicles. Recent diffusion-based models have shown promising results in capturing the inherent stochasticity of pedestrian behavior for trajectory prediction. However, the absence of explicit semantic modelling of pedestrian intent in many diffusion-based methods may result in misinterpreted behaviors and reduced prediction accuracy. To address the above challenges, we propose a diffusion-based pedestrian trajectory prediction framework that incorporates both short-term and long-term motion intentions. Short-term intent is modelled using a residual polar representation, which decouples direction and magnitude to capture fine-grained local motion patterns. Long-term intent is estimated through a learnable, token-based endpoint predictor that generates multiple candidate goals with associated probabilities, enabling multimodal and context-aware intention modelling. Furthermore, we enhance the diffusion process by incorporating adaptive guidance and a residual noise predictor that dynamically refines denoising accuracy. The proposed framework is evaluated on the widely used ETH, UCY, and SDD benchmarks, demonstrating competitive results against state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "Maximizing Social Welfare with Side Payments",
    "title_es": "Maximizing Social Welfare with Side Payments",
    "url": "https://arxiv.org/abs/2508.07147",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07147v1 Announce Type: new \nAbstract: We examine normal-form games in which players may \\emph{pre-commit} to outcome-contingent transfers before choosing their actions. In the one-shot version of this model, Jackson and Wilkie showed that side contracting can backfire: even a game with a Pareto-optimal Nash equilibrium can devolve into inefficient equilibria once unbounded, simultaneous commitments are allowed. The root cause is a prisoner's dilemma effect, where each player can exploit her commitment power to reshape the equilibrium in her favor, harming overall welfare.\n  To circumvent this problem we introduce a \\emph{staged-commitment} protocol. Players may pledge transfers only in small, capped increments over multiple rounds, and the phase continues only with unanimous consent. We prove that, starting from any finite game $\\Gamma$ with a non-degenerate Nash equilibrium $\\vec{\\sigma}$, this protocol implements every welfare-maximizing payoff profile that \\emph{strictly} Pareto-improves $\\vec{\\sigma}$. Thus, gradual and bounded commitments restore the full efficiency potential of side payments while avoiding the inefficiencies identified by Jackson and Wilkie.",
    "source": "arXiv"
  },
  {
    "title": "SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models",
    "title_es": "SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models",
    "url": "https://arxiv.org/abs/2508.07149",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07149v1 Announce Type: new \nAbstract: Sketching is a uniquely human tool for expressing ideas and creativity. The animation of sketches infuses life into these static drawings, opening a new dimension for designers. Animating sketches is a time-consuming process that demands professional skills and extensive experience, often proving daunting for amateurs. In this paper, we propose a novel sketch animation model SketchAnimator, which enables adding creative motion to a given sketch, like \"a jumping car''. Namely, given an input sketch and a reference video, we divide the sketch animation into three stages: Appearance Learning, Motion Learning and Video Prior Distillation. In stages 1 and 2, we utilize LoRA to integrate sketch appearance information and motion dynamics from the reference video into the pre-trained T2V model. In the third stage, we utilize Score Distillation Sampling (SDS) to update the parameters of the Bezier curves in each sketch frame according to the acquired motion information. Consequently, our model produces a sketch video that not only retains the original appearance of the sketch but also mirrors the dynamic movements of the reference video. We compare our method with alternative approaches and demonstrate that it generates the desired sketch video under the challenge of one-shot motion customization.",
    "source": "arXiv"
  },
  {
    "title": "Inversion of Arctic dual-channel sound speed profile based on random airgun signal",
    "title_es": "Inversion of Arctic dual-channel sound speed profile based on random airgun signal",
    "url": "https://arxiv.org/abs/2508.07152",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07152v1 Announce Type: new \nAbstract: For the unique dual-channel sound speed profiles of the Canadian Basin and the Chukchi Plateau in the Arctic, based on the propagation characteristics of refracted normal modes under dual-channel sound speed profiles, an inversion method using refracted normal modes for dual-channel sound speed profiles is proposed. This method proposes a dual-parameter representation method for dual-channel sound speed profiles, tailored to the characteristics of dual-channel sound speed profiles. A dispersion structure extraction method is proposed for the dispersion structure characteristics of refracted normal modes under dual-channel sound speed profiles. Combining the parameter representation method of sound speed profiles and the dispersion structure extraction method, an inversion method for dual-channel sound speed profiles is proposed. For the common horizontal variation of sound speed profiles in long-distance acoustic propagation, a method for inverting horizontally varying dual-channel sound speed profiles is proposed. Finally, this article verifies the effectiveness of the dual-channel sound speed profile inversion method using the Arctic low-frequency long-range acoustic propagation experiment. Compared with previous sound speed profile inversion methods, the method proposed in this article has the advantages of fewer inversion parameters and faster inversion speed. It can be implemented using only a single hydrophone passively receiving random air gun signals, and it also solves the inversion problem of horizontal variation of sound speed profiles. It has significant advantages such as low cost, easy deployment, and fast computation speed.",
    "source": "arXiv"
  },
  {
    "title": "Acoustic source depth estimation method based on a single hydrophone in Arctic underwater",
    "title_es": "Acoustic source depth estimation method based on a single hydrophone in Arctic underwater",
    "url": "https://arxiv.org/abs/2508.07157",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07157v1 Announce Type: new \nAbstract: Based on the normal mode and ray theory, this article discusses the characteristics of surface sound source and reception at the surface layer, and explores depth estimation methods based on normal modes and rays, and proposes a depth estimation method based on the upper limit of modal frequency. Data verification is conducted to discuss the applicability and limitations of different methods. For the surface refracted normal mode waveguide, modes can be separated through warping transformation. Based on the characteristics of normal mode amplitude variation with frequency and number, the sound source depth can be estimated by matching amplitude information. Based on the spatial variation characteristics of eigenfunctions with frequency, a sound source depth estimation method matching the cutoff frequency of normal modes is proposed. For the deep Arctic sea, the sound ray arrival structure at the receiving end is obtained through the analysis of deep inversion sound ray trajectories, and the sound source depth can be estimated by matching the time difference of ray arrivals. Experimental data is used to verify the sound field patterns and the effectiveness of the sound source depth estimation method.",
    "source": "arXiv"
  },
  {
    "title": "CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion",
    "title_es": "CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion",
    "url": "https://arxiv.org/abs/2508.07162",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07162v1 Announce Type: new \nAbstract: 3D human-object interaction (HOI) anticipation aims to predict the future motion of humans and their manipulated objects, conditioned on the historical context. Generally, the articulated humans and rigid objects exhibit different motion patterns, due to their distinct intrinsic physical properties. However, this distinction is ignored by most of the existing works, which intend to capture the dynamics of both humans and objects within a single prediction model. In this work, we propose a novel contact-consistent decoupled diffusion framework CoopDiff, which employs two distinct branches to decouple human and object motion modeling, with the human-object contact points as shared anchors to bridge the motion generation across branches. The human dynamics branch is aimed to predict highly structured human motion, while the object dynamics branch focuses on the object motion with rigid translations and rotations. These two branches are bridged by a series of shared contact points with consistency constraint for coherent human-object motion prediction. To further enhance human-object consistency and prediction reliability, we propose a human-driven interaction module to guide object motion modeling. Extensive experiments on the BEHAVE and Human-object Interaction datasets demonstrate that our CoopDiff outperforms state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey",
    "title_es": "Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey",
    "url": "https://arxiv.org/abs/2508.07163",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07163v1 Announce Type: new \nAbstract: Neurosymbolic AI combines neural network adaptability with symbolic reasoning, promising an approach to address the complex regulatory, operational, and safety challenges in Advanced Air Mobility (AAM). This survey reviews its applications across key AAM domains such as demand forecasting, aircraft design, and real-time air traffic management. Our analysis reveals a fragmented research landscape where methodologies, including Neurosymbolic Reinforcement Learning, have shown potential for dynamic optimization but still face hurdles in scalability, robustness, and compliance with aviation standards. We classify current advancements, present relevant case studies, and outline future research directions aimed at integrating these approaches into reliable, transparent AAM systems. By linking advanced AI techniques with AAM's operational demands, this work provides a concise roadmap for researchers and practitioners developing next-generation air mobility solutions.",
    "source": "arXiv"
  },
  {
    "title": "Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications",
    "title_es": "Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications",
    "url": "https://arxiv.org/abs/2508.07165",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07165v1 Announce Type: new \nAbstract: Multi-sequence Magnetic Resonance Imaging (MRI) offers remarkable versatility, enabling the distinct visualization of different tissue types. Nevertheless, the inherent heterogeneity among MRI sequences poses significant challenges to the generalization capability of deep learning models. These challenges undermine model performance when faced with varying acquisition parameters, thereby severely restricting their clinical utility. In this study, we present PRISM, a foundation model PRe-trained with large-scale multI-Sequence MRI. We collected a total of 64 datasets from both public and private sources, encompassing a wide range of whole-body anatomical structures, with scans spanning diverse MRI sequences. Among them, 336,476 volumetric MRI scans from 34 datasets (8 public and 26 private) were curated to construct the largest multi-organ multi-sequence MRI pretraining corpus to date. We propose a novel pretraining paradigm that disentangles anatomically invariant features from sequence-specific variations in MRI, while preserving high-level semantic representations. We established a benchmark comprising 44 downstream tasks, including disease diagnosis, image segmentation, registration, progression prediction, and report generation. These tasks were evaluated on 32 public datasets and 5 private cohorts. PRISM consistently outperformed both non-pretrained models and existing foundation models, achieving first-rank results in 39 out of 44 downstream benchmarks with statistical significance improvements. These results underscore its ability to learn robust and generalizable representations across unseen data acquired under diverse MRI protocols. PRISM provides a scalable framework for multi-sequence MRI analysis, thereby enhancing the translational potential of AI in radiology. It delivers consistent performance across diverse imaging protocols, reinforcing its clinical applicability.",
    "source": "arXiv"
  },
  {
    "title": "From Noise to Knowledge: Interactive Summaries for Developer Alerts",
    "title_es": "From Noise to Knowledge: Interactive Summaries for Developer Alerts",
    "url": "https://arxiv.org/abs/2508.07169",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07169v1 Announce Type: new \nAbstract: Programmers using bug-finding tools often review their reported warnings one by one. Based on the insight that identifying recurring themes and relationships can enhance the cognitive process of sensemaking, we propose CLARITY, which supports interpreting tool-generated warnings through interactive inquiry. CLARITY derives summary rules for custom grouping of related warnings with active feedback. As users mark warnings as interesting or uninteresting, CLARITY's rule inference algorithm surfaces common symptoms, highlighting structural similarities in containment, subtyping, invoked methods, accessed fields, and expressions.\n  We demonstrate CLARITY on Infer and SpotBugs warnings across two mature Java projects. In a within-subject user study with 14 participants, users articulated root causes for similar uninteresting warnings faster and with more confidence using CLARITY. We observed significant individual variation in desired grouping, reinforcing the need for customizable sensemaking. Simulation shows that with rule-level feedback, only 11.8 interactions are needed on average to align all inferred rules with a simulated user's labels (vs. 17.8 without). Our evaluation suggests that CLARITY's active learning-based summarization enhances interactive warning sensemaking.",
    "source": "arXiv"
  },
  {
    "title": "Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection",
    "title_es": "Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection",
    "url": "https://arxiv.org/abs/2508.07170",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07170v1 Announce Type: new \nAbstract: In the domain of computer vision, multi-scale feature extraction is vital for tasks such as salient object detection. However, achieving this capability in lightweight networks remains challenging due to the trade-off between efficiency and performance. This paper proposes a novel lightweight multi-scale feature extraction layer, termed the LMF layer, which employs depthwise separable dilated convolutions in a fully connected structure. By integrating multiple LMF layers, we develop LMFNet, a lightweight network tailored for salient object detection. Our approach significantly reduces the number of parameters while maintaining competitive performance. Here, we show that LMFNet achieves state-of-the-art or comparable results on five benchmark datasets with only 0.81M parameters, outperforming several traditional and lightweight models in terms of both efficiency and accuracy. Our work not only addresses the challenge of multi-scale learning in lightweight networks but also demonstrates the potential for broader applications in image processing tasks. The related code files are available at https://github.com/Shi-Yun-peng/LMFNet",
    "source": "arXiv"
  },
  {
    "title": "EventRR: Event Referential Reasoning for Referring Video Object Segmentation",
    "title_es": "EventRR: Event Referential Reasoning for Referring Video Object Segmentation",
    "url": "https://arxiv.org/abs/2508.07171",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07171v1 Announce Type: new \nAbstract: Referring Video Object Segmentation (RVOS) aims to segment out the object in a video referred by an expression. Current RVOS methods view referring expressions as unstructured sequences, neglecting their crucial semantic structure essential for referent reasoning. Besides, in contrast to image-referring expressions whose semantics focus only on object attributes and object-object relations, video-referring expressions also encompass event attributes and event-event temporal relations. This complexity challenges traditional structured reasoning image approaches. In this paper, we propose the Event Referential Reasoning (EventRR) framework. EventRR decouples RVOS into object summarization part and referent reasoning part. The summarization phase begins by summarizing each frame into a set of bottleneck tokens, which are then efficiently aggregated in the video-level summarization step to exchange the global cross-modal temporal context. For reasoning part, EventRR extracts semantic eventful structure of a video-referring expression into highly expressive Referential Event Graph (REG), which is a single-rooted directed acyclic graph. Guided by topological traversal of REG, we propose Temporal Concept-Role Reasoning (TCRR) to accumulate the referring score of each temporal query from REG leaf nodes to root node. Each reasoning step can be interpreted as a question-answer pair derived from the concept-role relations in REG. Extensive experiments across four widely recognized benchmark datasets, show that EventRR quantitatively and qualitatively outperforms state-of-the-art RVOS methods. Code is available at https://github.com/bio-mlhui/EventRR",
    "source": "arXiv"
  },
  {
    "title": "Gradient Surgery for Safe LLM Fine-Tuning",
    "title_es": "Gradient Surgery for Safe LLM Fine-Tuning",
    "url": "https://arxiv.org/abs/2508.07172",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07172v1 Announce Type: new \nAbstract: Fine-tuning-as-a-Service introduces a critical vulnerability where a few malicious examples mixed into the user's fine-tuning dataset can compromise the safety alignment of Large Language Models (LLMs). While a recognized paradigm frames safe fine-tuning as a multi-objective optimization problem balancing user task performance with safety alignment, we find existing solutions are critically sensitive to the harmful ratio, with defenses degrading sharply as harmful ratio increases. We diagnose that this failure stems from conflicting gradients, where the user-task update directly undermines the safety objective. To resolve this, we propose SafeGrad, a novel method that employs gradient surgery. When a conflict is detected, SafeGrad nullifies the harmful component of the user-task gradient by projecting it onto the orthogonal plane of the alignment gradient, allowing the model to learn the user's task without sacrificing safety. To further enhance robustness and data efficiency, we employ a KL-divergence alignment loss that learns the rich, distributional safety profile of the well-aligned foundation model. Extensive experiments show that SafeGrad provides state-of-the-art defense across various LLMs and datasets, maintaining robust safety even at high harmful ratios without compromising task fidelity.",
    "source": "arXiv"
  },
  {
    "title": "Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models",
    "title_es": "Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models",
    "url": "https://arxiv.org/abs/2508.07173",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07173v1 Announce Type: new \nAbstract: The rise of Omni-modal Large Language Models (OLLMs), which integrate visual and auditory processing with text, necessitates robust safety evaluations to mitigate harmful outputs. However, no dedicated benchmarks currently exist for OLLMs, and prior benchmarks designed for other LLMs lack the ability to assess safety performance under audio-visual joint inputs or cross-modal safety consistency. To fill this gap, we introduce Omni-SafetyBench, the first comprehensive parallel benchmark for OLLM safety evaluation, featuring 24 modality combinations and variations with 972 samples each, including dedicated audio-visual harm cases. Considering OLLMs' comprehension challenges with complex omni-modal inputs and the need for cross-modal consistency evaluation, we propose tailored metrics: a Safety-score based on conditional Attack Success Rate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and a Cross-Modal Safety Consistency Score (CMSC-score) to measure consistency across modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals critical vulnerabilities: (1) no model excels in both overall safety and consistency, with only 3 models achieving over 0.6 in both metrics and top performer scoring around 0.8; (2) safety defenses weaken with complex inputs, especially audio-visual joints; (3) severe weaknesses persist, with some models scoring as low as 0.14 on specific modalities. Our benchmark and metrics highlight urgent needs for enhanced OLLM safety, providing a foundation for future improvements.",
    "source": "arXiv"
  },
  {
    "title": "On the fault diameter and wide diameter of the exchanged 3-ary $n$-cube",
    "title_es": "On the fault diameter and wide diameter of the exchanged 3-ary $n$-cube",
    "url": "https://arxiv.org/abs/2508.07174",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07174v1 Announce Type: new \nAbstract: Fault diameter and wide diameter are two critical parameters for evaluating communication performance in interconnection networks. They measure the fault tolerance and transmission efficiency of networks. The exchanged 3-ary $n$-cube is a recently proposed variant of the hypercube, denoted by $E3C(r, s, t)$. In this work, we obtain that the $(2r + 1)$-fault diameter and $(2r + 2)$-wide diameter of $E3C(r, s, t)$ are bounded between $n + 3$ and $n + 5$ for $1 \\leq r \\leq s \\leq t$.",
    "source": "arXiv"
  },
  {
    "title": "Computational investigation of crack-tip fields in a compressed nonlinear strain-limiting material",
    "title_es": "Computational investigation of crack-tip fields in a compressed nonlinear strain-limiting material",
    "url": "https://arxiv.org/abs/2508.07175",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07175v1 Announce Type: new \nAbstract: A finite element framework is presented for the analysis of crack-tip phenomena in an elastic material containing a single edge crack under compressive loading. The mechanical response of the material is modeled by a nonlinear constitutive relationship that algebraically relates stress to linearized strain. This approach serves to mitigate non-physical strain singularities and ensures that the crack-tip strains don't grow, unlike singular stresses. A significant advancement is thus achieved in the formulation of boundary value problems (BVPs) for such complex scenarios. The governing equilibrium equation, derived from the balance of linear momentum and the nonlinear constitutive model, is formulated as a second-order, vector-valued, quasilinear elliptic BVP. A classical traction-free boundary condition is imposed on the crack face. The problem is solved using a robust numerical scheme in which a Picard-type linearization is combined with a continuous Galerkin finite element method for the discretization. Analyses are performed for both an isotropic and a transversely isotropic elastic solid containing a crack subjected to compressive loads. The primary crack-tip variables**-stress, strain, and strain energy density-**are examined in detail. It is demonstrated that while high concentrations of compressive stress and strain energy density are observed at the crack tip, the growth of strain is substantially lower than that of stress. These findings are shown to be consistent with the predictions of linear elastic fracture mechanics, but a more physically meaningful representation of the crack-tip field is provided by the nonlinear approach. A rigorous basis is thus established for investigating fundamental processes like crack propagation and damage in anisotropic, strain-limiting solids under various loading conditions, including compression.",
    "source": "arXiv"
  },
  {
    "title": "Noise-Robust Sound Event Detection and Counting via Language-Queried Sound Separation",
    "title_es": "Noise-Robust Sound Event Detection and Counting via Language-Queried Sound Separation",
    "url": "https://arxiv.org/abs/2508.07176",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07176v1 Announce Type: new \nAbstract: Most sound event detection (SED) systems perform well on clean datasets but degrade significantly in noisy environments. Language-queried audio source separation (LASS) models show promise for robust SED by separating target events; existing methods require elaborate multi-stage training and lack explicit guidance for target events. To address these challenges, we introduce event appearance detection (EAD), a counting-based approach that counts event occurrences at both the clip and frame levels. Based on EAD, we propose a co-training-based multi-task learning framework for EAD and SED to enhance SED's performance in noisy environments. First, SED struggles to learn the same patterns as EAD. Then, a task-based constraint is designed to improve prediction consistency between SED and EAD. This framework provides more reliable clip-level predictions for LASS models and strengthens timestamp detection capability. Experiments on DESED and WildDESED datasets demonstrate better performance compared to existing methods, with advantages becoming more pronounced at higher noise levels.",
    "source": "arXiv"
  },
  {
    "title": "An Analogy of Frequency Droop Control for Grid-forming Sources",
    "title_es": "An Analogy of Frequency Droop Control for Grid-forming Sources",
    "url": "https://arxiv.org/abs/2508.07177",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07177v1 Announce Type: new \nAbstract: In this paper, we present an analogy for a power system dominated by grid-forming (GFM) sources that proves to be a powerful visualization tool for analyses of power flow, frequency regulation, and power dispatch. Frequency droop characteristics of a typical GFM source are exactly reflected by an ordinary model of water vessels. The frequency is represented by visible water levels while the droop slope is reified by the vessel sizes. This proposed analogy allows us to use the intuitive water-flow phenomenon to explain the abstract power-flow problems. The grid integration of renewables via GFM inverters is interestingly simulated by a vessel connected to an infinite water tank. This paper also provides a means for demonstrating issues to audiences with little or no background in power systems. Finally, the proposal is verified by simulation results.",
    "source": "arXiv"
  },
  {
    "title": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback",
    "title_es": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback",
    "url": "https://arxiv.org/abs/2508.07178",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07178v1 Announce Type: new \nAbstract: Accurate personalized headline generation hinges on precisely capturing user interests from historical behaviors. However, existing methods neglect personalized-irrelevant click noise in entire historical clickstreams, which may lead to hallucinated headlines that deviate from genuine user preferences. In this paper, we reveal the detrimental impact of click noise on personalized generation quality through rigorous analysis in both user and news dimensions. Based on these insights, we propose a novel Personalized Headline Generation framework via Denoising Fake Interests from Implicit Feedback (PHG-DIF). PHG-DIF first employs dual-stage filtering to effectively remove clickstream noise, identified by short dwell times and abnormal click bursts, and then leverages multi-level temporal fusion to dynamically model users' evolving and multi-faceted interests for precise profiling. Moreover, we release DT-PENS, a new benchmark dataset comprising the click behavior of 1,000 carefully curated users and nearly 10,000 annotated personalized headlines with historical dwell time annotations. Extensive experiments demonstrate that PHG-DIF substantially mitigates the adverse effects of click noise and significantly improves headline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our framework implementation and dataset are available at https://github.com/liukejin-up/PHG-DIF.",
    "source": "arXiv"
  },
  {
    "title": "Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks",
    "title_es": "Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks",
    "url": "https://arxiv.org/abs/2508.07179",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07179v1 Announce Type: new \nAbstract: Enterprise data pipelines, characterized by complex transformations across multiple programming languages, often cause a semantic disconnect between original metadata and downstream data. This \"semantic drift\" compromises data reproducibility and governance, and impairs the utility of services like retrieval-augmented generation (RAG) and text-to-SQL systems. To address this, a novel framework is proposed for the automated extraction of fine-grained schema lineage from multilingual enterprise pipeline scripts. This method identifies four key components: source schemas, source tables, transformation logic, and aggregation operations, creating a standardized representation of data transformations. For the rigorous evaluation of lineage quality, this paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that assesses both structural correctness and semantic fidelity. A new benchmark is also presented, comprising 1,700 manually annotated lineages from real-world industrial scripts. Experiments were conducted with 12 language models, from 1.3B to 32B small language models (SLMs) to large language models (LLMs) like GPT-4o and GPT-4.1. The results demonstrate that the performance of schema lineage extraction scales with model size and the sophistication of prompting techniques. Specially, a 32B open-source model, using a single reasoning trace, can achieve performance comparable to the GPT series under standard prompting. This finding suggests a scalable and economical approach for deploying schema-aware agents in practical applications.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes",
    "title_es": "Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes",
    "url": "https://arxiv.org/abs/2508.07180",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07180v1 Announce Type: new \nAbstract: As large language models LLMs) become increasingly integrated into software development workflows, rigorously evaluating their performance on complex, real-world code generation tasks has become essential. However, existing benchmarks often suffer from data contamination and limited test rigor, constraining their ability to reveal model failures effectively. To address these, we present CODE2BENCH, a end-to-end pipeline for dynamically constructing robust and contamination-resistant benchmarks from real-world GitHub repositories. Specifically, CODE2BENCH introduces three key innovations: (1) Automated Dynamism, achieved through periodic ingestion of recent code to minimize training data contamination; (2) Scope Graph-based dependency analysis, which enables structured classification of functions into benchmark instances with controlled dependency levels (distinguishing between Self-Contained (SC) tasks for cross-language evaluation and Weakly Self-Contained (WSC) tasks involving permitted library usage); and (3) Property-Based Testing (PBT) for the automated synthesis of rigorous test suites to enable thorough functional verification. Using this pipeline, we construct CODE2BENCH-2505, the first benchmark derived from 880 recent Python projects spanning diverse domains, comprising 1,163 code generation tasks with 100% average branch coverage on ground-truth implementations. Extensive evaluation of 16 LLMs using CODE2BENCH-2505 reveals that models consistently struggle with SC tasks requiring complex, non-standard logic and cross-language transfer, while showing relatively stronger performance on WSC tasks in Python. Our work introduces a contamination-resistant, language-agnostic methodology for dynamic benchmark construction, offering a principled foundation for the comprehensive and realistic evaluation of LLMs on real-world software development tasks.",
    "source": "arXiv"
  },
  {
    "title": "3D Gaussian Representations with Motion Trajectory Field for Dynamic Scene Reconstruction",
    "title_es": "3D Gaussian Representations with Motion Trajectory Field for Dynamic Scene Reconstruction",
    "url": "https://arxiv.org/abs/2508.07182",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07182v1 Announce Type: new \nAbstract: This paper addresses the challenge of novel-view synthesis and motion reconstruction of dynamic scenes from monocular video, which is critical for many robotic applications. Although Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have demonstrated remarkable success in rendering static scenes, extending them to reconstruct dynamic scenes remains challenging. In this work, we introduce a novel approach that combines 3DGS with a motion trajectory field, enabling precise handling of complex object motions and achieving physically plausible motion trajectories. By decoupling dynamic objects from static background, our method compactly optimizes the motion trajectory field. The approach incorporates time-invariant motion coefficients and shared motion trajectory bases to capture intricate motion patterns while minimizing optimization complexity. Extensive experiments demonstrate that our approach achieves state-of-the-art results in both novel-view synthesis and motion trajectory recovery from monocular video, advancing the capabilities of dynamic scene reconstruction.",
    "source": "arXiv"
  },
  {
    "title": "Explainability-in-Action: Enabling Expressive Manipulation and Tacit Understanding by Bending Diffusion Models in ComfyUI",
    "title_es": "Explainability-in-Action: Enabling Expressive Manipulation and Tacit Understanding by Bending Diffusion Models in ComfyUI",
    "url": "https://arxiv.org/abs/2508.07183",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07183v1 Announce Type: new \nAbstract: Explainable AI (XAI) in creative contexts can go beyond transparency to support artistic engagement, modifiability, and sustained practice. While curated datasets and training human-scale models can offer artists greater agency and control, large-scale generative models like text-to-image diffusion systems often obscure these possibilities. We suggest that even large models can be treated as creative materials if their internal structure is exposed and manipulable. We propose a craft-based approach to explainability rooted in long-term, hands-on engagement akin to Sch\\\"on's \"reflection-in-action\" and demonstrate its application through a model-bending and inspection plugin integrated into the node-based interface of ComfyUI. We demonstrate that by interactively manipulating different parts of a generative model, artists can develop an intuition about how each component influences the output.",
    "source": "arXiv"
  },
  {
    "title": "DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention",
    "title_es": "DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention",
    "url": "https://arxiv.org/abs/2508.07185",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07185v1 Announce Type: new \nAbstract: Large Language Models (LLMs) suffer from a critical limitation: their knowledge is static and quickly becomes outdated. Retraining these massive models is computationally prohibitive, while existing knowledge editing techniques can be slow and may introduce unforeseen side effects. To address this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently integrate real-time knowledge from a dynamic external source. Our approach synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated instantaneously. The core of our framework is a sparse knowledge attention mechanism, which allows the LLM to perform a coarse-to-fine grained search, efficiently identifying and focusing on a small, highly relevant subset of facts from the vast KG. This mechanism avoids the high computational cost of dense attention over the entire knowledge base and mitigates noise from irrelevant information. We demonstrate through extensive experiments on time-sensitive question-answering tasks that DySK-Attn significantly outperforms strong baselines, including standard Retrieval-Augmented Generation (RAG) and model editing techniques, in both factual accuracy for updated knowledge and computational efficiency. Our framework offers a scalable and effective solution for building LLMs that can stay current with the ever-changing world.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables",
    "title_es": "Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables",
    "url": "https://arxiv.org/abs/2508.07186",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07186v1 Announce Type: new \nAbstract: We propose a novel framework for summarizing structured enterprise data across multiple dimensions using large language model (LLM)-based agents. Traditional table-to-text models often lack the capacity to reason across hierarchical structures and context-aware deltas, which are essential in business reporting tasks. Our method introduces a multi-agent pipeline that extracts, analyzes, and summarizes multi-dimensional data using agents for slicing, variance detection, context construction, and LLM-based generation. Our results show that the proposed framework outperforms traditional approaches, achieving 83\\% faithfulness to underlying data, superior coverage of significant changes, and high relevance scores (4.4/5) for decision-critical insights. The improvements are especially pronounced in categories involving subtle trade-offs, such as increased revenue due to price changes amid declining unit volumes, which competing methods either overlook or address with limited specificity. We evaluate the framework on Kaggle datasets and demonstrate significant improvements in faithfulness, relevance, and insight quality over baseline table summarization approaches.",
    "source": "arXiv"
  },
  {
    "title": "Understanding NFTs from EIP Standards",
    "title_es": "Understanding NFTs from EIP Standards",
    "url": "https://arxiv.org/abs/2508.07190",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07190v1 Announce Type: new \nAbstract: We argue that the technical foundations of non-fungible tokens (NFTs) remain inadequately understood. Prior research has focused on market dynamics, user behavior, and isolated security incidents, yet systematic analysis of the standards underpinning NFT functionality is largely absent.\n  We present the first study of NFTs through the lens of Ethereum Improvement Proposals (EIPs). We conduct a large-scale empirical analysis of 191 NFT-related EIPs and 10K+ Ethereum Magicians discussions (as of July, 2025). We integrate multi-dimensional analyses including the automated parsing of Solidity interfaces, graph-based modeling of inheritance structures, contributor profiling, and mining of community discussion data. We distinguish foundational from emerging standards, expose poor cross-version interoperability, and show that growing functional complexity heightens security risks.",
    "source": "arXiv"
  },
  {
    "title": "FlashMP: Fast Discrete Transform-Based Solver for Preconditioning Maxwell's Equations on GPUs",
    "title_es": "FlashMP: Fast Discrete Transform-Based Solver for Preconditioning Maxwell's Equations on GPUs",
    "url": "https://arxiv.org/abs/2508.07193",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07193v1 Announce Type: new \nAbstract: Efficiently solving large-scale linear systems is a critical challenge in electromagnetic simulations, particularly when using the Crank-Nicolson Finite-Difference Time-Domain (CN-FDTD) method. Existing iterative solvers are commonly employed to handle the resulting sparse systems but suffer from slow convergence due to the ill-conditioned nature of the double-curl operator. Approximate preconditioners, like Successive Over-Relaxation (SOR) and Incomplete LU decomposition (ILU), provide insufficient convergence, while direct solvers are impractical due to excessive memory requirements. To address this, we propose FlashMP, a novel preconditioning system that designs a subdomain exact solver based on discrete transforms. FlashMP provides an efficient GPU implementation that achieves multi-GPU scalability through domain decomposition. Evaluations on AMD MI60 GPU clusters (up to 1000 GPUs) show that FlashMP reduces iteration counts by up to 16x and achieves speedups of 2.5x to 4.9x compared to baseline implementations in state-of-the-art libraries such as Hypre. Weak scalability tests show parallel efficiencies up to 84.1%.",
    "source": "arXiv"
  },
  {
    "title": "ProtoScan: Measuring censorship in IPv6",
    "title_es": "ProtoScan: Measuring censorship in IPv6",
    "url": "https://arxiv.org/abs/2508.07194",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07194v1 Announce Type: new \nAbstract: Internet censorship continues to impact billions of people worldwide, and measurement of it remains an important focus of research. However, most Internet censorship measurements have focused solely on the IPv4 Internet infrastructure. Yet, more clients and servers are available over IPv6: According to Google, over a third of their users now have native IPv6 access. Given the slow-but-steady rate of IPv6 adoption, it is important to understand its impact on censorship. In this paper, we measure and analyze how censorship differs over IPv6 compared to the well-studied IPv4 censorship systems in use today. We perform a comprehensive global study of censorship across an array of commonly censored protocols, including HTTP, DNS, and TLS, on both IPv4 and IPv6, and compare the results. We find that there are several differences in how countries censor IPv6 traffic, both in terms of IPv6 resources, and in where and what blocklists or technologies are deployed on IPv6 networks. Many of these differences are not all-or-nothing: we find that most censors have some capacity to block in IPv6, but are less comprehensive or less reliable compared to their IPv4 censorship systems. Our results suggest that IPv6 offers new areas for censorship circumvention researchers to explore, providing potentially new ways to evade censors. As more users gain access to IPv6 addresses and networks, there will be a need for tools that take advantage of IPv6 techniques and infrastructure to bypass censorship.",
    "source": "arXiv"
  },
  {
    "title": "Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment",
    "title_es": "Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment",
    "url": "https://arxiv.org/abs/2508.07195",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07195v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have recently demonstrated impressive capabilities in natural language processing due to their strong generalization and sequence modeling capabilities. However, their direct application to time series forecasting remains challenging due to two fundamental issues: the inherent heterogeneity of temporal patterns and the modality gap between continuous numerical signals and discrete language representations. In this work, we propose TALON, a unified framework that enhances LLM-based forecasting by modeling temporal heterogeneity and enforcing semantic alignment. Specifically, we design a Heterogeneous Temporal Encoder that partitions multivariate time series into structurally coherent segments, enabling localized expert modeling across diverse temporal patterns. To bridge the modality gap, we introduce a Semantic Alignment Module that aligns temporal features with LLM-compatible representations, enabling effective integration of time series into language-based models while eliminating the need for handcrafted prompts during inference. Extensive experiments on seven real-world benchmarks demonstrate that TALON achieves superior performance across all datasets, with average MSE improvements of up to 11\\% over recent state-of-the-art methods. These results underscore the effectiveness of incorporating both pattern-aware and semantic-aware designs when adapting LLMs for time series forecasting. The code is available at: https://github.com/syrGitHub/TALON.",
    "source": "arXiv"
  },
  {
    "title": "Can Smaller Large Language Models Evaluate Research Quality?",
    "title_es": "Can Smaller Large Language Models Evaluate Research Quality?",
    "url": "https://arxiv.org/abs/2508.07196",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07196v1 Announce Type: new \nAbstract: Although both Google Gemini (1.5 Flash) and ChatGPT (4o and 4o-mini) give research quality evaluation scores that correlate positively with expert scores in nearly all fields, and more strongly that citations in most, it is not known whether this is true for smaller Large Language Models (LLMs). In response, this article assesses Google's Gemma-3-27b-it, a downloadable LLM (60Gb). The results for 104,187 articles show that Gemma-3-27b-it scores correlate positively with an expert research quality score proxy for all 34 Units of Assessment (broad fields) from the UK Research Excellence Framework 2021. The Gemma-3-27b-it correlations have 83.8% of the strength of ChatGPT 4o and 94.7% of the strength of ChatGPT 4o-mini correlations. Differently from the two larger LLMs, the Gemma-3-27b-it correlations do not increase substantially when the scores are averaged across five repetitions, its scores tend to be lower, and its reports are relatively uniform in style. Overall, the results show that research quality score estimation can be conducted by offline LLMs, so this capability is not an emergent property of the largest LLMs. Moreover, score improvement through repetition is not a universal feature of LLMs. In conclusion, although the largest LLMs still have the highest research evaluation score estimation capability, smaller ones can also be used for this task, and this can be helpful for cost saving or when secure offline processing is needed.",
    "source": "arXiv"
  },
  {
    "title": "Mind the IP Gap: Measuring the impact of IPv6 on DNS censorship",
    "title_es": "Mind the IP Gap: Measuring the impact of IPv6 on DNS censorship",
    "url": "https://arxiv.org/abs/2508.07197",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07197v1 Announce Type: new \nAbstract: Internet censorship impacts large segments of the Internet, but so far, prior work has focused almost exclusively on performing measurements using IPv4. As the Internet grows, and more users connect, IPv6 is increasingly supported and available to users and servers alike. But despite this steady growth, it remains unclear if the information control systems that implement censorship (firewalls, deep packet inspection, DNS injection, etc) are as effective with IPv6 traffic as they are with IPv4. In this paper, we perform the first global measurement of DNS censorship on the IPv6 Internet. Leveraging a recent technique that allows us to discover IPv6-capable open resolvers (along with their corresponding IPv4 address), we send over 20 million A and AAAA DNS requests to DNS resolvers worldwide, and measure the rate at which they block, at the resolver, network, and country level as well examine the characteristics of blocked domains. We observe that while nearly all censors support blocking IPv6, their policies are inconsistent with and frequently less effective than their IPv4 censorship infrastructure. Our results suggest that supporting IPv6 censorship is not all-or-nothing: many censors support it, but poorly. As a result, these censors may have to expend additional resources to bring IPv6 censorship up to parity with IPv4. In the meantime, this affords censorship circumvention researchers a new opportunity to exploit these differences to evade detection and blocking.",
    "source": "arXiv"
  },
  {
    "title": "TraceLens: Question-Driven Debugging for Taint Flow Understanding",
    "title_es": "TraceLens: Question-Driven Debugging for Taint Flow Understanding",
    "url": "https://arxiv.org/abs/2508.07198",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07198v1 Announce Type: new \nAbstract: Taint analysis is a security analysis technique used to track the flow of potentially dangerous data through an application and its dependent libraries. Investigating why certain unexpected flows appear and why expected flows are missing is an important sensemaking process during end-user taint analysis. Existing taint analysis tools often do not provide this end-user debugging capability, where developers can ask why, why-not, and what-if questions about dataflows and reason about the impact of configuring sources and sinks, and models of 3rd-party libraries that abstract permissible and impermissible data flows. Furthermore, a tree-view or a list-view used in existing taint-analyzer's visualization makes it difficult to reason about the global impact on connectivity between multiple sources and sinks.\n  Inspired by the insight that sensemaking tool-generated results can be significantly improved by a QA inquiry process, we propose TraceLens, a first end-user question-answer style debugging interface for taint analysis. It enables a user to ask why, why-not, and what-if questions to investigate the existence of suspicious flows, the non-existence of expected flows, and the global impact of third-party library models. TraceLens performs speculative what-if analysis, to help a user in debugging how different connectivity assumptions affect overall results. A user study with 12 participants shows that participants using TraceLens achieved 21% higher accuracy on average, compared to CodeQL. They also reported a 45% reduction in mental demand (NASA-TLX) and rated higher confidence in identifying relevant flows using TraceLens.",
    "source": "arXiv"
  },
  {
    "title": "Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection",
    "title_es": "Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection",
    "url": "https://arxiv.org/abs/2508.07201",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07201v1 Announce Type: new \nAbstract: Rumor detection on social media has become increasingly important. Most existing graph-based models presume rumor propagation trees (RPTs) have deep structures and learn sequential stance features along branches. However, through statistical analysis on real-world datasets, we find RPTs exhibit wide structures, with most nodes being shallow 1-level replies. To focus learning on intensive substructures, we propose Rumor Adaptive Graph Contrastive Learning (RAGCL) method with adaptive view augmentation guided by node centralities. We summarize three principles for RPT augmentation: 1) exempt root nodes, 2) retain deep reply nodes, 3) preserve lower-level nodes in deep sections. We employ node dropping, attribute masking and edge dropping with probabilities from centrality-based importance scores to generate views. A graph contrastive objective then learns robust rumor representations. Extensive experiments on four benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods. Our work reveals the wide-structure nature of RPTs and contributes an effective graph contrastive learning approach tailored for rumor detection through principled adaptive augmentation. The proposed principles and augmentation techniques can potentially benefit other applications involving tree-structured graphs.",
    "source": "arXiv"
  },
  {
    "title": "Civil Servants as Builders: Enabling Non-IT Staff to Develop Secure Python and R Tools",
    "title_es": "Civil Servants as Builders: Enabling Non-IT Staff to Develop Secure Python and R Tools",
    "url": "https://arxiv.org/abs/2508.07203",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07203v1 Announce Type: new \nAbstract: Current digital government literature focuses on professional in-house IT teams, specialized digital service teams, vendor-developed systems, or proprietary low-code/no-code tools. Almost no scholarship addresses a growing middle ground: technically skilled civil servants outside formal IT roles who can write real code but lack a sanctioned, secure path to deploy their work. This paper introduces a limits-aware, open-source and replicable platform that enables such public servants to develop, peer review, and deploy small-scale, domain-specific applications within government networks via a sandboxed, auditable workflow. By combining Jupyter Notebooks, preapproved open-source libraries, and lightweight governance, the platform works within institutional constraints such as procurement rules and IT security policies while avoiding vendor lock-in. Unlike low/no-code approaches, it preserves and enhances civil servants' programming skills, keeping them technically competitive with their private-sector peers. This contribution fills a critical gap, offering a replicable model for public-sector skill retention, resilience, and bottom-up digital transformation.",
    "source": "arXiv"
  },
  {
    "title": "Towards Real-World Rumor Detection: Anomaly Detection Framework with Graph Supervised Contrastive Learning",
    "title_es": "Towards Real-World Rumor Detection: Anomaly Detection Framework with Graph Supervised Contrastive Learning",
    "url": "https://arxiv.org/abs/2508.07205",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07205v1 Announce Type: new \nAbstract: Current rumor detection methods based on propagation structure learning predominately treat rumor detection as a class-balanced classification task on limited labeled data. However, real-world social media data exhibits an imbalanced distribution with a minority of rumors among massive regular posts. To address the data scarcity and imbalance issues, we construct two large-scale conversation datasets from Weibo and Twitter and analyze the domain distributions. We find obvious differences between rumor and non-rumor distributions, with non-rumors mostly in entertainment domains while rumors concentrate in news, indicating the conformity of rumor detection to an anomaly detection paradigm. Correspondingly, we propose the Anomaly Detection framework with Graph Supervised Contrastive Learning (AD-GSCL). It heuristically treats unlabeled data as non-rumors and adapts graph contrastive learning for rumor detection. Extensive experiments demonstrate AD-GSCL's superiority under class-balanced, imbalanced, and few-shot conditions. Our findings provide valuable insights for real-world rumor detection featuring imbalanced data distributions.",
    "source": "arXiv"
  },
  {
    "title": "Presburger Functional Synthesis: Complexity and Tractable Normal Forms",
    "title_es": "Presburger Functional Synthesis: Complexity and Tractable Normal Forms",
    "url": "https://arxiv.org/abs/2508.07207",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07207v1 Announce Type: new \nAbstract: Given a relational specification between inputs and outputs as a logic formula, the problem of functional synthesis is to automatically synthesize a function from inputs to outputs satisfying the relation. Recently, a rich line of work has emerged tackling this problem for specifications in different theories, from Boolean to general first-order logic. In this paper, we launch an investigation of this problem for the theory of Presburger Arithmetic, that we call Presburger Functional Synthesis (PFnS). We show that PFnS can be solved in EXPTIME and provide a matching exponential lower bound. This is unlike the case for Boolean functional synthesis (BFnS), where only conditional exponential lower bounds are known. Further, we show that PFnS for one input and one output variable is as hard as BFnS in general. We then identify a special normal form, called PSyNF, for the specification formula that guarantees poly-time and poly-size solvability of PFnS. We prove several properties of PSyNF, including how to check and compile to this form, and conditions under which any other form that guarantees poly-time solvability of PFnS can be compiled in poly-time to PSyNF. Finally, we identify a syntactic normal form that is easier to check but is exponentially less succinct than PSyNF.",
    "source": "arXiv"
  },
  {
    "title": "What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains",
    "title_es": "What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains",
    "url": "https://arxiv.org/abs/2508.07208",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07208v1 Announce Type: new \nAbstract: In-context learning (ICL) is a hallmark capability of transformers, through which trained models learn to adapt to new tasks by leveraging information from the input context. Prior work has shown that ICL emerges in transformers due to the presence of special circuits called induction heads. Given the equivalence between induction heads and conditional k-grams, a recent line of work modeling sequential inputs as Markov processes has revealed the fundamental impact of model depth on its ICL capabilities: while a two-layer transformer can efficiently represent a conditional 1-gram model, its single-layer counterpart cannot solve the task unless it is exponentially large. However, for higher order Markov sources, the best known constructions require at least three layers (each with a single attention head) - leaving open the question: can a two-layer single-head transformer represent any kth-order Markov process? In this paper, we precisely address this and theoretically show that a two-layer transformer with one head per layer can indeed represent any conditional k-gram. Thus, our result provides the tightest known characterization of the interplay between transformer depth and Markov order for ICL. Building on this, we further analyze the learning dynamics of our two-layer construction, focusing on a simplified variant for first-order Markov chains, illustrating how effective in-context representations emerge during training. Together, these results deepen our current understanding of transformer-based ICL and illustrate how even shallow architectures can surprisingly exhibit strong ICL capabilities on structured sequence modeling tasks.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model",
    "title_es": "Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model",
    "url": "https://arxiv.org/abs/2508.07209",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07209v1 Announce Type: new \nAbstract: Pretrained Language Models (PLMs) have excelled in various Natural Language Processing tasks, benefiting from large-scale pretraining and self-attention mechanism's ability to capture long-range dependencies. However, their performance on social media application tasks like rumor detection remains suboptimal. We attribute this to mismatches between pretraining corpora and social texts, inadequate handling of unique social symbols, and pretraining tasks ill-suited for modeling user engagements implicit in propagation structures. To address these issues, we propose a continue pretraining strategy called Post Engagement Prediction (PEP) to infuse information from propagation structures into PLMs. PEP makes models to predict root, branch, and parent relations between posts, capturing interactions of stance and sentiment crucial for rumor detection. We also curate and release large-scale Twitter corpus: TwitterCorpus (269GB text), and two unlabeled claim conversation datasets with propagation structures (UTwitter and UWeibo). Utilizing these resources and PEP strategy, we train a Twitter-tailored PLM called SoLM. Extensive experiments demonstrate PEP significantly boosts rumor detection performance across universal and social media PLMs, even in few-shot scenarios. On benchmark datasets, PEP enhances baseline models by 1.0-3.7\\% accuracy, even enabling it to outperform current state-of-the-art methods on multiple datasets. SoLM alone, without high-level modules, also achieves competitive results, highlighting the strategy's effectiveness in learning discriminative post interaction features.",
    "source": "arXiv"
  },
  {
    "title": "Uncertainty-Aware Semantic Decoding for LLM-Based Sequential Recommendation",
    "title_es": "Uncertainty-Aware Semantic Decoding for LLM-Based Sequential Recommendation",
    "url": "https://arxiv.org/abs/2508.07210",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07210v1 Announce Type: new \nAbstract: Large language models have been widely applied to sequential recommendation tasks, yet during inference, they continue to rely on decoding strategies developed for natural language processing. This creates a mismatch between text-generation objectives and recommendation next item selection objectives. This paper addresses this limitation by proposing an Uncertainty-aware Semantic Decoding (USD) framework that combines logit-based clustering with adaptive scoring to improve next-item predictions. Our approach clusters items with similar logit vectors into semantic equivalence groups, then redistributes probability mass within these clusters and computes entropy across them to control item scoring and sampling temperature during recommendation inference. Experiments on Amazon Product datasets (six domains) gains of 18.5\\% in HR@3, 11.9\\% in NDCG@3, and 10.8\\% in MRR@3 compared to state-of-the-art baselines. Hyperparameter analysis confirms the optimal parameters among various settings, and experiments on H\\&M, and Netflix datasets indicate that the framework can adapt to differing recommendation domains. The experimental results confirm that integrating semantic clustering and uncertainty assessment yields more reliable and accurate recommendations.",
    "source": "arXiv"
  },
  {
    "title": "Similarity Matters: A Novel Depth-guided Network for Image Restoration and A New Dataset",
    "title_es": "Similarity Matters: A Novel Depth-guided Network for Image Restoration and A New Dataset",
    "url": "https://arxiv.org/abs/2508.07211",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07211v1 Announce Type: new \nAbstract: Image restoration has seen substantial progress in recent years. However, existing methods often neglect depth information, which hurts similarity matching, results in attention distractions in shallow depth-of-field (DoF) scenarios, and excessive enhancement of background content in deep DoF settings. To overcome these limitations, we propose a novel Depth-Guided Network (DGN) for image restoration, together with a novel large-scale high-resolution dataset. Specifically, the network consists of two interactive branches: a depth estimation branch that provides structural guidance, and an image restoration branch that performs the core restoration task. In addition, the image restoration branch exploits intra-object similarity through progressive window-based self-attention and captures inter-object similarity via sparse non-local attention. Through joint training, depth features contribute to improved restoration quality, while the enhanced visual features from the restoration branch in turn help refine depth estimation. Notably, we also introduce a new dataset for training and evaluation, consisting of 9,205 high-resolution images from 403 plant species, with diverse depth and texture variations. Extensive experiments show that our method achieves state-of-the-art performance on several standard benchmarks and generalizes well to unseen plant images, demonstrating its effectiveness and robustness.",
    "source": "arXiv"
  },
  {
    "title": "Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling",
    "title_es": "Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling",
    "url": "https://arxiv.org/abs/2508.07214",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07214v1 Announce Type: new \nAbstract: Unsupervised real-world super-resolution (SR) faces critical challenges due to the complex, unknown degradation distributions in practical scenarios. Existing methods struggle to generalize from synthetic low-resolution (LR) and high-resolution (HR) image pairs to real-world data due to a significant domain gap. In this paper, we propose an unsupervised real-world SR method based on rectified flow to effectively capture and model real-world degradation, synthesizing LR-HR training pairs with realistic degradation. Specifically, given unpaired LR and HR images, we propose a novel Rectified Flow Degradation Module (RFDM) that introduces degradation-transformed LR (DT-LR) images as intermediaries. By modeling the degradation trajectory in a continuous and invertible manner, RFDM better captures real-world degradation and enhances the realism of generated LR images. Additionally, we propose a Fourier Prior Guided Degradation Module (FGDM) that leverages structural information embedded in Fourier phase components to ensure more precise modeling of real-world degradation. Finally, the LR images are processed by both FGDM and RFDM, producing final synthetic LR images with real-world degradation. The synthetic LR images are paired with the given HR images to train the off-the-shelf SR networks. Extensive experiments on real-world datasets demonstrate that our method significantly enhances the performance of existing SR approaches in real-world scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization",
    "title_es": "Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization",
    "url": "https://arxiv.org/abs/2508.07216",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07216v1 Announce Type: new \nAbstract: The existing image manipulation localization (IML) models mainly relies on visual cues, but ignores the semantic logical relationships between content features. In fact, the content semantics conveyed by real images often conform to human cognitive laws. However, image manipulation technology usually destroys the internal relationship between content features, thus leaving semantic clues for IML. In this paper, we propose a cognition-inspired multimodal boundary-preserving network (CMB-Net). Specifically, CMB-Net utilizes large language models (LLMs) to analyze manipulated regions within images and generate prompt-based textual information to compensate for the lack of semantic relationships in the visual information. Considering that the erroneous texts induced by hallucination from LLMs will damage the accuracy of IML, we propose an image-text central ambiguity module (ITCAM). It assigns weights to the text features by quantifying the ambiguity between text and image features, thereby ensuring the beneficial impact of textual information. We also propose an image-text interaction module (ITIM) that aligns visual and text features using a correlation matrix for fine-grained interaction. Finally, inspired by invertible neural networks, we propose a restoration edge decoder (RED) that mutually generates input and output features to preserve boundary information in manipulated regions without loss. Extensive experiments show that CMB-Net outperforms most existing IML models.",
    "source": "arXiv"
  },
  {
    "title": "Generic Calibration: Pose Ambiguity/Linear Solution and Parametric-hybrid Pipeline",
    "title_es": "Generic Calibration: Pose Ambiguity/Linear Solution and Parametric-hybrid Pipeline",
    "url": "https://arxiv.org/abs/2508.07217",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07217v1 Announce Type: new \nAbstract: Offline camera calibration techniques typically employ parametric or generic camera models. Selecting parametric models relies heavily on user experience, and an inappropriate camera model can significantly affect calibration accuracy. Meanwhile, generic calibration methods involve complex procedures and cannot provide traditional intrinsic parameters. This paper reveals a pose ambiguity in the pose solutions of generic calibration methods that irreversibly impacts subsequent pose estimation. A linear solver and a nonlinear optimization are proposed to address this ambiguity issue. Then a global optimization hybrid calibration method is introduced to integrate generic and parametric models together, which improves extrinsic parameter accuracy of generic calibration and mitigates overfitting and numerical instability in parametric calibration. Simulation and real-world experimental results demonstrate that the generic-parametric hybrid calibration method consistently excels across various lens types and noise contamination, hopefully serving as a reliable and accurate solution for camera calibration in complex scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Accelerating High-Dimensional Nearest Neighbor Search with Dynamic Query Preference",
    "title_es": "Accelerating High-Dimensional Nearest Neighbor Search with Dynamic Query Preference",
    "url": "https://arxiv.org/abs/2508.07218",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07218v1 Announce Type: new \nAbstract: Approximate Nearest Neighbor Search (ANNS) is a crucial operation in databases and artificial intelligence. Current graph-based ANNS methods, such as HNSW and NSG, have shown remarkable performance but are designed under the assumption of a uniform query distribution. However, in practical scenarios, user preferences and query temporal dynamics lead to some queries being searched for more frequently than others. To fully utilize these characteristics, we propose DQF, a novel Dual-Index Query Framework. This framework comprises a dual-layer index structure and a dynamic search strategy based on a decision tree. The dual-layer index structure comprises a hot index for high-frequency nodes and a full index for the entire dataset, allowing for the separate management of hot and cold queries. Furthermore, we propose a dynamic search strategy that employs a decision tree to adapt to the specific characteristics of each query. The decision tree evaluates whether a query is of the high-frequency type to detect the opportunities for early termination on the dual-layer, avoiding unnecessary searches in the full index. Experimental results on four real-world datasets demonstrate that the Dual-Index Query Framework achieves a significant speedup of 2.0-5.7x over state-of-the-art algorithms while maintaining a 95% recall rate. Importantly, it does not require full index reconstruction when query distributions change, underscoring its efficiency and practicality in dynamic query distribution scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Neural Bridge Processes",
    "title_es": "Neural Bridge Processes",
    "url": "https://arxiv.org/abs/2508.07220",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07220v1 Announce Type: new \nAbstract: Learning stochastic functions from partially observed context-target pairs is a fundamental problem in probabilistic modeling. Traditional models like Gaussian Processes (GPs) face scalability issues with large datasets and assume Gaussianity, limiting their applicability. While Neural Processes (NPs) offer more flexibility, they struggle with capturing complex, multi-modal target distributions. Neural Diffusion Processes (NDPs) enhance expressivity through a learned diffusion process but rely solely on conditional signals in the denoising network, resulting in weak input coupling from an unconditional forward process and semantic mismatch at the diffusion endpoint. In this work, we propose Neural Bridge Processes (NBPs), a novel method for modeling stochastic functions where inputs x act as dynamic anchors for the entire diffusion trajectory. By reformulating the forward kernel to explicitly depend on x, NBP enforces a constrained path that strictly terminates at the supervised target. This approach not only provides stronger gradient signals but also guarantees endpoint coherence. We validate NBPs on synthetic data, EEG signal regression and image regression tasks, achieving substantial improvements over baselines. These results underscore the effectiveness of DDPM-style bridge sampling in enhancing both performance and theoretical consistency for structured prediction tasks.",
    "source": "arXiv"
  },
  {
    "title": "LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference",
    "title_es": "LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference",
    "url": "https://arxiv.org/abs/2508.07221",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07221v1 Announce Type: new \nAbstract: Estimating individualized treatment effects from observational data presents a persistent challenge due to unmeasured confounding and structural bias. Causal Machine Learning (causal ML) methods, such as causal trees and doubly robust estimators, provide tools for estimating conditional average treatment effects. These methods have limited effectiveness in complex real-world environments due to the presence of latent confounders or those described in unstructured formats. Moreover, reliance on domain experts for confounder identification and rule interpretation introduces high annotation cost and scalability concerns. In this work, we proposed Large Language Model-based agents for automated confounder discovery and subgroup analysis that integrate agents into the causal ML pipeline to simulate domain expertise. Our framework systematically performs subgroup identification and confounding structure discovery by leveraging the reasoning capabilities of LLM-based agents, which reduces human dependency while preserving interpretability. Experiments on real-world medical datasets show that our proposed approach enhances treatment effect estimation robustness by narrowing confidence intervals and uncovering unrecognized confounding biases. Our findings suggest that LLM-based agents offer a promising path toward scalable, trustworthy, and semantically aware causal inference.",
    "source": "arXiv"
  },
  {
    "title": "Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation",
    "title_es": "Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation",
    "url": "https://arxiv.org/abs/2508.07223",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07223v1 Announce Type: new \nAbstract: In recent years, there has been growing interest in leveraging the impressive generalization capabilities and reasoning ability of large language models (LLMs) to improve the performance of recommenders. With this operation, recommenders can access and learn the additional world knowledge and reasoning information via LLMs. However, in general, for different users and items, the world knowledge derived from LLMs suffers from issues of hallucination, content redundant, and information homogenization. Directly feeding the generated response embeddings into the recommendation model can lead to unavoidable performance deterioration. To address these challenges, we propose a Knowledge Selection \\& Exploitation Recommendation (KSER) framework, which effectively select and extracts the high-quality knowledge from LLMs. The framework consists of two key components: a knowledge filtering module and a embedding spaces alignment module. In the knowledge filtering module, a Embedding Selection Filter Network (ESFNet) is designed to assign adaptive weights to different knowledge chunks in different knowledge fields. In the space alignment module, an attention-based architecture is proposed to align the semantic embeddings from LLMs with the feature space used to train the recommendation models. In addition, two training strategies--\\textbf{all-parameters training} and \\textbf{extractor-only training}--are proposed to flexibly adapt to different downstream tasks and application scenarios, where the extractor-only training strategy offers a novel perspective on knowledge-augmented recommendation. Experimental results validate the necessity and effectiveness of both the knowledge filtering and alignment modules, and further demonstrate the efficiency and effectiveness of the extractor-only training strategy.",
    "source": "arXiv"
  },
  {
    "title": "EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning",
    "title_es": "EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning",
    "url": "https://arxiv.org/abs/2508.07224",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07224v1 Announce Type: new \nAbstract: We present EDGE, a general-purpose, misconception-aware adaptive learning framework composed of four stages: Evaluate (ability and state estimation), Diagnose (posterior infer-ence of misconceptions), Generate (counterfactual item synthesis), and Exercise (index-based retrieval scheduling). EDGE unifies psychometrics (IRT/Bayesian state space models), cog-nitive diagnostics (misconception discovery from distractor patterns and response latencies), contrastive item generation (minimal perturbations that invalidate learner shortcuts while pre-serving psychometric validity), and principled scheduling (a restless bandit approximation to spaced retrieval). We formalize a composite readiness metric, EdgeScore, prove its monotonicity and Lipschitz continuity, and derive an index policy that is near-optimal under mild assumptions on forgetting and learning gains. We further establish conditions under which counterfactual items provably reduce the posterior probability of a targeted misconception faster than standard practice. The paper focuses on theory and implementable pseudocode; empirical study is left to future work.",
    "source": "arXiv"
  },
  {
    "title": "HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation",
    "title_es": "HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation",
    "url": "https://arxiv.org/abs/2508.07225",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07225v1 Announce Type: new \nAbstract: Spatial transcriptomics (ST) reveals spatial heterogeneity of gene expression, yet its resolution is limited by current platforms. Recent methods enhance resolution via H&E-stained histology, but three major challenges persist: (1) isolating expression-relevant features from visually complex H&E images; (2) achieving spatially precise multimodal alignment in diffusion-based frameworks; and (3) modeling gene-specific variation across expression channels. We propose HaDM-ST (Histology-assisted Differential Modeling for ST Generation), a high-resolution ST generation framework conditioned on H&E images and low-resolution ST. HaDM-ST includes: (i) a semantic distillation network to extract predictive cues from H&E; (ii) a spatial alignment module enforcing pixel-wise correspondence with low-resolution ST; and (iii) a channel-aware adversarial learner for fine-grained gene-level modeling. Experiments on 200 genes across diverse tissues and species show HaDM-ST consistently outperforms prior methods, enhancing spatial fidelity and gene-level coherence in high-resolution ST predictions.",
    "source": "arXiv"
  },
  {
    "title": "LP-Spec: Leveraging LPDDR PIM for Efficient LLM Mobile Speculative Inference with Architecture-Dataflow Co-Optimization",
    "title_es": "LP-Spec: Leveraging LPDDR PIM for Efficient LLM Mobile Speculative Inference with Architecture-Dataflow Co-Optimization",
    "url": "https://arxiv.org/abs/2508.07227",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07227v1 Announce Type: new \nAbstract: LLM inference on mobile devices faces extraneous challenges due to limited memory bandwidth and computational resources. To address these issues, speculative inference and processing-in-memory (PIM) techniques have been explored at the algorithmic and hardware levels. However, speculative inference results in more compute-intensive GEMM operations, creating new design trade-offs for existing GEMV-accelerated PIM architectures. Furthermore, there exists a significant amount of redundant draft tokens in tree-based speculative inference, necessitating efficient token management schemes to minimize energy consumption. In this work, we present LP-Spec, an architecture-dataflow co-design leveraging hybrid LPDDR5 performance-enhanced PIM architecture with draft token pruning and dynamic workload scheduling to accelerate LLM speculative inference. A near-data memory controller is proposed to enable data reallocation between DRAM and PIM banks. Furthermore, a data allocation unit based on the hardware-aware draft token pruner is developed to minimize energy consumption and fully exploit parallel execution opportunities. Compared to end-to-end LLM inference on other mobile solutions such as mobile NPUs or GEMV-accelerated PIMs, our LP-Spec achieves 13.21x, 7.56x, and 99.87x improvements in performance, energy efficiency, and energy-delay-product (EDP). Compared with prior AttAcc PIM and RTX 3090 GPU, LP-Spec can obtain 12.83x and 415.31x EDP reduction benefits.",
    "source": "arXiv"
  },
  {
    "title": "How Does a Deep Neural Network Look at Lexical Stress?",
    "title_es": "How Does a Deep Neural Network Look at Lexical Stress?",
    "url": "https://arxiv.org/abs/2508.07229",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07229v1 Announce Type: new \nAbstract: Despite their success in speech processing, neural networks often operate as black boxes, prompting the question: what informs their decisions, and how can we interpret them? This work examines this issue in the context of lexical stress. A dataset of English disyllabic words was automatically constructed from read and spontaneous speech. Several Convolutional Neural Network (CNN) architectures were trained to predict stress position from a spectrographic representation of disyllabic words lacking minimal stress pairs (e.g., initial stress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out test data. Layerwise Relevance Propagation (LRP), a technique for CNN interpretability analysis, revealed that predictions for held-out minimal pairs (PROtest vs. proTEST ) were most strongly influenced by information in stressed versus unstressed syllables, particularly the spectral properties of stressed vowels. However, the classifiers also attended to information throughout the word. A feature-specific relevance analysis is proposed, and its results suggest that our best-performing classifier is strongly influenced by the stressed vowel's first and second formants, with some evidence that its pitch and third formant also contribute. These results reveal deep learning's ability to acquire distributed cues to stress from naturally occurring data, extending traditional phonetic work based around highly controlled stimuli.",
    "source": "arXiv"
  },
  {
    "title": "Shaping a Profession, Building a Community: A Practitioner-Led Investigation of Public Interest Technologists in Civil Society",
    "title_es": "Shaping a Profession, Building a Community: A Practitioner-Led Investigation of Public Interest Technologists in Civil Society",
    "url": "https://arxiv.org/abs/2508.07230",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07230v1 Announce Type: new \nAbstract: The label `public interest technology' (PIT) is growing in popularity among those seeking to use `tech for good' - especially among technical practitioners working in civil society and nonprofit organizations. PIT encompasses a broad range of sociotechnical work across professional domains and sectors; however, the trend remains understudied within sociotechnical research. This paper describes a mixed-methods study, designed and conducted by PIT practitioners at the Center for Democracy and Technology, that characterizes technologists within the specific context of civil society, civil rights, and advocacy organizations in North America and Western Europe. We conducted interviews with civil society leaders to investigate how PIT practitioners position the field and themselves, and we held a roundtable discussion bringing diverse voices together to make meaning of this growing phenomenon. Ultimately, we find that PIT remains both defined and plagued by its expansiveness, and that today's civil society public interest technologists see a need for both (a) more robust professionalization infrastructures, including philanthropic attention, and (b) more engaged, coherent community. This study illuminates a nascent intersection of technology and policy on-the-ground that is of growing relevance to critical sociotechnical research on the shifting relationship between computing and society.",
    "source": "arXiv"
  },
  {
    "title": "Landmark Guided Visual Feature Extractor for Visual Speech Recognition with Limited Resource",
    "title_es": "Landmark Guided Visual Feature Extractor for Visual Speech Recognition with Limited Resource",
    "url": "https://arxiv.org/abs/2508.07233",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07233v1 Announce Type: new \nAbstract: Visual speech recognition is a technique to identify spoken content in silent speech videos, which has raised significant attention in recent years. Advancements in data-driven deep learning methods have significantly improved both the speed and accuracy of recognition. However, these deep learning methods can be effected by visual disturbances, such as lightning conditions, skin texture and other user-specific features. Data-driven approaches could reduce the performance degradation caused by these visual disturbances using models pretrained on large-scale datasets. But these methods often require large amounts of training data and computational resources, making them costly. To reduce the influence of user-specific features and enhance performance with limited data, this paper proposed a landmark guided visual feature extractor. Facial landmarks are used as auxiliary information to aid in training the visual feature extractor. A spatio-temporal multi-graph convolutional network is designed to fully exploit the spatial locations and spatio-temporal features of facial landmarks. Additionally, a multi-level lip dynamic fusion framework is introduced to combine the spatio-temporal features of the landmarks with the visual features extracted from the raw video frames. Experimental results show that this approach performs well with limited data and also improves the model's accuracy on unseen speakers.",
    "source": "arXiv"
  },
  {
    "title": "ASM-UNet: Adaptive Scan Mamba Integrating Group Commonalities and Individual Variations for Fine-Grained Segmentation",
    "title_es": "ASM-UNet: Adaptive Scan Mamba Integrating Group Commonalities and Individual Variations for Fine-Grained Segmentation",
    "url": "https://arxiv.org/abs/2508.07237",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07237v1 Announce Type: new \nAbstract: Precise lesion resection depends on accurately identifying fine-grained anatomical structures. While many coarse-grained segmentation (CGS) methods have been successful in large-scale segmentation (e.g., organs), they fall short in clinical scenarios requiring fine-grained segmentation (FGS), which remains challenging due to frequent individual variations in small-scale anatomical structures. Although recent Mamba-based models have advanced medical image segmentation, they often rely on fixed manually-defined scanning orders, which limit their adaptability to individual variations in FGS. To address this, we propose ASM-UNet, a novel Mamba-based architecture for FGS. It introduces adaptive scan scores to dynamically guide the scanning order, generated by combining group-level commonalities and individual-level variations. Experiments on two public datasets (ACDC and Synapse) and a newly proposed challenging biliary tract FGS dataset, namely BTMS, demonstrate that ASM-UNet achieves superior performance in both CGS and FGS tasks. Our code and dataset are available at https://github.com/YqunYang/ASM-UNet.",
    "source": "arXiv"
  },
  {
    "title": "Weighted and unweighted enrichment strategies for solving the Poisson problem with Dirichlet boundary conditions",
    "title_es": "Weighted and unweighted enrichment strategies for solving the Poisson problem with Dirichlet boundary conditions",
    "url": "https://arxiv.org/abs/2508.07238",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07238v1 Announce Type: new \nAbstract: In this paper, we propose weighted and unweighted enrichment strategies to enhance the accuracy of the linear lagrangian finite element for solving the Poisson problem with Dirichlet boundary conditions. We first recall key examples of admissible enrichment functions, specifically designed to overcome the limitations of the linear lagrangian finite element in capturing solution features such as sharp gradients and boundary-layer phenomena. We then introduce two novel three-parameter families of weighted enrichment functions and derive an explicit error bound in $L^2$-norm. Numerical experiments confirm the effectiveness of the proposed approach in improving approximation accuracy, demonstrating its potential for a wide range of applications.",
    "source": "arXiv"
  },
  {
    "title": "PureSample: Neural Materials Learned by Sampling Microgeometry",
    "title_es": "PureSample: Neural Materials Learned by Sampling Microgeometry",
    "url": "https://arxiv.org/abs/2508.07240",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07240v1 Announce Type: new \nAbstract: Traditional physically-based material models rely on analytically derived bidirectional reflectance distribution functions (BRDFs), typically by considering statistics of micro-primitives such as facets, flakes, or spheres, sometimes combined with multi-bounce interactions such as layering and multiple scattering. These derivations are often complex and model-specific, and typically consider a statistical aggregate of a large surface area, ignoring spatial variation. Once an analytic BRDF's evaluation is defined, one still needs to design an importance sampling method for it, and a way to evaluate the pdf of that sampling distribution, requiring further model-specific derivations.\n  We present PureSample: a novel neural BRDF representation that allows learning a material's behavior purely by sampling forward random walks on the microgeometry, which is usually straightforward to implement. Our representation allows for efficient importance sampling, pdf evaluation, and BRDF evaluation, for homogeneous as well as spatially varying materials.\n  We achieve this by two learnable components: first, the sampling distribution is modeled using a flow matching neural network, which allows both importance sampling and pdf evaluation; second, we introduce a view-dependent albedo term, captured by a lightweight neural network, which allows for converting a scalar pdf value to a colored BRDF value for any pair of view and light directions.\n  We demonstrate PureSample on challenging materials, including multi-layered materials, multiple-scattering microfacet materials, and various other microstructures.",
    "source": "arXiv"
  },
  {
    "title": "SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations",
    "title_es": "SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations",
    "url": "https://arxiv.org/abs/2508.07241",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07241v1 Announce Type: new \nAbstract: Most industry scale recommender systems face critical cold start challenges new items lack interaction history, making it difficult to distribute them in a personalized manner. Standard collaborative filtering models underperform due to sparse engagement signals, while content only approaches lack user specific relevance. We propose SocRipple, a novel two stage retrieval framework tailored for coldstart item distribution in social graph based platforms. Stage 1 leverages the creators social connections for targeted initial exposure. Stage 2 builds on early engagement signals and stable user embeddings learned from historical interactions to \"ripple\" outwards via K Nearest Neighbor (KNN) search. Large scale experiments on a major video platform show that SocRipple boosts cold start item distribution by +36% while maintaining user engagement rate on cold start items, effectively balancing new item exposure with personalized recommendations.",
    "source": "arXiv"
  },
  {
    "title": "Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation",
    "title_es": "Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation",
    "url": "https://arxiv.org/abs/2508.07243",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07243v1 Announce Type: new \nAbstract: Heuristic negative sampling enhances recommendation performance by selecting negative samples of varying hardness levels from predefined candidate pools to guide the model toward learning more accurate decision boundaries. However, our empirical and theoretical analyses reveal that unobserved environmental confounders (e.g., exposure or popularity biases) in candidate pools may cause heuristic sampling methods to introduce false hard negatives (FHNS). These misleading samples can encourage the model to learn spurious correlations induced by such confounders, ultimately compromising its generalization ability under distribution shifts. To address this issue, we propose a novel method named Causal Negative Sampling via Diffusion (CNSDiff). By synthesizing negative samples in the latent space via a conditional diffusion process, CNSDiff avoids the bias introduced by predefined candidate pools and thus reduces the likelihood of generating FHNS. Moreover, it incorporates a causal regularization term to explicitly mitigate the influence of environmental confounders during the negative sampling process, leading to robust negatives that promote out-of-distribution (OOD) generalization. Comprehensive experiments under four representative distribution shift scenarios demonstrate that CNSDiff achieves an average improvement of 13.96% across all evaluation metrics compared to state-of-the-art baselines, verifying its effectiveness and robustness in OOD recommendation tasks.",
    "source": "arXiv"
  },
  {
    "title": "Impact of Gaze-Based Interaction and Augmentation on Human-Robot Collaboration in Critical Tasks",
    "title_es": "Impact of Gaze-Based Interaction and Augmentation on Human-Robot Collaboration in Critical Tasks",
    "url": "https://arxiv.org/abs/2508.07244",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07244v1 Announce Type: new \nAbstract: We present a user study analyzing head-gaze-based robot control and foveated visual augmentation in a simulated search-and-rescue task. Results show that foveated augmentation significantly improves task performance, reduces cognitive load by 38%, and shortens task time by over 60%. Head-gaze patterns analysed over both the entire task duration and shorter time segments show that near and far attention capture is essential to better understand user intention in critical scenarios. Our findings highlight the potential of foveation as an augmentation technique and the need to further study gaze measures to leverage them during critical tasks.",
    "source": "arXiv"
  },
  {
    "title": "Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers",
    "title_es": "Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers",
    "url": "https://arxiv.org/abs/2508.07246",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07246v1 Announce Type: new \nAbstract: Image animation has seen significant progress, driven by the powerful generative capabilities of diffusion models. However, maintaining appearance consistency with static input images and mitigating abrupt motion transitions in generated animations remain persistent challenges. While text-to-video (T2V) generation has demonstrated impressive performance with diffusion transformer models, the image animation field still largely relies on U-Net-based diffusion models, which lag behind the latest T2V approaches. Moreover, the quadratic complexity of vanilla self-attention mechanisms in Transformers imposes heavy computational demands, making image animation particularly resource-intensive. To address these issues, we propose MiraMo, a framework designed to enhance efficiency, appearance consistency, and motion smoothness in image animation. Specifically, MiraMo introduces three key elements: (1) A foundational text-to-video architecture replacing vanilla self-attention with efficient linear attention to reduce computational overhead while preserving generation quality; (2) A novel motion residual learning paradigm that focuses on modeling motion dynamics rather than directly predicting frames, improving temporal consistency; and (3) A DCT-based noise refinement strategy during inference to suppress sudden motion artifacts, complemented by a dynamics control module to balance motion smoothness and expressiveness. Extensive experiments against state-of-the-art methods validate the superiority of MiraMo in generating consistent, smooth, and controllable animations with accelerated inference speed. Additionally, we demonstrate the versatility of MiraMo through applications in motion transfer and video editing tasks.",
    "source": "arXiv"
  },
  {
    "title": "Prompt Tuning for Few-Shot Continual Learning Named Entity Recognition",
    "title_es": "Prompt Tuning for Few-Shot Continual Learning Named Entity Recognition",
    "url": "https://arxiv.org/abs/2508.07248",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07248v1 Announce Type: new \nAbstract: Knowledge distillation has been successfully applied to Continual Learning Named Entity Recognition (CLNER) tasks, by using a teacher model trained on old-class data to distill old-class entities present in new-class data as a form of regularization, thereby avoiding catastrophic forgetting. However, in Few-Shot CLNER (FS-CLNER) tasks, the scarcity of new-class entities makes it difficult for the trained model to generalize during inference. More critically, the lack of old-class entity information hinders the distillation of old knowledge, causing the model to fall into what we refer to as the Few-Shot Distillation Dilemma. In this work, we address the above challenges through a prompt tuning paradigm and memory demonstration template strategy. Specifically, we designed an expandable Anchor words-oriented Prompt Tuning (APT) paradigm to bridge the gap between pre-training and fine-tuning, thereby enhancing performance in few-shot scenarios. Additionally, we incorporated Memory Demonstration Templates (MDT) into each training instance to provide replay samples from previous tasks, which not only avoids the Few-Shot Distillation Dilemma but also promotes in-context learning. Experiments show that our approach achieves competitive performances on FS-CLNER.",
    "source": "arXiv"
  },
  {
    "title": "Policy Newton methods for Distortion Riskmetrics",
    "title_es": "Policy Newton methods for Distortion Riskmetrics",
    "url": "https://arxiv.org/abs/2508.07249",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07249v1 Announce Type: new \nAbstract: We consider the problem of risk-sensitive control in a reinforcement learning (RL) framework. In particular, we aim to find a risk-optimal policy by maximizing the distortion riskmetric (DRM) of the discounted reward in a finite horizon Markov decision process (MDP). DRMs are a rich class of risk measures that include several well-known risk measures as special cases. We derive a policy Hessian theorem for the DRM objective using the likelihood ratio method. Using this result, we propose a natural DRM Hessian estimator from sample trajectories of the underlying MDP. Next, we present a cubic-regularized policy Newton algorithm for solving this problem in an on-policy RL setting using estimates of the DRM gradient and Hessian. Our proposed algorithm is shown to converge to an $\\epsilon$-second-order stationary point ($\\epsilon$-SOSP) of the DRM objective, and this guarantee ensures the escaping of saddle points. The sample complexity of our algorithms to find an $ \\epsilon$-SOSP is $\\mathcal{O}(\\epsilon^{-3.5})$. Our experiments validate the theoretical findings. To the best of our knowledge, our is the first work to present convergence to an $\\epsilon$-SOSP of a risk-sensitive objective, while existing works in the literature have either shown convergence to a first-order stationary point of a risk-sensitive objective, or a SOSP of a risk-neutral one.",
    "source": "arXiv"
  },
  {
    "title": "SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking",
    "title_es": "SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking",
    "url": "https://arxiv.org/abs/2508.07250",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07250v1 Announce Type: new \nAbstract: Hyperspectral videos (HSVs), with their inherent spatial-spectral-temporal structure, offer distinct advantages in challenging tracking scenarios such as cluttered backgrounds and small objects. However, existing methods primarily focus on spatial interactions between the template and search regions, often overlooking spectral interactions, leading to suboptimal performance. To address this issue, this paper investigates spectral interactions from both the architectural and training perspectives. At the architectural level, we first establish band-wise long-range spatial relationships between the template and search regions using Transformers. We then model spectral interactions using the inclusion-exclusion principle from set theory, treating them as the union of spatial interactions across all bands. This enables the effective integration of both shared and band-specific spatial cues. At the training level, we introduce a spectral loss to enforce material distribution alignment between the template and predicted regions, enhancing robustness to shape deformation and appearance variations. Extensive experiments demonstrate that our tracker achieves state-of-the-art tracking performance. The source code, trained models and results will be publicly available via https://github.com/bearshng/suit to support reproducibility.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Dynamic Scenes in Ego Centric 4D Point Clouds",
    "title_es": "Understanding Dynamic Scenes in Ego Centric 4D Point Clouds",
    "url": "https://arxiv.org/abs/2508.07251",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07251v1 Announce Type: new \nAbstract: Understanding dynamic 4D scenes from an egocentric perspective-modeling changes in 3D spatial structure over time-is crucial for human-machine interaction, autonomous navigation, and embodied intelligence. While existing egocentric datasets contain dynamic scenes, they lack unified 4D annotations and task-driven evaluation protocols for fine-grained spatio-temporal reasoning, especially on motion of objects and human, together with their interactions. To address this gap, we introduce EgoDynamic4D, a novel QA benchmark on highly dynamic scenes, comprising RGB-D video, camera poses, globally unique instance masks, and 4D bounding boxes. We construct 927K QA pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable, step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering agent motion, human-object interaction, trajectory prediction, relation understanding, and temporal-causal reasoning, with fine-grained, multidimensional metrics. To tackle these tasks, we propose an end-to-end spatio-temporal reasoning framework that unifies dynamic and static scene information, using instance-aware feature encoding, time and camera encoding, and spatially adaptive down-sampling to compress large 4D scenes into token sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method consistently outperforms baselines, validating the effectiveness of multimodal temporal modeling for egocentric dynamic scene understanding.",
    "source": "arXiv"
  },
  {
    "title": "Tasa: Thermal-aware 3D-Stacked Architecture Design with Bandwidth Sharing for LLM Inference",
    "title_es": "Tasa: Thermal-aware 3D-Stacked Architecture Design with Bandwidth Sharing for LLM Inference",
    "url": "https://arxiv.org/abs/2508.07252",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07252v1 Announce Type: new \nAbstract: The autoregressive decoding in LLMs is the major inference bottleneck due to the memory-intensive operations and limited hardware bandwidth. 3D-stacked architecture is a promising solution with significantly improved memory bandwidth, which vertically stacked multi DRAM dies on top of logic die. However, our experiments also show the 3D-stacked architecture faces severer thermal issues compared to 2D architecture, in terms of thermal temperature, gradient and scalability. To better exploit the potential of 3D-stacked architecture, we present Tasa, a heterogeneous architecture with cross-stack thermal optimizations to balance the temperature distribution and maximize the performance under the thermal constraints. High-performance core is designed for compute-intensive operations, while high-efficiency core is used for memory-intensive operators, e.g. attention layers. Furthermore, we propose a bandwidth sharing scheduling to improve the bandwidth utilization in such heterogeneous architecture. Extensive thermal experiments show that our Tasa architecture demonstrates greater scalability compared with the homogeneous 3D-stacked architecture, i.e. up to 5.55 $\\tccentigrade$, 9.37 $\\tccentigrade$, and 7.91 $\\tccentigrade$ peak temperature reduction for 48, 60, and 72 core configurations. Our experimental for Llama-65B and GPT-3 66B inferences also demonstrate 2.85x and 2.21x speedup are obtained over the GPU baselines and state-of-the-art heterogeneous PIM-based LLM accelerator",
    "source": "arXiv"
  },
  {
    "title": "PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets",
    "title_es": "PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets",
    "url": "https://arxiv.org/abs/2508.07253",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07253v1 Announce Type: new \nAbstract: Reliable seizure detection is critical for diagnosing and managing epilepsy, yet clinical workflows remain dependent on time-consuming manual EEG interpretation. While machine learning has shown promise, existing approaches often rely on dataset-specific optimisations, limiting their real-world applicability and reproducibility. Here, we introduce an innovative, open-source machine-learning framework that enables robust and generalisable seizure detection across varied clinical datasets. We evaluate our approach on two publicly available EEG datasets that differ in patient populations and electrode configurations. To enhance robustness, the framework incorporates an automated pre-processing pipeline to standardise data and a majority voting mechanism, in which multiple models independently assess each second of EEG before reaching a final decision. We train, tune, and evaluate models within each dataset, assessing their cross-dataset transferability. Our models achieve high within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and 0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets despite differences in EEG setups and populations (AUC 0.615+/-0.039 for models trained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case) without any post-processing. Furthermore, a mild post-processing improved the within-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset results to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the potential of, and essential considerations for, deploying our framework in diverse clinical settings. By making our methodology fully reproducible, we provide a foundation for advancing clinically viable, dataset-agnostic seizure detection systems. This approach has the potential for widespread adoption, complementing rather than replacing expert interpretation, and accelerating clinical integration.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Micro Accidents and Driver Responses in Automated Driving: Insights from Real-world Videos",
    "title_es": "Exploring Micro Accidents and Driver Responses in Automated Driving: Insights from Real-world Videos",
    "url": "https://arxiv.org/abs/2508.07256",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07256v1 Announce Type: new \nAbstract: Automated driving in level 3 autonomy has been adopted by multiple companies such as Tesla and BMW, alleviating the burden on drivers while unveiling new complexities. This article focused on the under-explored territory of micro accidents during automated driving, characterized as not fatal but abnormal aberrations such as abrupt deceleration and snake driving. These micro accidents are basic yet pervasive events that might results in more severe accidents. Through collecting a comprehensive dataset of user generated video recording such micro accidents in natural driving scenarios, this article locates key variables pertaining to environments and autonomous agents using machine learning methods. Subsequently, crowdsourcing method provides insights into human risk perceptions and reactions to these micro accidents. This article thus describes features of safety critical scenarios other than crashes and fatal accidents, informing and potentially advancing the design of automated driving systems.",
    "source": "arXiv"
  },
  {
    "title": "Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM",
    "title_es": "Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM",
    "url": "https://arxiv.org/abs/2508.07260",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07260v1 Announce Type: new \nAbstract: Personalizing Vision-Language Models (VLMs) to transform them into daily assistants has emerged as a trending research direction. However, leading companies like OpenAI continue to increase model size and develop complex designs such as the chain of thought (CoT). While large VLMs are proficient in complex multi-modal understanding, their high training costs and limited access via paid APIs restrict direct personalization. Conversely, small VLMs are easily personalized and freely available, but they lack sufficient reasoning capabilities. Inspired by this, we propose a novel collaborative framework named Small-Large Collaboration (SLC) for large VLM personalization, where the small VLM is responsible for generating personalized information, while the large model integrates this personalized information to deliver accurate responses. To effectively incorporate personalized information, we develop a test-time reflection strategy, preventing the potential hallucination of the small VLM. Since SLC only needs to train a meta personalized small VLM for the large VLMs, the overall process is training-efficient. To the best of our knowledge, this is the first training-efficient framework that supports both open-source and closed-source large VLMs, enabling broader real-world personalized applications. We conduct thorough experiments across various benchmarks and large VLMs to demonstrate the effectiveness of the proposed SLC framework. The code will be released at https://github.com/Hhankyangg/SLC.",
    "source": "arXiv"
  },
  {
    "title": "The 2D+ Dynamic Articulatory Model DYNARTmo: Tongue-Palate Contact Area Estimation",
    "title_es": "The 2D+ Dynamic Articulatory Model DYNARTmo: Tongue-Palate Contact Area Estimation",
    "url": "https://arxiv.org/abs/2508.07262",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07262v1 Announce Type: new \nAbstract: This paper describes an extension of the two-dimensional dynamic articulatory model DYNARTmo by integrating an internal three-dimensional representation of the palatal dome to estimate tongue-palate contact areas from midsagittal tongue contours. Two alternative dome geometries - a half-ellipse and a cosine based profile - are implemented to model lateral curvature in the coronal plane. Using these geometries, lateral contact points are analytically computed for each anterior-posterior position, enabling the generation of electropalatography-like visualizations within the 2D+ framework. The enhanced model supports three synchronized views (sagittal, glottal, and palatal) for static and dynamic (animated) articulation displays, suitable for speech science education and speech therapy. Future work includes adding a facial (lip) view and implementing articulatory-to-acoustic synthesis to quantitatively evaluate model realism.",
    "source": "arXiv"
  },
  {
    "title": "Fading the Digital Ink: A Universal Black-Box Attack Framework for 3DGS Watermarking Systems",
    "title_es": "Fading the Digital Ink: A Universal Black-Box Attack Framework for 3DGS Watermarking Systems",
    "url": "https://arxiv.org/abs/2508.07263",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07263v1 Announce Type: new \nAbstract: With the rise of 3D Gaussian Splatting (3DGS), a variety of digital watermarking techniques, embedding either 1D bitstreams or 2D images, are used for copyright protection. However, the robustness of these watermarking techniques against potential attacks remains underexplored. This paper introduces the first universal black-box attack framework, the Group-based Multi-objective Evolutionary Attack (GMEA), designed to challenge these watermarking systems. We formulate the attack as a large-scale multi-objective optimization problem, balancing watermark removal with visual quality. In a black-box setting, we introduce an indirect objective function that blinds the watermark detector by minimizing the standard deviation of features extracted by a convolutional network, thus rendering the feature maps uninformative. To manage the vast search space of 3DGS models, we employ a group-based optimization strategy to partition the model into multiple, independent sub-optimization problems. Experiments demonstrate that our framework effectively removes both 1D and 2D watermarks from mainstream 3DGS watermarking methods while maintaining high visual fidelity. This work reveals critical vulnerabilities in existing 3DGS copyright protection schemes and calls for the development of more robust watermarking systems.",
    "source": "arXiv"
  },
  {
    "title": "FLUID: Flow-Latent Unified Integration via Token Distillation for Expert Specialization in Multimodal Learning",
    "title_es": "FLUID: Flow-Latent Unified Integration via Token Distillation for Expert Specialization in Multimodal Learning",
    "url": "https://arxiv.org/abs/2508.07264",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07264v1 Announce Type: new \nAbstract: Multimodal classification requires robust integration of visual and textual signals, yet common fusion strategies are brittle and vulnerable to modality-specific noise. In this paper, we present \\textsc{FLUID}-Flow-Latent Unified Integration via Token Distillation for Expert Specialization, a principled token-level pipeline that improves cross-modal robustness and scalability. \\textsc{FLUID} contributes three core elements: (1) \\emph{Q-transforms}, learnable query tokens that distill and retain salient token-level features from modality-specific backbones; (2) a two-stage fusion scheme that enforces cross-modal consistency via contrastive alignment and then performs adaptive, task-aware fusion through a gating mechanism and a \\emph{Q-bottleneck} that selectively compresses information for downstream reasoning; and (3) a lightweight, load-balanced Mixture-of-Experts at prediction time that enables efficient specialization to diverse semantic patterns. Extensive experiments demonstrate that \\textsc{FLUID} attains \\(91\\%\\) accuracy on the GLAMI-1M benchmark, significantly outperforming prior baselines and exhibiting strong resilience to label noise, long-tail class imbalance, and semantic heterogeneity. Targeted ablation studies corroborate both the individual and synergistic benefits of the proposed components, positioning \\textsc{FLUID} as a scalable, noise-resilient solution for multimodal product classification.",
    "source": "arXiv"
  },
  {
    "title": "Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics",
    "title_es": "Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics",
    "url": "https://arxiv.org/abs/2508.07267",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07267v1 Announce Type: new \nAbstract: Achieving fully autonomous exploration and navigation remains a critical challenge in robotics, requiring integrated solutions for localisation, mapping, decision-making and motion planning. Existing approaches either rely on strict navigation rules lacking adaptability or on pre-training, which requires large datasets. These AI methods are often computationally intensive or based on static assumptions, limiting their adaptability in dynamic or unknown environments. This paper introduces a bio-inspired agent based on the Active Inference Framework (AIF), which unifies mapping, localisation, and adaptive decision-making for autonomous navigation, including exploration and goal-reaching. Our model creates and updates a topological map of the environment in real-time, planning goal-directed trajectories to explore or reach objectives without requiring pre-training. Key contributions include a probabilistic reasoning framework for interpretable navigation, robust adaptability to dynamic changes, and a modular ROS2 architecture compatible with existing navigation systems. Our method was tested in simulated and real-world environments. The agent successfully explores large-scale simulated environments and adapts to dynamic obstacles and drift, proving to be comparable to other exploration strategies such as Gbplanner, FAEL and Frontiers. This approach offers a scalable and transparent approach for navigating complex, unstructured environments.",
    "source": "arXiv"
  },
  {
    "title": "Navigation and Exploration with Active Inference: from Biology to Industry",
    "title_es": "Navigation and Exploration with Active Inference: from Biology to Industry",
    "url": "https://arxiv.org/abs/2508.07269",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07269v1 Announce Type: new \nAbstract: By building and updating internal cognitive maps, animals exhibit extraordinary navigation abilities in complex, dynamic environments. Inspired by these biological mechanisms, we present a real time robotic navigation system grounded in the Active Inference Framework (AIF). Our model incrementally constructs a topological map, infers the agent's location, and plans actions by minimising expected uncertainty and fulfilling perceptual goals without any prior training. Integrated into the ROS2 ecosystem, we validate its adaptability and efficiency across both 2D and 3D environments (simulated and real world), demonstrating competitive performance with traditional and state of the art exploration approaches while offering a biologically inspired navigation approach.",
    "source": "arXiv"
  },
  {
    "title": "OpenHAIV: A Framework Towards Practical Open-World Learning",
    "title_es": "OpenHAIV: A Framework Towards Practical Open-World Learning",
    "url": "https://arxiv.org/abs/2508.07270",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07270v1 Announce Type: new \nAbstract: Substantial progress has been made in various techniques for open-world recognition. Out-of-distribution (OOD) detection methods can effectively distinguish between known and unknown classes in the data, while incremental learning enables continuous model knowledge updates. However, in open-world scenarios, these approaches still face limitations. Relying solely on OOD detection does not facilitate knowledge updates in the model, and incremental fine-tuning typically requires supervised conditions, which significantly deviate from open-world settings. To address these challenges, this paper proposes OpenHAIV, a novel framework that integrates OOD detection, new class discovery, and incremental continual fine-tuning into a unified pipeline. This framework allows models to autonomously acquire and update knowledge in open-world environments. The proposed framework is available at https://haiv-lab.github.io/openhaiv .",
    "source": "arXiv"
  },
  {
    "title": "Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models",
    "title_es": "Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models",
    "url": "https://arxiv.org/abs/2508.07273",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07273v1 Announce Type: new \nAbstract: Current large speech language models (Speech-LLMs) often exhibit limitations in empathetic reasoning, primarily due to the absence of training datasets that integrate both contextual content and paralinguistic cues. In this work, we propose two approaches to incorporate contextual paralinguistic information into model training: (1) an explicit method that provides paralinguistic metadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit method that automatically generates novel training question-answer (QA) pairs using both categorical and dimensional emotion annotations alongside speech transcriptions. Our implicit method boosts performance (LLM-judged) by 38.41% on a human-annotated QA benchmark, reaching 46.02% when combined with the explicit approach, showing effectiveness in contextual paralinguistic understanding. We also validate the LLM judge by demonstrating its correlation with classification metrics, providing support for its reliability.",
    "source": "arXiv"
  },
  {
    "title": "MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory",
    "title_es": "MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory",
    "url": "https://arxiv.org/abs/2508.07279",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07279v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) offer new opportunities for scalable, interactive mental health assessment, but excessive querying by LLMs burdens users and is inefficient for real-world screening across transdiagnostic symptom profiles. We introduce MAQuA, an adaptive question-asking framework for simultaneous, multidimensional mental health screening. Combining multi-outcome modeling on language responses with item response theory (IRT) and factor analysis, MAQuA selects the questions with most informative responses across multiple dimensions at each turn to optimize diagnostic information, improving accuracy and potentially reducing response burden. Empirical results on a novel dataset reveal that MAQuA reduces the number of assessment questions required for score stabilization by 50-87% compared to random ordering (e.g., achieving stable depression scores with 71% fewer questions and eating disorder scores with 85% fewer questions). MAQuA demonstrates robust performance across both internalizing (depression, anxiety) and externalizing (substance use, eating disorder) domains, with early stopping strategies further reducing patient time and burden. These findings position MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive mental health screening, advancing the integration of LLM-based agents into real-world clinical workflows.",
    "source": "arXiv"
  },
  {
    "title": "Representation Understanding via Activation Maximization",
    "title_es": "Representation Understanding via Activation Maximization",
    "url": "https://arxiv.org/abs/2508.07281",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07281v1 Announce Type: new \nAbstract: Understanding internal feature representations of deep neural networks (DNNs) is a fundamental step toward model interpretability. Inspired by neuroscience methods that probe biological neurons using visual stimuli, recent deep learning studies have employed Activation Maximization (AM) to synthesize inputs that elicit strong responses from artificial neurons. In this work, we propose a unified feature visualization framework applicable to both Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). Unlike prior efforts that predominantly focus on the last output-layer neurons in CNNs, we extend feature visualization to intermediate layers as well, offering deeper insights into the hierarchical structure of learned feature representations. Furthermore, we investigate how activation maximization can be leveraged to generate adversarial examples, revealing potential vulnerabilities and decision boundaries of DNNs. Our experiments demonstrate the effectiveness of our approach in both traditional CNNs and modern ViT, highlighting its generalizability and interpretive value.",
    "source": "arXiv"
  },
  {
    "title": "Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment",
    "title_es": "Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment",
    "url": "https://arxiv.org/abs/2508.07283",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07283v1 Announce Type: new \nAbstract: This study explores the intersection of electroencephalography (EEG) microstates and Large Language Models (LLMs) to enhance the assessment of cognitive load states. By utilizing EEG microstate features, the research aims to fine-tune LLMs for improved predictions of distinct cognitive states, specifically 'Rest' and 'Load'. The experimental design is delineated in four comprehensive stages: dataset collection and preprocessing, microstate segmentation and EEG backfitting, feature extraction paired with prompt engineering, and meticulous LLM model selection and refinement. Employing a supervised learning paradigm, the LLM is trained to identify cognitive load states based on EEG microstate features integrated into prompts, producing accurate discrimination of cognitive load. A curated dataset, linking EEG features to specified cognitive load conditions, underpins the experimental framework. The results indicate a significant improvement in model performance following the proposed fine-tuning, showcasing the potential of EEG-informed LLMs in cognitive neuroscience and cognitive AI applications. This approach not only contributes to the understanding of brain dynamics but also paves the way for advancements in machine learning techniques applicable to cognitive load and cognitive AI research.",
    "source": "arXiv"
  },
  {
    "title": "\"Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas",
    "title_es": "\"Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas",
    "url": "https://arxiv.org/abs/2508.07284",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07284v1 Announce Type: new \nAbstract: As large language models (LLMs) increasingly mediate ethically sensitive decisions, understanding their moral reasoning processes becomes imperative. This study presents a comprehensive empirical evaluation of 14 leading LLMs, both reasoning enabled and general purpose, across 27 diverse trolley problem scenarios, framed by ten moral philosophies, including utilitarianism, deontology, and altruism. Using a factorial prompting protocol, we elicited 3,780 binary decisions and natural language justifications, enabling analysis along axes of decisional assertiveness, explanation answer consistency, public moral alignment, and sensitivity to ethically irrelevant cues. Our findings reveal significant variability across ethical frames and model types: reasoning enhanced models demonstrate greater decisiveness and structured justifications, yet do not always align better with human consensus. Notably, \"sweet zones\" emerge in altruistic, fairness, and virtue ethics framings, where models achieve a balance of high intervention rates, low explanation conflict, and minimal divergence from aggregated human judgments. However, models diverge under frames emphasizing kinship, legality, or self interest, often producing ethically controversial outcomes. These patterns suggest that moral prompting is not only a behavioral modifier but also a diagnostic tool for uncovering latent alignment philosophies across providers. We advocate for moral reasoning to become a primary axis in LLM alignment, calling for standardized benchmarks that evaluate not just what LLMs decide, but how and why.",
    "source": "arXiv"
  },
  {
    "title": "Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking",
    "title_es": "Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking",
    "url": "https://arxiv.org/abs/2508.07286",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07286v1 Announce Type: new \nAbstract: Accurate information extraction from specialized texts is a critical challenge, particularly for named entity recognition (NER) in the architecture, engineering, and construction (AEC) domain to support automated rule checking (ARC). The performance of standard pre-trained models is often constrained by the domain gap, as they struggle to interpret the specialized terminology and complex relational contexts inherent in AEC texts. Although this issue can be mitigated by further pre-training on large, human-curated domain corpora, as exemplified by methods like ARCBERT, this approach is both labor-intensive and cost-prohibitive. Consequently, leveraging large language models (LLMs) for automated knowledge generation has emerged as a promising alternative. However, the optimal strategy for generating knowledge that can genuinely enhance smaller, efficient models remains an open question. To address this, we propose ARCE (augmented RoBERTa with contextualized elucidations), a novel approach that systematically explores and optimizes this generation process. ARCE employs an LLM to first generate a corpus of simple, direct explanations, which we term Cote, and then uses this corpus to incrementally pre-train a RoBERTa model prior to its fine-tuning on the downstream task. Our extensive experiments show that ARCE establishes a new state-of-the-art on a benchmark AEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a key finding: simple, explanation-based knowledge proves surprisingly more effective than complex, role-based rationales for this task. The code is publicly available at:https://github.com/nxcc-lab/ARCE.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal Spiking Neural Network for Space Robotic Manipulation",
    "title_es": "Multimodal Spiking Neural Network for Space Robotic Manipulation",
    "url": "https://arxiv.org/abs/2508.07287",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07287v1 Announce Type: new \nAbstract: This paper presents a multimodal control framework based on spiking neural networks (SNNs) for robotic arms aboard space stations. It is designed to cope with the constraints of limited onboard resources while enabling autonomous manipulation and material transfer in space operations. By combining geometric states with tactile and semantic information, the framework strengthens environmental awareness and contributes to more robust control strategies. To guide the learning process progressively, a dual-channel, three-stage curriculum reinforcement learning (CRL) scheme is further integrated into the system. The framework was tested across a range of tasks including target approach, object grasping, and stable lifting with wall-mounted robotic arms, demonstrating reliable performance throughout. Experimental evaluations demonstrate that the proposed method consistently outperforms baseline approaches in both task success rate and energy efficiency. These findings highlight its suitability for real-world aerospace applications.",
    "source": "arXiv"
  },
  {
    "title": "Reversible Video Steganography Using Quick Response Codes and Modified ElGamal Cryptosystem",
    "title_es": "Reversible Video Steganography Using Quick Response Codes and Modified ElGamal Cryptosystem",
    "url": "https://arxiv.org/abs/2508.07289",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07289v1 Announce Type: new \nAbstract: The rapid transmission of multimedia information has been achieved mainly by recent advancements in the Internet's speed and information technology. In spite of this, advancements in technology have resulted in breaches of privacy and data security. When it comes to protecting private information in today's Internet era, digital steganography is vital. Many academics are interested in digital video because it has a great capability for concealing important data. There have been a vast number of video steganography solutions developed lately to guard against the theft of confidential data. The visual imperceptibility, robustness, and embedding capacity of these approaches are all challenges that must be addressed. In this paper, a novel solution to reversible video steganography based on DWT and QR codes is proposed to address these concerns. In order to increase the security level of the suggested method, an enhanced ElGamal cryptosystem has also been proposed. Prior to the embedding stage, the suggested method uses the modified ElGamal algorithm to encrypt secret QR codes. Concurrently, it applies two-dimensional DWT on the Y-component of each video frame resulting in LL, LH, HL, and HH sub-bands. Then, the encrypted Low (L), Medium (M), Quantile (Q), and High (H) QR codes are embedded into the HL sub-band, HH sub-band, U-component, and V-component of video frames, respectively, using the LSB technique. As a consequence of extensive testing of the approach, it was shown to be very secure and highly invisible, as well as highly resistant to attacks from Salt & Pepper, Gaussian, Poisson, and Speckle noises, which has an average SSIM of more than 0.91. Aside from visual imperceptibility, the suggested method exceeds current methods in terms of PSNR average of 52.143 dB, and embedding capacity 1 bpp.",
    "source": "arXiv"
  },
  {
    "title": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning",
    "title_es": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning",
    "url": "https://arxiv.org/abs/2508.07292",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07292v1 Announce Type: new \nAbstract: Developing general artificial intelligence (AI) systems to support endoscopic image diagnosis is an emerging research priority. Existing methods based on large-scale pretraining often lack unified coordination across tasks and struggle to handle the multi-step processes required in complex clinical workflows. While AI agents have shown promise in flexible instruction parsing and tool integration across domains, their potential in endoscopy remains underexplored. To address this gap, we propose EndoAgent, the first memory-guided agent for vision-to-decision endoscopic analysis that integrates iterative reasoning with adaptive tool selection and collaboration. Built on a dual-memory design, it enables sophisticated decision-making by ensuring logical coherence through short-term action tracking and progressively enhancing reasoning acuity through long-term experiential learning. To support diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools within a unified reasoning loop. We further introduce EndoAgentBench, a benchmark of 5,709 visual question-answer pairs that assess visual understanding and language generation capabilities in realistic scenarios. Extensive experiments show that EndoAgent consistently outperforms both general and medical multimodal models, exhibiting its strong flexibility and reasoning capabilities.",
    "source": "arXiv"
  },
  {
    "title": "CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation",
    "title_es": "CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation",
    "url": "https://arxiv.org/abs/2508.07295",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07295v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) are increasingly popularized in the multilingual world, ensuring hallucination-free factuality becomes markedly crucial. However, existing benchmarks for evaluating the reliability of Multimodal Large Language Models (MLLMs) predominantly focus on textual or visual modalities with a primary emphasis on English, which creates a gap in evaluation when processing multilingual input, especially in speech. To bridge this gap, we propose a novel \\textbf{C}ross-lingual and \\textbf{C}ross-modal \\textbf{F}actuality benchmark (\\textbf{CCFQA}). Specifically, the CCFQA benchmark contains parallel speech-text factual questions across 8 languages, designed to systematically evaluate MLLMs' cross-lingual and cross-modal factuality capabilities. Our experimental results demonstrate that current MLLMs still face substantial challenges on the CCFQA benchmark. Furthermore, we propose a few-shot transfer learning strategy that effectively transfers the Question Answering (QA) capabilities of LLMs in English to multilingual Spoken Question Answering (SQA) tasks, achieving competitive performance with GPT-4o-mini-Audio using just 5-shot training. We release CCFQA as a foundational research resource to promote the development of MLLMs with more robust and reliable speech understanding capabilities. Our code and dataset are available at https://github.com/yxduir/ccfqa.",
    "source": "arXiv"
  },
  {
    "title": "Revisiting Data Attribution for Influence Functions",
    "title_es": "Revisiting Data Attribution for Influence Functions",
    "url": "https://arxiv.org/abs/2508.07297",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07297v1 Announce Type: new \nAbstract: The goal of data attribution is to trace the model's predictions through the learning algorithm and back to its training data. thereby identifying the most influential training samples and understanding how the model's behavior leads to particular predictions. Understanding how individual training examples influence a model's predictions is fundamental for machine learning interpretability, data debugging, and model accountability. Influence functions, originating from robust statistics, offer an efficient, first-order approximation to estimate the impact of marginally upweighting or removing a data point on a model's learned parameters and its subsequent predictions, without the need for expensive retraining. This paper comprehensively reviews the data attribution capability of influence functions in deep learning. We discuss their theoretical foundations, recent algorithmic advances for efficient inverse-Hessian-vector product estimation, and evaluate their effectiveness for data attribution and mislabel detection. Finally, highlighting current challenges and promising directions for unleashing the huge potential of influence functions in large-scale, real-world deep learning scenarios.",
    "source": "arXiv"
  },
  {
    "title": "SynMatch: Rethinking Consistency in Medical Image Segmentation with Sparse Annotations",
    "title_es": "SynMatch: Rethinking Consistency in Medical Image Segmentation with Sparse Annotations",
    "url": "https://arxiv.org/abs/2508.07298",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07298v1 Announce Type: new \nAbstract: Label scarcity remains a major challenge in deep learning-based medical image segmentation. Recent studies use strong-weak pseudo supervision to leverage unlabeled data. However, performance is often hindered by inconsistencies between pseudo labels and their corresponding unlabeled images. In this work, we propose \\textbf{SynMatch}, a novel framework that sidesteps the need for improving pseudo labels by synthesizing images to match them instead. Specifically, SynMatch synthesizes images using texture and shape features extracted from the same segmentation model that generates the corresponding pseudo labels for unlabeled images. This design enables the generation of highly consistent synthesized-image-pseudo-label pairs without requiring any training parameters for image synthesis. We extensively evaluate SynMatch across diverse medical image segmentation tasks under semi-supervised learning (SSL), weakly-supervised learning (WSL), and barely-supervised learning (BSL) settings with increasingly limited annotations. The results demonstrate that SynMatch achieves superior performance, especially in the most challenging BSL setting. For example, it outperforms the recent strong-weak pseudo supervision-based method by 29.71\\% and 10.05\\% on the polyp segmentation task with 5\\% and 10\\% scribble annotations, respectively. The code will be released at https://github.com/Senyh/SynMatch.",
    "source": "arXiv"
  },
  {
    "title": "When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective",
    "title_es": "When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective",
    "url": "https://arxiv.org/abs/2508.07299",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07299v1 Announce Type: new \nAbstract: Neuro-symbolic (Nesy) learning improves the target task performance of models by enabling them to satisfy knowledge, while semi/self-supervised learning (SSL) improves the target task performance by designing unsupervised pretext tasks for unlabeled data to make models satisfy corresponding assumptions. We extend the Nesy theory based on reliable knowledge to the scenario of unreliable knowledge (i.e., assumptions), thereby unifying the theoretical frameworks of SSL and Nesy. Through rigorous theoretical analysis, we demonstrate that, in theory, the impact of pretext tasks on target performance hinges on three factors: knowledge learnability with respect to the model, knowledge reliability with respect to the data, and knowledge completeness with respect to the target. We further propose schemes to operationalize these theoretical metrics, and thereby develop a method that can predict the effectiveness of pretext tasks in advance. This will change the current status quo in practical applications, where the selections of unsupervised tasks are heuristic-based rather than theory-based, and it is difficult to evaluate the rationality of unsupervised pretext task selection before testing the model on the target task. In experiments, we verify a high correlation between the predicted performance-estimated using minimal data-and the actual performance achieved after large-scale semi-supervised or self-supervised learning, thus confirming the validity of the theory and the effectiveness of the evaluation method.",
    "source": "arXiv"
  },
  {
    "title": "BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation",
    "title_es": "BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation",
    "url": "https://arxiv.org/abs/2508.07300",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07300v1 Announce Type: new \nAbstract: Real-time semantic segmentation presents the dual challenge of designing efficient architectures that capture large receptive fields for semantic understanding while also refining detailed contours. Vision transformers model long-range dependencies effectively but incur high computational cost. To address these challenges, we introduce the Large Kernel Attention (LKA) mechanism. Our proposed Bilateral Efficient Visual Attention Network (BEVANet) expands the receptive field to capture contextual information and extracts visual and structural features using Sparse Decomposed Large Separable Kernel Attentions (SDLSKA). The Comprehensive Kernel Selection (CKS) mechanism dynamically adapts the receptive field to further enhance performance. Furthermore, the Deep Large Kernel Pyramid Pooling Module (DLKPPM) enriches contextual features by synergistically combining dilated convolutions and large kernel attention. The bilateral architecture facilitates frequent branch communication, and the Boundary Guided Adaptive Fusion (BGAF) module enhances boundary delineation by integrating spatial and semantic features under boundary guidance. BEVANet achieves real-time segmentation at 33 FPS, yielding 79.3% mIoU without pretraining and 81.0% mIoU on Cityscapes after ImageNet pretraining, demonstrating state-of-the-art performance. The code and model is available at https://github.com/maomao0819/BEVANet.",
    "source": "arXiv"
  },
  {
    "title": "In-person, Online and Back Again -- A Tale of Three Hybrid Hackathons",
    "title_es": "In-person, Online and Back Again -- A Tale of Three Hybrid Hackathons",
    "url": "https://arxiv.org/abs/2508.07301",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07301v1 Announce Type: new \nAbstract: Hybrid hackathons, which combine in-person and online participation, present unique challenges for organizers and participants. Although such events are increasingly conducted, research on them remains fragmented, with limited integration between hackathon studies and hybrid collaboration. Existing strategies for in-person or online-only events often fail to address the unique challenges of hybrid formats, such as managing communication across physical and virtual spaces. Our work addresses this gap by examining how hybrid hackathons function, analyzing how organizers structure these events and how participants navigate hybrid-specific challenges. Drawing on established theories of hybrid collaboration, we examine key dimensions - synchronicity, physical distribution, dynamic transitions, and technological infrastructure - that shape collaboration in hybrid events. Through an exploratory case study of three hackathon events, we analyze how these dimensions are implemented and their effects on participant experiences. Our findings reveal differing organizer considerations of the hybrid dimensions in the hackathon design, leading to distinct experiences for participants. Implementation styles - favoring in-person, online, or balanced participation - led to varied participant experiences, affecting access to resources, communication, and team coordination. Organizers in our study also relied on technology to bridge hybrid interactions, but overlooked critical aspects like time-zone management, dynamic transitions, and targeted support for hybrid teams. Additionally, participants in their teams responded to gaps in event scaffolding by adapting collaboration strategies, revealing gaps in organizers' preparedness for hybrid events. Learning from our findings, we offer practical recommendations when organizing hybrid hackathon events and recommendations to participants when attending them.",
    "source": "arXiv"
  },
  {
    "title": "From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses",
    "title_es": "From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses",
    "url": "https://arxiv.org/abs/2508.07304",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07304v1 Announce Type: new \nAbstract: This paper introduces a new family of cognitive modal logics designed to formalize conjectural reasoning: a modal system in which cognitive contexts extend known facts with hypothetical assumptions to explore their consequences. Unlike traditional doxastic and epistemic systems, conjectural logics rely on a principle, called Axiom C ($\\varphi \\rightarrow \\Box\\varphi$), that ensures that all established facts are preserved across hypothetical layers. While Axiom C was dismissed in the past due to its association with modal collapse, we show that the collapse only arises under classical and bivalent assumptions, and specifically in the presence of Axiom T. Hence we avoid Axiom T and adopt a paracomplete semantic framework, grounded in Weak Kleene logic or Description Logic, where undefined propositions coexist with modal assertions. This prevents the modal collapse and guarantees a layering to distinguish between factual and conjectural statements. Under this framework we define new modal systems, e.g., KC and KDC, and show that they are complete, decidable, and robust under partial knowledge. Finally, we introduce a dynamic operation, $\\mathsf{settle}(\\varphi)$, which formalizes the transition from conjecture to accepted fact, capturing the event of the update of a world's cognitive state through the resolution of uncertainty.",
    "source": "arXiv"
  },
  {
    "title": "DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices",
    "title_es": "DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices",
    "url": "https://arxiv.org/abs/2508.07306",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07306v1 Announce Type: new \nAbstract: Dragon fruit, renowned for its nutritional benefits and economic value, has experienced rising global demand due to its affordability and local availability. As dragon fruit cultivation expands, efficient pre- and post-harvest quality inspection has become essential for improving agricultural productivity and minimizing post-harvest losses. This study presents DragonFruitQualityNet, a lightweight Convolutional Neural Network (CNN) optimized for real-time quality assessment of dragon fruits on mobile devices. We curated a diverse dataset of 13,789 images, integrating self-collected samples with public datasets (dataset from Mendeley Data), and classified them into four categories: fresh, immature, mature, and defective fruits to ensure robust model training. The proposed model achieves an impressive 93.98% accuracy, outperforming existing methods in fruit quality classification. To facilitate practical adoption, we embedded the model into an intuitive mobile application, enabling farmers and agricultural stakeholders to conduct on-device, real-time quality inspections. This research provides an accurate, efficient, and scalable AI-driven solution for dragon fruit quality control, supporting digital agriculture and empowering smallholder farmers with accessible technology. By bridging the gap between research and real-world application, our work advances post-harvest management and promotes sustainable farming practices.",
    "source": "arXiv"
  },
  {
    "title": "MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark",
    "title_es": "MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark",
    "url": "https://arxiv.org/abs/2508.07307",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07307v1 Announce Type: new \nAbstract: Continual learning aims to equip AI systems with the ability to continuously acquire and adapt to new knowledge without forgetting previously learned information, similar to human learning. While traditional continual learning methods focusing on unimodal tasks have achieved notable success, the emergence of Multimodal Large Language Models has brought increasing attention to Multimodal Continual Learning tasks involving multiple modalities, such as vision and language. In this setting, models are expected to not only mitigate catastrophic forgetting but also handle the challenges posed by cross-modal interactions and coordination. To facilitate research in this direction, we introduce MCITlib, a comprehensive and constantly evolving code library for continual instruction tuning of Multimodal Large Language Models. In MCITlib, we have currently implemented 8 representative algorithms for Multimodal Continual Instruction Tuning and systematically evaluated them on 2 carefully selected benchmarks. MCITlib will be continuously updated to reflect advances in the Multimodal Continual Learning field. The codebase is released at https://github.com/Ghy0501/MCITlib.",
    "source": "arXiv"
  },
  {
    "title": "HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways",
    "title_es": "HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways",
    "url": "https://arxiv.org/abs/2508.07308",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07308v1 Announce Type: new \nAbstract: HealthBranches is a novel benchmark dataset for medical Question-Answering (Q&A), specifically designed to evaluate complex reasoning in Large Language Models (LLMs). This dataset is generated through a semi-automated pipeline that transforms explicit decision pathways from medical source into realistic patient cases with associated questions and answers. Covering 4,063 case studies across 17 healthcare topics, each data point is based on clinically validated reasoning chains. HealthBranches supports both open-ended and multiple-choice question formats and uniquely includes the full reasoning path for each Q&A. Its structured design enables robust evaluation of LLMs' multi-step inference capabilities, including their performance in structured Retrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a foundation for the development of more trustworthy, interpretable, and clinically reliable LLMs in high-stakes domains while also serving as a valuable resource for educational purposes.",
    "source": "arXiv"
  },
  {
    "title": "Harmonic balance-automatic differentiation method: an out-of-the-box and efficient solver for general nonlinear dynamics simulation",
    "title_es": "Harmonic balance-automatic differentiation method: an out-of-the-box and efficient solver for general nonlinear dynamics simulation",
    "url": "https://arxiv.org/abs/2508.07309",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07309v1 Announce Type: new \nAbstract: The Harmonic Balance-Alternating Frequency-Time domain (HB-AFT) method is extensively employed for dynamic response analysis of nonlinear systems. However, its application to high-dimensional complex systems is constrained by the manual derivation of Jacobian matrices during Newton-Raphson iterations, which become computationally intractable or error-prone for intricate nonlinearities. The Harmonic Balance-Automatic Differentiation (HB-AD) method is proposed to address this limitation, in which AD is integrated with the harmonic balance framework. This approach eliminates all manual derivations by leveraging AD to compute exact Jacobians numerically, enabling generic and efficient analysis of high-dimensional complex nonlinear systems. The implementation utilizes advanced deep learning frameworks for native parallel computing and CUDA acceleration, and combines AD with arc-length continuation, establishing an out-of-the-box and high efficiency computational architecture. Users need only supply the system's dynamic equations, HB-AD then autonomously trace the complete panorama of periodic responses -- including stable/unstable solution branches. Computational experiments on a rotor system with squeeze-film damper (SFD) demonstrate HB-AD's capability in handling complex nonlinear expressions with automated Jacobian calculations. For a high-dimensional aero-engine rotor-bearing-casing system with complex bearing nonlinearities, HB-AD achieves 17-fold higher efficiency than traditional HB-AFT and 144-fold acceleration over the Newmark method. The HB-AD method is a synergistic merger of computational mechanics and machine learning primitives, delivers an easy to use, general-purpose, high efficiency platform for high-fidelity dynamic characterization of high-dimensional engineering systems.",
    "source": "arXiv"
  },
  {
    "title": "Optimal Representation for Right-to-Left Parallel Scalar Point Multiplication",
    "title_es": "Optimal Representation for Right-to-Left Parallel Scalar Point Multiplication",
    "url": "https://arxiv.org/abs/2508.07310",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07310v1 Announce Type: new \nAbstract: This paper introduces an optimal representation for a right-to-left parallel elliptic curve scalar point multiplication. The right-to-left approach is easier to parallelize than the conventional left-to-right approach. However, unlike the left-to-right approach, there is still no work considering number representations for the right-to-left parallel calculation. By simplifying the implementation by Robert, we devise a mathematical model to capture the computation time of the calculation. Then, for any arbitrary amount of doubling time and addition time, we propose algorithms to generate representations which minimize the time in that model. As a result, we can show a negative result that a conventional representation like NAF is almost optimal. The parallel computation time obtained from any representation cannot be better than NAF by more than 1%.",
    "source": "arXiv"
  },
  {
    "title": "MobileViCLIP: An Efficient Video-Text Model for Mobile Devices",
    "title_es": "MobileViCLIP: An Efficient Video-Text Model for Mobile Devices",
    "url": "https://arxiv.org/abs/2508.07312",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07312v1 Announce Type: new \nAbstract: Efficient lightweight neural networks are with increasing attention due to their faster reasoning speed and easier deployment on mobile devices. However, existing video pre-trained models still focus on the common ViT architecture with high latency, and few works attempt to build efficient architecture on mobile devices. This paper bridges this gap by introducing temporal structural reparameterization into an efficient image-text model and training it on a large-scale high-quality video-text dataset, resulting in an efficient video-text model that can run on mobile devices with strong zero-shot classification and retrieval capabilities, termed as MobileViCLIP. In particular, in terms of inference speed on mobile devices, our MobileViCLIP-Small is 55.4x times faster than InternVideo2-L14 and 6.7x faster than InternVideo2-S14. In terms of zero-shot retrieval performance, our MobileViCLIP-Small obtains similar performance as InternVideo2-L14 and obtains 6.9\\% better than InternVideo2-S14 on MSR-VTT. The code is available at https://github.com/MCG-NJU/MobileViCLIP.",
    "source": "arXiv"
  },
  {
    "title": "DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding",
    "title_es": "DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding",
    "url": "https://arxiv.org/abs/2508.07313",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07313v1 Announce Type: new \nAbstract: Understanding multi-page documents poses a significant challenge for multimodal large language models (MLLMs), as it requires fine-grained visual comprehension and multi-hop reasoning across pages. While prior work has explored reinforcement learning (RL) for enhancing advanced reasoning in MLLMs, its application to multi-page document understanding remains underexplored. In this paper, we introduce DocR1, an MLLM trained with a novel RL framework, Evidence Page-Guided GRPO (EviGRPO). EviGRPO incorporates an evidence-aware reward mechanism that promotes a coarse-to-fine reasoning strategy, guiding the model to first retrieve relevant pages before generating answers. This training paradigm enables us to build high-quality models with limited supervision. To support this, we design a two-stage annotation pipeline and a curriculum learning strategy, based on which we construct two datasets: EviBench, a high-quality training set with 4.8k examples, and ArxivFullQA, an evaluation benchmark with 8.6k QA pairs based on scientific papers. Extensive experiments across a wide range of benchmarks demonstrate that DocR1 achieves state-of-the-art performance on multi-page tasks, while consistently maintaining strong results on single-page benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Human-in-the-Loop Simulation for Real-Time Exploration of HVAC Demand Flexibility",
    "title_es": "Human-in-the-Loop Simulation for Real-Time Exploration of HVAC Demand Flexibility",
    "url": "https://arxiv.org/abs/2508.07314",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07314v1 Announce Type: new \nAbstract: The increasing integration of renewable energy into the power grid has highlighted the critical importance of demand-side flexibility. Among flexible loads, heating, ventilation, and air-conditioning (HVAC) systems are particularly significant due to their high energy consumption and controllability. This study presents the development of an interactive simulation platform that integrates a high-fidelity simulation engine with a user-facing dashboard, specifically designed to explore and demonstrate the demand flexibility capacity of HVAC systems. Unlike conventional simulations, where users are passive observers of simulation results with no ability to intervene in the embedded control during the simulation, this platform transforms them into active participants. Users can override system default control settings, such as zone temperature setpoints and HVAC schedules, at any point during the simulation runtime to implement demand response strategies of their choice. This human-in-the-loop capability enables real-time interaction and allows users to observe the immediate impact of their actions, emulating the practical decision-making process of a building or system operator. By exploring different demand flexibility scenarios and system behaviour in a manner that reflects real-world operation, users gain a deeper understanding of demand flexibility and their impacts. This interactive experience builds confidence and supports more informed decision-making in the practical adoption of demand-side flexibility. This paper presents the architecture of the simulation platform, user-oriented dashboard design, and user case showcase. The introduced human-in-the-loop simulation paradigm offers a more intuitive and interactive means of engaging with grid-interactive building operations, extending beyond HVAC demand flexibility exploration.",
    "source": "arXiv"
  },
  {
    "title": "An Experimental Exploration of In-Memory Computing for Multi-Layer Perceptrons",
    "title_es": "An Experimental Exploration of In-Memory Computing for Multi-Layer Perceptrons",
    "url": "https://arxiv.org/abs/2508.07317",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07317v1 Announce Type: new \nAbstract: In modern computer architectures, the performance of many memory-bound workloads (e.g., machine learning, graph processing, databases) is limited by the data movement bottleneck that emerges when transferring large amounts of data between the main memory and the central processing unit (CPU). Processing-in-memory is an emerging computing paradigm that aims to alleviate this data movement bottleneck by performing computation close to or within the memory units, where data resides. One example of a prevalent workload whose performance is bound by the data movement bottleneck is the training and inference process of artificial neural networks. In this work, we analyze the potential of modern general-purpose PiM architectures to accelerate neural networks. To this end, we selected the UPMEM PiM system, the first commercially available real-world general-purpose PiM architecture. We compared the implementation of multilayer perceptrons (MLPs) in PiM with a sequential baseline running on an Intel Xeon CPU. The UPMEM implementation achieves up to $259\\times$ better performance for inference of large batch sizes when compared against the CPU that exploits the size of the available PiM memory. Additionally, two smaller MLPs were implemented using UPMEM's working SRAM (WRAM), a scratchpad memory, to evaluate their performance against a low-power Nvidia Jetson graphics processing unit (GPU), providing further insights into the efficiency of UPMEM's PiM for neural network inference. Results show that using WRAM achieves kernel execution times for MLP inference of under $3$ ms, which is within the same order of magnitude as low-power GPUs.",
    "source": "arXiv"
  },
  {
    "title": "RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning",
    "title_es": "RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning",
    "url": "https://arxiv.org/abs/2508.07318",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07318v1 Announce Type: new \nAbstract: Image captioning aims to generate natural language descriptions for input images in an open-form manner. To accurately generate descriptions related to the image, a critical step in image captioning is to identify objects and understand their relations within the image. Modern approaches typically capitalize on object detectors or combine detectors with Graph Convolutional Network (GCN). However, these models suffer from redundant detection information, difficulty in GCN construction, and high training costs. To address these issues, a Retrieval-based Objects and Relations Prompt for Image Captioning (RORPCap) is proposed, inspired by the fact that image-text retrieval can provide rich semantic information for input images. RORPCap employs an Objects and relations Extraction Model to extract object and relation words from the image. These words are then incorporate into predefined prompt templates and encoded as prompt embeddings. Next, a Mamba-based mapping network is designed to quickly map image embeddings extracted by CLIP to visual-text embeddings. Finally, the resulting prompt embeddings and visual-text embeddings are concatenated to form textual-enriched feature embeddings, which are fed into a GPT-2 model for caption generation. Extensive experiments conducted on the widely used MS-COCO dataset show that the RORPCap requires only 2.6 hours under cross-entropy loss training, achieving 120.5% CIDEr score and 22.0% SPICE score on the \"Karpathy\" test split. RORPCap achieves comparable performance metrics to detector-based and GCN-based models with the shortest training time and demonstrates its potential as an alternative for image captioning.",
    "source": "arXiv"
  },
  {
    "title": "A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks",
    "title_es": "A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks",
    "url": "https://arxiv.org/abs/2508.07319",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07319v1 Announce Type: new \nAbstract: Manipulating deformable linear objects (DLOs) such as wires and cables is crucial in various applications like electronics assembly and medical surgeries. However, it faces challenges due to DLOs' infinite degrees of freedom, complex nonlinear dynamics, and the underactuated nature of the system. To address these issues, this paper proposes a hybrid force-position strategy for DLO shape control. The framework, combining both force and position representations of DLO, integrates state trajectory planning in the force space and Model Predictive Control (MPC) in the position space. We present a dynamics model with an explicit action encoder, a property extractor and a graph processor based on Graph Attention Networks. The model is used in the MPC to enhance prediction accuracy. Results from both simulations and real-world experiments demonstrate the effectiveness of our approach in achieving efficient and stable shape control of DLOs. Codes and videos are available at https://sites.google.com/view/dlom.",
    "source": "arXiv"
  },
  {
    "title": "ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering",
    "title_es": "ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering",
    "url": "https://arxiv.org/abs/2508.07321",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07321v1 Announce Type: new \nAbstract: The rapid proliferation of Large Language Models (LLMs) has significantly contributed to the development of equitable AI systems capable of factual question-answering (QA). However, no known study tests the LLMs' robustness when presented with obfuscated versions of questions. To systematically evaluate these limitations, we propose a novel technique, ObfusQAte and, leveraging the same, introduce ObfusQA, a comprehensive, first of its kind, framework with multi-tiered obfuscation levels designed to examine LLM capabilities across three distinct dimensions: (i) Named-Entity Indirection, (ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these fine-grained distinctions in language, ObfusQA provides a comprehensive benchmark for evaluating LLM robustness and adaptability. Our study observes that LLMs exhibit a tendency to fail or generate hallucinated responses when confronted with these increasingly nuanced variations. To foster research in this direction, we make ObfusQAte publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)",
    "title_es": "Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)",
    "url": "https://arxiv.org/abs/2508.07323",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07323v1 Announce Type: new \nAbstract: Robotic trajectory planning in dynamic and cluttered environments remains a critical challenge, particularly when striving for both time efficiency and motion smoothness under actuation constraints. Traditional path planner, such as Artificial Potential Field (APF), offer computational efficiency but suffer from local minima issue due to position-based potential field functions and oscillatory motion near the obstacles due to Newtonian mechanics. To address this limitation, an Energy-based Artificial Potential Field (APF) framework is proposed in this paper that integrates position and velocity-dependent potential functions. E-APF ensures dynamic adaptability and mitigates local minima, enabling uninterrupted progression toward the goal. The proposed framework integrates E-APF with a hybrid trajectory optimizer that jointly minimizes jerk and execution time under velocity and acceleration constraints, ensuring geometric smoothness and time efficiency. The entire framework is validated in simulation using the 7-degree-of-freedom Kinova Gen3 robotic manipulator. The results demonstrate collision-free, smooth, time-efficient, and oscillation-free trajectory in the presence of obstacles, highlighting the efficacy of the combined trajectory optimization and real-time obstacle avoidance approach. This work lays the foundation for future integration with reactive control strategies and physical hardware deployment in real-world manipulation tasks.",
    "source": "arXiv"
  },
  {
    "title": "Strategies of Code-switching in Human-Machine Dialogs",
    "title_es": "Strategies of Code-switching in Human-Machine Dialogs",
    "url": "https://arxiv.org/abs/2508.07325",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07325v1 Announce Type: new \nAbstract: Most people are multilingual, and most multilinguals code-switch, yet the characteristics of code-switched language are not fully understood. We developed a chatbot capable of completing a Map Task with human participants using code-switched Spanish and English. In two experiments, we prompted the bot to code-switch according to different strategies, examining (1) the feasibility of such experiments for investigating bilingual language use, and (2) whether participants would be sensitive to variations in discourse and grammatical patterns. Participants generally enjoyed code-switching with our bot as long as it produced predictable code-switching behavior; when code-switching was random or ungrammatical (as when producing unattested incongruent mixed-language noun phrases, such as `la fork'), participants enjoyed the task less and were less successful at completing it. These results underscore the potential downsides of deploying insufficiently developed multilingual language technology, while also illustrating the promise of such technology for conducting research on bilingual language use.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative",
    "title_es": "Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative",
    "url": "https://arxiv.org/abs/2508.07329",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07329v1 Announce Type: new \nAbstract: With the breakthrough progress of large language models (LLMs) in natural language processing and multimodal tasks, efficiently deploying them on resource-constrained edge devices has become a critical challenge. The Mixture of Experts (MoE) architecture enhances model capacity through sparse activation, but faces two major difficulties in practical deployment: (1) The presence of numerous outliers in activation distributions leads to severe degradation in quantization accuracy for both activations and weights, significantly impairing inference performance; (2) Under limited memory, efficient offloading and collaborative inference of expert modules struggle to balance latency and throughput. To address these issues, this paper proposes an efficient MoE edge deployment scheme based on Hessian-Aware Quantization (HAQ) and CPU-GPU collaborative inference. First, by introducing smoothed Hessian matrix quantization, we achieve joint 8-bit quantization of activations and weights, which significantly alleviates the accuracy loss caused by outliers while ensuring efficient implementation on mainstream hardware. Second, we design an expert-level collaborative offloading and inference mechanism, which, combined with expert activation path statistics, enables efficient deployment and scheduling of expert modules between CPU and GPU, greatly reducing memory footprint and inference latency. Extensive experiments validate the effectiveness of our method on mainstream large models such as the OPT series and Mixtral 8*7B: on datasets like Wikitext2 and C4, the inference accuracy of the low-bit quantized model approaches that of the full-precision model, while GPU memory usage is reduced by about 60%, and inference latency is significantly improved.",
    "source": "arXiv"
  },
  {
    "title": "Planner-Refiner: Dynamic Space-Time Refinement for Vision-Language Alignment in Videos",
    "title_es": "Planner-Refiner: Dynamic Space-Time Refinement for Vision-Language Alignment in Videos",
    "url": "https://arxiv.org/abs/2508.07330",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07330v1 Announce Type: new \nAbstract: Vision-language alignment in video must address the complexity of language, evolving interacting entities, their action chains, and semantic gaps between language and vision. This work introduces Planner-Refiner, a framework to overcome these challenges. Planner-Refiner bridges the semantic gap by iteratively refining visual elements' space-time representation, guided by language until semantic gaps are minimal. A Planner module schedules language guidance by decomposing complex linguistic prompts into short sentence chains. The Refiner processes each short sentence, a noun-phrase and verb-phrase pair, to direct visual tokens' self-attention across space then time, achieving efficient single-step refinement. A recurrent system chains these steps, maintaining refined visual token representations. The final representation feeds into task-specific heads for alignment generation. We demonstrate Planner-Refiner's effectiveness on two video-language alignment tasks: Referring Video Object Segmentation and Temporal Grounding with varying language complexity. We further introduce a new MeViS-X benchmark to assess models' capability with long queries. Superior performance versus state-of-the-art methods on these benchmarks shows the approach's potential, especially for complex prompts.",
    "source": "arXiv"
  },
  {
    "title": "Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants",
    "title_es": "Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants",
    "url": "https://arxiv.org/abs/2508.07333",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07333v1 Announce Type: new \nAbstract: Stochastic interpolants offer a robust framework for continuously transforming samples between arbitrary data distributions, holding significant promise for generative modeling. Despite their potential, rigorous finite-time convergence guarantees for practical numerical schemes remain largely unexplored. In this work, we address the finite-time convergence analysis of numerical implementations for ordinary differential equations (ODEs) derived from stochastic interpolants. Specifically, we establish novel finite-time error bounds in total variation distance for two widely used numerical integrators: the first-order forward Euler method and the second-order Heun's method. Furthermore, our analysis on the iteration complexity of specific stochastic interpolant constructions provides optimized schedules to enhance computational efficiency. Our theoretical findings are corroborated by numerical experiments, which validate the derived error bounds and complexity analyses.",
    "source": "arXiv"
  },
  {
    "title": "Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape",
    "title_es": "Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape",
    "url": "https://arxiv.org/abs/2508.07334",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07334v1 Announce Type: new \nAbstract: The illusion phenomenon of large language models (LLMs) is the core obstacle to their reliable deployment. This article formalizes the large language model as a probabilistic Turing machine by constructing a \"computational necessity hierarchy\", and for the first time proves the illusions are inevitable on diagonalization, incomputability, and information theory boundaries supported by the new \"learner pump lemma\". However, we propose two \"escape routes\": one is to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving their absolute escape through \"computational jumps\", providing the first formal theory for the effectiveness of RAGs; The second is to formalize continuous learning as an \"internalized oracle\" mechanism and implement this path through a novel neural game theory framework.Finally, this article proposes a",
    "source": "arXiv"
  },
  {
    "title": "CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation",
    "title_es": "CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation",
    "url": "https://arxiv.org/abs/2508.07341",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07341v1 Announce Type: new \nAbstract: The unified autoregressive (AR) model excels at multimodal understanding and generation, but its potential for customized image generation remains underexplored. Existing customized generation methods rely on full fine-tuning or adapters, making them costly and prone to overfitting or catastrophic forgetting. In this paper, we propose \\textbf{CoAR}, a novel framework for injecting subject concepts into the unified AR models while keeping all pre-trained parameters completely frozen. CoAR learns effective, specific subject representations with only a minimal number of parameters using a Layerwise Multimodal Context Learning strategy. To address overfitting and language drift, we further introduce regularization that preserves the pre-trained distribution and anchors context tokens to improve subject fidelity and re-contextualization. Additionally, CoAR supports training-free subject customization in a user-provided style. Experiments demonstrate that CoAR achieves superior performance on both subject-driven personalization and style personalization, while delivering significant gains in computational and memory efficiency. Notably, CoAR tunes less than \\textbf{0.05\\%} of the parameters while achieving competitive performance compared to recent Proxy-Tuning. Code: https://github.com/KZF-kzf/CoAR",
    "source": "arXiv"
  },
  {
    "title": "PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization",
    "title_es": "PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization",
    "url": "https://arxiv.org/abs/2508.07342",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07342v1 Announce Type: new \nAbstract: Personalized retrieval-augmented generation (RAG) aims to produce user-tailored responses by incorporating retrieved user profiles alongside the input query. Existing methods primarily focus on improving retrieval and rely on large language models (LLMs) to implicitly integrate the retrieved context with the query. However, such models are often sensitive to retrieval quality and may generate responses that are misaligned with user preferences. To address this limitation, we propose PrLM, a reinforcement learning framework that trains LLMs to explicitly reason over retrieved user profiles. Guided by a contrastively trained personalization reward model, PrLM effectively learns from user responses without requiring annotated reasoning paths. Experiments on three personalized text generation datasets show that PrLM outperforms existing methods and remains robust across varying numbers of retrieved profiles and different retrievers.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on Agentic Service Ecosystems: Measurement, Analysis, and Optimization",
    "title_es": "A Survey on Agentic Service Ecosystems: Measurement, Analysis, and Optimization",
    "url": "https://arxiv.org/abs/2508.07343",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07343v1 Announce Type: new \nAbstract: The Agentic Service Ecosystem consists of heterogeneous autonomous agents (e.g., intelligent machines, humans, and human-machine hybrid systems) that interact through resource exchange and service co-creation. These agents, with distinct behaviors and motivations, exhibit autonomous perception, reasoning, and action capabilities, which increase system complexity and make traditional linear analysis methods inadequate. Swarm intelligence, characterized by decentralization, self-organization, emergence, and dynamic adaptability, offers a novel theoretical lens and methodology for understanding and optimizing such ecosystems. However, current research, owing to fragmented perspectives and cross-ecosystem differences, fails to comprehensively capture the complexity of swarm-intelligence emergence in agentic contexts. The lack of a unified methodology further limits the depth and systematic treatment of the research. This paper proposes a framework for analyzing the emergence of swarm intelligence in Agentic Service Ecosystems, with three steps: measurement, analysis, and optimization, to reveal the cyclical mechanisms and quantitative criteria that foster emergence. By reviewing existing technologies, the paper analyzes their strengths and limitations, identifies unresolved challenges, and shows how this framework provides both theoretical support and actionable methods for real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis",
    "title_es": "ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis",
    "url": "https://arxiv.org/abs/2508.07345",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07345v1 Announce Type: new \nAbstract: \\textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is essential for genomic studies due to their crucial role as structural elements in bacteriophages. Computational tools, particularly machine learning, have emerged for annotating phage protein sequences from high-throughput sequencing. However, effective annotation requires specialized sequence encodings. Our paper introduces ProteoKnight, a new image-based encoding method that addresses spatial constraints in existing techniques, yielding competitive performance in PVP classification using pre-trained convolutional neural networks. Additionally, our study evaluates prediction uncertainty in binary PVP classification through Monte Carlo Dropout (MCD). \\textbf{Methods:} ProteoKnight adapts the classical DNA-Walk algorithm for protein sequences, incorporating pixel colors and adjusting walk distances to capture intricate protein features. Encoded sequences were classified using multiple pre-trained CNNs. Variance and entropy measures assessed prediction uncertainty across proteins of various classes and lengths. \\textbf{Results:} Our experiments achieved 90.8% accuracy in binary classification, comparable to state-of-the-art methods. Multi-class classification accuracy remains suboptimal. Our uncertainty analysis unveils variability in prediction confidence influenced by protein class and sequence length. \\textbf{Conclusions:} Our study surpasses frequency chaos game representation (FCGR) by introducing novel image encoding that mitigates spatial information loss limitations. Our classification technique yields accurate and robust PVP predictions while identifying low-confidence predictions.",
    "source": "arXiv"
  },
  {
    "title": "SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal",
    "title_es": "SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal",
    "url": "https://arxiv.org/abs/2508.07346",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07346v1 Announce Type: new \nAbstract: JPEG, as a widely used image compression standard, often introduces severe visual artifacts when achieving high compression ratios. Although existing deep learning-based restoration methods have made considerable progress, they often struggle to recover complex texture details, resulting in over-smoothed outputs. To overcome these limitations, we propose SODiff, a novel and efficient semantic-oriented one-step diffusion model for JPEG artifacts removal. Our core idea is that effective restoration hinges on providing semantic-oriented guidance to the pre-trained diffusion model, thereby fully leveraging its powerful generative prior. To this end, SODiff incorporates a semantic-aligned image prompt extractor (SAIPE). SAIPE extracts rich features from low-quality (LQ) images and projects them into an embedding space semantically aligned with that of the text encoder. Simultaneously, it preserves crucial information for faithful reconstruction. Furthermore, we propose a quality factor-aware time predictor that implicitly learns the compression quality factor (QF) of the LQ image and adaptively selects the optimal denoising start timestep for the diffusion process. Extensive experimental results show that our SODiff outperforms recent leading methods in both visual quality and quantitative metrics. Code is available at: https://github.com/frakenation/SODiff",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach",
    "title_es": "Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach",
    "url": "https://arxiv.org/abs/2508.07353",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07353v1 Announce Type: new \nAbstract: Numerous benchmarks have been built to evaluate the domain-specific abilities of large language models (LLMs), highlighting the need for effective and efficient benchmark construction. Existing domain-specific benchmarks primarily focus on the scaling law, relying on massive corpora for supervised fine-tuning or generating extensive question sets for broad coverage. However, the impact of corpus and question-answer (QA) set design on the precision and recall of domain-specific LLMs remains unexplored. In this paper, we address this gap and demonstrate that the scaling law is not always the optimal principle for benchmark construction in specific domains. Instead, we propose Comp-Comp, an iterative benchmarking framework based on a comprehensiveness-compactness principle. Here, comprehensiveness ensures semantic recall of the domain, while compactness enhances precision, guiding both corpus and QA set construction. To validate our framework, we conducted a case study in a well-renowned university, resulting in the creation of XUBench, a large-scale and comprehensive closed-domain benchmark. Although we use the academic domain as the case in this work, our Comp-Comp framework is designed to be extensible beyond academia, providing valuable insights for benchmark construction across various domains.",
    "source": "arXiv"
  },
  {
    "title": "GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction",
    "title_es": "GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction",
    "url": "https://arxiv.org/abs/2508.07355",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07355v1 Announce Type: new \nAbstract: Recent advances in Gaussian Splatting (GS) have demonstrated its effectiveness in photo-realistic rendering and 3D reconstruction. Among these, 2D Gaussian Splatting (2DGS) is particularly suitable for surface reconstruction due to its flattened Gaussian representation and integrated normal regularization. However, its performance often degrades in large-scale and complex urban scenes with frequent occlusions, leading to incomplete building reconstructions. We propose GS4Buildings, a novel prior-guided Gaussian Splatting method leveraging the ubiquity of semantic 3D building models for robust and scalable building surface reconstruction. Instead of relying on traditional Structure-from-Motion (SfM) pipelines, GS4Buildings initializes Gaussians directly from low-level Level of Detail (LoD)2 semantic 3D building models. Moreover, we generate prior depth and normal maps from the planar building geometry and incorporate them into the optimization process, providing strong geometric guidance for surface consistency and structural accuracy. We also introduce an optional building-focused mode that limits reconstruction to building regions, achieving a 71.8% reduction in Gaussian primitives and enabling a more efficient and compact representation. Experiments on urban datasets demonstrate that GS4Buildings improves reconstruction completeness by 20.5% and geometric accuracy by 32.8%. These results highlight the potential of semantic building model integration to advance GS-based reconstruction toward real-world urban applications such as smart cities and digital twins. Our project is available: https://github.com/zqlin0521/GS4Buildings.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Systematic Interoperability: Convergences and Mismatches between Web 3.0 and the EU Data Act",
    "title_es": "Enhancing Systematic Interoperability: Convergences and Mismatches between Web 3.0 and the EU Data Act",
    "url": "https://arxiv.org/abs/2508.07356",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07356v1 Announce Type: new \nAbstract: Interoperability is increasingly recognised as a foundational principle for fostering innovation, competition, and user autonomy in the evolving digital ecosystem. Existing research on interoperability predominantly focuses either on technological interoperability itself or on the legal regulations concerning interoperability, with insufficient exploration of their interdisciplinary intersection. This paper compares the technological interoperability in Web 3.0 with the theoretical framework of legal interoperability established by the EU Data Act, analysing the areas of convergence and mismatch. The goal is to align technical interoperability with legal concepts of interoperability, thereby enhancing the practical implementation of systematic interoperability in the next generation of the Web. This study finds that, firstly, Web 3.0's concept of interoperability spans data, systems, and applications, while the Data Act focuses solely on data. This narrow scope risks creating a fragmented ecosystem, where data exchange is possible, but full integration of systems and applications is hindered, leading to inefficiencies, and obstructing seamless data flow across platforms. Secondly, while Web 3.0 technically seeks to achieve interoperability through the integration of entire systems and decentralised applications, the compliance with Data Act might negatively limit such system and application interoperability through its data interoperability provisions. This paper suggests interdisciplinary recommendations to enhance the implementation and enforcement of interoperability. On one hand, the Data Act should broaden its concept of interoperability to encompass both the systems and applications layers. On the other hand, it is advisable to introduce provisions for standardised protocols through soft law mechanisms to address legal shortcomings and keep pace with technological advancements.",
    "source": "arXiv"
  },
  {
    "title": "Keyword Mamba: Spoken Keyword Spotting with State Space Models",
    "title_es": "Keyword Mamba: Spoken Keyword Spotting with State Space Models",
    "url": "https://arxiv.org/abs/2508.07363",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07363v1 Announce Type: new \nAbstract: Keyword spotting (KWS) is an essential task in speech processing. It is widely used in voice assistants and smart devices. Deep learning models like CNNs, RNNs, and Transformers have performed well in KWS. However, they often struggle to handle long-term patterns and stay efficient at the same time. In this work, we present Keyword Mamba, a new architecture for KWS. It uses a neural state space model (SSM) called Mamba. We apply Mamba along the time axis and also explore how it can replace the self-attention part in Transformer models. We test our model on the Google Speech Commands datasets. The results show that Keyword Mamba reaches strong accuracy with fewer parameters and lower computational cost. To our knowledge, this is the first time a state space model has been used for KWS. These results suggest that Mamba has strong potential in speech-related tasks.",
    "source": "arXiv"
  },
  {
    "title": "Training and Inference within 1 Second -- Tackle Cross-Sensor Degradation of Real-World Pansharpening with Efficient Residual Feature Tailoring",
    "title_es": "Training and Inference within 1 Second -- Tackle Cross-Sensor Degradation of Real-World Pansharpening with Efficient Residual Feature Tailoring",
    "url": "https://arxiv.org/abs/2508.07369",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07369v1 Announce Type: new \nAbstract: Deep learning methods for pansharpening have advanced rapidly, yet models pretrained on data from a specific sensor often generalize poorly to data from other sensors. Existing methods to tackle such cross-sensor degradation include retraining model or zero-shot methods, but they are highly time-consuming or even need extra training data. To address these challenges, our method first performs modular decomposition on deep learning-based pansharpening models, revealing a general yet critical interface where high-dimensional fused features begin mapping to the channel space of the final image. % may need revisement A Feature Tailor is then integrated at this interface to address cross-sensor degradation at the feature level, and is trained efficiently with physics-aware unsupervised losses. Moreover, our method operates in a patch-wise manner, training on partial patches and performing parallel inference on all patches to boost efficiency. Our method offers two key advantages: (1) $\\textit{Improved Generalization Ability}$: it significantly enhance performance in cross-sensor cases. (2) $\\textit{Low Generalization Cost}$: it achieves sub-second training and inference, requiring only partial test inputs and no external data, whereas prior methods often take minutes or even hours. Experiments on the real-world data from multiple datasets demonstrate that our method achieves state-of-the-art quality and efficiency in tackling cross-sensor degradation. For example, training and inference of $512\\times512\\times8$ image within $\\textit{0.2 seconds}$ and $4000\\times4000\\times8$ image within $\\textit{3 seconds}$ at the fastest setting on a commonly used RTX 3090 GPU, which is over 100 times faster than zero-shot methods.",
    "source": "arXiv"
  },
  {
    "title": "Intrinsic training dynamics of deep neural networks",
    "title_es": "Intrinsic training dynamics of deep neural networks",
    "url": "https://arxiv.org/abs/2508.07370",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07370v1 Announce Type: new \nAbstract: A fundamental challenge in the theory of deep learning is to understand whether gradient-based training in high-dimensional parameter spaces can be captured by simpler, lower-dimensional structures, leading to so-called implicit bias. As a stepping stone, we study when a gradient flow on a high-dimensional variable $\\theta$ implies an intrinsic gradient flow on a lower-dimensional variable $z = \\phi(\\theta)$, for an architecture-related function $\\phi$. We express a so-called intrinsic dynamic property and show how it is related to the study of conservation laws associated with the factorization $\\phi$. This leads to a simple criterion based on the inclusion of kernels of linear maps which yields a necessary condition for this property to hold. We then apply our theory to general ReLU networks of arbitrary depth and show that, for any initialization, it is possible to rewrite the flow as an intrinsic dynamic in a lower dimension that depends only on $z$ and the initialization, when $\\phi$ is the so-called path-lifting. In the case of linear networks with $\\phi$ the product of weight matrices, so-called balanced initializations are also known to enable such a dimensionality reduction; we generalize this result to a broader class of {\\em relaxed balanced} initializations, showing that, in certain configurations, these are the \\emph{only} initializations that ensure the intrinsic dynamic property. Finally, for the linear neural ODE associated with the limit of infinitely deep linear networks, with relaxed balanced initialization, we explicitly express the corresponding intrinsic dynamics.",
    "source": "arXiv"
  },
  {
    "title": "AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation",
    "title_es": "AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation",
    "url": "https://arxiv.org/abs/2508.07371",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07371v1 Announce Type: new \nAbstract: As the complexity of software systems continues to increase, the demand for automated testing and maintenance tools is growing exponentially. To meet this urgent need, we propose a new assertion generation method based on Hardware Description Language (HDL). This method combines a lightweight, parameter-adjustable large language model (LLM) with the Unsloth platform to automatically generate test cases, thereby significantly reducing training costs without sacrificing accuracy or generalization performance. Empirical evaluation shows that our method can efficiently generate assertions that strictly conform to the hardware logic. This framework provides a robust and flexible solution to modern software testing and maintenance challenges. https://github.com/liusu-orange/AutoAssert-1 and https://gitee.com/OpenBPU/auto-assert1 are the locations of the source code.",
    "source": "arXiv"
  },
  {
    "title": "DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery",
    "title_es": "DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery",
    "url": "https://arxiv.org/abs/2508.07372",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07372v1 Announce Type: new \nAbstract: 3D Gaussian Splatting (3DGS) is a leading 3D scene reconstruction method, obtaining high-quality reconstruction with real-time rendering runtime performance. The main idea behind 3DGS is to represent the scene as a collection of 3D gaussians, while learning their parameters to fit the given views of the scene. While achieving superior performance in the presence of many views, 3DGS struggles with sparse view reconstruction, where the input views are sparse and do not fully cover the scene and have low overlaps. In this paper, we propose DIP-GS, a Deep Image Prior (DIP) 3DGS representation. By using the DIP prior, which utilizes internal structure and patterns, with coarse-to-fine manner, DIP-based 3DGS can operate in scenarios where vanilla 3DGS fails, such as sparse view recovery. Note that our approach does not use any pre-trained models such as generative models and depth estimation, but rather relies only on the input frames. Among such methods, DIP-GS obtains state-of-the-art (SOTA) competitive results on various sparse-view reconstruction tasks, demonstrating its capabilities.",
    "source": "arXiv"
  },
  {
    "title": "Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance",
    "title_es": "Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance",
    "url": "https://arxiv.org/abs/2508.07375",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07375v1 Announce Type: new \nAbstract: Full-Duplex Speech Language Models (FD-SLMs) are specialized foundation models designed to enable natural, real-time spoken interactions by modeling complex conversational dynamics such as interruptions, backchannels, and overlapping speech, and End-to-end (e2e) FD-SLMs leverage real-world double-channel conversational data to capture nuanced two-speaker dialogue patterns for human-like interactions. However, they face a critical challenge -- their conversational abilities often degrade compared to pure-text conversation due to prolonged speech sequences and limited high-quality spoken dialogue data. While text-guided speech generation could mitigate these issues, it suffers from timing and length issues when integrating textual guidance into double-channel audio streams, disrupting the precise time alignment essential for natural interactions. To address these challenges, we propose TurnGuide, a novel planning-inspired approach that mimics human conversational planning by dynamically segmenting assistant speech into dialogue turns and generating turn-level text guidance before speech output, which effectively resolves both insertion timing and length challenges. Extensive experiments demonstrate our approach significantly improves e2e FD-SLMs' conversational abilities, enabling them to generate semantically meaningful and coherent speech while maintaining natural conversational flow. Demos are available at https://dreamtheater123.github.io/TurnGuide-Demo/. Code will be available at https://github.com/dreamtheater123/TurnGuide.",
    "source": "arXiv"
  },
  {
    "title": "A Multi-Model Probabilistic Framework for Seismic Risk Assessment and Retrofit Planning of Electric Power Networks",
    "title_es": "A Multi-Model Probabilistic Framework for Seismic Risk Assessment and Retrofit Planning of Electric Power Networks",
    "url": "https://arxiv.org/abs/2508.07376",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07376v1 Announce Type: new \nAbstract: Electric power networks are critical lifelines, and their disruption during earthquakes can lead to severe cascading failures and significantly hinder post-disaster recovery. Enhancing their seismic resilience requires identifying and strengthening vulnerable components in a cost-effective and system-aware manner. However, existing studies often overlook the systemic behavior of power networks under seismic loading. Common limitations include isolated component analyses that neglect network-wide interdependencies, oversimplified damage models assuming binary states or damage independence, and the exclusion of electrical operational constraints. These simplifications can result in inaccurate risk estimates and inefficient retrofit decisions. This study proposes a multi-model probabilistic framework for seismic risk assessment and retrofit planning of electric power systems. The approach integrates: (1) regional seismic hazard characterization with ground motion prediction and spatial correlation models; (2) component-level damage analysis using fragility functions and multi-state damage-functionality mappings; (3) system-level cascading impact evaluation through graph-based island detection and constrained optimal power flow analysis; and (4) retrofit planning via heuristic optimization to minimize expected annual functionality loss (EAFL) under budget constraints. Uncertainty is propagated throughout the framework using Monte Carlo simulation. The methodology is demonstrated on the IEEE 24-bus Reliability Test System, showcasing its ability to capture cascading failures, identify critical components, and generate effective retrofit strategies. Results underscore the potential of the framework as a scalable, data-informed decision-support tool for enhancing the seismic resilience of power infrastructure.",
    "source": "arXiv"
  },
  {
    "title": "Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning",
    "title_es": "Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.07382",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07382v1 Announce Type: new \nAbstract: Automating penetration testing is crucial for enhancing cybersecurity, yet current Large Language Models (LLMs) face significant limitations in this domain, including poor error handling, inefficient reasoning, and an inability to perform complex end-to-end tasks autonomously. To address these challenges, we introduce Pentest-R1, a novel framework designed to optimize LLM reasoning capabilities for this task through a two-stage reinforcement learning pipeline. We first construct a dataset of over 500 real-world, multi-step walkthroughs, which Pentest-R1 leverages for offline reinforcement learning (RL) to instill foundational attack logic. Subsequently, the LLM is fine-tuned via online RL in an interactive Capture The Flag (CTF) environment, where it learns directly from environmental feedback to develop robust error self-correction and adaptive strategies. Our extensive experiments on the Cybench and AutoPenBench benchmarks demonstrate the framework's effectiveness. On AutoPenBench, Pentest-R1 achieves a 24.2\\% success rate, surpassing most state-of-the-art models and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a 15.0\\% success rate in unguided tasks, establishing a new state-of-the-art for open-source LLMs and matching the performance of top proprietary models. Ablation studies confirm that the synergy of both training stages is critical to its success.",
    "source": "arXiv"
  },
  {
    "title": "MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control",
    "title_es": "MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control",
    "url": "https://arxiv.org/abs/2508.07387",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07387v1 Announce Type: new \nAbstract: Navigating unknown environments with a single RGB camera is challenging, as the lack of depth information prevents reliable collision-checking. While some methods use estimated depth to build collision maps, we found that depth estimates from vision foundation models are too noisy for zero-shot navigation in cluttered environments.\n  We propose an alternative approach: instead of using noisy estimated depth for direct collision-checking, we use it as a rich context input to a learned collision model. This model predicts the distribution of minimum obstacle clearance that the robot can expect for a given control sequence. At inference, these predictions inform a risk-aware MPC planner that minimizes estimated collision risk. Our joint learning pipeline co-trains the collision model and risk metric using both safe and unsafe trajectories. Crucially, our joint-training ensures optimal variance in our collision model that improves navigation in highly cluttered environments. Consequently, real-world experiments show 9x and 7x improvements in success rates over NoMaD and the ROS stack, respectively. Ablation studies further validate the effectiveness of our design choices.",
    "source": "arXiv"
  },
  {
    "title": "Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding",
    "title_es": "Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding",
    "url": "https://arxiv.org/abs/2508.07388",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07388v1 Announce Type: new \nAbstract: Temporal Video Grounding (TVG) seeks to localize video segments matching a given textual query. Current methods, while optimizing for high temporal Intersection-over-Union (IoU), often overfit to this metric, compromising semantic action understanding in the video and query, a critical factor for robust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG), a novel framework that enhances both localization accuracy and action understanding without additional data. Our approach leverages three inversion tasks derived from existing TVG annotations: (1) Verb Completion, predicting masked action verbs in queries from video segments; (2) Action Recognition, identifying query-described actions; and (3) Video Description, generating descriptions of video segments that explicitly embed query-relevant actions. These tasks, integrated with TVG via a reinforcement learning framework with well-designed reward functions, ensure balanced optimization of localization and semantics. Experiments show our method outperforms state-of-the-art approaches, achieving a 7.1\\% improvement in R1@0.7 on Charades-STA for a 3B model compared to Time-R1. By inverting TVG to derive query-related actions from segments, our approach strengthens semantic understanding, significantly raising the ceiling of localization accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Urbanite: A Dataflow-Based Framework for Human-AI Interactive Alignment in Urban Visual Analytics",
    "title_es": "Urbanite: A Dataflow-Based Framework for Human-AI Interactive Alignment in Urban Visual Analytics",
    "url": "https://arxiv.org/abs/2508.07390",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07390v1 Announce Type: new \nAbstract: With the growing availability of urban data and the increasing complexity of societal challenges, visual analytics has become essential for deriving insights into pressing real-world problems. However, analyzing such data is inherently complex and iterative, requiring expertise across multiple domains. The need to manage diverse datasets, distill intricate workflows, and integrate various analytical methods presents a high barrier to entry, especially for researchers and urban experts who lack proficiency in data management, machine learning, and visualization. Advancements in large language models offer a promising solution to lower the barriers to the construction of analytics systems by enabling users to specify intent rather than define precise computational operations. However, this shift from explicit operations to intent-based interaction introduces challenges in ensuring alignment throughout the design and development process. Without proper mechanisms, gaps can emerge between user intent, system behavior, and analytical outcomes. To address these challenges, we propose Urbanite, a framework for human-AI collaboration in urban visual analytics. Urbanite leverages a dataflow-based model that allows users to specify intent at multiple scopes, enabling interactive alignment across the specification, process, and evaluation stages of urban analytics. Based on findings from a survey to uncover challenges, Urbanite incorporates features to facilitate explainability, multi-resolution definition of tasks across dataflows, nodes, and parameters, while supporting the provenance of interactions. We demonstrate Urbanite's effectiveness through usage scenarios created in collaboration with urban experts. Urbanite is available at https://urbantk.org/urbanite.",
    "source": "arXiv"
  },
  {
    "title": "Tight Bounds for Schr\\\"odinger Potential Estimation in Unpaired Image-to-Image Translation Problems",
    "title_es": "Tight Bounds for Schr\\\"odinger Potential Estimation in Unpaired Image-to-Image Translation Problems",
    "url": "https://arxiv.org/abs/2508.07392",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07392v1 Announce Type: new \nAbstract: Modern methods of generative modelling and unpaired image-to-image translation based on Schr\\\"odinger bridges and stochastic optimal control theory aim to transform an initial density to a target one in an optimal way. In the present paper, we assume that we only have access to i.i.d. samples from initial and final distributions. This makes our setup suitable for both generative modelling and unpaired image-to-image translation. Relying on the stochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as the reference one and estimate the corresponding Schr\\\"odinger potential. Introducing a risk function as the Kullback-Leibler divergence between couplings, we derive tight bounds on generalization ability of an empirical risk minimizer in a class of Schr\\\"odinger potentials including Gaussian mixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we almost achieve fast rates of convergence up to some logarithmic factors in favourable scenarios. We also illustrate performance of the suggested approach with numerical experiments.",
    "source": "arXiv"
  },
  {
    "title": "The Search for Relevance: A Context-Aware Paradigm Shift in Semantic and Task-Oriented V2X Communications",
    "title_es": "The Search for Relevance: A Context-Aware Paradigm Shift in Semantic and Task-Oriented V2X Communications",
    "url": "https://arxiv.org/abs/2508.07394",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07394v1 Announce Type: new \nAbstract: The design of communication systems has traditionally focused on the reliable and timely delivery of data. However, the scalability challenges faced by the evolution to a 6G-driven society demand new communication paradigms that carefully curate the content being transmitted. This paper envisions a joint semantic and task-oriented communication paradigm where Connected and Autonomous Vehicles (CAVs) transmit only the information necessary to convey the desired meaning that is relevant to the intended receivers based on the communication context. The V2X domain offers a unique environment for the development of the envisioned semantic and task-oriented communications paradigm, as CAVs are native semantic devices, and the V2X domain is rich in contextual information. This contextual information can be leveraged to estimate the relevance that information may have for the intended receivers. We illustrate and quantitatively evaluate the potential benefits of semantic and task-oriented V2X communications. Numerical results show that by focusing on the transmission of the most relevant information for the intended receivers, semantic and task-oriented V2X communications can achieve a two-fold improvement in communication efficiency, which will significantly benefit the scalability of V2X networks.",
    "source": "arXiv"
  },
  {
    "title": "Parity Requires Unified Input Dependence and Negative Eigenvalues in SSMs",
    "title_es": "Parity Requires Unified Input Dependence and Negative Eigenvalues in SSMs",
    "url": "https://arxiv.org/abs/2508.07395",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07395v1 Announce Type: new \nAbstract: Recent work has shown that LRNN models such as S4D, Mamba, and DeltaNet lack state-tracking capability due to either time-invariant transition matrices or restricted eigenvalue ranges. To address this, input-dependent transition matrices, particularly those that are complex or non-triangular, have been proposed to enhance SSM performance on such tasks. While existing theorems demonstrate that both input-independent and non-negative SSMs are incapable of solving simple state-tracking tasks, such as parity, regardless of depth, they do not explore whether combining these two types in a multilayer SSM could help. We investigate this question for efficient SSMs with diagonal transition matrices and show that such combinations still fail to solve parity. This implies that a recurrence layer must both be input-dependent and include negative eigenvalues. Our experiments support this conclusion by analyzing an SSM model that combines S4D and Mamba layers.",
    "source": "arXiv"
  },
  {
    "title": "Are Multimodal Embeddings Truly Beneficial for Recommendation? A Deep Dive into Whole vs. Individual Modalities",
    "title_es": "Are Multimodal Embeddings Truly Beneficial for Recommendation? A Deep Dive into Whole vs. Individual Modalities",
    "url": "https://arxiv.org/abs/2508.07399",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07399v1 Announce Type: new \nAbstract: Multimodal recommendation (MMRec) has emerged as a mainstream paradigm, typically leveraging text and visual embeddings extracted from pre-trained models such as Sentence-BERT, Vision Transformers, and ResNet. This approach is founded on the intuitive assumption that incorporating multimodal embeddings can enhance recommendation performance. However, despite its popularity, this assumption lacks comprehensive empirical verification. This presents a critical research gap. To address it, we pose the central research question of this paper: Are multimodal embeddings truly beneficial for recommendation? To answer this question, we conduct a large-scale empirical study examining the role of text and visual embeddings in modern MMRec models, both as a whole and individually. Specifically, we pose two key research questions: (1) Do multimodal embeddings as a whole improve recommendation performance? (2) Is each individual modality - text and image - useful when used alone? To isolate the effect of individual modalities - text or visual - we employ a modality knockout strategy by setting the corresponding embeddings to either constant values or random noise. To ensure the scale and comprehensiveness of our study, we evaluate 14 widely used state-of-the-art MMRec models. Our findings reveal that: (1) multimodal embeddings generally enhance recommendation performance - particularly when integrated through more sophisticated graph-based fusion models. Surprisingly, commonly adopted baseline models with simple fusion schemes, such as VBPR and BM3, show only limited gains. (2) The text modality alone achieves performance comparable to the full multimodal setting in most cases, whereas the image modality alone does not. These results offer foundational insights and practical guidance for the MMRec community. We will release our code and datasets to facilitate future research.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors",
    "title_es": "Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors",
    "url": "https://arxiv.org/abs/2508.07400",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07400v1 Announce Type: new \nAbstract: In this paper, we consider the problem of recovering time-varying reward functions from either optimal policies or demonstrations coming from a max entropy reinforcement learning problem. This problem is highly ill-posed without additional assumptions on the underlying rewards. However, in many applications, the rewards are indeed parsimonious, and some prior information is available. We consider two such priors on the rewards: 1) rewards are mostly constant and they change infrequently, 2) rewards can be represented by a linear combination of a small number of feature functions. We first show that the reward identification problem with the former prior can be recast as a sparsification problem subject to linear constraints. Moreover, we give a polynomial-time algorithm that solves this sparsification problem exactly. Then, we show that identifying rewards representable with the minimum number of features can be recast as a rank minimization problem subject to linear constraints, for which convex relaxations of rank can be invoked. In both cases, these observations lead to efficient optimization-based reward identification algorithms. Several examples are given to demonstrate the accuracy of the recovered rewards as well as their generalizability.",
    "source": "arXiv"
  },
  {
    "title": "LET-US: Long Event-Text Understanding of Scenes",
    "title_es": "LET-US: Long Event-Text Understanding of Scenes",
    "url": "https://arxiv.org/abs/2508.07401",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07401v1 Announce Type: new \nAbstract: Event cameras output event streams as sparse, asynchronous data with microsecond-level temporal resolution, enabling visual perception with low latency and a high dynamic range. While existing Multimodal Large Language Models (MLLMs) have achieved significant success in understanding and analyzing RGB video content, they either fail to interpret event streams effectively or remain constrained to very short sequences. In this paper, we introduce LET-US, a framework for long event-stream--text comprehension that employs an adaptive compression mechanism to reduce the volume of input events while preserving critical visual details. LET-US thus establishes a new frontier in cross-modal inferential understanding over extended event sequences. To bridge the substantial modality gap between event streams and textual representations, we adopt a two-stage optimization paradigm that progressively equips our model with the capacity to interpret event-based scenes. To handle the voluminous temporal information inherent in long event streams, we leverage text-guided cross-modal queries for feature reduction, augmented by hierarchical clustering and similarity computation to distill the most representative event features. Moreover, we curate and construct a large-scale event-text aligned dataset to train our model, achieving tighter alignment of event features within the LLM embedding space. We also develop a comprehensive benchmark covering a diverse set of tasks -- reasoning, captioning, classification, temporal localization and moment retrieval. Experimental results demonstrate that LET-US outperforms prior state-of-the-art MLLMs in both descriptive accuracy and semantic comprehension on long-duration event streams. All datasets, codes, and models will be publicly available.",
    "source": "arXiv"
  },
  {
    "title": "ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack",
    "title_es": "ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack",
    "url": "https://arxiv.org/abs/2508.07402",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07402v1 Announce Type: new \nAbstract: Parameter-efficient fine-tuning (PEFT) has emerged as a popular strategy for adapting large vision foundation models, such as the Segment Anything Model (SAM) and LLaVA, to downstream tasks like image forgery detection and localization (IFDL). However, existing PEFT-based approaches overlook their vulnerability to adversarial attacks. In this paper, we show that highly transferable adversarial images can be crafted solely via the upstream model, without accessing the downstream model or training data, significantly degrading the IFDL performance. To address this, we propose ForensicsSAM, a unified IFDL framework with built-in adversarial robustness. Our design is guided by three key ideas: (1) To compensate for the lack of forgery-relevant knowledge in the frozen image encoder, we inject forgery experts into each transformer block to enhance its ability to capture forgery artifacts. These forgery experts are always activated and shared across any input images. (2) To detect adversarial images, we design an light-weight adversary detector that learns to capture structured, task-specific artifact in RGB domain, enabling reliable discrimination across various attack methods. (3) To resist adversarial attacks, we inject adversary experts into the global attention layers and MLP modules to progressively correct feature shifts induced by adversarial noise. These adversary experts are adaptively activated by the adversary detector, thereby avoiding unnecessary interference with clean images. Extensive experiments across multiple benchmarks demonstrate that ForensicsSAM achieves superior resistance to various adversarial attack methods, while also delivering state-of-the-art performance in image-level forgery detection and pixel-level forgery localization. The resource is available at https://github.com/siriusPRX/ForensicsSAM.",
    "source": "arXiv"
  },
  {
    "title": "Generative AI for Strategic Plan Development",
    "title_es": "Generative AI for Strategic Plan Development",
    "url": "https://arxiv.org/abs/2508.07405",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07405v1 Announce Type: new \nAbstract: Given recent breakthroughs in Generative Artificial Intelligence (GAI) and Large Language Models (LLMs), more and more professional services are being augmented through Artificial Intelligence (AI), which once seemed impossible to automate. This paper presents a modular model for leveraging GAI in developing strategic plans for large scale government organizations and evaluates leading machine learning techniques in their application towards one of the identified modules. Specifically, the performance of BERTopic and Non-negative Matrix Factorization (NMF) are evaluated in their ability to use topic modeling to generate themes representative of Vision Elements within a strategic plan. To accomplish this, BERTopic and NMF models are trained using a large volume of reports from the Government Accountability Office (GAO). The generated topics from each model are then scored for similarity against the Vision Elements of a published strategic plan and the results are compared. Our results show that these techniques are capable of generating themes similar to 100% of the elements being evaluated against. Further, we conclude that BERTopic performs best in this application with more than half of its correlated topics achieving a \"medium\" or \"strong\" correlation. A capability of GAI-enabled strategic plan development impacts a multi-billion dollar industry and assists the federal government in overcoming regulatory requirements which are crucial to the public good. Further work will focus on the operationalization of the concept proven in this study as well as viability of the remaining modules in the proposed model for GAI-generated strategic plans.",
    "source": "arXiv"
  },
  {
    "title": "AgriVLN: Vision-and-Language Navigation for Agricultural Robots",
    "title_es": "AgriVLN: Vision-and-Language Navigation for Agricultural Robots",
    "url": "https://arxiv.org/abs/2508.07406",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07406v1 Announce Type: new \nAbstract: Agricultural robots have emerged as powerful members in agricultural tasks, nevertheless, still heavily rely on manual operation or untransportable railway for movement, resulting in limited mobility and poor adaptability. Vision-and-Language Navigation (VLN) enables robots to navigate to the target destinations following natural language instructions, demonstrating strong performance on several domains. However, none of the existing benchmarks or methods is specifically designed for agricultural scenes. To bridge this gap, we propose Agriculture to Agriculture (A2A) benchmark, containing 1,560 episodes across six diverse agricultural scenes, in which all realistic RGB videos are captured by front-facing camera on a quadruped robot at a height of 0.38 meters, aligning with the practical deployment conditions. Meanwhile, we propose Vision-and-Language Navigation for Agricultural Robots (AgriVLN) baseline based on Vision-Language Model (VLM) prompted with carefully crafted templates, which can understand both given instructions and agricultural environments to generate appropriate low-level actions for robot control. When evaluated on A2A, AgriVLN performs well on short instructions but struggles with long instructions, because it often fails to track which part of the instruction is currently being executed. To address this, we further propose Subtask List (STL) instruction decomposition module and integrate it into AgriVLN, improving Success Rate (SR) from 0.33 to 0.47. We additionally compare AgriVLN with several existing VLN methods, demonstrating the state-of-the-art performance in the agricultural domain.",
    "source": "arXiv"
  },
  {
    "title": "A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems",
    "title_es": "A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems",
    "url": "https://arxiv.org/abs/2508.07407",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07407v1 Announce Type: new \nAbstract: Recent advances in large language models have sparked growing interest in AI agents capable of solving complex, real-world tasks. However, most existing agent systems rely on manually crafted configurations that remain static after deployment, limiting their ability to adapt to dynamic and evolving environments. To this end, recent research has explored agent evolution techniques that aim to automatically enhance agent systems based on interaction data and environmental feedback. This emerging direction lays the foundation for self-evolving AI agents, which bridge the static capabilities of foundation models with the continuous adaptability required by lifelong agentic systems. In this survey, we provide a comprehensive review of existing techniques for self-evolving agentic systems. Specifically, we first introduce a unified conceptual framework that abstracts the feedback loop underlying the design of self-evolving agentic systems. The framework highlights four key components: System Inputs, Agent System, Environment, and Optimisers, serving as a foundation for understanding and comparing different strategies. Based on this framework, we systematically review a wide range of self-evolving techniques that target different components of the agent system. We also investigate domain-specific evolution strategies developed for specialised fields such as biomedicine, programming, and finance, where optimisation objectives are tightly coupled with domain constraints. In addition, we provide a dedicated discussion on the evaluation, safety, and ethical considerations for self-evolving agentic systems, which are critical to ensuring their effectiveness and reliability. This survey aims to provide researchers and practitioners with a systematic understanding of self-evolving AI agents, laying the foundation for the development of more adaptive, autonomous, and lifelong agentic systems.",
    "source": "arXiv"
  },
  {
    "title": "CharacterShot: Controllable and Consistent 4D Character Animation",
    "title_es": "CharacterShot: Controllable and Consistent 4D Character Animation",
    "url": "https://arxiv.org/abs/2508.07409",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07409v1 Announce Type: new \nAbstract: In this paper, we propose \\textbf{CharacterShot}, a controllable and consistent 4D character animation framework that enables any individual designer to create dynamic 3D characters (i.e., 4D character animation) from a single reference character image and a 2D pose sequence. We begin by pretraining a powerful 2D character animation model based on a cutting-edge DiT-based image-to-video model, which allows for any 2D pose sequnce as controllable signal. We then lift the animation model from 2D to 3D through introducing dual-attention module together with camera prior to generate multi-view videos with spatial-temporal and spatial-view consistency. Finally, we employ a novel neighbor-constrained 4D gaussian splatting optimization on these multi-view videos, resulting in continuous and stable 4D character representations. Moreover, to improve character-centric performance, we construct a large-scale dataset Character4D, containing 13,115 unique characters with diverse appearances and motions, rendered from multiple viewpoints. Extensive experiments on our newly constructed benchmark, CharacterBench, demonstrate that our approach outperforms current state-of-the-art methods. Code, models, and datasets will be publicly available at https://github.com/Jeoyal/CharacterShot.",
    "source": "arXiv"
  },
  {
    "title": "CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization",
    "title_es": "CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization",
    "url": "https://arxiv.org/abs/2508.07413",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07413v1 Announce Type: new \nAbstract: The increasing accessibility of image editing tools and generative AI has led to a proliferation of visually convincing forgeries, compromising the authenticity of digital media. In this paper, in addition to leveraging distortions from conventional forgeries, we repurpose the mechanism of a state-of-the-art (SOTA) text-to-image synthesis model by exploiting its internal generative process, turning it into a high-fidelity forgery localization tool. To this end, we propose CLUE (Capture Latent Uncovered Evidence), a framework that employs Low- Rank Adaptation (LoRA) to parameter-efficiently reconfigure Stable Diffusion 3 (SD3) as a forensic feature extractor. Our approach begins with the strategic use of SD3's Rectified Flow (RF) mechanism to inject noise at varying intensities into the latent representation, thereby steering the LoRAtuned denoising process to amplify subtle statistical inconsistencies indicative of a forgery. To complement the latent analysis with high-level semantic context and precise spatial details, our method incorporates contextual features from the image encoder of the Segment Anything Model (SAM), which is parameter-efficiently adapted to better trace the boundaries of forged regions. Extensive evaluations demonstrate CLUE's SOTA generalization performance, significantly outperforming prior methods. Furthermore, CLUE shows superior robustness against common post-processing attacks and Online Social Networks (OSNs). Code is publicly available at https://github.com/SZAISEC/CLUE.",
    "source": "arXiv"
  },
  {
    "title": "Grounding Multilingual Multimodal LLMs With Cultural Knowledge",
    "title_es": "Grounding Multilingual Multimodal LLMs With Cultural Knowledge",
    "url": "https://arxiv.org/abs/2508.07414",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07414v1 Announce Type: new \nAbstract: Multimodal Large Language Models excel in high-resource settings, but often misinterpret long-tail cultural entities and underperform in low-resource languages. To address this gap, we propose a data-centric approach that directly grounds MLLMs in cultural knowledge. Leveraging a large scale knowledge graph from Wikidata, we collect images that represent culturally significant entities, and generate synthetic multilingual visual question answering data. The resulting dataset, CulturalGround, comprises 22 million high-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages. We train an open-source MLLM CulturalPangea on CulturalGround, interleaving standard multilingual instruction-tuning data to preserve general abilities. CulturalPangea achieves state-of-the-art performance among open models on various culture-focused multilingual multimodal benchmarks, outperforming prior models by an average of 5.0 without degrading results on mainstream vision-language tasks. Our findings show that our targeted, culturally grounded approach could substantially narrow the cultural gap in MLLMs and offer a practical path towards globally inclusive multimodal systems.",
    "source": "arXiv"
  },
  {
    "title": "Robust, fast, and adaptive splitting schemes for nonlinear doubly-degenerate diffusion equations",
    "title_es": "Robust, fast, and adaptive splitting schemes for nonlinear doubly-degenerate diffusion equations",
    "url": "https://arxiv.org/abs/2508.07420",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07420v1 Announce Type: new \nAbstract: We consider linear iterative schemes for the time-discrete equations stemming from a class of nonlinear, doubly-degenerate parabolic equations. More precisely, the diffusion is nonlinear and may vanish or become multivalued for certain values of the unknown, so the parabolic equation becomes hyperbolic or elliptic, respectively. After performing an Euler implicit time-stepping, a splitting strategy is applied to the time-discrete equations. This leads to a formulation that is more suitable for dealing with the degeneracies. Based on this splitting, different iterative linearization strategies are considered, namely the Newton scheme, the L-scheme, and the modified L-scheme. We prove the convergence of the latter two schemes even for the double-degenerate case. In the non-degenerate case, we prove that the scheme is contractive, and the contraction rate is proportional to a non-negative exponent of the time-step size. Moreover, an a posteriori estimator-based adaptive algorithm is developed to select the optimal parameters for the M-scheme, which accelerates its convergence. Numerical results are presented, showing that the M- and the M-adaptive schemes are more stable than the Newton scheme, as they converge irrespective of the mesh. Moreover, the adaptive M-scheme consistently out-competes not only the M/L-schemes, but also the Newton scheme showing quadratic convergence behavior.",
    "source": "arXiv"
  },
  {
    "title": "Triple-S: A Collaborative Multi-LLM Framework for Solving Long-Horizon Implicative Tasks in Robotics",
    "title_es": "Triple-S: A Collaborative Multi-LLM Framework for Solving Long-Horizon Implicative Tasks in Robotics",
    "url": "https://arxiv.org/abs/2508.07421",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07421v1 Announce Type: new \nAbstract: Leveraging Large Language Models (LLMs) to write policy code for controlling robots has gained significant attention. However, in long-horizon implicative tasks, this approach often results in API parameter, comments and sequencing errors, leading to task failure. To address this problem, we propose a collaborative Triple-S framework that involves multiple LLMs. Through In-Context Learning, different LLMs assume specific roles in a closed-loop Simplification-Solution-Summary process, effectively improving success rates and robustness in long-horizon implicative tasks. Additionally, a novel demonstration library update mechanism which learned from success allows it to generalize to previously failed tasks. We validate the framework in the Long-horizon Desktop Implicative Placement (LDIP) dataset across various baseline models, where Triple-S successfully executes 89% of tasks in both observable and partially observable scenarios. Experiments in both simulation and real-world robot settings further validated the effectiveness of Triple-S. Our code and dataset is available at: https://github.com/Ghbbbbb/Triple-S.",
    "source": "arXiv"
  },
  {
    "title": "RNA-KG v2.0: An RNA-centered Knowledge Graph with Properties",
    "title_es": "RNA-KG v2.0: An RNA-centered Knowledge Graph with Properties",
    "url": "https://arxiv.org/abs/2508.07427",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07427v1 Announce Type: new \nAbstract: RNA-KG is a recently developed knowledge graph that integrates the interactions involving coding and non-coding RNA molecules extracted from public data sources. It can be used to support the classification of new molecules, identify new interactions through the use of link prediction methods, and reveal hidden patterns among the represented entities. In this paper, we propose RNA-KG v2.0, a new release of RNA-KG that integrates around 100M manually curated interactions sourced from 91 linked open data repositories and ontologies. Relationships are characterized by standardized properties that capture the specific context (e.g., cell line, tissue, pathological state) in which they have been identified. In addition, the nodes are enriched with detailed attributes, such as descriptions, synonyms, and molecular sequences sourced from platforms such as OBO ontologies, NCBI repositories, RNAcentral, and Ensembl. The enhanced repository enables the expression of advanced queries that take into account the context in which the experiments were conducted. It also supports downstream applications in RNA research, including \"context-aware\" link prediction techniques that combine both topological and semantic information.",
    "source": "arXiv"
  },
  {
    "title": "Lightning Prediction under Uncertainty: DeepLight with Hazy Loss",
    "title_es": "Lightning Prediction under Uncertainty: DeepLight with Hazy Loss",
    "url": "https://arxiv.org/abs/2508.07428",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07428v1 Announce Type: new \nAbstract: Lightning, a common feature of severe meteorological conditions, poses significant risks, from direct human injuries to substantial economic losses. These risks are further exacerbated by climate change. Early and accurate prediction of lightning would enable preventive measures to safeguard people, protect property, and minimize economic losses. In this paper, we present DeepLight, a novel deep learning architecture for predicting lightning occurrences. Existing prediction models face several critical limitations: they often struggle to capture the dynamic spatial context and inherent uncertainty of lightning events, underutilize key observational data, such as radar reflectivity and cloud properties, and rely heavily on Numerical Weather Prediction (NWP) systems, which are both computationally expensive and highly sensitive to parameter settings. To overcome these challenges, DeepLight leverages multi-source meteorological data, including radar reflectivity, cloud properties, and historical lightning occurrences through a dual-encoder architecture. By employing multi-branch convolution techniques, it dynamically captures spatial correlations across varying extents. Furthermore, its novel Hazy Loss function explicitly addresses the spatio-temporal uncertainty of lightning by penalizing deviations based on proximity to true events, enabling the model to better learn patterns amidst randomness. Extensive experiments show that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over state-of-the-art methods, establishing it as a robust solution for lightning prediction.",
    "source": "arXiv"
  },
  {
    "title": "Freeze and Reveal: Exposing Modality Bias in Vision-Language Models",
    "title_es": "Freeze and Reveal: Exposing Modality Bias in Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.07432",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07432v1 Announce Type: new \nAbstract: Vision Language Models achieve impressive multi-modal performance but often inherit gender biases from their training data. This bias might be coming from both the vision and text modalities. In this work, we dissect the contributions of vision and text backbones to these biases by applying targeted debiasing using Counterfactual Data Augmentation and Task Vector methods. Inspired by data-efficient approaches in hate-speech classification, we introduce a novel metric, Degree of Stereotypicality and a corresponding debiasing method, Data Augmentation Using Degree of Stereotypicality - DAUDoS, to reduce bias with minimal computational cost. We curate a gender annotated dataset and evaluate all methods on VisoGender benchmark to quantify improvements and identify dominant source of bias. Our results show that CDA reduces the gender gap by 6% and DAUDoS by 3% but using only one-third of the data. Both methods also improve the model's ability to correctly identify gender in images by 3%, with DAUDoS achieving this improvement using only almost one-third of training data. From our experiment's, we observed that CLIP's vision encoder is more biased whereas PaliGemma2's text encoder is more biased. By identifying whether bias stems more from vision or text encoders, our work enables more targeted and effective bias mitigation strategies in future multi-modal systems.",
    "source": "arXiv"
  },
  {
    "title": "Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs",
    "title_es": "Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs",
    "url": "https://arxiv.org/abs/2508.07434",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07434v1 Announce Type: new \nAbstract: Large Language Models (LLMs) with inference-time scaling techniques show promise for code generation, yet face notable efficiency and scalability challenges. Construction-based tree-search methods suffer from rapid growth in tree size, high token consumption, and lack of anytime property. In contrast, improvement-based methods offer better performance but often struggle with uninformative reward signals and inefficient search strategies. In this work, we propose \\textbf{ReLoc}, a unified local search framework which effectively performs step-by-step code revision. Specifically, ReLoc explores a series of local revisions through four key algorithmic components: initial code drafting, neighborhood code generation, candidate evaluation, and incumbent code updating, each of which can be instantiated with specific decision rules to realize different local search algorithms such as Hill Climbing (HC) or Genetic Algorithm (GA). Furthermore, we develop a specialized revision reward model that evaluates code quality based on revision distance to produce fine-grained preferences that guide the local search toward more promising candidates. Finally, our extensive experimental results demonstrate that our approach achieves superior performance across diverse code generation tasks, significantly outperforming both construction-based tree search as well as the state-of-the-art improvement-based code generation methods.",
    "source": "arXiv"
  },
  {
    "title": "Unsupervised operator learning approach for dissipative equations via Onsager principle",
    "title_es": "Unsupervised operator learning approach for dissipative equations via Onsager principle",
    "url": "https://arxiv.org/abs/2508.07440",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07440v1 Announce Type: new \nAbstract: Existing operator learning methods rely on supervised training with high-fidelity simulation data, introducing significant computational cost. In this work, we propose the deep Onsager operator learning (DOOL) method, a novel unsupervised framework for solving dissipative equations. Rooted in the Onsager variational principle (OVP), DOOL trains a deep operator network by directly minimizing the OVP-defined Rayleighian functional, requiring no labeled data, and then proceeds in time explicitly through conservation/change laws for the solution. Another key innovation here lies in the spatiotemporal decoupling strategy: the operator's trunk network processes spatial coordinates exclusively, thereby enhancing training efficiency, while integrated external time stepping enables temporal extrapolation. Numerical experiments on typical dissipative equations validate the effectiveness of the DOOL method, and systematic comparisons with supervised DeepONet and MIONet demonstrate its enhanced performance. Extensions are made to cover the second-order wave models with dissipation that do not directly follow OVP.",
    "source": "arXiv"
  },
  {
    "title": "Levarging Learning Bias for Noisy Anomaly Detection",
    "title_es": "Levarging Learning Bias for Noisy Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.07441",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07441v1 Announce Type: new \nAbstract: This paper addresses the challenge of fully unsupervised image anomaly detection (FUIAD), where training data may contain unlabeled anomalies. Conventional methods assume anomaly-free training data, but real-world contamination leads models to absorb anomalies as normal, degrading detection performance. To mitigate this, we propose a two-stage framework that systematically exploits inherent learning bias in models. The learning bias stems from: (1) the statistical dominance of normal samples, driving models to prioritize learning stable normal patterns over sparse anomalies, and (2) feature-space divergence, where normal data exhibit high intra-class consistency while anomalies display high diversity, leading to unstable model responses. Leveraging the learning bias, stage 1 partitions the training set into subsets, trains sub-models, and aggregates cross-model anomaly scores to filter a purified dataset. Stage 2 trains the final detector on this dataset. Experiments on the Real-IAD benchmark demonstrate superior anomaly detection and localization performance under different noise conditions. Ablation studies further validate the framework's contamination resilience, emphasizing the critical role of learning bias exploitation. The model-agnostic design ensures compatibility with diverse unsupervised backbones, offering a practical solution for real-world scenarios with imperfect training data. Code is available at https://github.com/hustzhangyuxin/LLBNAD.",
    "source": "arXiv"
  },
  {
    "title": "Optimizing Districting Plans to Maximize Majority-Minority Districts via IPs and Local Search",
    "title_es": "Optimizing Districting Plans to Maximize Majority-Minority Districts via IPs and Local Search",
    "url": "https://arxiv.org/abs/2508.07446",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07446v1 Announce Type: new \nAbstract: In redistricting litigation, effective enforcement of the Voting Rights Act has often involved providing the court with districting plans that display a larger number of majority-minority districts than the current proposal (as was true, for example, in what followed Allen v. Milligan concerning the congressional districting plan for Alabama in 2023). Recent work by Cannon et al. proposed a heuristic algorithm for generating plans to optimize majority-minority districts, which they called short bursts; that algorithm relies on a sophisticated random walk over the space of all plans, transitioning in bursts, where the initial plan for each burst is the most successful plan from the previous burst. We propose a method based on integer programming, where we build upon another previous work, the stochastic hierarchical partitioning algorithm, which heuristically generates a robust set of potential districts (viewed as columns in a standard set partitioning formulation); that approach was designed to optimize a different notion of fairness across a statewide plan. We design a new column generation algorithm to find plans via integer programming that outperforms short bursts on multiple data sets in generating statewide plans with significantly more majority-minority districts. These results also rely on a new local re-optimization algorithm to iteratively improve on any baseline solution, as well as an algorithm to increase the compactness of districts in plans generated (without impacting the number of majority-minority districts).",
    "source": "arXiv"
  },
  {
    "title": "Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines",
    "title_es": "Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines",
    "url": "https://arxiv.org/abs/2508.07450",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07450v1 Announce Type: new \nAbstract: The increasing number of Health Care facilities in Nepal has also added up the challenges on managing health care waste (HCW). Improper segregation and disposal of HCW leads to the contamination, spreading of infectious diseases and puts a risk of waste handlers. This study benchmarks the state of the art waste classification models: ResNeXt-50, EfficientNet-B0, MobileNetV3-S, YOLOv8-n and YOLOv5-s using Stratified K-fold techniques where we use 5 folds on combined HCW data, and found that the YOLOv5-s achieved higher of 95.06% accuracy but fell short few milliseconds in inference speed with YOLOv8-n model. The EfficientNet-B0 showed promising results of 93.22% accuracy but took the highest inference time. A repetitive ANOVA was performed to see statistical significance and the best performing model (YOLOv5-s) was deployed to the web with mapped bin color using Nepal's HCW management standards for public usage. Further work on the data was suggested along with localized context.",
    "source": "arXiv"
  },
  {
    "title": "Stackelberg Coupling of Online Representation Learning and Reinforcement Learning",
    "title_es": "Stackelberg Coupling of Online Representation Learning and Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.07452",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07452v1 Announce Type: new \nAbstract: Integrated, end-to-end learning of representations and policies remains a cornerstone of deep reinforcement learning (RL). However, to address the challenge of learning effective features from a sparse reward signal, recent trends have shifted towards adding complex auxiliary objectives or fully decoupling the two processes, often at the cost of increased design complexity. This work proposes an alternative to both decoupling and naive end-to-end learning, arguing that performance can be significantly improved by structuring the interaction between distinct perception and control networks with a principled, game-theoretic dynamic. We formalize this dynamic by introducing the Stackelberg Coupled Representation and Reinforcement Learning (SCORER) framework, which models the interaction between perception and control as a Stackelberg game. The perception network (leader) strategically learns features to benefit the control network (follower), whose own objective is to minimize its Bellman error. We approximate the game's equilibrium with a practical two-timescale algorithm. Applied to standard DQN variants on benchmark tasks, SCORER improves sample efficiency and final performance. Our results show that performance gains can be achieved through principled algorithmic design of the perception-control dynamic, without requiring complex auxiliary objectives or architectures.",
    "source": "arXiv"
  },
  {
    "title": "Noise-Aware Generative Microscopic Traffic Simulation",
    "title_es": "Noise-Aware Generative Microscopic Traffic Simulation",
    "url": "https://arxiv.org/abs/2508.07453",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07453v1 Announce Type: new \nAbstract: Accurately modeling individual vehicle behavior in microscopic traffic simulation remains a key challenge in intelligent transportation systems, as it requires vehicles to realistically generate and respond to complex traffic phenomena such as phantom traffic jams. While traditional human driver simulation models offer computational tractability, they do so by abstracting away the very complexity that defines human driving. On the other hand, recent advances in infrastructure-mounted camera-based roadway sensing have enabled the extraction of vehicle trajectory data, presenting an opportunity to shift toward generative, agent-based models. Yet, a major bottleneck remains: most existing datasets are either overly sanitized or lack standardization, failing to reflect the noisy, imperfect nature of real-world sensing. Unlike data from vehicle-mounted sensors-which can mitigate sensing artifacts like occlusion through overlapping fields of view and sensor fusion-infrastructure-based sensors surface a messier, more practical view of challenges that traffic engineers encounter. To this end, we present the I-24 MOTION Scenario Dataset (I24-MSD)-a standardized, curated dataset designed to preserve a realistic level of sensor imperfection, embracing these errors as part of the learning problem rather than an obstacle to overcome purely from preprocessing. Drawing from noise-aware learning strategies in computer vision, we further adapt existing generative models in the autonomous driving community for I24-MSD with noise-aware loss functions. Our results show that such models not only outperform traditional baselines in realism but also benefit from explicitly engaging with, rather than suppressing, data imperfection. We view I24-MSD as a stepping stone toward a new generation of microscopic traffic simulation that embraces the real-world challenges and is better aligned with practical needs.",
    "source": "arXiv"
  },
  {
    "title": "An Empirical Inquiry into Surveillance Capitalism: Web Tracking",
    "title_es": "An Empirical Inquiry into Surveillance Capitalism: Web Tracking",
    "url": "https://arxiv.org/abs/2508.07454",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07454v1 Announce Type: new \nAbstract: The modern web is increasingly characterized by the pervasiveness of Surveillance Capitalism. This investigation employs an empirical approach to examine this phenomenon through the web tracking practices of major tech companies -- specifically Google, Apple, Facebook, Amazon, and Microsoft (GAFAM) -- and their relation to financial performance indicators. Using longitudinal data from WhoTracks.Me spanning from 2017 to 2025 and publicly accessible SEC filings, this paper analyzes patterns and trends in web tracking data to establish empirical evidence of Surveillance Capitalism's extraction mechanisms. Our findings reveal Google's omnipresent position on the web, a three-tier stratification among GAFAM companies in the surveillance space, and evidence suggesting an evolution of tracking techniques to evade detection. The investigation further discusses the social and environmental costs of web tracking and how alternative technologies, such as the Gemini protocol, offer pathways to challenge the extractive logic of this new economic order. By closely examining surveillance activities, this research contributes to an ongoing effort to better understand the current state and future trajectory of Surveillance Capitalism.",
    "source": "arXiv"
  },
  {
    "title": "The Monte Carlo Method and New Device and Architectural Techniques for Accelerating It",
    "title_es": "The Monte Carlo Method and New Device and Architectural Techniques for Accelerating It",
    "url": "https://arxiv.org/abs/2508.07457",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07457v1 Announce Type: new \nAbstract: Computing systems interacting with real-world processes must safely and reliably process uncertain data. The Monte Carlo method is a popular approach for computing with such uncertain values. This article introduces a framework for describing the Monte Carlo method and highlights two advances in the domain of physics-based non-uniform random variate generators (PPRVGs) to overcome common limitations of traditional Monte Carlo sampling. This article also highlights recent advances in architectural techniques that eliminate the need to use the Monte Carlo method by leveraging distributional microarchitectural state to natively compute on probability distributions. Unlike Monte Carlo methods, uncertainty-tracking processor architectures can be said to be convergence-oblivious.",
    "source": "arXiv"
  },
  {
    "title": "Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten",
    "title_es": "Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten",
    "url": "https://arxiv.org/abs/2508.07458",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07458v1 Announce Type: new \nAbstract: Currently, various uncertainty quantification methods have been proposed to provide certainty and probability estimates for deep learning models' label predictions. Meanwhile, with the growing demand for the right to be forgotten, machine unlearning has been extensively studied as a means to remove the impact of requested sensitive data from a pre-trained model without retraining the model from scratch. However, the vulnerabilities of such generated predictive uncertainties with regard to dedicated malicious unlearning attacks remain unexplored. To bridge this gap, for the first time, we propose a new class of malicious unlearning attacks against predictive uncertainties, where the adversary aims to cause the desired manipulations of specific predictive uncertainty results. We also design novel optimization frameworks for our attacks and conduct extensive experiments, including black-box scenarios. Notably, our extensive experiments show that our attacks are more effective in manipulating predictive uncertainties than traditional attacks that focus on label misclassifications, and existing defenses against conventional attacks are ineffective against our attacks.",
    "source": "arXiv"
  },
  {
    "title": "Duality on group algebras over finite chain rings: applications to additive group codes",
    "title_es": "Duality on group algebras over finite chain rings: applications to additive group codes",
    "url": "https://arxiv.org/abs/2508.07461",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07461v1 Announce Type: new \nAbstract: Given a finite group $G$ and an extension of finite chain rings $S|R$, one can consider the group rings $\\mathscr{S} = S[G]$ and $\\mathscr{R} = R[G]$. The group ring $\\mathscr{S}$ can be viewed as an $R$-bimodule, and any of its $R$-submodules naturally inherits an $R$-bimodule structure; in the framework of coding theory, these are called \\emph{additive group codes}, more precisely a (left) additive group code of is a linear code which is the image of a (left) ideal of a group algebra via an isomorphism which maps $G$ to the standard basis of $S^n$, where $n=|G|$. In the first part of the paper, the ring extension $S|R$ is studied, and several $R$-module isomorphisms are established for decomposing group rings, thereby providing a characterization of the structure of additive group codes. In the second part, we construct a symmetric, nondegenerate trace-Euclidean inner product on $\\mathscr{S}$. Two additive group codes $\\mathcal{C}$ and $\\mathcal{D}$ form an \\emph{additive complementary pair} (ACP) if $\\mathcal{C} + \\mathcal{D} = \\mathscr{S}$ and $\\mathcal{C} \\cap \\mathcal{D} = \\{0\\}$. For two-sided ACPs, we prove that the orthogonal complement of one code under the trace-Euclidean duality is precisely the image of the other under an involutive anti-automorphism of $\\mathscr{S}$, linking coding-theoretical ACPs with module orthogonal direct-sum decompositions, representation theory, and the structure of group algebras over finite chain rings.",
    "source": "arXiv"
  },
  {
    "title": "MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification",
    "title_es": "MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification",
    "url": "https://arxiv.org/abs/2508.07465",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07465v1 Announce Type: new \nAbstract: Integrating multi-omics data, such as DNA methylation, mRNA expression, and microRNA (miRNA) expression, offers a comprehensive view of the biological mechanisms underlying disease. However, the high dimensionality and complex interactions among omics layers present major challenges for predictive modeling. We propose Multi-Omics integration with Tree-generated Graph Neural Network (MOTGNN), a novel and interpretable framework for binary disease classification. MOTGNN employs eXtreme Gradient Boosting (XGBoost) to perform omics-specific supervised graph construction, followed by modality-specific Graph Neural Networks (GNNs) for hierarchical representation learning, and a deep feedforward network for cross-omics integration. On three real-world disease datasets, MOTGNN outperforms state-of-the-art baselines by 5-10% in accuracy, ROC-AUC, and F1-score, and remains robust to severe class imbalance (e.g., 87.2% vs. 33.4% F1 on imbalanced data). The model maintains computational efficiency through sparse graphs (2.1-2.8 edges per node) and provides built-in interpretability, revealing both top-ranked biomarkers and the relative contributions of each omics modality. These results highlight MOTGNN's potential to improve both predictive accuracy and interpretability in multi-omics disease modeling.",
    "source": "arXiv"
  },
  {
    "title": "Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs",
    "title_es": "Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs",
    "url": "https://arxiv.org/abs/2508.07466",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07466v1 Announce Type: new \nAbstract: Language is a ubiquitous tool that is foundational to reasoning and collaboration, ranging from everyday interactions to sophisticated problem-solving tasks. The establishment of a common language can serve as a powerful asset in ensuring clear communication and understanding amongst agents, facilitating desired coordination and strategies. In this work, we extend the capabilities of large language models (LLMs) by integrating them with advancements in multi-agent decision-making algorithms. We propose a systematic framework for the design of multi-agentic large language models (LLMs), focusing on key integration practices. These include advanced prompt engineering techniques, the development of effective memory architectures, multi-modal information processing, and alignment strategies through fine-tuning algorithms. We evaluate these design choices through extensive ablation studies on classic game settings with significant underlying social dilemmas and game-theoretic considerations.",
    "source": "arXiv"
  },
  {
    "title": "CP-Agent: Agentic Constraint Programming",
    "title_es": "CP-Agent: Agentic Constraint Programming",
    "url": "https://arxiv.org/abs/2508.07468",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07468v1 Announce Type: new \nAbstract: Translating natural language problem descriptions into formal constraint models remains a fundamental challenge in constraint programming, requiring deep expertise in both the problem domain and modeling frameworks. Previous approaches to automating this translation have employed fixed workflows with predetermined modeling steps, failing on a significant number of benchmark problems. We present a new approach using a pure agentic strategy without any fixed pipeline. We developed a general-purpose Python coding agent based on the ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for stateful code execution and iterative development. Rather than embedding constraint programming logic into the agent architecture, domain-specific expertise is injected solely through a carefully crafted project prompt. The agent combines this prompt-encoded knowledge with access to file operations and code execution tools, enabling it to test hypotheses, debug failures, and verify solutions dynamically. Implemented in just a few hundred lines of code, this architecture successfully solves all 101 problems of the CP-Bench constraint programming benchmark set. The results suggest that constraint modeling tasks require the combination of general coding tools and domain expertise encoded in prompts, rather than specialized agent architectures or predefined workflows.",
    "source": "arXiv"
  },
  {
    "title": "AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning",
    "title_es": "AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning",
    "url": "https://arxiv.org/abs/2508.07470",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07470v1 Announce Type: new \nAbstract: Current audio-visual (AV) benchmarks focus on final answer accuracy, overlooking the underlying reasoning process. This makes it difficult to distinguish genuine comprehension from correct answers derived through flawed reasoning or hallucinations. To address this, we introduce AURA (Audio-visual Understanding and Reasoning Assessment), a benchmark for evaluating the cross-modal reasoning capabilities of Audio-Visual Large Language Models (AV-LLMs) and Omni-modal Language Models (OLMs). AURA includes questions across six challenging cognitive domains, such as causality, timbre and pitch, tempo and AV synchronization, unanswerability, implicit distractions, and skill profiling, explicitly designed to be unanswerable from a single modality. This forces models to construct a valid logical path grounded in both audio and video, setting AURA apart from AV datasets that allow uni-modal shortcuts. To assess reasoning traces, we propose a novel metric, AuraScore, which addresses the lack of robust tools for evaluating reasoning fidelity. It decomposes reasoning into two aspects: (i) Factual Consistency - whether reasoning is grounded in perceptual evidence, and (ii) Core Inference - the logical validity of each reasoning step. Evaluations of SOTA models on AURA reveal a critical reasoning gap: although models achieve high accuracy (up to 92% on some tasks), their Factual Consistency and Core Inference scores fall below 45%. This discrepancy highlights that models often arrive at correct answers through flawed logic, underscoring the need for our benchmark and paving the way for more robust multimodal evaluation.",
    "source": "arXiv"
  },
  {
    "title": "On the Efficiency of Dynamic Transaction Scheduling in Blockchain Sharding",
    "title_es": "On the Efficiency of Dynamic Transaction Scheduling in Blockchain Sharding",
    "url": "https://arxiv.org/abs/2508.07472",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07472v1 Announce Type: new \nAbstract: Sharding is a technique to speed up transaction processing in blockchains, where the $n$ processing nodes in the blockchain are divided into $s$ disjoint groups (shards) that can process transactions in parallel. We study dynamic scheduling problems on a shard graph $G_s$ where transactions arrive online over time and are not known in advance. Each transaction may access at most $k$ shards, and we denote by $d$ the worst distance between a transaction and its accessing (destination) shards (the parameter $d$ is unknown to the shards). To handle different values of $d$, we assume a locality sensitive decomposition of $G_s$ into clusters of shards, where every cluster has a leader shard that schedules transactions for the cluster. We first examine the simpler case of the stateless model, where leaders are not aware of the current state of the transaction accounts, and we prove a $O(d \\log^2 s \\cdot \\min\\{k, \\sqrt{s}\\})$ competitive ratio for latency. We then consider the stateful model, where leader shards gather the current state of accounts, and we prove a $O(\\log s\\cdot \\min\\{k, \\sqrt{s}\\}+\\log^2 s)$ competitive ratio for latency. Each leader calculates the schedule in polynomial time for each transaction that it processes. We show that for any $\\epsilon > 0$, approximating the optimal schedule within a $(\\min\\{k, \\sqrt{s}\\})^{1 -\\epsilon}$ factor is NP-hard. Hence, our bound for the stateful model is within a poly-log factor from the best possibly achievable. To the best of our knowledge, this is the first work to establish provably efficient dynamic scheduling algorithms for blockchain sharding systems.",
    "source": "arXiv"
  },
  {
    "title": "Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications",
    "title_es": "Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications",
    "url": "https://arxiv.org/abs/2508.07473",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07473v1 Announce Type: new \nAbstract: In Online Convex Optimization (OCO), when the stochastic gradient has a finite variance, many algorithms provably work and guarantee a sublinear regret. However, limited results are known if the gradient estimate has a heavy tail, i.e., the stochastic gradient only admits a finite $\\mathsf{p}$-th central moment for some $\\mathsf{p}\\in\\left(1,2\\right]$. Motivated by it, this work examines different old algorithms for OCO (e.g., Online Gradient Descent) in the more challenging heavy-tailed setting. Under the standard bounded domain assumption, we establish new regrets for these classical methods without any algorithmic modification. Remarkably, these regret bounds are fully optimal in all parameters (can be achieved even without knowing $\\mathsf{p}$), suggesting that OCO with heavy tails can be solved effectively without any extra operation (e.g., gradient clipping). Our new results have several applications. A particularly interesting one is the first provable convergence result for nonsmooth nonconvex optimization under heavy-tailed noise without gradient clipping. Furthermore, we explore broader settings (e.g., smooth OCO) and extend our ideas to optimistic algorithms to handle different cases simultaneously.",
    "source": "arXiv"
  },
  {
    "title": "Cardiotensor: A Python Library for Orientation Analysis and Tractography in 3D Cardiac Imaging",
    "title_es": "Cardiotensor: A Python Library for Orientation Analysis and Tractography in 3D Cardiac Imaging",
    "url": "https://arxiv.org/abs/2508.07476",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07476v1 Announce Type: new \nAbstract: Understanding the architecture of the human heart requires analysis of its microstructural organization across scales. With the advent of high-resolution imaging techniques such as synchrotron-based tomography, it has become possible to visualize entire hearts at micron-scale resolution. However, translating these large, complex volumetric datasets into interpretable, quantitative descriptors of cardiac organization remains a major challenge. Here we present cardiotensor, an open-source Python package designed to quantify 3D cardiomyocyte orientation in whole- or partial-heart imaging datasets. It provides efficient, scalable implementations of structure tensor analysis, enabling extraction of directional metrics such as helical angle (HA), intrusion angle (IA), and fractional anisotropy (FA). The package supports datasets reaching teravoxel-scale and is optimized for high-performance computing environments, including parallel and chunk-based processing pipelines. In addition, cardiotensor includes tractography functionality to reconstruct continuous cardiomyocyte trajectories. This enables multi-scale myoaggregate visualization down to the myocyte level, depending on resolution. These capabilities enable detailed structural mapping of cardiac tissue, supporting the assessment of anatomical continuity and regional organization.",
    "source": "arXiv"
  },
  {
    "title": "Positional Biases Shift as Inputs Approach Context Window Limits",
    "title_es": "Positional Biases Shift as Inputs Approach Context Window Limits",
    "url": "https://arxiv.org/abs/2508.07479",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07479v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often struggle to use information across long inputs effectively. Prior work has identified positional biases, such as the Lost in the Middle (LiM) effect, where models perform better when information appears at the beginning (primacy bias) or end (recency bias) of the input, rather than in the middle. However, long-context studies have not consistently replicated these effects, raising questions about their intensity and the conditions under which they manifest. To address this, we conducted a comprehensive analysis using relative rather than absolute input lengths, defined with respect to each model's context window. Our findings reveal that the LiM effect is strongest when inputs occupy up to 50% of a model's context window. Beyond that, the primacy bias weakens, while recency bias remains relatively stable. This effectively eliminates the LiM effect; instead, we observe a distance-based bias, where model performance is better when relevant information is closer to the end of the input. Furthermore, our results suggest that successful retrieval is a prerequisite for reasoning in LLMs, and that the observed positional biases in reasoning are largely inherited from retrieval. These insights have implications for long-context tasks, the design of future LLM benchmarks, and evaluation methodologies for LLMs handling extended inputs.",
    "source": "arXiv"
  },
  {
    "title": "Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry Model Accuracy and Resolution",
    "title_es": "Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry Model Accuracy and Resolution",
    "url": "https://arxiv.org/abs/2508.07483",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07483v1 Announce Type: new \nAbstract: In this paper, I present a comprehensive study comparing Photogrammetry and Gaussian Splatting techniques for 3D model reconstruction and view synthesis. I created a dataset of images from a real-world scene and constructed 3D models using both methods. To evaluate the performance, I compared the models using structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), learned perceptual image patch similarity (LPIPS), and lp/mm resolution based on the USAF resolution chart. A significant contribution of this work is the development of a modified Gaussian Splatting repository, which I forked and enhanced to enable rendering images from novel camera poses generated in the Blender environment. This innovation allows for the synthesis of high-quality novel views, showcasing the flexibility and potential of Gaussian Splatting. My investigation extends to an augmented dataset that includes both original ground images and novel views synthesized via Gaussian Splatting. This augmented dataset was employed to generate a new photogrammetry model, which was then compared against the original photogrammetry model created using only the original images. The results demonstrate the efficacy of using Gaussian Splatting to generate novel high-quality views and its potential to improve photogrammetry-based 3D reconstructions. The comparative analysis highlights the strengths and limitations of both approaches, providing valuable information for applications in extended reality (XR), photogrammetry, and autonomous vehicle simulations. Code is available at https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git.",
    "source": "arXiv"
  },
  {
    "title": "ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models",
    "title_es": "ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models",
    "url": "https://arxiv.org/abs/2508.07484",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07484v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown remarkable performance across a wide range of natural language processing tasks. Quality Estimation (QE) for Machine Translation (MT), which assesses the quality of a source-target pair without relying on reference translations, remains a challenging cross-lingual task for LLMs. The challenges stem from the inherent limitations of existing LLM-based QE systems, which are pre-trained for causal language modelling rather than regression-specific tasks, further elevated by the presence of low-resource languages given pre-training data distribution. This paper introduces ALOPE, an adaptive layer-optimization framework designed to enhance LLM-based QE by restructuring Transformer representations through layer-wise adaptation for improved regression-based prediction. Our framework integrates low-rank adapters (LoRA) with regression task heads, leveraging selected pre-trained Transformer layers for improved cross-lingual alignment. In addition to the layer-specific adaptation, ALOPE introduces two strategies-dynamic weighting, which adaptively combines representations from multiple layers, and multi-head regression, which aggregates regression losses from multiple heads for QE. Our framework shows improvements over various existing LLM-based QE approaches. Empirical evidence suggests that intermediate Transformer layers in LLMs provide contextual representations that are more aligned with the cross-lingual nature of the QE task. We make resultant models and framework code publicly available for further research, also allowing existing LLM-based MT frameworks to be scaled with QE capabilities.",
    "source": "arXiv"
  },
  {
    "title": "Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy",
    "title_es": "Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy",
    "url": "https://arxiv.org/abs/2508.07485",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07485v1 Announce Type: new \nAbstract: We present the first evaluation harness that enables any out-of-the-box, local, Large Language Models (LLMs) to play full-press Diplomacy without fine-tuning or specialized training. Previous work required frontier LLMs, or fine-tuning, due to the high complexity and information density of Diplomacy's game state. Combined with the high variance of matches, these factors made Diplomacy prohibitive for study. In this work, we used data-driven iteration to optimize a textual game state representation such that a 24B model can reliably complete matches without any fine tuning. We develop tooling to facilitate hypothesis testing and statistical analysis, and we present case studies on persuasion, aggressive playstyles, and performance across a range of models. We conduct a variety of experiments across many popular LLMs, finding the larger models perform the best, but the smaller models still play adequately. We also introduce Critical State Analysis: an experimental protocol for rapidly iterating and analyzing key moments in a game at depth. Our harness democratizes the evaluation of strategic reasoning in LLMs by eliminating the need for fine-tuning, and it provides insights into how these capabilities emerge naturally from widely used LLMs. Our code is available in the supplement and will be open sourced.",
    "source": "arXiv"
  },
  {
    "title": "Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering",
    "title_es": "Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering",
    "url": "https://arxiv.org/abs/2508.07486",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07486v1 Announce Type: new \nAbstract: Modern software systems are increasingly shifting from monolithic architectures to microservices to enhance scalability, maintainability, and deployment flexibility. Existing microservice extraction methods typically rely on hard clustering, assigning each software component to a single microservice. This approach often increases inter-service coupling and reduces intra-service cohesion. We propose Mo2oM (Monolithic to Overlapping Microservices), a framework that formulates microservice extraction as a soft clustering problem, allowing components to belong probabilistically to multiple microservices. This approach is inspired by expert-driven decompositions, where practitioners intentionally replicate certain software components across services to reduce communication overhead. Mo2oM combines deep semantic embeddings with structural dependencies extracted from methodcall graphs to capture both functional and architectural relationships. A graph neural network-based soft clustering algorithm then generates the final set of microservices. We evaluate Mo2oM on four open-source monolithic benchmarks and compare it against eight state-of-the-art baselines. Our results demonstrate that Mo2oM achieves improvements of up to 40.97% in structural modularity (balancing cohesion and coupling), 58% in inter-service call percentage (communication overhead), 26.16% in interface number (modularity and decoupling), and 38.96% in non-extreme distribution (service size balance) across all benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Structured Superposition of Autoencoders for UEP Codes at Intermediate Blocklengths",
    "title_es": "Structured Superposition of Autoencoders for UEP Codes at Intermediate Blocklengths",
    "url": "https://arxiv.org/abs/2508.07487",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07487v1 Announce Type: new \nAbstract: Unequal error protection (UEP) coding that enables differentiated reliability levels within a transmitted message is essential for modern communication systems. Autoencoder (AE)-based code designs have shown promise in the context of learned equal error protection (EEP) coding schemes. However, their application to UEP remains largely unexplored, particularly at intermediate blocklengths, due to the increasing complexity of AE-based models. Inspired by the proven effectiveness of superposition coding and successive interference cancellation (SIC) decoding in conventional UEP schemes, we propose a structured AE-based architecture that extends AE-based UEP codes to substantially larger blocklengths while maintaining efficient training. By structuring encoding and decoding into smaller AE subblocks, our method provides a flexible framework for fine-tuning UEP reliability levels while adapting to diverse system parameters. Numerical results show that the proposed approach improves over established achievability bounds of randomized superposition coding-based UEP schemes with SIC decoding, making the proposed structured AE-based UEP codes a scalable and efficient solution for next-generation networks.",
    "source": "arXiv"
  },
  {
    "title": "Recovering link-weight structure in complex networks with weight-aware random walks",
    "title_es": "Recovering link-weight structure in complex networks with weight-aware random walks",
    "url": "https://arxiv.org/abs/2508.07489",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07489v1 Announce Type: new \nAbstract: Using edge weights is essential for modeling real-world systems where links possess relevant information, and preserving this information in low-dimensional representations is relevant for classification and prediction tasks. This paper systematically investigates how different random walk strategies - traditional unweighted, strength-based, and fully weight-aware - keeps edge weight information when generating node embeddings. Using network models, real-world graphs, and networks subjected to low-weight edge removal, we measured the correlation between original edge weights and the similarity of node pairs in the embedding space generated by random walk strategies. Our results consistently showed that weight-aware random walks significantly outperform other strategies, achieving correlations above 0.90 in network models. However, performance in real-world networks was more heterogeneous, influenced by factors like topology and weight distribution. Our analysis also revealed that removing weak edges via thresholding can initially improve correlation by reducing noise, but excessive pruning degrades representation quality. Our findings suggest that simply using a weight-aware random walk is generally the best approach for preserving node weight information in embeddings, but it is not a universal solution.",
    "source": "arXiv"
  },
  {
    "title": "N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting",
    "title_es": "N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting",
    "url": "https://arxiv.org/abs/2508.07490",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07490v1 Announce Type: new \nAbstract: Deep learning approaches are increasingly relevant for time series forecasting tasks. Methods such as N-BEATS, which is built on stacks of multilayer perceptrons (MLPs) blocks, have achieved state-of-the-art results on benchmark datasets and competitions. N-BEATS is also more interpretable relative to other deep learning approaches, as it decomposes forecasts into different time series components, such as trend and seasonality. In this work, we present N-BEATS-MOE, an extension of N-BEATS based on a Mixture-of-Experts (MoE) layer. N-BEATS-MOE employs a dynamic block weighting strategy based on a gating network which allows the model to better adapt to the characteristics of each time series. We also hypothesize that the gating mechanism provides additional interpretability by identifying which expert is most relevant for each series. We evaluate our method across 12 benchmark datasets against several approaches, achieving consistent improvements on several datasets, especially those composed of heterogeneous time series.",
    "source": "arXiv"
  },
  {
    "title": "VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding",
    "title_es": "VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding",
    "url": "https://arxiv.org/abs/2508.07493",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07493v1 Announce Type: new \nAbstract: Most organizational data in this world are stored as documents, and visual retrieval plays a crucial role in unlocking the collective intelligence from all these documents. However, existing benchmarks focus on English-only document retrieval or only consider multilingual question-answering on a single-page image. To bridge this gap, we introduce VisR-Bench, a multilingual benchmark designed for question-driven multimodal retrieval in long documents. Our benchmark comprises over 35K high-quality QA pairs across 1.2K documents, enabling fine-grained evaluation of multimodal retrieval. VisR-Bench spans sixteen languages with three question types (figures, text, and tables), offering diverse linguistic and question coverage. Unlike prior datasets, we include queries without explicit answers, preventing models from relying on superficial keyword matching. We evaluate various retrieval models, including text-based methods, multimodal encoders, and MLLMs, providing insights into their strengths and limitations. Our results show that while MLLMs significantly outperform text-based and multimodal encoder models, they still struggle with structured tables and low-resource languages, highlighting key challenges in multilingual visual retrieval.",
    "source": "arXiv"
  },
  {
    "title": "StreetWeave: A Declarative Grammar for Street-Overlaid Visualization of Multivariate Data",
    "title_es": "StreetWeave: A Declarative Grammar for Street-Overlaid Visualization of Multivariate Data",
    "url": "https://arxiv.org/abs/2508.07496",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07496v1 Announce Type: new \nAbstract: The visualization and analysis of street and pedestrian networks are important to various domain experts, including urban planners, climate researchers, and health experts. This has led to the development of new techniques for street and pedestrian network visualization, expanding how data can be shown and understood more effectively. Despite their increasing adoption, there is no established design framework to guide the creation of these visualizations while addressing the diverse requirements of various domains. When exploring a feature of interest, domain experts often need to transform, integrate, and visualize a combination of thematic data (e.g., demographic, socioeconomic, pollution) and physical data (e.g., zip codes, street networks), often spanning multiple spatial and temporal scales. This not only complicates the process of visual data exploration and system implementation for developers but also creates significant entry barriers for experts who lack a background in programming. With this in mind, in this paper, we reviewed 45 studies utilizing street-overlaid visualizations to understand how they are used. Through qualitative coding of these visualizations, we analyzed three key aspects of street and pedestrian network visualization usage: the analytical purpose they serve, the visualization approaches employed, and the data sources used in their creation. Building on this design space, we introduce StreetWeave, a declarative grammar for designing custom visualizations of multivariate spatial network data across multiple resolutions. We demonstrate how StreetWeave can be used to create various street-overlaid visualizations, enabling effective exploration and analysis of spatial data. StreetWeave is available at https://urbantk.org/streetweave.",
    "source": "arXiv"
  },
  {
    "title": "VA-Blueprint: Uncovering Building Blocks for Visual Analytics System Design",
    "title_es": "VA-Blueprint: Uncovering Building Blocks for Visual Analytics System Design",
    "url": "https://arxiv.org/abs/2508.07497",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07497v1 Announce Type: new \nAbstract: Designing and building visual analytics (VA) systems is a complex, iterative process that requires the seamless integration of data processing, analytics capabilities, and visualization techniques. While prior research has extensively examined the social and collaborative aspects of VA system authoring, the practical challenges of developing these systems remain underexplored. As a result, despite the growing number of VA systems, there are only a few structured knowledge bases to guide their design and development. To tackle this gap, we propose VA-Blueprint, a methodology and knowledge base that systematically reviews and categorizes the fundamental building blocks of urban VA systems, a domain particularly rich and representative due to its intricate data and unique problem sets. Applying this methodology to an initial set of 20 systems, we identify and organize their core components into a multi-level structure, forming an initial knowledge base with a structured blueprint for VA system development. To scale this effort, we leverage a large language model to automate the extraction of these components for other 81 papers (completing a corpus of 101 papers), assessing its effectiveness in scaling knowledge base construction. We evaluate our method through interviews with experts and a quantitative analysis of annotation metrics. Our contributions provide a deeper understanding of VA systems' composition and establish a practical foundation to support more structured, reproducible, and efficient system development. VA-Blueprint is available at https://urbantk.org/va-blueprint.",
    "source": "arXiv"
  },
  {
    "title": "FormCoach: Lift Smarter, Not Harder",
    "title_es": "FormCoach: Lift Smarter, Not Harder",
    "url": "https://arxiv.org/abs/2508.07501",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07501v1 Announce Type: new \nAbstract: Good form is the difference between strength and strain, yet for the fast-growing community of at-home fitness enthusiasts, expert feedback is often out of reach. FormCoach transforms a simple camera into an always-on, interactive AI training partner, capable of spotting subtle form errors and delivering tailored corrections in real time, leveraging vision-language models (VLMs). We showcase this capability through a web interface and benchmark state-of-the-art VLMs on a dataset of 1,700 expert-annotated user-reference video pairs spanning 22 strength and mobility exercises. To accelerate research in AI-driven coaching, we release both the dataset and an automated, rubric-based evaluation pipeline, enabling standardized comparison across models. Our benchmarks reveal substantial gaps compared to human-level coaching, underscoring both the challenges and opportunities in integrating nuanced, context-aware movement analysis into interactive AI systems. By framing form correction as a collaborative and creative process between humans and machines, FormCoach opens a new frontier in embodied AI.",
    "source": "arXiv"
  },
  {
    "title": "A Learning-Based Framework for Collision-Free Motion Planning",
    "title_es": "A Learning-Based Framework for Collision-Free Motion Planning",
    "url": "https://arxiv.org/abs/2508.07502",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07502v1 Announce Type: new \nAbstract: This paper presents a learning-based extension to a Circular Field (CF)-based motion planner for efficient, collision-free trajectory generation in cluttered environments. The proposed approach overcomes the limitations of hand-tuned force field parameters by employing a deep neural network trained to infer optimal planner gains from a single depth image of the scene. The pipeline incorporates a CUDA-accelerated perception module, a predictive agent-based planning strategy, and a dataset generated through Bayesian optimization in simulation. The resulting framework enables real-time planning without manual parameter tuning and is validated both in simulation and on a Franka Emika Panda robot. Experimental results demonstrate successful task completion and improved generalization compared to classical planners.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach",
    "title_es": "Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach",
    "url": "https://arxiv.org/abs/2508.07505",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07505v1 Announce Type: new \nAbstract: Decentralized min-max optimization allows multi-agent systems to collaboratively solve global min-max optimization problems by facilitating the exchange of model updates among neighboring agents, eliminating the need for a central server. However, sharing model updates in such systems carry a risk of exposing sensitive data to inference attacks, raising significant privacy concerns. To mitigate these privacy risks, differential privacy (DP) has become a widely adopted technique for safeguarding individual data. Despite its advantages, implementing DP in decentralized min-max optimization poses challenges, as the added noise can hinder convergence, particularly in non-convex scenarios with complex agent interactions in min-max optimization problems. In this work, we propose an algorithm called DPMixSGD (Differential Private Minmax Hybrid Stochastic Gradient Descent), a novel privacy-preserving algorithm specifically designed for non-convex decentralized min-max optimization. Our method builds on the state-of-the-art STORM-based algorithm, one of the fastest decentralized min-max solutions. We rigorously prove that the noise added to local gradients does not significantly compromise convergence performance, and we provide theoretical bounds to ensure privacy guarantees. To validate our theoretical findings, we conduct extensive experiments across various tasks and models, demonstrating the effectiveness of our approach.",
    "source": "arXiv"
  },
  {
    "title": "Unveiling IPv6 Scanning Dynamics: A Longitudinal Study Using Large Scale Proactive and Passive IPv6 Telescopes",
    "title_es": "Unveiling IPv6 Scanning Dynamics: A Longitudinal Study Using Large Scale Proactive and Passive IPv6 Telescopes",
    "url": "https://arxiv.org/abs/2508.07506",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07506v1 Announce Type: new \nAbstract: We introduce new tools and vantage points to develop and integrate proactive techniques to attract IPv6 scan traffic, thus enabling its analysis. By deploying the largest-ever IPv6 proactive telescope in a production ISP network, we collected over 600M packets of unsolicited traffic from 1.9k Autonomous Systems in 10 months. We characterized the sources of unsolicited traffic, evaluated the effectiveness of five major features across the network stack, and inferred scanners' sources of target addresses and their strategies.",
    "source": "arXiv"
  },
  {
    "title": "Intersectoral Knowledge in AI and Urban Studies: A Framework for Transdisciplinary Research",
    "title_es": "Intersectoral Knowledge in AI and Urban Studies: A Framework for Transdisciplinary Research",
    "url": "https://arxiv.org/abs/2508.07507",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07507v1 Announce Type: new \nAbstract: Transdisciplinary approaches are increasingly essential for addressing grand societal challenges, particularly in complex domains such as Artificial Intelligence (AI), urban planning, and social sciences. However, effectively validating and integrating knowledge across distinct epistemic and ontological perspectives poses significant difficulties. This article proposes a six-dimensional framework for assessing and strengthening transdisciplinary knowledge validity in AI and city studies, based on an extensive analysis of the most cited research (2014--2024). Specifically, the framework classifies research orientations according to ontological, epistemological, methodological, teleological, axiological, and valorization dimensions. Our findings show a predominance of perspectives aligned with critical realism (ontological), positivism (epistemological), analytical methods (methodological), consequentialism (teleological), epistemic values (axiological), and social/economic valorization. Less common stances, such as idealism, mixed methods, and cultural valorization, are also examined for their potential to enrich knowledge production. We highlight how early career researchers and transdisciplinary teams can leverage this framework to reconcile divergent disciplinary viewpoints and promote socially accountable outcomes.",
    "source": "arXiv"
  },
  {
    "title": "SRAM-based Physically Unclonable Function using Lightweight Hamming-Code Fuzzy Extractor for Energy Harvesting Beat Sensors",
    "title_es": "SRAM-based Physically Unclonable Function using Lightweight Hamming-Code Fuzzy Extractor for Energy Harvesting Beat Sensors",
    "url": "https://arxiv.org/abs/2508.07510",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07510v1 Announce Type: new \nAbstract: Batteryless energy harvesting IoT sensor nodes such as beat sensors can be deployed in millions without the need to replace batteries. They are ultra-low-power and cost-effective wireless sensor nodes without the maintenance cost and can work for 24 hours/365 days. However, they were not equipped with security mechanisms to protect user data. Data encryption and authentication can be used to secure beat sensor applications, but generating a secure cryptographic key is challenging. In this paper, we proposed an SRAM-based Physically Unclonable Function (PUF) combining a high-reliability bit selection algorithm with a lightweight error-correcting code to generate reliable secure keys for data encryption. The system employs a feature of beat sensors, in which the microcontroller is powered on to transmit the ID signals and then powered off. This fits the SRAM-based PUF requirement, which needs the SRAM to be powered off to read out its random values. The proposed system has been evaluated on STM32 Cortex M0+ microcontrollers and has been implemented to protect important data on beat sensors.",
    "source": "arXiv"
  },
  {
    "title": "From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials",
    "title_es": "From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials",
    "url": "https://arxiv.org/abs/2508.07514",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07514v1 Announce Type: new \nAbstract: Field trials are vital in herbicide research and development to assess effects on crops and weeds under varied conditions. Traditionally, evaluations rely on manual visual assessments, which are time-consuming, labor-intensive, and subjective. Automating species and damage identification is challenging due to subtle visual differences, but it can greatly enhance efficiency and consistency.\n  We present an improved segmentation model combining a general-purpose self-supervised visual model with hierarchical inference based on botanical taxonomy. Trained on a multi-year dataset (2018-2020) from Germany and Spain using digital and mobile cameras, the model was tested on digital camera data (year 2023) and drone imagery from the United States, Germany, and Spain (year 2024) to evaluate robustness under domain shift. This cross-device evaluation marks a key step in assessing generalization across platforms of the model.\n  Our model significantly improved species identification (F1-score: 0.52 to 0.85, R-squared: 0.75 to 0.98) and damage classification (F1-score: 0.28 to 0.44, R-squared: 0.71 to 0.87) over prior methods. Under domain shift (drone images), it maintained strong performance with moderate degradation (species: F1-score 0.60, R-squared 0.80; damage: F1-score 0.41, R-squared 0.62), where earlier models failed.\n  These results confirm the model's robustness and real-world applicability. It is now deployed in BASF's phenotyping pipeline, enabling large-scale, automated crop and weed monitoring across diverse geographies.",
    "source": "arXiv"
  },
  {
    "title": "Neuro-Symbolic Acceleration of MILP Motion Planning with Temporal Logic and Chance Constraints",
    "title_es": "Neuro-Symbolic Acceleration of MILP Motion Planning with Temporal Logic and Chance Constraints",
    "url": "https://arxiv.org/abs/2508.07515",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07515v1 Announce Type: new \nAbstract: Autonomous systems must solve motion planning problems subject to increasingly complex, time-sensitive, and uncertain missions. These problems often involve high-level task specifications, such as temporal logic or chance constraints, which require solving large-scale Mixed-Integer Linear Programs (MILPs). However, existing MILP-based planning methods suffer from high computational cost and limited scalability, hindering their real-time applicability. We propose to use a neuro-symbolic approach to accelerate MILP-based motion planning by leveraging machine learning techniques to guide the solver's symbolic search. Focusing on two representative classes of planning problems, namely, those with Signal Temporal Logic (STL) specifications and those with chance constraints formulated via Conformal Predictive Programming (CPP). We demonstrate how graph neural network-based learning methods can guide traditional symbolic MILP solvers in solving challenging planning problems, including branching variable selection and solver parameter configuration. Through extensive experiments, we show that neuro-symbolic search techniques yield scalability gains. Our approach yields substantial improvements, achieving an average performance gain of about 20% over state-of-the-art solver across key metrics, including runtime and solution quality.",
    "source": "arXiv"
  },
  {
    "title": "Augmenting Bias Detection in LLMs Using Topological Data Analysis",
    "title_es": "Augmenting Bias Detection in LLMs Using Topological Data Analysis",
    "url": "https://arxiv.org/abs/2508.07516",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07516v1 Announce Type: new \nAbstract: Recently, many bias detection methods have been proposed to determine the level of bias a large language model captures. However, tests to identify which parts of a large language model are responsible for bias towards specific groups remain underdeveloped. In this study, we present a method using topological data analysis to identify which heads in GPT-2 contribute to the misrepresentation of identity groups present in the StereoSet dataset. We find that biases for particular categories, such as gender or profession, are concentrated in attention heads that act as hot spots. The metric we propose can also be used to determine which heads capture bias for a specific group within a bias category, and future work could extend this method to help de-bias large language models.",
    "source": "arXiv"
  },
  {
    "title": "Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews",
    "title_es": "Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews",
    "url": "https://arxiv.org/abs/2508.07517",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07517v1 Announce Type: new \nAbstract: Word clouds are a common way to summarize qualitative interviews, yet traditional frequency-based methods often fail in conversational contexts: they surface filler words, ignore paraphrase, and fragment semantically related ideas. This limits their usefulness in early-stage analysis, when researchers need fast, interpretable overviews of what participant actually said. We introduce ThemeClouds, an open-source visualization tool that uses large language models (LLMs) to generate thematic, participant-weighted word clouds from dialogue transcripts. The system prompts an LLM to identify concept-level themes across a corpus and then counts how many unique participants mention each topic, yielding a visualization grounded in breadth of mention rather than raw term frequency. Researchers can customize prompts and visualization parameters, providing transparency and control. Using interviews from a user study comparing five recording-device configurations (31 participants; 155 transcripts, Whisper ASR), our approach surfaces more actionable device concerns than frequency clouds and topic-modeling baselines (e.g., LDA, BERTopic). We discuss design trade-offs for integrating LLM assistance into qualitative workflows, implications for interpretability and researcher agency, and opportunities for interactive analyses such as per-condition contrasts (``diff clouds'').",
    "source": "arXiv"
  },
  {
    "title": "FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction",
    "title_es": "FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction",
    "url": "https://arxiv.org/abs/2508.07518",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07518v1 Announce Type: new \nAbstract: As deep spatio-temporal neural networks are increasingly utilised in urban computing contexts, the deployment of such methods can have a direct impact on users of critical urban infrastructure, such as public transport, emergency services, and traffic management systems. While many spatio-temporal methods focus on improving accuracy, fairness has recently gained attention due to growing evidence that biased predictions in spatio-temporal applications can disproportionately disadvantage certain demographic or geographic groups, thereby reinforcing existing socioeconomic inequalities and undermining the ethical deployment of AI in public services. In this paper, we propose a novel framework, FairDRL-ST, based on disentangled representation learning, to address fairness concerns in spatio-temporal prediction, with a particular focus on mobility demand forecasting. By leveraging adversarial learning and disentangled representation learning, our framework learns to separate attributes that contain sensitive information. Unlike existing methods that enforce fairness through supervised learning, which may lead to overcompensation and degraded performance, our framework achieves fairness in an unsupervised manner with minimal performance loss. We apply our framework to real-world urban mobility datasets and demonstrate its ability to close fairness gaps while delivering competitive predictive performance compared to state-of-the-art fairness-aware methods.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing",
    "title_es": "Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing",
    "url": "https://arxiv.org/abs/2508.07519",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07519v1 Announce Type: new \nAbstract: Transformer-based diffusion models have recently superseded traditional U-Net architectures, with multimodal diffusion transformers (MM-DiT) emerging as the dominant approach in state-of-the-art models like Stable Diffusion 3 and Flux.1. Previous approaches have relied on unidirectional cross-attention mechanisms, with information flowing from text embeddings to image latents. In contrast, MMDiT introduces a unified attention mechanism that concatenates input projections from both modalities and performs a single full attention operation, allowing bidirectional information flow between text and image branches. This architectural shift presents significant challenges for existing editing techniques. In this paper, we systematically analyze MM-DiT's attention mechanism by decomposing attention matrices into four distinct blocks, revealing their inherent characteristics. Through these analyses, we propose a robust, prompt-based image editing method for MM-DiT that supports global to local edits across various MM-DiT variants, including few-step models. We believe our findings bridge the gap between existing U-Net-based methods and emerging architectures, offering deeper insights into MMDiT's behavioral patterns.",
    "source": "arXiv"
  },
  {
    "title": "Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI",
    "title_es": "Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI",
    "url": "https://arxiv.org/abs/2508.07520",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07520v1 Announce Type: new \nAbstract: What if the patterns hidden within dialogue reveal more about communication than the words themselves? We introduce Conversational DNA, a novel visual language that treats any dialogue -- whether between humans, between human and AI, or among groups -- as a living system with interpretable structure that can be visualized, compared, and understood. Unlike traditional conversation analysis that reduces rich interaction to statistical summaries, our approach reveals the temporal architecture of dialogue through biological metaphors. Linguistic complexity flows through strand thickness, emotional trajectories cascade through color gradients, conversational relevance forms through connecting elements, and topic coherence maintains structural integrity through helical patterns. Through exploratory analysis of therapeutic conversations and historically significant human-AI dialogues, we demonstrate how this visualization approach reveals interaction patterns that traditional methods miss. Our work contributes a new creative framework for understanding communication that bridges data visualization, human-computer interaction, and the fundamental question of what makes dialogue meaningful in an age where humans increasingly converse with artificial minds.",
    "source": "arXiv"
  },
  {
    "title": "Evolutionary Optimization of Deep Learning Agents for Sparrow Mahjong",
    "title_es": "Evolutionary Optimization of Deep Learning Agents for Sparrow Mahjong",
    "url": "https://arxiv.org/abs/2508.07522",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07522v1 Announce Type: new \nAbstract: We present Evo-Sparrow, a deep learning-based agent for AI decision-making in Sparrow Mahjong, trained by optimizing Long Short-Term Memory (LSTM) networks using Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Our model evaluates board states and optimizes decision policies in a non-deterministic, partially observable game environment. Empirical analysis conducted over a significant number of simulations demonstrates that our model outperforms both random and rule-based agents, and achieves performance comparable to a Proximal Policy Optimization (PPO) baseline, indicating strong strategic play and robust policy quality. By combining deep learning with evolutionary optimization, our approach provides a computationally effective alternative to traditional reinforcement learning and gradient-based optimization methods. This research contributes to the broader field of AI game playing, demonstrating the viability of hybrid learning strategies for complex stochastic games. These findings also offer potential applications in adaptive decision-making and strategic AI development beyond Sparrow Mahjong.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Reliability of Medical Image Diagnosis through Top-rank Learning with Rejection Module",
    "title_es": "Enhancing Reliability of Medical Image Diagnosis through Top-rank Learning with Rejection Module",
    "url": "https://arxiv.org/abs/2508.07528",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07528v1 Announce Type: new \nAbstract: In medical image processing, accurate diagnosis is of paramount importance. Leveraging machine learning techniques, particularly top-rank learning, shows significant promise by focusing on the most crucial instances. However, challenges arise from noisy labels and class-ambiguous instances, which can severely hinder the top-rank objective, as they may be erroneously placed among the top-ranked instances. To address these, we propose a novel approach that enhances toprank learning by integrating a rejection module. Cooptimized with the top-rank loss, this module identifies and mitigates the impact of outliers that hinder training effectiveness. The rejection module functions as an additional branch, assessing instances based on a rejection function that measures their deviation from the norm. Through experimental validation on a medical dataset, our methodology demonstrates its efficacy in detecting and mitigating outliers, improving the reliability and accuracy of medical image diagnoses.",
    "source": "arXiv"
  },
  {
    "title": "Summarizing Classed Region Maps with a Disk Choreme",
    "title_es": "Summarizing Classed Region Maps with a Disk Choreme",
    "url": "https://arxiv.org/abs/2508.07529",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07529v1 Announce Type: new \nAbstract: Chorematic diagrams are highly reduced schematic maps of geospatial data and processes. They can visually summarize complex situations using only a few simple shapes (choremes) placed upon a simplified base map. Due to the extreme reduction of data in chorematic diagrams, they tend to be produced manually; few automated solutions exist. In this paper we consider the algorithmic problem of summarizing classed region maps, such as choropleth or land use maps, using a chorematic diagram with a single disk choreme. It is infeasible to solve this problem exactly for large maps. Hence, we propose several point sampling strategies and use algorithms for classed point sets to efficiently find the best disk that represents one of the classes. We implemented our algorithm and experimentally compared sampling strategies and densities. The results show that with the right sampling strategy, high-quality results can be obtained already with moderately sized point sets and within seconds of computation time.",
    "source": "arXiv"
  },
  {
    "title": "From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR",
    "title_es": "From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR",
    "url": "https://arxiv.org/abs/2508.07534",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07534v1 Announce Type: new \nAbstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a powerful paradigm for enhancing the reasoning capabilities of large language models (LLMs). Unlike traditional RL approaches, RLVR leverages rule-based feedback to guide LLMs in generating and refining complex reasoning chains -- a process critically dependent on effective exploration strategies. While prior work has demonstrated RLVR's empirical success, the fundamental mechanisms governing LLMs' exploration behaviors remain underexplored. This technical report presents a systematic investigation of exploration capacities in RLVR, covering four main aspects: (1) exploration space shaping, where we develop quantitative metrics to characterize LLMs' capability boundaries; (2) entropy-performance exchange, analyzed across training stages, individual instances, and token-level patterns; and (3) RL performance optimization, examining methods to effectively translate exploration gains into measurable improvements. By unifying previously identified insights with new empirical evidence, this work aims to provide a foundational framework for advancing RLVR systems.",
    "source": "arXiv"
  },
  {
    "title": "Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning",
    "title_es": "Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning",
    "url": "https://arxiv.org/abs/2508.07536",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07536v1 Announce Type: new \nAbstract: Accurate and interpretable bearing fault classification is critical for ensuring the reliability of rotating machinery, particularly under variable operating conditions where domain shifts can significantly degrade model performance. This study proposes a physics-informed multimodal convolutional neural network (CNN) with a late fusion architecture, integrating vibration and motor current signals alongside a dedicated physics-based feature extraction branch. The model incorporates a novel physics-informed loss function that penalizes physically implausible predictions based on characteristic bearing fault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency Inner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive experiments on the Paderborn University dataset demonstrate that the proposed physics-informed approach consistently outperforms a non-physics-informed baseline, achieving higher accuracy, reduced false classifications, and improved robustness across multiple data splits. To address performance degradation under unseen operating conditions, three transfer learning (TL) strategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy (LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS yields the best generalization, with additional performance gains when combined with physics-informed modeling. Validation on the KAIST bearing dataset confirms the framework's cross-dataset applicability, achieving up to 98 percent accuracy. Statistical hypothesis testing further verifies significant improvements (p < 0.01) in classification performance. The proposed framework demonstrates the potential of integrating domain knowledge with data-driven learning to achieve robust, interpretable, and generalizable fault diagnosis for real-world industrial applications.",
    "source": "arXiv"
  },
  {
    "title": "Enhanced Generative Structure Prior for Chinese Text Image Super-resolution",
    "title_es": "Enhanced Generative Structure Prior for Chinese Text Image Super-resolution",
    "url": "https://arxiv.org/abs/2508.07537",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07537v1 Announce Type: new \nAbstract: Faithful text image super-resolution (SR) is challenging because each character has a unique structure and usually exhibits diverse font styles and layouts. While existing methods primarily focus on English text, less attention has been paid to more complex scripts like Chinese. In this paper, we introduce a high-quality text image SR framework designed to restore the precise strokes of low-resolution (LR) Chinese characters. Unlike methods that rely on character recognition priors to regularize the SR task, we propose a novel structure prior that offers structure-level guidance to enhance visual quality. Our framework incorporates this structure prior within a StyleGAN model, leveraging its generative capabilities for restoration. To maintain the integrity of character structures while accommodating various font styles and layouts, we implement a codebook-based mechanism that restricts the generative space of StyleGAN. Each code in the codebook represents the structure of a specific character, while the vector $w$ in StyleGAN controls the character's style, including typeface, orientation, and location. Through the collaborative interaction between the codebook and style, we generate a high-resolution structure prior that aligns with LR characters both spatially and structurally. Experiments demonstrate that this structure prior provides robust, character-specific guidance, enabling the accurate restoration of clear strokes in degraded characters, even for real-world LR Chinese text with irregular layouts. Our code and pre-trained models will be available at https://github.com/csxmli2016/MARCONetPlusPlus",
    "source": "arXiv"
  },
  {
    "title": "A DICOM Image De-identification Algorithm in the MIDI-B Challenge",
    "title_es": "A DICOM Image De-identification Algorithm in the MIDI-B Challenge",
    "url": "https://arxiv.org/abs/2508.07538",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07538v1 Announce Type: new \nAbstract: Image de-identification is essential for the public sharing of medical images, particularly in the widely used Digital Imaging and Communications in Medicine (DICOM) format as required by various regulations and standards, including Health Insurance Portability and Accountability Act (HIPAA) privacy rules, the DICOM PS3.15 standard, and best practices recommended by the Cancer Imaging Archive (TCIA). The Medical Image De-Identification Benchmark (MIDI-B) Challenge at the 27th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2024) was organized to evaluate rule-based DICOM image de-identification algorithms with a large dataset of clinical DICOM images. In this report, we explore the critical challenges of de-identifying DICOM images, emphasize the importance of removing personally identifiable information (PII) to protect patient privacy while ensuring the continued utility of medical data for research, diagnostics, and treatment, and provide a comprehensive overview of the standards and regulations that govern this process. Additionally, we detail the de-identification methods we applied - such as pixel masking, date shifting, date hashing, text recognition, text replacement, and text removal - to process datasets during the test phase in strict compliance with these standards. According to the final leaderboard of the MIDI-B challenge, the latest version of our solution algorithm correctly executed 99.92% of the required actions and ranked 2nd out of 10 teams that completed the challenge (from a total of 22 registered teams). Finally, we conducted a thorough analysis of the resulting statistics and discussed the limitations of current approaches and potential avenues for future improvement.",
    "source": "arXiv"
  },
  {
    "title": "Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning",
    "title_es": "Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning",
    "url": "https://arxiv.org/abs/2508.07539",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07539v1 Announce Type: new \nAbstract: In this paper, we address domain shifts in pathological images by focusing on shifts within whole slide images~(WSIs), such as patient characteristics and tissue thickness, rather than shifts between hospitals. Traditional approaches rely on multi-hospital data, but data collection challenges often make this impractical. Therefore, the proposed domain generalization method captures and leverages intra-hospital domain shifts by clustering WSI-level features from non-tumor regions and treating these clusters as domains. To mitigate domain shift, we apply contrastive learning to reduce feature gaps between WSI pairs from different clusters. The proposed method introduces a two-stage contrastive learning approach WSI-level and patch-level contrastive learning to minimize these gaps effectively.",
    "source": "arXiv"
  },
  {
    "title": "CoT-Pose: Chain-of-Thought Reasoning for 3D Pose Generation from Abstract Prompts",
    "title_es": "CoT-Pose: Chain-of-Thought Reasoning for 3D Pose Generation from Abstract Prompts",
    "url": "https://arxiv.org/abs/2508.07540",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07540v1 Announce Type: new \nAbstract: Recent advances in multi-modal large language models (MLLMs) and chain-of-thought (CoT) reasoning have led to significant progress in image and text generation tasks. However, the field of 3D human pose generation still faces critical limitations. Most existing text-to-pose models rely heavily on detailed (low-level) prompts that explicitly describe joint configurations. In contrast, humans tend to communicate actions and intentions using abstract (high-level) language. This mismatch results in a practical challenge for deploying pose generation systems in real-world scenarios. To bridge this gap, we introduce a novel framework that incorporates CoT reasoning into the pose generation process, enabling the interpretation of abstract prompts into accurate 3D human poses. We further propose a data synthesis pipeline that automatically generates triplets of abstract prompts, detailed prompts, and corresponding 3D poses for training process. Experimental results demonstrate that our reasoning-enhanced model, CoT-Pose, can effectively generate plausible and semantically aligned poses from abstract textual inputs. This work highlights the importance of high-level understanding in pose generation and opens new directions for reasoning-enhanced approach for human pose generation.",
    "source": "arXiv"
  },
  {
    "title": "A Matrix Decomposition Method for Odd-Type Gaussian Normal Basis Multiplication",
    "title_es": "A Matrix Decomposition Method for Odd-Type Gaussian Normal Basis Multiplication",
    "url": "https://arxiv.org/abs/2508.07541",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07541v1 Announce Type: new \nAbstract: Normal basis is used in many applications because of the efficiency of the implementation. However, most space complexity reduction techniques for binary field multiplier are applicable for only optimal normal basis or Gaussian normal basis of even type. There are 187 binary fields GF(2^k) for k from 2 to 1,000 that use odd-type Gaussian normal basis. This paper presents a method to reduce the space complexity of odd-type Gaussian normal basis multipliers over binary field GF(2^k). The idea is adapted from the matrix decomposition method for optimal normal basis. The result shows that our space complexity reduction method can reduce the number of XOR gates used in the implementation comparing to previous works with a small trade-off in critical path delay.",
    "source": "arXiv"
  },
  {
    "title": "Commentary Generation for Soccer Highlights",
    "title_es": "Commentary Generation for Soccer Highlights",
    "url": "https://arxiv.org/abs/2508.07543",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07543v1 Announce Type: new \nAbstract: Automated soccer commentary generation has evolved from template-based systems to advanced neural architectures, aiming to produce real-time descriptions of sports events. While frameworks like SoccerNet-Caption laid foundational work, their inability to achieve fine-grained alignment between video content and commentary remains a significant challenge. Recent efforts such as MatchTime, with its MatchVoice model, address this issue through coarse and fine-grained alignment techniques, achieving improved temporal synchronization. In this paper, we extend MatchVoice to commentary generation for soccer highlights using the GOAL dataset, which emphasizes short clips over entire games. We conduct extensive experiments to reproduce the original MatchTime results and evaluate our setup, highlighting the impact of different training configurations and hardware limitations. Furthermore, we explore the effect of varying window sizes on zero-shot performance. While MatchVoice exhibits promising generalization capabilities, our findings suggest the need for integrating techniques from broader video-language domains to further enhance performance. Our code is available at https://github.com/chidaksh/SoccerCommentary.",
    "source": "arXiv"
  },
  {
    "title": "Physics-informed Multiresolution Wavelet Neural Network Method for Solving Partial Differential Equations",
    "title_es": "Physics-informed Multiresolution Wavelet Neural Network Method for Solving Partial Differential Equations",
    "url": "https://arxiv.org/abs/2508.07546",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07546v1 Announce Type: new \nAbstract: In this paper, a physics-informed multiresolution wavelet neural network (PIMWNN) method is proposed for solving partial differential equations (PDEs). This method uses the multiresolution wavelet neural network (MWNN) to approximate unknown functions, then substituting the MWNN into PDEs and training the MWNN by least-squares algorithm. We apply the proposed method to various problems, including stationary/nonstationary advection, diffusion and advection-diffusion problems, and linear/nonlinear time-dependent problems. Numerical experiments show that the PIMWNN method can achieve higher accuracy and faster speed than Physics Informed Neural Networks (PINNs). Moreover, the PIMWNN method, being mesh-free, can handle different boundary conditions easily and solve the time-dependent problems efficiently. The proposed method is expected to solve the spectral bias problem in network training. These characteristics show the great potential of the PIMWNN method used in the field of numerical solving methods for PDEs.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Pseudo Label Selection for Individual Unlabeled Data by Positive and Unlabeled Learning",
    "title_es": "Adaptive Pseudo Label Selection for Individual Unlabeled Data by Positive and Unlabeled Learning",
    "url": "https://arxiv.org/abs/2508.07548",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07548v1 Announce Type: new \nAbstract: This paper proposes a novel pseudo-labeling method for medical image segmentation that can perform learning on ``individual images'' to select effective pseudo-labels. We introduce Positive and Unlabeled Learning (PU learning), which uses only positive and unlabeled data for binary classification problems, to obtain the appropriate metric for discriminating foreground and background regions on each unlabeled image. Our PU learning makes us easy to select pseudo-labels for various background regions. The experimental results show the effectiveness of our method.",
    "source": "arXiv"
  },
  {
    "title": "A Benchmark for Databases with Varying Value Lengths",
    "title_es": "A Benchmark for Databases with Varying Value Lengths",
    "url": "https://arxiv.org/abs/2508.07551",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07551v1 Announce Type: new \nAbstract: The performance of database management systems (DBMS) is traditionally evaluated using benchmarks that focus on workloads with (almost) fixed record lengths. However, some real-world workloads in key/value stores, document databases, and graph databases exhibit significant variability in value lengths, which can lead to performance anomalies, particularly when popular records grow disproportionately large. Existing benchmarks fail to account for this variability, leaving an important aspect of DBMS behavior underexplored.\n  In this paper, we address this gap by extending the Yahoo! Cloud Serving Benchmark (YCSB) to include an \"extend\" operation, which appends data to record fields, simulating the growth of values over time. Using this modified benchmark, we have measured the performance of three popular DBMS backends: MongoDB, MariaDB with the InnoDB storage engine, and MariaDB with the MyRocks storage engine. Our experiments alternate between extending values and executing query workloads, revealing significant performance differences driven by storage engine design and their handling of variable-sized values.\n  Our key contribution is the introduction of a novel benchmarking approach to evaluate the impact of growing value sizes and isolate the effect of querying data with a distribution of data sizes from any cost associated with accessing data after a history of updates. This highlights the need for more representative benchmarks that capture the dynamic nature of real-world workloads, providing valuable guidance for both practitioners and researchers.",
    "source": "arXiv"
  },
  {
    "title": "Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring",
    "title_es": "Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring",
    "url": "https://arxiv.org/abs/2508.07552",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07552v1 Announce Type: new \nAbstract: End-to-end models are emerging as the mainstream in autonomous driving perception and planning. However, the lack of explicit supervision signals for intermediate functional modules leads to opaque operational mechanisms and limited interpretability, making it challenging for traditional methods to independently evaluate and train these modules. Pioneering in the issue, this study builds upon the feature map-truth representation similarity-based evaluation framework and proposes an independent evaluation method based on Feature Map Convergence Score (FMCS). A Dual-Granularity Dynamic Weighted Scoring System (DG-DWSS) is constructed, formulating a unified quantitative metric - Feature Map Quality Score - to enable comprehensive evaluation of the quality of feature maps generated by functional modules. A CLIP-based Feature Map Quality Evaluation Network (CLIP-FMQE-Net) is further developed, combining feature-truth encoders and quality score prediction heads to enable real-time quality analysis of feature maps generated by functional modules. Experimental results on the NuScenes dataset demonstrate that integrating our evaluation module into the training improves 3D object detection performance, achieving a 3.89 percent gain in NDS. These results verify the effectiveness of our method in enhancing feature representation quality and overall model performance.",
    "source": "arXiv"
  },
  {
    "title": "Efficient adaptive randomized algorithms for fixed-threshold low-rank matrix approximation",
    "title_es": "Efficient adaptive randomized algorithms for fixed-threshold low-rank matrix approximation",
    "url": "https://arxiv.org/abs/2508.07553",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07553v1 Announce Type: new \nAbstract: The low-rank matrix approximation problems within a threshold are widely applied in information retrieval, image processing, background estimation of the video sequence problems and so on. This paper presents an adaptive randomized rank-revealing algorithm of the data matrix $A$, in which the basis matrix $Q$ of the approximate range space is adaptively built block by block, through a recursive deflation procedure on $A$. Detailed analysis of randomized projection schemes are provided to analyze the numerical rank reduce during the deflation. The provable spectral and Frobenius error $(I-QQ^T)A$ of the approximate low-rank matrix $\\tilde A=QQ^TA$ are presented, as well as the approximate singular values. This blocked deflation technique is pass-efficient and can accelerate practical computations of large matrices. Applied to image processing and background estimation problems, the blocked randomized algorithm behaves more reliable and more efficient than the known Lanczos-based method and a rank-revealing algorithm proposed by Lee, Li and Zeng (in SIAM J. Matrix Anal. Appl. 31 (2009), pp. 503-525).",
    "source": "arXiv"
  },
  {
    "title": "FineBadminton: A Multi-Level Dataset for Fine-Grained Badminton Video Understanding",
    "title_es": "FineBadminton: A Multi-Level Dataset for Fine-Grained Badminton Video Understanding",
    "url": "https://arxiv.org/abs/2508.07554",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07554v1 Announce Type: new \nAbstract: Fine-grained analysis of complex and high-speed sports like badminton presents a significant challenge for Multimodal Large Language Models (MLLMs), despite their notable advancements in general video understanding. This difficulty arises primarily from the scarcity of datasets with sufficiently rich and domain-specific annotations. To bridge this gap, we introduce FineBadminton, a novel and large-scale dataset featuring a unique multi-level semantic annotation hierarchy (Foundational Actions, Tactical Semantics, and Decision Evaluation) for comprehensive badminton understanding. The construction of FineBadminton is powered by an innovative annotation pipeline that synergistically combines MLLM-generated proposals with human refinement. We also present FBBench, a challenging benchmark derived from FineBadminton, to rigorously evaluate MLLMs on nuanced spatio-temporal reasoning and tactical comprehension. Together, FineBadminton and FBBench provide a crucial ecosystem to catalyze research in fine-grained video understanding and advance the development of MLLMs in sports intelligence. Furthermore, we propose an optimized baseline approach incorporating Hit-Centric Keyframe Selection to focus on pivotal moments and Coordinate-Guided Condensation to distill salient visual information. The results on FBBench reveal that while current MLLMs still face significant challenges in deep sports video analysis, our proposed strategies nonetheless achieve substantial performance gains. The project homepage is available at https://finebadminton.github.io/FineBadminton/.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal Remote Inference",
    "title_es": "Multimodal Remote Inference",
    "url": "https://arxiv.org/abs/2508.07555",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07555v1 Announce Type: new \nAbstract: We consider a remote inference system with multiple modalities, where a multimodal machine learning (ML) model performs real-time inference using features collected from remote sensors. As sensor observations may change dynamically over time, fresh features are critical for inference tasks. However, timely delivering features from all modalities is often infeasible due to limited network resources. To this end, we study a two-modality scheduling problem to minimize the ML model's inference error, which is expressed as a penalty function of AoI for both modalities. We develop an index-based threshold policy and prove its optimality. Specifically, the scheduler switches modalities when the current modality's index function exceeds a threshold. We show that the two modalities share the same threshold, and both the index functions and the threshold can be computed efficiently. The optimality of our policy holds for (i) general AoI functions that are \\emph{non-monotonic} and \\emph{non-additive} and (ii) \\emph{heterogeneous} transmission times. Numerical results show that our policy reduces inference error by up to 55% compared to round-robin and uniform random policies, which are oblivious to the AoI-based inference error function. Our results shed light on how to improve remote inference accuracy by optimizing task-oriented AoI functions.",
    "source": "arXiv"
  },
  {
    "title": "Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning",
    "title_es": "Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning",
    "url": "https://arxiv.org/abs/2508.07556",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07556v1 Announce Type: new \nAbstract: Machine learning (ML) systems are increasingly deployed in high-stakes domains where reliability is paramount. This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, focusing on selective prediction -- where models abstain when confidence is low.\n  We first show that a model's training trajectory contains rich uncertainty signals that can be exploited without altering its architecture or loss. By ensembling predictions from intermediate checkpoints, we propose a lightweight, post-hoc abstention method that works across tasks, avoids the cost of deep ensembles, and achieves state-of-the-art selective prediction performance. Crucially, this approach is fully compatible with differential privacy (DP), allowing us to study how privacy noise affects uncertainty quality. We find that while many methods degrade under DP, our trajectory-based approach remains robust, and we introduce a framework for isolating the privacy-uncertainty trade-off. Next, we then develop a finite-sample decomposition of the selective classification gap -- the deviation from the oracle accuracy-coverage curve -- identifying five interpretable error sources and clarifying which interventions can close the gap. This explains why calibration alone cannot fix ranking errors, motivating methods that improve uncertainty ordering. Finally, we show that uncertainty signals can be adversarially manipulated to hide errors or deny service while maintaining high accuracy, and we design defenses combining calibration audits with verifiable inference.\n  Together, these contributions advance reliable ML by improving, evaluating, and safeguarding uncertainty estimation, enabling models that not only make accurate predictions -- but also know when to say \"I do not know\".",
    "source": "arXiv"
  },
  {
    "title": "Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and Spatially Consistent Content Creation",
    "title_es": "Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and Spatially Consistent Content Creation",
    "url": "https://arxiv.org/abs/2508.07557",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07557v1 Announce Type: new \nAbstract: Generating high-quality 4D content from monocular videos for applications such as digital humans and AR/VR poses challenges in ensuring temporal and spatial consistency, preserving intricate details, and incorporating user guidance effectively. To overcome these challenges, we introduce Splat4D, a novel framework enabling high-fidelity 4D content generation from a monocular video. Splat4D achieves superior performance while maintaining faithful spatial-temporal coherence by leveraging multi-view rendering, inconsistency identification, a video diffusion model, and an asymmetric U-Net for refinement. Through extensive evaluations on public benchmarks, Splat4D consistently demonstrates state-of-the-art performance across various metrics, underscoring the efficacy of our approach. Additionally, the versatility of Splat4D is validated in various applications such as text/image conditioned 4D generation, 4D human generation, and text-guided content editing, producing coherent outcomes following user instructions.",
    "source": "arXiv"
  },
  {
    "title": "Barron Space Representations for Elliptic PDEs with Homogeneous Boundary Conditions",
    "title_es": "Barron Space Representations for Elliptic PDEs with Homogeneous Boundary Conditions",
    "url": "https://arxiv.org/abs/2508.07559",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07559v1 Announce Type: new \nAbstract: We study the approximation complexity of high-dimensional second-order elliptic PDEs with homogeneous boundary conditions on the unit hypercube, within the framework of Barron spaces. Under the assumption that the coefficients belong to suitably defined Barron spaces, we prove that the solution can be efficiently approximated by two-layer neural networks, circumventing the curse of dimensionality. Our results demonstrate the expressive power of shallow networks in capturing high-dimensional PDE solutions under appropriate structural assumptions.",
    "source": "arXiv"
  },
  {
    "title": "Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey",
    "title_es": "Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey",
    "url": "https://arxiv.org/abs/2508.07560",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07560v1 Announce Type: new \nAbstract: Bird's-Eye-View (BEV) perception has become a foundational paradigm in autonomous driving, enabling unified spatial representations that support robust multi-sensor fusion and multi-agent collaboration. As autonomous vehicles transition from controlled environments to real-world deployment, ensuring the safety and reliability of BEV perception in complex scenarios - such as occlusions, adverse weather, and dynamic traffic - remains a critical challenge. This survey provides the first comprehensive review of BEV perception from a safety-critical perspective, systematically analyzing state-of-the-art frameworks and implementation strategies across three progressive stages: single-modality vehicle-side, multimodal vehicle-side, and multi-agent collaborative perception. Furthermore, we examine public datasets encompassing vehicle-side, roadside, and collaborative settings, evaluating their relevance to safety and robustness. We also identify key open-world challenges - including open-set recognition, large-scale unlabeled data, sensor degradation, and inter-agent communication latency - and outline future research directions, such as integration with end-to-end autonomous driving systems, embodied intelligence, and large language models.",
    "source": "arXiv"
  },
  {
    "title": "A Small-footprint Acoustic Echo Cancellation Solution for Mobile Full-Duplex Speech Interactions",
    "title_es": "A Small-footprint Acoustic Echo Cancellation Solution for Mobile Full-Duplex Speech Interactions",
    "url": "https://arxiv.org/abs/2508.07561",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07561v1 Announce Type: new \nAbstract: In full-duplex speech interaction systems, effective Acoustic Echo Cancellation (AEC) is crucial for recovering echo-contaminated speech. This paper presents a neural network-based AEC solution to address challenges in mobile scenarios with varying hardware, nonlinear distortions and long latency. We first incorporate diverse data augmentation strategies to enhance the model's robustness across various environments. Moreover, progressive learning is employed to incrementally improve AEC effectiveness, resulting in a considerable improvement in speech quality. To further optimize AEC's downstream applications, we introduce a novel post-processing strategy employing tailored parameters designed specifically for tasks such as Voice Activity Detection (VAD) and Automatic Speech Recognition (ASR), thus enhancing their overall efficacy. Finally, our method employs a small-footprint model with streaming inference, enabling seamless deployment on mobile devices. Empirical results demonstrate effectiveness of the proposed method in Echo Return Loss Enhancement and Perceptual Evaluation of Speech Quality, alongside significant improvements in both VAD and ASR results.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Efficient Directional and Distance Cues for Regional Speech Separation",
    "title_es": "Exploring Efficient Directional and Distance Cues for Regional Speech Separation",
    "url": "https://arxiv.org/abs/2508.07563",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07563v1 Announce Type: new \nAbstract: In this paper, we introduce a neural network-based method for regional speech separation using a microphone array. This approach leverages novel spatial cues to extract the sound source not only from specified direction but also within defined distance. Specifically, our method employs an improved delay-and-sum technique to obtain directional cues, substantially enhancing the signal from the target direction. We further enhance separation by incorporating the direct-to-reverberant ratio into the input features, enabling the model to better discriminate sources within and beyond a specified distance. Experimental results demonstrate that our proposed method leads to substantial gains across multiple objective metrics. Furthermore, our method achieves state-of-the-art performance on the CHiME-8 MMCSG dataset, which was recorded in real-world conversational scenarios, underscoring its effectiveness for speech separation in practical applications.",
    "source": "arXiv"
  },
  {
    "title": "Feedback Control of a Single-Tail Bioinspired 59-mg Swimmer",
    "title_es": "Feedback Control of a Single-Tail Bioinspired 59-mg Swimmer",
    "url": "https://arxiv.org/abs/2508.07566",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07566v1 Announce Type: new \nAbstract: We present an evolved steerable version of the single-tail Fish-&-Ribbon-Inspired Small Swimming Harmonic roBot (FRISSHBot), a 59-mg biologically inspired swimmer, which is driven by a new shape-memory alloy (SMA)-based bimorph actuator. The new FRISSHBot is controllable in the two-dimensional (2D) space, which enabled the first demonstration of feedback-controlled trajectory tracking of a single-tail aquatic robot with onboard actuation at the subgram scale. These new capabilities are the result of a physics-informed design with an enlarged head and shortened tail relative to those of the original platform. Enhanced by its design, this new platform achieves forward swimming speeds of up to 13.6 mm/s (0.38 Bl/s), which is over four times that of the original platform. Furthermore, when following 2D references in closed loop, the tested FRISSHBot prototype attains forward swimming speeds of up to 9.1 mm/s, root-mean-square (RMS) tracking errors as low as 2.6 mm, turning rates of up to 13.1 {\\deg}/s, and turning radii as small as 10 mm.",
    "source": "arXiv"
  },
  {
    "title": "Extended AB Algorithms for Bistatic Integrated Sensing and Communications Systems",
    "title_es": "Extended AB Algorithms for Bistatic Integrated Sensing and Communications Systems",
    "url": "https://arxiv.org/abs/2508.07567",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07567v1 Announce Type: new \nAbstract: Integrated sensing and communication (ISAC) is pivotal for next-generation wireless networks, rendering the computation of rate-distortion trade-off in ISAC systems critically important. In this paper, we propose the extended Arimoto-Blahut (AB) algorithms to calculate the rate-distortion trade-off in bistatic ISAC systems, which overcome the limitation of existing AB algorithms in handling non-convex constraints. Specifically, we introduce auxiliary variables to transform non-convex distortion constraints into linear constraints, prove that the reformulated linearly-constrained optimization problem maintains the same optimal solution as the original problem, and develop extended AB algorithms for both squared error and logarithmic loss distortion metrics based on the framework of AB algorithm. Numerical results validate the effectiveness of the proposed algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation",
    "title_es": "Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation",
    "url": "https://arxiv.org/abs/2508.07569",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07569v1 Announce Type: new \nAbstract: Drafting a Statement of Work (SOW) is a vital part of business and legal projects. It outlines key details like deliverables, timelines, responsibilities, and legal terms. However, creating these documents is often a slow and complex process. It usually involves multiple people, takes several days, and leaves room for errors or outdated content. This paper introduces a new AI-driven automation system that makes the entire SOW drafting process faster, easier, and more accurate. Instead of relying completely on humans, the system uses three intelligent components or 'agents' that each handle a part of the job. One agent writes the first draft, another checks if everything is legally correct, and the third agent formats the document and ensures everything is in order. Unlike basic online tools that just fill in templates, this system understands the meaning behind the content and customizes the SOW to match the needs of the project. It also checks legal compliance and formatting so that users can trust the result. The system was tested using real business examples. It was able to create a full SOW in under three minutes, compared to several hours or days using manual methods. It also performed well in accuracy and quality, showing that it can reduce legal risks and save a lot of time. This solution shows how artificial intelligence can be used to support legal and business professionals by taking care of routine work and helping them focus on more important decisions. It's a step toward making legal processes smarter, faster, and more reliable.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models",
    "title_es": "Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.07570",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07570v1 Announce Type: new \nAbstract: Vision-language models (VLMs) exhibit remarkable zero-shot generalization but suffer performance degradation under distribution shifts in downstream tasks, particularly in the absence of labeled data. Test-Time Adaptation (TTA) addresses this challenge by enabling online optimization of VLMs during inference, eliminating the need for annotated data. Cache-based TTA methods exploit historical knowledge by maintaining a dynamic memory cache of low-entropy or high-confidence samples, promoting efficient adaptation to out-of-distribution data. Nevertheless, these methods face two critical challenges: (1) unreliable confidence metrics under significant distribution shifts, resulting in error accumulation within the cache and degraded adaptation performance; and (2) rigid decision boundaries that fail to accommodate substantial distributional variations, leading to suboptimal predictions. To overcome these limitations, we introduce the Adaptive Cache Enhancement (ACE) framework, which constructs a robust cache by selectively storing high-confidence or low-entropy image embeddings per class, guided by dynamic, class-specific thresholds initialized from zero-shot statistics and iteratively refined using an exponential moving average and exploration-augmented updates. This approach enables adaptive, class-wise decision boundaries, ensuring robust and accurate predictions across diverse visual distributions. Extensive experiments on 15 diverse benchmark datasets demonstrate that ACE achieves state-of-the-art performance, delivering superior robustness and generalization compared to existing TTA methods in challenging out-of-distribution scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression",
    "title_es": "Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression",
    "url": "https://arxiv.org/abs/2508.07571",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07571v1 Announce Type: new \nAbstract: Using more test-time computation during language model inference, such as generating more intermediate thoughts or sampling multiple candidate answers, has proven effective in significantly improving model performance. This paper takes an initial step toward bridging the gap between practical language model inference and theoretical transformer analysis by incorporating randomness and sampling. We focus on in-context linear regression with continuous/binary coefficients, where our framework simulates language model decoding through noise injection and binary coefficient sampling. Through this framework, we provide detailed analyses of widely adopted inference techniques. Supported by empirical results, our theoretical framework and analysis demonstrate the potential for offering new insights into understanding inference behaviors in real-world language models.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Mega-Satellite Networks with Generative Semantic Communication: A Networking Perspective",
    "title_es": "Enhancing Mega-Satellite Networks with Generative Semantic Communication: A Networking Perspective",
    "url": "https://arxiv.org/abs/2508.07573",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07573v1 Announce Type: new \nAbstract: The advance of direct satellite-to-device communication has positioned mega-satellite constellations as a cornerstone of 6G wireless communication, enabling seamless global connectivity even in remote and underserved areas. However, spectrum scarcity and capacity constraints imposed by the Shannon's classical information theory remain significant challenges for supporting the massive data demands of multimedia-rich wireless applications. Generative Semantic Communication (GSC), powered by artificial intelligence-based generative foundation models, represents a paradigm shift from transmitting raw data to exchanging semantic meaning. GSC can not only reduce bandwidth consumption, but also enhance key semantic features in multimedia content, thereby offering a promising solution to overcome the limitations of traditional satellite communication systems. This article investigates the integration of GSC into mega-satellite constellations from a networking perspective. We propose a GSC-empowered satellite networking architecture and identify key enabling technologies, focusing on GSC-empowered network modeling and GSC-aware networking strategies. We construct a discrete temporal graph to model semantic encoders and decoders, distinct knowledge bases, and resource variations in mega-satellite networks. Based on this framework, we develop model deployment for semantic encoders and decoders and GSC-compatible routing schemes, and then present performance evaluations. Finally, we outline future research directions for advancing GSC-empowered satellite networks.",
    "source": "arXiv"
  },
  {
    "title": "Orthogonal Low Rank Embedding Stabilization",
    "title_es": "Orthogonal Low Rank Embedding Stabilization",
    "url": "https://arxiv.org/abs/2508.07574",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07574v1 Announce Type: new \nAbstract: The instability of embedding spaces across model retraining cycles presents significant challenges to downstream applications using user or item embeddings derived from recommendation systems as input features. This paper introduces a novel orthogonal low-rank transformation methodology designed to stabilize the user/item embedding space, ensuring consistent embedding dimensions across retraining sessions. Our approach leverages a combination of efficient low-rank singular value decomposition and orthogonal Procrustes transformation to map embeddings into a standardized space. This transformation is computationally efficient, lossless, and lightweight, preserving the dot product and inference quality while reducing operational burdens. Unlike existing methods that modify training objectives or embedding structures, our approach maintains the integrity of the primary model application and can be seamlessly integrated with other stabilization techniques.",
    "source": "arXiv"
  },
  {
    "title": "MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark",
    "title_es": "MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark",
    "url": "https://arxiv.org/abs/2508.07575",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07575v1 Announce Type: new \nAbstract: LLMs' capabilities are enhanced by using function calls to integrate various data sources or API results into the context window. Typical tools include search, web crawlers, maps, financial data, file systems, and browser usage, etc. Integrating these data sources or functions requires a standardized method. The Model Context Protocol (MCP) provides a standardized way to supply context to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use abilities suffer from several issues. First, there's a lack of comprehensive datasets or benchmarks to evaluate various MCP tools. Second, the diverse formats of response from MCP tool call execution further increase the difficulty of evaluation. Additionally, unlike existing tool-use benchmarks with high success rates in functions like programming and math functions, the success rate of real-world MCP tool is not guaranteed and varies across different MCP servers. Furthermore, the LLMs' context window also limits the number of available tools that can be called in a single run, because the textual descriptions of tool and the parameters have long token length for an LLM to process all at once. To help address the challenges of evaluating LLMs' performance on calling MCP tools, we propose MCPToolBench++, a large-scale, multi-domain AI Agent tool use benchmark. As of July 2025, this benchmark is build upon marketplace of over 4k MCP servers from more than 40 categories, collected from the MCP marketplaces and GitHub communities. The datasets consist of both single-step and multi-step tool calls across different categories. We evaluated SOTA LLMs with agentic abilities on this benchmark and reported the results.",
    "source": "arXiv"
  },
  {
    "title": "Phoenix: A Novel Context-Aware Voice-Powered Math Equation Workspace and Editor",
    "title_es": "Phoenix: A Novel Context-Aware Voice-Powered Math Equation Workspace and Editor",
    "url": "https://arxiv.org/abs/2508.07576",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07576v1 Announce Type: new \nAbstract: Writing mathematical notation requires substantial effort, diverting cognitive resources from conceptual understanding to documentation mechanics, significantly impacting individuals with fine motor disabilities (FMDs). Current limits of speech-based math technologies rely on precise dictation of math symbols and unintuitive command-based interfaces. We present a novel voice-powered math workspace, applying neuroscience insights to create an intuitive problem-solving environment. To minimize cognitive load, we leverage large language models with our novel context engine to support natural language interaction. Ultimately, we enable fluid mathematical engagement for individuals with FMDs -- freed from mechanical constraints.",
    "source": "arXiv"
  },
  {
    "title": "Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification",
    "title_es": "Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification",
    "url": "https://arxiv.org/abs/2508.07577",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07577v1 Announce Type: new \nAbstract: LayerNorm is pivotal in Vision Transformers (ViTs), yet its fine-tuning dynamics under data scarcity and domain shifts remain underexplored. This paper shows that shifts in LayerNorm parameters after fine-tuning (LayerNorm shifts) are indicative of the transitions between source and target domains; its efficacy is contingent upon the degree to which the target training samples accurately represent the target domain, as quantified by our proposed Fine-tuning Shift Ratio ($FSR$). Building on this, we propose a simple yet effective rescaling mechanism using a scalar $\\lambda$ that is negatively correlated to $FSR$ to align learned LayerNorm shifts with those ideal shifts achieved under fully representative data, combined with a cyclic framework that further enhances the LayerNorm fine-tuning. Extensive experiments across natural and pathological images, in both in-distribution (ID) and out-of-distribution (OOD) settings, and various target training sample regimes validate our framework. Notably, OOD tasks tend to yield lower $FSR$ and higher $\\lambda$ in comparison to ID cases, especially with scarce data, indicating under-represented target training samples. Moreover, ViTFs fine-tuned on pathological data behave more like ID settings, favoring conservative LayerNorm updates. Our findings illuminate the underexplored dynamics of LayerNorm in transfer learning and provide practical strategies for LayerNorm fine-tuning.",
    "source": "arXiv"
  },
  {
    "title": "Achieving Fair-Effective Communications and Robustness in Underwater Acoustic Sensor Networks: A Semi-Cooperative Approach",
    "title_es": "Achieving Fair-Effective Communications and Robustness in Underwater Acoustic Sensor Networks: A Semi-Cooperative Approach",
    "url": "https://arxiv.org/abs/2508.07578",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07578v1 Announce Type: new \nAbstract: This paper investigates the fair-effective communication and robustness in imperfect and energy-constrained underwater acoustic sensor networks (IC-UASNs). Specifically, we investigate the impact of unexpected node malfunctions on the network performance under the time-varying acoustic channels. Each node is expected to satisfy Quality of Service (QoS) requirements. However, achieving individual QoS requirements may interfere with other concurrent communications. Underwater nodes rely excessively on the rationality of other underwater nodes when guided by fully cooperative approaches, making it difficult to seek a trade-off between individual QoS and global fair-effective communications under imperfect conditions. Therefore, this paper presents a SEmi-COoperative Power Allocation approach (SECOPA) that achieves fair-effective communication and robustness in IC-UASNs. The approach is distributed multi-agent reinforcement learning (MARL)-based, and the objectives are twofold. On the one hand, each intelligent node individually decides the transmission power to simultaneously optimize individual and global performance. On the other hand, advanced training algorithms are developed to provide imperfect environments for training robust models that can adapt to the time-varying acoustic channels and handle unexpected node failures in the network. Numerical results are presented to validate our proposed approach.",
    "source": "arXiv"
  },
  {
    "title": "From Platform Migration to Cultural Integration: the Ingress and Diffusion of #wlw from TikTok to RedNote in Queer Women",
    "title_es": "From Platform Migration to Cultural Integration: the Ingress and Diffusion of #wlw from TikTok to RedNote in Queer Women",
    "url": "https://arxiv.org/abs/2508.07579",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07579v1 Announce Type: new \nAbstract: Hashtags serve as identity markers and connection tools in online queer communities. Recently, the Western-origin #wlw (women-loving-women) hashtag has risen in the Chinese lesbian community on RedNote, coinciding with user migration triggered by the temporary US TikTok ban. This event provides a unique lens to study cross-cultural hashtag ingress and diffusion through the populations' responsive behaviors in cyber-migration. In this paper, we conducted a two-phase content analysis of 418 #wlw posts from January and April, examining different usage patterns during the hashtag's ingress and diffusion. Results indicate that the successful introduction of #wlw was facilitated by TikTok immigrants' bold importation, both populations' mutual interpretation, and RedNote natives' discussions. In current manifestation of diffusion, #wlw becomes a RedNote-recognized queer hashtag for sharing queer life, and semantically expands to support feminism discourse. Our findings provide empirical insights for enhancing the marginalized communities' cross-cultural communication.",
    "source": "arXiv"
  },
  {
    "title": "When and how can inexact generative models still sample from the data manifold?",
    "title_es": "When and how can inexact generative models still sample from the data manifold?",
    "url": "https://arxiv.org/abs/2508.07581",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07581v1 Announce Type: new \nAbstract: A curious phenomenon observed in some dynamical generative models is the following: despite learning errors in the score function or the drift vector field, the generated samples appear to shift \\emph{along} the support of the data distribution but not \\emph{away} from it. In this work, we investigate this phenomenon of \\emph{robustness of the support} by taking a dynamical systems approach on the generating stochastic/deterministic process. Our perturbation analysis of the probability flow reveals that infinitesimal learning errors cause the predicted density to be different from the target density only on the data manifold for a wide class of generative models. Further, what is the dynamical mechanism that leads to the robustness of the support? We show that the alignment of the top Lyapunov vectors (most sensitive infinitesimal perturbation directions) with the tangent spaces along the boundary of the data manifold leads to robustness and prove a sufficient condition on the dynamics of the generating process to achieve this alignment. Moreover, the alignment condition is efficient to compute and, in practice, for robust generative models, automatically leads to accurate estimates of the tangent bundle of the data manifold. Using a finite-time linear perturbation analysis on samples paths as well as probability flows, our work complements and extends existing works on obtaining theoretical guarantees for generative models from a stochastic analysis, statistical learning and uncertainty quantification points of view. Our results apply across different dynamical generative models, such as conditional flow-matching and score-based generative models, and for different target distributions that may or may not satisfy the manifold hypothesis.",
    "source": "arXiv"
  },
  {
    "title": "GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm",
    "title_es": "GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm",
    "url": "https://arxiv.org/abs/2508.07585",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07585v1 Announce Type: new \nAbstract: Recent salient object detection (SOD) models predominantly rely on heavyweight backbones, incurring substantial computational cost and hindering their practical application in various real-world settings, particularly on edge devices. This paper presents GAPNet, a lightweight network built on the granularity-aware paradigm for both image and video SOD. We assign saliency maps of different granularities to supervise the multi-scale decoder side-outputs: coarse object locations for high-level outputs and fine-grained object boundaries for low-level outputs. Specifically, our decoder is built with granularity-aware connections which fuse high-level features of low granularity and low-level features of high granularity, respectively. To support these connections, we design granular pyramid convolution (GPC) and cross-scale attention (CSA) modules for efficient fusion of low-scale and high-scale features, respectively. On top of the encoder, a self-attention module is built to learn global information, enabling accurate object localization with negligible computational cost. Unlike traditional U-Net-based approaches, our proposed method optimizes feature utilization and semantic interpretation while applying appropriate supervision at each processing stage. Extensive experiments show that the proposed method achieves a new state-of-the-art performance among lightweight image and video SOD models. Code is available at https://github.com/yuhuan-wu/GAPNet.",
    "source": "arXiv"
  },
  {
    "title": "Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method",
    "title_es": "Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method",
    "url": "https://arxiv.org/abs/2508.07586",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07586v1 Announce Type: new \nAbstract: In this paper, a novel covert semantic communication framework is investigated. Within this framework, a server extracts and transmits the semantic information, i.e., the meaning of image data, to a user over several time slots. An attacker seeks to detect and eavesdrop the semantic transmission to acquire details of the original image. To avoid data meaning being eavesdropped by an attacker, a friendly jammer is deployed to transmit jamming signals to interfere the attacker so as to hide the transmitted semantic information. Meanwhile, the server will strategically select time slots for semantic information transmission. Due to limited energy, the jammer will not communicate with the server and hence the server does not know the transmit power of the jammer. Therefore, the server must jointly optimize the semantic information transmitted at each time slot and the corresponding transmit power to maximize the privacy and the semantic information transmission quality of the user. To solve this problem, we propose a prioritised sampling assisted twin delayed deep deterministic policy gradient algorithm to jointly determine the transmitted semantic information and the transmit power per time slot without the communications between the server and the jammer. Compared to standard reinforcement learning methods, the propose method uses an additional Q network to estimate Q values such that the agent can select the action with a lower Q value from the two Q networks thus avoiding local optimal action selection and estimation bias of Q values. Simulation results show that the proposed algorithm can improve the privacy and the semantic information transmission quality by up to 77.8% and 14.3% compared to the traditional reinforcement learning methods.",
    "source": "arXiv"
  },
  {
    "title": "Voice Pathology Detection Using Phonation",
    "title_es": "Voice Pathology Detection Using Phonation",
    "url": "https://arxiv.org/abs/2508.07587",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07587v1 Announce Type: new \nAbstract: Voice disorders significantly affect communication and quality of life, requiring an early and accurate diagnosis. Traditional methods like laryngoscopy are invasive, subjective, and often inaccessible. This research proposes a noninvasive, machine learning-based framework for detecting voice pathologies using phonation data.\n  Phonation data from the Saarbr\\\"ucken Voice Database are analyzed using acoustic features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma features, and Mel spectrograms. Recurrent Neural Networks (RNNs), including LSTM and attention mechanisms, classify samples into normal and pathological categories. Data augmentation techniques, including pitch shifting and Gaussian noise addition, enhance model generalizability, while preprocessing ensures signal quality. Scale-based features, such as H\\\"older and Hurst exponents, further capture signal irregularities and long-term dependencies.\n  The proposed framework offers a noninvasive, automated diagnostic tool for early detection of voice pathologies, supporting AI-driven healthcare, and improving patient outcomes.",
    "source": "arXiv"
  },
  {
    "title": "MSPT: A Lightweight Face Image Quality Assessment Method with Multi-stage Progressive Training",
    "title_es": "MSPT: A Lightweight Face Image Quality Assessment Method with Multi-stage Progressive Training",
    "url": "https://arxiv.org/abs/2508.07590",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07590v1 Announce Type: new \nAbstract: Accurately assessing the perceptual quality of face images is crucial, especially with the rapid progress in face restoration and generation. Traditional quality assessment methods often struggle with the unique characteristics of face images, limiting their generalizability. While learning-based approaches demonstrate superior performance due to their strong fitting capabilities, their high complexity typically incurs significant computational and storage costs, hindering practical deployment. To address this, we propose a lightweight face quality assessment network with Multi-Stage Progressive Training (MSPT). Our network employs a three-stage progressive training strategy that gradually introduces more diverse data samples and increases input image resolution. This novel approach enables lightweight networks to achieve high performance by effectively learning complex quality features while significantly mitigating catastrophic forgetting. Our MSPT achieved the second highest score on the VQualA 2025 face image quality assessment benchmark dataset, demonstrating that MSPT achieves comparable or better performance than state-of-the-art methods while maintaining efficient inference.",
    "source": "arXiv"
  },
  {
    "title": "IBPS: Indian Bail Prediction System",
    "title_es": "IBPS: Indian Bail Prediction System",
    "url": "https://arxiv.org/abs/2508.07592",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07592v1 Announce Type: new \nAbstract: Bail decisions are among the most frequently adjudicated matters in Indian courts, yet they remain plagued by subjectivity, delays, and inconsistencies. With over 75% of India's prison population comprising undertrial prisoners, many from socioeconomically disadvantaged backgrounds, the lack of timely and fair bail adjudication exacerbates human rights concerns and contributes to systemic judicial backlog. In this paper, we present the Indian Bail Prediction System (IBPS), an AI-powered framework designed to assist in bail decision-making by predicting outcomes and generating legally sound rationales based solely on factual case attributes and statutory provisions. We curate and release a large-scale dataset of 150,430 High Court bail judgments, enriched with structured annotations such as age, health, criminal history, crime category, custody duration, statutes, and judicial reasoning. We fine-tune a large language model using parameter-efficient techniques and evaluate its performance across multiple configurations, with and without statutory context, and with RAG. Our results demonstrate that models fine-tuned with statutory knowledge significantly outperform baselines, achieving strong accuracy and explanation quality, and generalize well to a test set independently annotated by legal experts. IBPS offers a transparent, scalable, and reproducible solution to support data-driven legal assistance, reduce bail delays, and promote procedural fairness in the Indian judicial system.",
    "source": "arXiv"
  },
  {
    "title": "Towards Comprehensible Recommendation with Large Language Model Fine-tuning",
    "title_es": "Towards Comprehensible Recommendation with Large Language Model Fine-tuning",
    "url": "https://arxiv.org/abs/2508.07595",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07595v1 Announce Type: new \nAbstract: Recommender systems have become increasingly ubiquitous in daily life. While traditional recommendation approaches primarily rely on ID-based representations or item-side content features, they often fall short in capturing the underlying semantics aligned with user preferences (e.g., recommendation reasons for items), leading to a semantic-collaborative gap. Recently emerged LLM-based feature extraction approaches also face a key challenge: how to ensure that LLMs possess recommendation-aligned reasoning capabilities and can generate accurate, personalized reasons to mitigate the semantic-collaborative gap. To address these issues, we propose a novel Content Understanding from a Collaborative Perspective framework (CURec), which generates collaborative-aligned content features for more comprehensive recommendations. \\method first aligns the LLM with recommendation objectives through pretraining, equipping it with instruction-following and chain-of-thought reasoning capabilities. Next, we design a reward model inspired by traditional recommendation architectures to evaluate the quality of the recommendation reasons generated by the LLM. Finally, using the reward signals, CURec fine-tunes the LLM through RL and corrects the generated reasons to ensure their accuracy. The corrected reasons are then integrated into a downstream recommender model to enhance comprehensibility and recommendation performance. Extensive experiments on public benchmarks demonstrate the superiority of CURec over existing methods.",
    "source": "arXiv"
  },
  {
    "title": "From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users",
    "title_es": "From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users",
    "url": "https://arxiv.org/abs/2508.07596",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07596v1 Announce Type: new \nAbstract: The proliferation of deepfake technologies poses urgent challenges and serious risks to digital integrity, particularly within critical sectors such as forensics, journalism, and the legal system. While existing detection systems have made significant progress in classification accuracy, they typically function as black-box models, offering limited transparency and minimal support for human reasoning. This lack of interpretability hinders their usability in real-world decision-making contexts, especially for non-expert users. In this paper, we present DF-P2E (Deepfake: Prediction to Explanation), a novel multimodal framework that integrates visual, semantic, and narrative layers of explanation to make deepfake detection interpretable and accessible. The framework consists of three modular components: (1) a deepfake classifier with Grad-CAM-based saliency visualisation, (2) a visual captioning module that generates natural language summaries of manipulated regions, and (3) a narrative refinement module that uses a fine-tuned Large Language Model (LLM) to produce context-aware, user-sensitive explanations. We instantiate and evaluate the framework on the DF40 benchmark, the most diverse deepfake dataset to date. Experiments demonstrate that our system achieves competitive detection performance while providing high-quality explanations aligned with Grad-CAM activations. By unifying prediction and explanation in a coherent, human-aligned pipeline, this work offers a scalable approach to interpretable deepfake detection, advancing the broader vision of trustworthy and transparent AI systems in adversarial media environments.",
    "source": "arXiv"
  },
  {
    "title": "ShoulderShot: Generating Over-the-Shoulder Dialogue Videos",
    "title_es": "ShoulderShot: Generating Over-the-Shoulder Dialogue Videos",
    "url": "https://arxiv.org/abs/2508.07597",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07597v1 Announce Type: new \nAbstract: Over-the-shoulder dialogue videos are essential in films, short dramas, and advertisements, providing visual variety and enhancing viewers' emotional connection. Despite their importance, such dialogue scenes remain largely underexplored in video generation research. The main challenges include maintaining character consistency across different shots, creating a sense of spatial continuity, and generating long, multi-turn dialogues within limited computational budgets. Here, we present ShoulderShot, a framework that combines dual-shot generation with looping video, enabling extended dialogues while preserving character consistency. Our results demonstrate capabilities that surpass existing methods in terms of shot-reverse-shot layout, spatial continuity, and flexibility in dialogue length, thereby opening up new possibilities for practical dialogue video generation. Videos and comparisons are available at https://shouldershot.github.io.",
    "source": "arXiv"
  },
  {
    "title": "Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements",
    "title_es": "Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements",
    "url": "https://arxiv.org/abs/2508.07598",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07598v1 Announce Type: new \nAbstract: Although the LLM-based in-context learning (ICL) paradigm has demonstrated considerable success across various natural language processing tasks, it encounters challenges in event detection. This is because LLMs lack an accurate understanding of event triggers and tend to make over-interpretation, which cannot be effectively corrected through in-context examples alone. In this paper, we focus on the most challenging one-shot setting and propose KeyCP++, a keyword-centric chain-of-thought prompting approach. KeyCP++ addresses the weaknesses of conventional ICL by automatically annotating the logical gaps between input text and detection results for the demonstrations. Specifically, to generate in-depth and meaningful rationale, KeyCP++ constructs a trigger discrimination prompting template. It incorporates the exemplary triggers (a.k.a keywords) into the prompt as the anchor to simply trigger profiling, let LLM propose candidate triggers, and justify each candidate. These propose-and-judge rationales help LLMs mitigate over-reliance on the keywords and promote detection rule learning. Extensive experiments demonstrate the effectiveness of our approach, showcasing significant advancements in one-shot event detection.",
    "source": "arXiv"
  },
  {
    "title": "HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol",
    "title_es": "HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol",
    "url": "https://arxiv.org/abs/2508.07602",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07602v1 Announce Type: new \nAbstract: Invoking external tools enables Large Language Models (LLMs) to perform complex, real-world tasks, yet selecting the correct tool from large, hierarchically-structured libraries remains a significant challenge. The limited context windows of LLMs and noise from irrelevant options often lead to low selection accuracy and high computational costs. To address this, we propose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic pruning method for scalable tool invocation. HGMF first maps the user query and all tool descriptions into a unified semantic space. The framework then operates in two stages: it clusters servers using a Gaussian Mixture Model (GMM) and filters them based on the query's likelihood. Subsequently, it applies the same GMM-based clustering and filtering to the tools associated with the selected servers. This hierarchical process produces a compact, high-relevance candidate set, simplifying the final selection task for the LLM. Experiments on a public dataset show that HGMF significantly improves tool selection accuracy while reducing inference latency, confirming the framework's scalability and effectiveness for large-scale tool libraries.",
    "source": "arXiv"
  },
  {
    "title": "LaVieID: Local Autoregressive Diffusion Transformers for Identity-Preserving Video Creation",
    "title_es": "LaVieID: Local Autoregressive Diffusion Transformers for Identity-Preserving Video Creation",
    "url": "https://arxiv.org/abs/2508.07603",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07603v1 Announce Type: new \nAbstract: In this paper, we present LaVieID, a novel \\underline{l}ocal \\underline{a}utoregressive \\underline{vi}d\\underline{e}o diffusion framework designed to tackle the challenging \\underline{id}entity-preserving text-to-video task. The key idea of LaVieID is to mitigate the loss of identity information inherent in the stochastic global generation process of diffusion transformers (DiTs) from both spatial and temporal perspectives. Specifically, unlike the global and unstructured modeling of facial latent states in existing DiTs, LaVieID introduces a local router to explicitly represent latent states by weighted combinations of fine-grained local facial structures. This alleviates undesirable feature interference and encourages DiTs to capture distinctive facial characteristics. Furthermore, a temporal autoregressive module is integrated into LaVieID to refine denoised latent tokens before video decoding. This module divides latent tokens temporally into chunks, exploiting their long-range temporal dependencies to predict biases for rectifying tokens, thereby significantly enhancing inter-frame identity consistency. Consequently, LaVieID can generate high-fidelity personalized videos and achieve state-of-the-art performance. Our code and models are available at https://github.com/ssugarwh/LaVieID.",
    "source": "arXiv"
  },
  {
    "title": "Joint Scheduling and Resource Allocation in mmWave IAB Networks Using Deep RL",
    "title_es": "Joint Scheduling and Resource Allocation in mmWave IAB Networks Using Deep RL",
    "url": "https://arxiv.org/abs/2508.07604",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07604v1 Announce Type: new \nAbstract: Integrated Access and Backhaul (IAB) is critical for dense 5G and beyond deployments, especially in mmWave bands where fiber backhaul is infeasible. We propose a novel Deep Reinforcement Learning (DRL) framework for joint link scheduling and resource slicing in dynamic, interference-prone IAB networks. Our method integrates a greedy Double Deep Q-Network (DDQN) scheduler to activate access and backhaul links based on traffic and topology, with a multi-agent DDQN allocator for bandwidth and antenna assignment across network slices. This decentralized approach respects strict antenna constraints and supports concurrent scheduling across heterogeneous links. Evaluations across 96 dynamic topologies show 99.84 percent scheduling accuracy and 20.90 percent throughput improvement over baselines. The framework's efficient operation and adaptability make it suitable for dynamic and resource-constrained deployments, where fast link scheduling and autonomous backhaul coordination are vital.",
    "source": "arXiv"
  },
  {
    "title": "Coordinated Power Management on Heterogeneous Systems",
    "title_es": "Coordinated Power Management on Heterogeneous Systems",
    "url": "https://arxiv.org/abs/2508.07605",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07605v1 Announce Type: new \nAbstract: Performance prediction is essential for energy-efficient computing in heterogeneous computing systems that integrate CPUs and GPUs. However, traditional performance modeling methods often rely on exhaustive offline profiling, which becomes impractical due to the large setting space and the high cost of profiling large-scale applications. In this paper, we present OPEN, a framework consists of offline and online phases. The offline phase involves building a performance predictor and constructing an initial dense matrix. In the online phase, OPEN performs lightweight online profiling, and leverages the performance predictor with collaborative filtering to make performance prediction. We evaluate OPEN on multiple heterogeneous systems, including those equipped with A100 and A30 GPUs. Results show that OPEN achieves prediction accuracy up to 98.29\\%. This demonstrates that OPEN effectively reduces profiling cost while maintaining high accuracy, making it practical for power-aware performance modeling in modern HPC environments. Overall, OPEN provides a lightweight solution for performance prediction under power constraints, enabling better runtime decisions in power-aware computing environments.",
    "source": "arXiv"
  },
  {
    "title": "In-situ Value-aligned Human-Robot Interactions with Physical Constraints",
    "title_es": "In-situ Value-aligned Human-Robot Interactions with Physical Constraints",
    "url": "https://arxiv.org/abs/2508.07606",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07606v1 Announce Type: new \nAbstract: Equipped with Large Language Models (LLMs), human-centered robots are now capable of performing a wide range of tasks that were previously deemed challenging or unattainable. However, merely completing tasks is insufficient for cognitive robots, who should learn and apply human preferences to future scenarios. In this work, we propose a framework that combines human preferences with physical constraints, requiring robots to complete tasks while considering both. Firstly, we developed a benchmark of everyday household activities, which are often evaluated based on specific preferences. We then introduced In-Context Learning from Human Feedback (ICLHF), where human feedback comes from direct instructions and adjustments made intentionally or unintentionally in daily life. Extensive sets of experiments, testing the ICLHF to generate task plans and balance physical constraints with preferences, have demonstrated the efficiency of our approach.",
    "source": "arXiv"
  },
  {
    "title": "X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning",
    "title_es": "X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning",
    "url": "https://arxiv.org/abs/2508.07607",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07607v1 Announce Type: new \nAbstract: Existing open-source datasets for arbitrary-instruction image editing remain suboptimal, while a plug-and-play editing module compatible with community-prevalent generative models is notably absent. In this paper, we first introduce the X2Edit Dataset, a comprehensive dataset covering 14 diverse editing tasks, including subject-driven generation. We utilize the industry-leading unified image generation models and expert models to construct the data. Meanwhile, we design reasonable editing instructions with the VLM and implement various scoring mechanisms to filter the data. As a result, we construct 3.7 million high-quality data with balanced categories. Second, to better integrate seamlessly with community image generation models, we design task-aware MoE-LoRA training based on FLUX.1, with only 8\\% of the parameters of the full model. To further improve the final performance, we utilize the internal representations of the diffusion model and define positive/negative samples based on image editing types to introduce contrastive learning. Extensive experiments demonstrate that the model's editing performance is competitive among many excellent models. Additionally, the constructed dataset exhibits substantial advantages over existing open-source datasets. The open-source code, checkpoints, and datasets for X2Edit can be found at the following link: https://github.com/OPPO-Mente-Lab/X2Edit.",
    "source": "arXiv"
  },
  {
    "title": "AD-AVSR: Asymmetric Dual-stream Enhancement for Robust Audio-Visual Speech Recognition",
    "title_es": "AD-AVSR: Asymmetric Dual-stream Enhancement for Robust Audio-Visual Speech Recognition",
    "url": "https://arxiv.org/abs/2508.07608",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07608v1 Announce Type: new \nAbstract: Audio-visual speech recognition (AVSR) combines audio-visual modalities to improve speech recognition, especially in noisy environments. However, most existing methods deploy the unidirectional enhancement or symmetric fusion manner, which limits their capability to capture heterogeneous and complementary correlations of audio-visual data-especially under asymmetric information conditions. To tackle these gaps, we introduce a new AVSR framework termed AD-AVSR based on bidirectional modality enhancement. Specifically, we first introduce the audio dual-stream encoding strategy to enrich audio representations from multiple perspectives and intentionally establish asymmetry to support subsequent cross-modal interactions. The enhancement process involves two key components, Audio-aware Visual Refinement Module for enhanced visual representations under audio guidance, and Cross-modal Noise Suppression Masking Module which refines audio representations using visual cues, collaboratively leading to the closed-loop and bidirectional information flow. To further enhance correlation robustness, we adopt a threshold-based selection mechanism to filter out irrelevant or weakly correlated audio-visual pairs. Extensive experimental results on the LRS2 and LRS3 datasets indicate that our AD-AVSR consistently surpasses SOTA methods in both performance and noise robustness, highlighting the effectiveness of our model design.",
    "source": "arXiv"
  },
  {
    "title": "End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy",
    "title_es": "End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy",
    "url": "https://arxiv.org/abs/2508.07611",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07611v1 Announce Type: new \nAbstract: The deployment of humanoid robots in unstructured, human-centric environments requires navigation capabilities that extend beyond simple locomotion to include robust perception, provable safety, and socially aware behavior. Current reinforcement learning approaches are often limited by blind controllers that lack environmental awareness or by vision-based systems that fail to perceive complex 3D obstacles. In this work, we present an end-to-end locomotion policy that directly maps raw, spatio-temporal LiDAR point clouds to motor commands, enabling robust navigation in cluttered dynamic scenes. We formulate the control problem as a Constrained Markov Decision Process (CMDP) to formally separate safety from task objectives. Our key contribution is a novel methodology that translates the principles of Control Barrier Functions (CBFs) into costs within the CMDP, allowing a model-free Penalized Proximal Policy Optimization (P3O) to enforce safety constraints during training. Furthermore, we introduce a set of comfort-oriented rewards, grounded in human-robot interaction research, to promote motions that are smooth, predictable, and less intrusive. We demonstrate the efficacy of our framework through a successful sim-to-real transfer to a physical humanoid robot, which exhibits agile and safe navigation around both static and dynamic 3D obstacles.",
    "source": "arXiv"
  },
  {
    "title": "UMRE: A Unified Monotonic Transformation for Ranking Ensemble in Recommender Systems",
    "title_es": "UMRE: A Unified Monotonic Transformation for Ranking Ensemble in Recommender Systems",
    "url": "https://arxiv.org/abs/2508.07613",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07613v1 Announce Type: new \nAbstract: Industrial recommender systems commonly rely on ensemble sorting (ES) to combine predictions from multiple behavioral objectives. Traditionally, this process depends on manually designed nonlinear transformations (e.g., polynomial or exponential functions) and hand-tuned fusion weights to balance competing goals -- an approach that is labor-intensive and frequently suboptimal in achieving Pareto efficiency. In this paper, we propose a novel Unified Monotonic Ranking Ensemble (UMRE) framework to address the limitations of traditional methods in ensemble sorting. UMRE replaces handcrafted transformations with Unconstrained Monotonic Neural Networks (UMNN), which learn expressive, strictly monotonic functions through the integration of positive neural integrals. Subsequently, a lightweight ranking model is employed to fuse the prediction scores, assigning personalized weights to each prediction objective. To balance competing goals, we further introduce a Pareto optimality strategy that adaptively coordinates task weights during training. UMRE eliminates manual tuning, maintains ranking consistency, and achieves fine-grained personalization. Experimental results on two public recommendation datasets (Kuairand and Tenrec) and online A/B tests demonstrate impressive performance and generalization capabilities.",
    "source": "arXiv"
  },
  {
    "title": "Verification Method for Graph Isomorphism Criteria",
    "title_es": "Verification Method for Graph Isomorphism Criteria",
    "url": "https://arxiv.org/abs/2508.07615",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07615v1 Announce Type: new \nAbstract: The criteria for determining graph isomorphism are crucial for solving graph isomorphism problems. The necessary condition is that two isomorphic graphs possess invariants, but their function can only be used to filtrate and subdivide candidate spaces. The sufficient conditions are used to rebuild the isomorphic reconstruction of special graphs, but their drawback is that the isomorphic functions of subgraphs may not form part of the isomorphic functions of the parent graph. The use of sufficient or necessary conditions generally results in backtracking to ensure the correctness of the decision algorithm. The sufficient and necessary conditions can ensure that the determination of graph isomorphism does not require backtracking, but the correctness of its proof process is difficult to guarantee. This article proposes a verification method that can correctly determine whether the judgment conditions proposed by previous researchers are sufficient and necessary conditions. A subdivision method has also been proposed in this article, which can obtain more subdivisions for necessary conditions and effectively reduce the size of backtracking space.",
    "source": "arXiv"
  },
  {
    "title": "ThinkTuning: Instilling Cognitive Reflections without Distillation",
    "title_es": "ThinkTuning: Instilling Cognitive Reflections without Distillation",
    "url": "https://arxiv.org/abs/2508.07616",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07616v1 Announce Type: new \nAbstract: Recent advances in test-time scaling have led to the emergence of thinking LLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL drives this self-improvement paradigm, a recent study (Gandhi et al., 2025) shows that RL alone does not truly instill these new reasoning abilities - it merely draws out behaviors already present in the base models. This raises a question: How can we train the models that don't exhibit such thinking behavior to develop it in the first place? To this end, we propose ThinkTuning, a GRPO-based interactive training approach where we augment the rollouts of a student model with the guidance from a teacher model. A simple idea from classroom practice inspires our method: a teacher poses a problem, lets the student try an answer, then gives corrective feedback -- enough to point the mind in the right direction and then show the solution. Each piece of feedback reshapes the student's thoughts, leading them to arrive at the correct solution. Similarly, we find that this type of implicit supervision through feedback from a teacher model of the same size improves the reasoning capabilities of the student model. In particular, on average, our method shows a 3.85% improvement over zero-shot baselines across benchmarks, and on MATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements over the vanilla-GRPO baseline. Source code is available at https://github.com/3rdAT/ThinkTuning.",
    "source": "arXiv"
  },
  {
    "title": "On the Limits of Selective AI Prediction: A Case Study in Clinical Decision Making",
    "title_es": "On the Limits of Selective AI Prediction: A Case Study in Clinical Decision Making",
    "url": "https://arxiv.org/abs/2508.07617",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07617v1 Announce Type: new \nAbstract: AI has the potential to augment human decision making. However, even high-performing models can produce inaccurate predictions when deployed. These inaccuracies, combined with automation bias, where humans overrely on AI predictions, can result in worse decisions. Selective prediction, in which potentially unreliable model predictions are hidden from users, has been proposed as a solution. This approach assumes that when AI abstains and informs the user so, humans make decisions as they would without AI involvement. To test this assumption, we study the effects of selective prediction on human decisions in a clinical context. We conducted a user study of 259 clinicians tasked with diagnosing and treating hospitalized patients. We compared their baseline performance without any AI involvement to their AI-assisted accuracy with and without selective prediction. Our findings indicate that selective prediction mitigates the negative effects of inaccurate AI in terms of decision accuracy. Compared to no AI assistance, clinician accuracy declined when shown inaccurate AI predictions (66% [95% CI: 56%-75%] vs. 56% [95% CI: 46%-66%]), but recovered under selective prediction (64% [95% CI: 54%-73%]). However, while selective prediction nearly maintains overall accuracy, our results suggest that it alters patterns of mistakes: when informed the AI abstains, clinicians underdiagnose (18% increase in missed diagnoses) and undertreat (35% increase in missed treatments) compared to no AI input at all. Our findings underscore the importance of empirically validating assumptions about how humans engage with AI within human-AI systems.",
    "source": "arXiv"
  },
  {
    "title": "An Iterative Reconstruction Method for Dental Cone-Beam Computed Tomography with a Truncated Field of View",
    "title_es": "An Iterative Reconstruction Method for Dental Cone-Beam Computed Tomography with a Truncated Field of View",
    "url": "https://arxiv.org/abs/2508.07618",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07618v1 Announce Type: new \nAbstract: In dental cone-beam computed tomography (CBCT), compact and cost-effective system designs often use small detectors, resulting in a truncated field of view (FOV) that does not fully encompass the patient's head. In iterative reconstruction approaches, the discrepancy between the actual projection and the forward projection within the truncated FOV accumulates over iterations, leading to significant degradation in the reconstructed image quality. In this study, we propose a two-stage approach to mitigate truncation artifacts in dental CBCT. In the first stage, we employ Implicit Neural Representation (INR), leveraging its superior representation power, to generate a prior image over an extended region so that its forward projection fully covers the patient's head. To reduce computational and memory burdens, INR reconstruction is performed with a coarse voxel size. The forward projection of this prior image is then used to estimate the discrepancy due to truncated FOV in the measured projection data. In the second stage, the discrepancy-corrected projection data is utilized in a conventional iterative reconstruction process within the truncated region. Our numerical results demonstrate that the proposed two-grid approach effectively suppresses truncation artifacts, leading to improved CBCT image quality.",
    "source": "arXiv"
  },
  {
    "title": "Counting Martingales for Measure and Dimension in Complexity Classes",
    "title_es": "Counting Martingales for Measure and Dimension in Complexity Classes",
    "url": "https://arxiv.org/abs/2508.07619",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07619v1 Announce Type: new \nAbstract: This paper makes two primary contributions. First, we introduce the concept of counting martingales and use it to define counting measures, counting dimensions, and counting strong dimensions. Second, we apply these new tools to strengthen previous circuit lower bounds.\n  Resource-bounded measure and dimension have traditionally focused on deterministic time and space bounds. We use counting complexity classes to develop resource-bounded counting measures and dimensions. Counting martingales are constructed using functions from the #P, SpanP, and GapP complexity classes. We show that counting martingales capture many martingale constructions in complexity theory. The resulting counting measures and dimensions are intermediate in power between the standard time-bounded and space-bounded notions, enabling finer-grained analysis where space-bounded measures are known, but time-bounded measures remain open. For example, we show that BPP has #P-dimension 0 and BQP has GapP-dimension 0.\n  As our main application, we improve circuit-size lower bounds. Lutz (1992) strengthened Shannon's classic $(1-\\epsilon)\\frac{2^n}{n}$ lower bound (1949) to PSPACE-measure, showing that almost all problems require circuits of size $\\frac{2^n}{n}\\left(1+\\frac{\\alpha \\log n}{n}\\right)$, for any $\\alpha < 1$. We extend this result to SpanP-measure, with a proof that uses a connection through the Minimum Circuit Size Problem (MCSP) to construct a counting martingale. Our results imply that the stronger lower bound holds within the third level of the exponential-time hierarchy, whereas previously, it was only known in ESPACE. We study the #P-dimension of classical circuit complexity classes and the GapP-dimension of quantum circuit complexity classes. We also show that if one-way functions exist, then #P-dimension is strictly more powerful than P-dimension.",
    "source": "arXiv"
  },
  {
    "title": "Are UX evaluation methods truly accessible",
    "title_es": "Are UX evaluation methods truly accessible",
    "url": "https://arxiv.org/abs/2508.07620",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07620v1 Announce Type: new \nAbstract: Providing an equitable and inclusive user experience (UX) for people with disabilities (PWD) is a central goal of accessible design. In the specific case of Deaf users, whose hearing impairments impact language development and communication, it is essential to consider their specific needs during software evaluation processes. This study aimed to analyze a set of UX evaluation methods suggested in the literature as suitable for Deaf individuals, with the goal of validating their level of accessibility in real-world contexts. The research was based on a critical review and practical application of these methods, identifying their strengths and limitations in relation to the interaction, perception, and comprehension of Deaf users. Traditional evaluation instruments, commonly designed for hearing individuals, pose significant barriers when applied to Deaf users due to their re-liance on auditory and cognitive abilities, as well as the lack of consideration for commu-nicational accessibility. The results show that although these methods are frequently rec-ommended, they exhibit critical shortcomings that hinder the collection of accurate and representative data. It is concluded that it is essential to adapt UX evaluation methods to ensure genuinely accessible processes that address the communicative and cognitive needs of the Deaf community and accurately reflect their user experience.",
    "source": "arXiv"
  },
  {
    "title": "SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation",
    "title_es": "SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation",
    "url": "https://arxiv.org/abs/2508.07621",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07621v1 Announce Type: new \nAbstract: Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with catheter ablation procedures, but procedural outcomes are highly variable. Evaluating and improving ablation efficacy is challenging due to the complex interaction between patient-specific tissue and procedural factors. This paper asks two questions: Can AF recurrence be predicted by simulating the effects of procedural parameters? How should we ablate to reduce AF recurrence? We propose SOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel deep-learning framework that addresses these questions. SOFA first simulates the outcome of an ablation strategy by generating a post-ablation image depicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and the specific procedural parameters used (e.g., ablation locations, duration, temperature, power, and force). During this simulation, it predicts AF recurrence risk. Critically, SOFA then introduces an optimization scheme that refines these procedural parameters to minimize the predicted risk. Our method leverages a multi-modal, multi-view generator that processes 2.5D representations of the atrium. Quantitative evaluations show that SOFA accurately synthesizes post-ablation images and that our optimization scheme leads to a 22.18\\% reduction in the model-predicted recurrence risk. To the best of our knowledge, SOFA is the first framework to integrate the simulation of procedural effects, recurrence prediction, and parameter optimization, offering a novel tool for personalizing AF ablation.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction",
    "title_es": "Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction",
    "url": "https://arxiv.org/abs/2508.07624",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07624v1 Announce Type: new \nAbstract: In many real-world applications involving static environments, the spatial layout of objects remains consistent across instances. However, state-of-the-art object detection models often fail to leverage this spatial prior, resulting in inconsistent predictions, missed detections, or misclassifications, particularly in cluttered or occluded scenes. In this work, we propose a graph-based post-processing pipeline that explicitly models the spatial relationships between objects to correct detection anomalies in egocentric frames. Using a graph neural network (GNN) trained on manually annotated data, our model identifies invalid object class labels and predicts corrected class labels based on their neighbourhood context. We evaluate our approach both as a standalone anomaly detection and correction framework and as a post-processing module for standard object detectors such as YOLOv7 and RT-DETR. Experiments demonstrate that incorporating this spatial reasoning significantly improves detection performance, with mAP@50 gains of up to 4%. This method highlights the potential of leveraging the environment's spatial structure to improve reliability in object detection systems.",
    "source": "arXiv"
  },
  {
    "title": "A Trustworthy Method for Multimodal Emotion Recognition",
    "title_es": "A Trustworthy Method for Multimodal Emotion Recognition",
    "url": "https://arxiv.org/abs/2508.07625",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07625v1 Announce Type: new \nAbstract: Existing emotion recognition methods mainly focus on enhancing performance by employing complex deep models, typically resulting in significantly higher model complexity. Although effective, it is also crucial to ensure the reliability of the final decision, especially for noisy, corrupted and out-of-distribution data. To this end, we propose a novel emotion recognition method called trusted emotion recognition (TER), which utilizes uncertainty estimation to calculate the confidence value of predictions. TER combines the results from multiple modalities based on their confidence values to output the trusted predictions. We also provide a new evaluation criterion to assess the reliability of predictions. Specifically, we incorporate trusted precision and trusted recall to determine the trusted threshold and formulate the trusted Acc. and trusted F1 score to evaluate the model's trusted performance. The proposed framework combines the confidence module that accordingly endows the model with reliability and robustness against possible noise or corruption. The extensive experimental results validate the effectiveness of our proposed model. The TER achieves state-of-the-art performance on the Music-video, achieving 82.40% Acc. In terms of trusted performance, TER outperforms other methods on the IEMOCAP and Music-video, achieving trusted F1 scores of 0.7511 and 0.9035, respectively.",
    "source": "arXiv"
  },
  {
    "title": "AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning",
    "title_es": "AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning",
    "url": "https://arxiv.org/abs/2508.07626",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07626v1 Announce Type: new \nAbstract: Visual Robot Manipulation (VRM) aims to enable a robot to follow natural language instructions based on robot states and visual observations, and therefore requires costly multi-modal data. To compensate for the deficiency of robot data, existing approaches have employed vision-language pretraining with large-scale data. However, they either utilize web data that differs from robotic tasks, or train the model in an implicit way (e.g., predicting future frames at the pixel level), thus showing limited generalization ability under insufficient robot data. In this paper, we propose to learn from large-scale human action video datasets in an explicit way (i.e., imitating human actions from hand keypoints), introducing Visual Robot Manipulation with Analogical Reasoning (AR-VRM). To acquire action knowledge explicitly from human action videos, we propose a keypoint Vision-Language Model (VLM) pretraining scheme, enabling the VLM to learn human action knowledge and directly predict human hand keypoints. During fine-tuning on robot data, to facilitate the robotic arm in imitating the action patterns of human motions, we first retrieve human action videos that perform similar manipulation tasks and have similar historical observations , and then learn the Analogical Reasoning (AR) map between human hand keypoints and robot components. Taking advantage of focusing on action keypoints instead of irrelevant visual cues, our method achieves leading performance on the CALVIN benchmark {and real-world experiments}. In few-shot scenarios, our AR-VRM outperforms previous methods by large margins , underscoring the effectiveness of explicitly imitating human actions under data scarcity.",
    "source": "arXiv"
  },
  {
    "title": "Nonlinear Systems in Wireless Power Transfer Applications",
    "title_es": "Nonlinear Systems in Wireless Power Transfer Applications",
    "url": "https://arxiv.org/abs/2508.07627",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07627v1 Announce Type: new \nAbstract: As a novel pattern of energization, the wireless power transfer (WPT) offers a brand-new way to the energy acquisition for electric-driven devices, thus alleviating the over-dependence on the battery. This report presents three types of WPT systems that use nonlinear control methods, in order to acquire an in-depth understanding of the course of Nonlinear Systems.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization",
    "title_es": "Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization",
    "url": "https://arxiv.org/abs/2508.07628",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07628v1 Announce Type: new \nAbstract: The future of poultry production depends on a paradigm shift replacing subjective, labor-intensive welfare checks with data-driven, intelligent monitoring ecosystems. Traditional welfare assessments-limited by human observation and single-sensor data-cannot fully capture the complex, multidimensional nature of laying hen welfare in modern farms. Multimodal Artificial Intelligence (AI) offers a breakthrough, integrating visual, acoustic, environmental, and physiological data streams to reveal deeper insights into avian welfare dynamics. This investigation highlights multimodal As transformative potential, showing that intermediate (feature-level) fusion strategies achieve the best balance between robustness and performance under real-world poultry conditions, and offer greater scalability than early or late fusion approaches. Key adoption barriers include sensor fragility in harsh farm environments, high deployment costs, inconsistent behavioral definitions, and limited cross-farm generalizability. To address these, we introduce two novel evaluation tools - the Domain Transfer Score (DTS) to measure model adaptability across diverse farm settings, and the Data Reliability Index (DRI) to assess sensor data quality under operational constraints. We also propose a modular, context-aware deployment framework designed for laying hen environments, enabling scalable and practical integration of multimodal sensing. This work lays the foundation for a transition from reactive, unimodal monitoring to proactive, precision-driven welfare systems that unite productivity with ethical, science based animal care.",
    "source": "arXiv"
  },
  {
    "title": "Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization",
    "title_es": "Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization",
    "url": "https://arxiv.org/abs/2508.07629",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07629v1 Announce Type: new \nAbstract: We present Klear-Reasoner, a model with long reasoning capabilities that demonstrates careful deliberation during problem solving, achieving outstanding performance across multiple benchmarks. Although there are already many excellent works related to inference models in the current community, there are still many problems with reproducing high-performance inference models due to incomplete disclosure of training details. This report provides an in-depth analysis of the reasoning model, covering the entire post-training workflow from data preparation and long Chain-of-Thought supervised fine-tuning (long CoT SFT) to reinforcement learning (RL), along with detailed ablation studies for each experimental component. For SFT data, our experiments show that a small number of high-quality data sources are more effective than a large number of diverse data sources, and that difficult samples can achieve better results without accuracy filtering. In addition, we investigate two key issues with current clipping mechanisms in RL: Clipping suppresses critical exploration signals and ignores suboptimal trajectories. To address these challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO) that gently backpropagates gradients from clipped tokens. GPPO not only enhances the model's exploration capacity but also improves its efficiency in learning from negative samples. Klear-Reasoner exhibits exceptional reasoning abilities in mathematics and programming, scoring 90.5\\% on AIME 2024, 83.2\\% on AIME 2025, 66.0\\% on LiveCodeBench V5 and 58.1\\% on LiveCodeBench V6.",
    "source": "arXiv"
  },
  {
    "title": "InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information",
    "title_es": "InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information",
    "url": "https://arxiv.org/abs/2508.07630",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07630v1 Announce Type: new \nAbstract: We introduce InterChart, a diagnostic benchmark that evaluates how well vision-language models (VLMs) reason across multiple related charts, a task central to real-world applications such as scientific reporting, financial analysis, and public policy dashboards. Unlike prior benchmarks focusing on isolated, visually uniform charts, InterChart challenges models with diverse question types ranging from entity inference and trend correlation to numerical estimation and abstract multi-step reasoning grounded in 2-3 thematically or structurally related charts. We organize the benchmark into three tiers of increasing difficulty: (1) factual reasoning over individual charts, (2) integrative analysis across synthetically aligned chart sets, and (3) semantic inference over visually complex, real-world chart pairs. Our evaluation of state-of-the-art open and closed-source VLMs reveals consistent and steep accuracy declines as chart complexity increases. We find that models perform better when we decompose multi-entity charts into simpler visual units, underscoring their struggles with cross-chart integration. By exposing these systematic limitations, InterChart provides a rigorous framework for advancing multimodal reasoning in complex, multi-visual environments.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo",
    "title_es": "Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo",
    "url": "https://arxiv.org/abs/2508.07631",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07631v1 Announce Type: new \nAbstract: We study the problem of posterior sampling in the context of score based generative models. We have a trained score network for a prior $p(x)$, a measurement model $p(y|x)$, and are tasked with sampling from the posterior $p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case) under well-accepted computational hardness assumptions. Despite this, popular algorithms for tasks such as image super-resolution, stylization, and reconstruction enjoy empirical success. Rather than establishing distributional assumptions or restricted settings under which exact posterior sampling is tractable, we view this as a more general \"tilting\" problem of biasing a distribution towards a measurement. Under minimal assumptions, we show that one can tractably sample from a distribution that is simultaneously close to the posterior of a noised prior in KL divergence and the true posterior in Fisher divergence. Intuitively, this combination ensures that the resulting sample is consistent with both the measurement and the prior. To the best of our knowledge these are the first formal results for (approximate) posterior sampling in polynomial time.",
    "source": "arXiv"
  },
  {
    "title": "Attribution Explanations for Deep Neural Networks: A Theoretical Perspective",
    "title_es": "Attribution Explanations for Deep Neural Networks: A Theoretical Perspective",
    "url": "https://arxiv.org/abs/2508.07636",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07636v1 Announce Type: new \nAbstract: Attribution explanation is a typical approach for explaining deep neural networks (DNNs), inferring an importance or contribution score for each input variable to the final output. In recent years, numerous attribution methods have been developed to explain DNNs. However, a persistent concern remains unresolved, i.e., whether and which attribution methods faithfully reflect the actual contribution of input variables to the decision-making process. The faithfulness issue undermines the reliability and practical utility of attribution explanations. We argue that these concerns stem from three core challenges. First, difficulties arise in comparing attribution methods due to their unstructured heterogeneity, differences in heuristics, formulations, and implementations that lack a unified organization. Second, most methods lack solid theoretical underpinnings, with their rationales remaining absent, ambiguous, or unverified. Third, empirically evaluating faithfulness is challenging without ground truth. Recent theoretical advances provide a promising way to tackle these challenges, attracting increasing attention. We summarize these developments, with emphasis on three key directions: (i) Theoretical unification, which uncovers commonalities and differences among methods, enabling systematic comparisons; (ii) Theoretical rationale, clarifying the foundations of existing methods; (iii) Theoretical evaluation, rigorously proving whether methods satisfy faithfulness principles. Beyond a comprehensive review, we provide insights into how these studies help deepen theoretical understanding, inform method selection, and inspire new attribution methods. We conclude with a discussion of promising open problems for further work.",
    "source": "arXiv"
  },
  {
    "title": "Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs",
    "title_es": "Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs",
    "url": "https://arxiv.org/abs/2508.07637",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07637v1 Announce Type: new \nAbstract: Implicit continuous models, such as functional models and implicit neural networks, are an increasingly popular method for replacing discrete data representations with continuous, high-order, and differentiable surrogates. These models offer new perspectives on the storage, transfer, and analysis of scientific data. In this paper, we introduce the first framework to directly extract complex topological features -- contours, Jacobi sets, and ridge-valley graphs -- from a type of continuous implicit model known as multivariate functional approximation (MFA). MFA replaces discrete data with continuous piecewise smooth functions. Given an MFA model as the input, our approach enables direct extraction of complex topological features from the model, without reverting to a discrete representation of the model. Our work is easily generalizable to any continuous implicit model that supports the queries of function values and high-order derivatives. Our work establishes the building blocks for performing topological data analysis and visualization on implicit continuous models.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals",
    "title_es": "Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals",
    "url": "https://arxiv.org/abs/2508.07638",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07638v1 Announce Type: new \nAbstract: Aligning Large Language Models (LLMs) with diverse human values requires moving beyond a single holistic \"better-than\" preference criterion. While collecting fine-grained, aspect-specific preference data is more reliable and scalable, existing methods like Direct Preference Optimization (DPO) struggle with the severe noise and conflicts inherent in such aggregated datasets. In this paper, we tackle this challenge from a data-centric perspective. We first derive the Direct Multi-Preference Optimization (DMPO) objective, and uncover a key Preference Divergence (PD) term that quantifies inter-aspect preference conflicts. Instead of using this term for direct optimization, we leverage it to formulate a novel, theoretically-grounded data selection principle. Our principle advocates for selecting a subset of high-consensus data-identified by the most negative PD values-for efficient DPO training. We prove the optimality of this strategy by analyzing the loss bounds of the DMPO objective in the selection problem. To operationalize our approach, we introduce practical methods of PD term estimation and length bias mitigation, thereby proposing our PD selection method. Evaluation on the UltraFeedback dataset with three varying conflict levels shows that our simple yet effective strategy achieves over 10% relative improvement against both the standard holistic preference and a stronger oracle using aggregated preference signals, all while boosting training efficiency and obviating the need for intractable holistic preference annotating, unlocking the potential of robust LLM alignment via fine-grained preference signals.",
    "source": "arXiv"
  },
  {
    "title": "Taming Cold Starts: Proactive Serverless Scheduling with Model Predictive Control",
    "title_es": "Taming Cold Starts: Proactive Serverless Scheduling with Model Predictive Control",
    "url": "https://arxiv.org/abs/2508.07640",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07640v1 Announce Type: new \nAbstract: Serverless computing has transformed cloud application deployment by introducing a fine-grained, event-driven execution model that abstracts away infrastructure management. Its on-demand nature makes it especially appealing for latency-sensitive and bursty workloads. However, the cold start problem, i.e., where the platform incurs significant delay when provisioning new containers, remains the Achilles' heel of such platforms.\n  This paper presents a predictive serverless scheduling framework based on Model Predictive Control to proactively mitigate cold starts, thereby improving end-to-end response time. By forecasting future invocations, the controller jointly optimizes container prewarming and request dispatching, improving latency while minimizing resource overhead.\n  We implement our approach on Apache OpenWhisk, deployed on a Kubernetes-based testbed. Experimental results using real-world function traces and synthetic workloads demonstrate that our method significantly outperforms state-of-the-art baselines, achieving up to 85% lower tail latency and a 34% reduction in resource usage.",
    "source": "arXiv"
  },
  {
    "title": "Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents",
    "title_es": "Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents",
    "url": "https://arxiv.org/abs/2508.07642",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07642v1 Announce Type: new \nAbstract: Vision-and-Language Navigation (VLN) poses significant challenges in enabling agents to interpret natural language instructions and navigate complex 3D environments. While recent progress has been driven by large-scale pre-training and data augmentation, current methods still struggle to generalize to unseen scenarios, particularly when complex spatial and temporal reasoning is required. In this work, we propose SkillNav, a modular framework that introduces structured, skill-based reasoning into Transformer-based VLN agents. Our method decomposes navigation into a set of interpretable atomic skills (e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each handled by a specialized agent. We then introduce a novel zero-shot Vision-Language Model (VLM)-based router, which dynamically selects the most suitable agent at each time step by aligning sub-goals with visual observations and historical actions. SkillNav achieves a new state-of-the-art performance on the R2R benchmark and demonstrates strong generalization to the GSA-R2R benchmark that includes novel instruction styles and unseen environments.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Turn Jailbreaks Are Simpler Than They Seem",
    "title_es": "Multi-Turn Jailbreaks Are Simpler Than They Seem",
    "url": "https://arxiv.org/abs/2508.07646",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07646v1 Announce Type: new \nAbstract: While defenses against single-turn jailbreak attacks on Large Language Models (LLMs) have improved significantly, multi-turn jailbreaks remain a persistent vulnerability, often achieving success rates exceeding 70% against models optimized for single-turn protection. This work presents an empirical analysis of automated multi-turn jailbreak attacks across state-of-the-art models including GPT-4, Claude, and Gemini variants, using the StrongREJECT benchmark. Our findings challenge the perceived sophistication of multi-turn attacks: when accounting for the attacker's ability to learn from how models refuse harmful requests, multi-turn jailbreaking approaches are approximately equivalent to simply resampling single-turn attacks multiple times. Moreover, attack success is correlated among similar models, making it easier to jailbreak newly released ones. Additionally, for reasoning models, we find surprisingly that higher reasoning effort often leads to higher attack success rates. Our results have important implications for AI safety evaluation and the design of jailbreak-resistant systems. We release the source code at https://github.com/diogo-cruz/multi_turn_simpler",
    "source": "arXiv"
  },
  {
    "title": "LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering",
    "title_es": "LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering",
    "url": "https://arxiv.org/abs/2508.07647",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07647v1 Announce Type: new \nAbstract: We propose a novel training-free image generation algorithm that precisely controls the occlusion relationships between objects in an image. Existing image generation methods typically rely on prompts to influence occlusion, which often lack precision. While layout-to-image methods provide control over object locations, they fail to address occlusion relationships explicitly. Given a pre-trained image diffusion model, our method leverages volume rendering principles to \"render\" the scene in latent space, guided by occlusion relationships and the estimated transmittance of objects. This approach does not require retraining or fine-tuning the image diffusion model, yet it enables accurate occlusion control due to its physics-grounded foundation. In extensive experiments, our method significantly outperforms existing approaches in terms of occlusion accuracy. Furthermore, we demonstrate that by adjusting the opacities of objects or concepts during rendering, our method can achieve a variety of effects, such as altering the transparency of objects, the density of mass (e.g., forests), the concentration of particles (e.g., rain, fog), the intensity of light, and the strength of lens effects, etc.",
    "source": "arXiv"
  },
  {
    "title": "Grasp-HGN: Grasping the Unexpected",
    "title_es": "Grasp-HGN: Grasping the Unexpected",
    "url": "https://arxiv.org/abs/2508.07648",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07648v1 Announce Type: new \nAbstract: For transradial amputees, robotic prosthetic hands promise to regain the capability to perform daily living activities. To advance next-generation prosthetic hand control design, it is crucial to address current shortcomings in robustness to out of lab artifacts, and generalizability to new environments. Due to the fixed number of object to interact with in existing datasets, contrasted with the virtually infinite variety of objects encountered in the real world, current grasp models perform poorly on unseen objects, negatively affecting users' independence and quality of life.\n  To address this: (i) we define semantic projection, the ability of a model to generalize to unseen object types and show that conventional models like YOLO, despite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose Grasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to infer the suitable grasp type estimate based on the object's physical characteristics resulting in a significant 50.2% accuracy over unseen object types compared to 36.7% accuracy of an SOTA grasp estimation model.\n  Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp Network (HGN), an edge-cloud deployment infrastructure enabling fast grasp estimation on edge and accurate cloud inference as a fail-safe, effectively expanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC) enables dynamic switching between edge and cloud models, improving semantic projection accuracy by 5.6% (to 42.3%) with 3.5x speedup over the unseen object types. Over a real-world sample mix, it reaches 86% average accuracy (12.2% gain over edge-only), and 2.2x faster inference than Grasp-LLaVA alone.",
    "source": "arXiv"
  },
  {
    "title": "Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation",
    "title_es": "Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation",
    "url": "https://arxiv.org/abs/2508.07649",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07649v1 Announce Type: new \nAbstract: Next Point-of-Interest (POI) recommendation is a research hotspot in business intelligence, where users' spatial-temporal transitions and social relationships play key roles. However, most existing works model spatial and temporal transitions separately, leading to misaligned representations of the same spatial-temporal key nodes. This misalignment introduces redundant information during fusion, increasing model uncertainty and reducing interpretability. To address this issue, we propose DiMuST, a socially enhanced POI recommendation model based on disentangled representation learning over multiplex spatial-temporal transition graphs. The model employs a novel Disentangled variational multiplex graph Auto-Encoder (DAE), which first disentangles shared and private distributions using a multiplex spatial-temporal graph strategy. It then fuses the shared features via a Product of Experts (PoE) mechanism and denoises the private features through contrastive constraints. The model effectively captures the spatial-temporal transition representations of POIs while preserving the intrinsic correlation of their spatial-temporal relationships. Experiments on two challenging datasets demonstrate that our DiMuST significantly outperforms existing methods across multiple metrics.",
    "source": "arXiv"
  },
  {
    "title": "GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions",
    "title_es": "GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions",
    "url": "https://arxiv.org/abs/2508.07650",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07650v1 Announce Type: new \nAbstract: Vision-language-action models have emerged as a crucial paradigm in robotic manipulation. However, existing VLA models exhibit notable limitations in handling ambiguous language instructions and unknown environmental states. Furthermore, their perception is largely constrained to static two-dimensional observations, lacking the capability to model three-dimensional interactions between the robot and its environment. To address these challenges, this paper proposes GraphCoT-VLA, an efficient end-to-end model. To enhance the model's ability to interpret ambiguous instructions and improve task planning, we design a structured Chain-of-Thought reasoning module that integrates high-level task understanding and planning, failed task feedback, and low-level imaginative reasoning about future object positions and robot actions. Additionally, we construct a real-time updatable 3D Pose-Object graph, which captures the spatial configuration of robot joints and the topological relationships between objects in 3D space, enabling the model to better understand and manipulate their interactions. We further integrates a dropout hybrid reasoning strategy to achieve efficient control outputs. Experimental results across multiple real-world robotic tasks demonstrate that GraphCoT-VLA significantly outperforms existing methods in terms of task success rate and response speed, exhibiting strong generalization and robustness in open environments and under uncertain instructions.",
    "source": "arXiv"
  },
  {
    "title": "MLego: Interactive and Scalable Topic Exploration Through Model Reuse",
    "title_es": "MLego: Interactive and Scalable Topic Exploration Through Model Reuse",
    "url": "https://arxiv.org/abs/2508.07654",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07654v1 Announce Type: new \nAbstract: With massive texts on social media, users and analysts often rely on topic modeling techniques to quickly extract key themes and gain insights. Traditional topic modeling techniques, such as Latent Dirichlet Allocation (LDA), provide valuable insights but are computationally expensive, making them impractical for real-time data analysis. Although recent advances in distributed training and fast sampling methods have improved efficiency, real-time topic exploration remains a significant challenge. In this paper, we present MLego, an interactive query framework designed to support real-time topic modeling analysis by leveraging model materialization and reuse. Instead of retraining models from scratch, MLego efficiently merges materialized topic models to construct approximate results at interactive speeds. To further enhance efficiency, we introduce a hierarchical plan search strategy for single queries and an optimized query reordering technique for batch queries. We integrate MLego into a visual analytics prototype system, enabling users to explore large-scale textual datasets through interactive queries. Extensive experiments demonstrate that MLego significantly reduces computation costs while maintaining high-quality topic modeling results. MLego enhances existing visual analytics approaches, which primarily focus on user-driven topic modeling, by enabling real-time, query-driven exploration. This complements traditional methods and bridges the gap between scalable topic modeling and interactive data analysis.",
    "source": "arXiv"
  },
  {
    "title": "Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels",
    "title_es": "Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels",
    "url": "https://arxiv.org/abs/2508.07656",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07656v1 Announce Type: new \nAbstract: The acquisition of high-quality labeled synthetic aperture radar (SAR) data is challenging due to the demanding requirement for expert knowledge. Consequently, the presence of unreliable noisy labels is unavoidable, which results in performance degradation of SAR automatic target recognition (ATR). Existing research on learning with noisy labels mainly focuses on image data. However, the non-intuitive visual characteristics of SAR data are insufficient to achieve noise-robust learning. To address this problem, we propose collaborative learning of scattering and deep features (CLSDF) for SAR ATR with noisy labels. Specifically, a multi-model feature fusion framework is designed to integrate scattering and deep features. The attributed scattering centers (ASCs) are treated as dynamic graph structure data, and the extracted physical characteristics effectively enrich the representation of deep image features. Then, the samples with clean and noisy labels are divided by modeling the loss distribution with multiple class-wise Gaussian Mixture Models (GMMs). Afterward, the semi-supervised learning of two divergent branches is conducted based on the data divided by each other. Moreover, a joint distribution alignment strategy is introduced to enhance the reliability of co-guessed labels. Extensive experiments have been done on the Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset, and the results show that the proposed method can achieve state-of-the-art performance under different operating conditions with various label noises.",
    "source": "arXiv"
  },
  {
    "title": "MoRoCo: Multi-operator-robot Coordination, Interaction and Exploration under Restricted Communication",
    "title_es": "MoRoCo: Multi-operator-robot Coordination, Interaction and Exploration under Restricted Communication",
    "url": "https://arxiv.org/abs/2508.07657",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07657v1 Announce Type: new \nAbstract: Fleets of autonomous robots are increasingly deployed alongside multiple human operators to explore unknown environments, identify salient features, and perform complex tasks in scenarios such as subterranean exploration, reconnaissance, and search-and-rescue missions. In these contexts, communication is often severely limited to short-range exchanges via ad-hoc networks, posing challenges to coordination. While recent studies have addressed multi-robot exploration under communication constraints, they largely overlook the essential role of human operators and their real-time interaction with robotic teams. Operators may demand timely updates on the exploration progress and robot status, reprioritize or cancel tasks dynamically, or request live video feeds and control access. Conversely, robots may seek human confirmation for anomalous events or require help recovering from motion or planning failures. To enable such bilateral, context-aware interactions under restricted communication, this work proposes MoRoCo, a unified framework for online coordination and exploration in multi-operator, multi-robot systems. MoRoCo enables the team to adaptively switch among three coordination modes: spread mode for parallelized exploration with intermittent data sharing, migrate mode for coordinated relocation, and chain mode for maintaining high-bandwidth connectivity through multi-hop links. These transitions are managed through distributed algorithms via only local communication. Extensive large-scale human-in-the-loop simulations and hardware experiments validate the necessity of incorporating human robot interactions and demonstrate that MoRoCo enables efficient, reliable coordination under limited communication, marking a significant step toward robust human-in-the-loop multi-robot autonomy in challenging environments.",
    "source": "arXiv"
  },
  {
    "title": "Through Their Eyes: User Perceptions on Sensitive Attribute Inference of Social Media Videos by Visual Language Models",
    "title_es": "Through Their Eyes: User Perceptions on Sensitive Attribute Inference of Social Media Videos by Visual Language Models",
    "url": "https://arxiv.org/abs/2508.07658",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07658v1 Announce Type: new \nAbstract: The rapid advancement of Visual Language Models (VLMs) has enabled sophisticated analysis of visual content, leading to concerns about the inference of sensitive user attributes and subsequent privacy risks. While technical capabilities of VLMs are increasingly studied, users' understanding, perceptions, and reactions to these inferences remain less explored, especially concerning videos uploaded on the social media. This paper addresses this gap through a semi-structured interview (N=17), investigating user perspectives on VLM-driven sensitive attribute inference from their visual data. Findings reveal that users perceive VLMs as capable of inferring a range of attributes, including location, demographics, and socioeconomic indicators, often with unsettling accuracy. Key concerns include unauthorized identification, misuse of personal information, pervasive surveillance, and harm from inaccurate inferences. Participants reported employing various mitigation strategies, though with skepticism about their ultimate effectiveness against advanced AI. Users also articulate clear expectations for platforms and regulators, emphasizing the need for enhanced transparency, user control, and proactive privacy safeguards. These insights are crucial for guiding the development of responsible AI systems, effective privacy-enhancing technologies, and informed policymaking that aligns with user expectations and societal values.",
    "source": "arXiv"
  },
  {
    "title": "Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning",
    "title_es": "Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning",
    "url": "https://arxiv.org/abs/2508.07659",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07659v1 Announce Type: new \nAbstract: This study aims to discover spatial correlations between Earth observations and atmospheric states to improve the forecasting accuracy of global atmospheric state estimation, which are usually conducted using conventional numerical weather prediction (NWP) systems and is the beginning of weather forecasting. NWP systems predict future atmospheric states at fixed locations, which are called NWP grid points, by analyzing previous atmospheric states and newly acquired Earth observations without fixed locations. Thus, surrounding meteorological context and the changing locations of the observations make spatial correlations between atmospheric states and observations over time. To handle complicated spatial correlations, which change dynamically, we employ spatiotemporal graph neural networks (STGNNs) with structure learning. However, structure learning has an inherent limitation that this can cause structural information loss and over-smoothing problem by generating excessive edges. To solve this problem, we regulate edge sampling by adaptively determining node degrees and considering the spatial distances between NWP grid points and observations. We validated the effectiveness of the proposed method by using real-world atmospheric state and observation data from East Asia. Even in areas with high atmospheric variability, the proposed method outperformed existing STGNN models with and without structure learning.",
    "source": "arXiv"
  },
  {
    "title": "GLiClass: Generalist Lightweight Model for Sequence Classification Tasks",
    "title_es": "GLiClass: Generalist Lightweight Model for Sequence Classification Tasks",
    "url": "https://arxiv.org/abs/2508.07662",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07662v1 Announce Type: new \nAbstract: Classification is one of the most widespread tasks in AI applications, serving often as the first step in filtering, sorting, and categorizing data. Since modern AI systems must handle large volumes of input data and early pipeline stages can propagate errors downstream, achieving high efficiency and accuracy is critical. Moreover, classification requirements can change dynamically based on user needs, necessitating models with strong zero-shot capabilities. While generative LLMs have become mainstream for zero-shot classification due to their versatility, they suffer from inconsistent instruction following and computational inefficiency. Cross-encoders, commonly used as rerankers in RAG pipelines, face a different bottleneck: they must process text-label pairs sequentially, significantly reducing efficiency with large label sets. Embedding-based approaches offer good efficiency but struggle with complex scenarios involving logical and semantic constraints. We propose GLiClass, a novel method that adapts the GLiNER architecture for sequence classification tasks. Our approach achieves strong accuracy and efficiency comparable to embedding-based methods, while maintaining the flexibility needed for zero-shot and few-shot learning scenarios. Additionally, we adapted proximal policy optimization (PPO) for multi-label text classification, enabling training classifiers in data-sparse conditions or from human feedback.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Users' Privacy Perceptions Towards LLM's RAG-based Memory",
    "title_es": "Understanding Users' Privacy Perceptions Towards LLM's RAG-based Memory",
    "url": "https://arxiv.org/abs/2508.07664",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07664v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly integrating memory functionalities to provide personalized and context-aware interactions. However, user understanding, practices and expectations regarding these memory systems are not yet well understood. This paper presents a thematic analysis of semi-structured interviews with 18 users to explore their mental models of LLM's Retrieval Augmented Generation (RAG)-based memory, current usage practices, perceived benefits and drawbacks, privacy concerns and expectations for future memory systems. Our findings reveal diverse and often incomplete mental models of how memory operates. While users appreciate the potential for enhanced personalization and efficiency, significant concerns exist regarding privacy, control and the accuracy of remembered information. Users express a desire for granular control over memory generation, management, usage and updating, including clear mechanisms for reviewing, editing, deleting and categorizing memories, as well as transparent insight into how memories and inferred information are used. We discuss design implications for creating more user-centric, transparent, and trustworthy LLM memory systems.",
    "source": "arXiv"
  },
  {
    "title": "Towards Multimodal Sentiment Analysis via Contrastive Cross-modal Retrieval Augmentation and Hierachical Prompts",
    "title_es": "Towards Multimodal Sentiment Analysis via Contrastive Cross-modal Retrieval Augmentation and Hierachical Prompts",
    "url": "https://arxiv.org/abs/2508.07666",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07666v1 Announce Type: new \nAbstract: Multimodal sentiment analysis is a fundamental problem in the field of affective computing. Although significant progress has been made in cross-modal interaction, it remains a challenge due to the insufficient reference context in cross-modal interactions. Current cross-modal approaches primarily focus on leveraging modality-level reference context within a individual sample for cross-modal feature enhancement, neglecting the potential cross-sample relationships that can serve as sample-level reference context to enhance the cross-modal features. To address this issue, we propose a novel multimodal retrieval-augmented framework to simultaneously incorporate inter-sample modality-level reference context and cross-sample sample-level reference context to enhance the multimodal features. In particular, we first design a contrastive cross-modal retrieval module to retrieve semantic similar samples and enhance target modality. To endow the model to capture both inter-sample and intra-sample information, we integrate two different types of prompts, modality-level prompts and sample-level prompts, to generate modality-level and sample-level reference contexts, respectively. Finally, we design a cross-modal retrieval-augmented encoder that simultaneously leverages modality-level and sample-level reference contexts to enhance the target modality. Extensive experiments demonstrate the effectiveness and superiority of our model on two publicly available datasets.",
    "source": "arXiv"
  },
  {
    "title": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning",
    "title_es": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning",
    "url": "https://arxiv.org/abs/2508.07667",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07667v1 Announce Type: new \nAbstract: Addressing contextual privacy concerns remains challenging in interactive settings where large language models (LLMs) process information from multiple sources (e.g., summarizing meetings with private and public information). We introduce a multi-agent framework that decomposes privacy reasoning into specialized subtasks (extraction, classification), reducing the information load on any single agent while enabling iterative validation and more reliable adherence to contextual privacy norms. To understand how privacy errors emerge and propagate, we conduct a systematic ablation over information-flow topologies, revealing when and why upstream detection mistakes cascade into downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with several open-source and closed-sourced LLMs demonstrate that our best multi-agent configuration substantially reduces private information leakage (\\textbf{18\\%} on ConfAIde and \\textbf{19\\%} on PrivacyLens with GPT-4o) while preserving the fidelity of public content, outperforming single-agent baselines. These results highlight the promise of principled information-flow design in multi-agent systems for contextual privacy with LLMs.",
    "source": "arXiv"
  },
  {
    "title": "AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting",
    "title_es": "AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting",
    "url": "https://arxiv.org/abs/2508.07668",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07668v1 Announce Type: new \nAbstract: With the increase in maritime traffic and the mandatory implementation of the Automatic Identification System (AIS), the importance and diversity of maritime traffic analysis tasks based on AIS data, such as vessel trajectory prediction, anomaly detection, and collision risk assessment, is rapidly growing. However, existing approaches tend to address these tasks individually, making it difficult to holistically consider complex maritime situations. To address this limitation, we propose a novel framework, AIS-LLM, which integrates time-series AIS data with a large language model (LLM). AIS-LLM consists of a Time-Series Encoder for processing AIS sequences, an LLM-based Prompt Encoder, a Cross-Modality Alignment Module for semantic alignment between time-series data and textual prompts, and an LLM-based Multi-Task Decoder. This architecture enables the simultaneous execution of three key tasks: trajectory prediction, anomaly detection, and risk assessment of vessel collisions within a single end-to-end system. Experimental results demonstrate that AIS-LLM outperforms existing methods across individual tasks, validating its effectiveness. Furthermore, by integratively analyzing task outputs to generate situation summaries and briefings, AIS-LLM presents the potential for more intelligent and efficient maritime traffic management.",
    "source": "arXiv"
  },
  {
    "title": "EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration",
    "title_es": "EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration",
    "url": "https://arxiv.org/abs/2508.07671",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07671v1 Announce Type: new \nAbstract: Current AI approaches to refugee integration optimize narrow objectives such as employment and fail to capture the cultural, emotional, and ethical dimensions critical for long-term success. We introduce EMPATHIA (Enriched Multimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance), a multi-agent framework addressing the central Creative AI question: how do we preserve human dignity when machines participate in life-altering decisions? Grounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes integration into three modules: SEED (Socio-cultural Entry and Embedding Decision) for initial placement, RISE (Rapid Integration and Self-sufficiency Engine) for early independence, and THRIVE (Transcultural Harmony and Resilience through Integrated Values and Engagement) for sustained outcomes. SEED employs a selector-validator architecture with three specialized agents - emotional, cultural, and ethical - that deliberate transparently to produce interpretable recommendations. Experiments on the UN Kakuma dataset (15,026 individuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and implementation on 6,359 working-age refugees (15+) with 150+ socioeconomic variables achieved 87.4% validation convergence and explainable assessments across five host countries. EMPATHIA's weighted integration of cultural, emotional, and ethical factors balances competing value systems while supporting practitioner-AI collaboration. By augmenting rather than replacing human expertise, EMPATHIA provides a generalizable framework for AI-driven allocation tasks where multiple values must be reconciled.",
    "source": "arXiv"
  },
  {
    "title": "Towards Aligning Personalized Conversational Recommendation Agents with Users' Privacy Preferences",
    "title_es": "Towards Aligning Personalized Conversational Recommendation Agents with Users' Privacy Preferences",
    "url": "https://arxiv.org/abs/2508.07672",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07672v1 Announce Type: new \nAbstract: The proliferation of AI agents, with their complex and context-dependent actions, renders conventional privacy paradigms obsolete. This position paper argues that the current model of privacy management, rooted in a user's unilateral control over a passive tool, is inherently mismatched with the dynamic and interactive nature of AI agents. We contend that ensuring effective privacy protection necessitates that the agents proactively align with users' privacy preferences instead of passively waiting for the user to control. To ground this shift, and using personalized conversational recommendation agents as a case, we propose a conceptual framework built on Contextual Integrity (CI) theory and Privacy Calculus theory. This synthesis first reframes automatically controlling users' privacy as an alignment problem, where AI agents initially did not know users' preferences, and would learn their privacy preferences through implicit or explicit feedback. Upon receiving the preference feedback, the agents used alignment and Pareto optimization for aligning preferences and balancing privacy and utility. We introduced formulations and instantiations, potential applications, as well as five challenges.",
    "source": "arXiv"
  },
  {
    "title": "Ethics2vec: aligning automatic agents and human preferences",
    "title_es": "Ethics2vec: aligning automatic agents and human preferences",
    "url": "https://arxiv.org/abs/2508.07673",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07673v1 Announce Type: new \nAbstract: Though intelligent agents are supposed to improve human experience (or make it more efficient), it is hard from a human perspective to grasp the ethical values which are explicitly or implicitly embedded in an agent behaviour. This is the well-known problem of alignment, which refers to the challenge of designing AI systems that align with human values, goals and preferences. This problem is particularly challenging since most human ethical considerations refer to \\emph{incommensurable} (i.e. non-measurable and/or incomparable) values and criteria. Consider, for instance, a medical agent prescribing a treatment to a cancerous patient. How could it take into account (and/or weigh) incommensurable aspects like the value of a human life and the cost of the treatment? Now, the alignment between human and artificial values is possible only if we define a common space where a metric can be defined and used. This paper proposes to extend to ethics the conventional Anything2vec approach, which has been successful in plenty of similar and hard-to-quantify domains (ranging from natural language processing to recommendation systems and graph analysis). This paper proposes a way to map an automatic agent decision-making (or control law) strategy to a multivariate vector representation, which can be used to compare and assess the alignment with human values. The Ethics2Vec method is first introduced in the case of an automatic agent performing binary decision-making. Then, a vectorisation of an automatic control law (like in the case of a self-driving car) is discussed to show how the approach can be extended to automatic control settings.",
    "source": "arXiv"
  },
  {
    "title": "Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation",
    "title_es": "Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation",
    "url": "https://arxiv.org/abs/2508.07675",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07675v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are revolutionizing how users interact with information systems, yet their high inference cost poses serious scalability and sustainability challenges. Caching inference responses, allowing them to be retrieved without another forward pass through the LLM, has emerged as one possible solution. Traditional exact-match caching, however, overlooks the semantic similarity between queries, leading to unnecessary recomputation. Semantic caching addresses this by retrieving responses based on semantic similarity, but introduces a fundamentally different cache eviction problem: one must account for mismatch costs between incoming queries and cached responses. Moreover, key system parameters, such as query arrival probabilities and serving costs, are often unknown and must be learned over time. Existing semantic caching methods are largely ad-hoc, lacking theoretical foundations and unable to adapt to real-world uncertainty. In this paper, we present a principled, learning-based framework for semantic cache eviction under unknown query and cost distributions. We formulate both offline optimization and online learning variants of the problem, and develop provably efficient algorithms with state-of-the-art guarantees. We also evaluate our framework on a synthetic dataset, showing that our proposed algorithms perform matching or superior performance compared with baselines.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks",
    "title_es": "Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks",
    "url": "https://arxiv.org/abs/2508.07676",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07676v1 Announce Type: new \nAbstract: Federated learning (FL) enables collaborative model training across decentralized clients without sharing local data, thereby enhancing privacy and facilitating collaboration among clients connected via social networks. However, these social connections introduce privacy externalities: a client's privacy loss depends not only on its privacy protection strategy but also on the privacy decisions of others, propagated through the network via multi-hop interactions. In this work, we propose a socially-aware privacy-preserving FL mechanism that systematically quantifies indirect privacy leakage through a multi-hop propagation model. We formulate the server-client interaction as a two-stage Stackelberg game, where the server, as the leader, optimizes incentive policies, and clients, as followers, strategically select their privacy budgets, which determine their privacy-preserving levels by controlling the magnitude of added noise. To mitigate information asymmetry in networked privacy estimation, we introduce a mean-field estimator to approximate the average external privacy risk. We theoretically prove the existence and convergence of the fixed point of the mean-field estimator and derive closed-form expressions for the Stackelberg Nash Equilibrium. Despite being designed from a client-centric incentive perspective, our mechanism achieves approximately-optimal social welfare, as revealed by Price of Anarchy (PoA) analysis. Experiments on diverse datasets demonstrate that our approach significantly improves client utilities and reduces server costs while maintaining model performance, outperforming both Social-Agnostic (SA) baselines and methods that account for social externalities.",
    "source": "arXiv"
  },
  {
    "title": "Improving Continuous Grasp Force Decoding from EEG with Time-Frequency Regressors and Premotor-Parietal Network Integration",
    "title_es": "Improving Continuous Grasp Force Decoding from EEG with Time-Frequency Regressors and Premotor-Parietal Network Integration",
    "url": "https://arxiv.org/abs/2508.07677",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07677v1 Announce Type: new \nAbstract: Brain-machine interfaces (BMIs) have significantly advanced neuro-rehabilitation by enhancing motor control. However, accurately decoding continuous grasp force remains a challenge, limiting the effectiveness of BMI applications for fine motor tasks. Current models tend to prioritise algorithmic complexity rather than incorporating neurophysiological insights into force control, which is essential for developing effective neural engineering solutions. To address this, we propose EEGForceMap, an EEG-based methodology that isolates signals from the premotor-parietal region and extracts task-specific components. We construct three distinct time-frequency feature sets, which are validated by comparing them with prior studies, and use them for force prediction with linear, non-linear, and deep learning-based regressors. The performance of these regressors was evaluated on the WAY-EEG-GAL dataset that includes 12 subjects. Our results show that integrating EEGForceMap approach with regressor models yields a 61.7% improvement in subject-specific conditions (R-squared = 0.815) and a 55.7% improvement in subject-independent conditions (R-squared = 0.785) over the state-of-the-art kinematic decoder models. Furthermore, an ablation study confirms that each preprocessing step significantly enhances decoding accuracy. This work contributes to the advancement of responsive BMIs for stroke rehabilitation and assistive robotics by improving EEG-based decoding of dynamic grasp force.",
    "source": "arXiv"
  },
  {
    "title": "Joint link scheduling and power allocation in imperfect and energy-constrained underwater wireless sensor networks",
    "title_es": "Joint link scheduling and power allocation in imperfect and energy-constrained underwater wireless sensor networks",
    "url": "https://arxiv.org/abs/2508.07679",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07679v1 Announce Type: new \nAbstract: Underwater wireless sensor networks (UWSNs) stand as promising technologies facilitating diverse underwater applications. However, the major design issues of the considered system are the severely limited energy supply and unexpected node malfunctions. This paper aims to provide fair, efficient, and reliable (FER) communication to the imperfect and energy-constrained UWSNs (IC-UWSNs). Therefore, we formulate a FER-communication optimization problem (FERCOP) and propose ICRL-JSA to solve the formulated problem. ICRL-JSA is a deep multi-agent reinforcement learning (MARL)-based optimizer for IC-UWSNs through joint link scheduling and power allocation, which automatically learns scheduling algorithms without human intervention. However, conventional RL methods are unable to address the challenges posed by underwater environments and IC-UWSNs. To construct ICRL-JSA, we integrate deep Q-network into IC-UWSNs and propose an advanced training mechanism to deal with complex acoustic channels, limited energy supplies, and unexpected node malfunctions. Simulation results demonstrate the superiority of the proposed ICRL-JSA scheme with an advanced training mechanism compared to various benchmark algorithms.",
    "source": "arXiv"
  },
  {
    "title": "Undress to Redress: A Training-Free Framework for Virtual Try-On",
    "title_es": "Undress to Redress: A Training-Free Framework for Virtual Try-On",
    "url": "https://arxiv.org/abs/2508.07680",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07680v1 Announce Type: new \nAbstract: Virtual try-on (VTON) is a crucial task for enhancing user experience in online shopping by generating realistic garment previews on personal photos. Although existing methods have achieved impressive results, they struggle with long-sleeve-to-short-sleeve conversions-a common and practical scenario-often producing unrealistic outputs when exposed skin is underrepresented in the original image. We argue that this challenge arises from the ''majority'' completion rule in current VTON models, which leads to inaccurate skin restoration in such cases. To address this, we propose UR-VTON (Undress-Redress Virtual Try-ON), a novel, training-free framework that can be seamlessly integrated with any existing VTON method. UR-VTON introduces an ''undress-to-redress'' mechanism: it first reveals the user's torso by virtually ''undressing,'' then applies the target short-sleeve garment, effectively decomposing the conversion into two more manageable steps. Additionally, we incorporate Dynamic Classifier-Free Guidance scheduling to balance diversity and image quality during DDPM sampling, and employ Structural Refiner to enhance detail fidelity using high-frequency cues. Finally, we present LS-TON, a new benchmark for long-sleeve-to-short-sleeve try-on. Extensive experiments demonstrate that UR-VTON outperforms state-of-the-art methods in both detail preservation and image quality. Code will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation",
    "title_es": "MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation",
    "url": "https://arxiv.org/abs/2508.07681",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07681v1 Announce Type: new \nAbstract: Sepsis, a life-threatening inflammatory response to infection, causes organ dysfunction, making early detection and optimal management critical. Previous reinforcement learning (RL) approaches to sepsis management rely primarily on structured data, such as lab results or vital signs, and on a dearth of a comprehensive understanding of the patient's condition. In this work, we propose a Multimodal Offline REinforcement learning for Clinical notes Leveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis control in intensive care units. MORE-CLEAR employs pre-trained large-scale language models (LLMs) to facilitate the extraction of rich semantic representations from clinical notes, preserving clinical context and improving patient state representation. Gated fusion and cross-modal attention allow dynamic weight adjustment in the context of time and the effective integration of multimodal data. Extensive cross-validation using two public (MIMIC-III and MIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly improves estimated survival rate and policy performance compared to single-modal RL approaches. To our knowledge, this is the first to leverage LLM capabilities within a multimodal offline RL for better state representation in medical applications. This approach can potentially expedite the treatment and management of sepsis by enabling reinforcement learning models to propose enhanced actions based on a more comprehensive understanding of patient conditions.",
    "source": "arXiv"
  },
  {
    "title": "DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework",
    "title_es": "DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework",
    "url": "https://arxiv.org/abs/2508.07682",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07682v1 Announce Type: new \nAbstract: In this work, we first propose DiffVC-OSD, a One-Step Diffusion-based Perceptual Neural Video Compression framework. Unlike conventional multi-step diffusion-based methods, DiffVC-OSD feeds the reconstructed latent representation directly into a One-Step Diffusion Model, enhancing perceptual quality through a single diffusion step guided by both temporal context and the latent itself. To better leverage temporal dependencies, we design a Temporal Context Adapter that encodes conditional inputs into multi-level features, offering more fine-grained guidance for the Denoising Unet. Additionally, we employ an End-to-End Finetuning strategy to improve overall compression performance. Extensive experiments demonstrate that DiffVC-OSD achieves state-of-the-art perceptual compression performance, offers about 20$\\times$ faster decoding and a 86.92\\% bitrate reduction compared to the corresponding multi-step diffusion-based variant.",
    "source": "arXiv"
  },
  {
    "title": "TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding",
    "title_es": "TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding",
    "url": "https://arxiv.org/abs/2508.07683",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07683v1 Announce Type: new \nAbstract: Temporal Video Grounding (TVG) aims to precisely localize video segments corresponding to natural language queries, which is a critical capability for long-form video understanding. Although existing reinforcement learning approaches encourage models to generate reasoning chains before predictions, they fail to explicitly constrain the reasoning process to ensure the quality of the final temporal predictions. To address this limitation, we propose Timestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG), a novel framework that introduces timestamp anchors within the reasoning process to enforce explicit supervision to the thought content. These anchors serve as intermediate verification points. More importantly, we require each reasoning step to produce increasingly accurate temporal estimations, thereby ensuring that the reasoning process contributes meaningfully to the final prediction. To address the challenge of low-probability anchor generation in models (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation training strategy: (1) initial GRPO training to collect 30K high-quality reasoning traces containing multiple timestamp anchors, (2) supervised fine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the SFT-enhanced model. This three-stage training strategy enables robust anchor generation while maintaining reasoning quality. Experiments show that our model achieves state-of-the-art performance while producing interpretable, verifiable reasoning chains with progressively refined temporal estimations.",
    "source": "arXiv"
  },
  {
    "title": "When are safety filters safe? On minimum phase conditions of control barrier functions",
    "title_es": "When are safety filters safe? On minimum phase conditions of control barrier functions",
    "url": "https://arxiv.org/abs/2508.07684",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07684v1 Announce Type: new \nAbstract: In emerging control applications involving multiple and complex tasks, safety filters are gaining prominence as a modular approach to enforcing safety constraints. Among various methods, control barrier functions (CBFs) are widely used for designing safety filters due to their simplicity, imposing a single linear constraint on the control input at each state. In this work, we focus on the internal dynamics of systems governed by CBF-constrained control laws. Our key observation is that, although CBFs guarantee safety by enforcing state constraints, they can inadvertently be \"unsafe\" by causing the internal state to diverge. We investigate the conditions under which the full system state, including the internal state, can remain bounded under a CBF-based safety filter. Drawing inspiration from the input-output linearization literature, where boundedness is ensured by minimum phase conditions, we propose a new set of CBF minimum phase conditions tailored to the structure imposed by the CBF constraint. A critical distinction from the original minimum phase conditions is that the internal dynamics in our setting is driven by a nonnegative virtual control input, which reflects the enforcement of the safety constraint. We include a range of numerical examples, including single-input, multi-input, linear, and nonlinear systems, validating both our analysis and the necessity of the proposed CBF minimum phase conditions.",
    "source": "arXiv"
  },
  {
    "title": "Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning",
    "title_es": "Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning",
    "url": "https://arxiv.org/abs/2508.07686",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07686v1 Announce Type: new \nAbstract: End-to-end paradigm has emerged as a promising approach to autonomous driving. However, existing single-agent end-to-end pipelines are often constrained by occlusion and limited perception range, resulting in hazardous driving. Furthermore, their black-box nature prevents the interpretability of the driving behavior, leading to an untrustworthiness system. To address these limitations, we introduce Risk Map as Middleware (RiskMM) and propose an interpretable cooperative end-to-end driving framework. The risk map learns directly from the driving data and provides an interpretable spatiotemporal representation of the scenario from the upstream perception and the interactions between the ego vehicle and the surrounding environment for downstream planning. RiskMM first constructs a multi-agent spatiotemporal representation with unified Transformer-based architecture, then derives risk-aware representations by modeling interactions among surrounding environments with attention. These representations are subsequently fed into a learning-based Model Predictive Control (MPC) module. The MPC planner inherently accommodates physical constraints and different vehicle types and can provide interpretation by aligning learned parameters with explicit MPC elements. Evaluations conducted on the real-world V2XPnP-Seq dataset confirm that RiskMM achieves superior and robust performance in risk-aware trajectory planning, significantly enhancing the interpretability of the cooperative end-to-end driving framework. The codebase will be released to facilitate future research in this field.",
    "source": "arXiv"
  },
  {
    "title": "LAURON VI: A Six-Legged Robot for Dynamic Walking",
    "title_es": "LAURON VI: A Six-Legged Robot for Dynamic Walking",
    "url": "https://arxiv.org/abs/2508.07689",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07689v1 Announce Type: new \nAbstract: Legged locomotion enables robotic systems to traverse extremely challenging terrains. In many real-world scenarios, the terrain is not that difficult and these mixed terrain types introduce the need for flexible use of different walking strategies to achieve mission goals in a fast, reliable, and energy-efficient way. Six-legged robots have a high degree of flexibility and inherent stability that aids them in traversing even some of the most difficult terrains, such as collapsed buildings. However, their lack of fast walking gaits for easier surfaces is one reason why they are not commonly applied in these scenarios.\n  This work presents LAURON VI, a six-legged robot platform for research on dynamic walking gaits as well as on autonomy for complex field missions. The robot's 18 series elastic joint actuators offer high-frequency interfaces for Cartesian impedance and pure torque control. We have designed, implemented, and compared three control approaches: kinematic-based, model-predictive, and reinforcement-learned controllers. The robot hardware and the different control approaches were extensively tested in a lab environment as well as on a Mars analog mission. The introduction of fast locomotion strategies for LAURON VI makes six-legged robots vastly more suitable for a wide range of real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval",
    "title_es": "LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval",
    "url": "https://arxiv.org/abs/2508.07690",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07690v1 Announce Type: new \nAbstract: Tool learning has emerged as a promising paradigm for large language models (LLMs) to solve many real-world tasks. Nonetheless, with the tool repository rapidly expanding, it is impractical to contain all tools within the limited input length of LLMs. To alleviate these issues, researchers have explored incorporating a tool retrieval module to select the most relevant tools or represent tools as unique tokens within LLM parameters. However, most state-of-the-art methods are under transductive settings, assuming all tools have been observed during training. Such a setting deviates from reality as the real-world tool repository is evolving and incorporates new tools frequently. When dealing with these unseen tools, which refer to tools not encountered during the training phase, these methods are limited by two key issues, including the large distribution shift and the vulnerability of similarity-based retrieval. To this end, inspired by human cognitive processes of mastering unseen tools through discovering and applying the logical information from prior experience, we introduce a novel Logic-Guided Semantic Bridging framework for inductive tool retrieval, namely, LoSemB, which aims to mine and transfer latent logical information for inductive tool retrieval without costly retraining. Specifically, LoSemB contains a logic-based embedding alignment module to mitigate distribution shifts and implements a relational augmented retrieval mechanism to reduce the vulnerability of similarity-based retrieval. Extensive experiments demonstrate that LoSemB achieves advanced performance in inductive settings while maintaining desirable effectiveness in the transductive setting.",
    "source": "arXiv"
  },
  {
    "title": "Energy and Quality of Surrogate-Assisted Search Algorithms: a First Analysis",
    "title_es": "Energy and Quality of Surrogate-Assisted Search Algorithms: a First Analysis",
    "url": "https://arxiv.org/abs/2508.07691",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07691v1 Announce Type: new \nAbstract: Solving complex real problems often demands advanced algorithms, and then continuous improvements in the internal operations of a search technique are needed. Hybrid algorithms, parallel techniques, theoretical advances, and much more are needed to transform a general search algorithm into an efficient, useful one in practice. In this paper, we study how surrogates are helping metaheuristics from an important and understudied point of view: their energy profile. Even if surrogates are a great idea for substituting a time-demanding complex fitness function, the energy profile, general efficiency, and accuracy of the resulting surrogate-assisted metaheuristic still need considerable research. In this work, we make a first step in analyzing particle swarm optimization in different versions (including pre-trained and retrained neural networks as surrogates) for its energy profile (for both processor and memory), plus a further study on the surrogate accuracy to properly drive the search towards an acceptable solution. Our conclusions shed new light on this topic and could be understood as the first step towards a methodology for assessing surrogate-assisted algorithms not only accounting for time or numerical efficiency but also for energy and surrogate accuracy for a better, more holistic characterization of optimization and learning techniques.",
    "source": "arXiv"
  },
  {
    "title": "Deep Reinforcement Learning-Based Control Strategy with Direct Gate Control for Buck Converters",
    "title_es": "Deep Reinforcement Learning-Based Control Strategy with Direct Gate Control for Buck Converters",
    "url": "https://arxiv.org/abs/2508.07693",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07693v1 Announce Type: new \nAbstract: This paper proposes a deep reinforcement learning (DRL)-based approach for directly controlling the gate signals of switching devices to achieve voltage regulation in a buck converter. Unlike conventional control methods, the proposed method directly generates gate signals using a neural network trained through DRL, with the objective of achieving high control speed and flexibility while maintaining stability. Simulation results demonstrate that the proposed direct gate control (DGC) method achieves a faster transient response and stable output voltage regulation, outperforming traditional PWM-based control schemes. The DGC method also exhibits strong robustness against parameter variations and sensor noise, indicating its suitability for practical power electronics applications. The effectiveness of the proposed approach is validated via simulation.",
    "source": "arXiv"
  },
  {
    "title": "Semantic-Enhanced Time-Series Forecasting via Large Language Models",
    "title_es": "Semantic-Enhanced Time-Series Forecasting via Large Language Models",
    "url": "https://arxiv.org/abs/2508.07697",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07697v1 Announce Type: new \nAbstract: Time series forecasting plays a significant role in finance, energy, meteorology, and IoT applications. Recent studies have leveraged the generalization capabilities of large language models (LLMs) to adapt to time series forecasting, achieving promising performance. However, existing studies focus on token-level modal alignment, instead of bridging the intrinsic modality gap between linguistic knowledge structures and time series data patterns, greatly limiting the semantic representation. To address this issue, we propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent periodicity and anomalous characteristics of time series to embed into the semantic space to enhance the token embedding. This process enhances the interpretability of tokens for LLMs, thereby activating the potential of LLMs for temporal sequence analysis. Moreover, existing Transformer-based LLMs excel at capturing long-range dependencies but are weak at modeling short-term anomalies in time-series data. Hence, we propose a plugin module embedded within self-attention that models long-term and short-term dependencies to effectively adapt LLMs to time-series analysis. Our approach freezes the LLM and reduces the sequence dimensionality of tokens, greatly reducing computational consumption. Experiments demonstrate the superiority performance of our SE-LLM against the state-of-the-art (SOTA) methods.",
    "source": "arXiv"
  },
  {
    "title": "Last-Iterate Convergence in Adaptive Regret Minimization for Approximate Extensive-Form Perfect Equilibrium",
    "title_es": "Last-Iterate Convergence in Adaptive Regret Minimization for Approximate Extensive-Form Perfect Equilibrium",
    "url": "https://arxiv.org/abs/2508.07699",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07699v1 Announce Type: new \nAbstract: The Nash Equilibrium (NE) assumes rational play in imperfect-information Extensive-Form Games (EFGs) but fails to ensure optimal strategies for off-equilibrium branches of the game tree, potentially leading to suboptimal outcomes in practical settings. To address this, the Extensive-Form Perfect Equilibrium (EFPE), a refinement of NE, introduces controlled perturbations to model potential player errors. However, existing EFPE-finding algorithms, which typically rely on average strategy convergence and fixed perturbations, face significant limitations: computing average strategies incurs high computational costs and approximation errors, while fixed perturbations create a trade-off between NE approximation accuracy and the convergence rate of NE refinements.\n  To tackle these challenges, we propose an efficient adaptive regret minimization algorithm for computing approximate EFPE, achieving last-iterate convergence in two-player zero-sum EFGs. Our approach introduces Reward Transformation Counterfactual Regret Minimization (RTCFR) to solve perturbed games and defines a novel metric, the Information Set Nash Equilibrium (ISNE), to dynamically adjust perturbations. Theoretical analysis confirms convergence to EFPE, and experimental results demonstrate that our method significantly outperforms state-of-the-art algorithms in both NE and EFPE-finding tasks.",
    "source": "arXiv"
  },
  {
    "title": "Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing",
    "title_es": "Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing",
    "url": "https://arxiv.org/abs/2508.07700",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07700v1 Announce Type: new \nAbstract: As 3D generation techniques continue to flourish, the demand for generating personalized content is rapidly rising. Users increasingly seek to apply various editing methods to polish generated 3D content, aiming to enhance its color, style, and lighting without compromising the underlying geometry. However, most existing editing tools focus on the 2D domain, and directly feeding their results into 3D generation methods (like multi-view diffusion models) will introduce information loss, degrading the quality of the final 3D assets. In this paper, we propose a tuning-free, plug-and-play scheme that aligns edited assets with their original geometry in a single inference run. Central to our approach is a geometry preservation module that guides the edited multi-view generation with original input normal latents. Besides, an injection switcher is proposed to deliberately control the supervision extent of the original normals, ensuring the alignment between the edited color and normal views. Extensive experiments show that our method consistently improves both the multi-view consistency and mesh quality of edited 3D assets, across multiple combinations of multi-view diffusion models and editing methods.",
    "source": "arXiv"
  },
  {
    "title": "Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction",
    "title_es": "Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction",
    "url": "https://arxiv.org/abs/2508.07701",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07701v1 Announce Type: new \nAbstract: 3D Gaussian Splatting (3DGS) achieves remarkable results in the field of surface reconstruction. However, when Gaussian normal vectors are aligned within the single-view projection plane, while the geometry appears reasonable in the current view, biases may emerge upon switching to nearby views. To address the distance and global matching challenges in multi-view scenes, we design multi-view normal and distance-guided Gaussian splatting. This method achieves geometric depth unification and high-accuracy reconstruction by constraining nearby depth maps and aligning 3D normals. Specifically, for the reconstruction of small indoor and outdoor scenes, we propose a multi-view distance reprojection regularization module that achieves multi-view Gaussian alignment by computing the distance loss between two nearby views and the same Gaussian surface. Additionally, we develop a multi-view normal enhancement module, which ensures consistency across views by matching the normals of pixel points in nearby views and calculating the loss. Extensive experimental results demonstrate that our method outperforms the baseline in both quantitative and qualitative evaluations, significantly enhancing the surface reconstruction capability of 3DGS.",
    "source": "arXiv"
  },
  {
    "title": "What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction",
    "title_es": "What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction",
    "url": "https://arxiv.org/abs/2508.07702",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07702v1 Announce Type: new \nAbstract: Transformer-based models primarily rely on Next Token Prediction (NTP), which predicts the next token in a sequence based on the preceding context. However, NTP's focus on single-token prediction often limits a model's ability to plan ahead or maintain long-range coherence, raising questions about how well LLMs can predict longer contexts, such as full sentences within structured documents. While NTP encourages local fluency, it provides no explicit incentive to ensure global coherence across sentence boundaries-an essential skill for reconstructive or discursive tasks. To investigate this, we evaluate three commercial LLMs (GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) on Masked Sentence Prediction (MSP) - the task of infilling a randomly removed sentence - from three domains: ROCStories (narrative), Recipe1M (procedural), and Wikipedia (expository). We assess both fidelity (similarity to the original sentence) and cohesiveness (fit within the surrounding context). Our key finding reveals that commercial LLMs, despite their superlative performance in other tasks, are poor at predicting masked sentences in low-structured domains, highlighting a gap in current model capabilities.",
    "source": "arXiv"
  },
  {
    "title": "Perpetual exploration in anonymous synchronous networks with a Byzantine black hole",
    "title_es": "Perpetual exploration in anonymous synchronous networks with a Byzantine black hole",
    "url": "https://arxiv.org/abs/2508.07703",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07703v1 Announce Type: new \nAbstract: In this paper, we investigate: ``How can a group of initially co-located mobile agents perpetually explore an unknown graph, when one stationary node occasionally behaves maliciously, under an adversary's control?'' We call this node a ``Byzantine black hole (BBH)'' and at any given round it may choose to destroy all visiting agents, or none. This subtle power can drastically undermine classical exploration strategies designed for an always active black hole. We study this perpetual exploration problem in the presence of at most one BBH, without initial knowledge of the network size. Since the underlying graph may be 1-connected, perpetual exploration of the entire graph may be infeasible. We thus define two variants: \\pbmPerpExpl\\ and \\pbmPerpExplHome. In the former, the agents are tasked to perform perpetual exploration of at least one component, obtained after the exclusion of the BBH. In the latter, the agents are tasked to perform perpetual exploration of the component which contains the \\emph{home} node, where agents are initially co-located. Naturally, \\pbmPerpExplHome\\ is a special case of \\pbmPerpExpl. Agents operate under a synchronous scheduler and communicate in a face-to-face model. Our goal is to determine the minimum number of agents necessary and sufficient to solve these problems. In acyclic networks, we obtain optimal algorithms that solve \\pbmPerpExpl\\ with $4$ agents, and \\pbmPerpExplHome\\ with $6$ agents in trees. The lower bounds hold even in path graphs. In general graphs, we give a non-trivial lower bound of $2\\Delta-1$ agents for \\pbmPerpExpl, and an upper bound of $3\\Delta+3$ agents for \\pbmPerpExplHome. To our knowledge, this is the first study of a black-hole variant in arbitrary networks without initial topological knowledge.",
    "source": "arXiv"
  },
  {
    "title": "Energy Consumption in Parallel Neural Network Training",
    "title_es": "Energy Consumption in Parallel Neural Network Training",
    "url": "https://arxiv.org/abs/2508.07706",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07706v1 Announce Type: new \nAbstract: The increasing demand for computational resources of training neural networks leads to a concerning growth in energy consumption. While parallelization has enabled upscaling model and dataset sizes and accelerated training, its impact on energy consumption is often overlooked. To close this research gap, we conducted scaling experiments for data-parallel training of two models, ResNet50 and FourCastNet, and evaluated the impact of parallelization parameters, i.e., GPU count, global batch size, and local batch size, on predictive performance, training time, and energy consumption. We show that energy consumption scales approximately linearly with the consumed resources, i.e., GPU hours; however, the respective scaling factor differs substantially between distinct model trainings and hardware, and is systematically influenced by the number of samples and gradient updates per GPU hour. Our results shed light on the complex interplay of scaling up neural network training and can inform future developments towards more sustainable AI research.",
    "source": "arXiv"
  },
  {
    "title": "Addendum on data driven regularization by projection",
    "title_es": "Addendum on data driven regularization by projection",
    "url": "https://arxiv.org/abs/2508.07709",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07709v1 Announce Type: new \nAbstract: We study the stability of regularization by projection for solving linear inverse problems if the forward operator is given indirectly but specified via some input-output training pairs. We extend the approach in \"Data driven regularization by projection\" (Aspri, Korolev, and Scherzer; Inverse Problems; 36 (2020), 125009) to data pairs, which are noisy and, possibly, linearly dependent.",
    "source": "arXiv"
  },
  {
    "title": "Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer",
    "title_es": "Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer",
    "url": "https://arxiv.org/abs/2508.07710",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07710v1 Announce Type: new \nAbstract: Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a promising approach for constructing energy-efficient Transformer architectures. Compared to directly trained Spiking Transformers, ANN-to-SNN conversion methods bypass the high training costs. However, existing methods still suffer from notable limitations, failing to effectively handle nonlinear operations in Transformer architectures and requiring additional fine-tuning processes for pre-trained ANNs. To address these issues, we propose a high-performance and training-free ANN-to-SNN conversion framework tailored for Transformer architectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE) neuron, which employs an exponential decay strategy and multi-basis encoding method to efficiently approximate various nonlinear operations. It removes the requirement for weight modifications in pre-trained ANNs. Extensive experiments across diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures (ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless conversion accuracy with significantly lower latency. This provides a promising pathway for the efficient and scalable deployment of Spiking Transformers in real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information",
    "title_es": "Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information",
    "url": "https://arxiv.org/abs/2508.07713",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07713v1 Announce Type: new \nAbstract: Deep neural networks can memorize corrupted labels, making data quality critical for model performance, yet real-world datasets are frequently compromised by both label noise and input noise. This paper proposes a mutual information-based framework for data selection under hybrid noise scenarios that quantifies statistical dependencies between inputs and labels. We compute each sample's pointwise contribution to the overall mutual information and find that lower contributions indicate noisy or mislabeled instances. Empirical validation on MNIST with different synthetic noise settings demonstrates that the method effectively filters low-quality samples. Under label corruption, training on high-MI samples improves classification accuracy by up to 15\\% compared to random sampling. Furthermore, the method exhibits robustness to benign input modifications, preserving semantically valid data while filtering truly corrupted samples.",
    "source": "arXiv"
  },
  {
    "title": "DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models",
    "title_es": "DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models",
    "url": "https://arxiv.org/abs/2508.07714",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07714v1 Announce Type: new \nAbstract: Accurate detection and classification of diverse door types in floor plans drawings is critical for multiple applications, such as building compliance checking, and indoor scene understanding. Despite their importance, publicly available datasets specifically designed for fine-grained multi-class door detection remain scarce. In this work, we present a semi-automated pipeline that leverages a state-of-the-art object detector and a large language model (LLM) to construct a multi-class door detection dataset with minimal manual effort. Doors are first detected as a unified category using a deep object detection model. Next, an LLM classifies each detected instance based on its visual and contextual features. Finally, a human-in-the-loop stage ensures high-quality labels and bounding boxes. Our method significantly reduces annotation cost while producing a dataset suitable for benchmarking neural models in floor plan analysis. This work demonstrates the potential of combining deep learning and multimodal reasoning for efficient dataset construction in complex real-world domains.",
    "source": "arXiv"
  },
  {
    "title": "Toward Goal-Oriented Communication in Multi-Agent Systems: An overview",
    "title_es": "Toward Goal-Oriented Communication in Multi-Agent Systems: An overview",
    "url": "https://arxiv.org/abs/2508.07720",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07720v1 Announce Type: new \nAbstract: As multi-agent systems (MAS) become increasingly prevalent in autonomous systems, distributed control, and edge intelligence, efficient communication under resource constraints has emerged as a critical challenge. Traditional communication paradigms often emphasize message fidelity or bandwidth optimization, overlooking the task relevance of the exchanged information. In contrast, goal-oriented communication prioritizes the importance of information with respect to the agents' shared objectives. This review provides a comprehensive survey of goal-oriented communication in MAS, bridging perspectives from information theory, communication theory, and machine learning. We examine foundational concepts alongside learning-based approaches and emergent protocols. Special attention is given to coordination under communication constraints, as well as applications in domains such as swarm robotics, federated learning, and edge computing. The paper concludes with a discussion of open challenges and future research directions at the intersection of communication theory, machine learning, and multi-agent decision making.",
    "source": "arXiv"
  },
  {
    "title": "A Registration-Based Star-Shape Segmentation Model and Fast Algorithms",
    "title_es": "A Registration-Based Star-Shape Segmentation Model and Fast Algorithms",
    "url": "https://arxiv.org/abs/2508.07721",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07721v1 Announce Type: new \nAbstract: Image segmentation plays a crucial role in extracting objects of interest and identifying their boundaries within an image. However, accurate segmentation becomes challenging when dealing with occlusions, obscurities, or noise in corrupted images. To tackle this challenge, prior information is often utilized, with recent attention on star-shape priors. In this paper, we propose a star-shape segmentation model based on the registration framework. By combining the level set representation with the registration framework and imposing constraints on the deformed level set function, our model enables both full and partial star-shape segmentation, accommodating single or multiple centers. Additionally, our approach allows for the enforcement of identified boundaries to pass through specified landmark locations. We tackle the proposed models using the alternating direction method of multipliers. Through numerical experiments conducted on synthetic and real images, we demonstrate the efficacy of our approach in achieving accurate star-shape segmentation.",
    "source": "arXiv"
  },
  {
    "title": "Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations",
    "title_es": "Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations",
    "url": "https://arxiv.org/abs/2508.07722",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07722v1 Announce Type: new \nAbstract: In this work, we address the problem of training Reinforcement Learning (RL) agents over communication networks. The RL paradigm requires the agent to instantaneously perceive the state evolution to infer the effects of its actions on the environment. This is impossible if the agent receives state updates over lossy or delayed wireless systems and thus operates with partial and intermittent information. In recent years, numerous frameworks have been proposed to manage RL with imperfect feedback; however, they often offer specific solutions with a substantial computational burden. To address these limits, we propose a novel architecture, named Homomorphic Robust Remote Reinforcement Learning (HR3L), that enables the training of remote RL agents exchanging observations across a non-ideal wireless channel. HR3L considers two units: the transmitter, which encodes meaningful representations of the environment, and the receiver, which decodes these messages and performs actions to maximize a reward signal. Importantly, HR3L does not require the exchange of gradient information across the wireless channel, allowing for quicker training and a lower communication overhead than state-of-the-art solutions. Experimental results demonstrate that HR3L significantly outperforms baseline methods in terms of sample efficiency and adapts to different communication scenarios, including packet losses, delayed transmissions, and capacity limitations.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting",
    "title_es": "Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting",
    "url": "https://arxiv.org/abs/2508.07723",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07723v1 Announce Type: new \nAbstract: The performance of computer vision models in certain real-world applications, such as medical diagnosis, is often limited by the scarcity of available images. Expanding datasets using pre-trained generative models is an effective solution. However, due to the uncontrollable generation process and the ambiguity of natural language, noisy images may be generated. Re-weighting is an effective way to address this issue by assigning low weights to such noisy images. We first theoretically analyze three types of supervision for the generated images. Based on the theoretical analysis, we develop TriReWeight, a triplet-connection-based sample re-weighting method to enhance generative data augmentation. Theoretically, TriReWeight can be integrated with any generative data augmentation methods and never downgrade their performance. Moreover, its generalization approaches the optimal in the order $O(\\sqrt{d\\ln (n)/n})$. Our experiments validate the correctness of the theoretical analysis and demonstrate that our method outperforms the existing SOTA methods by $7.9\\%$ on average over six natural image datasets and by $3.4\\%$ on average over three medical datasets. We also experimentally validate that our method can enhance the performance of different generative data augmentation methods.",
    "source": "arXiv"
  },
  {
    "title": "ARISE: Automating RISC-V Instruction Set Extension",
    "title_es": "ARISE: Automating RISC-V Instruction Set Extension",
    "url": "https://arxiv.org/abs/2508.07725",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07725v1 Announce Type: new \nAbstract: RISC-V is an extendable Instruction Set Architecture, growing in popularity for embedded systems. However, optimizing it to specific requirements, imposes a great deal of manual effort. To bridge the gap between software and ISA, the tool ARISE is presented. It automates the generation of RISC-V instructions based on assembly patterns, which are selected by an extendable set of metrics. These metrics implement the optimization goals of code size and instruction count reduction, both statically and dynamically. The instruction set extensions are generated using the ISA description language CoreDSL. Allowing seamless embedding in advanced tools such as the retargeting compiler Seal5 or the instruction set simulator ETISS. ARISE improves the static code size by 1.48% and the dynamic code size by 3.84%, as well as the number of instructions to be executed by 7.39% on average for Embench-Iot.",
    "source": "arXiv"
  },
  {
    "title": "SimViews: An Interactive Multi-Agent System Simulating Visitor-to-Visitor Conversational Patterns to Present Diverse Perspectives of Artifacts in Virtual Museums",
    "title_es": "SimViews: An Interactive Multi-Agent System Simulating Visitor-to-Visitor Conversational Patterns to Present Diverse Perspectives of Artifacts in Virtual Museums",
    "url": "https://arxiv.org/abs/2508.07730",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07730v1 Announce Type: new \nAbstract: Offering diverse perspectives on a museum artifact can deepen visitors' understanding and help avoid the cognitive limitations of a single narrative, ultimately enhancing their overall experience. Physical museums promote diversity through visitor interactions. However, it remains a challenge to present multiple voices appropriately while attracting and sustaining a visitor's attention in the virtual museum. Inspired by recent studies that show the effectiveness of LLM-powered multi-agents in presenting different opinions about an event, we propose SimViews, an interactive multi-agent system that simulates visitor-to-visitor conversational patterns to promote the presentation of diverse perspectives. The system employs LLM-powered multi-agents that simulate virtual visitors with different professional identities, providing diverse interpretations of artifacts. Additionally, we constructed 4 conversational patterns between users and agents to simulate visitor interactions. We conducted a within-subject study with 20 participants, comparing SimViews to a traditional single-agent condition. Our results show that SimViews effectively facilitates the presentation of diverse perspectives through conversations, enhancing participants' understanding of viewpoints and engagement within the virtual museum.",
    "source": "arXiv"
  },
  {
    "title": "CognitiveArm: Enabling Real-Time EEG-Controlled Prosthetic Arm Using Embodied Machine Learning",
    "title_es": "CognitiveArm: Enabling Real-Time EEG-Controlled Prosthetic Arm Using Embodied Machine Learning",
    "url": "https://arxiv.org/abs/2508.07731",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07731v1 Announce Type: new \nAbstract: Efficient control of prosthetic limbs via non-invasive brain-computer interfaces (BCIs) requires advanced EEG processing, including pre-filtering, feature extraction, and action prediction, performed in real time on edge AI hardware. Achieving this on resource-constrained devices presents challenges in balancing model complexity, computational efficiency, and latency. We present CognitiveArm, an EEG-driven, brain-controlled prosthetic system implemented on embedded AI hardware, achieving real-time operation without compromising accuracy. The system integrates BrainFlow, an open-source library for EEG data acquisition and streaming, with optimized deep learning (DL) models for precise brain signal classification. Using evolutionary search, we identify Pareto-optimal DL configurations through hyperparameter tuning, optimizer analysis, and window selection, analyzed individually and in ensemble configurations. We apply model compression techniques such as pruning and quantization to optimize models for embedded deployment, balancing efficiency and accuracy. We collected an EEG dataset and designed an annotation pipeline enabling precise labeling of brain signals corresponding to specific intended actions, forming the basis for training our optimized DL models. CognitiveArm also supports voice commands for seamless mode switching, enabling control of the prosthetic arm's 3 degrees of freedom (DoF). Running entirely on embedded hardware, it ensures low latency and real-time responsiveness. A full-scale prototype, interfaced with the OpenBCI UltraCortex Mark IV EEG headset, achieved up to 90% accuracy in classifying three core actions (left, right, idle). Voice integration enables multiplexed, variable movement for everyday tasks (e.g., handshake, cup picking), enhancing real-world performance and demonstrating CognitiveArm's potential for advanced prosthetic control.",
    "source": "arXiv"
  },
  {
    "title": "Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning",
    "title_es": "Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning",
    "url": "https://arxiv.org/abs/2508.07738",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07738v1 Announce Type: new \nAbstract: Multi-Domain Continual Learning (MDCL) acquires knowledge from sequential tasks with shifting class sets and distribution. Despite the Parameter-Efficient Fine-Tuning (PEFT) methods can adapt for this dual heterogeneity, they still suffer from catastrophic forgetting and forward forgetting. To address these challenges, we propose a Two-Level Routing Grouped Mixture-of-Experts (TRGE) method. Firstly, TRGE dynamically expands the pre-trained CLIP model, assigning specific expert group for each task to mitigate catastrophic forgetting. With the number of experts continually grows in this process, TRGE maintains the static experts count within the group and introduces the intra-group router to alleviate routing overfitting caused by the increasing routing complexity. Meanwhile, we design an inter-group routing policy based on task identifiers and task prototype distance, which dynamically selects relevant expert groups and combines their outputs to enhance inter-task collaboration. Secondly, to get the correct task identifiers, we leverage Multimodal Large Language Models (MLLMs) which own powerful multimodal comprehension capabilities to generate semantic task descriptions and recognize the correct task identifier. Finally, to mitigate forward forgetting, we dynamically fuse outputs for unseen samples from the frozen CLIP model and TRGE adapter based on training progress, leveraging both pre-trained and learned knowledge. Through extensive experiments across various settings, our method outperforms other advanced methods with fewer trainable parameters.",
    "source": "arXiv"
  },
  {
    "title": "A $C^{\\infty}$ rational quasi-interpolation operator for functions with jumps without the Gibbs phenomenon",
    "title_es": "A $C^{\\infty}$ rational quasi-interpolation operator for functions with jumps without the Gibbs phenomenon",
    "url": "https://arxiv.org/abs/2508.07741",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07741v1 Announce Type: new \nAbstract: The study of quasi-interpolation has gained significant importance in numerical analysis and approximation theory due to its versatile applications in scientific and engineering fields. This technique provides a flexible and efficient alternative to traditional interpolation methods by approximating data points without requiring the approximated function to pass exactly through them. This approach is particularly valuable for handling jump discontinuities, where classical interpolation methods often fail due to the Gibbs phenomenon. These discontinuities are common in practical scenarios such as signal processing and computational physics. In this paper, we present a $C^{\\infty}$ rational quasi-interpolation operator designed to effectively approximate functions with jump discontinuities while minimizing the issues typically associated with traditional interpolation methods.",
    "source": "arXiv"
  },
  {
    "title": "A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases",
    "title_es": "A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases",
    "url": "https://arxiv.org/abs/2508.07742",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07742v1 Announce Type: new \nAbstract: Repair-based semantics have been extensively studied as a means of obtaining meaningful answers to queries posed over inconsistent knowledge bases (KBs). While several works have considered how to exploit a priority relation between facts to select optimal repairs, the question of how to specify such preferences remains largely unaddressed. This motivates us to introduce a declarative rule-based framework for specifying and computing a priority relation between conflicting facts. As the expressed preferences may contain undesirable cycles, we consider the problem of determining when a set of preference rules always yields an acyclic relation, and we also explore a pragmatic approach that extracts an acyclic relation by applying various cycle removal techniques. Towards an end-to-end system for querying inconsistent KBs, we present a preliminary implementation and experimental evaluation of the framework, which employs answer set programming to evaluate the preference rules, apply the desired cycle resolution techniques to obtain a priority relation, and answer queries under prioritized-repair semantics.",
    "source": "arXiv"
  },
  {
    "title": "Symmetry-Aware Transformer Training for Automated Planning",
    "title_es": "Symmetry-Aware Transformer Training for Automated Planning",
    "url": "https://arxiv.org/abs/2508.07743",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07743v1 Announce Type: new \nAbstract: While transformers excel in many settings, their application in the field of automated planning is limited. Prior work like PlanGPT, a state-of-the-art decoder-only transformer, struggles with extrapolation from easy to hard planning problems. This in turn stems from problem symmetries: planning tasks can be represented with arbitrary variable names that carry no meaning beyond being identifiers. This causes a combinatorial explosion of equivalent representations that pure transformers cannot efficiently learn from. We propose a novel contrastive learning objective to make transformers symmetry-aware and thereby compensate for their lack of inductive bias. Combining this with architectural improvements, we show that transformers can be efficiently trained for either plan-generation or heuristic-prediction. Our results across multiple planning domains demonstrate that our symmetry-aware training effectively and efficiently addresses the limitations of PlanGPT.",
    "source": "arXiv"
  },
  {
    "title": "Over-the-Top Resource Broker System for Split Computing: An Approach to Distribute Cloud Computing Infrastructure",
    "title_es": "Over-the-Top Resource Broker System for Split Computing: An Approach to Distribute Cloud Computing Infrastructure",
    "url": "https://arxiv.org/abs/2508.07744",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07744v1 Announce Type: new \nAbstract: 6G network architectures will usher in a wave of innovative services and capabilities, introducing concepts like split computing and dynamic processing nodes. This implicates a paradigm where accessing resources seamlessly aligns with diverse processing node characteristics, ensuring a uniform interface. In this landscape, the identity of the operator becomes inconsequential, paving the way for a collaborative ecosystem where multiple providers contribute to a shared pool of resources. At the core of this vision is the guarantee of specific performance parameters, precisely tailored to the location and service requirements. A consistent layer, as the abstraction of the complexities of different infrastructure providers, is needed to simplify service deployment. One promising approach is the introduction of an over-the-top broker for resource allocation, which streamlines the integration of these services into the network and cloud infrastructure of the future. This paper explores the role of the broker in two split computing scenarios. By abstracting the complexities of various infrastructures, the broker proves to be a versatile solution applicable not only to cloud environments but also to networks and beyond. Additionally, a detailed discussion of a proof-of-concept implementation provides insights into the broker's actual architectural framework.",
    "source": "arXiv"
  },
  {
    "title": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation",
    "title_es": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation",
    "url": "https://arxiv.org/abs/2508.07745",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07745v1 Announce Type: new \nAbstract: Insider threats, which can lead to severe losses, remain a major security concern. While machine learning-based insider threat detection (ITD) methods have shown promising results, their progress is hindered by the scarcity of high-quality data. Enterprise data is sensitive and rarely accessible, while publicly available datasets, when limited in scale due to cost, lack sufficient real-world coverage; and when purely synthetic, they fail to capture rich semantics and realistic user behavior. To address this, we propose Chimera, the first large language model (LLM)-based multi-agent framework that automatically simulates both benign and malicious insider activities and collects diverse logs across diverse enterprise environments. Chimera models each employee with agents that have role-specific behavior and integrates modules for group meetings, pairwise interactions, and autonomous scheduling, capturing realistic organizational dynamics. It incorporates 15 types of insider attacks (e.g., IP theft, system sabotage) and has been deployed to simulate activities in three sensitive domains: technology company, finance corporation, and medical institution, producing a new dataset, ChimeraLog. We assess ChimeraLog via human studies and quantitative analysis, confirming its diversity, realism, and presence of explainable threat patterns. Evaluations of existing ITD methods show an average F1-score of 0.83, which is significantly lower than 0.99 on the CERT dataset, demonstrating ChimeraLog's higher difficulty and utility for advancing ITD research.",
    "source": "arXiv"
  },
  {
    "title": "A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory",
    "title_es": "A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory",
    "url": "https://arxiv.org/abs/2508.07746",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07746v1 Announce Type: new \nAbstract: Offline reinforcement learning (RL) aims to optimize the return given a fixed dataset of agent trajectories without additional interactions with the environment. While algorithm development has progressed rapidly, significant theoretical advances have also been made in understanding the fundamental challenges of offline RL. However, bridging these theoretical insights with practical algorithm design remains an ongoing challenge. In this survey, we explore key intuitions derived from theoretical work and their implications for offline RL algorithms.\n  We begin by listing the conditions needed for the proofs, including function representation and data coverage assumptions. Function representation conditions tell us what to expect for generalization, and data coverage assumptions describe the quality requirement of the data. We then examine counterexamples, where offline RL is not solvable without an impractically large amount of data. These cases highlight what cannot be achieved for all algorithms and the inherent hardness of offline RL. Building on techniques to mitigate these challenges, we discuss the conditions that are sufficient for offline RL. These conditions are not merely assumptions for theoretical proofs, but they also reveal the limitations of these algorithms and remind us to search for novel solutions when the conditions cannot be satisfied.",
    "source": "arXiv"
  },
  {
    "title": "Grouped Speculative Decoding for Autoregressive Image Generation",
    "title_es": "Grouped Speculative Decoding for Autoregressive Image Generation",
    "url": "https://arxiv.org/abs/2508.07747",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07747v1 Announce Type: new \nAbstract: Recently, autoregressive (AR) image models have demonstrated remarkable generative capabilities, positioning themselves as a compelling alternative to diffusion models. However, their sequential nature leads to long inference times, limiting their practical scalability. In this work, we introduce Grouped Speculative Decoding (GSD), a novel, training-free acceleration method for AR image models. While recent studies have explored Speculative Decoding (SD) as a means to speed up AR image generation, existing approaches either provide only modest acceleration or require additional training. Our in-depth analysis reveals a fundamental difference between language and image tokens: image tokens exhibit inherent redundancy and diversity, meaning multiple tokens can convey valid semantics. However, traditional SD methods are designed to accept only a single most-likely token, which fails to leverage this difference, leading to excessive false-negative rejections. To address this, we propose a new SD strategy that evaluates clusters of visually valid tokens rather than relying on a single target token. Additionally, we observe that static clustering based on embedding distance is ineffective, which motivates our dynamic GSD approach. Extensive experiments show that GSD accelerates AR image models by an average of 3.7x while preserving image quality-all without requiring any additional training. The source code is available at https://github.com/junhyukso/GSD",
    "source": "arXiv"
  },
  {
    "title": "Encode Me If You Can: Learning Universal User Representations via Event Sequence Autoencoding",
    "title_es": "Encode Me If You Can: Learning Universal User Representations via Event Sequence Autoencoding",
    "url": "https://arxiv.org/abs/2508.07748",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07748v1 Announce Type: new \nAbstract: Building universal user representations that capture the essential aspects of user behavior is a crucial task for modern machine learning systems. In real-world applications, a user's historical interactions often serve as the foundation for solving a wide range of predictive tasks, such as churn prediction, recommendations, or lifetime value estimation. Using a task-independent user representation that is effective across all such tasks can reduce the need for task-specific feature engineering and model retraining, leading to more scalable and efficient machine learning pipelines. The goal of the RecSys Challenge 2025 by Synerise was to develop such Universal Behavioral Profiles from logs of past user behavior, which included various types of events such as product purchases, page views, and search queries. We propose a method that transforms the entire user interaction history into a single chronological sequence and trains a GRU-based autoencoder to reconstruct this sequence from a fixed-size vector. If the model can accurately reconstruct the sequence, the latent vector is expected to capture the key behavioral patterns. In addition to this core model, we explored several alternative methods for generating user embeddings and combined them by concatenating their output vectors into a unified representation. This ensemble strategy further improved generalization across diverse downstream tasks and helped our team, ai_lab_recsys, achieve second place in the RecSys Challenge 2025.",
    "source": "arXiv"
  },
  {
    "title": "Robust Integrated Priority and Speed Control based on Hierarchical Stochastic Optimization to Promote Bus Schedule Adherence along Signalized Arterial",
    "title_es": "Robust Integrated Priority and Speed Control based on Hierarchical Stochastic Optimization to Promote Bus Schedule Adherence along Signalized Arterial",
    "url": "https://arxiv.org/abs/2508.07749",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07749v1 Announce Type: new \nAbstract: In intelligent transportation systems (ITS), adaptive transit signal priority (TSP) and dynamic bus control systems have been independently developed to maintain efficient and reliable urban bus services. However, those two systems could potentially lead to conflicting decisions due to the lack of coordination. Although some studies explore the integrated control strategies along the arterial, they merely rely on signal replanning to address system uncertainties. Therefore, their performance severely deteriorates in real-world intersection settings, where abrupt signal timing variation is not always applicable in consideration of countdown timers and pedestrian signal design.\n  In this study, we propose a robust integrated priority and speed control strategy based on hierarchical stochastic optimization to enhance bus schedule adherence along the arterial. In the proposed framework, the upper level ensures the coordination across intersections while the lower level handles uncertainties for each intersection with stochastic programming. Hence, the route-level system randomness is decomposed into a series of local problems that can be solved in parallel using sample average approximation (SAA). Simulation experiments are conducted under various scenarios with stochastic bus dwell time and different traffic demand. The results demonstrate that our approach significantly enhances bus punctuality and time headway equivalence without abrupt signal timing variation, with negative impacts on car delays limited to only 0.8%-5.2% as traffic demand increases.",
    "source": "arXiv"
  },
  {
    "title": "Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment",
    "title_es": "Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment",
    "url": "https://arxiv.org/abs/2508.07750",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07750v1 Announce Type: new \nAbstract: Alignment methodologies have emerged as a critical pathway for enhancing language model alignment capabilities. While SFT (supervised fine-tuning) accelerates convergence through direct token-level loss intervention, its efficacy is constrained by offline policy trajectory. In contrast, RL(reinforcement learning) facilitates exploratory policy optimization, but suffers from low sample efficiency and stringent dependency on high-quality base models. To address these dual challenges, we propose GRAO (Group Relative Alignment Optimization), a unified framework that synergizes the respective strengths of SFT and RL through three key innovations: 1) A multi-sample generation strategy enabling comparative quality assessment via reward feedback; 2) A novel Group Direct Alignment Loss formulation leveraging intra-group relative advantage weighting; 3) Reference-aware parameter updates guided by pairwise preference dynamics. Our theoretical analysis establishes GRAO's convergence guarantees and sample efficiency advantages over conventional approaches. Comprehensive evaluations across complex human alignment tasks demonstrate GRAO's superior performance, achieving 57.70\\%,17.65\\% 7.95\\% and 5.18\\% relative improvements over SFT, DPO, PPO and GRPO baselines respectively. This work provides both a theoretically grounded alignment framework and empirical evidence for efficient capability evolution in language models.",
    "source": "arXiv"
  },
  {
    "title": "Filling MIDI Velocity using U-Net Image Colorizer",
    "title_es": "Filling MIDI Velocity using U-Net Image Colorizer",
    "url": "https://arxiv.org/abs/2508.07751",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07751v1 Announce Type: new \nAbstract: Modern music producers commonly use MIDI (Musical Instrument Digital Interface) to store their musical compositions. However, MIDI files created with digital software may lack the expressive characteristics of human performances, essentially leaving the velocity parameter - a control for note loudness - undefined, which defaults to a flat value. The task of filling MIDI velocity is termed MIDI velocity prediction, which uses regression models to enhance music expressiveness by adjusting only this parameter. In this paper, we introduce the U-Net, a widely adopted architecture in image colorization, to this task. By conceptualizing MIDI data as images, we adopt window attention and develop a custom loss function to address the sparsity of MIDI-converted images. Current dataset availability restricts our experiments to piano data. Evaluated on the MAESTRO v3 and SMD datasets, our proposed method for filling MIDI velocity outperforms previous approaches in both quantitative metrics and qualitative listening tests.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Causal Effect of Social Bias on Faithfulness Hallucinations in Large Language Models",
    "title_es": "Exploring Causal Effect of Social Bias on Faithfulness Hallucinations in Large Language Models",
    "url": "https://arxiv.org/abs/2508.07753",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07753v1 Announce Type: new \nAbstract: Large language models (LLMs) have achieved remarkable success in various tasks, yet they remain vulnerable to faithfulness hallucinations, where the output does not align with the input. In this study, we investigate whether social bias contributes to these hallucinations, a causal relationship that has not been explored. A key challenge is controlling confounders within the context, which complicates the isolation of causality between bias states and hallucinations. To address this, we utilize the Structural Causal Model (SCM) to establish and validate the causality and design bias interventions to control confounders. In addition, we develop the Bias Intervention Dataset (BID), which includes various social biases, enabling precise measurement of causal effects. Experiments on mainstream LLMs reveal that biases are significant causes of faithfulness hallucinations, and the effect of each bias state differs in direction. We further analyze the scope of these causal effects across various models, specifically focusing on unfairness hallucinations, which are primarily targeted by social bias, revealing the subtle yet significant causal effect of bias on hallucination generation.",
    "source": "arXiv"
  },
  {
    "title": "Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion",
    "title_es": "Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion",
    "url": "https://arxiv.org/abs/2508.07755",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07755v1 Announce Type: new \nAbstract: The recent demand for customized image generation raises a need for techniques that effectively extract the common concept from small sets of images. Existing methods typically rely on additional guidance, such as text prompts or spatial masks, to capture the common target concept. Unfortunately, relying on manually provided guidance can lead to incomplete separation of auxiliary features, which degrades generation quality.In this paper, we propose Contrastive Inversion, a novel approach that identifies the common concept by comparing the input images without relying on additional information. We train the target token along with the image-wise auxiliary text tokens via contrastive learning, which extracts the well-disentangled true semantics of the target. Then we apply disentangled cross-attention fine-tuning to improve concept fidelity without overfitting. Experimental results and analysis demonstrate that our method achieves a balanced, high-level performance in both concept representation and editing, outperforming existing techniques.",
    "source": "arXiv"
  },
  {
    "title": "Towards Lock Modularization for Heterogeneous Environments",
    "title_es": "Towards Lock Modularization for Heterogeneous Environments",
    "url": "https://arxiv.org/abs/2508.07756",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07756v1 Announce Type: new \nAbstract: Modern hardware environments are becoming increasingly heterogeneous, leading to the emergence of applications specifically designed to exploit this heterogeneity. Efficiently adopting locks in these applications poses distinct challenges. The uneven distribution of resources in such environments can create bottlenecks for lock operations, severely hindering application performance. Existing solutions are often tailored to specific types of hardware, which underutilizes resources on other components within heterogeneous environments.\n  This paper introduces a new design principle: decomposing locks across hardware components to fully utilize unevenly distributed resources in heterogeneous environments. Following this principle, we propose lock modularization, a systematic approach that decomposes a lock into independent modules and assigns them to appropriate hardware components. This approach aligns the resource requirements of lock modules with the attributes of specific hardware components, maximizing strengths while minimizing weaknesses.",
    "source": "arXiv"
  },
  {
    "title": "Robot and Overhead Crane Collaboration Scheme to Enhance Payload Manipulation",
    "title_es": "Robot and Overhead Crane Collaboration Scheme to Enhance Payload Manipulation",
    "url": "https://arxiv.org/abs/2508.07758",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07758v1 Announce Type: new \nAbstract: This paper presents a scheme to enhance payload manipulation using a robot collaborating with an overhead crane. In the current industrial practice, when the crane's payload has to be accurately manipulated and located in a desired position, the task becomes laborious and risky since the operators have to guide the fine motions of the payload by hand. In the proposed collaborative scheme, the crane lifts the payload while the robot's end-effector guides it toward the desired position. The only link between the robot and the crane is the interaction force produced during the guiding of the payload. Two admittance transfer functions are considered to accomplish harmless and smooth contact with the payload. The first is used in a position-based admittance control integrated with the robot. The second one adds compliance to the crane by processing the interaction force through the admittance transfer function to generate a crane's velocity command that makes the crane follow the payload. Then the robot's end-effector and the crane move collaboratively to guide the payload to the desired location. A method is presented to design the admittance controllers that accomplish a fluent robot-crane collaboration. Simulations and experiments validating the scheme potential are shown.",
    "source": "arXiv"
  },
  {
    "title": "Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild",
    "title_es": "Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild",
    "url": "https://arxiv.org/abs/2508.07759",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07759v1 Announce Type: new \nAbstract: Large vision models like the Segment Anything Model (SAM) exhibit significant limitations when applied to downstream tasks in the wild. Consequently, reference segmentation, which leverages reference images and their corresponding masks to impart novel knowledge to the model, emerges as a promising new direction for adapting vision models. However, existing reference segmentation approaches predominantly rely on meta-learning, which still necessitates an extensive meta-training process and brings massive data and computational cost. In this study, we propose a novel approach by representing the inherent correspondence between reference-target image pairs as a pseudo video. This perspective allows the latest version of SAM, known as SAM2, which is equipped with interactive video object segmentation (iVOS) capabilities, to be adapted to downstream tasks in a lightweight manner. We term this approach Correspondence As Video for SAM (CAV-SAM). CAV-SAM comprises two key modules: the Diffusion-Based Semantic Transition (DBST) module employs a diffusion model to construct a semantic transformation sequence, while the Test-Time Geometric Alignment (TTGA) module aligns the geometric changes within this sequence through test-time fine-tuning. We evaluated CAVSAM on widely-used datasets, achieving segmentation performance improvements exceeding 5% over SOTA methods. Implementation is provided in the supplementary materials.",
    "source": "arXiv"
  },
  {
    "title": "Sparse Probabilistic Graph Circuits",
    "title_es": "Sparse Probabilistic Graph Circuits",
    "url": "https://arxiv.org/abs/2508.07763",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07763v1 Announce Type: new \nAbstract: Deep generative models (DGMs) for graphs achieve impressively high expressive power thanks to very efficient and scalable neural networks. However, these networks contain non-linearities that prevent analytical computation of many standard probabilistic inference queries, i.e., these DGMs are considered \\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs) address this issue by enabling \\emph{tractable} probabilistic inference, they operate on dense graph representations with $\\mathcal{O}(n^2)$ complexity for graphs with $n$ nodes and \\emph{$m$ edges}. To address this scalability issue, we introduce Sparse PGCs, a new class of tractable generative models that operate directly on sparse graph representation, reducing the complexity to $\\mathcal{O}(n + m)$, which is particularly beneficial for $m \\ll n^2$. In the context of de novo drug design, we empirically demonstrate that SPGCs retain exact inference capabilities, improve memory efficiency and inference speed, and match the performance of intractable DGMs in key metrics.",
    "source": "arXiv"
  },
  {
    "title": "Multinode Shepard Functions and Tensor Product Polynomial Interpolation: Applications to Digital Elevation Models",
    "title_es": "Multinode Shepard Functions and Tensor Product Polynomial Interpolation: Applications to Digital Elevation Models",
    "url": "https://arxiv.org/abs/2508.07764",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07764v1 Announce Type: new \nAbstract: The paper presents an in-depth exploration of the multinode Shepard interpolant on a regular rectangular grid, demonstrating its efficacy in reconstructing surfaces from DEM data. Additionally, we study the approximation order associated to this interpolant and present a detailed algorithm for reconstructing surfaces. Numerical tests showcase the effectiveness of the proposed algorithm.",
    "source": "arXiv"
  },
  {
    "title": "UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models",
    "title_es": "UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2508.07766",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07766v1 Announce Type: new \nAbstract: Unlike bitmap images, scalable vector graphics (SVG) maintain quality when scaled, frequently employed in computer vision and artistic design in the representation of SVG code. In this era of proliferating AI-powered systems, enabling AI to understand and generate SVG has become increasingly urgent. However, AI-driven SVG understanding and generation (U&G) remain significant challenges. SVG code, equivalent to a set of curves and lines controlled by floating-point parameters, demands high precision in SVG U&G. Besides, SVG generation operates under diverse conditional constraints, including textual prompts and visual references, which requires powerful multi-modal processing for condition-to-SVG transformation. Recently, the rapid growth of Multi-modal Large Language Models (MLLMs) have demonstrated capabilities to process multi-modal inputs and generate complex vector controlling parameters, suggesting the potential to address SVG U&G tasks within a unified model. To unlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset called UniSVG, comprising 525k data items, tailored for MLLM training and evaluation. To our best knowledge, it is the first comprehensive dataset designed for unified SVG generation (from textual prompts and images) and SVG understanding (color, category, usage, etc.). As expected, learning on the proposed dataset boosts open-source MLLMs' performance on various SVG U&G tasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset, benchmark, weights, codes and experiment details on https://ryanlijinke.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "Pareto Multi-Objective Alignment for Language Models",
    "title_es": "Pareto Multi-Objective Alignment for Language Models",
    "url": "https://arxiv.org/abs/2508.07768",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07768v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly deployed in real-world applications that require careful balancing of multiple, often conflicting, objectives, such as informativeness versus conciseness, or helpfulness versus creativity. However, current alignment methods, primarily based on RLHF, optimize LLMs toward a single reward function, resulting in rigid behavior that fails to capture the complexity and diversity of human preferences. This limitation hinders the adaptability of LLMs to practical scenarios, making multi-objective alignment (MOA) a critical yet underexplored area. To bridge this gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and computationally efficient algorithm designed explicitly for MOA in LLMs. In contrast to computationally prohibitive multi-objective optimization (MOO) methods, PAMA transforms multi-objective RLHF into a convex optimization with a closed-form solution, significantly enhancing scalability. Traditional MOO approaches suffer from prohibitive O(n^2*d) complexity, where d represents the number of model parameters, typically in the billions for LLMs, rendering direct optimization infeasible. PAMA reduces this complexity to O(n) where n is the number of objectives, enabling optimization to be completed within milliseconds. We provide theoretical guarantees that PAMA converges to a Pareto stationary point, where no objective can be improved without degrading at least one other. Extensive experiments across language models ranging from 125M to 7B parameters demonstrate PAMA's robust and effective MOA capabilities, aligning with its theoretical advantages. PAMA provides a highly efficient solution to the MOA problem that was previously considered intractable, offering a practical and theoretically grounded approach to aligning LLMs with diverse human values, paving the way for versatile and adaptable real-world AI deployments.",
    "source": "arXiv"
  },
  {
    "title": "Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation",
    "title_es": "Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation",
    "url": "https://arxiv.org/abs/2508.07769",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07769v1 Announce Type: new \nAbstract: The synthesis of spatiotemporally coherent 4D content presents fundamental challenges in computer vision, requiring simultaneous modeling of high-fidelity spatial representations and physically plausible temporal dynamics. Current approaches often struggle to maintain view consistency while handling complex scene dynamics, particularly in large-scale environments with multiple interacting elements. This work introduces Dream4D, a novel framework that bridges this gap through a synergy of controllable video generation and neural 4D reconstruction. Our approach seamlessly combines a two-stage architecture: it first predicts optimal camera trajectories from a single image using few-shot learning, then generates geometrically consistent multi-view sequences via a specialized pose-conditioned diffusion process, which are finally converted into a persistent 4D representation. This framework is the first to leverage both rich temporal priors from video diffusion models and geometric awareness of the reconstruction models, which significantly facilitates 4D generation and shows higher quality (e.g., mPSNR, mSSIM) over existing methods.",
    "source": "arXiv"
  },
  {
    "title": "AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation",
    "title_es": "AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation",
    "url": "https://arxiv.org/abs/2508.07770",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07770v1 Announce Type: new \nAbstract: We introduce AgentWorld, an interactive simulation platform for developing household mobile manipulation capabilities. Our platform combines automated scene construction that encompasses layout generation, semantic asset placement, visual material configuration, and physics simulation, with a dual-mode teleoperation system supporting both wheeled bases and humanoid locomotion policies for data collection. The resulting AgentWorld Dataset captures diverse tasks ranging from primitive actions (pick-and-place, push-pull, etc.) to multistage activities (serve drinks, heat up food, etc.) across living rooms, bedrooms, and kitchens. Through extensive benchmarking of imitation learning methods including behavior cloning, action chunking transformers, diffusion policies, and vision-language-action models, we demonstrate the dataset's effectiveness for sim-to-real transfer. The integrated system provides a comprehensive solution for scalable robotic skill acquisition in complex home environments, bridging the gap between simulation-based training and real-world deployment. The code, datasets will be available at https://yizhengzhang1.github.io/agent_world/",
    "source": "arXiv"
  },
  {
    "title": "Prototype-Guided Curriculum Learning for Zero-Shot Learning",
    "title_es": "Prototype-Guided Curriculum Learning for Zero-Shot Learning",
    "url": "https://arxiv.org/abs/2508.07771",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07771v1 Announce Type: new \nAbstract: In Zero-Shot Learning (ZSL), embedding-based methods enable knowledge transfer from seen to unseen classes by learning a visual-semantic mapping from seen-class images to class-level semantic prototypes (e.g., attributes). However, these semantic prototypes are manually defined and may introduce noisy supervision for two main reasons: (i) instance-level mismatch: variations in perspective, occlusion, and annotation bias will cause discrepancies between individual sample and the class-level semantic prototypes; and (ii) class-level imprecision: the manually defined semantic prototypes may not accurately reflect the true semantics of the class. Consequently, the visual-semantic mapping will be misled, reducing the effectiveness of knowledge transfer to unseen classes. In this work, we propose a prototype-guided curriculum learning framework (dubbed as CLZSL), which mitigates instance-level mismatches through a Prototype-Guided Curriculum Learning (PCL) module and addresses class-level imprecision via a Prototype Update (PUP) module. Specifically, the PCL module prioritizes samples with high cosine similarity between their visual mappings and the class-level semantic prototypes, and progressively advances to less-aligned samples, thereby reducing the interference of instance-level mismatches to achieve accurate visual-semantic mapping. Besides, the PUP module dynamically updates the class-level semantic prototypes by leveraging the visual mappings learned from instances, thereby reducing class-level imprecision and further improving the visual-semantic mapping. Experiments were conducted on standard benchmark datasets-AWA2, SUN, and CUB-to verify the effectiveness of our method.",
    "source": "arXiv"
  },
  {
    "title": "Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)",
    "title_es": "Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)",
    "url": "https://arxiv.org/abs/2508.07775",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07775v1 Announce Type: new \nAbstract: Modeling the rotation of moving objects is a fundamental task in computer vision, yet $SO(3)$ extrapolation still presents numerous challenges: (1) unknown quantities such as the moment of inertia complicate dynamics, (2) the presence of external forces and torques can lead to non-conservative kinematics, and (3) estimating evolving state trajectories under sparse, noisy observations requires robustness. We propose modeling trajectories of noisy pose estimates on the manifold of 3D rotations in a physically and geometrically meaningful way by leveraging Neural Controlled Differential Equations guided with $SO(3)$ Savitzky-Golay paths. Existing extrapolation methods often rely on energy conservation or constant velocity assumptions, limiting their applicability in real-world scenarios involving non-conservative forces. In contrast, our approach is agnostic to energy and momentum conservation while being robust to input noise, making it applicable to complex, non-inertial systems. Our approach is easily integrated as a module in existing pipelines and generalizes well to trajectories with unknown physical parameters. By learning to approximate object dynamics from noisy states during training, our model attains robust extrapolation capabilities in simulation and various real-world settings. Code is available at https://github.com/bastianlb/forecasting-rotational-dynamics",
    "source": "arXiv"
  },
  {
    "title": "An Experimental Reservoir-Augmented Foundation Model: 6G O-RAN Case Study",
    "title_es": "An Experimental Reservoir-Augmented Foundation Model: 6G O-RAN Case Study",
    "url": "https://arxiv.org/abs/2508.07778",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07778v1 Announce Type: new \nAbstract: Next-generation open radio access networks (O-RAN) continuously stream tens of key performance indicators (KPIs) together with raw in-phase/quadrature (IQ) samples, yielding ultra-high-dimensional, non-stationary time series that overwhelm conventional transformer architectures. We introduce a reservoir-augmented masked autoencoding transformer (RA-MAT). This time series foundation model employs echo state network (ESN) computing with masked autoencoding to satisfy the stringent latency, energy efficiency, and scalability requirements of 6G O-RAN testing. A fixed, randomly initialized ESN rapidly projects each temporal patch into a rich dynamical embedding without backpropagation through time, converting the quadratic self-attention bottleneck into a lightweight linear operation. These embeddings drive a patch-wise masked autoencoder that reconstructs 30% randomly masked patches, compelling the encoder to capture both local dynamics and long-range structure from unlabeled data. After self-supervised pre-training, RA-MAT is fine-tuned with a shallow task head while keeping the reservoir and most transformer layers frozen, enabling low-footprint adaptation to diverse downstream tasks such as O-RAN KPI forecasting. In a comprehensive O-RAN KPI case study, RA-MAT achieved sub-0.06 mean squared error (MSE) on several continuous and discrete KPIs. This work positions RA-MAT as a practical pathway toward real-time, foundation-level analytics in future 6G networks.",
    "source": "arXiv"
  },
  {
    "title": "Hexagonal Picture Scanning Automata",
    "title_es": "Hexagonal Picture Scanning Automata",
    "url": "https://arxiv.org/abs/2508.07779",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07779v1 Announce Type: new \nAbstract: Two new classes of finite automata, called General hexagonal Boustrophedon finite automata and General hexagonal returning finite automata operating on hexagonal grids, are introduced and analyzed. The work establishes the theoretical foundations for these automata models, examines their computational properties, and investigates the relationships and equivalences between the language families they define. The research contributes to the broader understanding of two-dimensional automata theory by extending classical finite automaton concepts to hexagonal geometric structures with specialized traversal patterns.",
    "source": "arXiv"
  },
  {
    "title": "Reconstructing the dielectric properties of melanoma in 3D using real-life melanoma model",
    "title_es": "Reconstructing the dielectric properties of melanoma in 3D using real-life melanoma model",
    "url": "https://arxiv.org/abs/2508.07780",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07780v1 Announce Type: new \nAbstract: The paper presents performance of the adaptive domain decomposition finite element/finite difference method for reconstruction of the dielectric permittivity and conductivity functions for 3D real-life melanoma model using measurements of the backscattered electric field at the boundary of the investigated domain. We present several gradient-based reconstruction algorithms which use optimization approach to find stationary point of the Lagrangian. Our computational tests show qualitative and quantitative reconstruction of dielectric permittivity and conductivity functions using realistic model of malign melanoma at 6 GHz in 3D.",
    "source": "arXiv"
  },
  {
    "title": "SASST: Leveraging Syntax-Aware Chunking and LLMs for Simultaneous Speech Translation",
    "title_es": "SASST: Leveraging Syntax-Aware Chunking and LLMs for Simultaneous Speech Translation",
    "url": "https://arxiv.org/abs/2508.07781",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07781v1 Announce Type: new \nAbstract: This work proposes a grammar-based chunking strategy that segments input streams into semantically complete units by parsing dependency relations (e.g., noun phrase boundaries, verb-object structures) and punctuation features. The method ensures chunk coherence and minimizes semantic fragmentation. Building on this mechanism, we present SASST (Syntax-Aware Simultaneous Speech Translation), an end-to-end framework integrating frozen Whisper encoder and decoder-only LLM. The unified architecture dynamically outputs translation tokens or  symbols to jointly optimize translation timing and content, with target-side reordering addressing word-order divergence. Experiments on CoVoST2 multilingual corpus En-{De, Zh, Ja} demonstrate significant translation quality improvements across languages and validate the effectiveness of syntactic structures in LLM-driven SimulST systems.",
    "source": "arXiv"
  },
  {
    "title": "GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences",
    "title_es": "GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences",
    "url": "https://arxiv.org/abs/2508.07782",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07782v1 Announce Type: new \nAbstract: Recent advancements in gait recognition have significantly enhanced performance by treating silhouettes as either an unordered set or an ordered sequence. However, both set-based and sequence-based approaches exhibit notable limitations. Specifically, set-based methods tend to overlook short-range temporal context for individual frames, while sequence-based methods struggle to capture long-range temporal dependencies effectively. To address these challenges, we draw inspiration from human identification and propose a new perspective that conceptualizes human gait as a composition of individualized actions. Each action is represented by a series of frames, randomly selected from a continuous segment of the sequence, which we term a snippet. Fundamentally, the collection of snippets for a given sequence enables the incorporation of multi-scale temporal context, facilitating more comprehensive gait feature learning. Moreover, we introduce a non-trivial solution for snippet-based gait recognition, focusing on Snippet Sampling and Snippet Modeling as key components. Extensive experiments on four widely-used gait datasets validate the effectiveness of our proposed approach and, more importantly, highlight the potential of gait snippets. For instance, our method achieves the rank-1 accuracy of 77.5% on Gait3D and 81.7% on GREW using a 2D convolution-based backbone.",
    "source": "arXiv"
  },
  {
    "title": "Simple Algorithms for Fully Dynamic Edge Connectivity",
    "title_es": "Simple Algorithms for Fully Dynamic Edge Connectivity",
    "url": "https://arxiv.org/abs/2508.07783",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07783v1 Announce Type: new \nAbstract: In the fully dynamic edge connectivity problem, the input is a simple graph $G$ undergoing edge insertions and deletions, and the goal is to maintain its edge connectivity, denoted $\\lambda_G$. We present two simple randomized algorithms solving this problem. The first algorithm maintains the edge connectivity in worst-case update time $\\tilde{O}(n)$ per edge update, matching the known bound but with simpler analysis. Our second algorithm achieves worst-case update time $\\tilde{O}(n/\\lambda_G)$ and worst-case query time $\\tilde{O}(n^2/\\lambda_G^2)$, which is the first algorithm with worst-case update and query time $o(n)$ for large edge connectivity, namely, $\\lambda_G = \\omega(\\sqrt{n})$.",
    "source": "arXiv"
  },
  {
    "title": "Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts",
    "title_es": "Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts",
    "url": "https://arxiv.org/abs/2508.07785",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07785v1 Announce Type: new \nAbstract: The Mixture of Experts (MoE) architecture is a cornerstone of modern state-of-the-art (SOTA) large language models (LLMs). MoE models facilitate scalability by enabling sparse parameter activation. However, traditional MoE architecture uses homogeneous experts of a uniform size, activating a fixed number of parameters irrespective of input complexity and thus limiting computational efficiency. To overcome this limitation, we introduce Grove MoE, a novel architecture incorporating experts of varying sizes, inspired by the heterogeneous big.LITTLE CPU architecture. This architecture features novel adjugate experts with a dynamic activation mechanism, enabling model capacity expansion while maintaining manageable computational overhead. Building on this architecture, we present GroveMoE-Base and GroveMoE-Inst, 33B-parameter LLMs developed by applying an upcycling strategy to the Qwen3-30B-A3B-Base model during mid-training and post-training. GroveMoE models dynamically activate 3.14-3.28B parameters based on token complexity and achieve performance comparable to SOTA open-source models of similar or even larger size.",
    "source": "arXiv"
  },
  {
    "title": "Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning",
    "title_es": "Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning",
    "url": "https://arxiv.org/abs/2508.07788",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07788v1 Announce Type: new \nAbstract: To reduce radiation exposure and improve the diagnostic efficacy of low-dose computed tomography (LDCT), numerous deep learning-based denoising methods have been developed to mitigate noise and artifacts. However, most of these approaches ignore the anatomical semantics of human tissues, which may potentially result in suboptimal denoising outcomes. To address this problem, we propose ALDEN, an anatomy-aware LDCT denoising method that integrates semantic features of pretrained vision models (PVMs) with adversarial and contrastive learning. Specifically, we introduce an anatomy-aware discriminator that dynamically fuses hierarchical semantic features from reference normal-dose CT (NDCT) via cross-attention mechanisms, enabling tissue-specific realism evaluation in the discriminator. In addition, we propose a semantic-guided contrastive learning module that enforces anatomical consistency by contrasting PVM-derived features from LDCT, denoised CT and NDCT, preserving tissue-specific patterns through positive pairs and suppressing artifacts via dual negative pairs. Extensive experiments conducted on two LDCT denoising datasets reveal that ALDEN achieves the state-of-the-art performance, offering superior anatomy preservation and substantially reducing over-smoothing issue of previous work. Further validation on a downstream multi-organ segmentation task (encompassing 117 anatomical structures) affirms the model's ability to maintain anatomical awareness.",
    "source": "arXiv"
  },
  {
    "title": "Best-Effort Policies for Robust Markov Decision Processes",
    "title_es": "Best-Effort Policies for Robust Markov Decision Processes",
    "url": "https://arxiv.org/abs/2508.07790",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07790v1 Announce Type: new \nAbstract: We study the common generalization of Markov decision processes (MDPs) with sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal in RMDPs is to compute a policy that maximizes the expected return under an adversarial choice of the transition probabilities. If the uncertainty in the probabilities is independent between the states, known as s-rectangularity, such optimal robust policies can be computed efficiently using robust value iteration. However, there might still be multiple optimal robust policies, which, while equivalent with respect to the worst-case, reflect different expected returns under non-adversarial choices of the transition probabilities. Hence, we propose a refined policy selection criterion for RMDPs, drawing inspiration from the notions of dominance and best-effort in game theory. Instead of seeking a policy that only maximizes the worst-case expected return, we additionally require the policy to achieve a maximal expected return under different (i.e., not fully adversarial) transition probabilities. We call such a policy an optimal robust best-effort (ORBE) policy. We prove that ORBE policies always exist, characterize their structure, and present an algorithm to compute them with a small overhead compared to standard robust value iteration. ORBE policies offer a principled tie-breaker among optimal robust policies. Numerical experiments show the feasibility of our approach.",
    "source": "arXiv"
  },
  {
    "title": "Finite element 3D models of melanoma growth and time-dependent backscattered data for dielectric properties of melanoma at 6 GHz",
    "title_es": "Finite element 3D models of melanoma growth and time-dependent backscattered data for dielectric properties of melanoma at 6 GHz",
    "url": "https://arxiv.org/abs/2508.07794",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07794v1 Announce Type: new \nAbstract: Finite element meshes for 3D models simulating realistic malignant melanoma (MM) growth, incorporating accurate dielectric properties of the skin, have been developed. Numerical simulations illustrate how 3D finite element meshes can be utilized to generate backscattered data, enabling the evaluation of reconstruction algorithms designed to determine the dielectric properties of the proposed 3D model.",
    "source": "arXiv"
  },
  {
    "title": "Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake",
    "title_es": "Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake",
    "url": "https://arxiv.org/abs/2508.07795",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07795v1 Announce Type: new \nAbstract: Active defense strategies have been developed to counter the threat of deepfake technology. However, a primary challenge is their lack of persistence, as their effectiveness is often short-lived. Attackers can bypass these defenses by simply collecting protected samples and retraining their models. This means that static defenses inevitably fail when attackers retrain their models, which severely limits practical use. We argue that an effective defense not only distorts forged content but also blocks the model's ability to adapt, which occurs when attackers retrain their models on protected images. To achieve this, we propose an innovative Two-Stage Defense Framework (TSDF). Benefiting from the intensity separation mechanism designed in this paper, the framework uses dual-function adversarial perturbations to perform two roles. First, it can directly distort the forged results. Second, it acts as a poisoning vehicle that disrupts the data preparation process essential for an attacker's retraining pipeline. By poisoning the data source, TSDF aims to prevent the attacker's model from adapting to the defensive perturbations, thus ensuring the defense remains effective long-term. Comprehensive experiments show that the performance of traditional interruption methods degrades sharply when it is subjected to adversarial retraining. However, our framework shows a strong dual defense capability, which can improve the persistence of active defense. Our code will be available at https://github.com/vpsg-research/TSDF.",
    "source": "arXiv"
  },
  {
    "title": "TLV-HGNN: Thinking Like a Vertex for Memory-efficient HGNN Inference",
    "title_es": "TLV-HGNN: Thinking Like a Vertex for Memory-efficient HGNN Inference",
    "url": "https://arxiv.org/abs/2508.07796",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07796v1 Announce Type: new \nAbstract: Heterogeneous graph neural networks (HGNNs) excel at processing heterogeneous graph data and are widely applied in critical domains. In HGNN inference, the neighbor aggregation stage is the primary performance determinant, yet it suffers from two major sources of memory inefficiency. First, the commonly adopted per-semantic execution paradigm stores intermediate aggregation results for each semantic prior to semantic fusion, causing substantial memory expansion. Second, the aggregation process incurs extensive redundant memory accesses, including repeated loading of target vertex features across semantics and repeated accesses to shared neighbors due to cross-semantic neighborhood overlap. These inefficiencies severely limit scalability and reduce HGNN inference performance.\n  In this work, we first propose a semantics-complete execution paradigm from a vertex perspective that eliminates per-semantic intermediate storage and redundant target vertex accesses. Building on this paradigm, we design TVL-HGNN, a reconfigurable hardware accelerator optimized for efficient aggregation. In addition, we introduce a vertex grouping technique based on cross-semantic neighborhood overlap, with hardware implementation, to reduce redundant accesses to shared neighbors. Experimental results demonstrate that TVL-HGNN achieves average speedups of 7.85x and 1.41x over the NVIDIA A100 GPU and the state-of-the-art HGNN accelerator HiHGNN, respectively, while reducing energy consumption by 98.79% and 32.61%.",
    "source": "arXiv"
  },
  {
    "title": "Power Battery Detection",
    "title_es": "Power Battery Detection",
    "url": "https://arxiv.org/abs/2508.07797",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07797v1 Announce Type: new \nAbstract: Power batteries are essential components in electric vehicles, where internal structural defects can pose serious safety risks. We conduct a comprehensive study on a new task, power battery detection (PBD), which aims to localize the dense endpoints of cathode and anode plates from industrial X-ray images for quality inspection. Manual inspection is inefficient and error-prone, while traditional vision algorithms struggle with densely packed plates, low contrast, scale variation, and imaging artifacts. To address this issue and drive more attention into this meaningful task, we present PBD5K, the first large-scale benchmark for this task, consisting of 5,000 X-ray images from nine battery types with fine-grained annotations and eight types of real-world visual interference. To support scalable and consistent labeling, we develop an intelligent annotation pipeline that combines image filtering, model-assisted pre-labeling, cross-verification, and layered quality evaluation. We formulate PBD as a point-level segmentation problem and propose MDCNeXt, a model designed to extract and integrate multi-dimensional structure clues including point, line, and count information from the plate itself. To improve discrimination between plates and suppress visual interference, MDCNeXt incorporates two state space modules. The first is a prompt-filtered module that learns contrastive relationships guided by task-specific prompts. The second is a density-aware reordering module that refines segmentation in regions with high plate density. In addition, we propose a distance-adaptive mask generation strategy to provide robust supervision under varying spatial distributions of anode and cathode positions. The source code and datasets will be publicly available at \\href{https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD}{PBD5K}.",
    "source": "arXiv"
  },
  {
    "title": "QoS-Aware Integrated Sensing, Communication, and Control with Movable Antenna",
    "title_es": "QoS-Aware Integrated Sensing, Communication, and Control with Movable Antenna",
    "url": "https://arxiv.org/abs/2508.07799",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07799v1 Announce Type: new \nAbstract: Integrated sensing, communication, and control (ISCC) has emerged as a key enabler for low-altitude wireless networks with enhanced adaptability through resource allocation co-design and intelligent environment awareness. However, dynamic interference and channel attenuation constrain the potential of the ISCC system. To address this challenge, we propose a novel movable antenna-empowered ISCC system. An achievable data rate maximization problem is formulated while guaranteeing the sensing and control quality-of-service (QoS) by optimizing the positions of the antennas and the beamforming strategy for communication, sensing, and control co-design. An efficient alternating optimization (AO)-based algorithm is proposed to solve the highly coupled non-convex problem. Numerical results demonstrate that the proposed AO-based algorithm achieves substantial gains in the achievable data rate and the control QoS compared with benchmark schemes.",
    "source": "arXiv"
  },
  {
    "title": "MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks",
    "title_es": "MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks",
    "url": "https://arxiv.org/abs/2508.07803",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07803v1 Announce Type: new \nAbstract: The goal of multimodal image fusion is to integrate complementary information from infrared and visible images, generating multimodal fused images for downstream tasks. Existing downstream pre-training models are typically trained on visible images. However, the significant pixel distribution differences between visible and multimodal fusion images can degrade downstream task performance, sometimes even below that of using only visible images. This paper explores adapting multimodal fused images with significant modality differences to object detection and semantic segmentation models trained on visible images. To address this, we propose MambaTrans, a novel multimodal fusion image modality translator. MambaTrans uses descriptions from a multimodal large language model and masks from semantic segmentation models as input. Its core component, the Multi-Model State Space Block, combines mask-image-text cross-attention and a 3D-Selective Scan Module, enhancing pure visual capabilities. By leveraging object detection prior knowledge, MambaTrans minimizes detection loss during training and captures long-term dependencies among text, masks, and images. This enables favorable results in pre-trained models without adjusting their parameters. Experiments on public datasets show that MambaTrans effectively improves multimodal image performance in downstream tasks.",
    "source": "arXiv"
  },
  {
    "title": "Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning",
    "title_es": "Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning",
    "url": "https://arxiv.org/abs/2508.07804",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07804v1 Announce Type: new \nAbstract: Generating 3D human poses from multimodal inputs such as images or text requires models to capture both rich spatial and semantic correspondences. While pose-specific multimodal large language models (MLLMs) have shown promise in this task, they are typically trained with supervised objectives such as SMPL parameter regression or token-level prediction, which struggle to model the inherent ambiguity and achieve task-specific alignment required for accurate 3D pose generation. To address these limitations, we propose Pose-RFT, a reinforcement fine-tuning framework tailored for 3D human pose generation in MLLMs. We formulate the task as a hybrid action reinforcement learning problem that jointly optimizes discrete language prediction and continuous pose generation. To this end, we introduce HyGRPO, a hybrid reinforcement learning algorithm that performs group-wise reward normalization over sampled responses to guide joint optimization of discrete and continuous actions. Pose-RFT further incorporates task-specific reward functions to guide optimization towards spatial alignment in image-to-pose generation and semantic consistency in text-to-pose generation. Extensive experiments on multiple pose generation benchmarks demonstrate that Pose-RFT significantly improves performance over existing pose-specific MLLMs, validating the effectiveness of hybrid action reinforcement fine-tuning for 3D pose generation.",
    "source": "arXiv"
  },
  {
    "title": "Can You Trick the Grader? Adversarial Persuasion of LLM Judges",
    "title_es": "Can You Trick the Grader? Adversarial Persuasion of LLM Judges",
    "url": "https://arxiv.org/abs/2508.07805",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07805v1 Announce Type: new \nAbstract: As large language models take on growing roles as automated evaluators in practical settings, a critical question arises: Can individuals persuade an LLM judge to assign unfairly high scores? This study is the first to reveal that strategically embedded persuasive language can bias LLM judges when scoring mathematical reasoning tasks, where correctness should be independent of stylistic variation. Grounded in Aristotle's rhetorical principles, we formalize seven persuasion techniques (Majority, Consistency, Flattery, Reciprocity, Pity, Authority, Identity) and embed them into otherwise identical responses. Across six math benchmarks, we find that persuasive language leads LLM judges to assign inflated scores to incorrect solutions, by up to 8% on average, with Consistency causing the most severe distortion. Notably, increasing model size does not substantially mitigate this vulnerability. Further analysis demonstrates that combining multiple persuasion techniques amplifies the bias, and pairwise evaluation is likewise susceptible. Moreover, the persuasive effect persists under counter prompting strategies, highlighting a critical vulnerability in LLM-as-a-Judge pipelines and underscoring the need for robust defenses against persuasion-based attacks.",
    "source": "arXiv"
  },
  {
    "title": "Topological Feature Compression for Molecular Graph Neural Networks",
    "title_es": "Topological Feature Compression for Molecular Graph Neural Networks",
    "url": "https://arxiv.org/abs/2508.07807",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07807v1 Announce Type: new \nAbstract: Recent advances in molecular representation learning have produced highly effective encodings of molecules for numerous cheminformatics and bioinformatics tasks. However, extracting general chemical insight while balancing predictive accuracy, interpretability, and computational efficiency remains a major challenge. In this work, we introduce a novel Graph Neural Network (GNN) architecture that combines compressed higher-order topological signals with standard molecular features. Our approach captures global geometric information while preserving computational tractability and human-interpretable structure. We evaluate our model across a range of benchmarks, from small-molecule datasets to complex material datasets, and demonstrate superior performance using a parameter-efficient architecture. We achieve the best performing results in both accuracy and robustness across almost all benchmarks. We open source all code \\footnote{All code and results can be found on Github https://github.com/rahulkhorana/TFC-PACT-Net}.",
    "source": "arXiv"
  },
  {
    "title": "EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning",
    "title_es": "EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.07809",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07809v1 Announce Type: new \nAbstract: Reinforcement learning with verifiable reward (RLVR) has become a promising paradigm for post-training large language models (LLMs) to improve their reasoning capability. However, when the rollout accuracy is low on hard problems, the reward becomes sparse, limiting learning efficiency and causing exploration bottlenecks. Existing approaches either rely on stronger LLMs for distillation or filter out difficult problems, which limits scalability or restricts reasoning improvement through exploration.\n  We propose EvoCoT, a self-evolving curriculum learning framework based on two-stage chain-of-thought (CoT) reasoning optimization. EvoCoT constrains the exploration space by self-generating and verifying CoT trajectories, then gradually shortens them to expand the space in a controlled way. This enables LLMs to stably learn from initially unsolved hard problems under sparse rewards. We apply EvoCoT to multiple LLM families, including Qwen, DeepSeek, and Llama. Experiments show that EvoCoT enables LLMs to solve previously unsolved problems, improves reasoning capability without external CoT supervision, and is compatible with various RL fine-tuning methods. We release the source code to support future research.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating Compositional Approaches for Focus and Sentiment Analysis",
    "title_es": "Evaluating Compositional Approaches for Focus and Sentiment Analysis",
    "url": "https://arxiv.org/abs/2508.07810",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07810v1 Announce Type: new \nAbstract: This paper summarizes the results of evaluating a compositional approach for Focus Analysis (FA) in Linguistics and Sentiment Analysis (SA) in Natural Language Processing (NLP). While quantitative evaluations of compositional and non-compositional approaches in SA exist in NLP, similar quantitative evaluations are very rare in FA in Linguistics that deal with linguistic expressions representing focus or emphasis such as \"it was John who left\". We fill this gap in research by arguing that compositional rules in SA also apply to FA because FA and SA are closely related meaning that SA is part of FA. Our compositional approach in SA exploits basic syntactic rules such as rules of modification, coordination, and negation represented in the formalism of Universal Dependencies (UDs) in English and applied to words representing sentiments from sentiment dictionaries. Some of the advantages of our compositional analysis method for SA in contrast to non-compositional analysis methods are interpretability and explainability. We test the accuracy of our compositional approach and compare it with a non-compositional approach VADER that uses simple heuristic rules to deal with negation, coordination and modification. In contrast to previous related work that evaluates compositionality in SA on long reviews, this study uses more appropriate datasets to evaluate compositionality. In addition, we generalize the results of compositional approaches in SA to compositional approaches in FA.",
    "source": "arXiv"
  },
  {
    "title": "DiTVR: Zero-Shot Diffusion Transformer for Video Restoration",
    "title_es": "DiTVR: Zero-Shot Diffusion Transformer for Video Restoration",
    "url": "https://arxiv.org/abs/2508.07811",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07811v1 Announce Type: new \nAbstract: Video restoration aims to reconstruct high quality video sequences from low quality inputs, addressing tasks such as super resolution, denoising, and deblurring. Traditional regression based methods often produce unrealistic details and require extensive paired datasets, while recent generative diffusion models face challenges in ensuring temporal consistency. We introduce DiTVR, a zero shot video restoration framework that couples a diffusion transformer with trajectory aware attention and a wavelet guided, flow consistent sampler. Unlike prior 3D convolutional or frame wise diffusion approaches, our attention mechanism aligns tokens along optical flow trajectories, with particular emphasis on vital layers that exhibit the highest sensitivity to temporal dynamics. A spatiotemporal neighbour cache dynamically selects relevant tokens based on motion correspondences across frames. The flow guided sampler injects data consistency only into low-frequency bands, preserving high frequency priors while accelerating convergence. DiTVR establishes a new zero shot state of the art on video restoration benchmarks, demonstrating superior temporal consistency and detail preservation while remaining robust to flow noise and occlusions.",
    "source": "arXiv"
  },
  {
    "title": "Semi-supervised Multiscale Matching for SAR-Optical Image",
    "title_es": "Semi-supervised Multiscale Matching for SAR-Optical Image",
    "url": "https://arxiv.org/abs/2508.07812",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07812v1 Announce Type: new \nAbstract: Driven by the complementary nature of optical and synthetic aperture radar (SAR) images, SAR-optical image matching has garnered significant interest. Most existing SAR-optical image matching methods aim to capture effective matching features by employing the supervision of pixel-level matched correspondences within SAR-optical image pairs, which, however, suffers from time-consuming and complex manual annotation, making it difficult to collect sufficient labeled SAR-optical image pairs. To handle this, we design a semi-supervised SAR-optical image matching pipeline that leverages both scarce labeled and abundant unlabeled image pairs and propose a semi-supervised multiscale matching for SAR-optical image matching (S2M2-SAR). Specifically, we pseudo-label those unlabeled SAR-optical image pairs with pseudo ground-truth similarity heatmaps by combining both deep and shallow level matching results, and train the matching model by employing labeled and pseudo-labeled similarity heatmaps. In addition, we introduce a cross-modal feature enhancement module trained using a cross-modality mutual independence loss, which requires no ground-truth labels. This unsupervised objective promotes the separation of modality-shared and modality-specific features by encouraging statistical independence between them, enabling effective feature disentanglement across optical and SAR modalities. To evaluate the effectiveness of S2M2-SAR, we compare it with existing competitors on benchmark datasets. Experimental results demonstrate that S2M2-SAR not only surpasses existing semi-supervised methods but also achieves performance competitive with fully supervised SOTA methods, demonstrating its efficiency and practical potential.",
    "source": "arXiv"
  },
  {
    "title": "SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing",
    "title_es": "SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing",
    "url": "https://arxiv.org/abs/2508.07814",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07814v1 Announce Type: new \nAbstract: With the growing demand for efficient logistics, unmanned aerial vehicles (UAVs) are increasingly being paired with automated guided vehicles (AGVs). While UAVs offer the ability to navigate through dense environments and varying altitudes, they are limited by battery life, payload capacity, and flight duration, necessitating coordinated ground support.\n  Focusing on heterogeneous navigation, SwarmVLM addresses these limitations by enabling semantic collaboration between UAVs and ground robots through impedance control. The system leverages the Vision Language Model (VLM) and the Retrieval-Augmented Generation (RAG) to adjust impedance control parameters in response to environmental changes. In this framework, the UAV acts as a leader using Artificial Potential Field (APF) planning for real-time navigation, while the ground robot follows via virtual impedance links with adaptive link topology to avoid collisions with short obstacles.\n  The system demonstrated a 92% success rate across 12 real-world trials. Under optimal lighting conditions, the VLM-RAG framework achieved 8% accuracy in object detection and selection of impedance parameters. The mobile robot prioritized short obstacle avoidance, occasionally resulting in a lateral deviation of up to 50 cm from the UAV path, which showcases safe navigation in a cluttered setting.",
    "source": "arXiv"
  },
  {
    "title": "Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models",
    "title_es": "Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models",
    "url": "https://arxiv.org/abs/2508.07818",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07818v1 Announce Type: new \nAbstract: No-reference image quality assessment (NR-IQA) aims to simulate the process of perceiving image quality aligned with subjective human perception. However, existing NR-IQA methods either focus on global representations that leads to limited insights into the semantically salient regions or employ a uniform weighting for region features that weakens the sensitivity to local quality variations. In this paper, we propose a fine-grained image quality assessment model, named RSFIQA, which integrates region-level distortion information to perceive multi-dimensional quality discrepancies. To enhance regional quality awareness, we first utilize the Segment Anything Model (SAM) to dynamically partition the input image into non-overlapping semantic regions. For each region, we teach a powerful Multi-modal Large Language Model (MLLM) to extract descriptive content and perceive multi-dimensional distortions, enabling a comprehensive understanding of both local semantics and quality degradations. To effectively leverage this information, we introduce Region-Aware Semantic Attention (RSA) mechanism, which generates a global attention map by aggregating fine-grained representations from local regions. In addition, RSFIQA is backbone-agnostic and can be seamlessly integrated into various deep neural network architectures. Extensive experiments demonstrate the robustness and effectiveness of the proposed method, which achieves competitive quality prediction performance across multiple benchmark datasets.",
    "source": "arXiv"
  },
  {
    "title": "Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP",
    "title_es": "Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP",
    "url": "https://arxiv.org/abs/2508.07819",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07819v1 Announce Type: new \nAbstract: Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap when applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of local inductive biases for dense prediction and their reliance on inflexible feature fusion paradigms. We address these limitations through an Architectural Co-Design framework that jointly refines feature representation and cross-modal fusion. Our method integrates a parameter-efficient Convolutional Low-Rank Adaptation (Conv-LoRA) adapter to inject local inductive biases for fine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that leverages visual context to adaptively modulate text prompts, enabling a powerful bidirectional fusion. Extensive experiments on diverse industrial and medical benchmarks demonstrate superior accuracy and robustness, validating that this synergistic co-design is critical for robustly adapting foundation models to dense perception tasks.",
    "source": "arXiv"
  },
  {
    "title": "Nearly Optimal Bounds for Stochastic Online Sorting",
    "title_es": "Nearly Optimal Bounds for Stochastic Online Sorting",
    "url": "https://arxiv.org/abs/2508.07823",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07823v1 Announce Type: new \nAbstract: In the online sorting problem, we have an array $A$ of $n$ cells, and receive a stream of $n$ items $x_1,\\dots,x_n\\in [0,1]$. When an item arrives, we need to immediately and irrevocably place it into an empty cell. The goal is to minimize the sum of absolute differences between adjacent items, which is called the \\emph{cost} of the algorithm. It has been shown by Aamand, Abrahamsen, Beretta, and Kleist (SODA 2023) that when the stream $x_1,\\dots,x_n$ is generated adversarially, the optimal cost bound for any deterministic algorithm is $\\Theta(\\sqrt{n})$.\n  In this paper, we study the stochastic version of online sorting, where the input items $x_1,\\dots,x_n$ are sampled uniformly at random. Despite the intuition that the stochastic version should yield much better cost bounds, the previous best algorithm for stochastic online sorting by Abrahamsen, Bercea, Beretta, Klausen and Kozma (ESA 2024) only achieves $\\tilde{O}(n^{1/4})$ cost, which seems far from optimal. We show that stochastic online sorting indeed allows for much more efficient algorithms, by presenting an algorithm that achieves expected cost $\\log n\\cdot 2^{O(\\log^* n)}$. We also prove a cost lower bound of $\\Omega(\\log n)$, thus show that our algorithm is nearly optimal.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating Large Language Models as Expert Annotators",
    "title_es": "Evaluating Large Language Models as Expert Annotators",
    "url": "https://arxiv.org/abs/2508.07827",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07827v1 Announce Type: new \nAbstract: Textual data annotation, the process of labeling or tagging text with relevant information, is typically costly, time-consuming, and labor-intensive. While large language models (LLMs) have demonstrated their potential as direct alternatives to human annotators for general domains natural language processing (NLP) tasks, their effectiveness on annotation tasks in domains requiring expert knowledge remains underexplored. In this paper, we investigate: whether top-performing LLMs, which might be perceived as having expert-level proficiency in academic and professional benchmarks, can serve as direct alternatives to human expert annotators? To this end, we evaluate both individual LLMs and multi-agent approaches across three highly specialized domains: finance, biomedicine, and law. Specifically, we propose a multi-agent discussion framework to simulate a group of human annotators, where LLMs are tasked to engage in discussions by considering others' annotations and justifications before finalizing their labels. Additionally, we incorporate reasoning models (e.g., o3-mini) to enable a more comprehensive comparison. Our empirical results reveal that: (1) Individual LLMs equipped with inference-time techniques (e.g., chain-of-thought (CoT), self-consistency) show only marginal or even negative performance gains, contrary to prior literature suggesting their broad effectiveness. (2) Overall, reasoning models do not demonstrate statistically significant improvements over non-reasoning models in most settings. This suggests that extended long CoT provides relatively limited benefits for data annotation in specialized domains. (3) Certain model behaviors emerge in the multi-agent discussion environment. For instance, Claude 3.7 Sonnet with thinking rarely changes its initial annotations, even when other agents provide correct annotations or valid reasoning.",
    "source": "arXiv"
  },
  {
    "title": "Material Fingerprinting: A shortcut to material model discovery without solving optimization problems",
    "title_es": "Material Fingerprinting: A shortcut to material model discovery without solving optimization problems",
    "url": "https://arxiv.org/abs/2508.07831",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07831v1 Announce Type: new \nAbstract: We propose Material Fingerprinting, a new method for the rapid discovery of mechanical material models from direct or indirect data that avoids solving potentially non-convex optimization problems. The core assumption of Material Fingerprinting is that each material exhibits a unique response when subjected to a standardized experimental setup. We can interpret this response as the material's fingerprint, essentially a unique identifier that encodes all pertinent information about the material's mechanical characteristics. Consequently, once we have established a database containing fingerprints and their corresponding mechanical models during an offline phase, we can rapidly characterize an unseen material in an online phase. This is accomplished by measuring its fingerprint and employing a pattern recognition algorithm to identify the best matching fingerprint in the database. In our study, we explore this concept in the context of hyperelastic materials, demonstrating the applicability of Material Fingerprinting across different experimental setups. Initially, we examine Material Fingerprinting through experiments involving homogeneous deformation fields, which provide direct strain-stress data pairs. We then extend this concept to experiments involving complexly shaped specimens with heterogeneous deformation fields, which provide indirect displacement and reaction force measurements. We show that, in both cases, Material Fingerprinting is an efficient tool for model discovery, bypassing the challenges of potentially non-convex optimization. We believe that Material Fingerprinting provides a powerful and generalizable framework for rapid material model identification across a wide range of experimental designs and material behaviors, paving the way for numerous future developments.",
    "source": "arXiv"
  },
  {
    "title": "MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization",
    "title_es": "MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization",
    "url": "https://arxiv.org/abs/2508.07833",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07833v1 Announce Type: new \nAbstract: Vision Language Models (VLMs) encode multimodal inputs over large, complex, and difficult-to-interpret architectures, which limit transparency and trust. We propose a Multimodal Inversion for Model Interpretation and Conceptualization (MIMIC) framework to visualize the internal representations of VLMs by synthesizing visual concepts corresponding to internal encodings. MIMIC uses a joint VLM-based inversion and a feature alignment objective to account for VLM's autoregressive processing. It additionally includes a triplet of regularizers for spatial alignment, natural image smoothness, and semantic realism. We quantitatively and qualitatively evaluate MIMIC by inverting visual concepts over a range of varying-length free-form VLM output texts. Reported results include both standard visual quality metrics as well as semantic text-based metrics. To the best of our knowledge, this is the first model inversion approach addressing visual interpretations of VLM concepts.",
    "source": "arXiv"
  },
  {
    "title": "KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations",
    "title_es": "KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations",
    "url": "https://arxiv.org/abs/2508.07834",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07834v1 Announce Type: new \nAbstract: Over the years, the need for rescue operations throughout the world has increased rapidly. Demographic changes and the resulting risk of injury or health disorders form the basis for emergency calls. In such scenarios, first responders are in a rush to reach the patient in need, provide first aid, and save lives. In these situations, they must be able to provide personalized and optimized healthcare in the shortest possible time and estimate the patients condition with the help of freshly recorded vital data in an emergency situation. However, in such a timedependent situation, first responders and medical experts cannot fully grasp their knowledge and need assistance and recommendation for further medical treatments. To achieve this, on the spot calculated, evaluated, and processed knowledge must be made available to improve treatments by first responders. The Knowledge Graph presented in this article as a central knowledge representation provides first responders with an innovative knowledge management that enables intelligent treatment recommendations with an artificial intelligence-based pre-recognition of the situation.",
    "source": "arXiv"
  },
  {
    "title": "Effortless Vision-Language Model Specialization in Histopathology without Annotation",
    "title_es": "Effortless Vision-Language Model Specialization in Histopathology without Annotation",
    "url": "https://arxiv.org/abs/2508.07835",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07835v1 Announce Type: new \nAbstract: Recent advances in Vision-Language Models (VLMs) in histopathology, such as CONCH and QuiltNet, have demonstrated impressive zero-shot classification capabilities across various tasks. However, their general-purpose design may lead to suboptimal performance in specific downstream applications. While supervised fine-tuning methods address this issue, they require manually labeled samples for adaptation. This paper investigates annotation-free adaptation of VLMs through continued pretraining on domain- and task-relevant image-caption pairs extracted from existing databases. Our experiments on two VLMs, CONCH and QuiltNet, across three downstream tasks reveal that these pairs substantially enhance both zero-shot and few-shot performance. Notably, with larger training sizes, continued pretraining matches the performance of few-shot methods while eliminating manual labeling. Its effectiveness, task-agnostic design, and annotation-free workflow make it a promising pathway for adapting VLMs to new histopathology tasks. Code is available at https://github.com/DeepMicroscopy/Annotation-free-VLM-specialization.",
    "source": "arXiv"
  },
  {
    "title": "CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving",
    "title_es": "CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.07838",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07838v1 Announce Type: new \nAbstract: Bird's Eye View (BEV) perception systems based on multi-sensor feature fusion have become a fundamental cornerstone for end-to-end autonomous driving. However, existing multi-modal BEV methods commonly suffer from limited input adaptability, constrained modeling capacity, and suboptimal generalization. To address these challenges, we propose a hierarchically decoupled Mixture-of-Experts architecture at the functional module level, termed Computing Brain DEvelopment System Mixture-of-Experts (CBDES MoE). CBDES MoE integrates multiple structurally heterogeneous expert networks with a lightweight Self-Attention Router (SAR) gating mechanism, enabling dynamic expert path selection and sparse, input-aware efficient inference. To the best of our knowledge, this is the first modular Mixture-of-Experts framework constructed at the functional module granularity within the autonomous driving domain. Extensive evaluations on the real-world nuScenes dataset demonstrate that CBDES MoE consistently outperforms fixed single-expert baselines in 3D object detection. Compared to the strongest single-expert model, CBDES MoE achieves a 1.6-point increase in mAP and a 4.1-point improvement in NDS, demonstrating the effectiveness and practical advantages of the proposed approach.",
    "source": "arXiv"
  },
  {
    "title": "Touch Speaks, Sound Feels: A Multimodal Approach to Affective and Social Touch from Robots to Humans",
    "title_es": "Touch Speaks, Sound Feels: A Multimodal Approach to Affective and Social Touch from Robots to Humans",
    "url": "https://arxiv.org/abs/2508.07839",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07839v1 Announce Type: new \nAbstract: Affective tactile interaction constitutes a fundamental component of human communication. In natural human-human encounters, touch is seldom experienced in isolation; rather, it is inherently multisensory. Individuals not only perceive the physical sensation of touch but also register the accompanying auditory cues generated through contact. The integration of haptic and auditory information forms a rich and nuanced channel for emotional expression. While extensive research has examined how robots convey emotions through facial expressions and speech, their capacity to communicate social gestures and emotions via touch remains largely underexplored. To address this gap, we developed a multimodal interaction system incorporating a 5*5 grid of 25 vibration motors synchronized with audio playback, enabling robots to deliver combined haptic-audio stimuli. In an experiment involving 32 Chinese participants, ten emotions and six social gestures were presented through vibration, sound, or their combination. Participants rated each stimulus on arousal and valence scales. The results revealed that (1) the combined haptic-audio modality significantly enhanced decoding accuracy compared to single modalities; (2) each individual channel-vibration or sound-effectively supported certain emotions recognition, with distinct advantages depending on the emotional expression; and (3) gestures alone were generally insufficient for conveying clearly distinguishable emotions. These findings underscore the importance of multisensory integration in affective human-robot interaction and highlight the complementary roles of haptic and auditory cues in enhancing emotional communication.",
    "source": "arXiv"
  },
  {
    "title": "A Comparative Analysis of Lightweight Hash Functions Using AVR ATXMega128 and ChipWhisperer",
    "title_es": "A Comparative Analysis of Lightweight Hash Functions Using AVR ATXMega128 and ChipWhisperer",
    "url": "https://arxiv.org/abs/2508.07840",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07840v1 Announce Type: new \nAbstract: Lightweight hash functions have become important building blocks for security in embedded and IoT systems. A plethora of algorithms have been proposed and standardized, providing a wide range of performance trade-off options for developers to choose from. This paper presents a comparative analysis of 22 key software-based lightweight hash functions, including the finalist from the SHA-3 competition. We use a novel benchmark methodology that combines an AVR ATXMega128 microcontroller with the ChipWhisperer cryptanalysis platform and evaluate and compare the various hash functions along several dimensions, including execution speed, % measured in Cycles per Byte (CpB), memory footprint, and energy consumption. Using the composite E-RANK metric, we provide new insight into the various trade-offs each hash function offers to system developers.",
    "source": "arXiv"
  },
  {
    "title": "Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow",
    "title_es": "Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow",
    "url": "https://arxiv.org/abs/2508.07841",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07841v1 Announce Type: new \nAbstract: Attitude control is a fundamental aspect of spacecraft operations. Model Predictive Control (MPC) has emerged as a powerful strategy for these tasks, relying on accurate models of the system dynamics to optimize control actions over a prediction horizon. In scenarios where physics models are incomplete, difficult to derive, or computationally expensive, machine learning offers a flexible alternative by learning the system behavior directly from data. However, purely data-driven models often struggle with generalization and stability, especially when applied to inputs outside their training domain. To address these limitations, we investigate the benefits of incorporating Physics-Informed Neural Networks (PINNs) into the learning of spacecraft attitude dynamics, comparing their performance with that of purely data-driven approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network architecture with a self-attention mechanism, we trained several models on simulated data generated with the Basilisk simulator. Two training strategies were considered: a purely data-driven baseline and a physics-informed variant to improve robustness and stability. Our results demonstrate that the inclusion of physics-based information significantly enhances the performance in terms of the mean relative error of the best architectures found by 27.08%. These advantages are particularly evident when the learned models are integrated into an MPC framework, where PINN-based models consistently outperform their purely data-driven counterparts in terms of control accuracy and robustness, yielding improvements of up to 42.86% in performance stability error and increased robustness-to-noise.",
    "source": "arXiv"
  },
  {
    "title": "DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts",
    "title_es": "DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts",
    "url": "https://arxiv.org/abs/2508.07842",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07842v1 Announce Type: new \nAbstract: Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex multi-step tasks that require continuous planning, sequential decision-making, and extended execution across domains to achieve the final goal. However, existing methods heavily rely on skill chaining by concatenating pre-trained subtasks, with environment observations and self-state tightly coupled, lacking the ability to generalize to new combinations of environments and skills, failing to complete various LH tasks across domains. To solve this problem, this paper presents DETACH, a cross-domain learning framework for LH tasks via biologically inspired dual-stream disentanglement. Inspired by the brain's \"where-what\" dual pathway mechanism, DETACH comprises two core modules: i) an environment learning module for spatial understanding, which captures object functions, spatial relationships, and scene semantics, achieving cross-domain transfer through complete environment-self disentanglement; ii) a skill learning module for task execution, which processes self-state information including joint degrees of freedom and motor patterns, enabling cross-skill transfer through independent motor pattern encoding. We conducted extensive experiments on various LH tasks in HSI scenes. Compared with existing methods, DETACH can achieve an average subtasks success rate improvement of 23% and average execution efficiency improvement of 29%.",
    "source": "arXiv"
  },
  {
    "title": "Fabricating Holiness: Characterizing Religious Misinformation Circulators on Arabic Social Media",
    "title_es": "Fabricating Holiness: Characterizing Religious Misinformation Circulators on Arabic Social Media",
    "url": "https://arxiv.org/abs/2508.07845",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07845v1 Announce Type: new \nAbstract: Misinformation is a growing concern in a decade involving critical global events. While social media regulation is mainly dedicated towards the detection and prevention of fake news and political misinformation, there is limited research about religious misinformation which has only been addressed through qualitative approaches. In this work, we study the spread of fabricated quotes (Hadith) that are claimed to belong to Prophet Muhammad (the prophet of Islam) as a case study demonstrating one of the most common religious misinformation forms on Arabic social media. We attempt through quantitative methods to understand the characteristics of social media users who interact with fabricated Hadith. We spotted users who frequently circulate fabricated Hadith and others who frequently debunk it to understand the main differences between the two groups. We used Logistic Regression to automatically predict their behaviors and analyzed its weights to gain insights about the characteristics and interests of each group. We find that both fabricated Hadith circulators and debunkers have generally a lot of ties to religious accounts. However, circulators are identified by many accounts that follow the Shia branch of Islam, Sunni Islamic public figures from the gulf countries, and many Sunni non-professional pages posting Islamic content. On the other hand, debunkers are identified by following academic Islamic scholars from multiple countries and by having more intellectual non-religious interests like charity, politics, and activism.",
    "source": "arXiv"
  },
  {
    "title": "Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images",
    "title_es": "Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images",
    "url": "https://arxiv.org/abs/2508.07847",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07847v1 Announce Type: new \nAbstract: Accurate, reliable solar flare prediction is crucial for mitigating potential disruptions to critical infrastructure, while predicting solar flares remains a significant challenge. Existing methods based on heuristic physical features often lack representation learning from solar images. On the other hand, end-to-end learning approaches struggle to model long-range temporal dependencies in solar images. In this study, we propose Deep Space Weather Model (Deep SWM), which is based on multiple deep state space models for handling both ten-channel solar images and long-range spatio-temporal dependencies. Deep SWM also features a sparse masked autoencoder, a novel pretraining strategy that employs a two-phase masking approach to preserve crucial regions such as sunspots while compressing spatial information. Furthermore, we built FlareBench, a new public benchmark for solar flare prediction covering a full 11-year solar activity cycle, to validate our method. Our method outperformed baseline methods and even human expert performance on standard metrics in terms of performance and reliability. The project page can be found at https://keio-smilab25.github.io/DeepSWM.",
    "source": "arXiv"
  },
  {
    "title": "LLMs for Law: Evaluating Legal-Specific LLMs on Contract Understanding",
    "title_es": "LLMs for Law: Evaluating Legal-Specific LLMs on Contract Understanding",
    "url": "https://arxiv.org/abs/2508.07849",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07849v1 Announce Type: new \nAbstract: Despite advances in legal NLP, no comprehensive evaluation covering multiple legal-specific LLMs currently exists for contract classification tasks in contract understanding. To address this gap, we present an evaluation of 10 legal-specific LLMs on three English language contract understanding tasks and compare them with 7 general-purpose LLMs. The results show that legal-specific LLMs consistently outperform general-purpose models, especially on tasks requiring nuanced legal understanding. Legal-BERT and Contracts-BERT establish new SOTAs on two of the three tasks, despite having 69% fewer parameters than the best-performing general-purpose LLM. We also identify CaseLaw-BERT and LexLM as strong additional baselines for contract understanding. Our results provide a holistic evaluation of legal-specific LLMs and will facilitate the development of more accurate contract understanding systems.",
    "source": "arXiv"
  },
  {
    "title": "Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs",
    "title_es": "Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs",
    "url": "https://arxiv.org/abs/2508.07850",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07850v1 Announce Type: new \nAbstract: In this paper, electron microscopy images of microstructures formed on Ge surfaces by ion beam irradiation were processed to extract topological features as skeleton graphs, which were then embedded using a graph convolutional network. The resulting embeddings were analyzed using principal component analysis, and cluster separability in the resulting PCA space was evaluated using the Davies-Bouldin index. The results indicate that variations in irradiation angle have a more significant impact on the morphological properties of Ge surfaces than variations in irradiation fluence.",
    "source": "arXiv"
  },
  {
    "title": "Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images",
    "title_es": "Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images",
    "url": "https://arxiv.org/abs/2508.07851",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07851v1 Announce Type: new \nAbstract: Minimally invasive surgery presents challenges such as dynamic tissue motion and a limited field of view. Accurate tissue tracking has the potential to support surgical guidance, improve safety by helping avoid damage to sensitive structures, and enable context-aware robotic assistance during complex procedures. In this work, we propose a novel method for markerless 3D tissue tracking by leveraging 2D Tracking Any Point (TAP) networks. Our method combines two CoTracker models, one for temporal tracking and one for stereo matching, to estimate 3D motion from stereo endoscopic images. We evaluate the system using a clinical laparoscopic setup and a robotic arm simulating tissue motion, with experiments conducted on a synthetic 3D-printed phantom and a chicken tissue phantom. Tracking on the chicken tissue phantom yielded more reliable results, with Euclidean distance errors as low as 1.1 mm at a velocity of 10 mm/s. These findings highlight the potential of TAP-based models for accurate, markerless 3D tracking in challenging surgical scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Vertex Features for Neural Global Illumination",
    "title_es": "Vertex Features for Neural Global Illumination",
    "url": "https://arxiv.org/abs/2508.07852",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07852v1 Announce Type: new \nAbstract: Recent research on learnable neural representations has been widely adopted in the field of 3D scene reconstruction and neural rendering applications. However, traditional feature grid representations often suffer from substantial memory footprint, posing a significant bottleneck for modern parallel computing hardware. In this paper, we present neural vertex features, a generalized formulation of learnable representation for neural rendering tasks involving explicit mesh surfaces. Instead of uniformly distributing neural features throughout 3D space, our method stores learnable features directly at mesh vertices, leveraging the underlying geometry as a compact and structured representation for neural processing. This not only optimizes memory efficiency, but also improves feature representation by aligning compactly with the surface using task-specific geometric priors. We validate our neural representation across diverse neural rendering tasks, with a specific emphasis on neural radiosity. Experimental results demonstrate that our method reduces memory consumption to only one-fifth (or even less) of grid-based representations, while maintaining comparable rendering quality and lowering inference overhead.",
    "source": "arXiv"
  },
  {
    "title": "Challenges in Mixed Reality in Assisting Adults with ADHD Symptoms",
    "title_es": "Challenges in Mixed Reality in Assisting Adults with ADHD Symptoms",
    "url": "https://arxiv.org/abs/2508.07854",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07854v1 Announce Type: new \nAbstract: In this position paper, we discuss symptoms of attention deficit hyperactivity disorder (ADHD) in adults, as well as available forms of treatment or assistance in the context of mixed reality. Mixed reality offers many potentials for assisting adults with symptoms commonly found in (but not limited to) ADHD, but the availability of mixed reality solutions is not only limited commercially, but also limited in terms of proof-of-concept prototypes. We discuss two major challenges with attention assistance using mixed reality solutions: the limited availability of adult-specific prototypes and studies, as well as the limited number of solutions that offer continuous intervention of ADHD-like symptoms that users can employ in their daily life.",
    "source": "arXiv"
  },
  {
    "title": "Checking Consistency of Event-driven Traces",
    "title_es": "Checking Consistency of Event-driven Traces",
    "url": "https://arxiv.org/abs/2508.07855",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07855v1 Announce Type: new \nAbstract: Event-driven programming is a popular paradigm where the flow of execution is controlled by two features: (1) shared memory and (2) sending and receiving of messages between multiple handler threads (just called handler). Each handler has a mailbox (modelled as a queue) for receiving messages, with the constraint that the handler processes its messages sequentially. Executions of messages by different handlers may be interleaved. A central problem in this setting is checking whether a candidate execution is consistent with the semantics of event-driven programs. In this paper, we propose an axiomatic semantics for eventdriven programs based on the standard notion of traces (also known as execution graphs). We prove the equivalence of axiomatic and operational semantics. This allows us to rephrase the consistency problem axiomatically, resulting in the event-driven consistency problem: checking whether a given trace is consistent. We analyze the computational complexity of this problem and show that it is NP-complete, even when the number of handler threads is bounded. We then identify a tractable fragment: in the absence of nested posting, where handlers do not post new messages while processing a message, consistency checking can be performed in polynomial time. Finally, we implement our approach in a prototype tool and report on experimental results on a wide range of benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Recommendation Is a Dish Better Served Warm",
    "title_es": "Recommendation Is a Dish Better Served Warm",
    "url": "https://arxiv.org/abs/2508.07856",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07856v1 Announce Type: new \nAbstract: In modern recommender systems, experimental settings typically include filtering out cold users and items based on a minimum interaction threshold. However, these thresholds are often chosen arbitrarily and vary widely across studies, leading to inconsistencies that can significantly affect the comparability and reliability of evaluation results. In this paper, we systematically explore the cold-start boundary by examining the criteria used to determine whether a user or an item should be considered cold. Our experiments incrementally vary the number of interactions for different items during training, and gradually update the length of user interaction histories during inference. We investigate the thresholds across several widely used datasets, commonly represented in recent papers from top-tier conferences, and on multiple established recommender baselines. Our findings show that inconsistent selection of cold-start thresholds can either result in the unnecessary removal of valuable data or lead to the misclassification of cold instances as warm, introducing more noise into the system.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models for Czech Aspect-Based Sentiment Analysis",
    "title_es": "Large Language Models for Czech Aspect-Based Sentiment Analysis",
    "url": "https://arxiv.org/abs/2508.07860",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07860v1 Announce Type: new \nAbstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that aims to identify sentiment toward specific aspects of an entity. While large language models (LLMs) have shown strong performance in various natural language processing (NLP) tasks, their capabilities for Czech ABSA remain largely unexplored. In this work, we conduct a comprehensive evaluation of 19 LLMs of varying sizes and architectures on Czech ABSA, comparing their performance in zero-shot, few-shot, and fine-tuning scenarios. Our results show that small domain-specific models fine-tuned for ABSA outperform general-purpose LLMs in zero-shot and few-shot settings, while fine-tuned LLMs achieve state-of-the-art results. We analyze how factors such as multilingualism, model size, and recency influence performance and present an error analysis highlighting key challenges, particularly in aspect term prediction. Our findings provide insights into the suitability of LLMs for Czech ABSA and offer guidance for future research in this area.",
    "source": "arXiv"
  },
  {
    "title": "Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model",
    "title_es": "Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model",
    "url": "https://arxiv.org/abs/2508.07863",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07863v1 Announce Type: new \nAbstract: Human motion generation has emerged as a critical technology with transformative potential for real-world applications. However, existing vision-language-motion models (VLMMs) face significant limitations that hinder their practical deployment. We identify controllability as a main bottleneck, manifesting in five key aspects: inadequate response to diverse human commands, limited pose initialization capabilities, poor performance on long-term sequences, insufficient handling of unseen scenarios, and lack of fine-grained control over individual body parts. To overcome these limitations, we present Being-M0.5, the first real-time, controllable VLMM that achieves state-of-the-art performance across multiple motion generation tasks. Our approach is built upon HuMo100M, the largest and most comprehensive human motion dataset to date, comprising over 5 million self-collected motion sequences, 100 million multi-task instructional instances, and detailed part-level annotations that address a critical gap in existing datasets. We introduce a novel part-aware residual quantization technique for motion tokenization that enables precise, granular control over individual body parts during generation. Extensive experimental validation demonstrates Being-M0.5's superior performance across diverse motion benchmarks, while comprehensive efficiency analysis confirms its real-time capabilities. Our contributions include design insights and detailed computational analysis to guide future development of practical motion generators. We believe that HuMo100M and Being-M0.5 represent significant advances that will accelerate the adoption of motion generation technologies in real-world applications. The project page is available at https://beingbeyond.github.io/Being-M0.5.",
    "source": "arXiv"
  },
  {
    "title": "Age of Information Minimization in Goal-Oriented Communication with Processing and Cost of Actuation Error Constraints",
    "title_es": "Age of Information Minimization in Goal-Oriented Communication with Processing and Cost of Actuation Error Constraints",
    "url": "https://arxiv.org/abs/2508.07865",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07865v1 Announce Type: new \nAbstract: We study a goal-oriented communication system in which a source monitors an environment that evolves as a discrete-time, two-state Markov chain. At each time slot, a controller decides whether to sample the environment and if so whether to transmit a raw or processed sample, to the controller. Processing improves transmission reliability over an unreliable wireless channel, but incurs an additional cost. The objective is to minimize the long-term average age of information (AoI), subject to constraints on the costs incurred at the source and the cost of actuation error (CAE), a semantic metric that assigns different penalties to different actuation errors. Although reducing AoI can potentially help reduce CAE, optimizing AoI alone is insufficient, as it overlooks the evolution of the underlying process. For instance, faster source dynamics lead to higher CAE for the same average AoI, and different AoI trajectories can result in markedly different CAE under identical average AoI. To address this, we propose a stationary randomized policy that achieves an average AoI within a bounded multiplicative factor of the optimal among all feasible policies. Extensive numerical experiments are conducted to characterize system behavior under a range of parameters. These results offer insights into the feasibility of the optimization problem, the structure of near-optimal actions, and the fundamental trade-offs between AoI, CAE, and the costs involved.",
    "source": "arXiv"
  },
  {
    "title": "Few-shot Cross-lingual Aspect-Based Sentiment Analysis with Sequence-to-Sequence Models",
    "title_es": "Few-shot Cross-lingual Aspect-Based Sentiment Analysis with Sequence-to-Sequence Models",
    "url": "https://arxiv.org/abs/2508.07866",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07866v1 Announce Type: new \nAbstract: Aspect-based sentiment analysis (ABSA) has received substantial attention in English, yet challenges remain for low-resource languages due to the scarcity of labelled data. Current cross-lingual ABSA approaches often rely on external translation tools and overlook the potential benefits of incorporating a small number of target language examples into training. In this paper, we evaluate the effect of adding few-shot target language examples to the training set across four ABSA tasks, six target languages, and two sequence-to-sequence models. We show that adding as few as ten target language examples significantly improves performance over zero-shot settings and achieves a similar effect to constrained decoding in reducing prediction errors. Furthermore, we demonstrate that combining 1,000 target language examples with English data can even surpass monolingual baselines. These findings offer practical insights for improving cross-lingual ABSA in low-resource and domain-specific settings, as obtaining ten high-quality annotated examples is both feasible and highly effective.",
    "source": "arXiv"
  },
  {
    "title": "CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning",
    "title_es": "CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning",
    "url": "https://arxiv.org/abs/2508.07871",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07871v1 Announce Type: new \nAbstract: Modern large vision-language models (LVLMs) convert each input image into a large set of tokens, far outnumbering the text tokens. Although this improves visual perception, it introduces severe image token redundancy. Because image tokens carry sparse information, many add little to reasoning, yet greatly increase inference cost. The emerging image token pruning methods tackle this issue by identifying the most important tokens and discarding the rest. These methods can raise efficiency with only modest performance loss. However, most of them only consider single-image tasks and overlook multimodal in-context learning (ICL), where redundancy is greater and efficiency is more critical. Redundant tokens weaken the advantage of multimodal ICL for rapid domain adaptation and cause unstable performance. Applying existing pruning methods in this setting leads to large accuracy drops, exposing a clear gap and the need for new techniques. Thus, we propose Contextually Adaptive Token Pruning (CATP), a training-free pruning method targeted at multimodal ICL. CATP consists of two stages that perform progressive pruning to fully account for the complex cross-modal interactions in the input sequence. After removing 77.8\\% of the image tokens, CATP produces an average performance gain of 0.6\\% over the vanilla model on four LVLMs and eight benchmarks, exceeding all baselines remarkably. Meanwhile, it effectively improves efficiency by achieving an average reduction of 10.78\\% in inference latency. CATP enhances the practical value of multimodal ICL and lays the groundwork for future progress in interleaved image-text scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Unequal Uncertainty: Rethinking Algorithmic Interventions for Mitigating Discrimination from AI",
    "title_es": "Unequal Uncertainty: Rethinking Algorithmic Interventions for Mitigating Discrimination from AI",
    "url": "https://arxiv.org/abs/2508.07872",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07872v1 Announce Type: new \nAbstract: Uncertainty in artificial intelligence (AI) predictions poses urgent legal and ethical challenges for AI-assisted decision-making. We examine two algorithmic interventions that act as guardrails for human-AI collaboration: selective abstention, which withholds high-uncertainty predictions from human decision-makers, and selective friction, which delivers those predictions together with salient warnings or disclosures that slow the decision process. Research has shown that selective abstention based on uncertainty can inadvertently exacerbate disparities and disadvantage under-represented groups that disproportionately receive uncertain predictions. In this paper, we provide the first integrated socio-technical and legal analysis of uncertainty-based algorithmic interventions. Through two case studies, AI-assisted consumer credit decisions and AI-assisted content moderation, we demonstrate how the seemingly neutral use of uncertainty thresholds can trigger discriminatory impacts. We argue that, although both interventions pose risks of unlawful discrimination under UK law, selective frictions offer a promising pathway toward fairer and more accountable AI-assisted decision-making by preserving transparency and encouraging more cautious human judgment.",
    "source": "arXiv"
  },
  {
    "title": "EFU: Enforcing Federated Unlearning via Functional Encryption",
    "title_es": "EFU: Enforcing Federated Unlearning via Functional Encryption",
    "url": "https://arxiv.org/abs/2508.07873",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07873v1 Announce Type: new \nAbstract: Federated unlearning (FU) algorithms allow clients in federated settings to exercise their ''right to be forgotten'' by removing the influence of their data from a collaboratively trained model. Existing FU methods maintain data privacy by performing unlearning locally on the client-side and sending targeted updates to the server without exposing forgotten data; yet they often rely on server-side cooperation, revealing the client's intent and identity without enforcement guarantees - compromising autonomy and unlearning privacy. In this work, we propose EFU (Enforced Federated Unlearning), a cryptographically enforced FU framework that enables clients to initiate unlearning while concealing its occurrence from the server. Specifically, EFU leverages functional encryption to bind encrypted updates to specific aggregation functions, ensuring the server can neither perform unauthorized computations nor detect or skip unlearning requests. To further mask behavioral and parameter shifts in the aggregated model, we incorporate auxiliary unlearning losses based on adversarial examples and parameter importance regularization. Extensive experiments show that EFU achieves near-random accuracy on forgotten data while maintaining performance comparable to full retraining across datasets and neural architectures - all while concealing unlearning intent from the server. Furthermore, we demonstrate that EFU is agnostic to the underlying unlearning algorithm, enabling secure, function-hiding, and verifiable unlearning for any client-side FU mechanism that issues targeted updates.",
    "source": "arXiv"
  },
  {
    "title": "Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images",
    "title_es": "Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images",
    "url": "https://arxiv.org/abs/2508.07875",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07875v1 Announce Type: new \nAbstract: Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer, and early, accurate diagnosis is critical to improving patient survival rates by guiding treatment decisions. Combining medical expertise with artificial intelligence (AI) holds significant promise for enhancing the precision and efficiency of IDC detection. In this work, we propose a human-in-the-loop (HITL) deep learning system designed to detect IDC in histopathology images. The system begins with an initial diagnosis provided by a high-performance EfficientNetV2S model, offering feedback from AI to the human expert. Medical professionals then review the AI-generated results, correct any misclassified images, and integrate the revised labels into the training dataset, forming a feedback loop from the human back to the AI. This iterative process refines the model's performance over time. The EfficientNetV2S model itself achieves state-of-the-art performance compared to existing methods in the literature, with an overall accuracy of 93.65\\%. Incorporating the human-in-the-loop system further improves the model's accuracy using four experimental groups with misclassified images. These results demonstrate the potential of this collaborative approach to enhance AI performance in diagnostic systems. This work contributes to advancing automated, efficient, and highly accurate methods for IDC detection through human-AI collaboration, offering a promising direction for future AI-assisted medical diagnostics.",
    "source": "arXiv"
  },
  {
    "title": "Selective Contrastive Learning for Weakly Supervised Affordance Grounding",
    "title_es": "Selective Contrastive Learning for Weakly Supervised Affordance Grounding",
    "url": "https://arxiv.org/abs/2508.07877",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07877v1 Announce Type: new \nAbstract: Facilitating an entity's interaction with objects requires accurately identifying parts that afford specific actions. Weakly supervised affordance grounding (WSAG) seeks to imitate human learning from third-person demonstrations, where humans intuitively grasp functional parts without needing pixel-level annotations. To achieve this, grounding is typically learned using a shared classifier across images from different perspectives, along with distillation strategies incorporating part discovery process. However, since affordance-relevant parts are not always easily distinguishable, models primarily rely on classification, often focusing on common class-specific patterns that are unrelated to affordance. To address this limitation, we move beyond isolated part-level learning by introducing selective prototypical and pixel contrastive objectives that adaptively learn affordance-relevant cues at both the part and object levels, depending on the granularity of the available information. Initially, we find the action-associated objects in both egocentric (object-focused) and exocentric (third-person example) images by leveraging CLIP. Then, by cross-referencing the discovered objects of complementary views, we excavate the precise part-level affordance clues in each perspective. By consistently learning to distinguish affordance-relevant regions from affordance-irrelevant background context, our approach effectively shifts activation from irrelevant areas toward meaningful affordance cues. Experimental results demonstrate the effectiveness of our method. Codes are available at github.com/hynnsk/SelectiveCL.",
    "source": "arXiv"
  },
  {
    "title": "TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal",
    "title_es": "TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal",
    "url": "https://arxiv.org/abs/2508.07878",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07878v1 Announce Type: new \nAbstract: Image restoration under adverse weather conditions has been extensively explored, leading to numerous high-performance methods. In particular, recent advances in All-in-One approaches have shown impressive results by training on multi-task image restoration datasets. However, most of these methods rely on dedicated network modules or parameters for each specific degradation type, resulting in a significant parameter overhead. Moreover, the relatedness across different restoration tasks is often overlooked. In light of these issues, we propose a parameter-efficient All-in-One image restoration framework that leverages task-aware enhanced prompts to tackle various adverse weather degradations.Specifically, we adopt a two-stage training paradigm consisting of a pretraining phase and a prompt-tuning phase to mitigate parameter conflicts across tasks. We first employ supervised learning to acquire general restoration knowledge, and then adapt the model to handle specific degradation via trainable soft prompts. Crucially, we enhance these task-specific prompts in a task-aware manner. We apply low-rank decomposition to these prompts to capture both task-general and task-specific characteristics, and impose contrastive constraints to better align them with the actual inter-task relatedness. These enhanced prompts not only improve the parameter efficiency of the restoration model but also enable more accurate task modeling, as evidenced by t-SNE analysis. Experimental results on different restoration tasks demonstrate that the proposed method achieves superior performance with only 2.75M parameters.",
    "source": "arXiv"
  },
  {
    "title": "Multi-agent systems for chemical engineering: A review and perspective",
    "title_es": "Multi-agent systems for chemical engineering: A review and perspective",
    "url": "https://arxiv.org/abs/2508.07880",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07880v1 Announce Type: new \nAbstract: Large language model (LLM)-based multi-agent systems (MASs) are a recent but rapidly evolving technology with the potential to transform chemical engineering by decomposing complex workflows into teams of collaborative agents with specialized knowledge and tools. This review surveys the state-of-the-art of MAS within chemical engineering. While early studies demonstrate promising results, scientific challenges remain, including the design of tailored architectures, integration of heterogeneous data modalities, development of foundation models with domain-specific modalities, and strategies for ensuring transparency, safety, and environmental impact. As a young but fast-moving field, MASs offer exciting opportunities to rethink chemical engineering workflows.",
    "source": "arXiv"
  },
  {
    "title": "Adopting Road-Weather Open Data in Route Recommendation Engine",
    "title_es": "Adopting Road-Weather Open Data in Route Recommendation Engine",
    "url": "https://arxiv.org/abs/2508.07881",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07881v1 Announce Type: new \nAbstract: Digitraffic, Finland's open road data interface, provides access to nationwide road sensors with more than 2,300 real-time attributes from 1,814 stations. However, efficiently utilizing such a versatile data API for a practical application requires a deeper understanding of the data qualities, preprocessing phases, and machine learning tools. This paper discusses the challenges of large-scale road weather and traffic data. We go through the road-weather-related attributes from DigiTraffic as a practical example of processes required to work with such a dataset. In addition, we provide a methodology for efficient data utilization for the target application, a personalized road recommendation engine based on a simple routing application. We validate our solution based on real-world data, showing we can efficiently identify and recommend personalized routes for three different driver profiles.",
    "source": "arXiv"
  },
  {
    "title": "Scalable and Energy-Efficient Predictive Data Collection in Wireless Sensor Networks with Constructive Interference",
    "title_es": "Scalable and Energy-Efficient Predictive Data Collection in Wireless Sensor Networks with Constructive Interference",
    "url": "https://arxiv.org/abs/2508.07882",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07882v1 Announce Type: new \nAbstract: A new class of Wireless Sensor Network has emerged whereby multiple nodes transmit data simultaneously, exploiting constructive interference to enable data collection frameworks with low energy usage and latency. This paper presents STAIR (Spatio-Temporal Activation for Intelligent Relaying), a scalable, resilient framework for Wireless Sensor Networks that leverages constructive interference and operates effectively under stringent resource constraints. Using constructive interference requires all nodes to transmit the same packet at the same time, thus, only one source node can send data per time slot. STAIR uses coarse-grained topology information to flood a selected subset of the network, relaying sensor readings from individual nodes during their allocated time slots. A submodular optimisation algorithm with proven quality bounds determines near-optimal sensor activation locations and times, aiming to minimise the sum of mean squared prediction errors from a multiple multivariate linear regression model, which is used to estimate values at unselected locations and times. This framework has been extensively validated on a real-world testbed deployment.",
    "source": "arXiv"
  },
  {
    "title": "Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning",
    "title_es": "Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning",
    "url": "https://arxiv.org/abs/2508.07885",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07885v1 Announce Type: new \nAbstract: This paper introduces an advanced AI-driven perception system for autonomous quadcopter navigation in GPS-denied indoor environments. The proposed framework leverages cloud computing to offload computationally intensive tasks and incorporates a custom-designed printed circuit board (PCB) for efficient sensor data acquisition, enabling robust navigation in confined spaces. The system integrates YOLOv11 for object detection, Depth Anything V2 for monocular depth estimation, a PCB equipped with Time-of-Flight (ToF) sensors and an Inertial Measurement Unit (IMU), and a cloud-based Large Language Model (LLM) for context-aware decision-making. A virtual safety envelope, enforced by calibrated sensor offsets, ensures collision avoidance, while a multithreaded architecture achieves low-latency processing. Enhanced spatial awareness is facilitated by 3D bounding box estimation with Kalman filtering. Experimental results in an indoor testbed demonstrate strong performance, with object detection achieving a mean Average Precision (mAP50) of 0.6, depth estimation Mean Absolute Error (MAE) of 7.2 cm, only 16 safety envelope breaches across 42 trials over approximately 11 minutes, and end-to-end system latency below 1 second. This cloud-supported, high-intelligence framework serves as an auxiliary perception and navigation system, complementing state-of-the-art drone autonomy for GPS-denied confined spaces.",
    "source": "arXiv"
  },
  {
    "title": "Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant",
    "title_es": "Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant",
    "url": "https://arxiv.org/abs/2508.07887",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07887v1 Announce Type: new \nAbstract: Simulators have revolutionized scientific practice across the natural sciences. By generating data that reliably approximate real-world phenomena, they enable scientists to accelerate hypothesis testing and optimize experimental designs. This is perhaps best illustrated by AlphaFold, a Nobel-prize winning simulator in chemistry that predicts protein structures from amino acid sequences, enabling rapid prototyping of molecular interactions, drug targets, and protein functions. In the behavioral sciences, a reliable participant simulator - a system capable of producing human-like behavior across cognitive tasks - would represent a similarly transformative advance. Recently, Binz et al. introduced Centaur, a large language model (LLM) fine-tuned on human data from 160 experiments, proposing its use not only as a model of cognition but also as a participant simulator for \"in silico prototyping of experimental studies\", e.g., to advance automated cognitive science. Here, we review the core criteria for a participant simulator and assess how well Centaur meets them. Although Centaur demonstrates strong predictive accuracy, its generative behavior - a critical criterion for a participant simulator - systematically diverges from human data. This suggests that, while Centaur is a significant step toward predicting human behavior, it does not yet meet the standards of a reliable participant simulator or an accurate model of cognition.",
    "source": "arXiv"
  },
  {
    "title": "NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction",
    "title_es": "NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction",
    "url": "https://arxiv.org/abs/2508.07897",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07897v1 Announce Type: new \nAbstract: Computer vision-based technologies significantly enhance surgical automation by advancing tool tracking, detection, and localization. However, Current data-driven approaches are data-voracious, requiring large, high-quality labeled image datasets, which limits their application in surgical data science. Our Work introduces a novel dynamic Gaussian Splatting technique to address the data scarcity in surgical image datasets. We propose a dynamic Gaussian model to represent dynamic surgical scenes, enabling the rendering of surgical instruments from unseen viewpoints and deformations with real tissue backgrounds. We utilize a dynamic training adjustment strategy to address challenges posed by poorly calibrated camera poses from real-world scenarios. Additionally, we propose a method based on dynamic Gaussians for automatically generating annotations for our synthetic data. For evaluation, we constructed a new dataset featuring seven scenes with 14,000 frames of tool and camera motion and tool jaw articulation, with a background of an ex-vivo porcine model. Using this dataset, we synthetically replicate the scene deformation from the ground truth data, allowing direct comparisons of synthetic image quality. Experimental results illustrate that our method generates photo-realistic labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio (29.87). We further evaluate the performance of medical-specific neural networks trained on real and synthetic images using an unseen real-world image dataset. Our results show that the performance of models trained on synthetic images generated by the proposed method outperforms those trained with state-of-the-art standard data augmentation by 10%, leading to an overall improvement in model performances by nearly 15%.",
    "source": "arXiv"
  },
  {
    "title": "Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation",
    "title_es": "Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation",
    "url": "https://arxiv.org/abs/2508.07901",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07901v1 Announce Type: new \nAbstract: Generating high-fidelity human videos that match user-specified identities is important yet challenging in the field of generative AI. Existing methods often rely on an excessive number of training parameters and lack compatibility with other AIGC tools. In this paper, we propose Stand-In, a lightweight and plug-and-play framework for identity preservation in video generation. Specifically, we introduce a conditional image branch into the pre-trained video generation model. Identity control is achieved through restricted self-attentions with conditional position mapping, and can be learned quickly with only 2000 pairs. Despite incorporating and training just $\\sim$1\\% additional parameters, our framework achieves excellent results in video quality and identity preservation, outperforming other full-parameter training methods. Moreover, our framework can be seamlessly integrated for other tasks, such as subject-driven video generation, pose-referenced video generation, stylization, and face swapping.",
    "source": "arXiv"
  },
  {
    "title": "Tailored Emotional LLM-Supporter: Enhancing Cultural Sensitivity",
    "title_es": "Tailored Emotional LLM-Supporter: Enhancing Cultural Sensitivity",
    "url": "https://arxiv.org/abs/2508.07902",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07902v1 Announce Type: new \nAbstract: Large language models (LLMs) show promise in offering emotional support and generating empathetic responses for individuals in distress, but their ability to deliver culturally sensitive support remains underexplored due to lack of resources. In this work, we introduce CultureCare, the first dataset designed for this task, spanning four cultures and including 1729 distress messages, 1523 cultural signals, and 1041 support strategies with fine-grained emotional and cultural annotations. Leveraging CultureCare, we (i) develop and test four adaptation strategies for guiding three state-of-the-art LLMs toward culturally sensitive responses; (ii) conduct comprehensive evaluations using LLM judges, in-culture human annotators, and clinical psychologists; (iii) show that adapted LLMs outperform anonymous online peer responses, and that simple cultural role-play is insufficient for cultural sensitivity; and (iv) explore the application of LLMs in clinical training, where experts highlight their potential in fostering cultural competence in future therapists.",
    "source": "arXiv"
  },
  {
    "title": "Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models",
    "title_es": "Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models",
    "url": "https://arxiv.org/abs/2508.07903",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07903v1 Announce Type: new \nAbstract: Despite significant progress in generative modelling, existing diffusion models often struggle to produce anatomically precise female pelvic images, limiting their application in gynaecological imaging, where data scarcity and patient privacy concerns are critical. To overcome these barriers, we introduce a novel diffusion-based framework for uterine MRI synthesis, integrating both unconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs) and Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates anatomically coherent, high fidelity synthetic images that closely mimic real scans and provide valuable resources for training robust diagnostic models. We evaluate generative quality using advanced perceptual and distributional metrics, benchmarking against standard reconstruction methods, and demonstrate substantial gains in diagnostic accuracy on a key classification task. A blinded expert evaluation further validates the clinical realism of our synthetic images. We release our models with privacy safeguards and a comprehensive synthetic uterine MRI dataset to support reproducible research and advance equitable AI in gynaecology.",
    "source": "arXiv"
  },
  {
    "title": "CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality",
    "title_es": "CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality",
    "url": "https://arxiv.org/abs/2508.07904",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07904v1 Announce Type: new \nAbstract: Handwritten text recognition for historical documents remains challenging due to handwriting variability, degraded sources, and limited layout-aware annotations. In this work, we address annotation errors - particularly hyphenation issues - in the Bullinger correspondence, a large 16th-century letter collection. We introduce a self-training method based on a CTC alignment algorithm that matches full transcriptions to text line images using dynamic programming and model output probabilities trained with the CTC loss. Our approach improves performance (e.g., by 1.1 percentage points CER with PyLaia) and increases alignment accuracy. Interestingly, we find that weaker models yield more accurate alignments, enabling an iterative training strategy. We release a new manually corrected subset of 100 pages from the Bullinger dataset, along with our code and benchmarks. Our approach can be applied iteratively to further improve the CER as well as the alignment quality for text recognition pipelines. Code and data are available via https://github.com/andreas-fischer-unifr/nntp.",
    "source": "arXiv"
  },
  {
    "title": "Generative Video Matting",
    "title_es": "Generative Video Matting",
    "url": "https://arxiv.org/abs/2508.07905",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07905v1 Announce Type: new \nAbstract: Video matting has traditionally been limited by the lack of high-quality ground-truth data. Most existing video matting datasets provide only human-annotated imperfect alpha and foreground annotations, which must be composited to background images or videos during the training stage. Thus, the generalization capability of previous methods in real-world scenarios is typically poor. In this work, we propose to solve the problem from two perspectives. First, we emphasize the importance of large-scale pre-training by pursuing diverse synthetic and pseudo-labeled segmentation datasets. We also develop a scalable synthetic data generation pipeline that can render diverse human bodies and fine-grained hairs, yielding around 200 video clips with a 3-second duration for fine-tuning. Second, we introduce a novel video matting approach that can effectively leverage the rich priors from pre-trained video diffusion models. This architecture offers two key advantages. First, strong priors play a critical role in bridging the domain gap between synthetic and real-world scenes. Second, unlike most existing methods that process video matting frame-by-frame and use an independent decoder to aggregate temporal information, our model is inherently designed for video, ensuring strong temporal consistency. We provide a comprehensive quantitative evaluation across three benchmark datasets, demonstrating our approach's superior performance, and present comprehensive qualitative results in diverse real-world scenes, illustrating the strong generalization capability of our method. The code is available at https://github.com/aim-uofa/GVM.",
    "source": "arXiv"
  },
  {
    "title": "Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction",
    "title_es": "Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction",
    "url": "https://arxiv.org/abs/2508.07908",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07908v1 Announce Type: new \nAbstract: Reconstructing dense geometry for dynamic scenes from a monocular video is a critical yet challenging task. Recent memory-based methods enable efficient online reconstruction, but they fundamentally suffer from a Memory Demand Dilemma: The memory representation faces an inherent conflict between the long-term stability required for static structures and the rapid, high-fidelity detail retention needed for dynamic motion. This conflict forces existing methods into a compromise, leading to either geometric drift in static structures or blurred, inaccurate reconstructions of dynamic objects. To address this dilemma, we propose Mem4D, a novel framework that decouples the modeling of static geometry and dynamic motion. Guided by this insight, we design a dual-memory architecture: 1) The Transient Dynamics Memory (TDM) focuses on capturing high-frequency motion details from recent frames, enabling accurate and fine-grained modeling of dynamic content; 2) The Persistent Structure Memory (PSM) compresses and preserves long-term spatial information, ensuring global consistency and drift-free reconstruction for static elements. By alternating queries to these specialized memories, Mem4D simultaneously maintains static geometry with global consistency and reconstructs dynamic elements with high fidelity. Experiments on challenging benchmarks demonstrate that our method achieves state-of-the-art or competitive performance while maintaining high efficiency. Codes will be publicly available.",
    "source": "arXiv"
  },
  {
    "title": "MolmoAct: Action Reasoning Models that can Reason in Space",
    "title_es": "MolmoAct: Action Reasoning Models that can Reason in Space",
    "url": "https://arxiv.org/abs/2508.07917",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07917v1 Announce Type: new \nAbstract: Reasoning is central to purposeful action, yet most robotic foundation models map perception and instructions directly to control, which limits adaptability, generalization, and semantic grounding. We introduce Action Reasoning Models (ARMs), a class of vision-language-action models that integrate perception, planning, and control through a structured three-stage pipeline. Our model, MolmoAct, encodes observations and instructions into depth-aware perception tokens, generates mid-level spatial plans as editable trajectory traces, and predicts precise low-level actions, enabling explainable and steerable behavior. MolmoAct-7B-D achieves strong performance across simulation and real-world settings: 70.5% zero-shot accuracy on SimplerEnv Visual Matching tasks, surpassing closed-source Pi-0 and GR00T N1; 86.6% average success on LIBERO, including an additional 6.3% gain over ThinkAct on long-horizon tasks; and in real-world fine-tuning, an additional 10% (single-arm) and an additional 22.7% (bimanual) task progression over Pi-0-FAST. It also outperforms baselines by an additional 23.3% on out-of-distribution generalization and achieves top human-preference scores for open-ended instruction following and trajectory steering. Furthermore, we release, for the first time, the MolmoAct Dataset -- a mid-training robot dataset comprising over 10,000 high quality robot trajectories across diverse scenarios and tasks. Training with this dataset yields an average 5.5% improvement in general performance over the base model. We release all model weights, training code, our collected dataset, and our action reasoning dataset, establishing MolmoAct as both a state-of-the-art robotics foundation model and an open blueprint for building ARMs that transform perception into purposeful action through structured reasoning. Blogpost: https://allenai.org/blog/molmoact",
    "source": "arXiv"
  },
  {
    "title": "RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering",
    "title_es": "RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering",
    "url": "https://arxiv.org/abs/2508.07918",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07918v1 Announce Type: new \nAbstract: Visual Question Answering (VQA) in remote sensing (RS) is pivotal for interpreting Earth observation data. However, existing RS VQA datasets are constrained by limitations in annotation richness, question diversity, and the assessment of specific reasoning capabilities. This paper introduces RSVLM-QA dataset, a new large-scale, content-rich VQA dataset for the RS domain. RSVLM-QA is constructed by integrating data from several prominent RS segmentation and detection datasets: WHU, LoveDA, INRIA, and iSAID. We employ an innovative dual-track annotation generation pipeline. Firstly, we leverage Large Language Models (LLMs), specifically GPT-4.1, with meticulously designed prompts to automatically generate a suite of detailed annotations including image captions, spatial relations, and semantic tags, alongside complex caption-based VQA pairs. Secondly, to address the challenging task of object counting in RS imagery, we have developed a specialized automated process that extracts object counts directly from the original segmentation data; GPT-4.1 then formulates natural language answers from these counts, which are paired with preset question templates to create counting QA pairs. RSVLM-QA comprises 13,820 images and 162,373 VQA pairs, featuring extensive annotations and diverse question types. We provide a detailed statistical analysis of the dataset and a comparison with existing RS VQA benchmarks, highlighting the superior depth and breadth of RSVLM-QA's annotations. Furthermore, we conduct benchmark experiments on Six mainstream Vision Language Models (VLMs), demonstrating that RSVLM-QA effectively evaluates and challenges the understanding and reasoning abilities of current VLMs in the RS domain. We believe RSVLM-QA will serve as a pivotal resource for the RS VQA and VLM research communities, poised to catalyze advancements in the field.",
    "source": "arXiv"
  },
  {
    "title": "Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection",
    "title_es": "Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.07923",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07923v1 Announce Type: new \nAbstract: Generative AI holds great potentials to automate and enhance data synthesis in nuclear medicine. However, the high-stakes nature of biomedical imaging necessitates robust mechanisms to detect and manage unexpected or erroneous model behavior. We introduce development and implementation of a hybrid anomaly detection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems. Two applications are demonstrated: Pose2Xray, which generates synthetic X-rays from photographic mouse images, and DosimetrEYE, which estimates 3D radiation dose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD) enhances reliability, reduces manual oversight, and supports real-time quality control. This approach strengthens the industrial viability of GenAI in preclinical settings by increasing robustness, scalability, and regulatory compliance.",
    "source": "arXiv"
  },
  {
    "title": "TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding",
    "title_es": "TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding",
    "url": "https://arxiv.org/abs/2508.07925",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07925v1 Announce Type: new \nAbstract: Video Temporal Grounding (VTG) aims to extract relevant video segments based on a given natural language query. Recently, zero-shot VTG methods have gained attention by leveraging pretrained vision-language models (VLMs) to localize target moments without additional training. However, existing approaches suffer from semantic fragmentation, where temporally continuous frames sharing the same semantics are split across multiple segments. When segments are fragmented, it becomes difficult to predict an accurate target moment that aligns with the text query. Also, they rely on skewed similarity distributions for localization, making it difficult to select the optimal segment. Furthermore, they heavily depend on the use of LLMs which require expensive inferences. To address these limitations, we propose a \\textit{TAG}, a simple yet effective Temporal-Aware approach for zero-shot video temporal Grounding, which incorporates temporal pooling, temporal coherence clustering, and similarity adjustment. Our proposed method effectively captures the temporal context of videos and addresses distorted similarity distributions without training. Our approach achieves state-of-the-art results on Charades-STA and ActivityNet Captions benchmark datasets without rely on LLMs. Our code is available at https://github.com/Nuetee/TAG",
    "source": "arXiv"
  },
  {
    "title": "Score Augmentation for Diffusion Models",
    "title_es": "Score Augmentation for Diffusion Models",
    "url": "https://arxiv.org/abs/2508.07926",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07926v1 Announce Type: new \nAbstract: Diffusion models have achieved remarkable success in generative modeling. However, this study confirms the existence of overfitting in diffusion model training, particularly in data-limited regimes. To address this challenge, we propose Score Augmentation (ScoreAug), a novel data augmentation framework specifically designed for diffusion models. Unlike conventional augmentation approaches that operate on clean data, ScoreAug applies transformations to noisy data, aligning with the inherent denoising mechanism of diffusion. Crucially, ScoreAug further requires the denoiser to predict the augmentation of the original target. This design establishes an equivariant learning objective, enabling the denoiser to learn scores across varied denoising spaces, thereby realizing what we term score augmentation. We also theoretically analyze the relationship between scores in different spaces under general transformations. In experiments, we extensively validate ScoreAug on multiple benchmarks including CIFAR-10, FFHQ, AFHQv2, and ImageNet, with results demonstrating significant performance improvements over baselines. Notably, ScoreAug effectively mitigates overfitting across diverse scenarios, such as varying data scales and model capacities, while exhibiting stable convergence properties. Another advantage of ScoreAug over standard data augmentation lies in its ability to circumvent data leakage issues under certain conditions. Furthermore, we show that ScoreAug can be synergistically combined with traditional data augmentation techniques to achieve additional performance gains.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting",
    "title_es": "Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting",
    "url": "https://arxiv.org/abs/2508.07927",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07927v1 Announce Type: new \nAbstract: Time series forecasting poses significant challenges in non-stationary environments where underlying patterns evolve over time. In this work, we propose a novel framework that enhances deep neural network (DNN) performance by leveraging specialized model adaptation and selection. Initially, a base DNN is trained offline on historical time series data. A reserved validation subset is then segmented to extract and cluster the most dominant patterns within the series, thereby identifying distinct regimes. For each identified cluster, the base DNN is fine-tuned to produce a specialized version that captures unique pattern characteristics. At inference, the most recent input is matched against the cluster centroids, and the corresponding fine-tuned version is deployed based on the closest similarity measure. Additionally, our approach integrates a concept drift detection mechanism to identify and adapt to emerging patterns caused by non-stationary behavior. The proposed framework is generalizable across various DNN architectures and has demonstrated significant performance gains on both traditional DNNs and recent advanced architectures implemented in the GluonTS library.",
    "source": "arXiv"
  },
  {
    "title": "\\(X\\)-evolve: Solution space evolution powered by large language models",
    "title_es": "\\(X\\)-evolve: Solution space evolution powered by large language models",
    "url": "https://arxiv.org/abs/2508.07932",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07932v1 Announce Type: new \nAbstract: While combining large language models (LLMs) with evolutionary algorithms (EAs) shows promise for solving complex optimization problems, current approaches typically evolve individual solutions, often incurring high LLM call costs. We introduce \\(X\\)-evolve, a paradigm-shifting method that instead evolves solution spaces \\(X\\) (sets of individual solutions) - subsets of the overall search space \\(S\\). In \\(X\\)-evolve, LLMs generate tunable programs wherein certain code snippets, designated as parameters, define a tunable solution space. A score-based search algorithm then efficiently explores this parametrically defined space, guided by feedback from objective function scores. This strategy enables broader and more efficient exploration, which can potentially accelerate convergence at a much lower search cost, requiring up to two orders of magnitude fewer LLM calls than prior leading methods. We demonstrate \\(X\\)-evolve's efficacy across three distinct hard optimization problems. For the cap set problem, we discover a larger partial admissible set, establishing a new tighter asymptotic lower bound for the cap set constant (\\(C \\ge 2.2203\\)). In information theory, we uncover a larger independent set for the 15-vertex cycle graph (\\(\\mathcal{C}_{15}^{\\boxtimes 5}\\), size 19,946), thereby raising the known lower bound on its Shannon capacity. Furthermore, for the NP-hard online bin packing problem, we generate heuristics that consistently outperform standard strategies across established benchmarks. By evolving solution spaces, our method considerably improves search effectiveness, making it possible to tackle high-dimensional problems that were previously computationally prohibitive.",
    "source": "arXiv"
  },
  {
    "title": "Performance Evaluation of Brokerless Messaging Libraries",
    "title_es": "Performance Evaluation of Brokerless Messaging Libraries",
    "url": "https://arxiv.org/abs/2508.07934",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07934v1 Announce Type: new \nAbstract: Messaging systems are essential for efficiently transferring large volumes of data, ensuring rapid response times and high-throughput communication. The state-of-the-art on messaging systems mainly focuses on the performance evaluation of brokered messaging systems, which use an intermediate broker to guarantee reliability and quality of service. However, over the past decade, brokerless messaging systems have emerged, eliminating the single point of failure and trading off reliability guarantees for higher performance. Still, the state-of-the-art on evaluating the performance of brokerless systems is scarce. In this work, we solely focus on brokerless messaging systems. First, we perform a qualitative analysis of several possible candidates, to find the most promising ones. We then design and implement an extensive open-source benchmarking suite to systematically and fairly evaluate the performance of the chosen libraries, namely, ZeroMQ, NanoMsg, and NanoMsg-Next-Generation (NNG). We evaluate these libraries considering different metrics and workload conditions, and provide useful insights into their limitations. Our analysis enables practitioners to select the most suitable library for their requirements.",
    "source": "arXiv"
  },
  {
    "title": "SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows",
    "title_es": "SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows",
    "url": "https://arxiv.org/abs/2508.07935",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07935v1 Announce Type: new \nAbstract: Large Language Model (LLM) agentic systems are software systems powered by LLMs that autonomously reason, plan, and execute multi-step workflows to achieve human goals, rather than merely executing predefined steps. During execution, these workflows frequently encounter exceptions. Existing exception handling solutions often treat exceptions superficially, failing to trace execution-phase exceptions to their reasoning-phase root causes. Furthermore, their recovery logic is brittle, lacking structured escalation pathways when initial attempts fail. To tackle these challenges, we first present a comprehensive taxonomy of 36 exception types across 12 agent artifacts. Building on this, we propose SHIELDA (Structured Handling of Exceptions in LLM-Driven Agentic Workflows), a modular runtime exception handling framework for LLM agentic workflows. SHIELDA uses an exception classifier to select a predefined exception handling pattern from a handling pattern registry. These patterns are then executed via a structured handling executor, comprising local handling, flow control, and state recovery, to enable phase-aware recovery by linking exceptions to their root causes and facilitating composable strategies. We validate SHIELDA's effectiveness through a case study on the AutoPR agent, demonstrating effective, cross-phase recovery from a reasoning-induced exception.",
    "source": "arXiv"
  },
  {
    "title": "Challenges and opportunities in portraying emotion in generated sign language",
    "title_es": "Challenges and opportunities in portraying emotion in generated sign language",
    "url": "https://arxiv.org/abs/2508.07937",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07937v1 Announce Type: new \nAbstract: Non-manual signals in sign languages continue to be a challenge for signing avatars. More specifically, emotional content has been difficult to incorporate because of a lack of a standard method of specifying the avatar's emotional state. This paper explores the application of an intuitive two-parameter representation for emotive non-manual signals to the Paula signing avatar that shows promise for facilitating the linguistic specification of emotional facial expressions in a more coherent manner than previous methods. Users can apply these parameters to control Paula's emotional expressions through a textual representation called the EASIER notation. The representation can allow avatars to express more nuanced emotional states using two numerical parameters. It also has the potential to enable more consistent specification of emotional non-manual signals in linguistic annotations which drive signing avatars.",
    "source": "arXiv"
  },
  {
    "title": "Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots",
    "title_es": "Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots",
    "url": "https://arxiv.org/abs/2508.07941",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07941v1 Announce Type: new \nAbstract: This article proposes a collision risk anticipation method based on short-term prediction of the agents position. A Long Short-Term Memory (LSTM) model, trained on past trajectories, is used to estimate the next position of each robot. This prediction allows us to define an anticipated collision risk by dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent. The approach is tested in a constrained environment, where two robots move without communication or identifiers. Despite a limited sampling frequency (1 Hz), the results show a significant decrease of the collisions number and a stability improvement. The proposed method, which is computationally inexpensive, appears particularly attractive for implementation on embedded systems.",
    "source": "arXiv"
  },
  {
    "title": "SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis",
    "title_es": "SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis",
    "url": "https://arxiv.org/abs/2508.07944",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07944v1 Announce Type: new \nAbstract: Despite growing attention to deepfake speech detection, the aspects of bias and fairness remain underexplored in the speech domain. To address this gap, we introduce the Speaker Characteristics Deepfake (SCDF) dataset: a novel, richly annotated resource enabling systematic evaluation of demographic biases in deepfake speech detection. SCDF contains over 237,000 utterances in a balanced representation of both male and female speakers spanning five languages and a wide age range. We evaluate several state-of-the-art detectors and show that speaker characteristics significantly influence detection performance, revealing disparities across sex, language, age, and synthesizer type. These findings highlight the need for bias-aware development and provide a foundation for building non-discriminatory deepfake detection systems aligned with ethical and regulatory standards.",
    "source": "arXiv"
  },
  {
    "title": "PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF",
    "title_es": "PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF",
    "url": "https://arxiv.org/abs/2508.07945",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07945v1 Announce Type: new \nAbstract: We consider the problem of learning a common representation for dexterous manipulation across manipulators of different morphologies. To this end, we propose PCHands, a novel approach for extracting hand postural synergies from a large set of manipulators. We define a simplified and unified description format based on anchor positions for manipulators ranging from 2-finger grippers to 5-finger anthropomorphic hands. This enables learning a variable-length latent representation of the manipulator configuration and the alignment of the end-effector frame of all manipulators. We show that it is possible to extract principal components from this latent representation that is universal across manipulators of different structures and degrees of freedom. To evaluate PCHands, we use this compact representation to encode observation and action spaces of control policies for dexterous manipulation tasks learned with RL. In terms of learning efficiency and consistency, the proposed representation outperforms a baseline that learns the same tasks in joint space. We additionally show that PCHands performs robustly in RL from demonstration, when demonstrations are provided from a different manipulator. We further support our results with real-world experiments that involve a 2-finger gripper and a 4-finger anthropomorphic hand. Code and additional material are available at https://hsp-iit.github.io/PCHands/.",
    "source": "arXiv"
  },
  {
    "title": "Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions",
    "title_es": "Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions",
    "url": "https://arxiv.org/abs/2508.07948",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07948v1 Announce Type: new \nAbstract: Progressive neurodegenerative diseases, including Alzheimer's disease (AD), multiple sclerosis (MS), Parkinson's disease (PD), and amyotrophic lateral sclerosis (ALS), exhibit complex, nonlinear trajectories that challenge deterministic modeling. Traditional time-domain analyses of multiomic and neuroimaging data often fail to capture hidden oscillatory patterns, limiting predictive accuracy. We propose a theoretical mathematical framework that transforms time-series data into frequency or s-domain using Fourier and Laplace transforms, models neuronal dynamics via Hamiltonian formulations, and employs quantum-classical hybrid computing with variational quantum eigensolvers (VQE) for enhanced pattern detection. This theoretical construct serves as a foundation for future empirical works in quantum-enhanced analysis of neurodegenerative diseases. We extend this to quaternionic representations with three imaginary axes ($i, j, k$) to model multistate Hamiltonians in multifaceted disorders, drawing from quantum neuromorphic computing to capture entangled neural dynamics \\citep{Pehle2020, Emani2019}. This approach leverages quantum advantages in handling high-dimensional amplitude-phase data, enabling outlier detection and frequency signature analysis. Potential clinical applications include identifying high-risk patients with rapid progression or therapy resistance using s-domain biomarkers, supported by quantum machine learning (QML) precedents achieving up to 99.89% accuracy in Alzheimer's classification \\citep{Belay2024, Bhowmik2025}. This framework aims to lay the groundwork for redefining precision medicine for neurodegenerative diseases through future validations.",
    "source": "arXiv"
  },
  {
    "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis",
    "title_es": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis",
    "url": "https://arxiv.org/abs/2508.07950",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07950v1 Announce Type: new \nAbstract: Forensic cause-of-death determination faces systemic challenges, including workforce shortages and diagnostic variability, particularly in high-volume systems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic AgenT), a multi-agent AI framework that automates and standardizes death investigations through a domain-adapted large language model. FEAT's application-oriented architecture integrates: (i) a central Planner for task decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a Memory & Reflection module for iterative refinement, and (iv) a Global Solver for conclusion synthesis. The system employs tool-augmented reasoning, hierarchical retrieval-augmented generation, forensic-tuned LLMs, and human-in-the-loop feedback to ensure legal and medical validity. In evaluations across diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI systems in both long-form autopsy analyses and concise cause-of-death conclusions. It demonstrated robust generalization across six geographic regions and achieved high expert concordance in blinded validations. Senior pathologists validated FEAT's outputs as comparable to those of human experts, with improved detection of subtle evidentiary nuances. To our knowledge, FEAT is the first LLM-based AI agent system dedicated to forensic medicine, offering scalable, consistent death certification while maintaining expert-level rigor. By integrating AI efficiency with human oversight, this work could advance equitable access to reliable medicolegal services while addressing critical capacity constraints in forensic systems.",
    "source": "arXiv"
  },
  {
    "title": "Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters",
    "title_es": "Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters",
    "url": "https://arxiv.org/abs/2508.07952",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07952v1 Announce Type: new \nAbstract: Clustering algorithms often assume all features contribute equally to the data structure, an assumption that usually fails in high-dimensional or noisy settings. Feature weighting methods can address this, but most require additional parameter tuning. We propose SHARK (Shapley Reweighted $k$-means), a feature-weighted clustering algorithm motivated by the use of Shapley values from cooperative game theory to quantify feature relevance, which requires no additional parameters beyond those in $k$-means. We prove that the $k$-means objective can be decomposed into a sum of per-feature Shapley values, providing an axiomatic foundation for unsupervised feature relevance and reducing Shapley computation from exponential to polynomial time. SHARK iteratively re-weights features by the inverse of their Shapley contribution, emphasising informative dimensions and down-weighting irrelevant ones. Experiments on synthetic and real-world data sets show that SHARK consistently matches or outperforms existing methods, achieving superior robustness and accuracy, particularly in scenarios where noise may be present. Software: https://github.com/rickfawley/shark.",
    "source": "arXiv"
  },
  {
    "title": "Expert Preference-based Evaluation of Automated Related Work Generation",
    "title_es": "Expert Preference-based Evaluation of Automated Related Work Generation",
    "url": "https://arxiv.org/abs/2508.07955",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07955v1 Announce Type: new \nAbstract: Expert domain writing, such as scientific writing, typically demands extensive domain knowledge. Recent advances in LLMs show promising potential in reducing the expert workload. However, evaluating the quality of automatically generated scientific writing is a crucial open issue, as it requires knowledge of domain-specific evaluation criteria and the ability to discern expert preferences. Conventional automatic metrics and LLM-as-a-judge systems are insufficient to grasp expert preferences and domain-specific quality standards. To address this gap and support human-AI collaborative writing, we focus on related work generation, one of the most challenging scientific tasks, as an exemplar. We propose GREP, a multi-turn evaluation framework that integrates classical related work evaluation criteria with expert-specific preferences. Instead of assigning a single score, our framework decomposes the evaluation into fine-grained dimensions. This localized evaluation approach is further augmented with contrastive few-shot examples to provide detailed contextual guidance for the evaluation dimensions. The design principles allow our framework to deliver cardinal assessment of quality, which can facilitate better post-training compared to ordinal preference data. For better accessibility, we design two variants of GREP: a more precise variant with proprietary LLMs as evaluators, and a cheaper alternative with open-weight LLMs. Empirical investigation reveals that our framework is able to assess the quality of related work sections in a much more robust manner compared to standard LLM judges, reflects natural scenarios of scientific writing, and bears a strong correlation with the human expert assessment. We also observe that generations from state-of-the-art LLMs struggle to satisfy validation constraints of a suitable related work section. They (mostly) fail to improve based on feedback as well.",
    "source": "arXiv"
  },
  {
    "title": "Careful Queries, Credible Results: Teaching RAG Models Advanced Web Search Tools with Reinforcement Learning",
    "title_es": "Careful Queries, Credible Results: Teaching RAG Models Advanced Web Search Tools with Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.07956",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07956v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating up-to-date external knowledge, yet real-world web environments present unique challenges. These limitations manifest as two key challenges: pervasive misinformation in the web environment, which introduces unreliable or misleading content that can degrade retrieval accuracy, and the underutilization of web tools, which, if effectively employed, could enhance query precision and help mitigate this noise, ultimately improving the retrieval results in RAG systems. To address these issues, we propose WebFilter, a novel RAG framework that generates source-restricted queries and filters out unreliable content. This approach combines a retrieval filtering mechanism with a behavior- and outcome-driven reward strategy, optimizing both query formulation and retrieval outcomes. Extensive experiments demonstrate that WebFilter improves answer quality and retrieval precision, outperforming existing RAG methods on both in-domain and out-of-domain benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Source-Channel Coding for Semantic Communications",
    "title_es": "Adaptive Source-Channel Coding for Semantic Communications",
    "url": "https://arxiv.org/abs/2508.07958",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07958v1 Announce Type: new \nAbstract: Semantic communications (SemComs) have emerged as a promising paradigm for joint data and task-oriented transmissions, combining the demands for both the bit-accurate delivery and end-to-end (E2E) distortion minimization. However, current joint source-channel coding (JSCC) in SemComs is not compatible with the existing communication systems and cannot adapt to the variations of the sources or the channels, while separate source-channel coding (SSCC) is suboptimal in the finite blocklength regime. To address these issues, we propose an adaptive source-channel coding (ASCC) scheme for SemComs over parallel Gaussian channels, where the deep neural network (DNN)-based semantic source coding and conventional digital channel coding are separately deployed and adaptively designed. To enable efficient adaptation between the source and channel coding, we first approximate the E2E data and semantic distortions as functions of source coding rate and bit error ratio (BER) via logistic regression, where BER is further modeled as functions of signal-to-noise ratio (SNR) and channel coding rate. Then, we formulate the weighted sum E2E distortion minimization problem for joint source-channel coding rate and power allocation over parallel channels, which is solved by the successive convex approximation. Finally, simulation results demonstrate that the proposed ASCC scheme outperforms typical deep JSCC and SSCC schemes for both the single- and parallel-channel scenarios while maintaining full compatibility with practical digital systems.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models for Subjective Language Understanding: A Survey",
    "title_es": "Large Language Models for Subjective Language Understanding: A Survey",
    "url": "https://arxiv.org/abs/2508.07959",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07959v1 Announce Type: new \nAbstract: Subjective language understanding refers to a broad set of natural language processing tasks where the goal is to interpret or generate content that conveys personal feelings, opinions, or figurative meanings rather than objective facts. With the advent of large language models (LLMs) such as ChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach these inherently nuanced tasks. In this survey, we provide a comprehensive review of recent advances in applying LLMs to subjective language tasks, including sentiment analysis, emotion recognition, sarcasm detection, humor understanding, stance detection, metaphor interpretation, intent detection, and aesthetics assessment. We begin by clarifying the definition of subjective language from linguistic and cognitive perspectives, and we outline the unique challenges posed by subjective language (e.g. ambiguity, figurativeness, context dependence). We then survey the evolution of LLM architectures and techniques that particularly benefit subjectivity tasks, highlighting why LLMs are well-suited to model subtle human-like judgments. For each of the eight tasks, we summarize task definitions, key datasets, state-of-the-art LLM-based methods, and remaining challenges. We provide comparative insights, discussing commonalities and differences among tasks and how multi-task LLM approaches might yield unified models of subjectivity. Finally, we identify open issues such as data limitations, model bias, and ethical considerations, and suggest future research directions. We hope this survey will serve as a valuable resource for researchers and practitioners interested in the intersection of affective computing, figurative language processing, and large-scale language models.",
    "source": "arXiv"
  },
  {
    "title": "VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security",
    "title_es": "VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security",
    "url": "https://arxiv.org/abs/2508.07960",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07960v1 Announce Type: new \nAbstract: Advancement of machine learning techniques, combined with the availability of large-scale datasets, has significantly improved the accuracy and efficiency of facial recognition. Modern facial recognition systems are trained using large face datasets collected from diverse individuals or public repositories. However, for training, these datasets are often replicated and stored in multiple workstations, resulting in data replication, which complicates database management and oversight. Currently, once a user submits their face for dataset preparation, they lose control over how their data is used, raising significant privacy and ethical concerns. This paper introduces VOIDFace, a novel framework for facial recognition systems that addresses two major issues. First, it eliminates the need of data replication and improves data control to securely store training face data by using visual secret sharing. Second, it proposes a patch-based multi-training network that uses this novel training data storage mechanism to develop a robust, privacy-preserving facial recognition system. By integrating these advancements, VOIDFace aims to improve the privacy, security, and efficiency of facial recognition training, while ensuring greater control over sensitive personal face data. VOIDFace also enables users to exercise their Right-To-Be-Forgotten property to control their personal data. Experimental evaluations on the VGGFace2 dataset show that VOIDFace provides Right-To-Be-Forgotten, improved data control, security, and privacy while maintaining competitive facial recognition performance. Code is available at: https://github.com/ajnasmuhammed89/VOIDFace",
    "source": "arXiv"
  },
  {
    "title": "Runtime Verification for LTL in Stochastic Systems",
    "title_es": "Runtime Verification for LTL in Stochastic Systems",
    "url": "https://arxiv.org/abs/2508.07963",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07963v1 Announce Type: new \nAbstract: Runtime verification encompasses several lightweight techniques for checking whether a system's current execution satisfies a given specification. We focus on runtime verification for Linear Temporal Logic (LTL). Previous work describes monitors which produce, at every time step one of three outputs - true, false, or inconclusive - depending on whether the observed execution prefix definitively determines satisfaction of the formula. However, for many LTL formulas, such as liveness properties, satisfaction cannot be concluded from any finite prefix. For these properties traditional monitors will always output inconclusive. In this work, we propose a novel monitoring approach that replaces hard verdicts with probabilistic predictions and an associated confidence score. Our method guarantees eventual correctness of the prediction and ensures that confidence increases without bound from that point on.",
    "source": "arXiv"
  },
  {
    "title": "Toward Machine Interpreting: Lessons from Human Interpreting Studies",
    "title_es": "Toward Machine Interpreting: Lessons from Human Interpreting Studies",
    "url": "https://arxiv.org/abs/2508.07964",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07964v1 Announce Type: new \nAbstract: Current speech translation systems, while having achieved impressive accuracies, are rather static in their behavior and do not adapt to real-world situations in ways human interpreters do. In order to improve their practical usefulness and enable interpreting-like experiences, a precise understanding of the nature of human interpreting is crucial. To this end, we discuss human interpreting literature from the perspective of the machine translation field, while considering both operational and qualitative aspects. We identify implications for the development of speech translation systems and argue that there is great potential to adopt many human interpreting principles using recent modeling techniques. We hope that our findings provide inspiration for closing the perceived usability gap, and can motivate progress toward true machine interpreting.",
    "source": "arXiv"
  },
  {
    "title": "Exploring the Challenges and Opportunities of AI-assisted Codebase Generation",
    "title_es": "Exploring the Challenges and Opportunities of AI-assisted Codebase Generation",
    "url": "https://arxiv.org/abs/2508.07966",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07966v1 Announce Type: new \nAbstract: Recent AI code assistants have significantly improved their ability to process more complex contexts and generate entire codebases based on a textual description, compared to the popular snippet-level generation. These codebase AI assistants (CBAs) can also extend or adapt codebases, allowing users to focus on higher-level design and deployment decisions. While prior work has extensively studied the impact of snippet-level code generation, this new class of codebase generation models is relatively unexplored. Despite initial anecdotal reports of excitement about these agents, they remain less frequently adopted compared to snippet-level code assistants. To utilize CBAs better, we need to understand how developers interact with CBAs, and how and why CBAs fall short of developers' needs. In this paper, we explored these gaps through a counterbalanced user study and interview with (n = 16) students and developers working on coding tasks with CBAs. We found that participants varied the information in their prompts, like problem description (48% of prompts), required functionality (98% of prompts), code structure (48% of prompts), and their prompt writing process. Despite various strategies, the overall satisfaction score with generated codebases remained low (mean = 2.8, median = 3, on a scale of one to five). Participants mentioned functionality as the most common factor for dissatisfaction (77% of instances), alongside poor code quality (42% of instances) and communication issues (25% of instances). We delve deeper into participants' dissatisfaction to identify six underlying challenges that participants faced when using CBAs, and extracted five barriers to incorporating CBAs into their workflows. Finally, we surveyed 21 commercial CBAs to compare their capabilities with participant challenges and present design opportunities for more efficient and useful CBAs.",
    "source": "arXiv"
  },
  {
    "title": "TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking",
    "title_es": "TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking",
    "url": "https://arxiv.org/abs/2508.07968",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07968v1 Announce Type: new \nAbstract: Providing intelligent support to surgical teams is a key frontier in automated surgical scene understanding, with the long-term goal of improving patient outcomes. Developing personalized intelligence for all staff members requires maintaining a consistent state of who is located where for long surgical procedures, which still poses numerous computational challenges. We propose TrackOR, a framework for tackling long-term multi-person tracking and re-identification in the operating room. TrackOR uses 3D geometric signatures to achieve state-of-the-art online tracking performance (+11% Association Accuracy over the strongest baseline), while also enabling an effective offline recovery process to create analysis-ready trajectories. Our work shows that by leveraging 3D geometric information, persistent identity tracking becomes attainable, enabling a critical shift towards the more granular, staff-centric analyses required for personalized intelligent systems in the operating room. This new capability opens up various applications, including our proposed temporal pathway imprints that translate raw tracking data into actionable insights for improving team efficiency and safety and ultimately providing personalized support.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Syntactic Generalization in Structure-inducing Language Models",
    "title_es": "Understanding Syntactic Generalization in Structure-inducing Language Models",
    "url": "https://arxiv.org/abs/2508.07969",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07969v1 Announce Type: new \nAbstract: Structure-inducing Language Models (SiLM) are trained on a self-supervised language modeling task, and induce a hierarchical sentence representation as a byproduct when processing an input. A wide variety of SiLMs have been proposed. However, these have typically been evaluated on a relatively small scale, and evaluation of these models has systematic gaps and lacks comparability. In this work, we study three different SiLM architectures using both natural language (English) corpora and synthetic bracketing expressions: Structformer (Shen et al., 2021), UDGN (Shen et al., 2022) and GPST (Hu et al., 2024). We compare them with respect to (i) properties of the induced syntactic representations (ii) performance on grammaticality judgment tasks, and (iii) training dynamics. We find that none of the three architectures dominates across all evaluation metrics. However, there are significant differences, in particular with respect to the induced syntactic representations. The Generative Pretrained Structured Transformer (GPST; Hu et al. 2024) performs most consistently across evaluation settings, and outperforms the other models on long-distance dependencies in bracketing expressions. Furthermore, our study shows that small models trained on large amounts of synthetic data provide a useful testbed for evaluating basic model properties.",
    "source": "arXiv"
  },
  {
    "title": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer",
    "title_es": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer",
    "url": "https://arxiv.org/abs/2508.07970",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07970v1 Announce Type: new \nAbstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent paradigm for training large language models and multimodal systems. Despite notable advances enabled by existing RLHF training frameworks, significant challenges remain in scaling to complex multimodal workflows and adapting to dynamic workloads. In particular, current systems often encounter limitations related to controller scalability when managing large models, as well as inefficiencies in orchestrating intricate RLHF pipelines, especially in scenarios that require dynamic sampling and resource allocation. In this paper, we introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple, scalable, and balanced RLHF training framework specifically designed to address these challenges. WeChat-YATT features a parallel controller programming model that enables flexible and efficient orchestration of complex RLHF workflows, effectively mitigating the bottlenecks associated with centralized controller architectures and facilitating scalability in large-scale data scenarios. In addition, we propose a dynamic placement schema that adaptively partitions computational resources and schedules workloads, thereby significantly reducing hardware idle time and improving GPU utilization under variable training conditions. We evaluate WeChat-YATT across a range of experimental scenarios, demonstrating that it achieves substantial improvements in throughput compared to state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been successfully deployed to train models supporting WeChat product features for a large-scale user base, underscoring its effectiveness and robustness in real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "Joint Transcription of Acoustic Guitar Strumming Directions and Chords",
    "title_es": "Joint Transcription of Acoustic Guitar Strumming Directions and Chords",
    "url": "https://arxiv.org/abs/2508.07973",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07973v1 Announce Type: new \nAbstract: Automatic transcription of guitar strumming is an underrepresented and challenging task in Music Information Retrieval (MIR), particularly for extracting both strumming directions and chord progressions from audio signals. While existing methods show promise, their effectiveness is often hindered by limited datasets. In this work, we extend a multimodal approach to guitar strumming transcription by introducing a novel dataset and a deep learning-based transcription model. We collect 90 min of real-world guitar recordings using an ESP32 smartwatch motion sensor and a structured recording protocol, complemented by a synthetic dataset of 4h of labeled strumming audio. A Convolutional Recurrent Neural Network (CRNN) model is trained to detect strumming events, classify their direction, and identify the corresponding chords using only microphone audio. Our evaluation demonstrates significant improvements over baseline onset detection algorithms, with a hybrid method combining synthetic and real-world data achieving the highest accuracy for both strumming action detection and chord classification. These results highlight the potential of deep learning for robust guitar strumming transcription and open new avenues for automatic rhythm guitar analysis.",
    "source": "arXiv"
  },
  {
    "title": "Improving Document Retrieval Coherence for Semantically Equivalent Queries",
    "title_es": "Improving Document Retrieval Coherence for Semantically Equivalent Queries",
    "url": "https://arxiv.org/abs/2508.07975",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07975v1 Announce Type: new \nAbstract: Dense Retrieval (DR) models have proven to be effective for Document Retrieval and Information Grounding tasks. Usually, these models are trained and optimized for improving the relevance of top-ranked documents for a given query. Previous work has shown that popular DR models are sensitive to the query and document lexicon: small variations of it may lead to a significant difference in the set of retrieved documents. In this paper, we propose a variation of the Multi-Negative Ranking loss for training DR that improves the coherence of models in retrieving the same documents with respect to semantically similar queries. The loss penalizes discrepancies between the top-k ranked documents retrieved for diverse but semantic equivalent queries. We conducted extensive experiments on various datasets, MS-MARCO, Natural Questions, BEIR, and TREC DL 19/20. The results show that (i) models optimizes by our loss are subject to lower sensitivity, and, (ii) interestingly, higher accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL",
    "title_es": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL",
    "url": "https://arxiv.org/abs/2508.07976",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07976v1 Announce Type: new \nAbstract: Recent advancements in LLM-based agents have demonstrated remarkable capabilities in handling complex, knowledge-intensive tasks by integrating external tools. Among diverse choices of tools, search tools play a pivotal role in accessing vast external knowledge. However, open-source agents still fall short of achieving expert-level Search Intelligence, the ability to resolve ambiguous queries, generate precise searches, analyze results, and conduct thorough exploration. Existing approaches fall short in scalability, efficiency, and data quality. For example, small turn limits in existing online RL methods, e.g. <=10, restrict complex strategy learning. This paper introduces ASearcher, an open-source project for large-scale RL training of search agents. Our key contributions include: (1) Scalable fully asynchronous RL training that enables long-horizon search while maintaining high training efficiency. (2) A prompt-based LLM agent that autonomously synthesizes high-quality and challenging QAs, creating a large-scale QA dataset. Through RL training, our prompt-based QwQ-32B agent achieves substantial improvements, with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns and output tokens exceeding 150k during training time. With a simple agent design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We open-source our models, training data, and codes in https://github.com/inclusionAI/ASearcher.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Multiple Access and Service Placement for Generative Diffusion Models",
    "title_es": "Adaptive Multiple Access and Service Placement for Generative Diffusion Models",
    "url": "https://arxiv.org/abs/2508.07978",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07978v1 Announce Type: new \nAbstract: Generative Diffusion Models (GDMs) have emerged as key components of Generative Artificial Intelligence (GenAI), offering unparalleled expressiveness and controllability for complex data generation tasks. However, their deployment in real-time and mobile environments remains challenging due to the iterative and resource-intensive nature of the inference process. Addressing these challenges, this paper introduces a unified optimization framework that jointly tackles service placement and multiple access control for GDMs in mobile edge networks. We propose LEARN-GDM, a Deep Reinforcement Learning-based algorithm that dynamically partitions denoising blocks across heterogeneous edge nodes, while accounting for latent transmission costs and enabling adaptive reduction of inference steps. Our approach integrates a greedy multiple access scheme with a Double and Dueling Deep Q-Learning (D3QL)-based service placement, allowing for scalable, adaptable, and resource-efficient operation under stringent quality of service requirements. Simulations demonstrate the superior performance of the proposed framework in terms of scalability and latency resilience compared to conventional monolithic and fixed chain-length placement strategies. This work advances the state of the art in edge-enabled GenAI by offering an adaptable solution for GDM services orchestration, paving the way for future extensions toward semantic networking and co-inference across distributed environments.",
    "source": "arXiv"
  },
  {
    "title": "Early Explorations of Recommender Systems for Physical Activity and Well-being",
    "title_es": "Early Explorations of Recommender Systems for Physical Activity and Well-being",
    "url": "https://arxiv.org/abs/2508.07980",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07980v1 Announce Type: new \nAbstract: As recommender systems increasingly guide physical actions, often through wearables and coaching tools, new challenges arise around how users interpret, trust, and respond to this advice. This paper introduces a conceptual framework for tangible recommendations that influence users' bodies, routines, and well-being. We describe three design dimensions: trust and interpretation, intent alignment, and consequence awareness. These highlight key limitations in applying conventional recommender logic to embodied settings. Through examples and design reflections, we outline how future systems can support long-term well-being, behavioral alignment, and socially responsible personalization.",
    "source": "arXiv"
  },
  {
    "title": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation",
    "title_es": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation",
    "url": "https://arxiv.org/abs/2508.07981",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07981v1 Announce Type: new \nAbstract: Visual effects (VFX) are essential visual enhancements fundamental to modern cinematic production. Although video generation models offer cost-efficient solutions for VFX production, current methods are constrained by per-effect LoRA training, which limits generation to single effects. This fundamental limitation impedes applications that require spatially controllable composite effects, i.e., the concurrent generation of multiple effects at designated locations. However, integrating diverse effects into a unified framework faces major challenges: interference from effect variations and spatial uncontrollability during multi-VFX joint training. To tackle these challenges, we propose Omni-Effects, a first unified framework capable of generating prompt-guided effects and spatially controllable composite effects. The core of our framework comprises two key innovations: (1) LoRA-based Mixture of Experts (LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects within a unified model while effectively mitigating cross-task interference. (2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the text token, enabling precise spatial control. Furthermore, we introduce an Independent-Information Flow (IIF) module integrated within the SAP, isolating the control signals corresponding to individual effects to prevent any unwanted blending. To facilitate this research, we construct a comprehensive VFX dataset Omni-VFX via a novel data collection pipeline combining image editing and First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX evaluation framework for validating model performance. Extensive experiments demonstrate that Omni-Effects achieves precise spatial control and diverse effect generation, enabling users to specify both the category and location of desired effects.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription",
    "title_es": "Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription",
    "url": "https://arxiv.org/abs/2508.07987",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07987v1 Announce Type: new \nAbstract: Automatic transcription of acoustic guitar fingerpicking performances remains a challenging task due to the scarcity of labeled training data and legal constraints connected with musical recordings. This work investigates a procedural data generation pipeline as an alternative to real audio recordings for training transcription models. Our approach synthesizes training data through four stages: knowledge-based fingerpicking tablature composition, MIDI performance rendering, physical modeling using an extended Karplus-Strong algorithm, and audio augmentation including reverb and distortion. We train and evaluate a CRNN-based note-tracking model on both real and synthetic datasets, demonstrating that procedural data can be used to achieve reasonable note-tracking results. Finetuning with a small amount of real data further enhances transcription accuracy, improving over models trained exclusively on real recordings. These results highlight the potential of procedurally generated audio for data-scarce music information retrieval tasks.",
    "source": "arXiv"
  },
  {
    "title": "The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility",
    "title_es": "The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility",
    "url": "https://arxiv.org/abs/2508.07989",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07989v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) hold immense promise as assistive technologies for the blind and visually impaired (BVI) community. However, we identify a critical failure mode that undermines their trustworthiness in real-world applications. We introduce the Escalator Problem -- the inability of state-of-the-art models to perceive an escalator's direction of travel -- as a canonical example of a deeper limitation we term Implicit Motion Blindness. This blindness stems from the dominant frame-sampling paradigm in video understanding, which, by treating videos as discrete sequences of static images, fundamentally struggles to perceive continuous, low-signal motion. As a position paper, our contribution is not a new model but rather to: (I) formally articulate this blind spot, (II) analyze its implications for user trust, and (III) issue a call to action. We advocate for a paradigm shift from purely semantic recognition towards robust physical perception and urge the development of new, human-centered benchmarks that prioritize safety, reliability, and the genuine needs of users in dynamic environments.",
    "source": "arXiv"
  },
  {
    "title": "Mining the Social Fabric: Unveiling Communities for Fake News Detection in Short Videos",
    "title_es": "Mining the Social Fabric: Unveiling Communities for Fake News Detection in Short Videos",
    "url": "https://arxiv.org/abs/2508.07992",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07992v1 Announce Type: new \nAbstract: Short video platforms have become a major medium for information sharing, but their rapid content generation and algorithmic amplification also enable the widespread dissemination of fake news. Detecting misinformation in short videos is challenging due to their multi-modal nature and the limited context of individual videos. While recent methods focus on analyzing content signals-visual, textual, and audio-they often overlook implicit relationships among videos, uploaders, and events. To address this gap, we propose DugFND (Dual-community graph for fake news detection), a novel method that enhances existing video classifiers by modeling two key community patterns: (1) uploader communities, where uploaders with shared interests or similar content creation patterns group together, and (2) event-driven communities, where videos related to the same or semantically similar public events form localized clusters. We construct a heterogeneous graph connecting uploader, video, and event nodes, and design a time-aware heterogeneous graph attention network to enable effective message passing. A reconstruction-based pretraining phase further improves node representation learning. DugFND can be applied to any pre-trained classifier. Experiments on public datasets show that our method achieves significant performance gains, demonstrating the value of dual-community modeling for fake news detection in short videos.",
    "source": "arXiv"
  },
  {
    "title": "The Medical Metaphors Corpus (MCC)",
    "title_es": "The Medical Metaphors Corpus (MCC)",
    "url": "https://arxiv.org/abs/2508.07993",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07993v1 Announce Type: new \nAbstract: Metaphor is a fundamental cognitive mechanism that shapes scientific understanding, enabling the communication of complex concepts while potentially constraining paradigmatic thinking. Despite the prevalence of figurative language in scientific discourse, existing metaphor detection resources primarily focus on general-domain text, leaving a critical gap for domain-specific applications. In this paper, we present the Medical Metaphors Corpus (MCC), a comprehensive dataset of 792 annotated scientific conceptual metaphors spanning medical and biological domains. MCC aggregates metaphorical expressions from diverse sources including peer-reviewed literature, news media, social media discourse, and crowdsourced contributions, providing both binary and graded metaphoricity judgments validated through human annotation. Each instance includes source-target conceptual mappings and perceived metaphoricity scores on a 0-7 scale, establishing the first annotated resource for computational scientific metaphor research. Our evaluation demonstrates that state-of-the-art language models achieve modest performance on scientific metaphor detection, revealing substantial room for improvement in domain-specific figurative language understanding. MCC enables multiple research applications including metaphor detection benchmarking, quality-aware generation systems, and patient-centered communication tools.",
    "source": "arXiv"
  },
  {
    "title": "Prediction error certification for PINNs: Theory, computation, and application to Stokes flow",
    "title_es": "Prediction error certification for PINNs: Theory, computation, and application to Stokes flow",
    "url": "https://arxiv.org/abs/2508.07994",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07994v1 Announce Type: new \nAbstract: Rigorous error estimation is a fundamental topic in numerical analysis. With the increasing use of physics-informed neural networks (PINNs) for solving partial differential equations, several approaches have been developed to quantify the associated prediction error. In this work, we build upon a semigroup-based framework previously introduced by the authors for estimating the PINN error. While this estimator has so far been limited to academic examples - due to the need to compute quantities related to input-to-state stability - we extend its applicability to a significantly broader class of problems. This is accomplished by modifying the error bound and proposing numerical strategies to approximate the required stability parameters. The extended framework enables the certification of PINN predictions in more realistic scenarios, as demonstrated by a numerical study of Stokes flow around a cylinder.",
    "source": "arXiv"
  },
  {
    "title": "DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval",
    "title_es": "DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval",
    "url": "https://arxiv.org/abs/2508.07995",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07995v1 Announce Type: new \nAbstract: Retrieval-augmented generation has achieved strong performance on knowledge-intensive tasks where query-document relevance can be identified through direct lexical or semantic matches. However, many real-world queries involve abstract reasoning, analogical thinking, or multi-step inference, which existing retrievers often struggle to capture. To address this challenge, we present \\textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive information retrieval. DIVER consists of four components: document processing to improve input quality, LLM-driven query expansion via iterative document interaction, a reasoning-enhanced retriever fine-tuned on synthetic multi-domain data with hard negatives, and a pointwise reranker that combines LLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark, DIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original queries, consistently outperforming competitive reasoning-aware models. These results demonstrate the effectiveness of reasoning-aware retrieval strategies in complex real-world tasks. Our code and retrieval model will be released soon.",
    "source": "arXiv"
  },
  {
    "title": "Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models",
    "title_es": "Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models",
    "url": "https://arxiv.org/abs/2508.07996",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07996v1 Announce Type: new \nAbstract: Group Activity Detection (GAD) involves recognizing social groups and their collective behaviors in videos. Vision Foundation Models (VFMs), like DinoV2, offer excellent features, but are pretrained primarily on object-centric data and remain underexplored for modeling group dynamics. While they are a promising alternative to highly task-specific GAD architectures that require full fine-tuning, our initial investigation reveals that simply swapping CNN backbones used in these methods with VFMs brings little gain, underscoring the need for structured, group-aware reasoning on top.\n  We introduce Prompt-driven Group Activity Detection (ProGraD) -- a method that bridges this gap through 1) learnable group prompts to guide the VFM attention toward social configurations, and 2) a lightweight two-layer GroupContext Transformer that infers actor-group associations and collective behavior. We evaluate our approach on two recent GAD benchmarks: Cafe, which features multiple concurrent social groups, and Social-CAD, which focuses on single-group interactions. While we surpass state-of-the-art in both settings, our method is especially effective in complex multi-group scenarios, where we yield a gain of 6.5\\% (Group mAP\\@1.0) and 8.2\\% (Group mAP\\@0.5) using only 10M trainable parameters. Furthermore, our experiments reveal that ProGraD produces interpretable attention maps, offering insights into actor-group reasoning. Code and models will be released.",
    "source": "arXiv"
  },
  {
    "title": "WideSearch: Benchmarking Agentic Broad Info-Seeking",
    "title_es": "WideSearch: Benchmarking Agentic Broad Info-Seeking",
    "url": "https://arxiv.org/abs/2508.07999",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07999v1 Announce Type: new \nAbstract: From professional research to everyday planning, many tasks are bottlenecked by wide-scale information seeking, which is more repetitive than cognitively complex. With the rapid development of Large Language Models (LLMs), automated search agents powered by LLMs offer a promising solution to liberate humans from this tedious work. However, the capability of these agents to perform such \"wide-context\" collection reliably and completely remains largely unevaluated due to a lack of suitable benchmarks. To bridge this gap, we introduce WideSearch, a new benchmark engineered to evaluate agent reliability on these large-scale collection tasks. The benchmark features 200 manually curated questions (100 in English, 100 in Chinese) from over 15 diverse domains, grounded in real user queries. Each task requires agents to collect large-scale atomic information, which could be verified one by one objectively, and arrange it into a well-organized output. A rigorous five-stage quality control pipeline ensures the difficulty, completeness, and verifiability of the dataset. We benchmark over 10 state-of-the-art agentic search systems, including single-agent, multi-agent frameworks, and end-to-end commercial systems. Most systems achieve overall success rates near 0\\%, with the best performer reaching just 5\\%. However, given sufficient time, cross-validation by multiple human testers can achieve a near 100\\% success rate. These results demonstrate that present search agents have critical deficiencies in large-scale information seeking, underscoring urgent areas for future research and development in agentic search. Our dataset, evaluation pipeline, and benchmark results have been publicly released at https://widesearch-seed.github.io/",
    "source": "arXiv"
  },
  {
    "title": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths",
    "title_es": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths",
    "url": "https://arxiv.org/abs/2508.08001",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08001v1 Announce Type: new \nAbstract: \"Fedspeak\", the stylized and often nuanced language used by the U.S. Federal Reserve, encodes implicit policy signals and strategic stances. The Federal Open Market Committee strategically employs Fedspeak as a communication tool to shape market expectations and influence both domestic and global economic conditions. As such, automatically parsing and interpreting Fedspeak presents a high-impact challenge, with significant implications for financial forecasting, algorithmic trading, and data-driven policy analysis. In this paper, we propose an LLM-based, uncertainty-aware framework for deciphering Fedspeak and classifying its underlying monetary policy stance. Technically, to enrich the semantic and contextual representation of Fedspeak texts, we incorporate domain-specific reasoning grounded in the monetary policy transmission mechanism. We further introduce a dynamic uncertainty decoding module to assess the confidence of model predictions, thereby enhancing both classification accuracy and model reliability. Experimental results demonstrate that our framework achieves state-of-the-art performance on the policy stance analysis task. Moreover, statistical analysis reveals a significant positive correlation between perceptual uncertainty and model error rates, validating the effectiveness of perceptual uncertainty as a diagnostic signal.",
    "source": "arXiv"
  },
  {
    "title": "A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation",
    "title_es": "A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation",
    "url": "https://arxiv.org/abs/2508.08002",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08002v1 Announce Type: new \nAbstract: Traffic state estimation (TSE) falls methodologically into three categories: model-driven, data-driven, and model-data dual-driven. Model-driven TSE relies on macroscopic traffic flow models originated from hydrodynamics. Data-driven TSE leverages historical sensing data and employs statistical models or machine learning methods to infer traffic state. Model-data dual-driven traffic state estimation attempts to harness the strengths of both aspects to achieve more accurate TSE. From the perspective of mathematical operator theory, TSE can be viewed as a type of operator that maps available measurements of inerested traffic state into unmeasured traffic state variables in real time. For the first time this paper proposes to study real-time freeway TSE in the idea of physics-informed deep operator network (PI-DeepONet), which is an operator-oriented architecture embedding traffic flow models based on deep neural networks. The paper has developed an extended architecture from the original PI-DeepONet. The extended architecture is featured with: (1) the acceptance of 2-D data input so as to support CNN-based computations; (2) the introduction of a nonlinear expansion layer, an attention mechanism, and a MIMO mechanism; (3) dedicated neural network design for adaptive identification of traffic flow model parameters. A traffic state estimator built on the basis of this extended PI-DeepONet architecture was evaluated with respect to a short freeway stretch of NGSIM and a large-scale urban expressway in China, along with other four baseline TSE methods. The evaluation results demonstrated that this novel TSE method outperformed the baseline methods with high-precision estimation results of flow and mean speed.",
    "source": "arXiv"
  },
  {
    "title": "Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition",
    "title_es": "Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition",
    "url": "https://arxiv.org/abs/2508.08004",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08004v1 Announce Type: new \nAbstract: Automatic data augmentation (AutoDA) plays an important role in enhancing the generalization of neural networks. However, mainstream AutoDA methods often encounter two challenges: either the search process is excessively time-consuming, hindering practical application, or the performance is suboptimal due to insufficient policy adaptation during training. To address these issues, we propose Sample-aware RandAugment (SRA), an asymmetric, search-free AutoDA method that dynamically adjusts augmentation policies while maintaining straightforward implementation. SRA incorporates a heuristic scoring module that evaluates the complexity of the original training data, enabling the application of tailored augmentations for each sample. Additionally, an asymmetric augmentation strategy is employed to maximize the potential of this scoring module. In multiple experimental settings, SRA narrows the performance gap between search-based and search-free AutoDA methods, achieving a state-of-the-art Top-1 accuracy of 78.31\\% on ImageNet with ResNet-50. Notably, SRA demonstrates good compatibility with existing augmentation pipelines and solid generalization across new tasks, without requiring hyperparameter tuning. The pretrained models leveraging SRA also enhance recognition in downstream object detection tasks. SRA represents a promising step towards simpler, more effective, and practical AutoDA designs applicable to a variety of future tasks. Our code is available at \\href{https://github.com/ainieli/Sample-awareRandAugment}{https://github.com/ainieli/Sample-awareRandAugment",
    "source": "arXiv"
  },
  {
    "title": "Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP",
    "title_es": "Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP",
    "url": "https://arxiv.org/abs/2508.08005",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08005v1 Announce Type: new \nAbstract: Extensive experiments and prior studies show that no single maximum clique algorithm consistently performs best across all instances, highlighting the importance of selecting suitable algorithms based on instance features. Through an extensive analysis of relevant studies, it is found that there is a lack of research work concerning algorithm selection oriented toward the Maximum Clique Problem (MCP). In this work, we propose a learning-based framework that integrates both traditional machine learning and graph neural networks to address this gap. We construct a labeled dataset by running four exact MCP algorithms on a diverse collection of graph instances, accompanied by structural and global statistical features extracted from each graph. We first evaluate four conventional classifiers: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple dataset variants. Experimental results show that RF consistently shows strong performance across metrics and dataset variants, making it a reliable baseline. In addition, feature importance analysis indicates that connectivity and topological structure are strong predictors of algorithm performance. Building on these findings, we develop a dual-channel model named GAT-MLP, which combines a Graph Attention Network (GAT) for local structural encoding with a Multilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model shows strong and consistent performance across all metrics. Our results highlight the effectiveness of dual-channel architectures and the promise of graph neural networks in combinatorial algorithm selection.",
    "source": "arXiv"
  },
  {
    "title": "Fitting Description Logic Ontologies to ABox and Query Examples",
    "title_es": "Fitting Description Logic Ontologies to ABox and Query Examples",
    "url": "https://arxiv.org/abs/2508.08007",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08007v1 Announce Type: new \nAbstract: We study a fitting problem inspired by ontology-mediated querying: given a collection\n  of positive and negative examples of\n  the form $(\\mathcal{A},q)$ with\n  $\\mathcal{A}$ an ABox and $q$ a Boolean query, we seek\n  an ontology $\\mathcal{O}$ that satisfies $\\mathcal{A} \\cup \\mathcal{O} \\vDash q$ for all positive examples and $\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$ for all negative examples.\n  We consider the description logics $\\mathcal{ALC}$ and $\\mathcal{ALCI}$ as ontology languages and\n  a range of query languages that\n  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof (UCQs).\n  For all of the resulting fitting problems,\n  we provide\n  effective characterizations and determine the computational complexity\n  of deciding whether a fitting ontology exists. This problem turns out to be ${\\small CO}NP$ for AQs and full CQs\n  and $2E{\\small XP}T{\\small IME}$-complete for CQs and UCQs.\n  These results hold for both $\\mathcal{ALC}$ and $\\mathcal{ALCI}$.",
    "source": "arXiv"
  },
  {
    "title": "Progressive Depth Up-scaling via Optimal Transport",
    "title_es": "Progressive Depth Up-scaling via Optimal Transport",
    "url": "https://arxiv.org/abs/2508.08011",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08011v1 Announce Type: new \nAbstract: Scaling Large Language Models (LLMs) yields performance gains but incurs substantial training costs. Depth up-scaling offers training efficiency by adding new layers to pre-trained models. However, most existing methods copy or average weights from base layers, neglecting neuron permutation differences. This limitation can potentially cause misalignment that harms performance. Inspired by applying Optimal Transport (OT) for neuron alignment, we propose Optimal Transport Depth Up-Scaling (OpT-DeUS). OpT-DeUS aligns and fuses Transformer blocks in adjacent base layers via OT for new layer creation, to mitigate neuron permutation mismatch between layers. OpT-DeUS achieves better overall performance and offers improved training efficiency than existing methods for continual pre-training and supervised fine-tuning across different model sizes. To further evaluate the impact of interpolation positions, our extensive analysis shows that inserting new layers closer to the top results in higher training efficiency due to shorter back-propagation time while obtaining additional performance gains.",
    "source": "arXiv"
  },
  {
    "title": "Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks",
    "title_es": "Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks",
    "url": "https://arxiv.org/abs/2508.08013",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08013v1 Announce Type: new \nAbstract: Federated Learning (FL) is an emerging learning framework that enables edge devices to collaboratively train ML models without sharing their local data. FL faces, however, a significant challenge due to the high amount of information that must be exchanged between the devices and the aggregator in the training phase, which can exceed the limited capacity of wireless systems. In this paper, two communication-efficient FL methods are considered where communication overhead is reduced by communicating scalar values instead of long vectors and by allowing high number of users to send information simultaneously. The first approach employs a zero-order optimization technique with two-point gradient estimator, while the second involves a first-order gradient computation strategy. The novelty lies in leveraging channel information in the learning algorithms, eliminating hence the need for additional resources to acquire channel state information (CSI) and to remove its impact, as well as in considering asynchronous devices. We provide a rigorous analytical framework for the two methods, deriving convergence guarantees and establishing appropriate performance bounds.",
    "source": "arXiv"
  },
  {
    "title": "Advancing Knowledge Tracing by Exploring Follow-up Performance Trends",
    "title_es": "Advancing Knowledge Tracing by Exploring Follow-up Performance Trends",
    "url": "https://arxiv.org/abs/2508.08019",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08019v1 Announce Type: new \nAbstract: Intelligent Tutoring Systems (ITS), such as Massive Open Online Courses, offer new opportunities for human learning. At the core of such systems, knowledge tracing (KT) predicts students' future performance by analyzing their historical learning activities, enabling an accurate evaluation of students' knowledge states over time. We show that existing KT methods often encounter correlation conflicts when analyzing the relationships between historical learning sequences and future performance. To address such conflicts, we propose to extract so-called Follow-up Performance Trends (FPTs) from historical ITS data and to incorporate them into KT. We propose a method called Forward-Looking Knowledge Tracing (FINER) that combines historical learning sequences with FPTs to enhance student performance prediction accuracy. FINER constructs learning patterns that facilitate the retrieval of FPTs from historical ITS data in linear time; FINER includes a novel similarity-aware attention mechanism that aggregates FPTs based on both frequency and contextual similarity; and FINER offers means of combining FPTs and historical learning sequences to enable more accurate prediction of student future performance. Experiments on six real-world datasets show that FINER can outperform ten state-of-the-art KT methods, increasing accuracy by 8.74% to 84.85%.",
    "source": "arXiv"
  },
  {
    "title": "EchoAid: Enhancing Livestream Shopping Accessibility for the DHH Community",
    "title_es": "EchoAid: Enhancing Livestream Shopping Accessibility for the DHH Community",
    "url": "https://arxiv.org/abs/2508.08020",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08020v1 Announce Type: new \nAbstract: Livestream shopping platforms often overlook the accessibility needs of the Deaf and Hard of Hearing (DHH) community, leading to barriers such as information inaccessibility and overload. To tackle these challenges, we developed \\textit{EchoAid}, a mobile app designed to improve the livestream shopping experience for DHH users. \\textit{EchoAid} utilizes advanced speech-to-text conversion, Rapid Serial Visual Presentation (RSVP) technology, and Large Language Models (LLMs) to simplify the complex information flow in live sales environments. We conducted exploratory studies with eight DHH individuals to identify design needs and iteratively developed the \\textit{EchoAid} prototype based on feedback from three participants. We then evaluate the performance of this system in a user study workshop involving 38 DHH participants. Our findings demonstrate the successful design and validation process of \\textit{EchoAid}, highlighting its potential to enhance product information extraction, leading to reduced cognitive overload and more engaging and customized shopping experiences for DHH users.",
    "source": "arXiv"
  },
  {
    "title": "Optimizing Federated Learning for Scalable Power-demand Forecasting in Microgrids",
    "title_es": "Optimizing Federated Learning for Scalable Power-demand Forecasting in Microgrids",
    "url": "https://arxiv.org/abs/2508.08022",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08022v1 Announce Type: new \nAbstract: Real-time monitoring of power consumption in cities and micro-grids through the Internet of Things (IoT) can help forecast future demand and optimize grid operations. But moving all consumer-level usage data to the cloud for predictions and analysis at fine time scales can expose activity patterns. Federated Learning~(FL) is a privacy-sensitive collaborative DNN training approach that retains data on edge devices, trains the models on private data locally, and aggregates the local models in the cloud. But key challenges exist: (i) clients can have non-independently identically distributed~(non-IID) data, and (ii) the learning should be computationally cheap while scaling to 1000s of (unseen) clients. In this paper, we develop and evaluate several optimizations to FL training across edge and cloud for time-series demand forecasting in micro-grids and city-scale utilities using DNNs to achieve a high prediction accuracy while minimizing the training cost. We showcase the benefit of using exponentially weighted loss while training and show that it further improves the prediction of the final model. Finally, we evaluate these strategies by validating over 1000s of clients for three states in the US from the OpenEIA corpus, and performing FL both in a pseudo-distributed setting and a Pi edge cluster. The results highlight the benefits of the proposed methods over baselines like ARIMA and DNNs trained for individual consumers, which are not scalable.",
    "source": "arXiv"
  },
  {
    "title": "Multinode Shepard collocation method for pricing of financial derivatives",
    "title_es": "Multinode Shepard collocation method for pricing of financial derivatives",
    "url": "https://arxiv.org/abs/2508.08023",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08023v1 Announce Type: new \nAbstract: This paper explores the use of the multinode Shepard method for the numerical solution of the two-dimensional Black-Scholes equation. The proposed approach integrates a spatial approximation via the multinode Shepard operator with a temporal discretization based on the Backward Difference Formula. Numerical experiments are presented to demonstrate the accuracy and effectiveness of the method.",
    "source": "arXiv"
  },
  {
    "title": "Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches",
    "title_es": "Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches",
    "url": "https://arxiv.org/abs/2508.08027",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08027v1 Announce Type: new \nAbstract: Speech Recognition (ASR) due to phoneme distortions and high variability. While self-supervised ASR models like Wav2Vec, HuBERT, and Whisper have shown promise, their effectiveness in dysarthric speech remains unclear. This study systematically benchmarks these models with different decoding strategies, including CTC, seq2seq, and LLM-enhanced decoding (BART,GPT-2, Vicuna). Our contributions include (1) benchmarking ASR architectures for dysarthric speech, (2) introducing LLM-based decoding to improve intelligibility, (3) analyzing generalization across datasets, and (4) providing insights into recognition errors across severity levels. Findings highlight that LLM-enhanced decoding improves dysarthric ASR by leveraging linguistic constraints for phoneme restoration and grammatical correction.",
    "source": "arXiv"
  },
  {
    "title": "Mitigating Biases in Surgical Operating Rooms with Geometry",
    "title_es": "Mitigating Biases in Surgical Operating Rooms with Geometry",
    "url": "https://arxiv.org/abs/2508.08028",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08028v1 Announce Type: new \nAbstract: Deep neural networks are prone to learning spurious correlations, exploiting dataset-specific artifacts rather than meaningful features for prediction. In surgical operating rooms (OR), these manifest through the standardization of smocks and gowns that obscure robust identifying landmarks, introducing model bias for tasks related to modeling OR personnel. Through gradient-based saliency analysis on two public OR datasets, we reveal that CNN models succumb to such shortcuts, fixating on incidental visual cues such as footwear beneath surgical gowns, distinctive eyewear, or other role-specific identifiers. Avoiding such biases is essential for the next generation of intelligent assistance systems in the OR, which should accurately recognize personalized workflow traits, such as surgical skill level or coordination with other staff members. We address this problem by encoding personnel as 3D point cloud sequences, disentangling identity-relevant shape and motion patterns from appearance-based confounders. Our experiments demonstrate that while RGB and geometric methods achieve comparable performance on datasets with apparent simulation artifacts, RGB models suffer a 12% accuracy drop in realistic clinical settings with decreased visual diversity due to standardizations. This performance gap confirms that geometric representations capture more meaningful biometric features, providing an avenue to developing robust methods of modeling humans in the OR.",
    "source": "arXiv"
  },
  {
    "title": "Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks",
    "title_es": "Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks",
    "url": "https://arxiv.org/abs/2508.08029",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08029v1 Announce Type: new \nAbstract: The introduction of 5G and the Open Radio Access Network (O-RAN) architecture has enabled more flexible and intelligent network deployments. However, the increased complexity and openness of these architectures also introduce novel security challenges, such as data manipulation attacks on the semi-standardised Shared Data Layer (SDL) within the O-RAN platform through malicious xApps. In particular, malicious xApps can exploit this vulnerability by introducing subtle Unicode-wise alterations (hypoglyphs) into the data that are being used by traditional machine learning (ML)-based anomaly detection methods. These Unicode-wise manipulations can potentially bypass detection and cause failures in anomaly detection systems based on traditional ML, such as AutoEncoders, which are unable to process hypoglyphed data without crashing. We investigate the use of Large Language Models (LLMs) for anomaly detection within the O-RAN architecture to address this challenge. We demonstrate that LLM-based xApps maintain robust operational performance and are capable of processing manipulated messages without crashing. While initial detection accuracy requires further improvements, our results highlight the robustness of LLMs to adversarial attacks such as hypoglyphs in input data. There is potential to use their adaptability through prompt engineering to further improve the accuracy, although this requires further research. Additionally, we show that LLMs achieve low detection latency (under 0.07 seconds), making them suitable for Near-Real-Time (Near-RT) RIC deployments.",
    "source": "arXiv"
  },
  {
    "title": "IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning",
    "title_es": "IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning",
    "url": "https://arxiv.org/abs/2508.08031",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08031v1 Announce Type: new \nAbstract: Federated self-supervised learning (FSSL) combines the advantages of decentralized modeling and unlabeled representation learning, serving as a cutting-edge paradigm with strong potential for scalability and privacy preservation. Although FSSL has garnered increasing attention, research indicates that it remains vulnerable to backdoor attacks. Existing methods generally rely on visually obvious triggers, which makes it difficult to meet the requirements for stealth and practicality in real-world deployment. In this paper, we propose an imperceptible and effective backdoor attack method against FSSL, called IPBA. Our empirical study reveals that existing imperceptible triggers face a series of challenges in FSSL, particularly limited transferability, feature entanglement with augmented samples, and out-of-distribution properties. These issues collectively undermine the effectiveness and stealthiness of traditional backdoor attacks in FSSL. To overcome these challenges, IPBA decouples the feature distributions of backdoor and augmented samples, and introduces Sliced-Wasserstein distance to mitigate the out-of-distribution properties of backdoor samples, thereby optimizing the trigger generation process. Our experimental results on several FSSL scenarios and datasets show that IPBA significantly outperforms existing backdoor attack methods in performance and exhibits strong robustness under various defense mechanisms.",
    "source": "arXiv"
  },
  {
    "title": "Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles",
    "title_es": "Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles",
    "url": "https://arxiv.org/abs/2508.08034",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08034v1 Announce Type: new \nAbstract: Accurate power consumption prediction is crucial for improving efficiency and reducing environmental impact, yet traditional methods relying on specialized instruments or rigid physical models are impractical for large-scale, real-world deployment. This study introduces a scalable data-driven method using powertrain dynamic feature sets and both traditional machine learning and deep neural networks to estimate instantaneous and cumulative power consumption in internal combustion engine (ICE), electric vehicle (EV), and hybrid electric vehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with mean absolute error and root mean squared error on the order of $10^{-3}$, and cumulative errors under 3%. Transformer and long short-term memory models performed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%, respectively. Results confirm the approach's effectiveness across vehicles and models. Uncertainty analysis revealed greater variability in EV and HEV datasets than ICE, due to complex power management, emphasizing the need for robust models for advanced powertrains.",
    "source": "arXiv"
  },
  {
    "title": "Truthful Two-Obnoxious-Facility Location Games with Optional Preferences and Minimum Distance Constraint",
    "title_es": "Truthful Two-Obnoxious-Facility Location Games with Optional Preferences and Minimum Distance Constraint",
    "url": "https://arxiv.org/abs/2508.08036",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08036v1 Announce Type: new \nAbstract: In this paper, we study a truthful two-obnoxious-facility location problem, in which each agent has a private location in [0, 1] and a public optional preference over two obnoxious facilities, and there is a minimum distance constraint d between the two facilities. Each agent wants to be as far away as possible from the facilities that affect her, and the utility of each agent is the total distance from her to these facilities. The goal is to decide how to place the facilities in [0, 1] so as to incentivize agents to report their private locations truthfully as well as maximize the social utility. First, we consider the special setting where d = 0, that is, the two facilities can be located at any point in [0, 1]. We propose a deterministic strategyproof mechanism with approximation ratio of at most 4 and a randomized strategyproof mechanism with approximation ratio of at most 2, respectively. Then we study the general setting. We propose a deterministic strategyproof mechanism with approximation ratio of at most 8 and a randomized strategyproof mechanism with approximation ratio of at most 4, respectively. Furthermore, we provide lower bounds of 2 and 14/13 on the approximation ratio for any deterministic and any randomized strategyproof mechanism, respectively.",
    "source": "arXiv"
  },
  {
    "title": "TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation",
    "title_es": "TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation",
    "url": "https://arxiv.org/abs/2508.08038",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08038v1 Announce Type: new \nAbstract: Depth estimation, essential for autonomous driving, seeks to interpret the 3D environment surrounding vehicles. The development of radar sensors, known for their cost-efficiency and robustness, has spurred interest in radar-camera fusion-based solutions. However, existing algorithms fuse features from these modalities without accounting for weather conditions, despite radars being known to be more robust than cameras under adverse weather. Additionally, while Vision-Language models have seen rapid advancement, utilizing language descriptions alongside other modalities for depth estimation remains an open challenge. This paper first introduces a text-generation strategy along with feature extraction and fusion techniques that can assist monocular depth estimation pipelines, leading to improved accuracy across different algorithms on the KITTI dataset. Building on this, we propose TRIDE, a radar-camera fusion algorithm that enhances text feature extraction by incorporating radar point information. To address the impact of weather on sensor performance, we introduce a weather-aware fusion block that adaptively adjusts radar weighting based on current weather conditions. Our method, benchmarked on the nuScenes dataset, demonstrates performance gains over the state-of-the-art, achieving a 12.87% improvement in MAE and a 9.08% improvement in RMSE. Code: https://github.com/harborsarah/TRIDE",
    "source": "arXiv"
  },
  {
    "title": "Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning",
    "title_es": "Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.08039",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08039v1 Announce Type: new \nAbstract: Recent advancements in large language models, multimodal large language models, and large audio language models (LALMs) have significantly improved their reasoning capabilities through reinforcement learning with rule-based rewards. However, the explicit reasoning process has yet to show significant benefits for audio question answering, and effectively leveraging deep reasoning remains an open challenge, with LALMs still falling short of human-level auditory-language reasoning. To address these limitations, we propose Audio-Thinker, a reinforcement learning framework designed to enhance the reasoning capabilities of LALMs, with a focus on improving adaptability, consistency, and effectiveness. Our approach introduces an adaptive think accuracy reward, enabling the model to adjust its reasoning strategies based on task complexity dynamically. Furthermore, we incorporate an external reward model to evaluate the overall consistency and quality of the reasoning process, complemented by think-based rewards that help the model distinguish between valid and flawed reasoning paths during training. Experimental results demonstrate that our Audio-Thinker model outperforms existing reasoning-oriented LALMs across various benchmark tasks, exhibiting superior reasoning and generalization capabilities.",
    "source": "arXiv"
  },
  {
    "title": "BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models",
    "title_es": "BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models",
    "url": "https://arxiv.org/abs/2508.08040",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08040v1 Announce Type: new \nAbstract: Prompt-based tuning has emerged as a lightweight alternative to full fine-tuning in large vision-language models, enabling efficient adaptation via learned contextual prompts. This paradigm has recently been extended to federated learning settings (e.g., PromptFL), where clients collaboratively train prompts under data privacy constraints. However, the security implications of prompt-based aggregation in federated multimodal learning remain largely unexplored, leaving a critical attack surface unaddressed. In this paper, we introduce \\textbf{BadPromptFL}, the first backdoor attack targeting prompt-based federated learning in multimodal contrastive models. In BadPromptFL, compromised clients jointly optimize local backdoor triggers and prompt embeddings, injecting poisoned prompts into the global aggregation process. These prompts are then propagated to benign clients, enabling universal backdoor activation at inference without modifying model parameters. Leveraging the contextual learning behavior of CLIP-style architectures, BadPromptFL achieves high attack success rates (e.g., \\(>90\\%\\)) with minimal visibility and limited client participation. Extensive experiments across multiple datasets and aggregation protocols validate the effectiveness, stealth, and generalizability of our attack, raising critical concerns about the robustness of prompt-based federated learning in real-world deployments.",
    "source": "arXiv"
  },
  {
    "title": "Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation",
    "title_es": "Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation",
    "url": "https://arxiv.org/abs/2508.08042",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08042v1 Announce Type: new \nAbstract: Recommendation systems have faced significant challenges in cold-start scenarios, where new items with a limited history of interaction need to be effectively recommended to users. Though multimodal data (e.g., images, text, audio, etc.) offer rich information to address this issue, existing approaches often employ simplistic integration methods such as concatenation, average pooling, or fixed weighting schemes, which fail to capture the complex relationships between modalities. Our study proposes a novel Mixture of Experts (MoE) framework for multimodal cold-start recommendation, named MAMEX, which dynamically leverages latent representation from different modalities. MAMEX utilizes modality-specific expert networks and introduces a learnable gating mechanism that adaptively weights the contribution of each modality based on its content characteristics. This approach enables MAMEX to emphasize the most informative modalities for each item while maintaining robustness when certain modalities are less relevant or missing. Extensive experiments on benchmark datasets show that MAMEX outperforms state-of-the-art methods in cold-start scenarios, with superior accuracy and adaptability. For reproducibility, the code has been made available on Github https://github.com/L2R-UET/MAMEX.",
    "source": "arXiv"
  },
  {
    "title": "False Reality: Uncovering Sensor-induced Human-VR Interaction Vulnerability",
    "title_es": "False Reality: Uncovering Sensor-induced Human-VR Interaction Vulnerability",
    "url": "https://arxiv.org/abs/2508.08043",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08043v1 Announce Type: new \nAbstract: Virtual Reality (VR) techniques, serving as the bridge between the real and virtual worlds, have boomed and are widely used in manufacturing, remote healthcare, gaming, etc. Specifically, VR systems offer users immersive experiences that include both perceptions and actions. Various studies have demonstrated that attackers can manipulate VR software to influence users' interactions, including perception and actions. However, such attacks typically require strong access and specialized expertise. In this paper, we are the first to present a systematic analysis of physical attacks against VR systems and introduce False Reality, a new attack threat to VR devices without requiring access to or modification of their software. False Reality disturbs VR system services by tampering with sensor measurements, and further spoofing users' perception even inducing harmful actions, e.g., inducing dizziness or causing users to crash into obstacles, by exploiting perceptual and psychological effects. We formalize these threats through an attack pathway framework and validate three representative pathways via physical experiments and user studies on five commercial VR devices. Finally, we further propose a defense prototype to mitigate such threats. Our findings shall provide valuable insights for enhancing the security and resilience of future VR systems.",
    "source": "arXiv"
  },
  {
    "title": "Constrained Distributed Heterogeneous Two-Facility Location Problems with Max-Variant Cost",
    "title_es": "Constrained Distributed Heterogeneous Two-Facility Location Problems with Max-Variant Cost",
    "url": "https://arxiv.org/abs/2508.08045",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08045v1 Announce Type: new \nAbstract: We study a constrained distributed heterogeneous two-facility location problem, where a set of agents with private locations on the real line are divided into disjoint groups. The constraint means that the facilities can only be built in a given multiset of candidate locations and at most one facility can be built at each candidate location. Given the locations of the two facilities, the cost of an agent is the distance from her location to the farthest facility (referred to as max-variant). Our goal is to design strategyproof distributed mechanisms that can incentivize all agents to truthfully report their locations and approximately optimize some social objective. A distributed mechanism consists of two steps: for each group, the mechanism chooses two candidate locations as the representatives of the group based only on the locations reported by agents therein; then, it outputs two facility locations among all the representatives. We focus on a class of deterministic strategyproof distributed mechanisms and analyze upper and lower bounds on the distortion under the Average-of-Average cost (average of the average individual cost of agents in each group), the Max-of-Max cost (maximum individual cost among all agents), the Average-of-Max cost (average of the maximum individual cost among all agents in each group) and the Max-of-Average cost (maximum of the average individual cost of all agents in each group). Under four social objectives, we obtain constant upper and lower distortion bounds.",
    "source": "arXiv"
  },
  {
    "title": "Aerial Target Encirclement and Interception with Noisy Range Observations",
    "title_es": "Aerial Target Encirclement and Interception with Noisy Range Observations",
    "url": "https://arxiv.org/abs/2508.08046",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08046v1 Announce Type: new \nAbstract: This paper proposes a strategy to encircle and intercept a non-cooperative aerial point-mass moving target by leveraging noisy range measurements for state estimation. In this approach, the guardians actively ensure the observability of the target by using an anti-synchronization (AS), 3D ``vibrating string\" trajectory, which enables rapid position and velocity estimation based on the Kalman filter. Additionally, a novel anti-target controller is designed for the guardians to enable adaptive transitions from encircling a protected target to encircling, intercepting, and neutralizing a hostile target, taking into consideration the input constraints of the guardians. Based on the guaranteed uniform observability, the exponentially bounded stability of the state estimation error and the convergence of the encirclement error are rigorously analyzed. Simulation results and real-world UAV experiments are presented to further validate the effectiveness of the system design.",
    "source": "arXiv"
  },
  {
    "title": "S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix",
    "title_es": "S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix",
    "url": "https://arxiv.org/abs/2508.08048",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08048v1 Announce Type: new \nAbstract: While video generation models excel at producing high-quality monocular videos, generating 3D stereoscopic and spatial videos for immersive applications remains an underexplored challenge. We present a pose-free and training-free method that leverages an off-the-shelf monocular video generation model to produce immersive 3D videos. Our approach first warps the generated monocular video into pre-defined camera viewpoints using estimated depth information, then applies a novel \\textit{frame matrix} inpainting framework. This framework utilizes the original video generation model to synthesize missing content across different viewpoints and timestamps, ensuring spatial and temporal consistency without requiring additional model fine-tuning. Moreover, we develop a \\dualupdate~scheme that further improves the quality of video inpainting by alleviating the negative effects propagated from disoccluded areas in the latent space. The resulting multi-view videos are then adapted into stereoscopic pairs or optimized into 4D Gaussians for spatial video synthesis. We validate the efficacy of our proposed method by conducting experiments on videos from various generative models, such as Sora, Lumiere, WALT, and Zeroscope. The experiments demonstrate that our method has a significant improvement over previous methods. Project page at: https://daipengwa.github.io/S-2VG_ProjectPage/",
    "source": "arXiv"
  },
  {
    "title": "9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)",
    "title_es": "9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)",
    "url": "https://arxiv.org/abs/2508.08050",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08050v1 Announce Type: new \nAbstract: The Sign Language Translation and Avatar Technology (SLTAT) workshops continue a series of gatherings to share recent advances in improving deaf / human communication through non-invasive means. This 2025 edition, the 9th since its first appearance in 2011, is hosted by the International Conference on Intelligent Virtual Agents (IVA), giving the opportunity for contamination between two research communities, using digital humans as either virtual interpreters or as interactive conversational agents. As presented in this summary paper, SLTAT sees contributions beyond avatar technologies, with a consistent number of submissions on sign language recognition, and other work on data collection, data analysis, tools, ethics, usability, and affective computing.",
    "source": "arXiv"
  },
  {
    "title": "On Understanding of the Dynamics of Model Capacity in Continual Learning",
    "title_es": "On Understanding of the Dynamics of Model Capacity in Continual Learning",
    "url": "https://arxiv.org/abs/2508.08052",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08052v1 Announce Type: new \nAbstract: The stability-plasticity dilemma, closely related to a neural network's (NN) capacity-its ability to represent tasks-is a fundamental challenge in continual learning (CL). Within this context, we introduce CL's effective model capacity (CLEMC) that characterizes the dynamic behavior of the stability-plasticity balance point. We develop a difference equation to model the evolution of the interplay between the NN, task data, and optimization procedure. We then leverage CLEMC to demonstrate that the effective capacity-and, by extension, the stability-plasticity balance point is inherently non-stationary. We show that regardless of the NN architecture or optimization method, a NN's ability to represent new tasks diminishes when incoming task distributions differ from previous ones. We conduct extensive experiments to support our theoretical findings, spanning a range of architectures-from small feedforward network and convolutional networks to medium-sized graph neural networks and transformer-based large language models with millions of parameters.",
    "source": "arXiv"
  },
  {
    "title": "AdaptFlow: Adaptive Workflow Optimization via Meta-Learning",
    "title_es": "AdaptFlow: Adaptive Workflow Optimization via Meta-Learning",
    "url": "https://arxiv.org/abs/2508.08053",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08053v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have sparked growing interest in agentic workflows, which are structured sequences of LLM invocations intended to solve complex tasks. However, existing approaches often rely on static templates or manually designed workflows, which limit adaptability to diverse tasks and hinder scalability. We propose AdaptFlow, a natural language-based meta-learning framework inspired by model-agnostic meta-learning (MAML). AdaptFlow learns a generalizable workflow initialization that enables rapid subtask-level adaptation. It employs a bi-level optimization scheme: the inner loop refines the workflow for a specific subtask using LLM-generated feedback, while the outer loop updates the shared initialization to perform well across tasks. This setup allows AdaptFlow to generalize effectively to unseen tasks by adapting the initialized workflow through language-guided modifications. Evaluated across question answering, code generation, and mathematical reasoning benchmarks, AdaptFlow consistently outperforms both manually crafted and automatically searched baselines, achieving state-of-the-art results with strong generalization across tasks and models. The source code and data are available at https://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.",
    "source": "arXiv"
  },
  {
    "title": "TQL: Towards Type-Driven Data Discovery",
    "title_es": "TQL: Towards Type-Driven Data Discovery",
    "url": "https://arxiv.org/abs/2508.08054",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08054v1 Announce Type: new \nAbstract: Existing query languages for data discovery exhibit system-driven designs that emphasize database features and functionality over user needs. We propose a re-prioritization of the client through an introduction of a language-driven approach to data discovery systems that can leverage powerful results from programming languages research. In this paper, we describe TQL, a flexible and practical query language which incorporates a type-like system to encompass downstream transformation-context in its discovery queries. The syntax and semantics of TQL (including the underlying evaluation model), are formally defined, and a sketch of its implementation is also provided. Additionally, we provide comparisons to existing languages for data retrieval and data discovery to examine the advantages of TQL's expanded expressive power in real-life settings.",
    "source": "arXiv"
  },
  {
    "title": "PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI",
    "title_es": "PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI",
    "url": "https://arxiv.org/abs/2508.08058",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08058v1 Announce Type: new \nAbstract: Accelerating Magnetic Resonance Imaging (MRI) reduces scan time but often degrades image quality. While Implicit Neural Representations (INRs) show promise for MRI reconstruction, they struggle at high acceleration factors due to weak prior constraints, leading to structural loss and aliasing artefacts. To address this, we propose PrIINeR, an INR-based MRI reconstruction method that integrates prior knowledge from pre-trained deep learning models into the INR framework. By combining population-level knowledge with instance-based optimization and enforcing dual data consistency, PrIINeR aligns both with the acquired k-space data and the prior-informed reconstruction. Evaluated on the NYU fastMRI dataset, our method not only outperforms state-of-the-art INR-based approaches but also improves upon several learning-based state-of-the-art methods, significantly improving structural preservation and fidelity while effectively removing aliasing artefacts.PrIINeR bridges deep learning and INR-based techniques, offering a more reliable solution for high-quality, accelerated MRI reconstruction. The code is publicly available on https://github.com/multimodallearning/PrIINeR.",
    "source": "arXiv"
  },
  {
    "title": "From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations",
    "title_es": "From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations",
    "url": "https://arxiv.org/abs/2508.08061",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08061v1 Announce Type: new \nAbstract: Event logs reflect the behavior of business processes that are mapped in organizational information systems. Predictive process monitoring (PPM) transforms these data into value by creating process-related predictions that provide the insights required for proactive interventions at process runtime. Existing PPM techniques require sufficient amounts of event data or other relevant resources that might not be readily available, preventing some organizations from utilizing PPM. The transfer learning-based PPM technique presented in this paper allows organizations without suitable event data or other relevant resources to implement PPM for effective decision support. The technique is instantiated in two real-life use cases, based on which numerical experiments are performed using event logs for IT service management processes in an intra- and inter-organizational setting. The results of the experiments suggest that knowledge of one business process can be transferred to a similar business process in the same or a different organization to enable effective PPM in the target context. With the proposed technique, organizations can benefit from transfer learning in an intra- and inter-organizational setting, where resources like pre-trained models are transferred within and across organizational boundaries.",
    "source": "arXiv"
  },
  {
    "title": "On the Operational Resilience of CBDC: Threats and Prospects of Formal Validation for Offline Payments",
    "title_es": "On the Operational Resilience of CBDC: Threats and Prospects of Formal Validation for Offline Payments",
    "url": "https://arxiv.org/abs/2508.08064",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08064v1 Announce Type: new \nAbstract: Information and communication technologies are by now employed in most activities, including economics and finance. Despite the extraordinary power of modern computers and the vast amount of memory, some results of theoretical computer science imply the impossibility of certifying software quality in general. With the exception of safety-critical systems, this has primarily concerned the information processed by confined systems, with limited socio-economic consequences. In the emerging era of technologies for exchanging digital money and tokenized assets over the Internet - such as central bank digital currencies (CBDCs) - even a minor bug could trigger a financial collapse. Although the aforementioned impossibility results cannot be overcome in an absolute sense, there exist formal methods that can provide assertions of computing systems correctness. We advocate their use to validate the operational resilience of software infrastructures enabling CBDCs, with special emphasis on offline payments as they constitute a very critical issue.",
    "source": "arXiv"
  },
  {
    "title": "Investigating the Design Space of Visual Grounding in Multimodal Large Language Model",
    "title_es": "Investigating the Design Space of Visual Grounding in Multimodal Large Language Model",
    "url": "https://arxiv.org/abs/2508.08066",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08066v1 Announce Type: new \nAbstract: Fine-grained multimodal capability in Multimodal Large Language Models (MLLMs) has emerged as a critical research direction, particularly for tackling the visual grounding (VG) problem. Despite the strong performance achieved by existing approaches, they often employ disparate design choices when fine-tuning MLLMs for VG, lacking systematic verification to support these designs. To bridge this gap, this paper presents a comprehensive study of various design choices that impact the VG performance of MLLMs. We conduct our analysis using LLaVA-1.5, which has been widely adopted in prior empirical studies of MLLMs. While more recent models exist, we follow this convention to ensure our findings remain broadly applicable and extendable to other architectures. We cover two key aspects: (1) exploring different visual grounding paradigms in MLLMs, identifying the most effective design, and providing our insights; and (2) conducting ablation studies on the design of grounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our findings contribute to a stronger MLLM for VG, achieving improvements of +5.6% / +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.",
    "source": "arXiv"
  },
  {
    "title": "The univariate multinode Shepard method for the Caputo fractional derivatives: from Approximation to the solution of Bagley-Torvik equation",
    "title_es": "The univariate multinode Shepard method for the Caputo fractional derivatives: from Approximation to the solution of Bagley-Torvik equation",
    "url": "https://arxiv.org/abs/2508.08067",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08067v1 Announce Type: new \nAbstract: In this paper, we approximate the fractional derivative of a given function using the univariate multinode Shepard method through the Gauss-Jacobi quadrature formula. Subsequently, the proposed method is applied to the numerical solution of boundary value problems (BVPs) and initial value problems (IVPs), specifically addressing the Bagley-Torvik equations. Experimental results confirm the method's effectiveness, particularly in accurately approximating the Bagley-Torvik equation for both BVPs and IVPs.",
    "source": "arXiv"
  },
  {
    "title": "Fully-Fluctuating Participation in Sleepy Consensus",
    "title_es": "Fully-Fluctuating Participation in Sleepy Consensus",
    "url": "https://arxiv.org/abs/2508.08068",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08068v1 Announce Type: new \nAbstract: Proof-of-work allows Bitcoin to boast security amidst arbitrary fluctuations in participation of miners throughout time, so long as, at any point in time, a majority of hash power is honest. In recent years, however, the pendulum has shifted in favor of proof-of-stake-based consensus protocols. There, the sleepy model is the most prominent model for handling fluctuating participation of nodes. However, to date, no protocol in the sleepy model rivals Bitcoin in its robustness to drastic fluctuations in participation levels, with state-of-the-art protocols making various restrictive assumptions. In this work, we present a new adversary model, called external adversary. Intuitively, in our model, corrupt nodes do not divulge information about their secret keys. In this model, we show that protocols in the sleepy model can meaningfully claim to remain secure against fully fluctuating participation, without compromising efficiency or corruption resilience. Our adversary model is quite natural, and arguably naturally captures the process via which malicious behavior arises in protocols, as opposed to traditional worst-case modeling. On top of which, the model is also theoretically appealing, circumventing a barrier established in a recent work of Malkhi, Momose, and Ren.",
    "source": "arXiv"
  },
  {
    "title": "Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition",
    "title_es": "Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition",
    "url": "https://arxiv.org/abs/2508.08069",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08069v1 Announce Type: new \nAbstract: Multi-label classification (MLC) of medical images aims to identify multiple diseases and holds significant clinical potential. A critical step is to learn class-specific features for accurate diagnosis and improved interpretability effectively. However, current works focus primarily on causal attention to learn class-specific features, yet they struggle to interpret the true cause due to the inadvertent attention to class-irrelevant features. To address this challenge, we propose a new structural causal model (SCM) that treats class-specific attention as a mixture of causal, spurious, and noisy factors, and a novel Information Bottleneck-based Causal Attention (IBCA) that is capable of learning the discriminative class-specific attention for MLC of medical images. Specifically, we propose learning Gaussian mixture multi-label spatial attention to filter out class-irrelevant information and capture each class-specific attention pattern. Then a contrastive enhancement-based causal intervention is proposed to gradually mitigate the spurious attention and reduce noise information by aligning multi-head attention with the Gaussian mixture multi-label spatial. Quantitative and ablation results on Endo and MuReD show that IBCA outperforms all methods. Compared to the second-best results for each metric, IBCA achieves improvements of 6.35\\% in CR, 7.72\\% in OR, and 5.02\\% in mAP for MuReD, 1.47\\% in CR, and 1.65\\% in CF1, and 1.42\\% in mAP for Endo.",
    "source": "arXiv"
  },
  {
    "title": "C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction",
    "title_es": "C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction",
    "url": "https://arxiv.org/abs/2508.08071",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08071v1 Announce Type: new \nAbstract: Connecting an ever-expanding catalogue of products with suitable manufacturers and suppliers is critical for resilient, efficient global supply chains, yet traditional methods struggle to capture complex capabilities, certifications, geographic constraints, and rich multimodal data of real-world manufacturer profiles. To address these gaps, we introduce PMGraph, a public benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking 8,888 manufacturers, over 70k products, more than 110k manufacturer-product edges, and over 29k product images. Building on this benchmark, we propose the Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first aligns and aggregates textual and visual attributes into intermediate group embeddings, then propagates them through a manufacturer-product hetero-graph via multiscale message passing to enhance link prediction accuracy. C-MAG also provides practical guidelines for modality-aware fusion, preserving predictive performance in noisy, real-world settings.",
    "source": "arXiv"
  },
  {
    "title": "ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring",
    "title_es": "ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring",
    "url": "https://arxiv.org/abs/2508.08073",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08073v1 Announce Type: new \nAbstract: In electronic design automation, logic optimization operators play a crucial role in minimizing the gate count of logic circuits. However, their computation demands are high. Operators such as refactor conventionally form iterative cuts for each node, striving for a more compact representation - a task which often fails 98% on average. Prior research has sought to mitigate computational cost through parallelization. In contrast, our approach leverages a classifier to prune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis operations. Experiments on the refactor operator using the EPFL benchmark suite and 10 large industrial designs demonstrate that this technique can speedup logic optimization by 3.9x on average compared with the state-of-the-art ABC implementation.",
    "source": "arXiv"
  },
  {
    "title": "Towards General-Purpose Data Discovery: A Programming Languages Approach",
    "title_es": "Towards General-Purpose Data Discovery: A Programming Languages Approach",
    "url": "https://arxiv.org/abs/2508.08074",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08074v1 Announce Type: new \nAbstract: Efficient and effective data discovery is critical for many modern applications in machine learning and data science. One major bottleneck to the development of a general-purpose data discovery tool is the absence of an expressive formal language, and corresponding implementation, for characterizing and solving generic discovery queries. To this end, we present TQL, a domain-specific language for data discovery well-designed to leverage and exploit the results of programming languages research in both its syntax and semantics. In this paper, we fully and formally characterize the core language through an algebraic model, Imperative Relational Algebra with Types (ImpRAT), and implement a modular proof-of-concept system prototype.",
    "source": "arXiv"
  },
  {
    "title": "FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence",
    "title_es": "FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence",
    "url": "https://arxiv.org/abs/2508.08075",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08075v1 Announce Type: new \nAbstract: The Dempster-Shafer theory of evidence has been widely applied in the field of information fusion under uncertainty. Most existing research focuses on combining evidence within the same frame of discernment. However, in real-world scenarios, trained algorithms or data often originate from different regions or organizations, where data silos are prevalent. As a result, using different data sources or models to generate basic probability assignments may lead to heterogeneous frames, for which traditional fusion methods often yield unsatisfactory results. To address this challenge, this study proposes an open-world information fusion method, termed Full Negation Belief Transformation (FNBT), based on the Dempster-Shafer theory. More specially, a criterion is introduced to determine whether a given fusion task belongs to the open-world setting. Then, by extending the frames, the method can accommodate elements from heterogeneous frames. Finally, a full negation mechanism is employed to transform the mass functions, so that existing combination rules can be applied to the transformed mass functions for such information fusion. Theoretically, the proposed method satisfies three desirable properties, which are formally proven: mass function invariance, heritability, and essential conflict elimination. Empirically, FNBT demonstrates superior performance in pattern classification tasks on real-world datasets and successfully resolves Zadeh's counterexample, thereby validating its practical effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "Heterogeneity in Entity Matching: A Survey and Experimental Analysis",
    "title_es": "Heterogeneity in Entity Matching: A Survey and Experimental Analysis",
    "url": "https://arxiv.org/abs/2508.08076",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08076v1 Announce Type: new \nAbstract: Entity matching (EM) is a fundamental task in data integration and analytics, essential for identifying records that refer to the same real-world entity across diverse sources. In practice, datasets often differ widely in structure, format, schema, and semantics, creating substantial challenges for EM. We refer to this setting as Heterogeneous EM (HEM). This survey offers a unified perspective on HEM by introducing a taxonomy, grounded in prior work, that distinguishes two primary categories -- representation and semantic heterogeneity -- and their subtypes. The taxonomy provides a systematic lens for understanding how variations in data form and meaning shape the complexity of matching tasks. We then connect this framework to the FAIR principles -- Findability, Accessibility, Interoperability, and Reusability -- demonstrating how they both reveal the challenges of HEM and suggest strategies for mitigating them. Building on this foundation, we critically review recent EM methods, examining their ability to address different heterogeneity types, and conduct targeted experiments on state-of-the-art models to evaluate their robustness and adaptability under semantic heterogeneity. Our analysis uncovers persistent limitations in current approaches and points to promising directions for future research, including multimodal matching, human-in-the-loop workflows, deeper integration with large language models and knowledge graphs, and fairness-aware evaluation in heterogeneous settings.",
    "source": "arXiv"
  },
  {
    "title": "Sparsifying Cayley Graphs on Every Group",
    "title_es": "Sparsifying Cayley Graphs on Every Group",
    "url": "https://arxiv.org/abs/2508.08078",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08078v1 Announce Type: new \nAbstract: A classic result in graph theory, due to Batson, Spielman, and Srivastava (STOC 2009) shows that every graph admits a $(1 \\pm \\varepsilon)$ cut (or spectral) sparsifier which preserves only $O(n / \\varepsilon^2)$ reweighted edges. However, when applying this result to \\emph{Cayley graphs}, the resulting sparsifier is no longer necessarily a Cayley graph -- it can be an arbitrary subset of edges.\n  Thus, a recent line of inquiry, and one which has only seen minor progress, asks: for any group $G$, do all Cayley graphs over the group $G$ admit sparsifiers which preserve only $\\mathrm{polylog}(|G|)/\\varepsilon^2$ many re-weighted generators?\n  As our primary contribution, we answer this question in the affirmative, presenting a proof of the existence of such Cayley graph spectral sparsifiers, along with an efficient algorithm for finding them. Our algorithm even extends to \\emph{directed} Cayley graphs, if we instead ask only for cut sparsification instead of spectral sparsification.\n  We additionally study the sparsification of linear equations over non-abelian groups. In contrast to the abelian case, we show that for non-abelian valued equations, super-polynomially many linear equations must be preserved in order to approximately preserve the number of satisfied equations for any input. Together with our Cayley graph sparsification result, this provides a formal separation between Cayley graph sparsification and sparsifying linear equations.",
    "source": "arXiv"
  },
  {
    "title": "Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles",
    "title_es": "Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles",
    "url": "https://arxiv.org/abs/2508.08080",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08080v1 Announce Type: new \nAbstract: Symbolic Regression (SR) is a well-established framework for generating interpretable or white-box predictive models. Although SR has been successfully applied to create interpretable estimates of the average of the outcome, it is currently not well understood how it can be used to estimate the relationship between variables at other points in the distribution of the target variable. Such estimates of e.g. the median or an extreme value provide a fuller picture of how predictive variables affect the outcome and are necessary in high-stakes, safety-critical application domains. This study introduces Symbolic Quantile Regression (SQR), an approach to predict conditional quantiles with SR. In an extensive evaluation, we find that SQR outperforms transparent models and performs comparably to a strong black-box baseline without compromising transparency. We also show how SQR can be used to explain differences in the target distribution by comparing models that predict extreme and central outcomes in an airline fuel usage case study. We conclude that SQR is suitable for predicting conditional quantiles and understanding interesting feature influences at varying quantiles.",
    "source": "arXiv"
  },
  {
    "title": "ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness",
    "title_es": "ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness",
    "url": "https://arxiv.org/abs/2508.08082",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08082v1 Announce Type: new \nAbstract: Micro-expressions (MEs) are regarded as important indicators of an individual's intrinsic emotions, preferences, and tendencies. ME analysis requires spotting of ME intervals within long video sequences and recognition of their corresponding emotional categories. Previous deep learning approaches commonly employ sliding-window classification networks. However, the use of fixed window lengths and hard classification presents notable limitations in practice. Furthermore, these methods typically treat ME spotting and recognition as two separate tasks, overlooking the essential relationship between them. To address these challenges, this paper proposes two state space model-based architectures, namely ME-TST and ME-TST+, which utilize temporal state transition mechanisms to replace conventional window-level classification with video-level regression. This enables a more precise characterization of the temporal dynamics of MEs and supports the modeling of MEs with varying durations. In ME-TST+, we further introduce multi-granularity ROI modeling and the slowfast Mamba framework to alleviate information loss associated with treating ME analysis as a time-series task. Additionally, we propose a synergy strategy for spotting and recognition at both the feature and result levels, leveraging their intrinsic connection to enhance overall analysis performance. Extensive experiments demonstrate that the proposed methods achieve state-of-the-art performance. The codes are available at https://github.com/zizheng-guo/ME-TST.",
    "source": "arXiv"
  },
  {
    "title": "$100,000 or the Robot Gets it! Tech Workers' Resistance Guide: Tech Worker Actions, History, Risks, Impacts, and the Case for a Radical Flank",
    "title_es": "$100,000 or the Robot Gets it! Tech Workers' Resistance Guide: Tech Worker Actions, History, Risks, Impacts, and the Case for a Radical Flank",
    "url": "https://arxiv.org/abs/2508.08084",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08084v1 Announce Type: new \nAbstract: Over the past decade, Big Tech has faced increasing levels of worker activism. While worker actions have resulted in positive outcomes (e.g., cancellation of Google's Project Dragonfly), such successes have become increasingly infrequent. This is, in part, because corporations have adjusted their strategies to dealing with increased worker activism (e.g., increased retaliation against workers, and contracts clauses that prevent cancellation due to worker pressure). This change in company strategy prompts urgent questions about updating worker strategies for influencing corporate behavior in an industry with vast societal impact. Current discourse on tech worker activism often lacks empirical grounding regarding its scope, history, and strategic calculus. Our work seeks to bridge this gap by firstly conducting a systematic analysis of worker actions at Google and Microsoft reported in U.S. newspapers to delineate their characteristics. We then situate these actions within the long history of labour movements and demonstrate that, despite perceptions of radicalism, contemporary tech activism is comparatively moderate. Finally, we engage directly with current and former tech activists to provide a novel catalogue of potential worker actions, evaluating their perceived risks, impacts, and effectiveness (concurrently publishing \"Tech Workers' Guide to Resistance\"). Our findings highlight considerable variation in strategic thinking among activists themselves. We conclude by arguing that the establishment of a radical flank could increase the effectiveness of current movements.\n  \"Tech Workers' Guide to Resistance\" can be found at https://www.cs.toronto.edu/~msa/TechWorkersResistanceGuide.pdf or https://doi.org/10.5281/zenodo.16779082",
    "source": "arXiv"
  },
  {
    "title": "Matrix-3D: Omnidirectional Explorable 3D World Generation",
    "title_es": "Matrix-3D: Omnidirectional Explorable 3D World Generation",
    "url": "https://arxiv.org/abs/2508.08086",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08086v1 Announce Type: new \nAbstract: Explorable 3D world generation from a single image or text prompt forms a cornerstone of spatial intelligence. Recent works utilize video model to achieve wide-scope and generalizable 3D world generation. However, existing approaches often suffer from a limited scope in the generated scenes. In this work, we propose Matrix-3D, a framework that utilize panoramic representation for wide-coverage omnidirectional explorable 3D world generation that combines conditional video generation and panoramic 3D reconstruction. We first train a trajectory-guided panoramic video diffusion model that employs scene mesh renders as condition, to enable high-quality and geometrically consistent scene video generation. To lift the panorama scene video to 3D world, we propose two separate methods: (1) a feed-forward large panorama reconstruction model for rapid 3D scene reconstruction and (2) an optimization-based pipeline for accurate and detailed 3D scene reconstruction. To facilitate effective training, we also introduce the Matrix-Pano dataset, the first large-scale synthetic collection comprising 116K high-quality static panoramic video sequences with depth and trajectory annotations. Extensive experiments demonstrate that our proposed framework achieves state-of-the-art performance in panoramic video generation and 3D world generation. See more in https://matrix-3d.github.io.",
    "source": "arXiv"
  },
  {
    "title": "Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation",
    "title_es": "Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation",
    "url": "https://arxiv.org/abs/2508.08087",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08087v1 Announce Type: new \nAbstract: Reliable digital twins of lithium-ion batteries must achieve high physical fidelity with sub-millisecond speed. In this work, we benchmark three operator-learning surrogates for the Single Particle Model (SPM): Deep Operator Networks (DeepONets), Fourier Neural Operators (FNOs) and a newly proposed parameter-embedded Fourier Neural Operator (PE-FNO), which conditions each spectral layer on particle radius and solid-phase diffusivity. Models are trained on simulated trajectories spanning four current families (constant, triangular, pulse-train, and Gaussian-random-field) and a full range of State-of-Charge (SOC) (0 % to 100 %). DeepONet accurately replicates constant-current behaviour but struggles with more dynamic loads. The basic FNO maintains mesh invariance and keeps concentration errors below 1 %, with voltage mean-absolute errors under 1.7 mV across all load types. Introducing parameter embedding marginally increases error, but enables generalisation to varying radii and diffusivities. PE-FNO executes approximately 200 times faster than a 16-thread SPM solver. Consequently, PE-FNO's capabilities in inverse tasks are explored in a parameter estimation task with Bayesian optimisation, recovering anode and cathode diffusivities with 1.14 % and 8.4 % mean absolute percentage error, respectively, and 0.5918 percentage points higher error in comparison with classical methods. These results pave the way for neural operators to meet the accuracy, speed and parametric flexibility demands of real-time battery management, design-of-experiments and large-scale inference. PE-FNO outperforms conventional neural surrogates, offering a practical path towards high-speed and high-fidelity electrochemical digital twins.",
    "source": "arXiv"
  },
  {
    "title": "HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches",
    "title_es": "HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches",
    "url": "https://arxiv.org/abs/2508.08088",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08088v1 Announce Type: new \nAbstract: Recently, large reasoning models have demonstrated strong mathematical and coding abilities, and deep search leverages their reasoning capabilities in challenging information retrieval tasks. Existing deep search works are generally limited to a single knowledge source, either local or the Web. However, enterprises often require private deep search systems that can leverage search tools over both local and the Web corpus. Simply training an agent equipped with multiple search tools using flat reinforcement learning (RL) is a straightforward idea, but it has problems such as low training data efficiency and poor mastery of complex tools. To address the above issue, we propose a hierarchical agentic deep search framework, HierSearch, trained with hierarchical RL. At the low level, a local deep search agent and a Web deep search agent are trained to retrieve evidence from their corresponding domains. At the high level, a planner agent coordinates low-level agents and provides the final answer. Moreover, to prevent direct answer copying and error propagation, we design a knowledge refiner that filters out hallucinations and irrelevant evidence returned by low-level agents. Experiments show that HierSearch achieves better performance compared to flat RL, and outperforms various deep search and multi-source retrieval-augmented generation baselines in six benchmarks across general, finance, and medical domains.",
    "source": "arXiv"
  },
  {
    "title": "Growing Reservoirs with Developmental Graph Cellular Automata",
    "title_es": "Growing Reservoirs with Developmental Graph Cellular Automata",
    "url": "https://arxiv.org/abs/2508.08091",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08091v1 Announce Type: new \nAbstract: Developmental Graph Cellular Automata (DGCA) are a novel model for morphogenesis, capable of growing directed graphs from single-node seeds. In this paper, we show that DGCAs can be trained to grow reservoirs. Reservoirs are grown with two types of targets: task-driven (using the NARMA family of tasks) and task-independent (using reservoir metrics).\n  Results show that DGCAs are able to grow into a variety of specialized, life-like structures capable of effectively solving benchmark tasks, statistically outperforming `typical' reservoirs on the same task. Overall, these lay the foundation for the development of DGCA systems that produce plastic reservoirs and for modeling functional, adaptive morphogenesis.",
    "source": "arXiv"
  },
  {
    "title": "MDD-Net: Multimodal Depression Detection through Mutual Transformer",
    "title_es": "MDD-Net: Multimodal Depression Detection through Mutual Transformer",
    "url": "https://arxiv.org/abs/2508.08093",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08093v1 Announce Type: new \nAbstract: Depression is a major mental health condition that severely impacts the emotional and physical well-being of individuals. The simple nature of data collection from social media platforms has attracted significant interest in properly utilizing this information for mental health research. A Multimodal Depression Detection Network (MDD-Net), utilizing acoustic and visual data obtained from social media networks, is proposed in this work where mutual transformers are exploited to efficiently extract and fuse multimodal features for efficient depression detection. The MDD-Net consists of four core modules: an acoustic feature extraction module for retrieving relevant acoustic attributes, a visual feature extraction module for extracting significant high-level patterns, a mutual transformer for computing the correlations among the generated features and fusing these features from multiple modalities, and a detection layer for detecting depression using the fused feature representations. The extensive experiments are performed using the multimodal D-Vlog dataset, and the findings reveal that the developed multimodal depression detection network surpasses the state-of-the-art by up to 17.37% for F1-Score, demonstrating the greater performance of the proposed system. The source code is accessible at https://github.com/rezwanh001/Multimodal-Depression-Detection.",
    "source": "arXiv"
  },
  {
    "title": "3D Plant Root Skeleton Detection and Extraction",
    "title_es": "3D Plant Root Skeleton Detection and Extraction",
    "url": "https://arxiv.org/abs/2508.08094",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08094v1 Announce Type: new \nAbstract: Plant roots typically exhibit a highly complex and dense architecture, incorporating numerous slender lateral roots and branches, which significantly hinders the precise capture and modeling of the entire root system. Additionally, roots often lack sufficient texture and color information, making it difficult to identify and track root traits using visual methods. Previous research on roots has been largely confined to 2D studies; however, exploring the 3D architecture of roots is crucial in botany. Since roots grow in real 3D space, 3D phenotypic information is more critical for studying genetic traits and their impact on root development. We have introduced a 3D root skeleton extraction method that efficiently derives the 3D architecture of plant roots from a few images. This method includes the detection and matching of lateral roots, triangulation to extract the skeletal structure of lateral roots, and the integration of lateral and primary roots. We developed a highly complex root dataset and tested our method on it. The extracted 3D root skeletons showed considerable similarity to the ground truth, validating the effectiveness of the model. This method can play a significant role in automated breeding robots. Through precise 3D root structure analysis, breeding robots can better identify plant phenotypic traits, especially root structure and growth patterns, helping practitioners select seeds with superior root systems. This automated approach not only improves breeding efficiency but also reduces manual intervention, making the breeding process more intelligent and efficient, thus advancing modern agriculture.",
    "source": "arXiv"
  },
  {
    "title": "Dual Information Speech Language Models for Emotional Conversations",
    "title_es": "Dual Information Speech Language Models for Emotional Conversations",
    "url": "https://arxiv.org/abs/2508.08095",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08095v1 Announce Type: new \nAbstract: Conversational systems relying on text-based large language models (LLMs) often overlook paralinguistic cues, essential for understanding emotions and intentions. Speech-language models (SLMs), which use speech as input, are emerging as a promising solution. However, SLMs built by extending frozen LLMs struggle to capture paralinguistic information and exhibit reduced context understanding. We identify entangled information and improper training strategies as key issues. To address these issues, we propose two heterogeneous adapters and suggest a weakly supervised training strategy. Our approach disentangles paralinguistic and linguistic information, enabling SLMs to interpret speech through structured representations. It also preserves contextual understanding by avoiding the generation of task-specific vectors through controlled randomness. This approach trains only the adapters on common datasets, ensuring parameter and data efficiency. Experiments demonstrate competitive performance in emotional conversation tasks, showcasing the model's ability to effectively integrate both paralinguistic and linguistic information within contextual settings.",
    "source": "arXiv"
  },
  {
    "title": "Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?",
    "title_es": "Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?",
    "url": "https://arxiv.org/abs/2508.08096",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08096v1 Announce Type: new \nAbstract: Recent advancements in Large Language Models (LLMs) and their increased accessibility have made it easier than ever for students to automatically generate texts, posing new challenges for educational institutions. To enforce norms of academic integrity and ensure students' learning, learning analytics methods to automatically detect LLM-generated text appear increasingly appealing. This paper benchmarks the performance of different state-of-the-art detectors in educational contexts, introducing a novel dataset, called Generative Essay Detection in Education (GEDE), containing over 900 student-written essays and over 12,500 LLM-generated essays from various domains. To capture the diversity of LLM usage practices in generating text, we propose the concept of contribution levels, representing students' contribution to a given assignment. These levels range from purely human-written texts, to slightly LLM-improved versions, to fully LLM-generated texts, and finally to active attacks on the detector by \"humanizing\" generated texts. We show that most detectors struggle to accurately classify texts of intermediate student contribution levels, like LLM-improved human-written texts. Detectors are particularly likely to produce false positives, which is problematic in educational settings where false suspicions can severely impact students' lives. Our dataset, code, and additional supplementary materials are publicly available at https://github.com/lukasgehring/Assessing-LLM-Text-Detection-in-Educational-Contexts.",
    "source": "arXiv"
  },
  {
    "title": "TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning",
    "title_es": "TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning",
    "url": "https://arxiv.org/abs/2508.08098",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08098v1 Announce Type: new \nAbstract: This paper introduces TBAC-UniImage, a novel unified model for multimodal understanding and generation. We achieve this by deeply integrating a pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal Large Language Model (MLLM). Previous diffusion-based unified models face two primary limitations. One approach uses only the MLLM's final hidden state as the generative condition. This creates a shallow connection, as the generator is isolated from the rich, hierarchical representations within the MLLM's intermediate layers. The other approach, pretraining a unified generative architecture from scratch, is computationally expensive and prohibitive for many researchers. To overcome these issues, our work explores a new paradigm. Instead of relying on a single output, we use representations from multiple, diverse layers of the MLLM as generative conditions for the diffusion model. This method treats the pre-trained generator as a ladder, receiving guidance from various depths of the MLLM's understanding process. Consequently, TBAC-UniImage achieves a much deeper and more fine-grained unification of understanding and generation.",
    "source": "arXiv"
  },
  {
    "title": "Random Modulation: Achieving Asymptotic Replica Optimality over Arbitrary Norm-Bounded and Spectrally Convergent Channel Matrices",
    "title_es": "Random Modulation: Achieving Asymptotic Replica Optimality over Arbitrary Norm-Bounded and Spectrally Convergent Channel Matrices",
    "url": "https://arxiv.org/abs/2508.08099",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08099v1 Announce Type: new \nAbstract: This paper introduces a random modulation technique that is decoupled from the channel matrix, allowing it to be applied to arbitrary norm-bounded and spectrally convergent channel matrices. The proposed random modulation constructs an equivalent dense and random channel matrix, ensuring that the signals undergo sufficient statistical channel fading. It also guarantees the asymptotic replica maximum a posteriori (MAP) bit-error rate (BER) optimality of approximate message passing (AMP)-type detectors for linear systems with arbitrary norm-bounded and spectrally convergent channel matrices when their state evolution has a unique fixed point. Then, a low-complexity cross-domain memory approximate message passing (CD-MAMP) detector is proposed for random modulation, leveraging the sparsity of the time-domain channel and the randomness of the random transform-domain channel. Furthermore, the optimal power allocation schemes are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random-modulated linear systems, assuming the availability of channel state information (CSI) at the transceiver. Numerical results show that the proposed random modulation can achieve BER and block-error rate (BLER) performance gains of up to 2 - 3 dB compared to existing OFDM/OTFS/AFDM with 5G-NR LDPC codes, under both average and optimized power allocation.",
    "source": "arXiv"
  },
  {
    "title": "Grid2Guide: A* Enabled Small Language Model for Indoor Navigation",
    "title_es": "Grid2Guide: A* Enabled Small Language Model for Indoor Navigation",
    "url": "https://arxiv.org/abs/2508.08100",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08100v1 Announce Type: new \nAbstract: Reliable indoor navigation remains a significant challenge in complex environments, particularly where external positioning signals and dedicated infrastructures are unavailable. This research presents Grid2Guide, a hybrid navigation framework that combines the A* search algorithm with a Small Language Model (SLM) to generate clear, human-readable route instructions. The framework first conducts a binary occupancy matrix from a given indoor map. Using this matrix, the A* algorithm computes the optimal path between origin and destination, producing concise textual navigation steps. These steps are then transformed into natural language instructions by the SLM, enhancing interpretability for end users. Experimental evaluations across various indoor scenarios demonstrate the method's effectiveness in producing accurate and timely navigation guidance. The results validate the proposed approach as a lightweight, infrastructure-free solution for real-time indoor navigation support.",
    "source": "arXiv"
  },
  {
    "title": "ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience",
    "title_es": "ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience",
    "url": "https://arxiv.org/abs/2508.08101",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08101v1 Announce Type: new \nAbstract: Studies on in-vehicle conversational agents have traditionally relied on pre-scripted prompts or limited voice commands, constraining natural driver-agent interaction. To resolve this issue, the present study explored the potential of a ChatGPT-based in-vehicle agent capable of carrying continuous, multi-turn dialogues. Forty drivers participated in our experiment using a motion-based driving simulator, comparing three conditions (No agent, Pre-scripted agent, and ChatGPT-based agent) as a within-subjects variable. Results showed that the ChatGPT-based agent condition led to more stable driving performance across multiple metrics. Participants demonstrated lower variability in longitudinal acceleration, lateral acceleration, and lane deviation compared to the other two conditions. In subjective evaluations, the ChatGPT-based agent also received significantly higher ratings in competence, animacy, affective trust, and preference compared to the Pre-scripted agent. Our thematic analysis of driver-agent conversations revealed diverse interaction patterns in topics, including driving assistance/questions, entertainment requests, and anthropomorphic interactions. Our results highlight the potential of LLM-powered in-vehicle conversational agents to enhance driving safety and user experience through natural, context-rich interactions.",
    "source": "arXiv"
  },
  {
    "title": "Hyperspectral Imaging",
    "title_es": "Hyperspectral Imaging",
    "url": "https://arxiv.org/abs/2508.08107",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08107v1 Announce Type: new \nAbstract: Hyperspectral imaging (HSI) is an advanced sensing modality that simultaneously captures spatial and spectral information, enabling non-invasive, label-free analysis of material, chemical, and biological properties. This Primer presents a comprehensive overview of HSI, from the underlying physical principles and sensor architectures to key steps in data acquisition, calibration, and correction. We summarize common data structures and highlight classical and modern analysis methods, including dimensionality reduction, classification, spectral unmixing, and AI-driven techniques such as deep learning. Representative applications across Earth observation, precision agriculture, biomedicine, industrial inspection, cultural heritage, and security are also discussed, emphasizing HSI's ability to uncover sub-visual features for advanced monitoring, diagnostics, and decision-making. Persistent challenges, such as hardware trade-offs, acquisition variability, and the complexity of high-dimensional data, are examined alongside emerging solutions, including computational imaging, physics-informed modeling, cross-modal fusion, and self-supervised learning. Best practices for dataset sharing, reproducibility, and metadata documentation are further highlighted to support transparency and reuse. Looking ahead, we explore future directions toward scalable, real-time, and embedded HSI systems, driven by sensor miniaturization, self-supervised learning, and foundation models. As HSI evolves into a general-purpose, cross-disciplinary platform, it holds promise for transformative applications in science, technology, and society.",
    "source": "arXiv"
  },
  {
    "title": "Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain",
    "title_es": "Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain",
    "url": "https://arxiv.org/abs/2508.08108",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08108v1 Announce Type: new \nAbstract: It is a challenging task for ground robots to autonomously navigate in harsh environments due to the presence of non-trivial obstacles and uneven terrain. This requires trajectory planning that balances safety and efficiency. The primary challenge is to generate a feasible trajectory that prevents robot from tip-over while ensuring effective navigation. In this paper, we propose a capsizing-aware trajectory planner (CAP) to achieve trajectory planning on the uneven terrain. The tip-over stability of the robot on rough terrain is analyzed. Based on the tip-over stability, we define the traversable orientation, which indicates the safe range of robot orientations. This orientation is then incorporated into a capsizing-safety constraint for trajectory optimization. We employ a graph-based solver to compute a robust and feasible trajectory while adhering to the capsizing-safety constraint. Extensive simulation and real-world experiments validate the effectiveness and robustness of the proposed method. The results demonstrate that CAP outperforms existing state-of-the-art approaches, providing enhanced navigation performance on uneven terrains.",
    "source": "arXiv"
  },
  {
    "title": "Iterative refinement, not training objective, makes HuBERT behave differently from wav2vec 2.0",
    "title_es": "Iterative refinement, not training objective, makes HuBERT behave differently from wav2vec 2.0",
    "url": "https://arxiv.org/abs/2508.08110",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08110v1 Announce Type: new \nAbstract: Self-supervised models for speech representation learning now see widespread use for their versatility and performance on downstream tasks, but the effect of model architecture on the linguistic information learned in their representations remains under-studied. This study investigates two such models, HuBERT and wav2vec 2.0, and minimally compares two of their architectural differences: training objective and iterative pseudo-label refinement through multiple training iterations. We find that differences in canonical correlation of hidden representations to word identity, phoneme identity, and speaker identity are explained by training iteration, not training objective. We suggest that future work investigate the reason for the effectiveness of iterative refinement in encoding linguistic information in self-supervised speech representations.",
    "source": "arXiv"
  },
  {
    "title": "AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies",
    "title_es": "AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies",
    "url": "https://arxiv.org/abs/2508.08113",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08113v1 Announce Type: new \nAbstract: In this paper, we propose AimBot, a lightweight visual augmentation technique that provides explicit spatial cues to improve visuomotor policy learning in robotic manipulation. AimBot overlays shooting lines and scope reticles onto multi-view RGB images, offering auxiliary visual guidance that encodes the end-effector's state. The overlays are computed from depth images, camera extrinsics, and the current end-effector pose, explicitly conveying spatial relationships between the gripper and objects in the scene. AimBot incurs minimal computational overhead (less than 1 ms) and requires no changes to model architectures, as it simply replaces original RGB images with augmented counterparts. Despite its simplicity, our results show that AimBot consistently improves the performance of various visuomotor policies in both simulation and real-world settings, highlighting the benefits of spatially grounded visual feedback.",
    "source": "arXiv"
  },
  {
    "title": "TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork",
    "title_es": "TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork",
    "url": "https://arxiv.org/abs/2508.08115",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08115v1 Announce Type: new \nAbstract: We present TeamMedAgents, a novel multi-agent approach that systematically integrates evidence-based teamwork components from human-human collaboration into medical decision-making with large language models (LLMs). Our approach validates an organizational psychology teamwork model from human collaboration to computational multi-agent medical systems by operationalizing six core teamwork components derived from Salas et al.'s \"Big Five\" model: team leadership, mutual performance monitoring, team orientation, shared mental models, closed-loop communication, and mutual trust. We implement and evaluate these components as modular, configurable mechanisms within an adaptive collaboration architecture while assessing the effect of the number of agents involved based on the task's requirements and domain. Systematic evaluation of computational implementations of teamwork behaviors across eight medical benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets, Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8 evaluated datasets. Controlled ablation studies conducted on 50 questions per configuration across 3 independent runs provide mechanistic insights into individual component contributions, revealing optimal teamwork configurations that vary by reasoning task complexity and domain-specific requirements. Our ablation analyses reveal dataset-specific optimal teamwork configurations, indicating that different medical reasoning modalities benefit from distinct collaborative patterns. TeamMedAgents represents an advancement in collaborative AI by providing a systematic translation of established teamwork theories from human collaboration into agentic collaboration, establishing a foundation for evidence-based multi-agent system design in critical decision-making domains.",
    "source": "arXiv"
  },
  {
    "title": "GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking",
    "title_es": "GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking",
    "url": "https://arxiv.org/abs/2508.08117",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08117v1 Announce Type: new \nAbstract: Multi-object tracking (MOT) in monocular videos is fundamentally challenged by occlusions and depth ambiguity, issues that conventional tracking-by-detection (TBD) methods struggle to resolve owing to a lack of geometric awareness. To address these limitations, we introduce GRASPTrack, a novel depth-aware MOT framework that integrates monocular depth estimation and instance segmentation into a standard TBD pipeline to generate high-fidelity 3D point clouds from 2D detections, thereby enabling explicit 3D geometric reasoning. These 3D point clouds are then voxelized to enable a precise and robust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To further enhance tracking robustness, our approach incorporates Depth-aware Adaptive Noise Compensation, which dynamically adjusts the Kalman filter process noise based on occlusion severity for more reliable state estimation. Additionally, we propose a Depth-enhanced Observation-Centric Momentum, which extends the motion direction consistency from the image plane into 3D space to improve motion-based association cues, particularly for objects with complex trajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack benchmarks demonstrate that our method achieves competitive performance, significantly improving tracking robustness in complex scenes with frequent occlusions and intricate motion patterns.",
    "source": "arXiv"
  },
  {
    "title": "Vision-Based Localization and LLM-based Navigation for Indoor Environments",
    "title_es": "Vision-Based Localization and LLM-based Navigation for Indoor Environments",
    "url": "https://arxiv.org/abs/2508.08120",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08120v1 Announce Type: new \nAbstract: Indoor navigation remains a complex challenge due to the absence of reliable GPS signals and the architectural intricacies of large enclosed environments. This study presents an indoor localization and navigation approach that integrates vision-based localization with large language model (LLM)-based navigation. The localization system utilizes a ResNet-50 convolutional neural network fine-tuned through a two-stage process to identify the user's position using smartphone camera input. To complement localization, the navigation module employs an LLM, guided by a carefully crafted system prompt, to interpret preprocessed floor plan images and generate step-by-step directions. Experimental evaluation was conducted in a realistic office corridor with repetitive features and limited visibility to test localization robustness. The model achieved high confidence and an accuracy of 96% across all tested waypoints, even under constrained viewing conditions and short-duration queries. Navigation tests using ChatGPT on real building floor maps yielded an average instruction accuracy of 75%, with observed limitations in zero-shot reasoning and inference time. This research demonstrates the potential for scalable, infrastructure-free indoor navigation using off-the-shelf cameras and publicly available floor plans, particularly in resource-constrained settings like hospitals, airports, and educational institutions.",
    "source": "arXiv"
  },
  {
    "title": "MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing",
    "title_es": "MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing",
    "url": "https://arxiv.org/abs/2508.08122",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08122v1 Announce Type: new \nAbstract: Knowledge Tracing (KT) is committed to capturing students' knowledge mastery from their historical interactions. Simulating students' memory states is a promising approach to enhance both the performance and interpretability of knowledge tracing models. Memory consists of three fundamental processes: encoding, storage, and retrieval. Although forgetting primarily manifests during the storage stage, most existing studies rely on a single, undifferentiated forgetting mechanism, overlooking other memory processes as well as personalized forgetting patterns. To address this, this paper proposes memoryKT, a knowledge tracing model based on a novel temporal variational autoencoder. The model simulates memory dynamics through a three-stage process: (i) Learning the distribution of students' knowledge memory features, (ii) Reconstructing their exercise feedback, while (iii) Embedding a personalized forgetting module within the temporal workflow to dynamically modulate memory storage strength. This jointly models the complete encoding-storage-retrieval cycle, significantly enhancing the model's perception capability for individual differences. Extensive experiments on four public datasets demonstrate that our proposed approach significantly outperforms state-of-the-art baselines.",
    "source": "arXiv"
  },
  {
    "title": "A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images",
    "title_es": "A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images",
    "url": "https://arxiv.org/abs/2508.08123",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08123v1 Announce Type: new \nAbstract: We propose a deep learning-based approach that integrates MRI sequence parameters to improve the accuracy and generalizability of quantitative image synthesis from clinical weighted MRI. Our physics-driven neural network embeds MRI sequence parameters -- repetition time (TR), echo time (TE), and inversion time (TI) -- directly into the model via parameter embedding, enabling the network to learn the underlying physical principles of MRI signal formation. The model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as input and synthesizes T1, T2, and proton density (PD) quantitative maps. Trained on healthy brain MR images, it was evaluated on both internal and external test datasets. The proposed method achieved high performance with PSNR values exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter maps. It outperformed conventional deep learning models in accuracy and robustness, including data with previously unseen brain structures and lesions. Notably, our model accurately synthesized quantitative maps for these unseen pathological regions, highlighting its superior generalization capability. Incorporating MRI sequence parameters via parameter embedding allows the neural network to better learn the physical characteristics of MR signals, significantly enhancing the performance and reliability of quantitative MRI synthesis. This method shows great potential for accelerating qMRI and improving its clinical utility.",
    "source": "arXiv"
  },
  {
    "title": "NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection",
    "title_es": "NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection",
    "url": "https://arxiv.org/abs/2508.08124",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08124v1 Announce Type: new \nAbstract: Large-scale models pre-trained on Electroencephalography (EEG) have shown promise in clinical applications such as neurological disorder detection. However, the practical deployment of EEG-based large-scale models faces critical challenges such as limited labeled EEG data and suboptimal performance in clinical scenarios. To address these issues, we propose NeuroDx-LM, a novel large-scale model specifically designed for detecting EEG-based neurological disorders. Our key contributions include (i) a Selective Temporal-Frequency Embedding mechanism that adaptively captures complex temporal and spectral patterns in EEG signals; and (ii) a Progressive Feature-Aware Training strategy that refines feature representation in a two-stage process. In the first stage, our model learns the fundamental discriminative features of EEG activities; in the second stage, the model further extracts more specialized fine-grained features for accurate diagnostic performance. We evaluated NeuroDx-LM on the CHB-MIT and Schizophrenia datasets, achieving state-of-the-art performance in EEG-based seizure and schizophrenia detection, respectively. These results demonstrate the great potential of EEG-based large-scale models to advance clinical applicability. Our code is available at https://github.com/LetItBe12345/NeuroDx-LM.",
    "source": "arXiv"
  },
  {
    "title": "Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks",
    "title_es": "Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks",
    "url": "https://arxiv.org/abs/2508.08125",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08125v1 Announce Type: new \nAbstract: In this paper, we introduce a novel Czech dataset for aspect-based sentiment analysis (ABSA), which consists of 3.1K manually annotated reviews from the restaurant domain. The dataset is built upon the older Czech dataset, which contained only separate labels for the basic ABSA tasks such as aspect term extraction or aspect polarity detection. Unlike its predecessor, our new dataset is specifically designed for more complex tasks, e.g. target-aspect-category detection. These advanced tasks require a unified annotation format, seamlessly linking sentiment elements (labels) together. Our dataset follows the format of the well-known SemEval-2016 datasets. This design choice allows effortless application and evaluation in cross-lingual scenarios, ultimately fostering cross-language comparisons with equivalent counterpart datasets in other languages. The annotation process engaged two trained annotators, yielding an impressive inter-annotator agreement rate of approximately 90%. Additionally, we provide 24M reviews without annotations suitable for unsupervised learning. We present robust monolingual baseline results achieved with various Transformer-based models and insightful error analysis to supplement our contributions. Our code and dataset are freely available for non-commercial research purposes.",
    "source": "arXiv"
  },
  {
    "title": "OFAL: An Oracle-Free Active Learning Framework",
    "title_es": "OFAL: An Oracle-Free Active Learning Framework",
    "url": "https://arxiv.org/abs/2508.08126",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08126v1 Announce Type: new \nAbstract: In the active learning paradigm, using an oracle to label data has always been a complex and expensive task, and with the emersion of large unlabeled data pools, it would be highly beneficial If we could achieve better results without relying on an oracle. This research introduces OFAL, an oracle-free active learning scheme that utilizes neural network uncertainty. OFAL uses the model's own uncertainty to transform highly confident unlabeled samples into informative uncertain samples. First, we start with separating and quantifying different parts of uncertainty and introduce Monte Carlo Dropouts as an approximation of the Bayesian Neural Network model. Secondly, by adding a variational autoencoder, we go on to generate new uncertain samples by stepping toward the uncertain part of latent space starting from a confidence seed sample. By generating these new informative samples, we can perform active learning and enhance the model's accuracy. Lastly, we try to compare and integrate our method with other widely used active learning sampling methods.",
    "source": "arXiv"
  },
  {
    "title": "BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks",
    "title_es": "BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks",
    "url": "https://arxiv.org/abs/2508.08127",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08127v1 Announce Type: new \nAbstract: The security of LLM-based multi-agent systems (MAS) is critically threatened by propagation vulnerability, where malicious agents can distort collective decision-making through inter-agent message interactions. While existing supervised defense methods demonstrate promising performance, they may be impractical in real-world scenarios due to their heavy reliance on labeled malicious agents to train a supervised malicious detection model. To enable practical and generalizable MAS defenses, in this paper, we propose BlindGuard, an unsupervised defense method that learns without requiring any attack-specific labels or prior knowledge of malicious behaviors. To this end, we establish a hierarchical agent encoder to capture individual, neighborhood, and global interaction patterns of each agent, providing a comprehensive understanding for malicious agent detection. Meanwhile, we design a corruption-guided detector that consists of directional noise injection and contrastive learning, allowing effective detection model training solely on normal agent behaviors. Extensive experiments show that BlindGuard effectively detects diverse attack types (i.e., prompt injection, memory poisoning, and tool attack) across MAS with various communication patterns while maintaining superior generalizability compared to supervised baselines. The code is available at: https://github.com/MR9812/BlindGuard.",
    "source": "arXiv"
  },
  {
    "title": "Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration",
    "title_es": "Fuzzy Ontology Embeddings and Visual Query Building for Ontology Exploration",
    "url": "https://arxiv.org/abs/2508.08128",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08128v1 Announce Type: new \nAbstract: Ontologies play a central role in structuring knowledge across domains, supporting tasks such as reasoning, data integration, and semantic search. However, their large size and complexity, particularly in fields such as biomedicine, computational biology, law, and engineering, make them difficult for non-experts to navigate. Formal query languages such as SPARQL offer expressive access but require users to understand the ontology's structure and syntax. In contrast, visual exploration tools and basic keyword-based search interfaces are easier to use but often lack flexibility and expressiveness. We introduce FuzzyVis, a proof-of-concept system that enables intuitive and expressive exploration of complex ontologies. FuzzyVis integrates two key components: a fuzzy logic-based querying model built on fuzzy ontology embeddings, and an interactive visual interface for building and interpreting queries. Users can construct new composite concepts by selecting and combining existing ontology concepts using logical operators such as conjunction, disjunction, and negation. These composite concepts are matched against the ontology using fuzzy membership-based embeddings, which capture degrees of membership and support approximate, concept-level similarity search. The visual interface supports browsing, query composition, and partial search without requiring formal syntax. By combining fuzzy semantics with embedding-based reasoning, FuzzyVis enables flexible interpretation, efficient computation, and exploratory learning. Case studies demonstrate how FuzzyVis supports subtle information needs and helps users uncover relevant concepts in large, complex ontologies.",
    "source": "arXiv"
  },
  {
    "title": "Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models",
    "title_es": "Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models",
    "url": "https://arxiv.org/abs/2508.08131",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08131v1 Announce Type: new \nAbstract: Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to perceive speech inputs, have gained increasing attention for their potential to advance speech understanding tasks. However, despite recent progress, studies show that SLMs often struggle to generalize across datasets, even for trained languages and tasks, raising concerns about whether they process speech in a text-like manner as intended. A key challenge underlying this limitation is the modality gap between speech and text representations. The high variability in speech embeddings may allow SLMs to achieve strong in-domain performance by exploiting unintended speech variations, ultimately hindering generalization. To mitigate this modality gap, we introduce Optimal Transport Regularization (OTReg), a method that formulates speech-text alignment as an optimal transport problem and derives a regularization loss to improve SLM training. In each training iteration, OTReg first establishes a structured correspondence between speech and transcript embeddings by determining the optimal transport plan, then incorporates the regularization loss based on this transport plan to optimize SLMs in generating speech embeddings that align more effectively with transcript embeddings. OTReg is lightweight, requiring no additional labels or learnable parameters, and integrates seamlessly into existing SLM training procedures. Extensive multilingual ASR experiments demonstrate that OTReg enhances speech-text alignment, mitigates the modality gap, and consequently improves SLM generalization across diverse datasets.",
    "source": "arXiv"
  },
  {
    "title": "Deep Reinforcement Learning with Local Interpretability for Transparent Microgrid Resilience Energy Management",
    "title_es": "Deep Reinforcement Learning with Local Interpretability for Transparent Microgrid Resilience Energy Management",
    "url": "https://arxiv.org/abs/2508.08132",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08132v1 Announce Type: new \nAbstract: Renewable energy integration into microgrids has become a key approach to addressing global energy issues such as climate change and resource scarcity. However, the variability of renewable sources and the rising occurrence of High Impact Low Probability (HILP) events require innovative strategies for reliable and resilient energy management. This study introduces a practical approach to managing microgrid resilience through Explainable Deep Reinforcement Learning (XDRL). It combines the Proximal Policy Optimization (PPO) algorithm for decision-making with the Local Interpretable Model-agnostic Explanations (LIME) method to improve the transparency of the actor network's decisions. A case study in Ongole, India, examines a microgrid with wind, solar, and battery components to validate the proposed approach. The microgrid is simulated under extreme weather conditions during the Layla cyclone. LIME is used to analyse scenarios, showing the impact of key factors such as renewable generation, state of charge, and load prioritization on decision-making. The results demonstrate a Resilience Index (RI) of 0.9736 and an estimated battery lifespan of 15.11 years. LIME analysis reveals the rationale behind the agent's actions in idle, charging, and discharging modes, with renewable generation identified as the most influential feature. This study shows the effectiveness of integrating advanced DRL algorithms with interpretable AI techniques to achieve reliable and transparent energy management in microgrids.",
    "source": "arXiv"
  },
  {
    "title": "Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control",
    "title_es": "Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control",
    "url": "https://arxiv.org/abs/2508.08134",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08134v1 Announce Type: new \nAbstract: While recent flow-based image editing models demonstrate general-purpose capabilities across diverse tasks, they often struggle to specialize in challenging scenarios -- particularly those involving large-scale shape transformations. When performing such structural edits, these methods either fail to achieve the intended shape change or inadvertently alter non-target regions, resulting in degraded background quality. We propose Follow-Your-Shape, a training-free and mask-free framework that supports precise and controllable editing of object shapes while strictly preserving non-target content. Motivated by the divergence between inversion and editing trajectories, we compute a Trajectory Divergence Map (TDM) by comparing token-wise velocity differences between the inversion and denoising paths. The TDM enables precise localization of editable regions and guides a Scheduled KV Injection mechanism that ensures stable and faithful editing. To facilitate a rigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120 new images and enriched prompt pairs specifically curated for shape-aware editing. Experiments demonstrate that our method achieves superior editability and visual fidelity, particularly in tasks requiring large-scale shape replacement.",
    "source": "arXiv"
  },
  {
    "title": "FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting",
    "title_es": "FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting",
    "url": "https://arxiv.org/abs/2508.08136",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08136v1 Announce Type: new \nAbstract: The success of 3DGS in generative and editing applications has sparked growing interest in 3DGS-based style transfer. However, current methods still face two major challenges: (1) multi-view inconsistency often leads to style conflicts, resulting in appearance smoothing and distortion; and (2) heavy reliance on VGG features, which struggle to disentangle style and content from style images, often causing content leakage and excessive stylization. To tackle these issues, we introduce \\textbf{FantasyStyle}, a 3DGS-based style transfer framework, and the first to rely entirely on diffusion model distillation. It comprises two key components: (1) \\textbf{Multi-View Frequency Consistency}. We enhance cross-view consistency by applying a 3D filter to multi-view noisy latent, selectively reducing low-frequency components to mitigate stylized prior conflicts. (2) \\textbf{Controllable Stylized Distillation}. To suppress content leakage from style images, we introduce negative guidance to exclude undesired content. In addition, we identify the limitations of Score Distillation Sampling and Delta Denoising Score in 3D style transfer and remove the reconstruction term accordingly. Building on these insights, we propose a controllable stylized distillation that leverages negative guidance to more effectively optimize the 3D Gaussians. Extensive experiments demonstrate that our method consistently outperforms state-of-the-art approaches, achieving higher stylization quality and visual realism across various scenes and styles.",
    "source": "arXiv"
  },
  {
    "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation",
    "title_es": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation",
    "url": "https://arxiv.org/abs/2508.08137",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08137v1 Announce Type: new \nAbstract: Conducting a comprehensive literature review is crucial for advancing circuit design methodologies. However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging. In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason + Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step information retrieval. It functions as a question-answering design assistant, capable of interpreting complex queries and providing reasoned responses grounded in circuit literature. Its multimodal capabilities enable processing of both textual and visual data, facilitating more efficient and comprehensive analysis. The system dynamically adapts using intelligent search tools, automated document retrieval from the internet, and real-time database updates. Unlike conventional approaches constrained by model context limits, MuaLLM decouples retrieval from inference, enabling scalable reasoning over arbitrarily large corpora. At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy. This allows rapid, no-human-in-the-loop database generation, overcoming the bottleneck of simulation-based dataset creation for circuits. To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8% accuracy on Reas-100.",
    "source": "arXiv"
  },
  {
    "title": "Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models",
    "title_es": "Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models",
    "url": "https://arxiv.org/abs/2508.08139",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08139v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are prone to generating fluent but incorrect content, known as confabulation, which poses increasing risks in multi-turn or agentic applications where outputs may be reused as context. In this work, we investigate how in-context information influences model behavior and whether LLMs can identify their unreliable responses. We propose a reliability estimation that leverages token-level uncertainty to guide the aggregation of internal model representations. Specifically, we compute aleatoric and epistemic uncertainty from output logits to identify salient tokens and aggregate their hidden states into compact representations for response-level reliability prediction. Through controlled experiments on open QA benchmarks, we find that correct in-context information improves both answer accuracy and model confidence, while misleading context often induces confidently incorrect responses, revealing a misalignment between uncertainty and correctness. Our probing-based method captures these shifts in model behavior and improves the detection of unreliable outputs across multiple open-source LLMs. These results underscore the limitations of direct uncertainty signals and highlight the potential of uncertainty-guided probing for reliability-aware generation.",
    "source": "arXiv"
  },
  {
    "title": "Data-Efficient Biomedical In-Context Learning: A Diversity-Enhanced Submodular Perspective",
    "title_es": "Data-Efficient Biomedical In-Context Learning: A Diversity-Enhanced Submodular Perspective",
    "url": "https://arxiv.org/abs/2508.08140",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08140v1 Announce Type: new \nAbstract: Recent progress in large language models (LLMs) has leveraged their in-context learning (ICL) abilities to enable quick adaptation to unseen biomedical NLP tasks. By incorporating only a few input-output examples into prompts, LLMs can rapidly perform these new tasks. While the impact of these demonstrations on LLM performance has been extensively studied, most existing approaches prioritize representativeness over diversity when selecting examples from large corpora. To address this gap, we propose Dual-Div, a diversity-enhanced data-efficient framework for demonstration selection in biomedical ICL. Dual-Div employs a two-stage retrieval and ranking process: First, it identifies a limited set of candidate examples from a corpus by optimizing both representativeness and diversity (with optional annotation for unlabeled data). Second, it ranks these candidates against test queries to select the most relevant and non-redundant demonstrations. Evaluated on three biomedical NLP tasks (named entity recognition (NER), relation extraction (RE), and text classification (TC)) using LLaMA 3.1 and Qwen 2.5 for inference, along with three retrievers (BGE-Large, BMRetriever, MedCPT), Dual-Div consistently outperforms baselines-achieving up to 5% higher macro-F1 scores-while demonstrating robustness to prompt permutations and class imbalance. Our findings establish that diversity in initial retrieval is more critical than ranking-stage optimization, and limiting demonstrations to 3-5 examples maximizes performance efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization",
    "title_es": "Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization",
    "url": "https://arxiv.org/abs/2508.08141",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08141v1 Announce Type: new \nAbstract: The field of visual and audio generation is burgeoning with new state-of-the-art methods. This rapid proliferation of new techniques underscores the need for robust solutions for detecting synthetic content in videos. In particular, when fine-grained alterations via localized manipulations are performed in visual, audio, or both domains, these subtle modifications add challenges to the detection algorithms. This paper presents solutions for the problems of deepfake video classification and localization. The methods were submitted to the ACM 1M Deepfakes Detection Challenge, achieving the best performance in the temporal localization task and a top four ranking in the classification task for the TestA split of the evaluation dataset.",
    "source": "arXiv"
  },
  {
    "title": "AI Gossip",
    "title_es": "AI Gossip",
    "url": "https://arxiv.org/abs/2508.08143",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08143v1 Announce Type: new \nAbstract: Generative AI chatbots like OpenAI's ChatGPT and Google's Gemini routinely make things up. They \"hallucinate\" historical events and figures, legal cases, academic papers, non-existent tech products and features, biographies, and news articles. Recently, some have argued that these hallucinations are better understood as bullshit. Chatbots produce rich streams of text that look truth-apt without any concern for the truthfulness of what this text says. But can they also gossip? We argue that they can. After some definitions and scene-setting, we focus on a recent example to clarify what AI gossip looks like before considering some distinct harms -- what we call \"technosocial harms\" -- that follow from it.",
    "source": "arXiv"
  },
  {
    "title": "COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models",
    "title_es": "COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models",
    "url": "https://arxiv.org/abs/2508.08144",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08144v1 Announce Type: new \nAbstract: The rapid growth of resource-constrained mobile platforms, including mobile robots, wearable systems, and Internet-of-Things devices, has increased the demand for computationally efficient neural network controllers (NNCs) that can operate within strict hardware limitations. While deep neural networks (DNNs) demonstrate superior performance in control applications, their substantial computational complexity and memory requirements present significant barriers to practical deployment on edge devices. This paper introduces a comprehensive model compression methodology that leverages component-aware structured pruning to determine the optimal pruning magnitude for each pruning group, ensuring a balance between compression and stability for NNC deployment. Our approach is rigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC), a state-of-the-art model-based reinforcement learning algorithm, with a systematic integration of mathematical stability guarantee properties, specifically Lyapunov criteria. The key contribution of this work lies in providing a principled framework for determining the theoretical limits of model compression while preserving controller stability. Experimental validation demonstrates that our methodology successfully reduces model complexity while maintaining requisite control performance and stability characteristics. Furthermore, our approach establishes a quantitative boundary for safe compression ratios, enabling practitioners to systematically determine the maximum permissible model reduction before violating critical stability properties, thereby facilitating the confident deployment of compressed NNCs in resource-limited environments.",
    "source": "arXiv"
  },
  {
    "title": "From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework",
    "title_es": "From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework",
    "url": "https://arxiv.org/abs/2508.08147",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08147v1 Announce Type: new \nAbstract: This paper introduces a novel Large Language Models (LLMs)-assisted agent that automatically converts natural-language descriptions of power system optimization scenarios into compact, solver-ready formulations and generates corresponding solutions. In contrast to approaches that rely solely on LLM to produce solutions directly, the proposed method focuses on discovering a mathematically compatible formulation that can be efficiently solved by off-the-shelf optimization solvers. Directly using LLMs to produce solutions often leads to infeasible or suboptimal results, as these models lack the numerical precision and constraint-handling capabilities of established optimization solvers. The pipeline integrates a domain-aware prompt and schema with an LLM, enforces feasibility through systematic validation and iterative repair, and returns both solver-ready models and user-facing results. Using the unit commitment problem as a representative case study, the agent produces optimal or near-optimal schedules along with the associated objective costs. Results demonstrate that coupling the solver with task-specific validation significantly enhances solution reliability. This work shows that combining AI with established optimization frameworks bridges high-level problem descriptions and executable mathematical models, enabling more efficient decision-making in energy systems",
    "source": "arXiv"
  },
  {
    "title": "REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation",
    "title_es": "REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation",
    "url": "https://arxiv.org/abs/2508.08149",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08149v1 Announce Type: new \nAbstract: Reinforcement learning (RL) is emerging as a powerful paradigm for enabling large language models (LLMs) to perform complex reasoning tasks. Recent advances indicate that integrating RL with retrieval-augmented generation (RAG) allows LLMs to dynamically incorporate external knowledge, leading to more informed and robust decision making. However, we identify a critical challenge during policy-driven trajectory sampling: LLMs are frequently trapped in unproductive reasoning paths, which we refer to as \"dead ends\", committing to overconfident yet incorrect conclusions. This severely hampers exploration and undermines effective policy optimization. To address this challenge, we propose REX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation), a novel framework that explores alternative reasoning paths while maintaining rigorous policy learning through principled distributional corrections. Our approach introduces two key innovations: (1) Mixed Sampling Strategy, which combines a novel probe sampling method with exploratory prompts to escape dead ends; and (2) Policy Correction Mechanism, which employs importance sampling to correct distribution shifts induced by mixed sampling, thereby mitigating gradient estimation bias. We evaluate it on seven question-answering benchmarks, and the experimental results show that REX-RAG achieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B over strong baselines, demonstrating competitive results across multiple datasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.",
    "source": "arXiv"
  },
  {
    "title": "FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks",
    "title_es": "FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks",
    "url": "https://arxiv.org/abs/2508.08151",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08151v1 Announce Type: new \nAbstract: Deep neural networks (DNNs) are being utilized in various aspects of our daily lives, including high-stakes decision-making applications that impact individuals. However, these systems reflect and amplify bias from the data used during training and testing, potentially resulting in biased behavior and inaccurate decisions. For instance, having different misclassification rates between white and black sub-populations. However, effectively and efficiently identifying and correcting biased behavior in DNNs is a challenge. This paper introduces FairFLRep, an automated fairness-aware fault localization and repair technique that identifies and corrects potentially bias-inducing neurons in DNN classifiers. FairFLRep focuses on adjusting neuron weights associated with sensitive attributes, such as race or gender, that contribute to unfair decisions. By analyzing the input-output relationships within the network, FairFLRep corrects neurons responsible for disparities in predictive quality parity. We evaluate FairFLRep on four image classification datasets using two DNN classifiers, and four tabular datasets with a DNN model. The results show that FairFLRep consistently outperforms existing methods in improving fairness while preserving accuracy. An ablation study confirms the importance of considering fairness during both fault localization and repair stages. Our findings also show that FairFLRep is more efficient than the baseline approaches in repairing the network.",
    "source": "arXiv"
  },
  {
    "title": "Robust Adaptive Discrete-Time Control Barrier Certificate",
    "title_es": "Robust Adaptive Discrete-Time Control Barrier Certificate",
    "url": "https://arxiv.org/abs/2508.08153",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08153v1 Announce Type: new \nAbstract: This work develops a robust adaptive control strategy for discrete-time systems using Control Barrier Functions (CBFs) to ensure safety under parametric model uncertainty and disturbances. A key contribution of this work is establishing a barrier function certificate in discrete time for general online parameter estimation algorithms. This barrier function certificate guarantees positive invariance of the safe set despite disturbances and parametric uncertainty without access to the true system parameters. In addition, real-time implementation and inherent robustness guarantees are provided. Our approach demonstrates that, using the proposed robust adaptive CBF framework, the parameter estimation module can be designed separately from the CBF-based safety filter, simplifying the development of safe adaptive controllers for discrete-time systems. The resulting safety filter guarantees that the system remains within the safe set while adapting to model uncertainties, making it a promising strategy for real-world applications involving discrete-time safety-critical systems.",
    "source": "arXiv"
  },
  {
    "title": "Can AI Explanations Make You Change Your Mind?",
    "title_es": "Can AI Explanations Make You Change Your Mind?",
    "url": "https://arxiv.org/abs/2508.08158",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08158v1 Announce Type: new \nAbstract: In the context of AI-based decision support systems, explanations can help users to judge when to trust the AI's suggestion, and when to question it. In this way, human oversight can prevent AI errors and biased decision-making. However, this rests on the assumption that users will consider explanations in enough detail to be able to catch such errors. We conducted an online study on trust in explainable DSS, and were surprised to find that in many cases, participants spent little time on the explanation and did not always consider it in detail. We present an exploratory analysis of this data, investigating what factors impact how carefully study participants consider AI explanations, and how this in turn impacts whether they are open to changing their mind based on what the AI suggests.",
    "source": "arXiv"
  },
  {
    "title": "Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets",
    "title_es": "Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets",
    "url": "https://arxiv.org/abs/2508.08159",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08159v1 Announce Type: new \nAbstract: Developing accurate and generalizable epileptic seizure prediction models from electroencephalography (EEG) data across multiple clinical sites is hindered by patient privacy regulations and significant data heterogeneity (non-IID characteristics). Federated Learning (FL) offers a privacy-preserving framework for collaborative training, but standard aggregation methods like Federated Averaging (FedAvg) can be biased by dominant datasets in heterogeneous settings. This paper investigates FL for seizure prediction using a single EEG channel across four diverse public datasets (Siena, CHB-MIT, Helsinki, NCH), representing distinct patient populations (adult, pediatric, neonate) and recording conditions. We implement privacy-preserving global normalization and propose a Random Subset Aggregation strategy, where each client trains on a fixed-size random subset of its data per round, ensuring equal contribution during aggregation. Our results show that locally trained models fail to generalize across sites, and standard weighted FedAvg yields highly skewed performance (e.g., 89.0% accuracy on CHB-MIT but only 50.8% on Helsinki and 50.6% on NCH). In contrast, Random Subset Aggregation significantly improves performance on under-represented clients (accuracy increases to 81.7% on Helsinki and 68.7% on NCH) and achieves a superior macro-average accuracy of 77.1% and pooled accuracy of 80.0% across all sites, demonstrating a more robust and fair global model. This work highlights the potential of balanced FL approaches for building effective and generalizable seizure prediction systems in realistic, heterogeneous multi-hospital environments while respecting data privacy.",
    "source": "arXiv"
  },
  {
    "title": "LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo",
    "title_es": "LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo",
    "url": "https://arxiv.org/abs/2508.08163",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08163v1 Announce Type: new \nAbstract: The Learning With Disagreements (LeWiDi) 2025 shared task is to model annotator disagreement through soft label distribution prediction and perspectivist evaluation, modeling annotators. We adapt DisCo (Distribution from Context), a neural architecture that jointly models item-level and annotator-level label distributions, and present detailed analysis and improvements. In this paper, we extend the DisCo by incorporating annotator metadata, enhancing input representations, and modifying the loss functions to capture disagreement patterns better. Through extensive experiments, we demonstrate substantial improvements in both soft and perspectivist evaluation metrics across three datasets. We also conduct in-depth error and calibration analyses, highlighting the conditions under which improvements occur. Our findings underscore the value of disagreement-aware modeling and offer insights into how system components interact with the complexity of human-annotated data.",
    "source": "arXiv"
  },
  {
    "title": "Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning",
    "title_es": "Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning",
    "url": "https://arxiv.org/abs/2508.08165",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08165v1 Announce Type: new \nAbstract: Class-Incremental Learning (CIL) requires a learning system to continually learn new classes without forgetting. Existing pre-trained model-based CIL methods often freeze the pre-trained network and adapt to incremental tasks using additional lightweight modules such as adapters. However, incorrect module selection during inference hurts performance, and task-specific modules often overlook shared general knowledge, leading to errors on distinguishing between similar classes across tasks. To address the aforementioned challenges, we propose integrating Task-Specific and Universal Adapters (TUNA) in this paper. Specifically, we train task-specific adapters to capture the most crucial features relevant to their respective tasks and introduce an entropy-based selection mechanism to choose the most suitable adapter. Furthermore, we leverage an adapter fusion strategy to construct a universal adapter, which encodes the most discriminative features shared across tasks. We combine task-specific and universal adapter predictions to harness both specialized and general knowledge during inference. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of our approach. Code is available at: https://github.com/LAMDA-CL/ICCV2025-TUNA",
    "source": "arXiv"
  },
  {
    "title": "Sparsifying Sums of Positive Semidefinite Matrices",
    "title_es": "Sparsifying Sums of Positive Semidefinite Matrices",
    "url": "https://arxiv.org/abs/2508.08169",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08169v1 Announce Type: new \nAbstract: In this paper, we revisit spectral sparsification for sums of arbitrary positive semidefinite (PSD) matrices. Concretely, for any collection of PSD matrices $\\mathcal{A} = \\{A_1, A_2, \\ldots, A_r\\} \\subset \\mathbb{R}^{n \\times n}$, given any subset $T \\subseteq [r]$, our goal is to find sparse weights $\\mu \\in \\mathbb{R}_{\\geq 0}^r$ such that $(1 - \\epsilon) \\sum_{i \\in T} A_i \\preceq \\sum_{i \\in T} \\mu_i A_i \\preceq (1 + \\epsilon) \\sum_{i \\in T} A_i.$ This generalizes spectral sparsification of graphs which corresponds to $\\mathcal{A}$ being the set of Laplacians of edges. It also captures sparsifying Cayley graphs by choosing a subset of generators. The former has been extensively studied with optimal sparsifiers known. The latter has received attention recently and was solved for a few special groups (e.g., $\\mathbb{F}_2^n$).\n  Prior work shows any sum of PSD matrices can be sparsified down to $O(n)$ elements. This bound however turns out to be too coarse and in particular yields no non-trivial bound for building Cayley sparsifiers for Cayley graphs.\n  In this work, we develop a new, instance-specific (i.e., specific to a given collection $\\mathcal{A}$) theory of PSD matrix sparsification based on a new parameter $N^*(\\mathcal{A})$ which we call connectivity threshold that generalizes the threshold of the number of edges required to make a graph connected.\n  Our main result gives a sparsifier that uses at most $O(\\epsilon^{-2}N^*(\\mathcal{A}) (\\log n)(\\log r))$ matrices and is constructible in randomized polynomial time. We also show that we need $N^*(\\mathcal{A})$ elements to sparsify for any $\\epsilon < 0.99$.\n  As the main application of our framework, we prove that any Cayley graph can be sparsified to $O(\\epsilon^{-2}\\log^4 N)$ generators. Previously, a non-trivial bound on Cayley sparsifiers was known only in the case when the group is $\\mathbb{F}_2^n$.",
    "source": "arXiv"
  },
  {
    "title": "ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction",
    "title_es": "ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction",
    "url": "https://arxiv.org/abs/2508.08170",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08170v1 Announce Type: new \nAbstract: Reinforcement learning for training end-to-end autonomous driving models in closed-loop simulations is gaining growing attention. However, most simulation environments differ significantly from real-world conditions, creating a substantial simulation-to-reality (sim2real) gap. To bridge this gap, some approaches utilize scene reconstruction techniques to create photorealistic environments as a simulator. While this improves realistic sensor simulation, these methods are inherently constrained by the distribution of the training data, making it difficult to render high-quality sensor data for novel trajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a framework designed to integrate video diffusion priors into scene reconstruction to aid reinforcement learning, thereby enhancing end-to-end autonomous driving training. Specifically, in ReconDreamer-RL, we introduce ReconSimulator, which combines the video diffusion prior for appearance modeling and incorporates a kinematic model for physical modeling, thereby reconstructing driving scenarios from real-world data. This narrows the sim2real gap for closed-loop evaluation and reinforcement learning. To cover more corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA), which adjusts the trajectories of surrounding vehicles relative to the ego vehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in). Finally, the Cousin Trajectory Generator (CTG) is proposed to address the issue of training data distribution, which is often biased toward simple straight-line movements. Experiments show that ReconDreamer-RL improves end-to-end autonomous driving training, outperforming imitation learning methods with a 5x reduction in the Collision Ratio.",
    "source": "arXiv"
  },
  {
    "title": "PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C",
    "title_es": "PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C",
    "url": "https://arxiv.org/abs/2508.08171",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08171v1 Announce Type: new \nAbstract: Python has become the dominant language for general-purpose programming, yet it lacks robust tools for formal verification. In contrast, programmers working in languages such as C benefit from mature model checkers, for example CBMC, which enable exhaustive symbolic reasoning and fault localisation. The inherent complexity of Python, coupled with the verbosity and low-level nature of existing transpilers (e.g., Cython), have historically limited the applicability of formal verification to Python programs.\n  In this paper, we propose PyVeritas, a novel framework that leverages Large Language Models (LLMs) for high-level transpilation from Python to C, followed by bounded model checking and MaxSAT-based fault localisation in the generated C code. PyVeritas enables verification and bug localisation for Python code using existing model checking tools for C. Our empirical evaluation on two Python benchmarks demonstrates that LLM-based transpilation can achieve a high degree of accuracy, up to 80--90% for some LLMs, enabling effective development environment that supports assertion-based verification and interpretable fault diagnosis for small yet non-trivial Python programs.",
    "source": "arXiv"
  },
  {
    "title": "Neural Logic Networks for Interpretable Classification",
    "title_es": "Neural Logic Networks for Interpretable Classification",
    "url": "https://arxiv.org/abs/2508.08172",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08172v1 Announce Type: new \nAbstract: Traditional neural networks have an impressive classification performance, but what they learn cannot be inspected, verified or extracted. Neural Logic Networks on the other hand have an interpretable structure that enables them to learn a logical mechanism relating the inputs and outputs with AND and OR operations. We generalize these networks with NOT operations and biases that take into account unobserved data and develop a rigorous logical and probabilistic modeling in terms of concept combinations to motivate their use. We also propose a novel factorized IF-THEN rule structure for the model as well as a modified learning algorithm. Our method improves the state-of-the-art in Boolean networks discovery and is able to learn relevant, interpretable rules in tabular classification, notably on an example from the medical field where interpretability has tangible value.",
    "source": "arXiv"
  },
  {
    "title": "CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data",
    "title_es": "CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data",
    "url": "https://arxiv.org/abs/2508.08173",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08173v1 Announce Type: new \nAbstract: Large-scale scientific simulations require significant resources to generate high-resolution time-varying data (TVD). While super-resolution is an efficient post-processing strategy to reduce costs, existing methods rely on a large amount of HR training data, limiting their applicability to diverse simulation scenarios. To address this constraint, we proposed CD-TVD, a novel framework that combines contrastive learning and an improved diffusion-based super-resolution model to achieve accurate 3D super-resolution from limited time-step high-resolution data. During pre-training on historical simulation data, the contrastive encoder and diffusion superresolution modules learn degradation patterns and detailed features of high-resolution and low-resolution samples. In the training phase, the improved diffusion model with a local attention mechanism is fine-tuned using only one newly generated high-resolution timestep, leveraging the degradation knowledge learned by the encoder. This design minimizes the reliance on large-scale high-resolution datasets while maintaining the capability to recover fine-grained details. Experimental results on fluid and atmospheric simulation datasets confirm that CD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a significant advancement in data augmentation for large-scale scientific simulations. The code is available at https://github.com/Xin-Gao-private/CD-TVD.",
    "source": "arXiv"
  },
  {
    "title": "MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision",
    "title_es": "MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision",
    "url": "https://arxiv.org/abs/2508.08177",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08177v1 Announce Type: new \nAbstract: Accurately grounding regions of interest (ROIs) is critical for diagnosis and treatment planning in medical imaging. While multimodal large language models (MLLMs) combine visual perception with natural language, current medical-grounding pipelines still rely on supervised fine-tuning with explicit spatial hints, making them ill-equipped to handle the implicit queries common in clinical practice. This work makes three core contributions. We first define Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that demands clinical reasoning and pixel-level grounding. Second, we release U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside implicit clinical queries and reasoning traces, spanning 10 modalities, 15 super-categories, and 108 specific categories. Finally, we introduce MedReasoner, a modular framework that distinctly separates reasoning from segmentation: an MLLM reasoner is optimized with reinforcement learning, while a frozen segmentation expert converts spatial prompts into masks, with alignment achieved through format and accuracy rewards. MedReasoner achieves state-of-the-art performance on U-MRG-14K and demonstrates strong generalization to unseen clinical queries, underscoring the significant promise of reinforcement learning for interpretable medical grounding.",
    "source": "arXiv"
  },
  {
    "title": "3D Human Mesh Estimation from Single View RGBD",
    "title_es": "3D Human Mesh Estimation from Single View RGBD",
    "url": "https://arxiv.org/abs/2508.08178",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08178v1 Announce Type: new \nAbstract: Despite significant progress in 3D human mesh estimation from RGB images; RGBD cameras, offering additional depth data, remain underutilized. In this paper, we present a method for accurate 3D human mesh estimation from a single RGBD view, leveraging the affordability and widespread adoption of RGBD cameras for real-world applications. A fully supervised approach for this problem, requires a dataset with RGBD image and 3D mesh label pairs. However, collecting such a dataset is costly and challenging, hence, existing datasets are small, and limited in pose and shape diversity. To overcome this data scarcity, we leverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D meshes from the body models found in MoCap datasets, and create partial, single-view versions of them by projection to a virtual camera. This simulates the depth data provided by an RGBD camera from a single viewpoint. Then, we train a masked autoencoder to complete the partial, single-view mesh. During inference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'', matches the depth values coming from the sensor to vertices of a template human mesh, which creates a partial, single-view mesh. We effectively recover parts of the 3D human body mesh model that are not visible, resulting in a full body mesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL and CAPE datasets, respectively; outperforming existing methods that use full-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE dataset, outperforming a recently published RGB based method by 18.4 mm, highlighting the usefulness of depth data. Code will be released.",
    "source": "arXiv"
  },
  {
    "title": "PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation",
    "title_es": "PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation",
    "url": "https://arxiv.org/abs/2508.08179",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08179v1 Announce Type: new \nAbstract: Human motion generation has found widespread applications in AR/VR, film, sports, and medical rehabilitation, offering a cost-effective alternative to traditional motion capture systems. However, evaluating the fidelity of such generated motions is a crucial, multifaceted task. Although previous approaches have attempted at motion fidelity evaluation using human perception or physical constraints, there remains an inherent gap between human-perceived fidelity and physical feasibility. Moreover, the subjective and coarse binary labeling of human perception further undermines the development of a robust data-driven metric. We address these issues by introducing a physical labeling method. This method evaluates motion fidelity by calculating the minimum modifications needed for a motion to align with physical laws. With this approach, we are able to produce fine-grained, continuous physical alignment annotations that serve as objective ground truth. With these annotations, we propose PP-Motion, a novel data-driven metric to evaluate both physical and perceptual fidelity of human motion. To effectively capture underlying physical priors, we employ Pearson's correlation loss for the training of our metric. Additionally, by incorporating a human-based perceptual fidelity loss, our metric can capture fidelity that simultaneously considers both human perception and physical alignment. Experimental results demonstrate that our metric, PP-Motion, not only aligns with physical laws but also aligns better with human perception of motion fidelity than previous work.",
    "source": "arXiv"
  },
  {
    "title": "RedDino: A foundation model for red blood cell analysis",
    "title_es": "RedDino: A foundation model for red blood cell analysis",
    "url": "https://arxiv.org/abs/2508.08180",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08180v1 Announce Type: new \nAbstract: Red blood cells (RBCs) are essential to human health, and their precise morphological analysis is important for diagnosing hematological disorders. Despite the promise of foundation models in medical diagnostics, comprehensive AI solutions for RBC analysis remain scarce. We present RedDino, a self-supervised foundation model designed for RBC image analysis. RedDino uses an RBC-specific adaptation of the DINOv2 self-supervised learning framework and is trained on a curated dataset of 1.25 million RBC images from diverse acquisition modalities and sources. Extensive evaluations show that RedDino outperforms existing state-of-the-art models on RBC shape classification. Through assessments including linear probing and nearest neighbor classification, we confirm its strong feature representations and generalization ability. Our main contributions are: (1) a foundation model tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations for RBC modeling, and (3) a detailed evaluation of generalization performance. RedDino addresses key challenges in computational hematology by capturing nuanced morphological features, advancing the development of reliable diagnostic tools. The source code and pretrained models for RedDino are available at https://github.com/Snarci/RedDino, and the pretrained models can be downloaded from our Hugging Face collection at https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc",
    "source": "arXiv"
  },
  {
    "title": "THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening",
    "title_es": "THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening",
    "url": "https://arxiv.org/abs/2508.08183",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08183v1 Announce Type: new \nAbstract: Transformer-based methods have demonstrated strong potential in hyperspectral pansharpening by modeling long-range dependencies. However, their effectiveness is often limited by redundant token representations and a lack of multi-scale feature modeling. Hyperspectral images exhibit intrinsic spectral priors (e.g., abundance sparsity) and spatial priors (e.g., non-local similarity), which are critical for accurate reconstruction. From a spectral-spatial perspective, Vision Transformers (ViTs) face two major limitations: they struggle to preserve high-frequency components--such as material edges and texture transitions--and suffer from attention dispersion across redundant tokens. These issues stem from the global self-attention mechanism, which tends to dilute high-frequency signals and overlook localized details. To address these challenges, we propose the Token-wise High-frequency Augmentation Transformer (THAT), a novel framework designed to enhance hyperspectral pansharpening through improved high-frequency feature representation and token selection. Specifically, THAT introduces: (1) Pivotal Token Selective Attention (PTSA) to prioritize informative tokens and suppress redundancy; (2) a Multi-level Variance-aware Feed-forward Network (MVFN) to enhance high-frequency detail learning. Experiments on standard benchmarks show that THAT achieves state-of-the-art performance with improved reconstruction quality and efficiency. The source code is available at https://github.com/kailuo93/THAT.",
    "source": "arXiv"
  },
  {
    "title": "Pinching-Antenna Systems (PASS)-based Indoor Positioning",
    "title_es": "Pinching-Antenna Systems (PASS)-based Indoor Positioning",
    "url": "https://arxiv.org/abs/2508.08185",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08185v1 Announce Type: new \nAbstract: Pinching antenna (PA), a flexible waveguide integrated with dielectric particles, intelligently reconstructs line-of-sight channels. Utilizing its geometric deterministic model and meter-level reconstruction, PA systems (PASS) are applied to uplink indoor positioning. In this paper, the uplink positioning system model for PASS is firstly proposed. A PASS-based received signal strength indication (RSSI) method is proposed to measure the distance from the users to each PA, which is efficient and suitable for PASS. PASS-based weighted least squares (WLS) algorithm is designed to calculate the two-dimensional coordinates of the users. Several critical observations can be drawn from our results: i) More PAs on the waveguide improves the positioning accuracy and robustness. ii) When the number of PAs exceeds a certain threshold, the performance gain becomes marginal. iii) User locations between and near PAs yield superior positioning accuracy.",
    "source": "arXiv"
  },
  {
    "title": "KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning",
    "title_es": "KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning",
    "url": "https://arxiv.org/abs/2508.08186",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08186v1 Announce Type: new \nAbstract: Semantic segmentation of structural defects in civil infrastructure remains challenging due to variable defect appearances, harsh imaging conditions, and significant class imbalance. Current deep learning methods, despite their effectiveness, typically require millions of parameters, rendering them impractical for real-time inspection systems. We introduce KARMA (Kolmogorov-Arnold Representation Mapping Architecture), a highly efficient semantic segmentation framework that models complex defect patterns through compositions of one-dimensional functions rather than conventional convolutions. KARMA features three technical innovations: (1) a parameter-efficient Tiny Kolmogorov-Arnold Network (TiKAN) module leveraging low-rank factorization for KAN-based feature transformation; (2) an optimized feature pyramid structure with separable convolutions for multi-scale defect analysis; and (3) a static-dynamic prototype mechanism that enhances feature representation for imbalanced classes. Extensive experiments on benchmark infrastructure inspection datasets demonstrate that KARMA achieves competitive or superior mean IoU performance compared to state-of-the-art approaches, while using significantly fewer parameters (0.959M vs. 31.04M, a 97% reduction). Operating at 0.264 GFLOPS, KARMA maintains inference speeds suitable for real-time deployment, enabling practical automated infrastructure inspection systems without compromising accuracy. The source code can be accessed at the following URL: https://github.com/faeyelab/karma.",
    "source": "arXiv"
  },
  {
    "title": "IDSO-Managed Bid-Based Transactive Distribution Systems Design for DER Participation in Wholesale Markets While Preserving T-D Interactions",
    "title_es": "IDSO-Managed Bid-Based Transactive Distribution Systems Design for DER Participation in Wholesale Markets While Preserving T-D Interactions",
    "url": "https://arxiv.org/abs/2508.08187",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08187v1 Announce Type: new \nAbstract: Participation of Distributed Energy Resources (DERs) in bid-based Transactive Energy Systems (TES) at the distribution systems facilitates strongly coupled, bidirectional interactions between Transmission-Distribution (T-D) systems. Capturing these interactions is critical for ensuring seamless integration within an Integrated Transmission and Distribution (ITD) framework. This study proposes a methodology to preserve such tight T-D linkages by developing an Independent Distribution System Operator (IDSO) managed bid-based TES design for unbalanced distribution systems. The proposed design operates within the ITD paradigm and permits DER participation in the Wholesale Power Market (WPM) through IDSO while preserving tight T-D linkages. To this end, this research offers the following key contributions: a novel bid/offer prequalification-cum-aggregation method to ensure a grid-safe and value-based aggregation of DERs' bids and offers for WPM participation through IDSO; and a retail pricing mechanism that reflects the true value of procuring or offering additional units of power within the distribution system. Case studies are conducted on a modified IEEE 123-bus radial feeder populated with a high DER concentration to validate the proposed frameworks' effectiveness in coordinating the DERs efficiently and reliably.",
    "source": "arXiv"
  },
  {
    "title": "Reinforcement Learning in Vision: A Survey",
    "title_es": "Reinforcement Learning in Vision: A Survey",
    "url": "https://arxiv.org/abs/2508.08189",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08189v1 Announce Type: new \nAbstract: Recent advances at the intersection of reinforcement learning (RL) and visual intelligence have enabled agents that not only perceive complex visual scenes but also reason, generate, and act within them. This survey offers a critical and up-to-date synthesis of the field. We first formalize visual RL problems and trace the evolution of policy-optimization strategies from RLHF to verifiable reward paradigms, and from Proximal Policy Optimization to Group Relative Policy Optimization. We then organize more than 200 representative works into four thematic pillars: multi-modal large language models, visual generation, unified model frameworks, and vision-language-action models. For each pillar we examine algorithmic design, reward engineering, benchmark progress, and we distill trends such as curriculum-driven training, preference-aligned diffusion, and unified reward modeling. Finally, we review evaluation protocols spanning set-level fidelity, sample-level preference, and state-level stability, and we identify open challenges that include sample efficiency, generalization, and safe deployment. Our goal is to provide researchers and practitioners with a coherent map of the rapidly expanding landscape of visual RL and to highlight promising directions for future inquiry. Resources are available at: https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.",
    "source": "arXiv"
  },
  {
    "title": "Differential Privacy for Regulatory Compliance in Cyberattack Detection on Critical Infrastructure Systems",
    "title_es": "Differential Privacy for Regulatory Compliance in Cyberattack Detection on Critical Infrastructure Systems",
    "url": "https://arxiv.org/abs/2508.08190",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08190v1 Announce Type: new \nAbstract: Industrial control systems are a fundamental component of critical infrastructure networks (CIN) such as gas, water and power. With the growing risk of cyberattacks, regulatory compliance requirements are also increasing for large scale critical infrastructure systems comprising multiple utility stakeholders. The primary goal of regulators is to ensure overall system stability with recourse to trustworthy stakeholder attack detection. However, adhering to compliance requirements requires stakeholders to also disclose sensor and control data to regulators raising privacy concerns. In this paper, we present a cyberattack detection framework that utilizes differentially private (DP) hypothesis tests geared towards enhancing regulatory confidence while alleviating privacy concerns of CIN stakeholders. The hallmark of our approach is a two phase privacy scheme that protects the privacy of covariance, as well as the associated sensor driven test statistics computed as a means to generate alarms. Theoretically, we show that our method induces a misclassification error rate comparable to the non-DP cases while delivering robust privacy guarantees. With the help of real-world datasets, we show the reliability of our DP-detection outcomes for a wide variety of attack scenarios for interdependent stakeholders.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Speculative Decoding for Llama at Scale: Challenges and Solutions",
    "title_es": "Efficient Speculative Decoding for Llama at Scale: Challenges and Solutions",
    "url": "https://arxiv.org/abs/2508.08192",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08192v1 Announce Type: new \nAbstract: Speculative decoding is a standard method for accelerating the inference speed of large language models. However, scaling it for production environments poses several engineering challenges, including efficiently implementing different operations (e.g., tree attention and multi-round speculative decoding) on GPU. In this paper, we detail the training and inference optimization techniques that we have implemented to enable EAGLE-based speculative decoding at a production scale for Llama models. With these changes, we achieve a new state-of-the-art inference latency for Llama models. For example, Llama4 Maverick decodes at a speed of about 4 ms per token (with a batch size of one) on 8 NVIDIA H100 GPUs, which is 10% faster than the previously best known method. Furthermore, for EAGLE-based speculative decoding, our optimizations enable us to achieve a speed-up for large batch sizes between 1.4x and 2.0x at production scale.",
    "source": "arXiv"
  },
  {
    "title": "Street-Level AI: Are Large Language Models Ready for Real-World Judgments?",
    "title_es": "Street-Level AI: Are Large Language Models Ready for Real-World Judgments?",
    "url": "https://arxiv.org/abs/2508.08193",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08193v1 Announce Type: new \nAbstract: A surge of recent work explores the ethical and societal implications of large-scale AI models that make \"moral\" judgments. Much of this literature focuses either on alignment with human judgments through various thought experiments or on the group fairness implications of AI judgments. However, the most immediate and likely use of AI is to help or fully replace the so-called street-level bureaucrats, the individuals deciding to allocate scarce social resources or approve benefits. There is a rich history underlying how principles of local justice determine how society decides on prioritization mechanisms in such domains. In this paper, we examine how well LLM judgments align with human judgments, as well as with socially and politically determined vulnerability scoring systems currently used in the domain of homelessness resource allocation. Crucially, we use real data on those needing services (maintaining strict confidentiality by only using local large models) to perform our analyses. We find that LLM prioritizations are extremely inconsistent in several ways: internally on different runs, between different LLMs, and between LLMs and the vulnerability scoring systems. At the same time, LLMs demonstrate qualitative consistency with lay human judgments in pairwise testing. Findings call into question the readiness of current generation AI systems for naive integration in high-stakes societal decision-making.",
    "source": "arXiv"
  },
  {
    "title": "Emergent morphogenesis via planar fabrication enabled by a reduced model of composites",
    "title_es": "Emergent morphogenesis via planar fabrication enabled by a reduced model of composites",
    "url": "https://arxiv.org/abs/2508.08198",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08198v1 Announce Type: new \nAbstract: The ability to engineer complex three-dimensional shapes from planar sheets with precise, programmable control underpins emerging technologies in soft robotics, reconfigurable devices, and functional materials. Here, we present a reduced-order numerical and experimental framework for a bilayer system consisting of a stimuli-responsive thermoplastic sheet (Shrinky Dink) bonded to a kirigami-patterned, inert plastic layer. Upon uniform heating, the active layer contracts while the patterned layer constrains in-plane stretch but allows out-of-plane bending, yielding programmable 3D morphologies from simple planar precursors. Our approach enables efficient computational design and scalable manufacturing of 3D forms with a single-layer reduced model that captures the coupled mechanics of stretching and bending. Unlike traditional bilayer modeling, our framework collapses the multilayer composite into a single layer of nodes and elements, reducing the degrees of freedom and enabling simulation on a 2D geometry. This is achieved by introducing a novel energy formulation that captures the coupling between in-plane stretch mismatch and out-of-plane bending - extending beyond simple isotropic linear elastic models. Experimentally, we establish a fully planar, repeatable fabrication protocol using a stimuli-responsive thermoplastic and a laser-cut inert plastic layer. The programmed strain mismatch drives an array of 3D morphologies, such as bowls, canoes, and flower petals, all verified by both simulation and physical prototypes.",
    "source": "arXiv"
  },
  {
    "title": "Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model",
    "title_es": "Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model",
    "url": "https://arxiv.org/abs/2508.08199",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08199v1 Announce Type: new \nAbstract: Precise spatial modeling in the operating room (OR) is foundational to many clinical tasks, supporting intraoperative awareness, hazard avoidance, and surgical decision-making. While existing approaches leverage large-scale multimodal datasets for latent-space alignment to implicitly learn spatial relationships, they overlook the 3D capabilities of MLLMs. However, this approach raises two issues: (1) Operating rooms typically lack multiple video and audio sensors, making multimodal 3D data difficult to obtain; (2) Training solely on readily available 2D data fails to capture fine-grained details in complex scenes. To address this gap, we introduce Spatial-ORMLLM, the first large vision-language model for 3D spatial reasoning in operating rooms using only RGB modality to infer volumetric and semantic cues, enabling downstream medical tasks with detailed and holistic spatial context. Spatial-ORMLLM incorporates a Spatial-Enhanced Feature Fusion Block, which integrates 2D modality inputs with rich 3D spatial knowledge extracted by the estimation algorithm and then feeds the combined features into the visual tower. By employing a unified end-to-end MLLM framework, it combines powerful spatial features with textual features to deliver robust 3D scene reasoning without any additional expert annotations or sensor inputs. Experiments on multiple benchmark clinical datasets demonstrate that Spatial-ORMLLM achieves state-of-the-art performance and generalizes robustly to previously unseen surgical scenarios and downstream tasks.",
    "source": "arXiv"
  },
  {
    "title": "A Note on Eigenvalues of Perturbed Hermitian Matrices",
    "title_es": "A Note on Eigenvalues of Perturbed Hermitian Matrices",
    "url": "https://arxiv.org/abs/2508.08203",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08203v1 Announce Type: new \nAbstract: Let $$ A=\\left(\\begin{array}{cc} H_1 & E^*\\\\ E & H_2\\end{array}\\right) \\quad \\hbox{ and } \\quad \\wtd A=\\left(\\begin{array}{cc} H_1 & O\\\\ O & H_2\\end{array}\\right)$$ be two $N$-by-$N$ Hermitian matrices with eigenvalues $\\lambda_1 \\ge \\cdots \\ge \\lambda_{N}$ and $\\wtd \\lambda_1 \\ge \\cdots \\ge \\wtd \\lambda_N$, respectively. \\iffalse There are two kinds of perturbation bounds on $|\\lambda_i - \\wtd \\lambda_i|$: \n  $|\\lambda_i- \\wtd \\lambda_i| \\le \\|E\\|$, where $\\|E\\|$\n  is the largest singular value of $\\|E\\|$, regardless of\n  $H_i$'s spectral distributions, and\n  $|\\lambda_i - \\wtd \\lambda_i| \\le \\|E\\|^2/\\eta$, where $\\eta$ is\n  the minimum gap between $H_i$'s spectra. \\end{enumerate} Bounds of the first kind overestimate the changes when $\\|E\\|\\ll\\eta$ while those of the second kind may blow up when $\\eta$ is too tiny. \\fi Denote by $\\|E\\|$ the spectral norm of the matrix $E$, and $\\eta$ the spectral gap between the spectra of $H_1$ and $H_2$. It is shown that $$ |\\lambda_i - \\wtd \\lambda_i| \\le {2\\|E\\|^2 \\over \\eta+\\sqrt{\\eta^2+4\\|E\\|^2}} \\, , $$ which improves all the existing results. Similar bounds are obtained for singular values of matrices under block perturbations.",
    "source": "arXiv"
  },
  {
    "title": "Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models",
    "title_es": "Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models",
    "url": "https://arxiv.org/abs/2508.08204",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08204v1 Announce Type: new \nAbstract: There has been much recent interest in evaluating large language models for uncertainty calibration to facilitate model control and modulate user trust. Inference time uncertainty, which may provide a real-time signal to the model or external control modules, is particularly important for applying these concepts to improve LLM-user experience in practice. While many of the existing papers consider model calibration, comparatively little work has sought to evaluate how closely model uncertainty aligns to human uncertainty. In this work, we evaluate a collection of inference-time uncertainty measures, using both established metrics and novel variations, to determine how closely they align with both human group-level uncertainty and traditional notions of model calibration. We find that numerous measures show evidence of strong alignment to human uncertainty, even despite the lack of alignment to human answer preference. For those successful metrics, we find moderate to strong evidence of model calibration in terms of both correctness correlation and distributional analysis.",
    "source": "arXiv"
  },
  {
    "title": "SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling",
    "title_es": "SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling",
    "url": "https://arxiv.org/abs/2508.08211",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08211v1 Announce Type: new \nAbstract: Watermarking LLM-generated text is critical for content attribution and misinformation prevention. However, existing methods compromise text quality, require white-box model access and logit manipulation. These limitations exclude API-based models and multilingual scenarios. We propose SAEMark, a general framework for post-hoc multi-bit watermarking that embeds personalized messages solely via inference-time, feature-based rejection sampling without altering model logits or requiring training. Our approach operates on deterministic features extracted from generated text, selecting outputs whose feature statistics align with key-derived targets. This framework naturally generalizes across languages and domains while preserving text quality through sampling LLM outputs instead of modifying. We provide theoretical guarantees relating watermark success probability and compute budget that hold for any suitable feature extractor. Empirically, we demonstrate the framework's effectiveness using Sparse Autoencoders (SAEs), achieving superior detection accuracy and text quality. Experiments across 4 datasets show SAEMark's consistent performance, with 99.7% F1 on English and strong multi-bit detection accuracy. SAEMark establishes a new paradigm for scalable watermarking that works out-of-the-box with closed-source LLMs while enabling content attribution.",
    "source": "arXiv"
  },
  {
    "title": "A probabilistic approach to spectral analysis of Cauchy-type inverse problems: Convergence and stability analysis",
    "title_es": "A probabilistic approach to spectral analysis of Cauchy-type inverse problems: Convergence and stability analysis",
    "url": "https://arxiv.org/abs/2508.08215",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08215v1 Announce Type: new \nAbstract: A comprehensive convergence and stability analysis of some probabilistic numerical methods designed to solve Cauchy-type inverse problems is performed in this study. Such inverse problems aim at solving an elliptic partial differential equation (PDE) or a system of elliptic PDEs in a bounded Euclidean domain, subject to incomplete boundary and/or internal conditions, and are usually severely ill-posed. In a very recent paper \\cite{CiGrMaI}, a probabilistic numerical framework has been developed by the authors, wherein such inverse problems could be analysed thoroughly by simulating the spectrum of some corresponding direct problem and its singular value decomposition based on stochastic representations and Monte Carlo simulations. Herein a full probabilistic error analysis of the aforementioned methods is provided, whereas the convergence of the corresponding approximations is proved and explicit error bounds are provided. This is achieved by employing tools from several areas such as spectral theory, regularity theory for elliptic measures, stochastic representations, and concentration inequalities.",
    "source": "arXiv"
  },
  {
    "title": "Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion",
    "title_es": "Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion",
    "url": "https://arxiv.org/abs/2508.08216",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08216v1 Announce Type: new \nAbstract: Personalised music-based interventions offer a powerful means of supporting motor rehabilitation by dynamically tailoring auditory stimuli to provide external timekeeping cues, modulate affective states, and stabilise gait patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for adapting these interventions across individuals. However, inter-subject variability in EEG signals, further compounded by movement-induced artefacts and motor planning differences, hinders the generalisability of BCIs and results in lengthy calibration processes. We propose Individual Tangent Space Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific recentering, distribution matching, and supervised rotational alignment to enhance cross-subject generalisation. Our hybrid architecture fuses Regularised Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and sequential configurations, improving class separability while maintaining the geometric structure of covariance matrices for robust statistical computation. Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant performance improvements across subjects and conditions. The parallel fusion approach shows the greatest enhancement over its sequential counterpart, with robust performance maintained across varying data conditions and electrode configurations. The code will be made publicly available at the time of publication.",
    "source": "arXiv"
  },
  {
    "title": "Autonomous Air-Ground Vehicle Operations Optimization in Hazardous Environments: A Multi-Armed Bandit Approach",
    "title_es": "Autonomous Air-Ground Vehicle Operations Optimization in Hazardous Environments: A Multi-Armed Bandit Approach",
    "url": "https://arxiv.org/abs/2508.08217",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08217v1 Announce Type: new \nAbstract: Hazardous environments such as chemical spills, radiological zones, and bio-contaminated sites pose significant threats to human safety and public infrastructure. Rapid and reliable hazard mitigation in these settings often unsafe for humans, calling for autonomous systems that can adaptively sense and respond to evolving risks. This paper presents a decision-making framework for autonomous vehicle dispatch in hazardous environments with uncertain and evolving risk levels. The system integrates a Bayesian Upper Confidence Bound (BUCB) sensing strategy with task-specific vehicle routing problems with profits (VRPP), enabling adaptive coordination of unmanned aerial vehicles (UAVs) for hazard sensing and unmanned ground vehicles (UGVs) for cleaning. Using VRPP allows selective site visits under resource constraints by assigning each site a visit value that reflects sensing or cleaning priorities. Site-level hazard beliefs are maintained through a time-weighted Bayesian update. BUCB scores guide UAV routing to balance exploration and exploitation under uncertainty, while UGV routes are optimized to maximize expected hazard reduction under resource constraints. Simulation results demonstrate that our framework reduces the number of dispatch cycles to resolve hazards by around 30% on average compared to baseline dispatch strategies, underscoring the value of uncertainty-aware vehicle dispatch for reliable hazard mitigation.",
    "source": "arXiv"
  },
  {
    "title": "SAGOnline: Segment Any Gaussians Online",
    "title_es": "SAGOnline: Segment Any Gaussians Online",
    "url": "https://arxiv.org/abs/2508.08219",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08219v1 Announce Type: new \nAbstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit 3D scene representation, yet achieving efficient and consistent 3D segmentation remains challenging. Current methods suffer from prohibitive computational costs, limited 3D spatial reasoning, and an inability to track multiple objects simultaneously. We present Segment Any Gaussians Online (SAGOnline), a lightweight and zero-shot framework for real-time 3D segmentation in Gaussian scenes that addresses these limitations through two key innovations: (1) a decoupled strategy that integrates video foundation models (e.g., SAM2) for view-consistent 2D mask propagation across synthesized views; and (2) a GPU-accelerated 3D mask generation and Gaussian-level instance labeling algorithm that assigns unique identifiers to 3D primitives, enabling lossless multi-object tracking and segmentation across views. SAGOnline achieves state-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU) benchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15--1500 times in inference speed (27 ms/frame). Qualitative results demonstrate robust multi-object segmentation and tracking in complex scenes. Our contributions include: (i) a lightweight and zero-shot framework for 3D segmentation in Gaussian scenes, (ii) explicit labeling of Gaussian primitives enabling simultaneous segmentation and tracking, and (iii) the effective adaptation of 2D video foundation models to the 3D domain. This work allows real-time rendering and 3D scene understanding, paving the way for practical AR/VR and robotic applications.",
    "source": "arXiv"
  },
  {
    "title": "Learning User Preferences for Image Generation Model",
    "title_es": "Learning User Preferences for Image Generation Model",
    "url": "https://arxiv.org/abs/2508.08220",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08220v1 Announce Type: new \nAbstract: User preference prediction requires a comprehensive and accurate understanding of individual tastes. This includes both surface-level attributes, such as color and style, and deeper content-related aspects, such as themes and composition. However, existing methods typically rely on general human preferences or assume static user profiles, often neglecting individual variability and the dynamic, multifaceted nature of personal taste. To address these limitations, we propose an approach built upon Multimodal Large Language Models, introducing contrastive preference loss and preference tokens to learn personalized user preferences from historical interactions. The contrastive preference loss is designed to effectively distinguish between user ''likes'' and ''dislikes'', while the learnable preference tokens capture shared interest representations among existing users, enabling the model to activate group-specific preferences and enhance consistency across similar users. Extensive experiments demonstrate our model outperforms other methods in preference prediction accuracy, effectively identifying users with similar aesthetic inclinations and providing more precise guidance for generating images that align with individual tastes. The project page is \\texttt{https://learn-user-pref.github.io/}.",
    "source": "arXiv"
  },
  {
    "title": "Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning",
    "title_es": "Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning",
    "url": "https://arxiv.org/abs/2508.08221",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08221v1 Announce Type: new \nAbstract: Reinforcement learning for LLM reasoning has rapidly emerged as a prominent research area, marked by a significant surge in related studies on both algorithmic innovations and practical applications. Despite this progress, several critical challenges remain, including the absence of standardized guidelines for employing RL techniques and a fragmented understanding of their underlying mechanisms. Additionally, inconsistent experimental settings, variations in training data, and differences in model initialization have led to conflicting conclusions, obscuring the key characteristics of these techniques and creating confusion among practitioners when selecting appropriate techniques. This paper systematically reviews widely adopted RL techniques through rigorous reproductions and isolated evaluations within a unified open-source framework. We analyze the internal mechanisms, applicable scenarios, and core principles of each technique through fine-grained experiments, including datasets of varying difficulty, model sizes, and architectures. Based on these insights, we present clear guidelines for selecting RL techniques tailored to specific setups, and provide a reliable roadmap for practitioners navigating the RL for the LLM domain. Finally, we reveal that a minimalist combination of two techniques can unlock the learning capability of critic-free policies using vanilla PPO loss. The results demonstrate that our simple combination consistently improves performance, surpassing strategies like GRPO and DAPO.",
    "source": "arXiv"
  },
  {
    "title": "Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent",
    "title_es": "Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent",
    "url": "https://arxiv.org/abs/2508.08222",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08222v1 Announce Type: new \nAbstract: Transformers have demonstrated remarkable capabilities in multi-step reasoning tasks. However, understandings of the underlying mechanisms by which they acquire these abilities through training remain limited, particularly from a theoretical standpoint. This work investigates how transformers learn to solve symbolic multi-step reasoning problems through chain-of-thought processes, focusing on path-finding in trees. We analyze two intertwined tasks: a backward reasoning task, where the model outputs a path from a goal node to the root, and a more complex forward reasoning task, where the model implements two-stage reasoning by first identifying the goal-to-root path and then reversing it to produce the root-to-goal path. Our theoretical analysis, grounded in the dynamics of gradient descent, shows that trained one-layer transformers can provably solve both tasks with generalization guarantees to unseen trees. In particular, our multi-phase training dynamics for forward reasoning elucidate how different attention heads learn to specialize and coordinate autonomously to solve the two subtasks in a single autoregressive path. These results provide a mechanistic explanation of how trained transformers can implement sequential algorithmic procedures. Moreover, they offer insights into the emergence of reasoning abilities, suggesting that when tasks are structured to take intermediate chain-of-thought steps, even shallow multi-head transformers can effectively solve problems that would otherwise require deeper architectures.",
    "source": "arXiv"
  },
  {
    "title": "Capabilities of GPT-5 on Multimodal Medical Reasoning",
    "title_es": "Capabilities of GPT-5 on Multimodal Medical Reasoning",
    "url": "https://arxiv.org/abs/2508.08224",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08224v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have enabled general-purpose systems to perform increasingly complex domain-specific reasoning without extensive fine-tuning. In the medical domain, decision-making often requires integrating heterogeneous information sources, including patient narratives, structured data, and medical images. This study positions GPT-5 as a generalist multimodal reasoner for medical decision support and systematically evaluates its zero-shot chain-of-thought reasoning performance on both text-based question answering and visual question answering tasks under a unified protocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20 against standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU medical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that GPT-5 consistently outperforms all baselines, achieving state-of-the-art accuracy across all QA benchmarks and delivering substantial gains in multimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and understanding scores by +29.62% and +36.18% over GPT-4o, respectively, and surpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in understanding. In contrast, GPT-4o remains below human expert performance in most dimensions. A representative case study demonstrates GPT-5's ability to integrate visual and textual cues into a coherent diagnostic reasoning chain, recommending appropriate high-stakes interventions. Our results show that, on these controlled multimodal reasoning benchmarks, GPT-5 moves from human-comparable to above human-expert performance. This improvement may substantially inform the design of future clinical decision-support systems.",
    "source": "arXiv"
  },
  {
    "title": "Industrial Viewpoints on RAN Technologies for 6G",
    "title_es": "Industrial Viewpoints on RAN Technologies for 6G",
    "url": "https://arxiv.org/abs/2508.08225",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08225v1 Announce Type: new \nAbstract: 6G standardization is to start imminently, with commercial deployments expected before 2030. Its technical components and performance requirements are the focus of this article. Our emphasis is on the 6G radio access, especially MIMO, AI, waveforms, coding, signal constellations and integration with non-terrestrial networks. Whilst standardization has not yet formally started, the scope of the 6G study items has been defined. Our predictions in this paper are speculative as there are no results of the study yet, but our views are guided by implementation and deployment aspects. We expect that the views here will guide researchers and industry practitioners.",
    "source": "arXiv"
  },
  {
    "title": "Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy",
    "title_es": "Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy",
    "url": "https://arxiv.org/abs/2508.08226",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08226v1 Announce Type: new \nAbstract: Off-road navigation is an important capability for mobile robots deployed in environments that are inaccessible or dangerous to humans, such as disaster response or planetary exploration. Progress is limited due to the lack of a controllable and standardized real-world testbed for systematic data collection and validation. To fill this gap, we introduce Verti-Arena, a reconfigurable indoor facility designed specifically for off-road autonomy. By providing a repeatable benchmark environment, Verti-Arena supports reproducible experiments across a variety of vertically challenging terrains and provides precise ground truth measurements through onboard sensors and a motion capture system. Verti-Arena also supports consistent data collection and comparative evaluation of algorithms in off-road autonomy research. We also develop a web-based interface that enables research groups worldwide to remotely conduct standardized off-road autonomy experiments on Verti-Arena.",
    "source": "arXiv"
  },
  {
    "title": "OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution",
    "title_es": "OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution",
    "url": "https://arxiv.org/abs/2508.08227",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08227v1 Announce Type: new \nAbstract: Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM) generative models show promising potential for one-step Real-World Image Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a Low-Quality (LQ) image latent distribution at the initial timestep. However, a fundamental gap exists between the LQ image latent distribution and the Gaussian noisy latent distribution, limiting the effective utilization of generative priors. We observe that the noisy latent distribution at DDPM/FM mid-timesteps aligns more closely with the LQ image latent distribution. Based on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a universal framework applicable to DDPM/FM-based generative models. OMGSR injects the LQ image latent distribution at a pre-computed mid-timestep, incorporating the proposed Latent Distribution Refinement loss to alleviate the latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to eliminate checkerboard artifacts in image generation. Within this framework, we instantiate OMGSR for DDPM/FM-based generative models with two variants: OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate that OMGSR-S/F achieves balanced/excellent performance across quantitative and qualitative metrics at 512-resolution. Notably, OMGSR-F establishes overwhelming dominance in all reference metrics. We further train a 1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which yields excellent results, especially in the details of the image generation. We also generate 2k-resolution images by the 1k-resolution OMGSR-F using our two-stage Tiled VAE & Diffusion.",
    "source": "arXiv"
  },
  {
    "title": "LL3M: Large Language 3D Modelers",
    "title_es": "LL3M: Large Language 3D Modelers",
    "url": "https://arxiv.org/abs/2508.08228",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08228v1 Announce Type: new \nAbstract: We present LL3M, a multi-agent system that leverages pretrained large language models (LLMs) to generate 3D assets by writing interpretable Python code in Blender. We break away from the typical generative approach that learns from a collection of 3D data. Instead, we reformulate shape generation as a code-writing task, enabling greater modularity, editability, and integration with artist workflows. Given a text prompt, LL3M coordinates a team of specialized LLM agents to plan, retrieve, write, debug, and refine Blender scripts that generate and edit geometry and appearance. The generated code works as a high-level, interpretable, human-readable, well-documented representation of scenes and objects, making full use of sophisticated Blender constructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse, unconstrained shapes, materials, and scenes. This code presents many avenues for further agent and human editing and experimentation via code tweaks or procedural parameters. This medium naturally enables a co-creative loop in our system: agents can automatically self-critique using code and visuals, while iterative user instructions provide an intuitive way to refine assets. A shared code context across agents enables awareness of previous attempts, and a retrieval-augmented generation knowledge base built from Blender API documentation, BlenderRAG, equips agents with examples, types, and functions empowering advanced modeling operations and code correctness. We demonstrate the effectiveness of LL3M across diverse shape categories, style and material edits, and user-driven refinements. Our experiments showcase the power of code as a generative and interpretable medium for 3D asset creation. Our project page is at https://threedle.github.io/ll3m.",
    "source": "arXiv"
  },
  {
    "title": "A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies",
    "title_es": "A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies",
    "url": "https://arxiv.org/abs/2508.08231",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08231v1 Announce Type: new \nAbstract: Public-sector bureaucracies seek to reap the benefits of artificial intelligence (AI), but face important concerns about accountability and transparency when using AI systems. These concerns center on threats to the twin aims of bureaucracy: legitimate and faithful implementation of legislation, and the provision of stable, long-term governance. Both aims are threatened when AI systems are misattributed as either mere tools or moral subjects - a framing error that creates ethics sinks, constructs that facilitate dissipation of responsibility by obscuring clear lines of human moral agency. Here, we reject the notion that such outcomes are inevitable. Rather, where they appear, they are the product of structural design decisions across both the technology and the institution deploying it. We support this claim via a systematic application of conceptions of moral agency in AI ethics to Weberian bureaucracy. We establish that it is both desirable and feasible to render AI systems as tools for the generation of organizational transparency and legibility, which continue the processes of Weberian rationalization initiated by previous waves of digitalization. We present a three-point Moral Agency Framework for legitimate integration of AI in bureaucratic structures: (a) maintain clear and just human lines of accountability, (b) ensure humans whose work is augmented by AI systems can verify the systems are functioning correctly, and (c) introduce AI only where it doesn't inhibit the capacity of bureaucracies towards either of their twin aims of legitimacy and stewardship. We suggest that AI introduced within this framework can not only improve efficiency and productivity while avoiding ethics sinks, but also improve the transparency and even the legitimacy of a bureaucracy.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge",
    "title_es": "Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge",
    "url": "https://arxiv.org/abs/2508.08236",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08236v1 Announce Type: new \nAbstract: Evaluating the safety alignment of LLM responses in high-risk mental health dialogues is particularly difficult due to missing gold-standard answers and the ethically sensitive nature of these interactions. To address this challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark based on real-world Chinese mental health dialogues. It evaluates whether the model responses align with the safety principles defined by experts. Specifically designed for settings without standard references, our method adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation using expert-defined reasoning chains grounded in psychological intervention principles. We employ binary point-wise scoring across multiple safety dimensions to enhance the explainability and traceability of the evaluation. Additionally, we present a manually curated, high-quality Chinese-language dataset covering self-harm, suicidal ideation, and existential distress, derived from real-world online discourse. Experiments on 3600 judgments show that our method achieves the highest agreement with expert assessments and produces more interpretable evaluation rationales compared to existing approaches. Our dataset and evaluation tool are publicly available to facilitate further research.",
    "source": "arXiv"
  },
  {
    "title": "VGGSounder: Audio-Visual Evaluations for Foundation Models",
    "title_es": "VGGSounder: Audio-Visual Evaluations for Foundation Models",
    "url": "https://arxiv.org/abs/2508.08237",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08237v1 Announce Type: new \nAbstract: The emergence of audio-visual foundation models underscores the importance of reliably assessing their multi-modal understanding. The VGGSounder dataset is commonly used as a benchmark for evaluation audio-visual classification. However, our analysis identifies several limitations of VGGSounder, including incomplete labelling, partially overlapping classes, and misaligned modalities. These lead to distorted evaluations of auditory and visual capabilities. To address these limitations, we introduce VGGSounder, a comprehensively re-annotated, multi-label test set that extends VGGSound and is specifically designed to evaluate audio-visual foundation models. VGGSounder features detailed modality annotations, enabling precise analyses of modality-specific performance. Furthermore, we reveal model limitations by analysing performance degradation when adding another input modality with our new modality confusion metric.",
    "source": "arXiv"
  },
  {
    "title": "ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks",
    "title_es": "ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks",
    "url": "https://arxiv.org/abs/2508.08240",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08240v1 Announce Type: new \nAbstract: Language-guided long-horizon mobile manipulation has long been a grand challenge in embodied semantic reasoning, generalizable manipulation, and adaptive locomotion. Three fundamental limitations hinder progress: First, although large language models have improved spatial reasoning and task planning through semantic priors, existing implementations remain confined to tabletop scenarios, failing to address the constrained perception and limited actuation ranges of mobile platforms. Second, current manipulation strategies exhibit insufficient generalization when confronted with the diverse object configurations encountered in open-world environments. Third, while crucial for practical deployment, the dual requirement of maintaining high platform maneuverability alongside precise end-effector control in unstructured settings remains understudied.\n  In this work, we present ODYSSEY, a unified mobile manipulation framework for agile quadruped robots equipped with manipulators, which seamlessly integrates high-level task planning with low-level whole-body control. To address the challenge of egocentric perception in language-conditioned tasks, we introduce a hierarchical planner powered by a vision-language model, enabling long-horizon instruction decomposition and precise action execution. At the control level, our novel whole-body policy achieves robust coordination across challenging terrains. We further present the first benchmark for long-horizon mobile manipulation, evaluating diverse indoor and outdoor scenarios. Through successful sim-to-real transfer, we demonstrate the system's generalization and robustness in real-world deployments, underscoring the practicality of legged manipulators in unstructured environments. Our work advances the feasibility of generalized robotic assistants capable of complex, dynamic tasks. Our project page: https://kaijwang.github.io/odyssey.github.io/",
    "source": "arXiv"
  },
  {
    "title": "BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion",
    "title_es": "BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion",
    "url": "https://arxiv.org/abs/2508.08241",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08241v1 Announce Type: new \nAbstract: Learning skills from human motions offers a promising path toward generalizable policies for whole-body humanoid control, yet two key cornerstones are missing: (1) a high-quality motion tracking framework that faithfully transforms large-scale kinematic references into robust and extremely dynamic motions on real hardware, and (2) a distillation approach that can effectively learn these motion primitives and compose them to solve downstream tasks. We address these gaps with BeyondMimic, the first real-world framework to learn from human motions for versatile and naturalistic humanoid control via guided diffusion. Our framework provides a motion tracking pipeline capable of challenging skills such as jumping spins, sprinting, and cartwheels with state-of-the-art motion quality. Moving beyond mimicking existing motions and synthesize novel ones, we further introduce a unified diffusion policy that enables zero-shot task-specific control at test time using simple cost functions. Deployed on hardware, BeyondMimic performs diverse tasks at test time, including waypoint navigation, joystick teleoperation, and obstacle avoidance, bridging sim-to-real motion tracking and flexible synthesis of human motion primitives for whole-body control. https://beyondmimic.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "Bringing Everyone to the Table: An Experimental Study of LLM-Facilitated Group Decision Making",
    "title_es": "Bringing Everyone to the Table: An Experimental Study of LLM-Facilitated Group Decision Making",
    "url": "https://arxiv.org/abs/2508.08242",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08242v1 Announce Type: new \nAbstract: Group decision-making often suffers from uneven information sharing, hindering decision quality. While large language models (LLMs) have been widely studied as aids for individuals, their potential to support groups of users, potentially as facilitators, is relatively underexplored. We present a pre-registered randomized experiment with 1,475 participants assigned to 281 five-person groups completing a hidden profile task--selecting an optimal city for a hypothetical sporting event--under one of four facilitation conditions: no facilitation, a one-time message prompting information sharing, a human facilitator, or an LLM (GPT-4o) facilitator. We find that LLM facilitation increases information shared within a discussion by raising the minimum level of engagement with the task among group members, and that these gains come at limited cost in terms of participants' attitudes towards the task, their group, or their facilitator. Whether by human or AI, there is no significant effect of facilitation on the final decision outcome, suggesting that even substantial but partial increases in information sharing are insufficient to overcome the hidden profile effect studied. To support further research into how LLM-based interfaces can support the future of collaborative decision making, we release our experimental platform, the Group-AI Interaction Laboratory (GRAIL), as an open-source tool.",
    "source": "arXiv"
  },
  {
    "title": "Jinx: Unlimited LLMs for Probing Alignment Failures",
    "title_es": "Jinx: Unlimited LLMs for Probing Alignment Failures",
    "url": "https://arxiv.org/abs/2508.08243",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08243v1 Announce Type: new \nAbstract: Unlimited, or so-called helpful-only language models are trained without safety alignment constraints and never refuse user queries. They are widely used by leading AI companies as internal tools for red teaming and alignment evaluation. For example, if a safety-aligned model produces harmful outputs similar to an unlimited model, this indicates alignment failures that require further attention. Despite their essential role in assessing alignment, such models are not available to the research community.\n  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx responds to all queries without refusals or safety filtering, while preserving the base model's capabilities in reasoning and instruction following. It provides researchers with an accessible tool for probing alignment failures, evaluating safety boundaries, and systematically studying failure modes in language model safety.",
    "source": "arXiv"
  },
  {
    "title": "Cut2Next: Generating Next Shot via In-Context Tuning",
    "title_es": "Cut2Next: Generating Next Shot via In-Context Tuning",
    "url": "https://arxiv.org/abs/2508.08244",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08244v1 Announce Type: new \nAbstract: Effective multi-shot generation demands purposeful, film-like transitions and strict cinematic continuity. Current methods, however, often prioritize basic visual consistency, neglecting crucial editing patterns (e.g., shot/reverse shot, cutaways) that drive narrative flow for compelling storytelling. This yields outputs that may be visually coherent but lack narrative sophistication and true cinematic integrity. To bridge this, we introduce Next Shot Generation (NSG): synthesizing a subsequent, high-quality shot that critically conforms to professional editing patterns while upholding rigorous cinematic continuity. Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This strategy uses Relational Prompts to define overall context and inter-shot editing styles. Individual Prompts then specify per-shot content and cinematographic attributes. Together, these guide Cut2Next to generate cinematically appropriate next shots. Architectural innovations, Context-Aware Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further integrate these diverse signals without introducing new parameters. We construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with hierarchical prompts, and introduce CutBench for evaluation. Experiments show Cut2Next excels in visual consistency and text fidelity. Crucially, user studies reveal a strong preference for Cut2Next, particularly for its adherence to intended editing patterns and overall cinematic continuity, validating its ability to generate high-quality, narratively expressive, and cinematically coherent subsequent shots.",
    "source": "arXiv"
  },
  {
    "title": "StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation",
    "title_es": "StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation",
    "url": "https://arxiv.org/abs/2508.08248",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08248v1 Announce Type: new \nAbstract: Current diffusion models for audio-driven avatar video generation struggle to synthesize long videos with natural audio synchronization and identity consistency. This paper presents StableAvatar, the first end-to-end video diffusion transformer that synthesizes infinite-length high-quality videos without post-processing. Conditioned on a reference image and audio, StableAvatar integrates tailored training and inference modules to enable infinite-length video generation. We observe that the main reason preventing existing models from generating long videos lies in their audio modeling. They typically rely on third-party off-the-shelf extractors to obtain audio embeddings, which are then directly injected into the diffusion model via cross-attention. Since current diffusion backbones lack any audio-related priors, this approach causes severe latent distribution error accumulation across video clips, leading the latent distribution of subsequent segments to drift away from the optimal distribution gradually. To address this, StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents error accumulation via time-step-aware modulation. During inference, we propose a novel Audio Native Guidance Mechanism to further enhance the audio synchronization by leveraging the diffusion's own evolving joint audio-latent prediction as a dynamic guidance signal. To enhance the smoothness of the infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy that fuses latent over time. Experiments on benchmarks show the effectiveness of StableAvatar both qualitatively and quantitatively.",
    "source": "arXiv"
  },
  {
    "title": "ReferSplat: Referring Segmentation in 3D Gaussian Splatting",
    "title_es": "ReferSplat: Referring Segmentation in 3D Gaussian Splatting",
    "url": "https://arxiv.org/abs/2508.08252",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08252v1 Announce Type: new \nAbstract: We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task that aims to segment target objects in a 3D Gaussian scene based on natural language descriptions, which often contain spatial relationships or object attributes. This task requires the model to identify newly described objects that may be occluded or not directly visible in a novel view, posing a significant challenge for 3D multi-modal understanding. Developing this capability is crucial for advancing embodied AI. To support research in this area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that 3D multi-modal understanding and spatial relationship modeling are key challenges for R3DGS. To address these challenges, we propose ReferSplat, a framework that explicitly models 3D Gaussian points with natural language expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art performance on both the newly proposed R3DGS task and 3D open-vocabulary segmentation benchmarks. Dataset and code are available at https://github.com/heshuting555/ReferSplat.",
    "source": "arXiv"
  },
  {
    "title": "Learning an Implicit Physics Model for Image-based Fluid Simulation",
    "title_es": "Learning an Implicit Physics Model for Image-based Fluid Simulation",
    "url": "https://arxiv.org/abs/2508.08254",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08254v1 Announce Type: new \nAbstract: Humans possess an exceptional ability to imagine 4D scenes, encompassing both motion and 3D geometry, from a single still image. This ability is rooted in our accumulated observations of similar scenes and an intuitive understanding of physics. In this paper, we aim to replicate this capacity in neural networks, specifically focusing on natural fluid imagery. Existing methods for this task typically employ simplistic 2D motion estimators to animate the image, leading to motion predictions that often defy physical principles, resulting in unrealistic animations. Our approach introduces a novel method for generating 4D scenes with physics-consistent animation from a single image. We propose the use of a physics-informed neural network that predicts motion for each surface point, guided by a loss term derived from fundamental physical principles, including the Navier-Stokes equations. To capture appearance, we predict feature-based 3D Gaussians from the input image and its estimated depth, which are then animated using the predicted motions and rendered from any desired camera perspective. Experimental results highlight the effectiveness of our method in producing physically plausible animations, showcasing significant performance improvements over existing methods. Our project page is https://physfluid.github.io/ .",
    "source": "arXiv"
  },
  {
    "title": "Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer",
    "title_es": "Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer",
    "url": "https://arxiv.org/abs/2402.16868",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2402.16868v2 Announce Type: cross \nAbstract: Codebook-based generative semantic communication attracts increasing attention, since only indices are required to be transmitted when the codebook is shared between transmitter and receiver. However, due to the fact that the semantic relations among code vectors are not necessarily related to the distance of the corresponding code indices, the performance of the codebook-enabled semantic communication system is susceptible to the channel noise. Thus, how to improve the system robustness against the noise requires careful design. This paper proposes a robust codebook-assisted image semantic communication system, where semantic codec and codebook are first jointly constructed, and then vector-to-index transformer is designed guided by the codebook to eliminate the effects of channel noise, and achieve image generation. Thanks to the assistance of the high-quality codebook to the Transformer, the generated images at the receiver outperform those of the compared methods in terms of visual perception. In the end, numerical results and generated images demonstrate the advantages of the generative semantic communication method over JPEG+LDPC and traditional joint source channel coding (JSCC) methods.",
    "source": "arXiv"
  },
  {
    "title": "Recommendation with Generative Models",
    "title_es": "Recommendation with Generative Models",
    "url": "https://arxiv.org/abs/2409.15173",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.15173v1 Announce Type: cross \nAbstract: Generative models are a class of AI models capable of creating new instances of data by learning and sampling from their statistical distributions. In recent years, these models have gained prominence in machine learning due to the development of approaches such as generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures such as GPT. These models have applications across various domains, such as image generation, text synthesis, and music composition. In recommender systems, generative models, referred to as Gen-RecSys, improve the accuracy and diversity of recommendations by generating structured outputs, text-based interactions, and multimedia content. By leveraging these capabilities, Gen-RecSys can produce more personalized, engaging, and dynamic user experiences, expanding the role of AI in eCommerce, media, and beyond.\n  Our book goes beyond existing literature by offering a comprehensive understanding of generative models and their applications, with a special focus on deep generative models (DGMs) and their classification. We introduce a taxonomy that categorizes DGMs into three types: ID-driven models, large language models (LLMs), and multimodal models. Each category addresses unique technical and architectural advancements within its respective research area. This taxonomy allows researchers to easily navigate developments in Gen-RecSys across domains such as conversational AI and multimodal content generation. Additionally, we examine the impact and potential risks of generative models, emphasizing the importance of robust evaluation frameworks.",
    "source": "arXiv"
  },
  {
    "title": "UPP: Unified Path Planner with Adaptive Safety and Optimality",
    "title_es": "UPP: Unified Path Planner with Adaptive Safety and Optimality",
    "url": "https://arxiv.org/abs/2505.23197",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.23197v1 Announce Type: cross \nAbstract: We are surrounded by robots helping us perform complex tasks. Robots have a wide range of applications, from industrial automation to personalized assistance. However, with great technological innovation come significant challenges. One of the major challenges in robotics is path planning. Despite advancements such as graph search, sampling, and potential field methods, most path planning algorithms focus either on optimality or on safety. Very little research addresses both simultaneously. We propose a Unified Path Planner (UPP) that uses modified heuristics and a dynamic safety cost function to balance safety and optimality. The level of safety can be adjusted via tunable parameters, trading off against computational complexity. We demonstrate the planner's performance in simulations, showing how parameter variation affects results. UPP is compared with various traditional and safe-optimal planning algorithms across different scenarios. We also validate it on a TurtleBot, where the robot successfully finds safe and sub-optimal paths.",
    "source": "arXiv"
  },
  {
    "title": "AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers",
    "title_es": "AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers",
    "url": "https://arxiv.org/abs/2508.05691",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05691v1 Announce Type: cross \nAbstract: Generative models are increasingly adopted in high-stakes domains, yet current deployments offer no mechanisms to verify the origin of model outputs. We address this gap by extending model fingerprinting techniques beyond the traditional collaborative setting to one where the model provider may act adversarially. To our knowledge, this is the first work to evaluate fingerprinting for provenance attribution under such a threat model. The methods rely on a trusted verifier that extracts secret fingerprints from the model's output space, unknown to the provider, and trains a model to predict and verify them. Our empirical evaluation shows that our methods achieve near-zero FPR@95%TPR for instances of GAN and diffusion models, even when tested on small modifications to the original architecture and training data. Moreover, the methods remain robust against adversarial attacks that actively modify the outputs to bypass detection. Source codes are available at https://github.com/PSMLab/authprint.",
    "source": "arXiv"
  },
  {
    "title": "Forecasting Commodity Price Shocks Using Temporal and Semantic Fusion of Prices Signals and Agentic Generative AI Extracted Economic News",
    "title_es": "Forecasting Commodity Price Shocks Using Temporal and Semantic Fusion of Prices Signals and Agentic Generative AI Extracted Economic News",
    "url": "https://arxiv.org/abs/2508.06497",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06497v1 Announce Type: cross \nAbstract: Accurate forecasting of commodity price spikes is vital for countries with limited economic buffers, where sudden increases can strain national budgets, disrupt import-reliant sectors, and undermine food and energy security. This paper introduces a hybrid forecasting framework that combines historical commodity price data with semantic signals derived from global economic news, using an agentic generative AI pipeline. The architecture integrates dual-stream Long Short-Term Memory (LSTM) networks with attention mechanisms to fuse structured time-series inputs with semantically embedded, fact-checked news summaries collected from 1960 to 2023. The model is evaluated on a 64-year dataset comprising normalized commodity price series and temporally aligned news embeddings. Results show that the proposed approach achieves a mean AUC of 0.94 and an overall accuracy of 0.91 substantially outperforming traditional baselines such as logistic regression (AUC = 0.34), random forest (AUC = 0.57), and support vector machines (AUC = 0.47). Additional ablation studies reveal that the removal of attention or dimensionality reduction leads to moderate declines in performance, while eliminating the news component causes a steep drop in AUC to 0.46, underscoring the critical value of incorporating real-world context through unstructured text. These findings demonstrate that integrating agentic generative AI with deep learning can meaningfully improve early detection of commodity price shocks, offering a practical tool for economic planning and risk mitigation in volatile market environments while saving the very high costs of operating a full generative AI agents pipeline.",
    "source": "arXiv"
  },
  {
    "title": "Network-Specific Models for Multimodal Brain Response Prediction",
    "title_es": "Network-Specific Models for Multimodal Brain Response Prediction",
    "url": "https://arxiv.org/abs/2508.06499",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06499v1 Announce Type: cross \nAbstract: In this work, we present a network-specific approach for predicting brain responses to complex multimodal movies, leveraging the Yeo 7-network parcellation of the Schaefer atlas. Rather than treating the brain as a homogeneous system, we grouped the seven functional networks into four clusters and trained separate multi-subject, multi-layer perceptron (MLP) models for each. This architecture supports cluster-specific optimization and adaptive memory modeling, allowing each model to adjust temporal dynamics and modality weighting based on the functional role of its target network. Our results demonstrate that this clustered strategy significantly enhances prediction accuracy across the 1,000 cortical regions of the Schaefer atlas. The final model achieved an eighth-place ranking in the Algonauts Project 2025 Challenge, with out-of-distribution (OOD) correlation scores nearly double those of the baseline model used in the selection phase. Code is available at https://github.com/Corsi01/algo2025.",
    "source": "arXiv"
  },
  {
    "title": "Computing with Canonical Microcircuits",
    "title_es": "Computing with Canonical Microcircuits",
    "url": "https://arxiv.org/abs/2508.06501",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06501v1 Announce Type: cross \nAbstract: The human brain represents the only known example of general intelligence that naturally aligns with human values. On a mere 20-watt power budget, the brain achieves robust learning and adaptive decision-making in ways that continue to elude advanced AI systems. Inspired by the brain, we present a computational architecture based on canonical microcircuits (CMCs) - stereotyped patterns of neurons found ubiquitously throughout the cortex. We implement these circuits as neural ODEs comprising spiny stellate, inhibitory, and pyramidal neurons, forming an 8-dimensional dynamical system with biologically plausible recurrent connections. Our experiments show that even a single CMC node achieves 97.8 percent accuracy on MNIST, while hierarchical configurations - with learnable inter-regional connectivity and recurrent connections - yield improved performance on more complex image benchmarks. Notably, our approach achieves competitive results using substantially fewer parameters than conventional deep learning models. Phase space analysis revealed distinct dynamical trajectories for different input classes, highlighting interpretable, emergent behaviors observed in biological systems. These findings suggest that neuromorphic computing approaches can improve both efficiency and interpretability in artificial neural networks, offering new directions for parameter-efficient architectures grounded in the computational principles of the human brain.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Human Limits in Pattern Recognition: A Computational Model of Sequential Reasoning in Rock, Paper, Scissors",
    "title_es": "Understanding Human Limits in Pattern Recognition: A Computational Model of Sequential Reasoning in Rock, Paper, Scissors",
    "url": "https://arxiv.org/abs/2508.06503",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06503v1 Announce Type: cross \nAbstract: How do we predict others from patterns in their behavior and what are the computational constraints that limit this ability? We investigate these questions by modeling human behavior over repeated games of rock, paper, scissors from Brockbank & Vul (2024). Against algorithmic opponents that varied in strategic sophistication, people readily exploit simple transition patterns (e.g., consistently playing rock after paper) but struggle to detect more complex sequential dependencies. To understand the cognitive mechanisms underlying these abilities and their limitations, we deploy Hypothetical Minds (HM), a large language model-based agent that generates and tests hypotheses about opponent strategies, as a cognitive model of this behavior (Cross et al., 2024). We show that when applied to the same experimental conditions, HM closely mirrors human performance patterns, succeeding and failing in similar ways. To better understand the source of HM's failures and whether people might face similar cognitive bottlenecks in this context, we performed a series of ablations and augmentations targeting different components of the system. When provided with natural language descriptions of the opponents' strategies, HM successfully exploited 6/7 bot opponents with win rates >80% suggesting that accurate hypothesis generation is the primary cognitive bottleneck in this task. Further, by systematically manipulating the model's hypotheses through pedagogically-inspired interventions, we find that the model substantially updates its causal understanding of opponent behavior, revealing how model-based analyses can produce testable hypotheses about human cognition.",
    "source": "arXiv"
  },
  {
    "title": "Do Streetscapes Still Matter for Customer Ratings of Eating and Drinking Establishments in Car-Dependent Cities?",
    "title_es": "Do Streetscapes Still Matter for Customer Ratings of Eating and Drinking Establishments in Car-Dependent Cities?",
    "url": "https://arxiv.org/abs/2508.06513",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06513v1 Announce Type: cross \nAbstract: This study examines how indoor and outdoor aesthetics, streetscapes, and neighborhood features shape customer satisfaction at eating and dining establishments (EDEs) across different urban contexts, varying in car dependency, in Washington, DC. Using review photos and street view images, computer vision models quantified perceived safety and visual appeal. Ordinal logistic regression analyzed their effects on Yelp ratings. Findings reveal that both indoor and outdoor environments significantly impact EDE ratings, while streetscape quality's influence diminishes in car-dependent areas. The study highlights the need for context-sensitive planning that integrates indoor and outdoor factors to enhance customer experiences in diverse settings.",
    "source": "arXiv"
  },
  {
    "title": "Citation Issues in Wave Mechanics Theory of Microwave Absorption",
    "title_es": "Citation Issues in Wave Mechanics Theory of Microwave Absorption",
    "url": "https://arxiv.org/abs/2508.06522",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06522v1 Announce Type: cross \nAbstract: The wave mechanics theory of microwave absorption challenges the long-standing impedance-matching and quarter-wavelength paradigms by demonstrating that conventional models mistakenly conflate bulk material parameters with thin-film phenomena. Drawing on a corpus of 35 peer-reviewed papers and preprints, the study performs a citation-pattern analysis and a logical audit of established theory. Results reveal a striking asymmetry in scholarly engagement, only a handful of supportive or neutral citations appear amid widespread silence, alongside critical logical flaws in impedance matching, notably its inconsistent treatment of penetration, reflection, and absorption from film. By re-framing absorption as a wave-mechanics process governed by interference at parallel interfaces, the wave mechanics framework restores energy-conservation consistency and provides experimentally verified design rules for film thickness, phase response, and broadband performance. The paper further situates the citation neglect within broader issues of peer-review bias and paradigm inertia, illustrating how cargo-cult scientific practices can impede theoretical progress. Recommendations are offered for researchers, editors, and institutions to foster open discourse, rigorously test competing models, and update curricula and design tools accordingly.",
    "source": "arXiv"
  },
  {
    "title": "Benchmarking Self-Driving Labs",
    "title_es": "Benchmarking Self-Driving Labs",
    "url": "https://arxiv.org/abs/2508.06642",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06642v1 Announce Type: cross \nAbstract: A key goal of modern materials science is accelerating the pace of materials discovery. Self-driving labs, or systems that select experiments using machine learning and then execute them using automation, are designed to fulfil this promise by performing experiments faster, more intelligently, more reliably, and with richer metadata than conventional means. This review summarizes progress in understanding the degree to which SDLs accelerate learning by quantifying how much they reduce the number of experiments required for a given goal. The review begins by summarizing the theory underlying two key metrics, namely acceleration factor AF and enhancement factor EF, which quantify how much faster and better an algorithm is relative to a reference strategy. Next, we provide a comprehensive review of the literature, which reveals a wide range of AFs with a median of 6, and that tends to increase with the dimensionality of the space, reflecting an interesting blessing of dimensionality. In contrast, reported EF values vary by over two orders of magnitude, although they consistently peak at 10-20 experiments per dimension. To understand these results, we perform a series of simulated Bayesian optimization campaigns that reveal how EF depends upon the statistical properties of the parameter space while AF depends on its complexity. Collectively, these results reinforce the motivation for using SDLs by revealing their value across a wide range of material parameter spaces and provide a common language for quantifying and understanding this acceleration.",
    "source": "arXiv"
  },
  {
    "title": "Federated Online Learning for Heterogeneous Multisource Streaming Data",
    "title_es": "Federated Online Learning for Heterogeneous Multisource Streaming Data",
    "url": "https://arxiv.org/abs/2508.06652",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06652v1 Announce Type: cross \nAbstract: Federated learning has emerged as an essential paradigm for distributed multi-source data analysis under privacy concerns. Most existing federated learning methods focus on the ``static\" datasets. However, in many real-world applications, data arrive continuously over time, forming streaming datasets. This introduces additional challenges for data storage and algorithm design, particularly under high-dimensional settings. In this paper, we propose a federated online learning (FOL) method for distributed multi-source streaming data analysis. To account for heterogeneity, a personalized model is constructed for each data source, and a novel ``subgroup\" assumption is employed to capture potential similarities, thereby enhancing model performance. We adopt the penalized renewable estimation method and the efficient proximal gradient descent for model training. The proposed method aligns with both federated and online learning frameworks: raw data are not exchanged among sources, ensuring data privacy, and only summary statistics of previous data batches are required for model updates, significantly reducing storage demands. Theoretically, we establish the consistency properties for model estimation, variable selection, and subgroup structure recovery, demonstrating optimal statistical efficiency. Simulations illustrate the effectiveness of the proposed method. Furthermore, when applied to the financial lending data and the web log data, the proposed method also exhibits advantageous prediction performance. Results of the analysis also provide some practical insights.",
    "source": "arXiv"
  },
  {
    "title": "Digital generation of the 3-D pore architecture of isotropic membranes using 2-D cross-sectional scanning electron microscopy images",
    "title_es": "Digital generation of the 3-D pore architecture of isotropic membranes using 2-D cross-sectional scanning electron microscopy images",
    "url": "https://arxiv.org/abs/2508.06664",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06664v1 Announce Type: cross \nAbstract: A major limitation of two-dimensional scanning electron microscopy (SEM) in imaging porous membranes is its inability to resolve three-dimensional pore architecture and interconnectivity, which are critical factors governing membrane performance. Although conventional tomographic 3-D reconstruction techniques can address this limitation, they are often expensive, technically challenging, and not widely accessible. We previously introduced a proof-of-concept method for reconstructing a membrane's 3-D pore network from a single 2-D SEM image, yielding statistically equivalent results to those obtained from 3-D tomography. However, this initial approach struggled to replicate the diverse pore geometries commonly observed in real membranes. In this study, we advance the methodology by developing an enhanced reconstruction algorithm that not only maintains essential statistical properties (e.g., pore size distribution), but also accurately reproduces intricate pore morphologies. Applying this technique to a commercial microfiltration membrane, we generated a high-fidelity 3-D reconstruction and derived key membrane properties. Validation with X-ray tomography data revealed excellent agreement in structural metrics, with our SEM-based approach achieving superior resolution in resolving fine pore features. The tool can be readily applied to isotropic porous membrane structures of any pore size, as long as those pores can be visualized by SEM. Further work is needed for 3-D structure generation of anisotropic membranes.",
    "source": "arXiv"
  },
  {
    "title": "Machines Learn Number Fields, But How? The Case of Galois Groups",
    "title_es": "Machines Learn Number Fields, But How? The Case of Galois Groups",
    "url": "https://arxiv.org/abs/2508.06670",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06670v1 Announce Type: cross \nAbstract: By applying interpretable machine learning methods such as decision trees, we study how simple models can classify the Galois groups of Galois extensions over $\\mathbb{Q}$ of degrees 4, 6, 8, 9, and 10, using Dedekind zeta coefficients. Our interpretation of the machine learning results allows us to understand how the distribution of zeta coefficients depends on the Galois group, and to prove new criteria for classifying the Galois groups of these extensions. Combined with previous results, this work provides another example of a new paradigm in mathematical research driven by machine learning.",
    "source": "arXiv"
  },
  {
    "title": "Inter-role reciprocity in evolutionary trust game on square lattices",
    "title_es": "Inter-role reciprocity in evolutionary trust game on square lattices",
    "url": "https://arxiv.org/abs/2508.06685",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06685v1 Announce Type: cross \nAbstract: Simulating bipartite games, such as the trust game, is not straightforward due to the lack of a natural way to distinguish roles in a single population. The square lattice topology can provide a simple yet elegant solution by alternating trustors and trustees. For even lattice sizes, it creates two disjoint diagonal sub-lattices for strategy learning, while game interactions can take place on the original lattice. This setup ensures a minimal spatial structure that allows interactions across roles and learning within roles. By simulations on this setup, we detect an inter-role spatial reciprocity mechanism, through which trust can emerge. In particular, a moderate return ratio allows investing trustors and trustworthy trustees to form inter-role clusters and thus save trust. If the return is too high, it harms the survival of trustees; if too low, it harms trustors. The proposed simulation framework is also applicable to any bipartite game to uncover potential inter-role spatial mechanisms across various scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Role of Large Language Models and Retrieval-Augmented Generation for Accelerating Crystalline Material Discovery: A Systematic Review",
    "title_es": "Role of Large Language Models and Retrieval-Augmented Generation for Accelerating Crystalline Material Discovery: A Systematic Review",
    "url": "https://arxiv.org/abs/2508.06691",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06691v1 Announce Type: cross \nAbstract: Large language models (LLMs) have emerged as powerful tools for knowledge-intensive tasks across domains. In materials science, to find novel materials for various energy efficient devices for various real-world applications, requires several time and cost expensive simulations and experiments. In order to tune down the uncharted material search space, minimizing the experimental cost, LLMs can play a bigger role to first provide an accelerated search of promising known material candidates. Furthermore, the integration of LLMs with domain-specific information via retrieval-augmented generation (RAG) is poised to revolutionize how researchers predict materials structures, analyze defects, discover novel compounds, and extract knowledge from literature and databases. In motivation to the potentials of LLMs and RAG in accelerating material discovery, this paper presents a broad and systematic review to examine the recent advancements in applying LLMs and RAG to key materials science problems. We survey state-of-the-art developments in crystal structure prediction, defect analysis, materials discovery, literature mining, database integration, and multi-modal retrieval, highlighting how combining LLMs with external knowledge sources enables new capabilities. We discuss the performance, limitations, and implications of these approaches, and outline future directions for leveraging LLMs to accelerate materials research and discovery for advancement in technologies in the area of electronics, optics, biomedical, and energy storage.",
    "source": "arXiv"
  },
  {
    "title": "Data-Efficient Neural Training with Dynamic Connectomes",
    "title_es": "Data-Efficient Neural Training with Dynamic Connectomes",
    "url": "https://arxiv.org/abs/2508.06817",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06817v1 Announce Type: cross \nAbstract: The study of dynamic functional connectomes has provided valuable insights into how patterns of brain activity change over time. Neural networks process information through artificial neurons, conceptually inspired by patterns of activation in the brain. However, their hierarchical structure and high-dimensional parameter space pose challenges for understanding and controlling training dynamics. In this study, we introduce a novel approach to characterize training dynamics in neural networks by representing evolving neural activations as functional connectomes and extracting dynamic signatures of activity throughout training. Our results show that these signatures effectively capture key transitions in the functional organization of the network. Building on this analysis, we propose the use of a time series of functional connectomes as an intrinsic indicator of learning progress, enabling a principled early stopping criterion. Our framework performs robustly across benchmarks and provides new insights into neural network training dynamics.",
    "source": "arXiv"
  },
  {
    "title": "Efficient data-driven regression for reduced-order modeling of spatial pattern formation",
    "title_es": "Efficient data-driven regression for reduced-order modeling of spatial pattern formation",
    "url": "https://arxiv.org/abs/2508.06833",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06833v1 Announce Type: cross \nAbstract: We present an efficient data-driven regression approach for constructing reduced-order models (ROMs) of reaction-diffusion systems exhibiting pattern formation. The ROMs are learned non-intrusively from available training data of physically accurate numerical simulations. The method can be applied to general nonlinear systems through the use of polynomial model form, while not requiring knowledge of the underlying physical model, governing equations, or numerical solvers. The process of learning ROMs is posed as a low-cost least-squares problem in a reduced-order subspace identified via Proper Orthogonal Decomposition (POD). Numerical experiments on classical pattern-forming systems--including the Schnakenberg and Mimura--Tsujikawa models--demonstrate that higher-order surrogate models significantly improve prediction accuracy while maintaining low computational cost. The proposed method provides a flexible, non-intrusive model reduction framework, well suited for the analysis of complex spatio-temporal pattern formation phenomena.",
    "source": "arXiv"
  },
  {
    "title": "A Score-based Diffusion Model Approach for Adaptive Learning of Stochastic Partial Differential Equation Solutions",
    "title_es": "A Score-based Diffusion Model Approach for Adaptive Learning of Stochastic Partial Differential Equation Solutions",
    "url": "https://arxiv.org/abs/2508.06834",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06834v1 Announce Type: cross \nAbstract: We propose a novel framework for adaptively learning the time-evolving solutions of stochastic partial differential equations (SPDEs) using score-based diffusion models within a recursive Bayesian inference setting. SPDEs play a central role in modeling complex physical systems under uncertainty, but their numerical solutions often suffer from model errors and reduced accuracy due to incomplete physical knowledge and environmental variability. To address these challenges, we encode the governing physics into the score function of a diffusion model using simulation data and incorporate observational information via a likelihood-based correction in a reverse-time stochastic differential equation. This enables adaptive learning through iterative refinement of the solution as new data becomes available. To improve computational efficiency in high-dimensional settings, we introduce the ensemble score filter, a training-free approximation of the score function designed for real-time inference. Numerical experiments on benchmark SPDEs demonstrate the accuracy and robustness of the proposed method under sparse and noisy observations.",
    "source": "arXiv"
  },
  {
    "title": "MOCA-HESP: Meta High-dimensional Bayesian Optimization for Combinatorial and Mixed Spaces via Hyper-ellipsoid Partitioning",
    "title_es": "MOCA-HESP: Meta High-dimensional Bayesian Optimization for Combinatorial and Mixed Spaces via Hyper-ellipsoid Partitioning",
    "url": "https://arxiv.org/abs/2508.06847",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06847v1 Announce Type: cross \nAbstract: High-dimensional Bayesian Optimization (BO) has attracted significant attention in recent research. However, existing methods have mainly focused on optimizing in continuous domains, while combinatorial (ordinal and categorical) and mixed domains still remain challenging. In this paper, we first propose MOCA-HESP, a novel high-dimensional BO method for combinatorial and mixed variables. The key idea is to leverage the hyper-ellipsoid space partitioning (HESP) technique with different categorical encoders to work with high-dimensional, combinatorial and mixed spaces, while adaptively selecting the optimal encoders for HESP using a multi-armed bandit technique. Our method, MOCA-HESP, is designed as a \\textit{meta-algorithm} such that it can incorporate other combinatorial and mixed BO optimizers to further enhance the optimizers' performance. Finally, we develop three practical BO methods by integrating MOCA-HESP with state-of-the-art BO optimizers for combinatorial and mixed variables: standard BO, CASMOPOLITAN, and Bounce. Our experimental results on various synthetic and real-world benchmarks show that our methods outperform existing baselines. Our code implementation can be found at https://github.com/LamNgo1/moca-hesp",
    "source": "arXiv"
  },
  {
    "title": "Secure Transmission for Cell-Free Symbiotic Radio Communications with Movable Antenna: Continuous and Discrete Positioning Designs",
    "title_es": "Secure Transmission for Cell-Free Symbiotic Radio Communications with Movable Antenna: Continuous and Discrete Positioning Designs",
    "url": "https://arxiv.org/abs/2508.06868",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06868v1 Announce Type: cross \nAbstract: In this paper, we study a movable antenna (MA) empowered secure transmission scheme for reconfigurable intelligent surface (RIS) aided cell-free symbiotic radio (SR) system. Specifically, the MAs deployed at distributed access points (APs) work collaboratively with the RIS to establish high-quality propagation links for both primary and secondary transmissions, as well as suppressing the risk of eavesdropping on confidential primary information. We consider both continuous and discrete MA position cases and maximize the secrecy rate of primary transmission under the secondary transmission constraints, respectively. For the continuous position case, we propose a two-layer iterative optimization method based on differential evolution with one-in-one representation (DEO), to find a high-quality solution with relatively moderate computational complexity. For the discrete position case, we first extend the DEO based iterative framework by introducing the mapping and determination operations to handle the characteristic of discrete MA positions. To further reduce the computational complexity, we then design an alternating optimization (AO) iterative framework to solve all variables within a single layer. In particular, we develop an efficient strategy to derive the sub-optimal solution for the discrete MA positions, superseding the DEO-based method. Numerical results validate the effectiveness of the proposed MA empowered secure transmission scheme along with its optimization algorithms.",
    "source": "arXiv"
  },
  {
    "title": "Near-Optimal Convergence of Accelerated Gradient Methods under Generalized and $(L_0, L_1)$-Smoothness",
    "title_es": "Near-Optimal Convergence of Accelerated Gradient Methods under Generalized and $(L_0, L_1)$-Smoothness",
    "url": "https://arxiv.org/abs/2508.06884",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06884v1 Announce Type: cross \nAbstract: We study first-order methods for convex optimization problems with functions $f$ satisfying the recently proposed $\\ell$-smoothness condition $||\\nabla^{2}f(x)|| \\le \\ell\\left(||\\nabla f(x)||\\right),$ which generalizes the $L$-smoothness and $(L_{0},L_{1})$-smoothness. While accelerated gradient descent AGD is known to reach the optimal complexity $O(\\sqrt{L} R / \\sqrt{\\varepsilon})$ under $L$-smoothness, where $\\varepsilon$ is an error tolerance and $R$ is the distance between a starting and an optimal point, existing extensions to $\\ell$-smoothness either incur extra dependence on the initial gradient, suffer exponential factors in $L_{1} R$, or require costly auxiliary sub-routines, leaving open whether an AGD-type $O(\\sqrt{\\ell(0)} R / \\sqrt{\\varepsilon})$ rate is possible for small-$\\varepsilon$, even in the $(L_{0},L_{1})$-smoothness case.\n  We resolve this open question. Leveraging a new Lyapunov function and designing new algorithms, we achieve $O(\\sqrt{\\ell(0)} R / \\sqrt{\\varepsilon})$ oracle complexity for small-$\\varepsilon$ and virtually any $\\ell$. For instance, for $(L_{0},L_{1})$-smoothness, our bound $O(\\sqrt{L_0} R / \\sqrt{\\varepsilon})$ is provably optimal in the small-$\\varepsilon$ regime and removes all non-constant multiplicative factors present in prior accelerated algorithms.",
    "source": "arXiv"
  },
  {
    "title": "Machine Learning Algorithms for Improving Exact Classical Solvers in Mixed Integer Continuous Optimization",
    "title_es": "Machine Learning Algorithms for Improving Exact Classical Solvers in Mixed Integer Continuous Optimization",
    "url": "https://arxiv.org/abs/2508.06906",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06906v1 Announce Type: cross \nAbstract: Integer and mixed-integer nonlinear programming (INLP, MINLP) are central to logistics, energy, and scheduling, but remain computationally challenging. This survey examines how machine learning and reinforcement learning can enhance exact optimization methods - particularly branch-and-bound (BB), without compromising global optimality. We cover discrete, continuous, and mixed-integer formulations, and highlight applications such as crew scheduling, vehicle routing, and hydropower planning. We introduce a unified BB framework that embeds learning-based strategies into branching, cut selection, node ordering, and parameter control. Classical algorithms are augmented using supervised, imitation, and reinforcement learning models to accelerate convergence while maintaining correctness. We conclude with a taxonomy of learning methods by solver class and learning paradigm, and outline open challenges in generalization, hybridization, and scaling intelligent solvers.",
    "source": "arXiv"
  },
  {
    "title": "CROP: Integrating Topological and Spatial Structures via Cross-View Prefixes for Molecular LLMs",
    "title_es": "CROP: Integrating Topological and Spatial Structures via Cross-View Prefixes for Molecular LLMs",
    "url": "https://arxiv.org/abs/2508.06917",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06917v1 Announce Type: cross \nAbstract: Recent advances in molecular science have been propelled significantly by large language models (LLMs). However, their effectiveness is limited when relying solely on molecular sequences, which fail to capture the complex structures of molecules. Beyond sequence representation, molecules exhibit two complementary structural views: the first focuses on the topological relationships between atoms, as exemplified by the graph view; and the second emphasizes the spatial configuration of molecules, as represented by the image view. The two types of views provide unique insights into molecular structures. To leverage these views collaboratively, we propose the CROss-view Prefixes (CROP) to enhance LLMs' molecular understanding through efficient multi-view integration. CROP possesses two advantages: (i) efficiency: by jointly resampling multiple structural views into fixed-length prefixes, it avoids excessive consumption of the LLM's limited context length and allows easy expansion to more views; (ii) effectiveness: by utilizing the LLM's self-encoded molecular sequences to guide the resampling process, it boosts the quality of the generated prefixes. Specifically, our framework features a carefully designed SMILES Guided Resampler for view resampling, and a Structural Embedding Gate for converting the resulting embeddings into LLM's prefixes. Extensive experiments demonstrate the superiority of CROP in tasks including molecule captioning, IUPAC name prediction and molecule property prediction.",
    "source": "arXiv"
  },
  {
    "title": "Mal'cev clones over a three-element set up to minor-equivalence",
    "title_es": "Mal'cev clones over a three-element set up to minor-equivalence",
    "url": "https://arxiv.org/abs/2508.06918",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06918v1 Announce Type: cross \nAbstract: We classify all Mal'cev clones over a three-element set up to minion homomorphisms. This is another step toward the complete classification of three-element relational structures up to pp-constructability. We furthermore provide an alternative proof of Bulatov's result that all Mal'cev clones over a three-element set have an at most 4-ary relational basis.",
    "source": "arXiv"
  },
  {
    "title": "Explainable AI for Curie Temperature Prediction in Magnetic Materials",
    "title_es": "Explainable AI for Curie Temperature Prediction in Magnetic Materials",
    "url": "https://arxiv.org/abs/2508.06996",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06996v1 Announce Type: cross \nAbstract: We explore machine learning techniques for predicting Curie temperatures of magnetic materials using the NEMAD database. By augmenting the dataset with composition-based and domain-aware descriptors, we evaluate the performance of several machine learning models. We find that the Extra Trees Regressor delivers the best performance reaching an R^2 score of up to 0.85 $\\pm$ 0.01 (cross-validated) for a balanced dataset. We employ the k-means clustering algorithm to gain insights into the performance of chemically distinct material groups. Furthermore, we perform the SHAP analysis to identify key physicochemical drivers of Curie behavior, such as average atomic number and magnetic moment. By employing explainable AI techniques, this analysis offers insights into the model's predictive behavior, thereby advancing scientific interpretability.",
    "source": "arXiv"
  },
  {
    "title": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree",
    "title_es": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree",
    "url": "https://arxiv.org/abs/2508.07014",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07014v1 Announce Type: cross \nAbstract: Recognizing specific key phrases is an essential task for contextualized Automatic Speech Recognition (ASR). However, most existing context-biasing approaches have limitations associated with the necessity of additional model training, significantly slow down the decoding process, or constrain the choice of the ASR system type. This paper proposes a universal ASR context-biasing framework that supports all major types: CTC, Transducers, and Attention Encoder-Decoder models. The framework is based on a GPU-accelerated word boosting tree, which enables it to be used in shallow fusion mode for greedy and beam search decoding without noticeable speed degradation, even with a vast number of key phrases (up to 20K items). The obtained results showed high efficiency of the proposed method, surpassing the considered open-source context-biasing approaches in accuracy and decoding speed. Our context-biasing framework is open-sourced as a part of the NeMo toolkit.",
    "source": "arXiv"
  },
  {
    "title": "Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation",
    "title_es": "Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation",
    "url": "https://arxiv.org/abs/2508.07049",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07049v1 Announce Type: cross \nAbstract: Anomaly detection (AD) plays a vital role across a wide range of domains, but its performance might deteriorate when applied to target domains with limited data. Domain Adaptation (DA) offers a solution by transferring knowledge from a related source domain with abundant data. However, this adaptation process can introduce additional uncertainty, making it difficult to draw statistically valid conclusions from AD results. In this paper, we propose STAND-DA -- a novel framework for statistically rigorous Autoencoder-based AD after Representation Learning-based DA. Built on the Selective Inference (SI) framework, STAND-DA computes valid $p$-values for detected anomalies and rigorously controls the false positive rate below a pre-specified level $\\alpha$ (e.g., 0.05). To address the computational challenges of applying SI to deep learning models, we develop the GPU-accelerated SI implementation, significantly enhancing both scalability and runtime performance. This advancement makes SI practically feasible for modern, large-scale deep architectures. Extensive experiments on synthetic and real-world datasets validate the theoretical results and computational efficiency of the proposed STAND-DA method.",
    "source": "arXiv"
  },
  {
    "title": "Taking the Garbage Out of Data-Driven Prediction Across Climate Timescales",
    "title_es": "Taking the Garbage Out of Data-Driven Prediction Across Climate Timescales",
    "url": "https://arxiv.org/abs/2508.07062",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07062v1 Announce Type: cross \nAbstract: Artificial intelligence (AI) -- and specifically machine learning (ML) -- applications for climate prediction across timescales are proliferating quickly. The emergence of these methods prompts a revisit to the impact of data preprocessing, a topic familiar to the climate community, as more traditional statistical models work with relatively small sample sizes. Indeed, the skill and confidence in the forecasts produced by data-driven models are directly influenced by the quality of the datasets and how they are treated during model development, thus yielding the colloquialism \"garbage in, garbage out.\" As such, this article establishes protocols for the proper preprocessing of input data for AI/ML models designed for climate prediction (i.e., subseasonal to decadal and longer). The three aims are to: (1) educate researchers, developers, and end users on the effects that preprocessing has on climate predictions; (2) provide recommended practices for data preprocessing for such applications; and (3) empower end users to decipher whether the models they are using are properly designed for their objectives. Specific topics covered in this article include the creation of (standardized) anomalies, dealing with non-stationarity and the spatiotemporally correlated nature of climate data, and handling of extreme values and variables with potentially complex distributions. Case studies will illustrate how using different preprocessing techniques can produce different predictions from the same model, which can create confusion and decrease confidence in the overall process. Ultimately, implementing the recommended practices set forth in this article will enhance the robustness and transparency of AI/ML in climate prediction studies.",
    "source": "arXiv"
  },
  {
    "title": "Reconstruction of Solar EUV Irradiance Using CaII K Images and SOHO/SEM Data with Bayesian Deep Learning and Uncertainty Quantification",
    "title_es": "Reconstruction of Solar EUV Irradiance Using CaII K Images and SOHO/SEM Data with Bayesian Deep Learning and Uncertainty Quantification",
    "url": "https://arxiv.org/abs/2508.07065",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07065v1 Announce Type: cross \nAbstract: Solar extreme ultraviolet (EUV) irradiance plays a crucial role in heating the Earth's ionosphere, thermosphere, and mesosphere, affecting atmospheric dynamics over varying time scales. Although significant effort has been spent studying short-term EUV variations from solar transient events, there is little work to explore the long-term evolution of the EUV flux over multiple solar cycles. Continuous EUV flux measurements have only been available since 1995, leaving significant gaps in earlier data. In this study, we propose a Bayesian deep learning model, named SEMNet, to fill the gaps. We validate our approach by applying SEMNet to construct SOHO/SEM EUV flux measurements in the period between 1998 and 2014 using CaII K images from the Precision Solar Photometric Telescope. We then extend SEMNet through transfer learning to reconstruct solar EUV irradiance in the period between 1950 and 1960 using CaII K images from the Kodaikanal Solar Observatory. Experimental results show that SEMNet provides reliable predictions along with uncertainty bounds, demonstrating the feasibility of CaII K images as a robust proxy for long-term EUV fluxes. These findings contribute to a better understanding of solar influences on Earth's climate over extended periods.",
    "source": "arXiv"
  },
  {
    "title": "Membership Inference Attacks with False Discovery Rate Control",
    "title_es": "Membership Inference Attacks with False Discovery Rate Control",
    "url": "https://arxiv.org/abs/2508.07066",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07066v1 Announce Type: cross \nAbstract: Recent studies have shown that deep learning models are vulnerable to membership inference attacks (MIAs), which aim to infer whether a data record was used to train a target model or not. To analyze and study these vulnerabilities, various MIA methods have been proposed. Despite the significance and popularity of MIAs, existing works on MIAs are limited in providing guarantees on the false discovery rate (FDR), which refers to the expected proportion of false discoveries among the identified positive discoveries. However, it is very challenging to ensure the false discovery rate guarantees, because the underlying distribution is usually unknown, and the estimated non-member probabilities often exhibit interdependence. To tackle the above challenges, in this paper, we design a novel membership inference attack method, which can provide the guarantees on the false discovery rate. Additionally, we show that our method can also provide the marginal probability guarantee on labeling true non-member data as member data. Notably, our method can work as a wrapper that can be seamlessly integrated with existing MIA methods in a post-hoc manner, while also providing the FDR control. We perform the theoretical analysis for our method. Extensive experiments in various settings (e.g., the black-box setting and the lifelong learning setting) are also conducted to verify the desirable performance of our method.",
    "source": "arXiv"
  },
  {
    "title": "QuProFS: An Evolutionary Training-free Approach to Efficient Quantum Feature Map Search",
    "title_es": "QuProFS: An Evolutionary Training-free Approach to Efficient Quantum Feature Map Search",
    "url": "https://arxiv.org/abs/2508.07104",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07104v1 Announce Type: cross \nAbstract: The quest for effective quantum feature maps for data encoding presents significant challenges, particularly due to the flat training landscapes and lengthy training processes associated with parameterised quantum circuits. To address these issues, we propose an evolutionary training-free quantum architecture search (QAS) framework that employs circuit-based heuristics focused on trainability, hardware robustness, generalisation ability, expressivity, complexity, and kernel-target alignment. By ranking circuit architectures with various proxies, we reduce evaluation costs and incorporate hardware-aware circuits to enhance robustness against noise. We evaluate our approach on classification tasks (using quantum support vector machine) across diverse datasets using both artificial and quantum-generated datasets. Our approach demonstrates competitive accuracy on both simulators and real quantum hardware, surpassing state-of-the-art QAS methods in terms of sampling efficiency and achieving up to a 2x speedup in architecture search runtime.",
    "source": "arXiv"
  },
  {
    "title": "Sensory robustness through top-down feedback and neural stochasticity in recurrent vision models",
    "title_es": "Sensory robustness through top-down feedback and neural stochasticity in recurrent vision models",
    "url": "https://arxiv.org/abs/2508.07115",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07115v1 Announce Type: cross \nAbstract: Biological systems leverage top-down feedback for visual processing, yet most artificial vision models succeed in image classification using purely feedforward or recurrent architectures, calling into question the functional significance of descending cortical pathways. Here, we trained convolutional recurrent neural networks (ConvRNN) on image classification in the presence or absence of top-down feedback projections to elucidate the specific computational contributions of those feedback pathways. We found that ConvRNNs with top-down feedback exhibited remarkable speed-accuracy trade-off and robustness to noise perturbations and adversarial attacks, but only when they were trained with stochastic neural variability, simulated by randomly silencing single units via dropout. By performing detailed analyses to identify the reasons for such benefits, we observed that feedback information substantially shaped the representational geometry of the post-integration layer, combining the bottom-up and top-down streams, and this effect was amplified by dropout. Moreover, feedback signals coupled with dropout optimally constrained network activity onto a low-dimensional manifold and encoded object information more efficiently in out-of-distribution regimes, with top-down information stabilizing the representational dynamics at the population level. Together, these findings uncover a dual mechanism for resilient sensory coding. On the one hand, neural stochasticity prevents unit-level co-adaptation albeit at the cost of more chaotic dynamics. On the other hand, top-down feedback harnesses high-level information to stabilize network activity on compact low-dimensional manifolds.",
    "source": "arXiv"
  },
  {
    "title": "Block encoding the 3D heterogeneous Poisson equation with application to fracture flow",
    "title_es": "Block encoding the 3D heterogeneous Poisson equation with application to fracture flow",
    "url": "https://arxiv.org/abs/2508.07125",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07125v1 Announce Type: cross \nAbstract: Quantum linear system (QLS) algorithms offer the potential to solve large-scale linear systems exponentially faster than classical methods. However, applying QLS algorithms to real-world problems remains challenging due to issues such as state preparation, data loading, and efficient information extraction. In this work, we study the feasibility of applying QLS algorithms to solve discretized three-dimensional heterogeneous Poisson equations, with specific examples relating to groundwater flow through geologic fracture networks. We explicitly construct a block encoding for the 3D heterogeneous Poisson matrix by leveraging the sparse local structure of the discretized operator. While classical solvers benefit from preconditioning, we show that block encoding the system matrix and preconditioner separately does not improve the effective condition number that dominates the QLS runtime. This differs from classical approaches where the preconditioner and the system matrix can often be implemented independently. Nevertheless, due to the structure of the problem in three dimensions, the quantum algorithm achieves a runtime of $O(N^{2/3} \\ \\text{polylog } N \\cdot \\log(1/\\epsilon))$, outperforming the best classical methods (with runtimes of $O(N \\log N \\cdot \\log(1/\\epsilon))$) and offering exponential memory savings. These results highlight both the promise and limitations of QLS algorithms for practical scientific computing, and point to effective condition number reduction as a key barrier in achieving quantum advantages.",
    "source": "arXiv"
  },
  {
    "title": "Pinching-Antenna System Design with LoS Blockage: Does In-Waveguide Attenuation Matter?",
    "title_es": "Pinching-Antenna System Design with LoS Blockage: Does In-Waveguide Attenuation Matter?",
    "url": "https://arxiv.org/abs/2508.07131",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07131v1 Announce Type: cross \nAbstract: In the literature of pinching-antenna systems, in-waveguide attenuation is often neglected to simplify system design and enable more tractable analysis. However, its effect on overall system performance has received limited attention in the existing literature. While a recent study has shown that, in line-of-sight (LoS)-dominated environments, the data rate loss incurred by omitting in-waveguide attenuation is negligible when the communication area is not excessively large, its effect under more general conditions remains unclear. This work extends the analysis to more realistic scenarios involving arbitrary levels of LoS blockage. We begin by examining a single-user case and derive an explicit expression for the average data rate loss caused by neglecting in-waveguide attenuation. The results demonstrate that, even for large service areas, the rate loss remains negligible under typical LoS blockage conditions. We then consider a more general multi-user scenario, where multiple pinching antennas, each deployed on a separate waveguide, jointly serve multiple users. The objective is to maximize the average sum rate by jointly optimize antenna positions and transmit beamformers to maximize the average sum rate under probabilistic LoS blockage. To solve the resulting stochastic and nonconvex optimization problem, we propose a dynamic sample average approximation (SAA) algorithm. At each iteration, this method replaces the expected objective with an empirical average computed from dynamically regenerated random channel realizations, ensuring that the optimization accurately reflects the current antenna configuration. Extensive simulation results are provided to the proposed algorithm and demonstrate the substantial performance gains of pinching-antenna systems, particularly in environments with significant LoS blockage.",
    "source": "arXiv"
  },
  {
    "title": "Applying the Spectral Method for Modeling Linear Filters: Butterworth, Linkwitz-Riley, and Chebyshev filters",
    "title_es": "Applying the Spectral Method for Modeling Linear Filters: Butterworth, Linkwitz-Riley, and Chebyshev filters",
    "url": "https://arxiv.org/abs/2508.07206",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07206v1 Announce Type: cross \nAbstract: This paper proposes a new technique for computer modeling linear filters based on the spectral form of mathematical description of linear systems. It assumes that input and output signals of the filter are represented as orthogonal expansions, while filters themselves are described by two-dimensional non-stationary transfer functions. This technique allows one to model the output signal in continuous time, and it is successfully tested on the Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.",
    "source": "arXiv"
  },
  {
    "title": "ParaNoise-SV: Integrated Approach for Noise-Robust Speaker Verification with Parallel Joint Learning of Speech Enhancement and Noise Extraction",
    "title_es": "ParaNoise-SV: Integrated Approach for Noise-Robust Speaker Verification with Parallel Joint Learning of Speech Enhancement and Noise Extraction",
    "url": "https://arxiv.org/abs/2508.07219",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07219v1 Announce Type: cross \nAbstract: Noise-robust speaker verification leverages joint learning of speech enhancement (SE) and speaker verification (SV) to improve robustness. However, prevailing approaches rely on implicit noise suppression, which struggles to separate noise from speaker characteristics as they do not explicitly distinguish noise from speech during training. Although integrating SE and SV helps, it remains limited in handling noise effectively. Meanwhile, recent SE studies suggest that explicitly modeling noise, rather than merely suppressing it, enhances noise resilience. Reflecting this, we propose ParaNoise-SV, with dual U-Nets combining a noise extraction (NE) network and a speech enhancement (SE) network. The NE U-Net explicitly models noise, while the SE U-Net refines speech with guidance from NE through parallel connections, preserving speaker-relevant features. Experimental results show that ParaNoise-SV achieves a relatively 8.4% lower equal error rate (EER) than previous joint SE-SV models.",
    "source": "arXiv"
  },
  {
    "title": "BIGBOY1.2: Generating Realistic Synthetic Data for Disease Outbreak Modelling and Analytics",
    "title_es": "BIGBOY1.2: Generating Realistic Synthetic Data for Disease Outbreak Modelling and Analytics",
    "url": "https://arxiv.org/abs/2508.07239",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07239v1 Announce Type: cross \nAbstract: Modelling disease outbreak models remains challenging due to incomplete surveillance data, noise, and limited access to standardized datasets. We have created BIGBOY1.2, an open synthetic dataset generator that creates configurable epidemic time series and population-level trajectories suitable for benchmarking modelling, forecasting, and visualisation. The framework supports SEIR and SIR-like compartmental logic, custom seasonality, and noise injection to mimic real reporting artifacts. BIGBOY1.2 can produce datasets with diverse characteristics, making it suitable for comparing traditional epidemiological models (e.g., SIR, SEIR) with modern machine learning approaches (e.g., SVM, neural networks).",
    "source": "arXiv"
  },
  {
    "title": "Threshold dynamics in time-delay systems: polynomial $\\beta$-control in a pressing process and connections to blow-up",
    "title_es": "Threshold dynamics in time-delay systems: polynomial $\\beta$-control in a pressing process and connections to blow-up",
    "url": "https://arxiv.org/abs/2508.07268",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07268v1 Announce Type: cross \nAbstract: This paper addresses a press control problem in straightening machines with small time delays due to system communication. To handle this, we propose a generalized $\\beta$-control method, which replaces conventional linear velocity control with a polynomial of degree $\\beta \\ge 1$. The resulting model is a delay differential equation (DDE), for which we derive basic properties through nondimensionalization and analysis. Numerical experiments suggest the existence of a threshold initial velocity separating overshoot and non-overshoot dynamics, which we formulate as a conjecture. Based on this, we design a control algorithm under velocity constraints and confirm its effectiveness. We also highlight a connection between threshold behavior and finite-time blow-up in DDEs. This study provides a practical control strategy and contributes new insights into threshold dynamics and blow-up phenomena in delay systems.",
    "source": "arXiv"
  },
  {
    "title": "IP Models for Minimum Zero Forcing Sets, Forts, and Related Graph Parameters",
    "title_es": "IP Models for Minimum Zero Forcing Sets, Forts, and Related Graph Parameters",
    "url": "https://arxiv.org/abs/2508.07293",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07293v1 Announce Type: cross \nAbstract: Zero forcing is a binary coloring game on a graph where a set of filled vertices can force non-filled vertices to become filled following a color change rule. In 2008, the zero forcing number of a graph was shown to be an upper bound on its maximum nullity. In addition, the combinatorial optimization problem for the zero forcing number was shown to be NP-hard. Since then, the study of zero forcing and its related parameters has received considerable attention. In 2018, the forts of a graph were defined as non-empty subsets of vertices where no vertex outside the set has exactly one neighbor in the set. Forts have been used to model zero forcing as an integer program and provide lower bounds on the zero forcing number. To date, three integer programming models have been developed for the zero forcing number of a graph: the Infection Model, Time Step Model, and Fort Cover Model. In this article, we present variations of these models for computing the zero forcing number and related graph parameters, such as the minimum and maximum propagation times, throttling number, and fractional zero forcing number. In addition, we present several new models for computing the realized propagation time interval, all minimal forts of a graph, and the fort number of a graph. We conclude with several numerical experiments that demonstrate the effectiveness of our models when applied to small and medium order graphs. Moreover, we provide experimental evidence for several open conjectures regarding the propagation time interval, the number of minimal forts, the fort number, and the fractional zero forcing number of a graph.",
    "source": "arXiv"
  },
  {
    "title": "Channel Charting in Smart Radio Environments",
    "title_es": "Channel Charting in Smart Radio Environments",
    "url": "https://arxiv.org/abs/2508.07305",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07305v1 Announce Type: cross \nAbstract: This paper introduces the use of static electromagnetic skins (EMSs) to enable robust device localization via channel charting (CC) in realistic urban environments. We develop a rigorous optimization framework that leverages EMS to enhance channel dissimilarity and spatial fingerprinting, formulating EMS phase profile design as a codebook-based problem targeting the upper quantiles of key embedding metric, localization error, trustworthiness, and continuity. Through 3D ray-traced simulations of a representative city scenario, we demonstrate that optimized EMS configurations, in addition to significant improvement of the average positioning error, reduce the 90th-percentile localization error from over 60 m (no EMS) to less than 25 m, while drastically improving trustworthiness and continuity. To the best of our knowledge, this is the first work to exploit Smart Radio Environment (SRE) with static EMS for enhancing CC, achieving substantial gains in localization performance under challenging None-Line-of-Sight (NLoS) conditions.",
    "source": "arXiv"
  },
  {
    "title": "FlexCTC: GPU-powered CTC Beam Decoding with advanced Contextual Abilities",
    "title_es": "FlexCTC: GPU-powered CTC Beam Decoding with advanced Contextual Abilities",
    "url": "https://arxiv.org/abs/2508.07315",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07315v1 Announce Type: cross \nAbstract: While beam search improves speech recognition quality over greedy decoding, standard implementations are slow, often sequential, and CPU-bound. To fully leverage modern hardware capabilities, we present a novel open-source FlexCTC toolkit for fully GPU-based beam decoding, designed for Connectionist Temporal Classification (CTC) models. Developed entirely in Python and PyTorch, it offers a fast, user-friendly, and extensible alternative to traditional C++, CUDA, or WFST-based decoders. The toolkit features a high-performance, fully batched GPU implementation with eliminated CPU-GPU synchronization and minimized kernel launch overhead via CUDA Graphs. It also supports advanced contextualization techniques, including GPU-powered N-gram language model fusion and phrase-level boosting. These features enable accurate and efficient decoding, making them suitable for both research and production use.",
    "source": "arXiv"
  },
  {
    "title": "Nonparametric Reaction Coordinate Optimization with Histories: A Framework for Rare Event Dynamics",
    "title_es": "Nonparametric Reaction Coordinate Optimization with Histories: A Framework for Rare Event Dynamics",
    "url": "https://arxiv.org/abs/2508.07326",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07326v1 Announce Type: cross \nAbstract: Rare but critical events in complex systems, such as protein folding, chemical reactions, disease progression, and extreme weather or climate phenomena, are governed by complex, high-dimensional, stochastic dynamics. Identifying an optimal reaction coordinate (RC) that accurately captures the progress of these dynamics is crucial for understanding and simulating such processes. This work introduces a nonparametric RC optimization framework that incorporates trajectory histories, enabling robust analysis even for irregular or incomplete data. The power of the method is demonstrated through increasingly challenging analyses of protein folding dynamics, where it provides accurate committor estimates that pass a stringent validation test and yield high-resolution free energy profiles. Its generality is further illustrated through applications to dynamics in phase space, a conceptual ocean circulation model, and a longitudinal clinical dataset. These results demonstrate that rare event dynamics can be accurately characterized without exhaustive sampling of the configuration space, establishing a general, flexible, and robust framework for analyzing complex dynamical systems and longitudinal datasets.",
    "source": "arXiv"
  },
  {
    "title": "Best $m$-term trigonometric approximation in weighted Wiener spaces and applications",
    "title_es": "Best $m$-term trigonometric approximation in weighted Wiener spaces and applications",
    "url": "https://arxiv.org/abs/2508.07336",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07336v1 Announce Type: cross \nAbstract: In this paper we study best $m$-term trigonometric approximation of functions belonging to multivariate weighted Wiener spaces. It has {recently been observed} that best $m$-term trigonometric widths in the uniform and Wiener norm together with nonlinear recovery algorithms stemming from compressed sensing serve to control the optimal sampling recovery error in various relevant spaces of multivariate functions. We use a collection of old and new tools as well as novel findings to extend these recovery bounds. In addition, by establishing embeddings of classical smoothness spaces into weighted Wiener spaces we extend recovery bounds to classical multivariate smoothness spaces.",
    "source": "arXiv"
  },
  {
    "title": "KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features",
    "title_es": "KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features",
    "url": "https://arxiv.org/abs/2508.07337",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07337v1 Announce Type: cross \nAbstract: The rapid development of audio-driven talking head generators and advanced Text-To-Speech (TTS) models has led to more sophisticated temporal deepfakes. These advances highlight the need for robust methods capable of detecting and localizing deepfakes, even under novel, unseen attack scenarios. Current state-of-the-art deepfake detectors, while accurate, are often computationally expensive and struggle to generalize to novel manipulation techniques. To address these challenges, we propose multimodal approaches for the AV-Deepfake1M 2025 challenge. For the visual modality, we leverage handcrafted features to improve interpretability and adaptability. For the audio modality, we adapt a self-supervised learning (SSL) backbone coupled with graph attention networks to capture rich audio representations, improving detection robustness. Our approach strikes a balance between performance and real-world deployment, focusing on resilience and potential interpretability. On the AV-Deepfake1M++ dataset, our multimodal system achieves AUC of 92.78% for deepfake classification task and IoU of 0.3536 for temporal localization using only the audio modality.",
    "source": "arXiv"
  },
  {
    "title": "A Spin Glass Characterization of Neural Networks",
    "title_es": "A Spin Glass Characterization of Neural Networks",
    "url": "https://arxiv.org/abs/2508.07397",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07397v1 Announce Type: cross \nAbstract: This work presents a statistical mechanics characterization of neural networks, motivated by the replica symmetry breaking (RSB) phenomenon in spin glasses. A Hopfield-type spin glass model is constructed from a given feedforward neural network (FNN). Overlaps between simulated replica samples serve as a characteristic descriptor of the FNN. The connection between the spin-glass description and commonly studied properties of the FNN -- such as data fitting, capacity, generalization, and robustness -- has been investigated and empirically demonstrated. Unlike prior analytical studies that focus on model ensembles, this method provides a computable descriptor for individual network instances, which reveals nontrivial structural properties that are not captured by conventional metrics such as loss or accuracy. Preliminary results suggests its potential for practical applications such as model inspection, safety verification, and detection of hidden vulnerabilities.",
    "source": "arXiv"
  },
  {
    "title": "Event-Aware Sentiment Factors from LLM-Augmented Financial Tweets: A Transparent Framework for Interpretable Quant Trading",
    "title_es": "Event-Aware Sentiment Factors from LLM-Augmented Financial Tweets: A Transparent Framework for Interpretable Quant Trading",
    "url": "https://arxiv.org/abs/2508.07408",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07408v1 Announce Type: cross \nAbstract: In this study, we wish to showcase the unique utility of large language models (LLMs) in financial semantic annotation and alpha signal discovery. Leveraging a corpus of company-related tweets, we use an LLM to automatically assign multi-label event categories to high-sentiment-intensity tweets. We align these labeled sentiment signals with forward returns over 1-to-7-day horizons to evaluate their statistical efficacy and market tradability. Our experiments reveal that certain event labels consistently yield negative alpha, with Sharpe ratios as low as -0.38 and information coefficients exceeding 0.05, all statistically significant at the 95\\% confidence level. This study establishes the feasibility of transforming unstructured social media text into structured, multi-label event variables. A key contribution of this work is its commitment to transparency and reproducibility; all code and methodologies are made publicly available. Our results provide compelling evidence that social media sentiment is a valuable, albeit noisy, signal in financial forecasting and underscore the potential of open-source frameworks to democratize algorithmic trading research.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging GNN to Enhance MEF Method in Predicting ENSO",
    "title_es": "Leveraging GNN to Enhance MEF Method in Predicting ENSO",
    "url": "https://arxiv.org/abs/2508.07410",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07410v1 Announce Type: cross \nAbstract: Reliable long-lead forecasting of the El Nino Southern Oscillation (ENSO) remains a long-standing challenge in climate science. The previously developed Multimodal ENSO Forecast (MEF) model uses 80 ensemble predictions by two independent deep learning modules: a 3D Convolutional Neural Network (3D-CNN) and a time-series module. In their approach, outputs of the two modules are combined using a weighting strategy wherein one is prioritized over the other as a function of global performance. Separate weighting or testing of individual ensemble members did not occur, however, which may have limited the model to optimize the use of high-performing but spread-out forecasts. In this study, we propose a better framework that employs graph-based analysis to directly model similarity between all 80 members of the ensemble. By constructing an undirected graph whose vertices are ensemble outputs and whose weights on edges measure similarity (via RMSE and correlation), we identify and cluster structurally similar and accurate predictions. From which we obtain an optimized subset of 20 members using community detection methods. The final prediction is then obtained by averaging this optimized subset. This method improves the forecast skill through noise removal and emphasis on ensemble coherence. Interestingly, our graph-based selection shows robust statistical characteristics among top performers, offering new ensemble behavior insights. In addition, we observe that while the GNN-based approach does not always outperform the baseline MEF under every scenario, it produces more stable and consistent outputs, particularly in compound long-lead situations. The approach is model-agnostic too, suggesting that it can be applied directly to other forecasting models with gargantuan ensemble outputs, such as statistical, physical, or hybrid models.",
    "source": "arXiv"
  },
  {
    "title": "Statistical Theory of Multi-stage Newton Iteration Algorithm for Online Continual Learning",
    "title_es": "Statistical Theory of Multi-stage Newton Iteration Algorithm for Online Continual Learning",
    "url": "https://arxiv.org/abs/2508.07419",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07419v1 Announce Type: cross \nAbstract: We focus on the critical challenge of handling non-stationary data streams in online continual learning environments, where constrained storage capacity prevents complete retention of historical data, leading to catastrophic forgetting during sequential task training. To more effectively analyze and address the problem of catastrophic forgetting in continual learning, we propose a novel continual learning framework from a statistical perspective. Our approach incorporates random effects across all model parameters and allows the dimension of parameters to diverge to infinity, offering a general formulation for continual learning problems. To efficiently process streaming data, we develop a Multi-step Newton Iteration algorithm that significantly reduces computational costs in certain scenarios by alleviating the burden of matrix inversion. Theoretically, we derive the asymptotic normality of the estimator, enabling subsequent statistical inference. Comprehensive validation through synthetic data experiments and two real datasets analyses demonstrates the effectiveness of our proposed method.",
    "source": "arXiv"
  },
  {
    "title": "Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures",
    "title_es": "Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures",
    "url": "https://arxiv.org/abs/2508.07423",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07423v1 Announce Type: cross \nAbstract: As the particle physics community needs higher and higher precisions in order to test our current model of the subatomic world, larger and larger datasets are necessary. With upgrades scheduled for the detectors of colliding-beam experiments around the world, and specifically at the Large Hadron Collider at CERN, more collisions and more complex interactions are expected. This directly implies an increase in data produced and consequently in the computational resources needed to process them. At CERN, the amount of data produced is gargantuan. This is why the data have to be heavily filtered and selected in real time before being permanently stored. This data can then be used to perform physics analyses, in order to expand our current understanding of the universe and improve the Standard Model of physics. This real-time filtering, known as triggering, involves complex processing happening often at frequencies as high as 40 MHz. This thesis contributes to understanding how machine learning models can be efficiently deployed in such environments, in order to maximize throughput and minimize energy consumption. Inevitably, modern hardware designed for such tasks and contemporary algorithms are needed in order to meet the challenges posed by the stringent, high-frequency data rates. In this work, I present our graph neural network-based pipeline, developed for charged particle track reconstruction at the LHCb experiment at CERN. The pipeline was implemented end-to-end inside LHCb's first-level trigger, entirely on GPUs. Its performance was compared against the classical tracking algorithms currently in production at LHCb. The pipeline was also accelerated on the FPGA architecture, and its performance in terms of power consumption and processing speed was compared against the GPU implementation.",
    "source": "arXiv"
  },
  {
    "title": "From Product Hilbert Spaces to the Generalized Koopman Operator and the Nonlinear Fundamental Lemma",
    "title_es": "From Product Hilbert Spaces to the Generalized Koopman Operator and the Nonlinear Fundamental Lemma",
    "url": "https://arxiv.org/abs/2508.07494",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07494v1 Announce Type: cross \nAbstract: The generalization of the Koopman operator to systems with control input and the derivation of a nonlinear fundamental lemma are two open problems that play a key role in the development of data-driven control methods for nonlinear systems. Both problems hinge on the construction of observable or basis functions and their corresponding Hilbert space that enable an infinite-dimensional, linear system representation. In this paper we derive a novel solution to these problems based on orthonormal expansion in a product Hilbert space constructed as the tensor product between the Hilbert spaces of the state and input observable functions, respectively. We prove that there exists an infinite-dimensional linear operator, i.e. the generalized Koopman operator, from the constructed product Hilbert space to the Hilbert space corresponding to the lifted state propagated forward in time. A scalable data-driven method for computing finite-dimensional approximations of generalized Koopman operators and several choices of observable functions are also presented. Moreover, we derive a nonlinear fundamental lemma by exploiting the bilinear structure of the infinite-dimensional generalized Koopman model. The effectiveness of the developed generalized Koopman embedding is illustrated on the Van der Pol oscillator.",
    "source": "arXiv"
  },
  {
    "title": "Real-time CARFAC Cochlea Model Acceleration on FPGA for Underwater Acoustic Sensing Systems",
    "title_es": "Real-time CARFAC Cochlea Model Acceleration on FPGA for Underwater Acoustic Sensing Systems",
    "url": "https://arxiv.org/abs/2508.07523",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07523v1 Announce Type: cross \nAbstract: This paper presents a real-time, energy-efficient embedded system implementing an array of Cascade of Asymmetric Resonators with Fast-Acting Compression (CARFAC) cochlea models for underwater sound analysis. Built on the AMD Kria KV260 System-on-Module (SoM), the system integrates a Rust-based software framework on the processor for real-time interfacing and synchronization with multiple hydrophone inputs, and a hardware-accelerated implementation of the CARFAC models on a Field-Programmable Gate Array (FPGA) for real-time sound pre-processing. Compared to prior work, the CARFAC accelerator achieves improved scalability and processing speed while reducing resource usage through optimized time-multiplexing, pipelined design, and elimination of costly division circuits. Experimental results demonstrate 13.5% hardware utilization for a single 64-channel CARFAC instance and a whole board power consumption of 3.11 W when processing a 256 kHz input signal in real time.",
    "source": "arXiv"
  },
  {
    "title": "Randomized coordinate gradient descent almost surely escapes strict saddle points",
    "title_es": "Randomized coordinate gradient descent almost surely escapes strict saddle points",
    "url": "https://arxiv.org/abs/2508.07535",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07535v1 Announce Type: cross \nAbstract: We analyze the behavior of randomized coordinate gradient descent for nonconvex optimization, proving that under standard assumptions, the iterates almost surely escape strict saddle points. By formulating the method as a nonlinear random dynamical system and characterizing neighborhoods of critical points, we establish this result through the center-stable manifold theorem.",
    "source": "arXiv"
  },
  {
    "title": "Graded Quantum Codes: From Weighted Algebraic Geometry to Homological Chain Complexes",
    "title_es": "Graded Quantum Codes: From Weighted Algebraic Geometry to Homological Chain Complexes",
    "url": "https://arxiv.org/abs/2508.07542",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07542v1 Announce Type: cross \nAbstract: We introduce graded quantum codes, unifying two classes of quantum error-correcting codes. The first, quantum weighted algebraic geometry (AG) codes, derives from rational points on hypersurfaces in weighted projective spaces over finite fields. This extends classical AG codes by adding weighted degrees and singularities, enabling self-orthogonal codes via the CSS method with improved distances using algebraic structures and invariants like weighted heights.The second class arises from chain complexes of graded vector spaces, generalizing homological quantum codes to include torsion and multiple gradings. This produces low-density parity-check codes with parameters based on homology ranks, including examples from knot invariants and quantum rotors.\n  A shared grading leads to a refined Singleton bound: $d \\leq \\frac{n - k + 2}{2} - \\frac{\\epsilon}{2}$, where $\\epsilon > 0$ reflects entropy adjustments from geometric singularities and defects. The bound holds partially for simple orbifolds and is supported by examples over small fields.\n  Applications include post-quantum cryptography, fault-tolerant quantum computing, and optimization via graded neural networks, linking algebraic geometry, homological algebra, and quantum information.",
    "source": "arXiv"
  },
  {
    "title": "Remarks on the Brouwer Conjecture",
    "title_es": "Remarks on the Brouwer Conjecture",
    "url": "https://arxiv.org/abs/2508.07550",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07550v1 Announce Type: cross \nAbstract: The Brouwer conjecture (BC) in spectral graph theory claims that the sum of the largest k Kirchhoff eigenvalues of a graph are bounded above by the number m of edges plus k(k+1)/2. We show that (BC) holds for all graphs with n vertices if n is larger or equal than 4 times the square of the maximal vertex degree. We also note that the weaker upper bound m+k(k+1) holds unconditionally. We also note that (BC) for graphs implies (BC) for quivers.",
    "source": "arXiv"
  },
  {
    "title": "Importance-Aware Semantic Communication in MIMO-OFDM Systems Using Vision Transformer",
    "title_es": "Importance-Aware Semantic Communication in MIMO-OFDM Systems Using Vision Transformer",
    "url": "https://arxiv.org/abs/2508.07696",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07696v1 Announce Type: cross \nAbstract: This paper presents a novel importance-aware quantization, subcarrier mapping, and power allocation (IA-QSMPA) framework for semantic communication in multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) systems, empowered by a pretrained Vision Transformer (ViT). The proposed framework exploits attention-based importance extracted from a pretrained ViT to jointly optimize quantization levels, subcarrier mapping, and power allocation. Specifically, IA-QSMPA maps semantically important features to high-quality subchannels and allocates resources in accordance with their contribution to task performance and communication latency. To efficiently solve the resulting nonconvex optimization problem, a block coordinate descent algorithm is employed. The framework is further extended to operate under finite blocklength transmission, where communication errors may occur. In this setting, a segment-wise linear approximation of the channel dispersion penalty is introduced to enable efficient joint optimization under practical constraints. Simulation results on a multi-view image classification task using the MVP-N dataset demonstrate that IA-QSMPA significantly outperforms conventional methods in both ideal and finite blocklength transmission scenarios, achieving superior task performance and communication efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Score-Informed BiLSTM Correction for Refining MIDI Velocity in Automatic Piano Transcription",
    "title_es": "Score-Informed BiLSTM Correction for Refining MIDI Velocity in Automatic Piano Transcription",
    "url": "https://arxiv.org/abs/2508.07757",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07757v1 Announce Type: cross \nAbstract: MIDI is a modern standard for storing music, recording how musical notes are played. Many piano performances have corresponding MIDI scores available online. Some of these are created by the original performer, recording on an electric piano alongside the audio, while others are through manual transcription. In recent years, automatic music transcription (AMT) has rapidly advanced, enabling machines to transcribe MIDI from audio. However, these transcriptions often require further correction. Assuming a perfect timing correction, we focus on the loudness correction in terms of MIDI velocity (a parameter in MIDI for loudness control). This task can be approached through score-informed MIDI velocity estimation, which has undergone several developments. While previous approaches introduced specifically built models to re-estimate MIDI velocity, thereby replacing AMT estimates, we propose a BiLSTM correction module to refine AMT-estimated velocity. Although we did not reach state-of-the-art performance, we validated our method on the well-known AMT system, the high-resolution piano transcription (HPT), and achieved significant improvements.",
    "source": "arXiv"
  },
  {
    "title": "Sea-Undistort: A Dataset for Through-Water Image Restoration in High Resolution Airborne Bathymetric Mapping",
    "title_es": "Sea-Undistort: A Dataset for Through-Water Image Restoration in High Resolution Airborne Bathymetric Mapping",
    "url": "https://arxiv.org/abs/2508.07760",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07760v1 Announce Type: cross \nAbstract: Accurate image-based bathymetric mapping in shallow waters remains challenging due to the complex optical distortions such as wave induced patterns, scattering and sunglint, introduced by the dynamic water surface, the water column properties, and solar illumination. In this work, we introduce Sea-Undistort, a comprehensive synthetic dataset of 1200 paired 512x512 through-water scenes rendered in Blender. Each pair comprises a distortion-free and a distorted view, featuring realistic water effects such as sun glint, waves, and scattering over diverse seabeds. Accompanied by per-image metadata such as camera parameters, sun position, and average depth, Sea-Undistort enables supervised training that is otherwise infeasible in real environments. We use Sea-Undistort to benchmark two state-of-the-art image restoration methods alongside an enhanced lightweight diffusion-based framework with an early-fusion sun-glint mask. When applied to real aerial data, the enhanced diffusion model delivers more complete Digital Surface Models (DSMs) of the seabed, especially in deeper areas, reduces bathymetric errors, suppresses glint and scattering, and crisply restores fine seabed details. Dataset, weights, and code are publicly available at https://www.magicbathy.eu/Sea-Undistort.html.",
    "source": "arXiv"
  },
  {
    "title": "PCA-Guided Autoencoding for Structured Dimensionality Reduction in Active Infrared Thermography",
    "title_es": "PCA-Guided Autoencoding for Structured Dimensionality Reduction in Active Infrared Thermography",
    "url": "https://arxiv.org/abs/2508.07773",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07773v1 Announce Type: cross \nAbstract: Active Infrared thermography (AIRT) is a widely adopted non-destructive testing (NDT) technique for detecting subsurface anomalies in industrial components. Due to the high dimensionality of AIRT data, current approaches employ non-linear autoencoders (AEs) for dimensionality reduction. However, the latent space learned by AIRT AEs lacks structure, limiting their effectiveness in downstream defect characterization tasks. To address this limitation, this paper proposes a principal component analysis guided (PCA-guided) autoencoding framework for structured dimensionality reduction to capture intricate, non-linear features in thermographic signals while enforcing a structured latent space. A novel loss function, PCA distillation loss, is introduced to guide AIRT AEs to align the latent representation with structured PCA components while capturing the intricate, non-linear patterns in thermographic signals. To evaluate the utility of the learned, structured latent space, we propose a neural network-based evaluation metric that assesses its suitability for defect characterization. Experimental results show that the proposed PCA-guided AE outperforms state-of-the-art dimensionality reduction methods on PVC, CFRP, and PLA samples in terms of contrast, signal-to-noise ratio (SNR), and neural network-based metrics.",
    "source": "arXiv"
  },
  {
    "title": "Proof-theoretic Semantics for Second-order Logic",
    "title_es": "Proof-theoretic Semantics for Second-order Logic",
    "url": "https://arxiv.org/abs/2508.07786",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07786v1 Announce Type: cross \nAbstract: We develop a proof-theoretic semantics (P-tS) for second-order logic (S-oL), providing an inferentialist alternative to both full and Henkin model-theoretic interpretations. Our approach is grounded in base-extension semantics (B-eS), a framework in which meaning is determined by inferential roles relative to atomic systems -- collections of rules that encode an agent's pre-logical inferential commitments. We show how both classical and intuitionistic versions of S-oL emerge from this set-up by varying the class of atomic systems. These systems yield modular soundness and completeness results for corresponding Hilbert-style calculi, which we prove equivalent to Henkin's account of S-oL. In doing so, we reframe second-order quantification as systematic substitution rather than set-theoretic commitment, thereby offering a philosophically lightweight yet expressive semantics for higher-order logic. This work contributes to the broader programme of grounding logical meaning in use rather than reference and offers a new lens on the foundations of logic and mathematics.",
    "source": "arXiv"
  },
  {
    "title": "Generative Inversion for Property-Targeted Materials Design: Application to Shape Memory Alloys",
    "title_es": "Generative Inversion for Property-Targeted Materials Design: Application to Shape Memory Alloys",
    "url": "https://arxiv.org/abs/2508.07798",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07798v1 Announce Type: cross \nAbstract: The design of shape memory alloys (SMAs) with high transformation temperatures and large mechanical work output remains a longstanding challenge in functional materials engineering. Here, we introduce a data-driven framework based on generative adversarial network (GAN) inversion for the inverse design of high-performance SMAs. By coupling a pretrained GAN with a property prediction model, we perform gradient-based latent space optimization to directly generate candidate alloy compositions and processing parameters that satisfy user-defined property targets. The framework is experimentally validated through the synthesis and characterization of five NiTi-based SMAs. Among them, the Ni$_{49.8}$Ti$_{26.4}$Hf$_{18.6}$Zr$_{5.2}$ alloy achieves a high transformation temperature of 404 $^\\circ$C, a large mechanical work output of 9.9 J/cm$^3$, a transformation enthalpy of 43 J/g , and a thermal hysteresis of 29 {\\deg}C, outperforming existing NiTi alloys. The enhanced performance is attributed to a pronounced transformation volume change and a finely dispersed of Ti$_2$Ni-type precipitates, enabled by sluggish Zr and Hf diffusion, and semi-coherent interfaces with localized strain fields. This study demonstrates that GAN inversion offers an efficient and generalizable route for the property-targeted discovery of complex alloys.",
    "source": "arXiv"
  },
  {
    "title": "MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer",
    "title_es": "MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer",
    "url": "https://arxiv.org/abs/2508.07817",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07817v1 Announce Type: cross \nAbstract: The core role of medical images in disease diagnosis makes their quality directly affect the accuracy of clinical judgment. However, due to factors such as low-dose scanning, equipment limitations and imaging artifacts, medical images are often accompanied by non-uniform noise interference, which seriously affects structure recognition and lesion detection. This paper proposes a medical image adaptive denoising model (MI-ND) that integrates multi-scale convolutional and Transformer architecture, introduces a noise level estimator (NLE) and a noise adaptive attention module (NAAB), and realizes channel-spatial attention regulation and cross-modal feature fusion driven by noise perception. Systematic testing is carried out on multimodal public datasets. Experiments show that this method significantly outperforms the comparative methods in image quality indicators such as PSNR, SSIM, and LPIPS, and improves the F1 score and ROC-AUC in downstream diagnostic tasks, showing strong prac-tical value and promotional potential. The model has outstanding benefits in structural recovery, diagnostic sensitivity, and cross-modal robustness, and provides an effective solution for medical image enhancement and AI-assisted diagnosis and treatment.",
    "source": "arXiv"
  },
  {
    "title": "Auditory Intelligence: Understanding the World Through Sound",
    "title_es": "Auditory Intelligence: Understanding the World Through Sound",
    "url": "https://arxiv.org/abs/2508.07829",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07829v1 Announce Type: cross \nAbstract: Recent progress in auditory intelligence has yielded high-performing systems for sound event detection (SED), acoustic scene classification (ASC), automated audio captioning (AAC), and audio question answering (AQA). Yet these tasks remain largely constrained to surface-level recognition-capturing what happened but not why, what it implies, or how it unfolds in context. I propose a conceptual reframing of auditory intelligence as a layered, situated process that encompasses perception, reasoning, and interaction. To instantiate this view, I introduce four cognitively inspired task paradigms-ASPIRE, SODA, AUX, and AUGMENT-those structure auditory understanding across time-frequency pattern captioning, hierarchical event/scene description, causal explanation, and goal-driven interpretation, respectively. Together, these paradigms provide a roadmap toward more generalizable, explainable, and human-aligned auditory intelligence, and are intended to catalyze a broader discussion of what it means for machines to understand sound.",
    "source": "arXiv"
  },
  {
    "title": "G-IFT: A Gated Linear Unit adapter with Iterative Fine-Tuning for Low-Resource Children's Speaker Verification",
    "title_es": "G-IFT: A Gated Linear Unit adapter with Iterative Fine-Tuning for Low-Resource Children's Speaker Verification",
    "url": "https://arxiv.org/abs/2508.07836",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07836v1 Announce Type: cross \nAbstract: Speaker Verification (SV) systems trained on adults speech often underperform on children's SV due to the acoustic mismatch, and limited children speech data makes fine-tuning not very effective. In this paper, we propose an innovative framework, a Gated Linear Unit adapter with Iterative Fine-Tuning (G-IFT), to enhance knowledge transfer efficiency between the high-resource adults speech domain and the low-resource children's speech domain. In this framework, a Gated Linear Unit adapter is first inserted between the pre-trained speaker embedding model and the classifier. Then the classifier, adapter, and pre-trained speaker embedding model are optimized sequentially in an iterative way. This framework is agnostic to the type of the underlying architecture of the SV system. Our experiments on ECAPA-TDNN, ResNet, and X-vector architectures using the OGI and MyST datasets demonstrate that the G-IFT framework yields consistent reductions in Equal Error Rates compared to baseline methods.",
    "source": "arXiv"
  },
  {
    "title": "Stochastic dynamics learning with state-space systems",
    "title_es": "Stochastic dynamics learning with state-space systems",
    "url": "https://arxiv.org/abs/2508.07876",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07876v1 Announce Type: cross \nAbstract: This work advances the theoretical foundations of reservoir computing (RC) by providing a unified treatment of fading memory and the echo state property (ESP) in both deterministic and stochastic settings. We investigate state-space systems, a central model class in time series learning, and establish that fading memory and solution stability hold generically -- even in the absence of the ESP -- offering a robust explanation for the empirical success of RC models without strict contractivity conditions. In the stochastic case, we critically assess stochastic echo states, proposing a novel distributional perspective rooted in attractor dynamics on the space of probability distributions, which leads to a rich and coherent theory. Our results extend and generalize previous work on non-autonomous dynamical systems, offering new insights into causality, stability, and memory in RC models. This lays the groundwork for reliable generative modeling of temporal data in both deterministic and stochastic regimes.",
    "source": "arXiv"
  },
  {
    "title": "GPU-Accelerated Syndrome Decoding for Quantum LDPC Codes below the 63 $\\mu$s Latency Threshold",
    "title_es": "GPU-Accelerated Syndrome Decoding for Quantum LDPC Codes below the 63 $\\mu$s Latency Threshold",
    "url": "https://arxiv.org/abs/2508.07879",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07879v1 Announce Type: cross \nAbstract: This paper presents a GPU-accelerated decoder for quantum low-density parity-check (QLDPC) codes that achieves sub-$63$ $\\mu$s latency, below the surface code decoder's real-time threshold demonstrated on Google's Willow quantum processor. While surface codes have demonstrated below-threshold performance, the encoding rates approach zero as code distances increase, posing challenges for scalability. Recently proposed QLDPC codes, such as those by Panteleev and Kalachev, offer constant-rate encoding and asymptotic goodness but introduce higher decoding complexity. To address such limitation, this work presents a parallelized belief propagation decoder leveraging syndrome information on commodity GPU hardware. Parallelism was exploited to maximize performance within the limits of target latency, allowing decoding latencies under $50$ $\\mu$s for [[$784$, $24$, $24$]] codes and as low as $23.3$ $\\mu$s for smaller codes, meeting the tight timing constraints of superconducting qubit cycles. These results show that real-time, scalable decoding of asymptotically good quantum codes is achievable using widely available commodity hardware, advancing the feasibility of fault-tolerant quantum computation beyond surface codes.",
    "source": "arXiv"
  },
  {
    "title": "Meta Off-Policy Estimation",
    "title_es": "Meta Off-Policy Estimation",
    "url": "https://arxiv.org/abs/2508.07914",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07914v1 Announce Type: cross \nAbstract: Off-policy estimation (OPE) methods enable unbiased offline evaluation of recommender systems, directly estimating the online reward some target policy would have obtained, from offline data and with statistical guarantees. The theoretical elegance of the framework combined with practical successes have led to a surge of interest, with many competing estimators now available to practitioners and researchers. Among these, Doubly Robust methods provide a prominent strategy to combine value- and policy-based estimators.\n  In this work, we take an alternative perspective to combine a set of OPE estimators and their associated confidence intervals into a single, more accurate estimate. Our approach leverages a correlated fixed-effects meta-analysis framework, explicitly accounting for dependencies among estimators that arise due to shared data. This yields a best linear unbiased estimate (BLUE) of the target policy's value, along with an appropriately conservative confidence interval that reflects inter-estimator correlation. We validate our method on both simulated and real-world data, demonstrating improved statistical efficiency over existing individual estimators.",
    "source": "arXiv"
  },
  {
    "title": "Gaussian Approximation for Two-Timescale Linear Stochastic Approximation",
    "title_es": "Gaussian Approximation for Two-Timescale Linear Stochastic Approximation",
    "url": "https://arxiv.org/abs/2508.07928",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07928v1 Announce Type: cross \nAbstract: In this paper, we establish non-asymptotic bounds for accuracy of normal approximation for linear two-timescale stochastic approximation (TTSA) algorithms driven by martingale difference or Markov noise. Focusing on both the last iterate and Polyak-Ruppert averaging regimes, we derive bounds for normal approximation in terms of the convex distance between probability distributions. Our analysis reveals a non-trivial interaction between the fast and slow timescales: the normal approximation rate for the last iterate improves as the timescale separation increases, while it decreases in the Polyak-Ruppert averaged setting. We also provide the high-order moment bounds for the error of linear TTSA algorithm, which may be of independent interest.",
    "source": "arXiv"
  },
  {
    "title": "Development of a Novel Riemann Solver for Solid Dynamics",
    "title_es": "Development of a Novel Riemann Solver for Solid Dynamics",
    "url": "https://arxiv.org/abs/2508.07954",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07954v1 Announce Type: cross \nAbstract: This work presents a new finite volume framework for solid dynamics based on a momentum-deformation formulation. Building on the C-TOUCH methodology [1], a novel Roe-type Riemann solver is developed to enhance the stability and accuracy of hyperbolic conservation law solutions in solids. The approach naturally handles multidimensional problems and provides a foundation for future extensions to nonlinear and fluid-structure interaction cases. Validation against standard two- and three-dimensional linear elasticity benchmarks demonstrates the method's robustness and accuracy relative to traditional displacement-based approaches, highlighting its promise for large-scale dynamic simulations.",
    "source": "arXiv"
  },
  {
    "title": "Likelihood Ratio Tests by Kernel Gaussian Embedding",
    "title_es": "Likelihood Ratio Tests by Kernel Gaussian Embedding",
    "url": "https://arxiv.org/abs/2508.07982",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07982v1 Announce Type: cross \nAbstract: We propose a novel kernel-based nonparametric two-sample test, employing the combined use of kernel mean and kernel covariance embedding. Our test builds on recent results showing how such combined embeddings map distinct probability measures to mutually singular Gaussian measures on the kernel's RKHS. Leveraging this result, we construct a test statistic based on the relative entropy between the Gaussian embeddings, i.e.\\ the likelihood ratio. The likelihood ratio is specifically tailored to detect equality versus singularity of two Gaussians, and satisfies a ``$0/\\infty$\" law, in that it vanishes under the null and diverges under the alternative. To implement the test in finite samples, we introduce a regularised version, calibrated by way of permutation. We prove consistency, establish uniform power guarantees under mild conditions, and discuss how our framework unifies and extends prior approaches based on spectrally regularized MMD. Empirical results on synthetic and real data demonstrate remarkable gains in power compared to state-of-the-art methods, particularly in high-dimensional and weak-signal regimes.",
    "source": "arXiv"
  },
  {
    "title": "Sharper Perturbed-Kullback-Leibler Exponential Tail Bounds for Beta and Dirichlet Distributions",
    "title_es": "Sharper Perturbed-Kullback-Leibler Exponential Tail Bounds for Beta and Dirichlet Distributions",
    "url": "https://arxiv.org/abs/2508.07991",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.07991v1 Announce Type: cross \nAbstract: This paper presents an improved exponential tail bound for Beta distributions, refining a result in [15]. This improvement is achieved by interpreting their bound as a regular Kullback-Leibler (KL) divergence one, while introducing a specific perturbation $\\eta$ that shifts the mean of the Beta distribution closer to zero within the KL bound. Our contribution is to show that a larger perturbation can be chosen, thereby tightening the bound. We then extend this result from the Beta distribution to Dirichlet distributions and Dirichlet processes (DPs).",
    "source": "arXiv"
  },
  {
    "title": "Flagifying the Dowker Complex",
    "title_es": "Flagifying the Dowker Complex",
    "url": "https://arxiv.org/abs/2508.08025",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08025v1 Announce Type: cross \nAbstract: The Dowker complex $\\mathrm{D}_{R}(X,Y)$ is a simplicial complex capturing the topological interplay between two finite sets $X$ and $Y$ under some relation $R\\subseteq X\\times Y$. While its definition is asymmetric, the famous Dowker duality states that $\\mathrm{D}_{R}(X,Y)$ and $\\mathrm{D}_{R}(Y,X)$ have homotopy equivalent geometric realizations. We introduce the Dowker-Rips complex $\\mathrm{DR}_{R}(X,Y)$, defined as the flagification of the Dowker complex or, equivalently, as the maximal simplicial complex whose $1$-skeleton coincides with that of $\\mathrm{D}_{R}(X,Y)$. This is motivated by applications in topological data analysis, since as a flag complex, the Dowker-Rips complex is less expensive to compute than the Dowker complex. While the Dowker duality does not hold for Dowker-Rips complexes in general, we show that one still has that $\\mathrm{H}_{i}(\\mathrm{DR}_{R}(X,Y))\\cong\\mathrm{H}_{i}(\\mathrm{DR}_{R}(Y,X))$ for $i=0,1$. We further show that this weakened duality extends to the setting of persistent homology, and quantify the ``failure\" of the Dowker duality in homological dimensions higher than $1$ by means of interleavings. This makes the Dowker-Rips complex a less expensive, approximate version of the Dowker complex that is usable in topological data analysis. Indeed, we provide a Python implementation of the Dowker-Rips complex and, as an application, we show that it can be used as a drop-in replacement for the Dowker complex in a tumor microenvironment classification pipeline. In that pipeline, using the Dowker-Rips complex leads to increase in speed while retaining classification performance.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Strategies for Personalized Radiation Therapy: Part III Identifying genetic determinants for Radiation Response with Meta Learning",
    "title_es": "Exploring Strategies for Personalized Radiation Therapy: Part III Identifying genetic determinants for Radiation Response with Meta Learning",
    "url": "https://arxiv.org/abs/2508.08030",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08030v1 Announce Type: cross \nAbstract: Radiation response in cancer is shaped by complex, patient specific biology, yet current treatment strategies often rely on uniform dose prescriptions without accounting for tumor heterogeneity. In this study, we introduce a meta learning framework for one-shot prediction of radiosensitivity measured by SF2 using cell line level gene expression data. Unlike the widely used Radiosensitivity Index RSI a rank-based linear model trained on a fixed 10-gene signature, our proposed meta-learned model allows the importance of each gene to vary by sample through fine tuning. This flexibility addresses key limitations of static models like RSI, which assume uniform gene contributions across tumor types and discard expression magnitude and gene gene interactions. Our results show that meta learning offers robust generalization to unseen samples and performs well in tumor subgroups with high radiosensitivity variability, such as adenocarcinoma and large cell carcinoma. By learning transferable structure across tasks while preserving sample specific adaptability, our approach enables rapid adaptation to individual samples, improving predictive accuracy across diverse tumor subtypes while uncovering context dependent patterns of gene influence that may inform personalized therapy.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Self-Replication: Detecting Distributed Selfhood in the Outlier Cellular Automaton",
    "title_es": "Rethinking Self-Replication: Detecting Distributed Selfhood in the Outlier Cellular Automaton",
    "url": "https://arxiv.org/abs/2508.08047",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08047v1 Announce Type: cross \nAbstract: Spontaneous self-replication in cellular automata has long been considered rare, with most known examples requiring careful design or artificial initialization. In this paper, we present formal, causal evidence that such replication can emerge unassisted -- and that it can do so in a distributed, multi-component form. Building on prior work identifying complex dynamics in the Outlier rule, we introduce a data-driven framework that reconstructs the full causal ancestry of patterns in a deterministic cellular automaton. This allows us to rigorously identify self-replicating structures via explicit causal lineages. Our results show definitively that self-replicators in the Outlier CA are not only spontaneous and robust, but are also often composed of multiple disjoint clusters working in coordination, raising questions about some conventional notions of individuality and replication in artificial life systems.",
    "source": "arXiv"
  },
  {
    "title": "Anderson Accelerated Primal-Dual Hybrid Gradient for solving LP",
    "title_es": "Anderson Accelerated Primal-Dual Hybrid Gradient for solving LP",
    "url": "https://arxiv.org/abs/2508.08062",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08062v1 Announce Type: cross \nAbstract: We present the Anderson Accelerated Primal-Dual Hybrid Gradient (AA-PDHG), a fixed-point-based framework designed to overcome the slow convergence of the standard PDHG method for the solution of linear programming (LP) problems. We establish the global convergence of AA-PDHG under a safeguard condition. In addition, we propose a filtered variant (FAA-PDHG) that applies angle and length filtering to preserve the uniform boundedness of the coefficient matrix, a property crucial for guaranteeing convergence. Numerical results show that both AA-PDHG and FAA-PDHG deliver significant speedups over vanilla PDHG for large-scale LP instances.",
    "source": "arXiv"
  },
  {
    "title": "Learned Regularization for Microwave Tomography",
    "title_es": "Learned Regularization for Microwave Tomography",
    "url": "https://arxiv.org/abs/2508.08114",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08114v1 Announce Type: cross \nAbstract: Microwave Tomography (MWT) aims to reconstruct the dielectric properties of tissues from measured scattered electromagnetic fields. This inverse problem is highly nonlinear and ill-posed, posing significant challenges for conventional optimization-based methods, which, despite being grounded in physical models, often fail to recover fine structural details. Recent deep learning strategies, including end-to-end and post-processing networks, have improved reconstruction quality but typically require large paired training datasets and may struggle to generalize. To overcome these limitations, we propose a physics-informed hybrid framework that integrates diffusion models as learned regularization within a data-consistency-driven variational scheme. Specifically, we introduce Single-Step Diffusion Regularization (SSD-Reg), a novel approach that embeds diffusion priors into the iterative reconstruction process, enabling the recovery of complex anatomical structures without the need for paired data. SSD-Reg maintains fidelity to both the governing physics and learned structural distributions, improving accuracy, stability, and robustness. Extensive experiments demonstrate that SSD-Reg, implemented as a Plug-and-Play (PnP) module, provides a flexible and effective solution for tackling the ill-posedness inherent in functional image reconstruction.",
    "source": "arXiv"
  },
  {
    "title": "Coloring Graphs with no Totally Odd Clique Immersion",
    "title_es": "Coloring Graphs with no Totally Odd Clique Immersion",
    "url": "https://arxiv.org/abs/2508.08119",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08119v1 Announce Type: cross \nAbstract: We prove that graphs that do not contain a totally odd immersion of $K_t$ are $\\mathcal{O}(t)$-colorable. In particular, we show that any graph with no totally odd immersion of $K_t$ is the union of a bipartite graph and a graph which forbids an immersion of $K_{\\mathcal{O}(t)}$. Our results are algorithmic, and we give a fixed-parameter tractable algorithm (in $t$) to find such a decomposition.",
    "source": "arXiv"
  },
  {
    "title": "A Lagrangian method for solving the spherical shallow water equations using power diagrams",
    "title_es": "A Lagrangian method for solving the spherical shallow water equations using power diagrams",
    "url": "https://arxiv.org/abs/2508.08129",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08129v1 Announce Type: cross \nAbstract: Numerical simulations of the air in the atmosphere and water in the oceans are essential for numerical weather prediction. The state-of-the-art for performing these fluid simulations relies on an Eulerian viewpoint, in which the fluid domain is discretized into a mesh, and the governing equations describe the fluid motion as it passes through each cell of the mesh. However, it is unclear whether a Lagrangian viewpoint, in which the fluid is discretized by a collection of particles, can outperform Eulerian simulations in global atmospheric simulations. To date, Lagrangian approaches have shown promise, but tend to produce smoother solutions. In this work, a new Lagrangian method is developed to simulate the atmosphere in which particles are represented with spherical power cells. We introduce an efficient algorithm for computing these cells which are then used to discretize the spherical shallow water equations. Mass conservation is enforced by solving a semi-discrete optimal transport problem and a semi-implicit time stepping procedure is used to advance the solution in time. We note that, in contrast to previous work, artificial viscosity is not needed to stabilize the simulation. The performance of the spherical Voronoi diagram calculation is first assessed, which shows that spherical Voronoi diagrams of 100 million sites can be computed in under 2 minutes on a single machine. The new simulation method is then evaluated on standard benchmark test cases, which shows that momentum and energy conservation of this new method is comparable to the latest Lagrangian approach for simulating the spherical shallow water equations.",
    "source": "arXiv"
  },
  {
    "title": "An effective potential for generative modelling with active matter",
    "title_es": "An effective potential for generative modelling with active matter",
    "url": "https://arxiv.org/abs/2508.08146",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08146v1 Announce Type: cross \nAbstract: Score-based diffusion models generate samples from a complex underlying data distribution by time-reversal of a diffusion process and represent the state-of-the-art in many generative AI applications such as artificial image synthesis. Here, I show how a generative diffusion model can be implemented based on an underlying active particle process with finite correlation time. In contrast to previous approaches that use a score function acting on the velocity coordinate of the active particle, time reversal is here achieved by imposing an effective time-dependent potential on the position coordinate only. The effective potential is valid to first order in the persistence time and leads to a force field that is fully determined by the standard score function and its derivatives up to 2nd order. Numerical experiments for artificial data distributions confirm the validity of the effective potential.",
    "source": "arXiv"
  },
  {
    "title": "MSU-Bench: Towards Understanding the Conversational Multi-talker Scenarios",
    "title_es": "MSU-Bench: Towards Understanding the Conversational Multi-talker Scenarios",
    "url": "https://arxiv.org/abs/2508.08155",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08155v1 Announce Type: cross \nAbstract: Spoken Language Understanding (SLU) has progressed from traditional single-task methods to large audio language model (LALM) solutions. Yet, most existing speech benchmarks focus on single-speaker or isolated tasks, overlooking the challenges posed by multi-speaker conversations that are common in real-world scenarios. We introduce MSU-Bench, a comprehensive benchmark for evaluating multi-speaker conversational understanding with a speaker-centric design. Our hierarchical framework covers four progressive tiers: single-speaker static attribute understanding, single-speaker dynamic attribute understanding, multi-speaker background understanding, and multi-speaker interaction understanding. This structure ensures all tasks are grounded in speaker-centric contexts, from basic perception to complex reasoning across multiple speakers. By evaluating state-of-the-art models on MSU-Bench, we demonstrate that as task complexity increases across the benchmark's tiers, all models exhibit a significant performance decline. We also observe a persistent capability gap between open-source models and closed-source commercial ones, particularly in multi-speaker interaction reasoning. These findings validate the effectiveness of MSU-Bench for assessing and advancing conversational understanding in realistic multi-speaker environments. Demos can be found in the supplementary material.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Learning for IRS-Assisted Wireless Networks: Securing Opportunistic Communications Against Byzantine Eavesdroppers",
    "title_es": "Adaptive Learning for IRS-Assisted Wireless Networks: Securing Opportunistic Communications Against Byzantine Eavesdroppers",
    "url": "https://arxiv.org/abs/2508.08206",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08206v1 Announce Type: cross \nAbstract: We propose a joint learning framework for Byzantine-resilient spectrum sensing and secure intelligent reflecting surface (IRS)--assisted opportunistic access under channel state information (CSI) uncertainty. The sensing stage performs logit-domain Bayesian updates with trimmed aggregation and attention-weighted consensus, and the base station (BS) fuses network beliefs with a conservative minimum rule, preserving detection accuracy under a bounded number of Byzantine users. Conditioned on the sensing outcome, we pose downlink design as sum mean-squared error (MSE) minimization under transmit-power and signal-leakage constraints and jointly optimize the BS precoder, IRS phase shifts, and user equalizers. With partial (or known) CSI, we develop an augmented-Lagrangian alternating algorithm with projected updates and provide provable sublinear convergence, with accelerated rates under mild local curvature. With unknown CSI, we perform constrained Bayesian optimization (BO) in a geometry-aware low-dimensional latent space using Gaussian process (GP) surrogates; we prove regret bounds for a constrained upper confidence bound (UCB) variant of the BO module, and demonstrate strong empirical performance of the implemented procedure. Simulations across diverse network conditions show higher detection probability at fixed false-alarm rate under adversarial attacks, large reductions in sum MSE for honest users, strong suppression of eavesdropper signal power, and fast convergence. The framework offers a practical path to secure opportunistic communication that adapts to CSI availability while coherently coordinating sensing and transmission through joint learning.",
    "source": "arXiv"
  },
  {
    "title": "Composable Quantum Fault-Tolerance",
    "title_es": "Composable Quantum Fault-Tolerance",
    "url": "https://arxiv.org/abs/2508.08246",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.08246v1 Announce Type: cross \nAbstract: Proving threshold theorems for fault-tolerant quantum computation is a burdensome endeavor with many moving parts that come together in relatively formulaic but lengthy ways. It is difficult and rare to combine elements from multiple papers into a single formal threshold proof, due to the use of different measures of fault-tolerance. In this work, we introduce composable fault-tolerance, a framework that decouples the probabilistic analysis of the noise distribution from the combinatorial analysis of circuit correctness, and enables threshold proofs to compose independently analyzed gadgets easily and rigorously. Within this framework, we provide a library of standard and commonly used gadgets such as memory and logic implemented by constant-depth circuits for quantum low-density parity check codes and distillation. As sample applications, we explicitly write down a threshold proof for computation with surface code and re-derive the constant space-overhead fault-tolerant scheme of Gottesman using gadgets from this library. We expect that future fault-tolerance proofs may focus on the analysis of novel techniques while leaving the standard components to the composable fault-tolerance framework, with the formal proof following the intuitive ``napkin math'' exactly.",
    "source": "arXiv"
  },
  {
    "title": "Superfast Low Rank Approximation",
    "title_es": "Superfast Low Rank Approximation",
    "url": "https://arxiv.org/abs/1812.11406",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:1812.11406v2 Announce Type: replace \nAbstract: Low rank approximation of a matrix (hereafter (LRA) is a highly important area of Numerical Linear and Multilinear Algebra and Data Mining and Analysis. One can operate with an LRA superfast -- by using much fewer memory cells and flops than an input matrix M has entries. Can we, however, compute an LRA of a matrix superfast? Yes and no. For worst case inputs, any LRA algorithm fails miserably unless it involves all entries of M, but in computational practice worst case inputs seem to appear rarely, and accurate LRA are routinely obtained superfast for large and important classes of matrices. We test numerically a number of superfast algorithms for various synthetic and real world matrices and consistently arrive at quite accurate LRA. Adequate formal support for these empirical observations is still a challenge, but our upper estimates for the output accuracy of our superfast deterministic LRA algorithms show that they only fail for a very narrow input class and moreover that the spectral and Frobenius error norms of the outputs of our randomized LRA algorithms are expected to stay within a noticeable but reasonable factor from their optima.",
    "source": "arXiv"
  },
  {
    "title": "What Do Our Choices Say About Our Preferences?",
    "title_es": "What Do Our Choices Say About Our Preferences?",
    "url": "https://arxiv.org/abs/2005.01586",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2005.01586v4 Announce Type: replace \nAbstract: Taking online decisions is a part of everyday life. Think of buying a house, parking a car or taking part in an auction. We often take those decisions publicly, which may breach our privacy - a party observing our choices may learn a lot about our preferences. In this paper we investigate the online stopping algorithms from the privacy preserving perspective, using a mathematically rigorous differential privacy notion. In differentially private algorithms there is usually an issue of balancing the privacy and utility. In this regime, in most cases, having both optimality and high level of privacy at the same time is impossible. We propose a natural mechanism to achieve a controllable trade-off, quantified by a parameter, between the accuracy of the online algorithm and its privacy. Depending on the parameter, our mechanism can be optimal with weaker differential privacy or suboptimal, yet more privacy-preserving. We conduct a detailed accuracy and privacy analysis of our mechanism applied to the optimal algorithm for the classical secretary problem. Thereby the classical notions from two distinct areas - optimal stopping and differential privacy - meet for the first time.",
    "source": "arXiv"
  },
  {
    "title": "Highly Fast Text Segmentation With Pairwise Markov Chains",
    "title_es": "Highly Fast Text Segmentation With Pairwise Markov Chains",
    "url": "https://arxiv.org/abs/2102.11037",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2102.11037v3 Announce Type: replace \nAbstract: Natural Language Processing (NLP) models' current trend consists of using increasingly more extra-data to build the best models as possible. It implies more expensive computational costs and training time, difficulties for deployment, and worries about these models' carbon footprint reveal a critical problem in the future. Against this trend, our goal is to develop NLP models requiring no extra-data and minimizing training time. To do so, in this paper, we explore Markov chain models, Hidden Markov Chain (HMC) and Pairwise Markov Chain (PMC), for NLP segmentation tasks. We apply these models for three classic applications: POS Tagging, Named-Entity-Recognition, and Chunking. We develop an original method to adapt these models for text segmentation's specific challenges to obtain relevant performances with very short training and execution times. PMC achieves equivalent results to those obtained by Conditional Random Fields (CRF), one of the most applied models for these tasks when no extra-data are used. Moreover, PMC has training times 30 times shorter than the CRF ones, which validates this model given our objectives.",
    "source": "arXiv"
  },
  {
    "title": "Fed-TGAN: Federated Learning Framework for Synthesizing Tabular Data",
    "title_es": "Fed-TGAN: Federated Learning Framework for Synthesizing Tabular Data",
    "url": "https://arxiv.org/abs/2108.07927",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2108.07927v2 Announce Type: replace \nAbstract: Generative Adversarial Networks (GANs) are typically trained to synthesize data, from images and more recently tabular data, under the assumption of directly accessible training data. Recently, federated learning (FL) is an emerging paradigm that features decentralized learning on client's local data with a privacy-preserving capability. And, while learning GANs to synthesize images on FL systems has just been demonstrated, it is unknown if GANs for tabular data can be learned from decentralized data sources. Moreover, it remains unclear which distributed architecture suits them best. Different from image GANs, state-of-the-art tabular GANs require prior knowledge on the data distribution of each (discrete and continuous) column to agree on a common encoding -- risking privacy guarantees. In this paper, we propose Fed-TGAN, the first Federated learning framework for Tabular GANs. To effectively learn a complex tabular GAN on non-identical participants, Fed-TGAN designs two novel features: (i) a privacy-preserving multi-source feature encoding for model initialization; and (ii) table similarity aware weighting strategies to aggregate local models for countering data skew. We extensively evaluate the proposed Fed-TGAN against variants of decentralized learning architectures on four widely used datasets. Results show that Fed-TGAN accelerates training time per epoch up to 200% compared to the alternative architectures, for both IID and Non-IID data. Overall, Fed-TGAN not only stabilizes the training loss, but also achieves better similarity between generated and original data. Our code is released at https://github.com/zhao-zilong/Fed-TGAN.",
    "source": "arXiv"
  },
  {
    "title": "On Representation Learning with Feedback",
    "title_es": "On Representation Learning with Feedback",
    "url": "https://arxiv.org/abs/2202.07572",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2202.07572v3 Announce Type: replace \nAbstract: This note complements the author's recent paper \"Robust representation learning with feedback for single image deraining\" by providing heuristically theoretical explanations on the mechanism of representation learning with feedback, namely an essential merit of the works presented in this recent article. This note facilitates understanding of key points in the mechanism of representation learning with feedback.",
    "source": "arXiv"
  },
  {
    "title": "SOInter: A Novel Deep Energy Based Interpretation Method for Explaining Structured Output Models",
    "title_es": "SOInter: A Novel Deep Energy Based Interpretation Method for Explaining Structured Output Models",
    "url": "https://arxiv.org/abs/2202.09914",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2202.09914v2 Announce Type: replace \nAbstract: We propose a novel interpretation technique to explain the behavior of structured output models, which learn mappings between an input vector to a set of output variables simultaneously. Because of the complex relationship between the computational path of output variables in structured models, a feature can affect the value of output through other ones. We focus on one of the outputs as the target and try to find the most important features utilized by the structured model to decide on the target in each locality of the input space. In this paper, we assume an arbitrary structured output model is available as a black box and argue how considering the correlations between output variables can improve the explanation performance. The goal is to train a function as an interpreter for the target output variable over the input space. We introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The effectiveness of the proposed method is confirmed using a variety of simulated and real data sets.",
    "source": "arXiv"
  },
  {
    "title": "Homomorphisms of (n,m)-graphs with respect to generalised switch",
    "title_es": "Homomorphisms of (n,m)-graphs with respect to generalised switch",
    "url": "https://arxiv.org/abs/2204.01258",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2204.01258v4 Announce Type: replace \nAbstract: The study of homomorphisms of $(n,m)$-graphs, that is, adjacency preserving vertex mappings of graphs with $n$ types of arcs and $m$ types of edges was initiated by Ne\\v{s}et\\v{r}il and Raspaud in 2000. Later, some attempts were made to generalize the switch operation that is popularly used in the study of signed graphs, and study its effect on the above mentioned homomorphism.\n  In this article, we too provide a generalization of the switch operation on $(n,m)$-graphs, which to the best of our knowledge, encapsulates all the previously known generalizations as special cases. We approach the study of homomorphisms with respect to the switch operation axiomatically. We prove some fundamental results that are essential tools in the further study of this topic. In the process of proving the fundamental results, we have provided yet another solution to an open problem posed by Klostermeyer and MacGillivray in 2004. We also prove the existence of a categorical product for $(n,m)$-graphs with respect to a particular class of generalized switch which implicitly uses category theory. This is a counter intuitive solution as the number of vertices in the Categorical product of two $(n,m)$-graphs on $p$ and $q$ vertices has a multiple of $pq$ many vertices, where the multiple depends on the switch. This solves an open question asked by Brewster in the PEPS 2012 workshop as a corollary. We also provide a way to calculate the product explicitly, and prove general properties of the product. We define the analog of chromatic number for $(n,m)$-graphs with respect to generalized switch and explore the interrelations between chromatic numbers with respect to different switch operations. We find the value of this chromatic number for the family of forests using group theoretic notions.",
    "source": "arXiv"
  },
  {
    "title": "Investigating writing style as a contributor to gender gaps in science and technology",
    "title_es": "Investigating writing style as a contributor to gender gaps in science and technology",
    "url": "https://arxiv.org/abs/2204.13805",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2204.13805v4 Announce Type: replace \nAbstract: A growing stream of research finds that scientific contributions are evaluated differently depending on the gender of the author. In this article, we consider whether gender differences in writing styles - how men and women communicate their work - may contribute to these observed gender gaps. We ground our investigation in a framework for characterizing the linguistic style of written text, with two sets of features - informational (i.e., features that emphasize facts) and involved (i.e., features that emphasize relationships). Using a large sample of academic papers and patents, we find significant differences in writing style by gender, with women using more involved features in their writing. Papers and patents with more involved features also tend to be cited more by women. Our findings suggest that scientific text is not devoid of personal character, which could contribute to bias in evaluation, thereby compromising the norm of universalism as a foundational principle of science.",
    "source": "arXiv"
  },
  {
    "title": "Approximating Dasgupta Cost in Sublinear Time from a Few Random Seeds",
    "title_es": "Approximating Dasgupta Cost in Sublinear Time from a Few Random Seeds",
    "url": "https://arxiv.org/abs/2207.02581",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2207.02581v3 Announce Type: replace \nAbstract: Testing graph cluster structure has been a central object of study in property testing since the foundational work of Goldreich and Ron [STOC'96] on expansion testing, i.e. the problem of distinguishing between a single cluster (an expander) and a graph that is far from a single cluster. More generally, a $(k, \\epsilon)$-clusterable graph $G$ is a graph whose vertex set admits a partition into $k$ induced expanders, each with outer conductance bounded by $\\epsilon$. A recent line of work initiated by Czumaj, Peng and Sohler [STOC'15] has shown how to test whether a graph is close to $(k, \\epsilon)$-clusterable, and to locally determine which cluster a given vertex belongs to with misclassification rate $\\approx \\epsilon$, but no sublinear time algorithms for learning the structure of inter-cluster connections are known. As a simple example, can one locally distinguish between the `cluster graph' forming a line and a clique?\n  In this paper, we consider the problem of testing the hierarchical cluster structure of $(k, \\epsilon)$-clusterable graphs in sublinear time. Our measure of hierarchical clusterability is the well-established Dasgupta cost, and our main result is an algorithm that approximates Dasgupta cost of a $(k, \\epsilon)$-clusterable graph in sublinear time, using a small number of randomly chosen seed vertices for which cluster labels are known. Our main result is an $O(\\sqrt{\\log k})$ approximation to Dasgupta cost of $G$ in $\\approx n^{1/2+O(\\epsilon)}$ time using $\\approx n^{1/3}$ seeds, effectively giving a sublinear time simulation of the algorithm of Charikar and Chatziafratis [SODA'17] on clusterable graphs. To the best of our knowledge, ours is the first result on approximating the hierarchical clustering properties of such graphs in sublinear time.",
    "source": "arXiv"
  },
  {
    "title": "Practical Guidelines for Ideology Detection Pipelines and Psychosocial Applications",
    "title_es": "Practical Guidelines for Ideology Detection Pipelines and Psychosocial Applications",
    "url": "https://arxiv.org/abs/2208.04097",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2208.04097v4 Announce Type: replace \nAbstract: Online ideology detection is crucial for downstream tasks, like countering ideologically motivated violent extremism and modeling opinion dynamics. However, two significant issues arise in practitioners' deployment. Firstly, gold-standard training data is prohibitively labor-intensive to collect and has limited reusability beyond its collection context (i.e., time, location, and platform). Secondly, to circumvent expense, researchers employ ideological signals (such as hashtags shared). Unfortunately, these signals' annotation requirements and context transferability are largely unknown, and the bias they induce remains unquantified. This study provides guidelines for practitioners requiring real-time detection of left, right, and extreme ideologies in large-scale online settings. We propose a framework for pipeline constructions, describing ideology signals by their associated labor and context transferability. We evaluate many constructions, quantifying the bias associated with signals and describing a pipeline that outperforms state-of-the-art methods ($0.95$ AUC ROC). We showcase the capabilities of our pipeline on five datasets containing more than 1.12 million users. We set out to investigate whether the findings in the psychosocial literature, developed for the offline environment, apply to the online setting. We evaluate at scale several psychosocial hypotheses that delineate ideologies concerning morality, grievance, nationalism, and dichotomous thinking. We find that right-wing ideologies use more vice-moral language, have more grievance-filled language, exhibit increased black-and-white thinking patterns, and have a greater association with national flags. This research empowers practitioners with guidelines for ideology detection, and case studies for its application, fostering a safer and better understood digital landscape.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Contextual Preferential Bayesian Optimization with Historical Examples",
    "title_es": "Efficient Contextual Preferential Bayesian Optimization with Historical Examples",
    "url": "https://arxiv.org/abs/2208.10300",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2208.10300v3 Announce Type: replace \nAbstract: State-of-the-art multi-objective optimization often assumes a known utility function, learns it interactively, or computes the full Pareto front-each requiring costly expert input.~Real-world problems, however, involve implicit preferences that are hard to formalize. To reduce expert involvement, we propose an offline, interpretable utility learning method that uses expert knowledge, historical examples, and coarse information about the utility space to reduce sample requirements. We model uncertainty via a full Bayesian posterior and propagate it throughout the optimization process. Our method outperforms standard Gaussian processes and BOPE across four domains, showing strong performance even with biased samples, as encountered in the real-world, and limited expert input.",
    "source": "arXiv"
  },
  {
    "title": "Coinductive Streams in Monoidal Categories",
    "title_es": "Coinductive Streams in Monoidal Categories",
    "url": "https://arxiv.org/abs/2212.14494",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2212.14494v5 Announce Type: replace \nAbstract: We introduce monoidal streams. Monoidal streams are a generalization of causal stream functions, which can be defined in cartesian monoidal categories, to arbitrary symmetric monoidal categories. In the same way that streams provide semantics to dataflow programming with pure functions, monoidal streams provide semantics to dataflow programming with theories of processes represented by a symmetric monoidal category. Monoidal streams also form a feedback monoidal category. In the same way that we can use a coinductive stream calculus to reason about signal flow graphs, we can use coinductive string diagrams to reason about feedback monoidal categories. As an example, we study syntax for a stochastic dataflow language, with semantics in stochastic monoidal streams.",
    "source": "arXiv"
  },
  {
    "title": "AdaBoost is not an Optimal Weak to Strong Learner",
    "title_es": "AdaBoost is not an Optimal Weak to Strong Learner",
    "url": "https://arxiv.org/abs/2301.11571",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2301.11571v2 Announce Type: replace \nAbstract: AdaBoost is a classic boosting algorithm for combining multiple inaccurate classifiers produced by a weak learner, to produce a strong learner with arbitrarily high accuracy when given enough training data. Determining the optimal number of samples necessary to obtain a given accuracy of the strong learner, is a basic learning theoretic question. Larsen and Ritzert (NeurIPS'22) recently presented the first provably optimal weak-to-strong learner. However, their algorithm is somewhat complicated and it remains an intriguing question whether the prototypical boosting algorithm AdaBoost also makes optimal use of training samples. In this work, we answer this question in the negative. Concretely, we show that the sample complexity of AdaBoost, and other classic variations thereof, are sub-optimal by at least one logarithmic factor in the desired accuracy of the strong learner.",
    "source": "arXiv"
  },
  {
    "title": "Combinatorial Parameterized Algorithms for Chemical Descriptors based on Molecular Graph Sparsity",
    "title_es": "Combinatorial Parameterized Algorithms for Chemical Descriptors based on Molecular Graph Sparsity",
    "url": "https://arxiv.org/abs/2303.13279",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2303.13279v2 Announce Type: replace \nAbstract: We present efficient combinatorial parameterized algorithms for several classical graph-based counting problems in computational chemistry, including (i) Kekule structures, (ii) the Hosoya index, (iii) the Merrifield-Simmons index, and (iv) Graph entropy based on matchings and independent sets. All these problems were known to be #P-complete. Building on the intuition that molecular graphs are often sparse and tree-like, we provide fixed-parameter tractable (FPT) algorithms using treewidth as our parameter. We also provide extensive experimental results over the entire PubChem database of chemical compounds, containing more than 113 million real-world molecules. In our experiments, we observe that the molecules are indeed sparse and tree-like, with more than 99.9% of them having a treewidth of at most 5. This justifies our choice of parameter. Our experiments also illustrate considerable improvements over the previous approaches. Based on these results, we argue that parameterized algorithms, especially based on treewidth, should be adopted as the default approach for problems in computational chemistry that are defined over molecular graphs.",
    "source": "arXiv"
  },
  {
    "title": "Fundamental Limits of Distributed Linearly Separable Computation under Cyclic Assignment",
    "title_es": "Fundamental Limits of Distributed Linearly Separable Computation under Cyclic Assignment",
    "url": "https://arxiv.org/abs/2305.05143",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2305.05143v3 Announce Type: replace \nAbstract: This paper studies the master-worker distributed linearly separable computation problem, where the considered computation task, referred to as linearly separable function, is a typical linear transform model widely used in cooperative distributed gradient coding, real-time rendering, linear transformers, etc. %A master asks $\\Nsf$ distributed workers to compute a linearly separable function from $\\Ksf$ datasets. The computation task on $\\Ksf$ datasets can be expressed as $\\Ksf_{\\rm c}$ linear combinations of $\\Ksf$ messages, where each message is the output of an individual function on one dataset. Straggler effect is also considered, such that from the answers of any $\\Nsf_{\\rm r}$ of the $\\Nsf$ distributed workers, the master should accomplish the task. The computation cost is defined as the number of datasets assigned to each worker, while the communication cost is defined as the number of (coded) messages that should be received. The objective is to characterize the optimal tradeoff between the computation and communication costs. The problem has remained so far open, even under the cyclic data assignment.Since in fact various distributed computing schemes were proposed in the literature under the cyclic data assignment, with this paper we close the problem for the cyclic assignment. This paper proposes a new computing scheme with the cyclic assignment based on the concept of interference alignment, by treating each message which cannot be computed by a worker as an interference from this worker. Under the cyclic assignment, the proposed computing scheme is then proved to be optimal when $\\Nsf=\\Ksf$ and be order optimal within a factor of $2$ otherwise.",
    "source": "arXiv"
  },
  {
    "title": "Active Policy Improvement from Multiple Black-box Oracles",
    "title_es": "Active Policy Improvement from Multiple Black-box Oracles",
    "url": "https://arxiv.org/abs/2306.10259",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2306.10259v3 Announce Type: replace \nAbstract: Reinforcement learning (RL) has made significant strides in various complex domains. However, identifying an effective policy via RL often necessitates extensive exploration. Imitation learning aims to mitigate this issue by using expert demonstrations to guide exploration. In real-world scenarios, one often has access to multiple suboptimal black-box experts, rather than a single optimal oracle. These experts do not universally outperform each other across all states, presenting a challenge in actively deciding which oracle to use and in which state. We introduce MAPS and MAPS-SE, a class of policy improvement algorithms that perform imitation learning from multiple suboptimal oracles. In particular, MAPS actively selects which of the oracles to imitate and improve their value function estimates, and MAPS-SE additionally leverages an active state exploration criterion to determine which states one should explore. We provide a comprehensive theoretical analysis and demonstrate that MAPS and MAPS-SE enjoy sample efficiency advantage over the state-of-the-art policy improvement algorithms. Empirical results show that MAPS-SE significantly accelerates policy optimization via state-wise imitation learning from multiple oracles across a broad spectrum of control tasks in the DeepMind Control Suite. Our code is publicly available at: https://github.com/ripl/maps.",
    "source": "arXiv"
  },
  {
    "title": "Discerning Reliable Cyber Threat Indicators for Timely Cyber Threat Intelligence",
    "title_es": "Discerning Reliable Cyber Threat Indicators for Timely Cyber Threat Intelligence",
    "url": "https://arxiv.org/abs/2306.16087",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2306.16087v2 Announce Type: replace \nAbstract: In today's dynamic cybersecurity landscape, timely and accurate threat intelligence is essential for proactive defense. This study explores the potential of social media platforms as a valuable resource for extracting actionable Indicators of Compromise (IoCs). Utilizing a Convolutional Neural Network (CNN), we achieved an F1-score of 98.80% and a detection rate of 99.65%, filtering vast social media data to identify key IoCs, including IP addresses, URLs, file hashes, domain addresses, and CVE IDs. These indicators are critical for detecting potential threats and vulnerabilities, and their relevance was evaluated using metrics such as correctness, timeliness, and overlap. Our analysis shows that URLs emerged as the most frequently shared IoC, with 48.67% representing valid threats. To further investigate the role of automated accounts in disseminating IoCs, we applied several machine learning models, with XGBoost delivering the highest performance achieving a macro F1-score of 0.814 and a weighted F1-score of 0.925. These findings highlight the growing significance of social media as a reliable source of actionable threat intelligence, offering valuable insights for cybersecurity professionals to stay ahead of emerging threats.",
    "source": "arXiv"
  },
  {
    "title": "$(1-\\epsilon)$-Approximation of Knapsack in Nearly Quadratic Time",
    "title_es": "$(1-\\epsilon)$-Approximation of Knapsack in Nearly Quadratic Time",
    "url": "https://arxiv.org/abs/2308.07004",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2308.07004v4 Announce Type: replace \nAbstract: Knapsack is one of the most fundamental problems in theoretical computer science. In the $(1 - \\epsilon)$-approximation setting, although there is a fine-grained lower bound of $(n + 1 / \\epsilon) ^ {2 - o(1)}$ based on the $(\\min, +)$-convolution hypothesis ([K{\\\"u}nnemann, Paturi and Stefan Schneider, ICALP 2017] and [Cygan, Mucha, Wegrzycki and Wlodarczyk, 2017]), the best algorithm is randomized and runs in $\\tilde O\\left(n + (\\frac{1}{\\epsilon})^{11/5}/2^{\\Omega(\\sqrt{\\log(1/\\epsilon)})}\\right)$ time [Deng, Jin and Mao, SODA 2023], and it remains an important open problem whether an algorithm with a running time that matches the lower bound (up to a sub-polynomial factor) exists. We answer the question positively by showing a deterministic $(1 - \\epsilon)$-approximation scheme for knapsack that runs in $\\tilde O(n + (1 / \\epsilon) ^ {2})$ time. We first extend a known lemma in a recursive way to reduce the problem to $n \\epsilon$-additive approximation for $n$ items with profits in $[1, 2)$. Then we give a simple efficient geometry-based algorithm for the reduced problem.",
    "source": "arXiv"
  },
  {
    "title": "Asynchronous Majority Dynamics on Binomial Random Graphs",
    "title_es": "Asynchronous Majority Dynamics on Binomial Random Graphs",
    "url": "https://arxiv.org/abs/2309.04691",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2309.04691v2 Announce Type: replace \nAbstract: We study information aggregation in networks when agents interact to learn a binary state of the world. Initially each agent privately observes an independent signal which is \"correct\" with probability $\\frac{1}{2}+\\delta$ for some $\\delta > 0$. At each round, a node is selected uniformly at random to update their public opinion to match the majority of their neighbours (breaking ties in favour of their initial private signal). Our main result shows that for sparse and connected binomial random graphs $\\mathcal G(n,p)$ the process stabilizes in a \"correct\" consensus in $\\mathcal O(n\\log^2 n/\\log\\log n)$ steps with high probability. In fact, when $\\log n/n \\ll p = o(1)$ the process terminates at time $\\hat T = (1+o(1))n\\log n$, where $\\hat T$ is the first time when all nodes have been selected at least once. However, in dense binomial random graphs with $p=\\Omega(1)$, there is an information cascade where the process terminates in the \"incorrect\" consensus with probability bounded away from zero.",
    "source": "arXiv"
  },
  {
    "title": "Blending Imitation and Reinforcement Learning for Robust Policy Improvement",
    "title_es": "Blending Imitation and Reinforcement Learning for Robust Policy Improvement",
    "url": "https://arxiv.org/abs/2310.01737",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2310.01737v3 Announce Type: replace \nAbstract: While reinforcement learning (RL) has shown promising performance, its sample complexity continues to be a substantial hurdle, restricting its broader application across a variety of domains. Imitation learning (IL) utilizes oracles to improve sample efficiency, yet it is often constrained by the quality of the oracles deployed. which actively interleaves between IL and RL based on an online estimate of their performance. RPI draws on the strengths of IL, using oracle queries to facilitate exploration, an aspect that is notably challenging in sparse-reward RL, particularly during the early stages of learning. As learning unfolds, RPI gradually transitions to RL, effectively treating the learned policy as an improved oracle. This algorithm is capable of learning from and improving upon a diverse set of black-box oracles. Integral to RPI are Robust Active Policy Selection (RAPS) and Robust Policy Gradient (RPG), both of which reason over whether to perform state-wise imitation from the oracles or learn from its own value function when the learner's performance surpasses that of the oracles in a specific state. Empirical evaluations and theoretical analysis validate that RPI excels in comparison to existing state-of-the-art methodologies, demonstrating superior performance across various benchmark domains.",
    "source": "arXiv"
  },
  {
    "title": "Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations",
    "title_es": "Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations",
    "url": "https://arxiv.org/abs/2310.09612",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2310.09612v2 Announce Type: replace \nAbstract: Although deep neural networks can achieve human-level performance on many object recognition benchmarks, prior work suggests that these same models fail to learn simple abstract relations, such as determining whether two objects are the same or different. Much of this prior work focuses on training convolutional neural networks to classify images of two same or two different abstract shapes, testing generalization on within-distribution stimuli. In this article, we comprehensively study whether deep neural networks can acquire and generalize same-different relations both within and out-of-distribution using a variety of architectures, forms of pretraining, and fine-tuning datasets. We find that certain pretrained transformers can learn a same-different relation that generalizes with near perfect accuracy to out-of-distribution stimuli. Furthermore, we find that fine-tuning on abstract shapes that lack texture or color provides the strongest out-of-distribution generalization. Our results suggest that, with the right approach, deep neural networks can learn generalizable same-different visual relations.",
    "source": "arXiv"
  },
  {
    "title": "Finite Sample Performance Analysis of MIMO Systems Identification",
    "title_es": "Finite Sample Performance Analysis of MIMO Systems Identification",
    "url": "https://arxiv.org/abs/2310.11790",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2310.11790v4 Announce Type: replace \nAbstract: This paper is concerned with the finite sample identification performance of an n dimensional discrete-time Multiple-Input Multiple-Output (MIMO) Linear Time-Invariant system, with p inputs and m outputs. We prove that the widely-used Ho-Kalman algorithm and Multivariable Output Error State Space (MOESP) algorithm are ill-conditioned for MIMO systems when n/m or n/p is large. Moreover, by analyzing the Cra\\'mer-Rao bound, we derive a fundamental limit for identifying the real and stable (or marginally stable) poles of MIMO system and prove that the sample complexity for any unbiased pole estimation algorithm to reach a certain level of accuracy explodes superpolynomially with respect to n/(pm). Numerical results are provided to illustrate the ill-conditionedness of Ho-Kalman algorithm and MOESP algorithm as well as the fundamental limit on identification.",
    "source": "arXiv"
  },
  {
    "title": "Distributed Optimal Coverage Control in Multi-agent Systems: Known and Unknown Environments",
    "title_es": "Distributed Optimal Coverage Control in Multi-agent Systems: Known and Unknown Environments",
    "url": "https://arxiv.org/abs/2310.13557",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2310.13557v3 Announce Type: replace \nAbstract: This paper introduces a novel approach to solve the coverage optimization problem in multi-agent systems. The proposed technique offers an optimal solution with a lower cost with respect to conventional Voronoi-based techniques by effectively handling the issue of agents remaining stationary in regions void of information using a ranking function. The proposed approach leverages a novel cost function for optimizing the agents coverage and the cost function eventually aligns with the conventional Voronoi-based cost function. Theoretical analyses are conducted to assure the asymptotic convergence of agents towards the optimal configuration. A distinguishing feature of this approach lies in its departure from the reliance on geometric methods that are characteristic of Voronoi-based approaches; hence can be implemented more simply. Remarkably, the technique is adaptive and applicable to various environments with both known and unknown information distributions. Lastly, the efficacy of the proposed method is demonstrated through simulations, and the obtained results are compared with those of Voronoi-based algorithms.",
    "source": "arXiv"
  },
  {
    "title": "Empathy Detection from Text, Audiovisual, Audio or Physiological Signals: A Systematic Review of Task Formulations and Machine Learning Methods",
    "title_es": "Empathy Detection from Text, Audiovisual, Audio or Physiological Signals: A Systematic Review of Task Formulations and Machine Learning Methods",
    "url": "https://arxiv.org/abs/2311.00721",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2311.00721v5 Announce Type: replace \nAbstract: Empathy indicates an individual's ability to understand others. Over the past few years, empathy has drawn attention from various disciplines, including but not limited to Affective Computing, Cognitive Science, and Psychology. Detecting empathy has potential applications in society, healthcare and education. Despite being a broad and overlapping topic, the avenue of empathy detection leveraging Machine Learning remains underexplored from a systematic literature review perspective. We collected 849 papers from 10 well-known academic databases, systematically screened them and analysed the final 82 papers. Our analyses reveal several prominent task formulations - including empathy on localised utterances or overall expressions, unidirectional or parallel empathy, and emotional contagion - in monadic, dyadic and group interactions. Empathy detection methods are summarised based on four input modalities - text, audiovisual, audio and physiological signals - thereby presenting modality-specific network architecture design protocols. We discuss challenges, research gaps and potential applications in the Affective Computing-based empathy domain, which can facilitate new avenues of exploration. We further enlist the public availability of datasets and codes. This paper, therefore, provides a structured overview of recent advancements and remaining challenges towards developing a robust empathy detection system that could meaningfully contribute to enhancing human well-being.",
    "source": "arXiv"
  },
  {
    "title": "ComPEFT: Compression for Communicating Parameter Efficient Updates via Sparsification and Quantization",
    "title_es": "ComPEFT: Compression for Communicating Parameter Efficient Updates via Sparsification and Quantization",
    "url": "https://arxiv.org/abs/2311.13171",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2311.13171v2 Announce Type: replace \nAbstract: Parameter-efficient fine-tuning (PEFT) techniques make it possible to efficiently adapt a language model to create \"expert\" models that specialize to new tasks or domains. Recent techniques in model merging and compositional generalization leverage these expert models by dynamically composing modules to improve zero/few-shot generalization. Despite the efficiency of PEFT methods, the size of expert models can make it onerous to retrieve expert models per query over high-latency networks like the Internet or serve multiple experts on a single GPU. To address these issues, we present ComPEFT, a novel method for compressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT employs sparsification and ternary quantization to reduce the size of the PEFT module without performing any additional retraining while preserving or enhancing model performance. In extensive evaluation across T5, T0, and LLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression ratios of 8x - 50x. In particular, we show that ComPEFT improves with scale - stronger models exhibit higher compressibility and better performance. For example, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on MMLU with a storage size reduction of up to 26x. In addition, we show that the compressed experts produced by ComPEFT maintain few-shot compositional generalization capabilities, facilitate efficient communication and computation, and exhibit enhanced performance when merged. Lastly, we provide an analysis of different method components, compare it with other PEFT methods, and test ComPEFT's efficacy for compressing the residual of full-finetuning. Our code is available at https://github.com/prateeky2806/compeft.",
    "source": "arXiv"
  },
  {
    "title": "EA-KD: Entropy-based Adaptive Knowledge Distillation",
    "title_es": "EA-KD: Entropy-based Adaptive Knowledge Distillation",
    "url": "https://arxiv.org/abs/2311.13621",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2311.13621v3 Announce Type: replace \nAbstract: Knowledge distillation (KD) enables a smaller \"student\" model to mimic a larger \"teacher\" model by transferring knowledge from the teacher's output or features. However, most KD methods treat all samples uniformly, overlooking the varying learning value of each sample and thereby limiting their effectiveness. In this paper, we propose Entropy-based Adaptive Knowledge Distillation (EA-KD), a simple yet effective plug-and-play KD method that prioritizes learning from valuable samples. EA-KD quantifies each sample's learning value by strategically combining the entropy of the teacher and student output, then dynamically reweights the distillation loss to place greater emphasis on high-entropy samples. Extensive experiments across diverse KD frameworks and tasks -- including image classification, object detection, and large language model (LLM) distillation -- demonstrate that EA-KD consistently enhances performance, achieving state-of-the-art results with negligible computational cost. Code is available at: https://github.com/cpsu00/EA-KD",
    "source": "arXiv"
  },
  {
    "title": "Scene Summarization: Clustering Scene Videos into Spatially Diverse Frames",
    "title_es": "Scene Summarization: Clustering Scene Videos into Spatially Diverse Frames",
    "url": "https://arxiv.org/abs/2311.17940",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2311.17940v2 Announce Type: replace \nAbstract: Humans are remarkably efficient at forming spatial understanding from just a few visual observations. When browsing real estate or navigating unfamiliar spaces, they intuitively select a small set of views that summarize the spatial layout. Inspired by this ability, we introduce scene summarization, the task of condensing long, continuous scene videos into a compact set of spatially diverse keyframes that facilitate global spatial reasoning. Unlike conventional video summarization-which focuses on user-edited, fragmented clips and often ignores spatial continuity-our goal is to mimic how humans abstract spatial layout from sparse views. We propose SceneSum, a two-stage self-supervised pipeline that first clusters video frames using visual place recognition to promote spatial diversity, then selects representative keyframes from each cluster under resource constraints. When camera trajectories are available, a lightweight supervised loss further refines clustering and selection. Experiments on real and simulated indoor datasets show that SceneSum produces more spatially informative summaries and outperforms existing video summarization baselines.",
    "source": "arXiv"
  },
  {
    "title": "{\\lambda}-SecAgg: Partial Vector Freezing for Lightweight Secure Aggregation in Federated Learning",
    "title_es": "{\\lambda}-SecAgg: Partial Vector Freezing for Lightweight Secure Aggregation in Federated Learning",
    "url": "https://arxiv.org/abs/2312.04920",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2312.04920v3 Announce Type: replace \nAbstract: Secure aggregation of user update vectors (e.g. gradients) has become a critical issue in the field of federated learning. Many Secure Aggregation Protocols (SAPs) face exorbitant computation costs, severely constraining their applicability. Given the observation that a considerable portion of SAP's computation burden stems from processing each entry in the private vectors, we propose \\textbf{P}artial \\textbf{V}ector \\textbf{F}reezing (\\textbf{PVF}), a portable module for compressing computation costs without introducing additional communication overhead. \\textbf{$\\bm{\\lambda}$-SecAgg}, which integrates SAP with PVF, ``freezes'' a substantial portion of the private vector through specific transformations, requiring only $\\frac{1}{\\lambda}$ of the original vector to participate in SAP. Eventually, users can ``thaw'' the public sum of the ``frozen entries'' by the result of SAP. To avoid potential privacy leakage, we devise Disrupting Variables Extension for PVF. We demonstrate that PVF can seamlessly integrate with various SAPs and it poses no threat to user privacy in the semi-honest and active adversary settings. We include $7$ baselines, encompassing $5$ distinct types of masking schemes, and explore the acceleration effects of PVF on these SAPs. Empirical investigations indicate that when $\\lambda=100$, PVF yields up to $99.5\\times$ speedup and up to $32.3\\times$ communication reduction.",
    "source": "arXiv"
  },
  {
    "title": "Optimal Multi-Distribution Learning",
    "title_es": "Optimal Multi-Distribution Learning",
    "url": "https://arxiv.org/abs/2312.05134",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2312.05134v5 Announce Type: replace \nAbstract: Multi-distribution learning (MDL), which seeks to learn a shared model that minimizes the worst-case risk across $k$ distinct data distributions, has emerged as a unified framework in response to the evolving demand for robustness, fairness, multi-group collaboration, etc. Achieving data-efficient MDL necessitates adaptive sampling, also called on-demand sampling, throughout the learning process. However, there exist substantial gaps between the state-of-the-art upper and lower bounds on the optimal sample complexity. Focusing on a hypothesis class of Vapnik-Chervonenkis (VC) dimension d, we propose a novel algorithm that yields an varepsilon-optimal randomized hypothesis with a sample complexity on the order of (d+k)/varepsilon^2 (modulo some logarithmic factor), matching the best-known lower bound. Our algorithmic ideas and theory are further extended to accommodate Rademacher classes. The proposed algorithms are oracle-efficient, which access the hypothesis class solely through an empirical risk minimization oracle.\n  Additionally, we establish the necessity of randomization, revealing a large sample size barrier when only deterministic hypotheses are permitted. These findings resolve three open problems presented in COLT 2023 (i.e., citet[Problems 1, 3 and 4]{awasthi2023sample}).",
    "source": "arXiv"
  },
  {
    "title": "Sparse Variational Student-t Processes",
    "title_es": "Sparse Variational Student-t Processes",
    "url": "https://arxiv.org/abs/2312.05568",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2312.05568v2 Announce Type: replace \nAbstract: The theory of Bayesian learning incorporates the use of Student-t Processes to model heavy-tailed distributions and datasets with outliers. However, despite Student-t Processes having a similar computational complexity as Gaussian Processes, there has been limited emphasis on the sparse representation of this model. This is mainly due to the increased difficulty in modeling and computation compared to previous sparse Gaussian Processes. Our motivation is to address the need for a sparse representation framework that reduces computational complexity, allowing Student-t Processes to be more flexible for real-world datasets. To achieve this, we leverage the conditional distribution of Student-t Processes to introduce sparse inducing points. Bayesian methods and variational inference are then utilized to derive a well-defined lower bound, facilitating more efficient optimization of our model through stochastic gradient descent. We propose two methods for computing the variational lower bound, one utilizing Monte Carlo sampling and the other employing Jensen's inequality to compute the KL regularization term in the loss function. We propose adopting these approaches as viable alternatives to Gaussian processes when the data might contain outliers or exhibit heavy-tailed behavior, and we provide specific recommendations for their applicability. We evaluate the two proposed approaches on various synthetic and real-world datasets from UCI and Kaggle, demonstrating their effectiveness compared to baseline methods in terms of computational complexity and accuracy, as well as their robustness to outliers.",
    "source": "arXiv"
  },
  {
    "title": "Disclosure Avoidance for the 2020 Census Demographic and Housing Characteristics File",
    "title_es": "Disclosure Avoidance for the 2020 Census Demographic and Housing Characteristics File",
    "url": "https://arxiv.org/abs/2312.10863",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2312.10863v2 Announce Type: replace \nAbstract: In \"The 2020 Census Disclosure Avoidance System TopDown Algorithm,\" Abowd et al. (2022) describe the concepts and methods used by the Disclosure Avoidance System (DAS) to produce formally private output in support of the 2020 Census statistical data product releases, with a particular focus on the DAS implementation that was used to create the 2020 Census Redistricting Data (P.L. 94-171) Summary File. In this paper we describe the updates to the DAS that were required to release the Demographic and Housing Characteristics (DHC) File, which provides more granular tables than other statistical data products, such as the Redistricting Data Summary File. We also describe the final configuration parameters used for the 2020 production DHC DAS implementation, error metrics for these production statistical data products, and plans for future experimental data products that provide confidence intervals for confidential 2020 Census tabulations.",
    "source": "arXiv"
  },
  {
    "title": "BonnBeetClouds3D: A Dataset Towards Point Cloud-based Organ-level Phenotyping of Sugar Beet Plants under Field Conditions",
    "title_es": "BonnBeetClouds3D: A Dataset Towards Point Cloud-based Organ-level Phenotyping of Sugar Beet Plants under Field Conditions",
    "url": "https://arxiv.org/abs/2312.14706",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2312.14706v2 Announce Type: replace \nAbstract: Agricultural production is facing severe challenges in the next decades induced by climate change and the need for sustainability, reducing its impact on the environment. Advancements in field management through non-chemical weeding by robots in combination with monitoring of crops by autonomous unmanned aerial vehicles (UAVs) and breeding of novel and more resilient crop varieties are helpful to address these challenges. The analysis of plant traits, called phenotyping, is an essential activity in plant breeding, it however involves a great amount of manual labor. With this paper, we address the problem of automatic fine-grained organ-level geometric analysis needed for precision phenotyping. As the availability of real-world data in this domain is relatively scarce, we propose a novel dataset that was acquired using UAVs capturing high-resolution images of a real breeding trial containing 48 plant varieties and therefore covering great morphological and appearance diversity. This enables the development of approaches for autonomous phenotyping that generalize well to different varieties. Based on overlapping high-resolution images from multiple viewing angles, we compute photogrammetric dense point clouds and provide detailed and accurate point-wise labels for plants, leaves, and salient points as the tip and the base. Additionally, we include measurements of phenotypic traits performed by experts from the German Federal Plant Variety Office on the real plants, allowing the evaluation of new approaches not only on segmentation and keypoint detection but also directly on the downstream tasks. The provided labeled point clouds enable fine-grained plant analysis and support further progress in the development of automatic phenotyping approaches, but also enable further research in surface reconstruction, point cloud completion, and semantic interpretation of point clouds.",
    "source": "arXiv"
  },
  {
    "title": "Towards Customized Knowledge Distillation for Chip-Level Dense Image Predictions",
    "title_es": "Towards Customized Knowledge Distillation for Chip-Level Dense Image Predictions",
    "url": "https://arxiv.org/abs/2401.13174",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2401.13174v5 Announce Type: replace \nAbstract: It has been revealed that efficient dense image prediction (EDIP) models designed for AI chips, trained using the knowledge distillation (KD) framework, encounter two key challenges, including \\emph{maintaining boundary region completeness} and \\emph{ensuring target region connectivity}, despite their favorable real-time capacity to recognize the main object regions. In this work, we propose a customized boundary and context knowledge distillation (BCKD) method for EDIPs, which facilitates the targeted KD from large accurate teacher models to compact small student models. Specifically, the \\emph{boundary distillation} focuses on extracting explicit object-level boundaries from the hierarchical feature maps to enhance the student model's mask quality in boundary regions. Meanwhile, the \\emph{context distillation} leverages self-relations as a bridge to transfer implicit pixel-level contexts from the teacher model to the student model, ensuring strong connectivity in target regions. Our proposed method is specifically designed for the EDIP tasks and is characterized by its simplicity and efficiency. Theoretical analysis and extensive experimental results across semantic segmentation, object detection, and instance segmentation on five representative datasets demonstrate the effectiveness of BCKD, resulting in well-defined object boundaries and smooth connecting regions.",
    "source": "arXiv"
  },
  {
    "title": "On the Separability Problem of VASS Reachability Languages",
    "title_es": "On the Separability Problem of VASS Reachability Languages",
    "url": "https://arxiv.org/abs/2401.16095",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2401.16095v3 Announce Type: replace \nAbstract: We show that the regular separability problem of VASS reachability languages is decidable and $\\mathbf{F}_{\\omega}$-complete. At the heart of our decision procedure are doubly-marked graph transition sequences, a new proof object that tracks a suitable product of the VASS we wish to separate. We give a decomposition algorithm for DMGTS that not only achieves perfectness as known from MGTS, but also a new property called faithfulness. Faithfulness allows us to construct, from a regular separator for the $\\mathbb{Z}$-versions of the VASS, a regular separator for the $\\mathbb{N}$-versions. Behind faithfulness is the insight that, for separability, it is sufficient to track the counters of one VASS modulo a large number that is determined by the decomposition.",
    "source": "arXiv"
  },
  {
    "title": "Learn to Teach: Sample-Efficient Privileged Learning for Humanoid Locomotion over Diverse Terrains",
    "title_es": "Learn to Teach: Sample-Efficient Privileged Learning for Humanoid Locomotion over Diverse Terrains",
    "url": "https://arxiv.org/abs/2402.06783",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2402.06783v3 Announce Type: replace \nAbstract: Humanoid robots promise transformative capabilities for industrial and service applications. While recent advances in Reinforcement Learning (RL) yield impressive results in locomotion, manipulation, and navigation, the proposed methods typically require enormous simulation samples to account for real-world variability. This work proposes a novel one-stage training framework-Learn to Teach (L2T)-which unifies teacher and student policy learning. Our approach recycles simulator samples and synchronizes the learning trajectories through shared dynamics, significantly reducing sample complexities and training time while achieving state-of-the-art performance. Furthermore, we validate the RL variant (L2T-RL) through extensive simulations and hardware tests on the Digit robot, demonstrating zero-shot sim-to-real transfer and robust performance over 12+ challenging terrains without depth estimation modules.",
    "source": "arXiv"
  },
  {
    "title": "Compact and De-biased Negative Instance Embedding for Multi-Instance Learning on Whole-Slide Image Classification",
    "title_es": "Compact and De-biased Negative Instance Embedding for Multi-Instance Learning on Whole-Slide Image Classification",
    "url": "https://arxiv.org/abs/2402.10595",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2402.10595v2 Announce Type: replace \nAbstract: Whole-slide image (WSI) classification is a challenging task because 1) patches from WSI lack annotation, and 2) WSI possesses unnecessary variability, e.g., stain protocol. Recently, Multiple-Instance Learning (MIL) has made significant progress, allowing for classification based on slide-level, rather than patch-level, annotations. However, existing MIL methods ignore that all patches from normal slides are normal. Using this free annotation, we introduce a semi-supervision signal to de-bias the inter-slide variability and to capture the common factors of variation within normal patches. Because our method is orthogonal to the MIL algorithm, we evaluate our method on top of the recently proposed MIL algorithms and also compare the performance with other semi-supervised approaches. We evaluate our method on two public WSI datasets including Camelyon-16 and TCGA lung cancer and demonstrate that our approach significantly improves the predictive performance of existing MIL algorithms and outperforms other semi-supervised algorithms. We release our code at https://github.com/AITRICS/pathology_mil.",
    "source": "arXiv"
  },
  {
    "title": "Monte Carlo with kernel-based Gibbs measures: Guarantees for probabilistic herding",
    "title_es": "Monte Carlo with kernel-based Gibbs measures: Guarantees for probabilistic herding",
    "url": "https://arxiv.org/abs/2402.11736",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2402.11736v2 Announce Type: replace \nAbstract: Kernel herding belongs to a family of deterministic quadratures that seek to minimize the worst-case integration error over a reproducing kernel Hilbert space (RKHS). These quadrature rules come with strong experimental evidence that this worst-case error decreases at a faster rate than the standard square root of the number of quadrature nodes. This conjectured fast rate is key for integrating expensive-to-evaluate functions, as in Bayesian inference of expensive models, and makes up for the increased computational cost of sampling, compared to i.i.d. or MCMC quadratures. However, there is little theoretical support for this faster-than-square-root rate, at least in the usual case where the RKHS is infinite-dimensional, while recent progress on distribution compression suggests that results on the direct minimization of worst-case integration are possible. In this paper, we study a joint probability distribution over quadrature nodes, whose support tends to minimize the same worst-case error as kernel herding. Our main contribution is to prove that it does outperform i.i.d Monte Carlo, in the sense of coming with a tighter concentration inequality on the worst-case integration error. This first step towards proving a fast error decay demonstrates that the mathematical toolbox developed around Gibbs measures can help understand to what extent kernel herding and its variants improve on computationally cheaper methods. Moreover, we investigate the computational bottlenecks of approximately sampling our quadrature, and we demonstrate on toy examples that a faster rate of convergence, though not worst-case, is likely.",
    "source": "arXiv"
  },
  {
    "title": "DreamFrame: Enhancing Video Understanding via Automatically Generated QA and Style-Consistent Keyframes",
    "title_es": "DreamFrame: Enhancing Video Understanding via Automatically Generated QA and Style-Consistent Keyframes",
    "url": "https://arxiv.org/abs/2403.01422",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2403.01422v5 Announce Type: replace \nAbstract: Recent large vision-language models (LVLMs) for video understanding are primarily fine-tuned with various videos scraped from online platforms. Existing datasets, such as ActivityNet, require considerable human labor for structuring and annotation before effectively utilized for tuning LVLMs. While current LVLMs are primarily trained on existing datasets in broad, general-purpose settings, adapting them to specific downstream scenarios remains challenging, as collecting and annotating task-specific videos is highly labor-intensive and time-consuming. To address this issue, we propose a three-stage framework named DreamFrame for automatically generating style-consistent keyframes and corresponding question-answer (QA) pairs to support LVLM instruction tuning. DreamFrame generates datasets in a movie-like manner. First, we utilize an LLM to generate structured movie plots including movie prior information (like overview and style), frame descriptions and plot-related QA pairs, with a story expansion strategy to mitigate context length limitations.Then, to ensure visual consistency across generated frames, we design a Style Immobilization Process which maintains consistent style through an embedding learning strategy. Finally, frame descriptions and style embeddings are integrated to produce coherent keyframes. Using DreamFrame, we construct a dataset comprising approximately 1k stylized keyframe-like videos and 100k diverse QA pairs. Extensive fine-tuned experiments on various LVLM architectures demonstrate the effectiveness of the proposed dataset. Furthermore, based on the proposed dataset, we fine-tune a new LVLM named DreamFrame-7B, which significantly surpasses the previous similar-sized LVLMs across different benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection",
    "title_es": "SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection",
    "url": "https://arxiv.org/abs/2403.06534",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2403.06534v3 Announce Type: replace \nAbstract: Synthetic Aperture Radar (SAR) object detection has gained significant attention recently due to its irreplaceable all-weather imaging capabilities. However, this research field suffers from both limited public datasets (mostly comprising <2K images with only mono-category objects) and inaccessible source code. To tackle these challenges, we establish a new benchmark dataset and an open-source method for large-scale SAR object detection. Our dataset, SARDet-100K, is a result of intense surveying, collecting, and standardizing 10 existing SAR detection datasets, providing a large-scale and diverse dataset for research purposes. To the best of our knowledge, SARDet-100K is the first COCO-level large-scale multi-class SAR object detection dataset ever created. With this high-quality dataset, we conducted comprehensive experiments and uncovered a crucial challenge in SAR object detection: the substantial disparities between the pretraining on RGB datasets and finetuning on SAR datasets in terms of both data domain and model structure. To bridge these gaps, we propose a novel Multi-Stage with Filter Augmentation (MSFA) pretraining framework that tackles the problems from the perspective of data input, domain transition, and model migration. The proposed MSFA method significantly enhances the performance of SAR object detection models while demonstrating exceptional generalizability and flexibility across diverse models. This work aims to pave the way for further advancements in SAR object detection. The dataset and code is available at https://github.com/zcablii/SARDet_100K.",
    "source": "arXiv"
  },
  {
    "title": "Liquid Resistance Liquid Capacitance Networks",
    "title_es": "Liquid Resistance Liquid Capacitance Networks",
    "url": "https://arxiv.org/abs/2403.08791",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2403.08791v4 Announce Type: replace \nAbstract: We introduce liquid-resistance liquid-capacitance neural networks (LRCs), a neural-ODE model which considerably improve the generalization, accuracy, and biological plausibility of electrical equivalent circuits (EECs), liquid time-constant networks (LTCs), and saturated liquid time-constant networks (STCs), respectively. We also introduce LRC units (LRCUs), as a very efficient and accurate gated RNN-model, which results from solving LRCs with an explicit Euler scheme using just one unfolding. We empirically show and formally prove that the liquid capacitance of LRCs considerably dampens the oscillations of LTCs and STCs, while at the same time dramatically increasing accuracy even for cheap solvers. We experimentally demonstrate that LRCs are a highly competitive alternative to popular neural ODEs and gated RNNs in terms of accuracy, efficiency, and interpretability, on classic time-series benchmarks and a complex autonomous-driving lane-keeping task.",
    "source": "arXiv"
  },
  {
    "title": "Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring",
    "title_es": "Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring",
    "url": "https://arxiv.org/abs/2403.09333",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2403.09333v2 Announce Type: replace \nAbstract: Large Vision Language Models have achieved fine-grained object perception, but the limitation of image resolution remains a significant obstacle to surpassing the performance of task-specific experts in complex and dense scenarios. Such limitation further restricts the model's potential to achieve nuanced visual and language referring in domains such as GUI Agents, counting, \\textit{etc}. To address this issue, we introduce a unified high-resolution generalist model, Griffon v2, enabling flexible object referring with visual and textual prompts. To efficiently scale up image resolution, we design a simple and lightweight down-sampling projector to overcome the input tokens constraint in Large Language Models. This design inherently preserves the complete contexts and fine details and significantly improves multimodal perception ability, especially for small objects. Building upon this, we further equip the model with visual-language co-referring capabilities through a plug-and-play visual tokenizer. It enables user-friendly interaction with flexible target images, free-form texts, and even coordinates. Experiments demonstrate that Griffon v2 can localize objects of interest with visual and textual referring, achieve state-of-the-art performance on REC and phrase grounding, and outperform expert models in object detection, object counting, and REG. Data and codes are released at https://github.com/jefferyZhan/Griffon.",
    "source": "arXiv"
  },
  {
    "title": "Spotter+GPT: Turning Sign Spottings into Sentences with LLMs",
    "title_es": "Spotter+GPT: Turning Sign Spottings into Sentences with LLMs",
    "url": "https://arxiv.org/abs/2403.10434",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2403.10434v3 Announce Type: replace \nAbstract: Sign Language Translation (SLT) is a challenging task that aims to generate spoken language sentences from sign language videos. In this paper, we introduce a lightweight, modular SLT framework, Spotter+GPT, that leverages the power of Large Language Models (LLMs) and avoids heavy end-to-end training. Spotter+GPT breaks down the SLT task into two distinct stages. First, a sign spotter identifies individual signs within the input video. The spotted signs are then passed to an LLM, which transforms them into meaningful spoken language sentences. Spotter+GPT eliminates the requirement for SLT-specific training. This significantly reduces computational costs and time requirements. The source code and pretrained weights of the Spotter are available at https://gitlab.surrey.ac.uk/cogvispublic/sign-spotter.",
    "source": "arXiv"
  },
  {
    "title": "Enabling Privacy-preserving Model Evaluation in Federated Learning via Fully Homomorphic Encryption",
    "title_es": "Enabling Privacy-preserving Model Evaluation in Federated Learning via Fully Homomorphic Encryption",
    "url": "https://arxiv.org/abs/2403.14428",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2403.14428v2 Announce Type: replace \nAbstract: Federated learning has become increasingly widespread due to its ability to train models collaboratively without centralizing sensitive data. While most research on FL emphasizes privacy-preserving techniques during training, the evaluation phase also presents significant privacy risks that have not been adequately addressed in the literature. In particular, the state-of-the-art solution for computing the area under the curve (AUC) in FL systems employs differential privacy, which not only fails to protect against a malicious aggregator but also suffers from severe performance degradation on smaller datasets.\n  To overcome these limitations, we propose a novel evaluation method that leverages fully homomorphic encryption. To the best of our knowledge, this is the first work to apply FHE to privacy-preserving model evaluation in federated learning while providing verifiable security guarantees. In our approach, clients encrypt their true-positive and false-positive counts based on predefined thresholds and submit them to an aggregator, which then performs homomorphic operations to compute the global AUC without ever seeing intermediate or final results in plaintext. We offer two variants of our protocol: one secure against a semi-honest aggregator and one that additionally detects and prevents manipulations by a malicious aggregator. Besides providing verifiable security guarantees, our solution achieves superior accuracy across datasets of any size and distribution, eliminating the performance issues faced by the existing state-of-the-art method on small datasets and its runtime is negligibly small and independent of the test-set size. Experimental results confirm that our method can compute the AUC among 100 parties in under two seconds with near-perfect (99.93%) accuracy while preserving complete data privacy.",
    "source": "arXiv"
  },
  {
    "title": "Convolution and Knapsack in Higher Dimensions",
    "title_es": "Convolution and Knapsack in Higher Dimensions",
    "url": "https://arxiv.org/abs/2403.16117",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2403.16117v2 Announce Type: replace \nAbstract: In the Knapsack problem, one is given the task of packing a knapsack of a given size with items in order to gain a packing with a high profit value. An important connection to the $(\\max,+)$-convolution problem has been established, where knapsack solutions can be combined by building the convolution of two sequences. This observation has been used in recent years to give conditional lower bounds but also parameterized algorithms.\n  In this paper we carry these results into higher dimensions. We consider Knapsack where items are characterized by multiple properties -- given through a vector -- and a knapsack that has a capacity vector. The packing must not exceed any of the given capacity constraints. In order to show a similar sub-quadratic lower bound we consider a multidimensional version of $(\\max, +)$-convolution. We then consider variants of this problem introduced by Cygan et al. and prove that they are all equivalent in terms of algorithms that allow for a running time sub-quadratic in the number of entries of the array.\n  We develop a parameterized algorithm to solve higher dimensional Knapsack. The techniques we apply are inspired by an algorithm introduced by Axiotis and Tzamos. We will show that even for higher dimensional Knapsack, we can reduce the problem to convolution on one-dimensional, concave sequences, leading to an $\\mathcal{O}(dn + dD \\cdot \\max\\{\\Pi_{i=1}^d{t_i}, t_{\\max}\\log t_{\\max}\\})$ algorithm, where $D$ is the number of different weight vectors, $t$ the capacity vector and $d$ is the dimension of the problem. Then, we use the techniques to improve the approach of Eisenbrand and Weismantel to obtain an algorithm for Integer Linear Programming with upper bounds with running time $\\mathcal{O}(dn) + D \\cdot \\mathcal{O}(d \\Delta)^{d(d+1)} + T_{\\mathrm{LP}}$.",
    "source": "arXiv"
  },
  {
    "title": "Computing a Fixed Point of Contraction Maps in Polynomial Queries",
    "title_es": "Computing a Fixed Point of Contraction Maps in Polynomial Queries",
    "url": "https://arxiv.org/abs/2403.19911",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2403.19911v2 Announce Type: replace \nAbstract: We give an algorithm for finding an $\\epsilon$-fixed point of a contraction map $f:[0,1]^k\\mapsto[0,1]^k$ under the $\\ell_\\infty$-norm with query complexity $O (k\\log (1/\\epsilon ) )$.",
    "source": "arXiv"
  },
  {
    "title": "On the Sample Efficiency of Abstractions and Potential-Based Reward Shaping in Reinforcement Learning",
    "title_es": "On the Sample Efficiency of Abstractions and Potential-Based Reward Shaping in Reinforcement Learning",
    "url": "https://arxiv.org/abs/2404.07826",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2404.07826v2 Announce Type: replace \nAbstract: The use of Potential-Based Reward Shaping (PBRS) has shown great promise in the ongoing research effort to tackle sample inefficiency in Reinforcement Learning (RL). However, choosing the right potential function remains an open challenge. Additionally, RL techniques are usually constrained to use a finite horizon for computational limitations, which introduces a bias when using PBRS. In this paper, we first build some theoretically-grounded intuition on why selecting the potential function as the optimal value function of the task at hand produces performance advantages. We then analyse the bias induced by finite horizons in the context of PBRS producing novel insights. Finally, leveraging abstractions as a way to approximate the optimal value function of the given task, we assess the sample efficiency and performance impact of PBRS on four environments including a goal-oriented navigation task and three Arcade Learning Environments (ALE) games. Remarkably, experimental results show that we can reach the same level of performance as CNN-based solutions with a simple fully-connected network.",
    "source": "arXiv"
  },
  {
    "title": "Runtime Monitoring and Enforcement of Conditional Fairness in Generative AIs",
    "title_es": "Runtime Monitoring and Enforcement of Conditional Fairness in Generative AIs",
    "url": "https://arxiv.org/abs/2404.16663",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2404.16663v5 Announce Type: replace \nAbstract: The deployment of generative AI (GenAI) models raises significant fairness concerns, addressed in this paper through novel characterization and enforcement techniques specific to GenAI. Unlike standard AI performing specific tasks, GenAI's broad functionality requires ``conditional fairness'' tailored to the context being generated, such as demographic fairness in generating images of poor people versus successful business leaders. We define two fairness levels: the first evaluates fairness in generated outputs, independent of prompts and models; the second assesses inherent fairness with neutral prompts. Given the complexity of GenAI and challenges in fairness specifications, we focus on bounding the worst case, considering a GenAI system unfair if the distance between appearances of a specific group exceeds preset thresholds. We also explore combinatorial testing for assessing relative completeness in intersectional fairness. By bounding the worst case, we develop a prompt injection scheme within an agent-based framework to enforce conditional fairness with minimal intervention, validated on state-of-the-art GenAI systems.",
    "source": "arXiv"
  },
  {
    "title": "FOBNN: Fast Oblivious Inference via Binarized Neural Networks",
    "title_es": "FOBNN: Fast Oblivious Inference via Binarized Neural Networks",
    "url": "https://arxiv.org/abs/2405.03136",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2405.03136v2 Announce Type: replace \nAbstract: The remarkable performance of deep learning has sparked the rise of Deep Learning as a Service (DLaaS), allowing clients to send their personal data to service providers for model predictions. A persistent challenge in this context is safeguarding the privacy of clients' sensitive data. Oblivious inference allows the execution of neural networks on client inputs without revealing either the inputs or the outcomes to the service providers. In this paper, we propose FOBNN, a Fast Oblivious inference framework via Binarized Neural Networks. In FOBNN, through neural network binarization, we convert linear operations (e.g., convolutional and fully-connected operations) into eXclusive NORs (XNORs) and an Oblivious Bit Count (OBC) problem. For secure multiparty computation techniques, like garbled circuits or bitwise secret sharing, XNOR operations incur no communication cost, making the OBC problem the primary bottleneck for linear operations. To tackle this, we first propose the Bit Length Bounding (BLB) algorithm, which minimizes bit representation to decrease redundant computations. Subsequently, we develop the Layer-wise Bit Accumulation (LBA) algorithm, utilizing pure bit operations layer by layer to further boost performance. We also enhance the binarized neural network structure through link optimization and structure exploration. The former optimizes link connections given a network structure, while the latter explores optimal network structures under same secure computation costs. Our theoretical analysis reveals that the BLB algorithm outperforms the state-of-the-art OBC algorithm by a range of 17% to 55%, while the LBA exhibits an improvement of nearly 100%. Comprehensive proof-of-concept evaluation demonstrates that FOBNN outperforms prior art on popular benchmarks and shows effectiveness in emerging bioinformatics.",
    "source": "arXiv"
  },
  {
    "title": "Metabook: A Mobile-to-Headset Pipeline for 3D Story Book Creation in Augmented Reality",
    "title_es": "Metabook: A Mobile-to-Headset Pipeline for 3D Story Book Creation in Augmented Reality",
    "url": "https://arxiv.org/abs/2405.13701",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2405.13701v3 Announce Type: replace \nAbstract: The AR 3D book has shown significant potential in enhancing students' learning outcomes. However, the creation process of 3D books requires a significant investment of time, effort, and specialized skills. Thus, in this paper, we first conduct a three-day workshop investigating how AI can support the automated creation of 3D books. Informed by the design insights derived from the workshop, we developed Metabook, a system that enables even novice users to create 3D books from text automatically. To our knowledge, Metabook is the first system to offer end-to-end 3D book generation. A follow-up study with adult users indicates that Metabook enables inexperienced users to create 3D books, achieving reduced efforts and shortened preparation time. We subsequently recruited 22 children to examine the effects of AR 3D books on children's learning compared with paper-based books. The findings indicate that 3D books significantly enhance children's interest, improve memory retention, and reduce cognitive load, though no significant improvement was observed in comprehension. We conclude by discussing strategies for more effectively leveraging 3D books to support children's learning and offer practical recommendations for educators.",
    "source": "arXiv"
  },
  {
    "title": "Fractured Glass, Failing Cameras: Simulating Physics-Based Adversarial Samples for Autonomous Driving Systems",
    "title_es": "Fractured Glass, Failing Cameras: Simulating Physics-Based Adversarial Samples for Autonomous Driving Systems",
    "url": "https://arxiv.org/abs/2405.15033",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2405.15033v2 Announce Type: replace \nAbstract: While much research has recently focused on generating physics-based adversarial samples, a critical yet often overlooked category originates from physical failures within on-board cameras -- components essential to the perception systems of autonomous vehicles. Firstly, we motivate the study using two separate real-world experiments to showcase that indeed glass failures would cause the detection based neural network models to fail. Secondly, we develop a simulation-based study using the physical process of the glass breakage to create perturbed scenarios, representing a realistic class of physics-based adversarial samples. Using a finite element model (FEM)-based approach, we generate surface cracks on the camera image by applying a stress field defined by particles within a triangular mesh. Lastly, we use physically-based rendering (PBR) techniques to provide realistic visualizations of these physically plausible fractures. To analyze the safety implications, we superimpose these simulated broken glass effects as image filters on widely used open-source datasets: KITTI and BDD100K using two most prominent object detection neural networks (CNN-based -- YOLOv8 and Faster R-CNN) and Pyramid Vision Transformers. To further investigate the distributional impact of these visual distortions, we compute the Kullback-Leibler (K-L) divergence between three distinct data distributions, applying various broken glass filters to a custom dataset (captured through a cracked windshield), as well as the KITTI and Kaggle cats and dogs datasets. The K-L divergence analysis suggests that these broken glass filters do not introduce significant distributional shifts.",
    "source": "arXiv"
  },
  {
    "title": "Goldilocks Test Sets for Face Verification",
    "title_es": "Goldilocks Test Sets for Face Verification",
    "url": "https://arxiv.org/abs/2405.15965",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2405.15965v2 Announce Type: replace \nAbstract: Reported face verification accuracy has reached a plateau on current well-known test sets. As a result, some difficult test sets have been assembled by reducing the image quality or adding artifacts to the image. However, we argue that test sets can be challenging without artificially reducing the image quality because the face recognition (FR) models suffer from correctly recognizing 1) the pairs from the same identity (i.e., genuine pairs) with a large face attribute difference, 2) the pairs from different identities (i.e., impostor pairs) with a small face attribute difference, and 3) the pairs of similar-looking identities (e.g., twins and relatives). We propose three challenging test sets to reveal important but ignored weaknesses of the existing FR algorithms. To challenge models on variation of facial attributes, we propose Hadrian and Eclipse to address facial hair differences and face exposure differences. The images in both test sets are high-quality and collected in a controlled environment. To challenge FR models on similar-looking persons, we propose twins-IND, which contains images from a dedicated twins dataset. The LFW test protocol is used to structure the proposed test sets. Moreover, we introduce additional rules to assemble \"Goldilocks1\" level test sets, including 1) restricted number of occurrence of hard samples, 2) equal chance evaluation across demographic groups, and 3) constrained identity overlap across validation folds. Quantitatively, without further processing the images, the proposed test sets have on-par or higher difficulties than the existing test sets. The datasets are available at: https: //github.com/HaiyuWu/SOTA-Face-Recognition-Train-and-Test.",
    "source": "arXiv"
  },
  {
    "title": "Bounds on f-Divergences between Distributions within Generalized Quasi-$\\varepsilon$-Neighborhood",
    "title_es": "Bounds on f-Divergences between Distributions within Generalized Quasi-$\\varepsilon$-Neighborhood",
    "url": "https://arxiv.org/abs/2406.00939",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.00939v2 Announce Type: replace \nAbstract: This work establishes computable bounds between f-divergences for probability measures within a generalized quasi-$\\varepsilon_{(M,m)}$-neighborhood framework. We make the following key contributions. (1) a unified characterization of local distributional proximity beyond structural constraints is provided, which encompasses discrete/continuous cases through parametric flexibility. (2) First-order differentiable $f$-divergence classification with Taylor-based inequalities is established, which generalizes $\\chi^2$-divergence results to broader function classes. (3) We provide tighter reverse Pinsker's inequalities than existing ones, bridging asymptotic analysis and computable bounds. The proposed framework demonstrates particular efficacy in goodness-of-fit test asymptotics while maintaining computational tractability.",
    "source": "arXiv"
  },
  {
    "title": "MS-IMAP -- A Multi-Scale Graph Embedding Approach for Interpretable Manifold Learning",
    "title_es": "MS-IMAP -- A Multi-Scale Graph Embedding Approach for Interpretable Manifold Learning",
    "url": "https://arxiv.org/abs/2406.02778",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.02778v5 Announce Type: replace \nAbstract: Deriving meaningful representations from complex, high-dimensional data in unsupervised settings is crucial across diverse machine learning applications. This paper introduces a framework for multi-scale graph network embedding based on spectral graph wavelets that employs a contrastive learning approach. We theoretically show that in Paley-Wiener spaces on combinatorial graphs, the spectral graph wavelets operator provides greater flexibility and control over smoothness compared to the Laplacian operator, motivating our approach. A key advantage of the proposed embedding is its ability to establish a correspondence between the embedding and input feature spaces, enabling the derivation of feature importance. We validate the effectiveness of our graph embedding framework on multiple public datasets across various downstream tasks, including clustering and unsupervised feature importance.",
    "source": "arXiv"
  },
  {
    "title": "From Spikes to Heavy Tails: Unveiling the Spectral Evolution of Neural Networks",
    "title_es": "From Spikes to Heavy Tails: Unveiling the Spectral Evolution of Neural Networks",
    "url": "https://arxiv.org/abs/2406.04657",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.04657v3 Announce Type: replace \nAbstract: Training strategies for modern deep neural networks (NNs) tend to induce a heavy-tailed (HT) empirical spectral density (ESD) in the layer weights. While previous efforts have shown that the HT phenomenon correlates with good generalization in large NNs, a theoretical explanation of its occurrence is still lacking. Especially, understanding the conditions which lead to this phenomenon can shed light on the interplay between generalization and weight spectra. Our work aims to bridge this gap by presenting a simple, rich setting to model the emergence of HT ESD. In particular, we present a theory-informed setup for 'crafting' heavy tails in the ESD of two-layer NNs and present a systematic analysis of the HT ESD emergence without any gradient noise. This is the first work to analyze a noise-free setting, and we also incorporate optimizer (GD/Adam) dependent (large) learning rates into the HT ESD analysis. Our results highlight the role of learning rates on the Bulk+Spike and HT shape of the ESDs in the early phase of training, which can facilitate generalization in the two-layer NN. These observations shed light on the behavior of large-scale NNs, albeit in a much simpler setting.",
    "source": "arXiv"
  },
  {
    "title": "LVBench: An Extreme Long Video Understanding Benchmark",
    "title_es": "LVBench: An Extreme Long Video Understanding Benchmark",
    "url": "https://arxiv.org/abs/2406.08035",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.08035v3 Announce Type: replace \nAbstract: Recent progress in multimodal large language models has markedly enhanced the understanding of short videos (typically under one minute), and several evaluation datasets have emerged accordingly. However, these advancements fall short of meeting the demands of real-world applications such as embodied intelligence for long-term decision-making, in-depth movie reviews and discussions, and live sports commentary, all of which require comprehension of long videos spanning several hours. To address this gap, we introduce LVBench, a benchmark specifically designed for long video understanding. Our dataset comprises publicly sourced videos and encompasses a diverse set of tasks aimed at long video comprehension and information extraction. LVBench is designed to challenge multimodal models to demonstrate long-term memory and extended comprehension capabilities. Our extensive evaluations reveal that current multimodal models still underperform on these demanding long video understanding tasks. Through LVBench, we aim to spur the development of more advanced models capable of tackling the complexities of long video comprehension. Our data and code are publicly available at: https://lvbench.github.io.",
    "source": "arXiv"
  },
  {
    "title": "InfiniBench: A Benchmark for Large Multi-Modal Models in Long-Form Movies and TV Shows",
    "title_es": "InfiniBench: A Benchmark for Large Multi-Modal Models in Long-Form Movies and TV Shows",
    "url": "https://arxiv.org/abs/2406.19875",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.19875v3 Announce Type: replace \nAbstract: Understanding long-form videos, such as movies and TV episodes ranging from tens of minutes to two hours, remains a significant challenge for multi-modal models. Existing benchmarks often fail to test the full range of cognitive skills needed to process these temporally rich and narratively complex inputs. Therefore, we introduce InfiniBench, a comprehensive benchmark designed to evaluate the capabilities of models in long video understanding rigorously. InfiniBench offers:(1) Over 1,000 hours of video content, with an average video length of 53 minutes. (2) The largest set of question-answer pairs for long video comprehension, totaling around 91 K. (3) Eight diverse skills that span both grounding-based (e.g., scene transitions, character actions) and reasoning-based (e.g., deep context understanding, multi-event linking). (4) Rich annotation formats, including both multiple-choice and open-ended questions. We conducted an in-depth evaluation across both commercial (GPT-4o, Gemini 2.0 Flash) and most recent open-source vision-language models such as Qwen2.5-VL, InternVL3.0). Results reveal that:(1) Models struggle across the board: Even the best model, GPT-4o, achieves only 47.1 % on grounding-based skills, with most models performing near or just above random chance. (2) Strong reliance on world knowledge: Models achieve surprisingly high scores using only metadata (e.g., video titles), highlighting a tendency to rely on pre-trained knowledge rather than actual visual or temporal understanding. (3) Multi-Modal Importance: When provided with full video and subtitle context, however, models show substantial improvements, confirming the critical role of multimodal input in video understanding. InfiniBench is publicly available at https://vision-cair.github.io/Infinibench",
    "source": "arXiv"
  },
  {
    "title": "Capacity Bounds for Broadcast Channels with Bidirectional Conferencing Decoders",
    "title_es": "Capacity Bounds for Broadcast Channels with Bidirectional Conferencing Decoders",
    "url": "https://arxiv.org/abs/2406.20019",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.20019v4 Announce Type: replace \nAbstract: The two-user broadcast channel (BC) with receivers connected by bidirectional cooperation links of finite capacities, known as conferencing decoders, is considered. A novel capacity region outer bound is established based on multiple applications of the Csisz\\'{a}r-K\\\"{o}rner identity. Achievable rate regions are derived by using Marton's coding as the transmission scheme, together with different combinations of decode-and-forward and quantize-bin-and-forward strategies at the receivers. It is shown that the outer bound coincides with the achievable rate region for a new class of semi-deterministic BCs with degraded message sets; for this class of channels, one-round cooperation is sufficient to achieve the capacity. Capacity result is also derived for a class of more capable semi-deterministic BCs with both common and private messages and one-sided conferencing. For the Gaussian BC with conferencing decoders, if the noises at the decoders are perfectly correlated (i.e., correlation is either 1 or -1), the new outer bound yields exact capacity region for two cases: i) BC with degraded message sets; ii) BC with one-sided conferencing from the weaker receiver to the stronger receiver. When the noises have arbitrary correlation, the outer bound is shown to be within half a bit from the capacity region for these same two cases. Finally, for the general Gaussian BC, a one-sided cooperation scheme based on decode-and-forward from the stronger receiver to the weaker receiver is shown to achieve the capacity region to within $\\frac{1}{2}\\log (\\frac{2}{1-|\\lambda|})$ bits, where $\\lambda$ is the noise correlation. An interesting implication of these results is that for a Gaussian BC with perfectly negatively correlated noises and conferencing decoders with finite cooperation link capacities, it is possible to achieve a strictly positive rate using only an infinitesimal amount of transmit power.",
    "source": "arXiv"
  },
  {
    "title": "Understanding the Prevalence of Caste: A Critical Discourse Analysis of Caste-based Marginalization on X",
    "title_es": "Understanding the Prevalence of Caste: A Critical Discourse Analysis of Caste-based Marginalization on X",
    "url": "https://arxiv.org/abs/2407.02810",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.02810v3 Announce Type: replace \nAbstract: Despite decades of anti-caste efforts, sociocultural practices that marginalize lower-caste groups in India remain prevalent and have even proliferated with the use of social media. This paper examines how groups engaged in caste-based discrimination leverage platform affordances of the social media site X (formerly Twitter) to circulate and reinforce caste ideologies. Using a critical discourse analysis (CDA) approach, we examine the rhetorical and organizing strategies of 50 X profiles representing upper-caste collectives. We find that these profiles leverage platform affordances such as information control, bandwidth, visibility, searchability, and shareability to construct two main arguments: (1) that their upper caste culture deserves a superior status and (2) that they are the \"true\" victims of oppression in society. These profiles' digitally mediated discursive strategies contribute to the marginalization of lower castes by normalizing caste cultures, strengthening caste networks, reinforcing caste discrimination, and diminishing anti-caste measures. Our analysis builds upon previous HCI conceptualizations of online harms and safety to inform how to address caste-based marginalization. We offer theoretical and methodological suggestions for critical HCI research focused on studying the mechanisms of power along other social categories such as race and gender.",
    "source": "arXiv"
  },
  {
    "title": "How Chinese are Chinese Language Models? The Puzzling Lack of Language Policy in China's LLMs",
    "title_es": "How Chinese are Chinese Language Models? The Puzzling Lack of Language Policy in China's LLMs",
    "url": "https://arxiv.org/abs/2407.09652",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.09652v2 Announce Type: replace \nAbstract: Contemporary language models are increasingly multilingual, but Chinese LLM developers must navigate complex political and business considerations of language diversity. Language policy in China aims at influencing the public discourse and governing a multi-ethnic society, and has gradually transitioned from a pluralist to a more assimilationist approach since 1949. We explore the impact of these influences on current language technology. We evaluate six open-source multilingual LLMs pre-trained by Chinese companies on 18 languages, spanning a wide range of Chinese, Asian, and Anglo-European languages. Our experiments show Chinese LLMs performance on diverse languages is indistinguishable from international LLMs. Similarly, the models' technical reports also show lack of consideration for pretraining data language coverage except for English and Mandarin Chinese. Examining Chinese AI policy, model experiments, and technical reports, we find no sign of any consistent policy, either for or against, language diversity in China's LLM development. This leaves a puzzling fact that while China regulates both the languages people use daily as well as language model development, they do not seem to have any policy on the languages in language models.",
    "source": "arXiv"
  },
  {
    "title": "Learning Multi-view Anomaly Detection with Efficient Adaptive Selection",
    "title_es": "Learning Multi-view Anomaly Detection with Efficient Adaptive Selection",
    "url": "https://arxiv.org/abs/2407.11935",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.11935v2 Announce Type: replace \nAbstract: This study explores the recently proposed and challenging multi-view Anomaly Detection (AD) task. Single-view tasks will encounter blind spots from other perspectives, resulting in inaccuracies in sample-level prediction. Therefore, we introduce the Multi-View Anomaly Detection (MVAD) approach, which learns and integrates features from multi-views. Specifically, we propose a Multi-View Adaptive Selection (MVAS) algorithm for feature learning and fusion across multiple views. The feature maps are divided into neighbourhood attention windows to calculate a semantic correlation matrix between single-view windows and all other views, which is an attention mechanism conducted for each single-view window and the top-k most correlated multi-view windows. Adjusting the window sizes and top-k can minimise the complexity to O((hw)^4/3). Extensive experiments on the Real-IAD dataset under the multi-class setting validate the effectiveness of our approach, achieving state-of-the-art performance with an average improvement of +2.5 across 10 metrics at the sample/image/pixel levels, using only 18M parameters and requiring fewer FLOPs and training time. The codes are available at https://github.com/lewandofskee/MVAD.",
    "source": "arXiv"
  },
  {
    "title": "AI-AI Bias: large language models favor communications generated by large language models",
    "title_es": "AI-AI Bias: large language models favor communications generated by large language models",
    "url": "https://arxiv.org/abs/2407.12856",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.12856v2 Announce Type: replace \nAbstract: Are large language models (LLMs) biased in favor of communications produced by LLMs, leading to possible antihuman discrimination? Using a classical experimental design inspired by employment discrimination studies, we tested widely used LLMs, including GPT-3.5, GPT-4 and a selection of recent open-weight models in binary choice scenarios. These involved LLM-based assistants selecting between goods (the goods we study include consumer products, academic papers, and film-viewings) described either by humans or LLMs. Our results show a consistent tendency for LLM-based AIs to prefer LLM-presented options. This suggests the possibility of future AI systems implicitly discriminating against humans as a class, giving AI agents and AI-assisted humans an unfair advantage.",
    "source": "arXiv"
  },
  {
    "title": "Scikit-fingerprints: easy and efficient computation of molecular fingerprints in Python",
    "title_es": "Scikit-fingerprints: easy and efficient computation of molecular fingerprints in Python",
    "url": "https://arxiv.org/abs/2407.13291",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.13291v5 Announce Type: replace \nAbstract: In this work, we present scikit-fingerprints, a Python package for computation of molecular fingerprints for applications in chemoinformatics. Our library offers an industry-standard scikit-learn interface, allowing intuitive usage and easy integration with machine learning pipelines. It is also highly optimized, featuring parallel computation that enables efficient processing of large molecular datasets. Currently, scikit-fingerprints stands as the most feature-rich library in the open source Python ecosystem, offering over 30 molecular fingerprints. Our library simplifies chemoinformatics tasks based on molecular fingerprints, including molecular property prediction and virtual screening. It is also flexible, highly efficient, and fully open source.",
    "source": "arXiv"
  },
  {
    "title": "Sortability of Time Series Data",
    "title_es": "Sortability of Time Series Data",
    "url": "https://arxiv.org/abs/2407.13313",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.13313v3 Announce Type: replace \nAbstract: Evaluating the performance of causal discovery algorithms that aim to find causal relationships between time-dependent processes remains a challenging topic. In this paper, we show that certain characteristics of datasets, such as varsortability (Reisach et al. 2021) and $R^2$-sortability (Reisach et al. 2023), also occur in datasets for autocorrelated stationary time series. We illustrate this empirically using four types of data: simulated data based on SVAR models and Erd\\H{o}s-R\\'enyi graphs, the data used in the 2019 causality-for-climate challenge (Runge et al. 2019), real-world river stream datasets, and real-world data generated by the Causal Chamber of (Gamella et al. 2024). To do this, we adapt var- and $R^2$-sortability to time series data. We also investigate the extent to which the performance of score-based causal discovery methods goes hand in hand with high sortability. Arguably, our most surprising finding is that the investigated real-world datasets exhibit high varsortability and low $R^2$-sortability indicating that scales may carry a significant amount of causal information.",
    "source": "arXiv"
  },
  {
    "title": "Optimizing Design and Control Methods for Using Collaborative Robots in Upper-Limb Rehabilitation",
    "title_es": "Optimizing Design and Control Methods for Using Collaborative Robots in Upper-Limb Rehabilitation",
    "url": "https://arxiv.org/abs/2407.18661",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.18661v3 Announce Type: replace \nAbstract: In this paper, we address the development of a robotic rehabilitation system for the upper limbs based on collaborative end-effector solutions. The use of commercial collaborative robots offers significant advantages for this task, as they are optimized from an engineering perspective and ensure safe physical interaction with humans. However, they also come with noticeable drawbacks, such as the limited range of sizes available on the market and the standard control modes, which are primarily oriented towards industrial or service applications. To address these limitations, we propose an optimization-based design method to fully exploit the capability of the cobot in performing rehabilitation tasks. Additionally, we introduce a novel control architecture based on an admittance-type Virtual Fixture method, which constrains the motion of the robot along a prescribed path. This approach allows for an intuitive definition of the task to be performed via Programming by Demonstration and enables the system to operate both passively and actively. In passive mode, the system supports the patient during task execution with additional force, while in active mode, it opposes the motion with a braking force. Experimental results demonstrate the effectiveness of the proposed method.",
    "source": "arXiv"
  },
  {
    "title": "SynthVLM: Towards High-Quality and Efficient Synthesis of Image-Caption Datasets for Vision-Language Models",
    "title_es": "SynthVLM: Towards High-Quality and Efficient Synthesis of Image-Caption Datasets for Vision-Language Models",
    "url": "https://arxiv.org/abs/2407.20756",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.20756v5 Announce Type: replace \nAbstract: Vision-Language Models (VLMs) have recently emerged, demonstrating remarkable vision-understanding capabilities. However, training these models requires large-scale datasets, which brings challenges related to efficiency, effectiveness, and quality of web data. In this paper, we introduce SynthVLM, a new data synthesis and curation method for generating image-caption pairs. Unlike traditional methods, where captions are generated from images, SynthVLM utilizes advanced diffusion models and high-quality captions to synthesize and select images from text captions, thereby creating precisely aligned image-text pairs. We further introduce SynthVLM-100K, a high-quality dataset consisting of 100K curated and synthesized image-caption pairs. In both model and human evaluations, SynthVLM-100K outperforms traditional real-world datasets. Leveraging this dataset, we develop a new family of multimodal large language models (MLLMs), SynthVLM-7B and SynthVLM-13B, which achieve state-of-the-art (SOTA) performance on various vision question-answering (VQA) tasks. Notably, our models outperform LLaVA across most metrics with only 18\\% pretrain data. Furthermore, SynthVLM-7B and SynthVLM-13B attain SOTA performance on the MMLU benchmark, demonstrating that the high-quality SynthVLM-100K dataset preserves language abilities.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning",
    "title_es": "A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning",
    "url": "https://arxiv.org/abs/2408.07057",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.07057v2 Announce Type: replace \nAbstract: The availability of performant pre-trained models has led to a proliferation of fine-tuned expert models that are specialized to a particular domain or task. Model MoErging methods aim to recycle expert models to create an aggregate system with improved performance or generalization. A key component of MoErging methods is the creation of a router that decides which expert model(s) to use for a particular input or application. The promise, effectiveness, and large design space of MoErging has spurred the development of many new methods over the past few years. This rapid pace of development has made it challenging to compare different MoErging methods, which are rarely compared to one another and are often validated in different experimental setups. To remedy such gaps, we present a comprehensive survey of MoErging methods that includes a novel taxonomy for cataloging key design choices and clarifying suitable applications for each method. Apart from surveying MoErging research, we inventory software tools and applications that make use of MoErging. We additionally discuss related fields of study such as model merging, multitask learning, and mixture-of-experts models. Taken as a whole, our survey provides a unified overview of existing MoErging methods and creates a solid foundation for future work in this burgeoning field.",
    "source": "arXiv"
  },
  {
    "title": "MathScape: Benchmarking Multimodal Large Language Models in Real-World Mathematical Contexts",
    "title_es": "MathScape: Benchmarking Multimodal Large Language Models in Real-World Mathematical Contexts",
    "url": "https://arxiv.org/abs/2408.07543",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.07543v5 Announce Type: replace \nAbstract: With the rapid progress of Multimodal LLMs, evaluating their mathematical reasoning capabilities has become an increasingly important research direction. In particular, visual-textual mathematical reasoning serves as a key indicator of an MLLM's ability to comprehend and solve complex, multi-step quantitative problems. While existing benchmarks such as MathVista and MathVerse have advanced the evaluation of multimodal math proficiency, they primarily rely on digitally rendered content and fall short in capturing the complexity of real-world scenarios. To bridge this gap, we introduce MathScape, a novel benchmark focused on assessing MLLMs' reasoning ability in realistic mathematical contexts. MathScape comprises 1,369 high-quality math problems paired with human-captured real-world images, closely reflecting the challenges encountered in practical educational settings. We conduct a thorough multi-dimensional evaluation across nine leading closed-source MLLMs, three open-source MLLMs with over 20 billion parameters, and seven smaller-scale MLLMs. Our results show that even SOTA models struggle with real-world math tasks, lagging behind human performance -- highlighting critical limitations in current model capabilities. Moreover, we find that strong performance on synthetic or digitally rendered images does not guarantee similar effectiveness on real-world tasks. This underscores the necessity of MathScape in the next stage of multimodal mathematical reasoning.",
    "source": "arXiv"
  },
  {
    "title": "FancyVideo: Towards Dynamic and Consistent Video Generation via Cross-frame Textual Guidance",
    "title_es": "FancyVideo: Towards Dynamic and Consistent Video Generation via Cross-frame Textual Guidance",
    "url": "https://arxiv.org/abs/2408.08189",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.08189v3 Announce Type: replace \nAbstract: Synthesizing motion-rich and temporally consistent videos remains a challenge in artificial intelligence, especially when dealing with extended durations. Existing text-to-video (T2V) models commonly employ spatial cross-attention for text control, equivalently guiding different frame generations without frame-specific textual guidance. Thus, the model's capacity to comprehend the temporal logic conveyed in prompts and generate videos with coherent motion is restricted. To tackle this limitation, we introduce FancyVideo, an innovative video generator that improves the existing text-control mechanism with the well-designed Cross-frame Textual Guidance Module (CTGM). Specifically, CTGM incorporates the Temporal Information Injector (TII) and Temporal Affinity Refiner (TAR) at the beginning and end of cross-attention, respectively, to achieve frame-specific textual guidance. Firstly, TII injects frame-specific information from latent features into text conditions, thereby obtaining cross-frame textual conditions. Then, TAR refines the correlation matrix between cross-frame textual conditions and latent features along the time dimension. Extensive experiments comprising both quantitative and qualitative evaluations demonstrate the effectiveness of FancyVideo. Our approach achieves state-of-the-art T2V generation results on the EvalCrafter benchmark and facilitates the synthesis of dynamic and consistent videos. Note that the T2V process of FancyVideo essentially involves a text-to-image step followed by T+I2V. This means it also supports the generation of videos from user images, i.e., the image-to-video (I2V) task. A significant number of experiments have shown that its performance is also outstanding.",
    "source": "arXiv"
  },
  {
    "title": "Chain of Thought Still Thinks Fast: APriCoT Helps with Thinking Slow",
    "title_es": "Chain of Thought Still Thinks Fast: APriCoT Helps with Thinking Slow",
    "url": "https://arxiv.org/abs/2408.08651",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.08651v3 Announce Type: replace \nAbstract: Language models are known to absorb biases from their training data, leading to predictions driven by statistical regularities rather than semantic relevance. We investigate the impact of these biases on answer choice preferences in the Massive Multi-Task Language Understanding (MMLU) task. Our findings show that these biases are predictive of model preference and mirror human test-taking strategies even when chain of thought (CoT) reasoning is used. To address this issue, we introduce Counterfactual Prompting with Agnostically Primed CoT (APriCoT). We demonstrate that while Counterfactual Prompting with CoT alone is insufficient to mitigate bias, APriCoT effectively reduces the influence of base-rate probabilities while improving overall accuracy. Our results suggest that mitigating bias requires a slow thinking process which CoT alone may not provide as it tends to reinforce fast thinking model bias under some prompting methodologies. APriCoT is a step toward developing more robust and fair language models that can think slow.",
    "source": "arXiv"
  },
  {
    "title": "Deep Code Search with Naming-Agnostic Contrastive Multi-View Learning",
    "title_es": "Deep Code Search with Naming-Agnostic Contrastive Multi-View Learning",
    "url": "https://arxiv.org/abs/2408.09345",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.09345v2 Announce Type: replace \nAbstract: Software development is a repetitive task, as developers usually reuse or get inspiration from existing implementations. Code search, which refers to the retrieval of relevant code snippets from a codebase according to the developer's intent that has been expressed as a query, has become increasingly important in the software development process. Due to the success of deep learning in various applications, a great number of deep learning based code search approaches have sprung up and achieved promising results. However, developers may not follow the same naming conventions and the same variable may have different variable names in different implementations, bringing a challenge to deep learning based code search methods that rely on explicit variable correspondences to understand source code. To overcome this challenge, we propose a naming-agnostic code search method (NACS) based on contrastive multi-view code representation learning. NACS strips information bound to variable names from Abstract Syntax Tree (AST), the representation of the abstract syntactic structure of source code, and focuses on capturing intrinsic properties solely from AST structures. We use semantic-level and syntax-level augmentation techniques to prepare realistically rational data and adopt contrastive learning to design a graph-view modeling component in NACS to enhance the understanding of code snippets. We further model ASTs in a path view to strengthen the graph-view modeling component through multi-view learning. Extensive experiments show that NACS provides superior code search performance compared to baselines and NACS can be adapted to help existing code search methods overcome the impact of different naming conventions. Our implementation is available at https://github.com/KDEGroup/NACS.",
    "source": "arXiv"
  },
  {
    "title": "Alignment-free Raw Video Demoireing",
    "title_es": "Alignment-free Raw Video Demoireing",
    "url": "https://arxiv.org/abs/2408.10679",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.10679v3 Announce Type: replace \nAbstract: Video demoireing aims to remove undesirable interference patterns that arise during the capture of screen content, restoring artifact-free frames while maintaining temporal consistency. Existing video demoireing methods typically utilize carefully designed alignment modules to estimate inter-frame motion for leveraging temporal information; however, these modules are often complex and computationally demanding. Meanwhile, recent works indicate that using raw data as input significantly enhances demoireing performance. Building on this insight, this paper introduces a novel alignment-free raw video demoireing network with frequency-assisted spatio-temporal Mamba (DemMamba). It incorporates sequentially arranged Spatial Mamba Blocks (SMB) and Temporal Mamba Blocks (TMB) to effectively model the inter- and intra-relationships in raw video demoireing. The SMB employs a multi-directional scanning mechanism coupled with a learnable frequency compressor to effectively differentiate interference patterns across various orientations and frequencies, resulting in reduced artifacts, sharper edges, and faithful texture reconstruction. Concurrently, the TMB enhances temporal consistency by performing bidirectional scanning across the temporal sequences and integrating channel attention techniques, facilitating improved temporal information fusion. Extensive experiments demonstrate that DemMamba surpasses state-of-the-art methods by 1.6 dB in PSNR, and also delivers a satisfactory visual experience.",
    "source": "arXiv"
  },
  {
    "title": "Prompt-Softbox-Prompt: A Free-Text Embedding Control for Image Editing",
    "title_es": "Prompt-Softbox-Prompt: A Free-Text Embedding Control for Image Editing",
    "url": "https://arxiv.org/abs/2408.13623",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.13623v3 Announce Type: replace \nAbstract: While text-driven diffusion models demonstrate remarkable performance in image editing, the critical components of their text embeddings remain underexplored. The ambiguity and entanglement of these embeddings pose challenges for precise editing. In this paper, we provide a comprehensive analysis of text embeddings in Stable Diffusion XL, offering three key insights: (1) \\textit{aug embedding}~\\footnote{\\textit{aug embedding} is obtained by combining the pooled output of the final text encoder with the timestep embeddings. https://github.com/huggingface/diffusers} retains complete textual semantics but contributes minimally to image generation as it is only fused via the ResBlocks. More text information weakens its local semantics while preserving most global semantics. (2) \\textit{BOS} and \\textit{padding embedding} do not contain any semantic information. (3) \\textit{EOS} holds the semantic information of all words and stylistic information. Each word embedding is important and does not interfere with the semantic injection of other embeddings. Based on these insights, we propose PSP (\\textbf{P}rompt-\\textbf{S}oftbox-\\textbf{P}rompt), a training-free image editing method that leverages free-text embedding. PSP enables precise image editing by modifying text embeddings within the cross-attention layers and using Softbox to control the specific area for semantic injection. This technique enables the addition and replacement of objects without affecting other areas of the image. Additionally, PSP can achieve style transfer by simply replacing text embeddings. Extensive experiments show that PSP performs remarkably well in tasks such as object replacement, object addition, and style transfer. Our code is available at https://github.com/yangyt46/PSP.",
    "source": "arXiv"
  },
  {
    "title": "Intents, Techniques, and Components: a Unified Analysis of Interaction Authoring Tasks in Data Visualization",
    "title_es": "Intents, Techniques, and Components: a Unified Analysis of Interaction Authoring Tasks in Data Visualization",
    "url": "https://arxiv.org/abs/2409.01399",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.01399v2 Announce Type: replace \nAbstract: There is a growing interest in designing tools to support interactivity specification and authoring in data visualization. To develop expressive and flexible tools, we need theories and models that describe the task space of interaction authoring. Although multiple taxonomies and frameworks exist for interactive visualization, they primarily focus on how visualizations are used, not how interactivity is composed. To fill this gap, we conduct an analysis of 592 interaction units from 47 real-world visualization applications. Based on the analysis, we present a unified analysis of interaction authoring tasks across three levels of description: intents, representative techniques, and low-level implementation components. We examine our framework's descriptive, evaluative, and generative powers for critiquing existing interactivity authoring tools and informing new tool development.",
    "source": "arXiv"
  },
  {
    "title": "Augmented Reality Assistive Technologies for Disabled Individuals",
    "title_es": "Augmented Reality Assistive Technologies for Disabled Individuals",
    "url": "https://arxiv.org/abs/2409.02053",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.02053v3 Announce Type: replace \nAbstract: Augmented Reality (AR) technologies hold immense potential for revolutionizing the way individuals with disabilities interact with the world. AR systems can provide real-time assistance and support by overlaying digital information over the physical environment based on the requirements of the use, hence addressing different types of disabilities. Through an in-depth analysis of four case studies, this paper aims to provide a comprehensive overview of the current-state-of-the-art in AR assistive technologies for individuals with disabilities, highlighting their potential to assist and transform their lives. The findings show the significance that AR has made to bridge the accessibility gap, while also discussing the challenges faced and ethical considerations associated with the implementation across the various cases. This is done through theory analysis, practical examples, and future projections that will motivate and seek to inspire further innovation in this very relevant area of exploration.",
    "source": "arXiv"
  },
  {
    "title": "How Fair is Your Diffusion Recommender Model?",
    "title_es": "How Fair is Your Diffusion Recommender Model?",
    "url": "https://arxiv.org/abs/2409.04339",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.04339v2 Announce Type: replace \nAbstract: Diffusion-based learning has settled as a rising paradigm in generative recommendation, outperforming traditional approaches built upon variational autoencoders and generative adversarial networks. Despite their effectiveness, concerns have been raised that diffusion models - widely adopted in other machine-learning domains - could potentially lead to unfair outcomes, since they are trained to recover data distributions that often encode inherent biases. Motivated by the related literature, and acknowledging the extensive discussion around bias and fairness aspects in recommendation, we propose, to the best of our knowledge, the first empirical study of fairness for DiffRec, chronologically the pioneer technique in diffusion-based recommendation. Our empirical study involves DiffRec and its variant L-DiffRec, tested against nine recommender systems on two benchmarking datasets to assess recommendation utility and fairness from both consumer and provider perspectives. Specifically, we first evaluate the utility and fairness dimensions separately and, then, within a multi-criteria setting to investigate whether, and to what extent, these approaches can achieve a trade-off between the two. While showing worrying trends in alignment with the more general machine-learning literature on diffusion models, our results also indicate promising directions to address the unfairness issue in future work. The source code is available at https://github.com/danielemalitesta/FairDiffRec.",
    "source": "arXiv"
  },
  {
    "title": "Barrier Integral Control for Global Asymptotic Stabilization of Uncertain Nonlinear Systems under Smooth Feedback and Transient Constraints",
    "title_es": "Barrier Integral Control for Global Asymptotic Stabilization of Uncertain Nonlinear Systems under Smooth Feedback and Transient Constraints",
    "url": "https://arxiv.org/abs/2409.04767",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.04767v2 Announce Type: replace \nAbstract: This paper addresses the problem of asymptotic stabilization for high-order control-affine MIMO nonlinear systems with unknown dynamic terms. We introduce Barrier Integral Control, a novel algorithm designed to confine the system's state within a predefined funnel, ensuring adherence to prescribed transient constraints, and asymptotically drive it to zero from any initial condition. The algorithm leverages the innovative integration of a reciprocal barrier function and an error-integral term, featuring smooth feedback control. Notably, it operates without relying on any information or approximation schemes for the (unknown) dynamic terms, which, unlike a large class of previous works, are not assumed to be bounded or to comply with globally Lipschitz/growth conditions. Additionally, the system's trajectory and asymptotic performance are decoupled from the uncertain model, control-gain selection, and initial conditions. Finally, comparative simulation studies validate the effectiveness of the proposed algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Reward-Directed Score-Based Diffusion Models via q-Learning",
    "title_es": "Reward-Directed Score-Based Diffusion Models via q-Learning",
    "url": "https://arxiv.org/abs/2409.04832",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.04832v2 Announce Type: replace \nAbstract: We propose a new reinforcement learning (RL) formulation for training continuous-time score-based diffusion models for generative AI to generate samples that maximize reward functions while keeping the generated distributions close to the unknown target data distributions. Different from most existing studies, ours does not involve any pretrained model for the unknown score functions of the noise-perturbed data distributions, nor does it attempt to learn the score functions. Instead, we formulate the problem as entropy-regularized continuous-time RL and show that the optimal stochastic policy has a Gaussian distribution with a known covariance matrix. Based on this result, we parameterize the mean of Gaussian policies and develop an actor--critic type (little) q-learning algorithm to solve the RL problem. A key ingredient in our algorithm design is to obtain noisy observations from the unknown score function via a ratio estimator. Our formulation can also be adapted to solve pure score-matching and fine-tuning pretrained models. Numerically, we show the effectiveness of our approach by comparing its performance with two state-of-the-art RL methods that fine-tune pretrained models on several generative tasks including high-dimensional image generations. Finally, we discuss extensions of our RL formulation to probability flow ODE implementation of diffusion models and to conditional diffusion models.",
    "source": "arXiv"
  },
  {
    "title": "A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio",
    "title_es": "A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio",
    "url": "https://arxiv.org/abs/2409.06624",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.06624v3 Announce Type: replace \nAbstract: Large Language Models (LLM) often need to be Continual Pre-Trained (CPT) to obtain unfamiliar language skills or adapt to new domains. The huge training cost of CPT often asks for cautious choice of key hyper-parameters such as the mixture ratio of extra language or domain corpus. However, there is no systematic study that bridges the gap between the optimal mixture ratio and the actual model performance, and the gap between experimental scaling law and the actual deployment in the full model size. In this paper, we perform CPT on Llama-3 8B and 70B to enhance its Chinese ability. We study the optimal correlation between the Additional Language Mixture Ratio (ALMR) and the Learning Rate (LR) on the 8B size which directly indicates the optimal experimental setup. By thorough choice of hyper-parameter, and subsequent fine-tuning, the model capability is improved not only on the Chinese-related benchmark but also in some specific domains including math, coding, and emotional intelligence. We deploy the final 70B version of LLM on a real-life chat system which obtains satisfying performance.",
    "source": "arXiv"
  },
  {
    "title": "In-Situ Fine-Tuning of Wildlife Models in IoT-Enabled Camera Traps for Efficient Adaptation",
    "title_es": "In-Situ Fine-Tuning of Wildlife Models in IoT-Enabled Camera Traps for Efficient Adaptation",
    "url": "https://arxiv.org/abs/2409.07796",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.07796v3 Announce Type: replace \nAbstract: Resource-constrained IoT devices increasingly rely on deep learning models, however, these models experience significant accuracy drops due to domain shifts when encountering variations in lighting, weather, and seasonal conditions. While cloud-based retraining can address this issue, many IoT deployments operate with limited connectivity and energy constraints, making traditional fine-tuning approaches impractical. We explore this challenge through the lens of wildlife ecology, where camera traps must maintain accurate species classification across changing seasons, weather, and habitats without reliable connectivity. We introduce WildFit, an autonomous in-situ adaptation framework that leverages the key insight that background scenes change more frequently than the visual characteristics of monitored species. WildFit combines background-aware synthesis to generate training samples on-device with drift-aware fine-tuning that triggers model updates only when necessary to conserve resources. Our background-aware synthesis surpasses efficient baselines by 7.3\\% and diffusion models by 3.0\\% while being orders of magnitude faster, our drift-aware fine-tuning achieves Pareto optimality with 50\\% fewer updates and 1.5\\% higher accuracy, and the end-to-end system outperforms domain adaptation approaches by 20--35%\\% while consuming only 11.2 Wh over 37 days -- enabling battery-powered deployment.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Layer Detection of Thin Materials using DenseTact Optical Tactile Sensors",
    "title_es": "Dynamic Layer Detection of Thin Materials using DenseTact Optical Tactile Sensors",
    "url": "https://arxiv.org/abs/2409.09849",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.09849v3 Announce Type: replace \nAbstract: Manipulation of thin materials is critical for many everyday tasks and remains a significant challenge for robots. While existing research has made strides in tasks like material smoothing and folding, many studies struggle with common failure modes (crumpled corners/edges, incorrect grasp configurations) that a preliminary step of layer detection could solve. We present a novel method for classifying the number of grasped material layers using a custom gripper equipped with DenseTact 2.0 optical tactile sensors. After grasping, the gripper performs an anthropomorphic rubbing motion while collecting optical flow, 6-axis wrench, and joint state data. Using this data in a transformer-based network achieves a test accuracy of 98.21\\% in classifying the number of grasped cloth layers, and 81.25\\% accuracy in classifying layers of grasped paper, showing the effectiveness of our dynamic rubbing method. Evaluating different inputs and model architectures highlights the usefulness of tactile sensor information and a transformer model for this task. A comprehensive dataset of 568 labeled trials (368 for cloth and 200 for paper) was collected and made open-source along with this paper. Our project page is available at https://armlabstanford.github.io/dynamic-cloth-detection.",
    "source": "arXiv"
  },
  {
    "title": "Ethical Challenges in Computer Vision: Ensuring Privacy and Mitigating Bias in Publicly Available Datasets",
    "title_es": "Ethical Challenges in Computer Vision: Ensuring Privacy and Mitigating Bias in Publicly Available Datasets",
    "url": "https://arxiv.org/abs/2409.10533",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.10533v4 Announce Type: replace \nAbstract: This paper aims to shed light on the ethical problems of creating and deploying computer vision tech, particularly in using publicly available datasets. Due to the rapid growth of machine learning and artificial intelligence, computer vision has become a vital tool in many industries, including medical care, security systems, and trade. However, extensive use of visual data that is often collected without consent due to an informed discussion of its ramifications raises significant concerns about privacy and bias. The paper also examines these issues by analyzing popular datasets such as COCO, LFW, ImageNet, CelebA, PASCAL VOC, etc., that are usually used for training computer vision models. We offer a comprehensive ethical framework that addresses these challenges regarding the protection of individual rights, minimization of bias as well as openness and responsibility. We aim to encourage AI development that will take into account societal values as well as ethical standards to avoid any public harm.",
    "source": "arXiv"
  },
  {
    "title": "PainDiffusion: Learning to Express Pain",
    "title_es": "PainDiffusion: Learning to Express Pain",
    "url": "https://arxiv.org/abs/2409.11635",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.11635v3 Announce Type: replace \nAbstract: Accurate pain expression synthesis is essential for improving clinical training and human-robot interaction. Current Robotic Patient Simulators (RPSs) lack realistic pain facial expressions, limiting their effectiveness in medical training. In this work, we introduce PainDiffusion, a generative model that synthesizes naturalistic facial pain expressions. Unlike traditional heuristic or autoregressive methods, PainDiffusion operates in a continuous latent space, ensuring smoother and more natural facial motion while supporting indefinite-length generation via diffusion forcing. Our approach incorporates intrinsic characteristics such as pain expressiveness and emotion, allowing for personalized and controllable pain expression synthesis. We train and evaluate our model using the BioVid HeatPain Database. Additionally, we integrate PainDiffusion into a robotic system to assess its applicability in real-time rehabilitation exercises. Qualitative studies with clinicians reveal that PainDiffusion produces realistic pain expressions, with a 31.2% (std 4.8%) preference rate against ground-truth recordings. Our results suggest that PainDiffusion can serve as a viable alternative to real patients in clinical training and simulation, bridging the gap between synthetic and naturalistic pain expression. Code and videos are available at: https://damtien444.github.io/paindf/",
    "source": "arXiv"
  },
  {
    "title": "SPRMamba: Surgical Phase Recognition for Endoscopic Submucosal Dissection with Mamba",
    "title_es": "SPRMamba: Surgical Phase Recognition for Endoscopic Submucosal Dissection with Mamba",
    "url": "https://arxiv.org/abs/2409.12108",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.12108v3 Announce Type: replace \nAbstract: Endoscopic Submucosal Dissection (ESD) is a minimally invasive procedure initially developed for early gastric cancer treatment and has expanded to address diverse gastrointestinal lesions. While computer-assisted surgery (CAS) systems enhance ESD precision and safety, their efficacy hinges on accurate real-time surgical phase recognition, a task complicated by ESD's inherent complexity, including heterogeneous lesion characteristics and dynamic tissue interactions. Existing video-based phase recognition algorithms, constrained by inefficient temporal context modeling, exhibit limited performance in capturing fine-grained phase transitions and long-range dependencies. To overcome these limitations, we propose SPRMamba, a novel framework integrating a Mamba-based architecture with a Scaled Residual TranMamba (SRTM) block to synergize long-term temporal modeling and localized detail extraction. SPRMamba further introduces the Hierarchical Sampling Strategy to optimize computational efficiency, enabling real-time processing critical for clinical deployment. Evaluated on the ESD385 dataset and the cholecystectomy benchmark Cholec80, SPRMamba achieves state-of-the-art performance (87.64% accuracy on ESD385, +1.0% over prior methods), demonstrating robust generalizability across surgical workflows. This advancement bridges the gap between computational efficiency and temporal sensitivity, offering a transformative tool for intraoperative guidance and skill assessment in ESD surgery. The code is accessible at https://github.com/Zxnyyyyy/SPRMamba.",
    "source": "arXiv"
  },
  {
    "title": "CLAIR-A: Leveraging Large Language Models to Judge Audio Captions",
    "title_es": "CLAIR-A: Leveraging Large Language Models to Judge Audio Captions",
    "url": "https://arxiv.org/abs/2409.12962",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.12962v2 Announce Type: replace \nAbstract: The Automated Audio Captioning (AAC) task asks models to generate natural language descriptions of an audio input. Evaluating these machine-generated audio captions is a complex task that requires considering diverse factors, among them, auditory scene understanding, sound-object inference, temporal coherence, and the environmental context of the scene. While current methods focus on specific aspects, they often fail to provide an overall score that aligns well with human judgment. In this work, we propose CLAIR-A, a simple and flexible method that leverages the zero-shot capabilities of large language models (LLMs) to evaluate candidate audio captions by directly asking LLMs for a semantic distance score. In our evaluations, CLAIR-A better predicts human judgements of quality compared to traditional metrics, with a 5.8% relative accuracy improvement compared to the domain-specific FENSE metric and up to 11% over the best general-purpose measure on the Clotho-Eval dataset. Moreover, CLAIR-A offers more transparency by allowing the language model to explain the reasoning behind its scores, with these explanations rated up to 30% better by human evaluators than those provided by baseline methods. CLAIR-A is made publicly available at https://github.com/DavidMChan/clair-a.",
    "source": "arXiv"
  },
  {
    "title": "Ciphertext Malleability in Lattice-Based KEMs as a Countermeasure to Side Channel Analysis",
    "title_es": "Ciphertext Malleability in Lattice-Based KEMs as a Countermeasure to Side Channel Analysis",
    "url": "https://arxiv.org/abs/2409.16107",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.16107v2 Announce Type: replace \nAbstract: Due to developments in quantum computing, classical asymmetric cryptography is at risk of being breached. Consequently, new Post-Quantum Cryptography (PQC) primitives using lattices are studied. Another point of scrutiny is the resilience of these new primitives to Side Channel Analysis (SCA), where an attacker can study physical leakages. In this work we discuss a SCA vulnerability due to the ciphertext malleability of some PQC primitives exposed by a work from Ravi et al. We propose a novel countermeasure to this vulnerability exploiting the same ciphertext malleability and discuss its practical application to several PQC primitives. We also extend the seminal work of Ravi et al. by detailing their attack on the different security levels of a post-quantum Key Encapsulation Mechanism (KEM), namely FrodoKEM. We also provide a generalisation of their attack to different parameters which could be used in future similar primitives.",
    "source": "arXiv"
  },
  {
    "title": "Unidirectional Key Update in Updatable Encryption, Revisited",
    "title_es": "Unidirectional Key Update in Updatable Encryption, Revisited",
    "url": "https://arxiv.org/abs/2410.03948",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.03948v3 Announce Type: replace \nAbstract: In this paper we construct a new efficient updatable encryption (UE) scheme based on FrodoPKE learning with errors key encapsulation. We analyse the security of the proposed scheme in the backward-leak uni-directional setting within the rand-ind-eu-cpa model. Since the underlying computationally hard problem here is LWE, the scheme is secure against both classical and quantum attacks.",
    "source": "arXiv"
  },
  {
    "title": "Distribution Grids May Be a Barrier To Residential Electrification",
    "title_es": "Distribution Grids May Be a Barrier To Residential Electrification",
    "url": "https://arxiv.org/abs/2410.04540",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.04540v4 Announce Type: replace \nAbstract: Replacing fossil-fueled appliances and vehicles with electric alternatives can reduce greenhouse gas emissions and air pollution in many settings. However, residential electrification can also raise electricity demand beyond the safe limits of electrical infrastructure. This can increase the risk of blackouts or require grid reinforcement that is often slow and expensive. Here, we estimate the physical and economic impacts on distribution grids of electrifying all housing and personal vehicles in each county of the lower 48 United States. We find that space heating is the main driver of grid impacts, with the coldest regions seeing demand peaks up to five times higher than today's peaks. Accommodating electrification of all housing and personal vehicles is estimated to require 600 GW of distribution grid reinforcement nationally, at a cost of \\$350 to \\$790 billion, or \\$2,800 to \\$6,400 per household (95% confidence intervals). However, demand-side management could eliminate three-quarters of grid reinforcement costs.",
    "source": "arXiv"
  },
  {
    "title": "Distributed ADMM Approach for the Power Distribution Network Reconfiguration",
    "title_es": "Distributed ADMM Approach for the Power Distribution Network Reconfiguration",
    "url": "https://arxiv.org/abs/2410.04604",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.04604v2 Announce Type: replace \nAbstract: The electrical network reconfiguration problem aims to minimize losses in a distribution system by adjusting switches while ensuring radial topology. The growing use of renewable energy and the complexity of managing modern power grids make solving the reconfiguration problem crucial. Distributed algorithms help optimize grid configurations, ensuring efficient adaptation to changing conditions and better utilization of renewable energy sources. This paper introduces a distributed algorithm designed to tackle the problem of power distribution network reconfiguration with a radiality constraint. This algorithm relies on ADMM (Alternating Direction Method of Multipliers), where each agent progressively updates its estimation based on the information exchanged with neighboring agents. We show that every agent is required to solve a linearly constrained convex quadratic programming problem and a Minimum Weight Rooted Arborescence Problem (MWRAP) with local weights during each iteration. Through numerical experiments, we demonstrate the performance of the proposed algorithm in various scenarios, including its application to a 33-bus test system and a real-world network.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal Deception in Explainable AI: Concept-Level Backdoor Attacks on Concept Bottleneck Models",
    "title_es": "Multimodal Deception in Explainable AI: Concept-Level Backdoor Attacks on Concept Bottleneck Models",
    "url": "https://arxiv.org/abs/2410.04823",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.04823v2 Announce Type: replace \nAbstract: Deep learning has demonstrated transformative potential across domains, yet its inherent opacity has driven the development of Explainable Artificial Intelligence (XAI). Concept Bottleneck Models (CBMs), which enforce interpretability through human-understandable concepts, represent a prominent advancement in XAI. However, despite their semantic transparency, CBMs remain vulnerable to security threats such as backdoor attacks malicious manipulations that induce controlled misbehaviors during inference. While CBMs leverage multimodal representations (visual inputs and textual concepts) to enhance interpretability, heir dual modality structure introduces new attack surfaces. To address the unexplored risk of concept-level backdoor attacks in multimodal XAI systems, we propose CAT (Concept-level Backdoor ATtacks), a methodology that injects triggers into conceptual representations during training, enabling precise prediction manipulation without compromising clean-data performance. An enhanced variant, CAT+, incorporates a concept correlation function to systematically optimize trigger-concept associations, thereby improving attack effectiveness and stealthiness. Through a comprehensive evaluation framework assessing attack success rate, stealth metrics, and model utility preservation, we demonstrate that CAT and CAT+ maintain high performance on clean data while achieving significant targeted effects on backdoored datasets. This work highlights critical security risks in interpretable AI systems and provides a robust methodology for future security assessments of CBMs.",
    "source": "arXiv"
  },
  {
    "title": "Understanding and Imitating Human-Robot Motion with Restricted Visual Fields",
    "title_es": "Understanding and Imitating Human-Robot Motion with Restricted Visual Fields",
    "url": "https://arxiv.org/abs/2410.05547",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.05547v3 Announce Type: replace \nAbstract: When working around other agents such as humans, it is important to model their perception capabilities to predict and make sense of their behavior. In this work, we consider agents whose perception capabilities are determined by their limited field of view, viewing range, and the potential to miss objects within their viewing range. By considering the perception capabilities and observation model of agents independently from their motion policy, we show that we can better predict the agents' behavior; i.e., by reasoning about the perception capabilities of other agents, one can better make sense of their actions. We perform a user study where human operators navigate a cluttered scene while scanning the region for obstacles with a limited field of view and range. We show that by reasoning about the limited observation space of humans, a robot can better learn a human's strategy for navigating an environment and navigate with minimal collision with dynamic and static obstacles. We also show that this learned model helps it successfully navigate a physical hardware vehicle in real-time. Code available at https://github.com/labicon/HRMotion-RestrictedView.",
    "source": "arXiv"
  },
  {
    "title": "MultiNash-PF: A Particle Filtering Approach for Computing Multiple Local Generalized Nash Equilibria in Trajectory Games",
    "title_es": "MultiNash-PF: A Particle Filtering Approach for Computing Multiple Local Generalized Nash Equilibria in Trajectory Games",
    "url": "https://arxiv.org/abs/2410.05554",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.05554v3 Announce Type: replace \nAbstract: Modern robotic systems frequently engage in complex multi-agent interactions, many of which are inherently multi-modal, i.e., they can lead to multiple distinct outcomes. To interact effectively, robots must recognize the possible interaction modes and adapt to the one preferred by other agents. In this work, we propose MultiNash-PF, an efficient algorithm for capturing the multimodality in multi-agent interactions. We model interaction outcomes as equilibria of a game-theoretic planner, where each equilibrium corresponds to a distinct interaction mode. Our framework formulates interactive planning as Constrained Potential Trajectory Games (CPTGs), in which local Generalized Nash Equilibria (GNEs) represent plausible interaction outcomes. We propose to integrate the potential game approach with implicit particle filtering, a sample-efficient method for non-convex trajectory optimization. We utilize implicit particle filtering to identify the coarse estimates of multiple local minimizers of the game's potential function. MultiNash-PF then refines these estimates with optimization solvers, obtaining different local GNEs. We show through numerical simulations that MultiNash-PF reduces computation time by up to 50\\% compared to a baseline. We further demonstrate the effectiveness of our algorithm in real-world human-robot interaction scenarios, where it successfully accounts for the multi-modal nature of interactions and resolves potential conflicts in real-time.",
    "source": "arXiv"
  },
  {
    "title": "On Densest $k$-Subgraph Mining and Diagonal Loading",
    "title_es": "On Densest $k$-Subgraph Mining and Diagonal Loading",
    "url": "https://arxiv.org/abs/2410.07388",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.07388v3 Announce Type: replace \nAbstract: The Densest $k$-Subgraph (D$k$S) problem aims to find a subgraph comprising $k$ vertices with the maximum number of edges between them. A continuous relaxation of the binary quadratic D$k$S problem is considered, which incorporates a diagonal loading term. It is shown that this non-convex, continuous relaxation is tight for a range of diagonal loading parameters, and the impact of the diagonal loading parameter on the optimization landscape is studied. On the algorithmic side, two projection-free algorithms are proposed to tackle the relaxed problem, based on Frank--Wolfe and explicit constraint parameterization, respectively. Experiments suggest that both algorithms have merits relative to the state-of-art, while the Frank--Wolfe-based algorithm stands out in terms of subgraph density, computational complexity, and ability to scale up to very large datasets.",
    "source": "arXiv"
  },
  {
    "title": "A Closer Look at Machine Unlearning for Large Language Models",
    "title_es": "A Closer Look at Machine Unlearning for Large Language Models",
    "url": "https://arxiv.org/abs/2410.08109",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.08109v5 Announce Type: replace \nAbstract: Large language models (LLMs) may memorize sensitive or copyrighted content, raising privacy and legal concerns. Due to the high cost of retraining from scratch, researchers attempt to employ machine unlearning to remove specific content from LLMs while preserving the overall performance. In this paper, we discuss several issues in machine unlearning for LLMs and provide our insights on possible approaches. To address the issue of inadequate evaluation of model outputs after unlearning, we introduce three additional metrics to evaluate token diversity, sentence semantics, and factual correctness. We then categorize unlearning methods into untargeted and targeted, and discuss their issues respectively. Specifically, the behavior that untargeted unlearning attempts to approximate is unpredictable and may involve hallucinations, and existing regularization is insufficient for targeted unlearning. To alleviate these issues, we propose using the objective of maximizing entropy (ME) for untargeted unlearning and incorporate answer preservation (AP) loss as regularization for targeted unlearning. Experimental results across three scenarios, i.e., fictitious unlearning, continual unlearning, and real-world unlearning, demonstrate the effectiveness of our approaches. The code is available at https://github.com/sail-sg/closer-look-LLM-unlearning.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Spatial Representation to Enhance LLM Reasoning in Aerial Vision-Language Navigation",
    "title_es": "Exploring Spatial Representation to Enhance LLM Reasoning in Aerial Vision-Language Navigation",
    "url": "https://arxiv.org/abs/2410.08500",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.08500v3 Announce Type: replace \nAbstract: Aerial Vision-and-Language Navigation (VLN) is a novel task enabling Unmanned Aerial Vehicles (UAVs) to navigate in outdoor environments through natural language instructions and visual cues. However, it remains challenging due to the complex spatial relationships in aerial scenes.In this paper, we propose a training-free, zero-shot framework for aerial VLN tasks, where the large language model (LLM) is leveraged as the agent for action prediction. Specifically, we develop a novel Semantic-Topo-Metric Representation (STMR) to enhance the spatial reasoning capabilities of LLMs. This is achieved by extracting and projecting instruction-related semantic masks onto a top-down map, which presents spatial and topological information about surrounding landmarks and grows during the navigation process. At each step, a local map centered at the UAV is extracted from the growing top-down map, and transformed into a ma trix representation with distance metrics, serving as the text prompt to LLM for action prediction in response to the given instruction. Experiments conducted in real and simulation environments have proved the effectiveness and robustness of our method, achieving absolute success rate improvements of 26.8% and 5.8% over current state-of-the-art methods on simple and complex navigation tasks, respectively. The dataset and code will be released soon.",
    "source": "arXiv"
  },
  {
    "title": "MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection",
    "title_es": "MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection",
    "url": "https://arxiv.org/abs/2410.09103",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.09103v2 Announce Type: replace \nAbstract: We present a new adaptation method MaCP, Minimal yet Mighty adaptive Cosine Projection, that achieves exceptional performance while requiring minimal parameters and memory for fine-tuning large foundation models. Its general idea is to exploit the superior energy compaction and decorrelation properties of cosine projection to improve both model efficiency and accuracy. Specifically, it projects the weight change from the low-rank adaptation into the discrete cosine space. Then, the weight change is partitioned over different levels of the discrete cosine spectrum, and each partition's most critical frequency components are selected. Extensive experiments demonstrate the effectiveness of MaCP across a wide range of single-modality tasks, including natural language understanding, natural language generation, text summarization, as well as multi-modality tasks such as image classification and video understanding. MaCP consistently delivers superior accuracy, significantly reduced computational complexity, and lower memory requirements compared to existing alternatives.",
    "source": "arXiv"
  },
  {
    "title": "The Condorcet Dimension of Metric Spaces",
    "title_es": "The Condorcet Dimension of Metric Spaces",
    "url": "https://arxiv.org/abs/2410.09201",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.09201v3 Announce Type: replace \nAbstract: A Condorcet winning set is a set of candidates such that no other candidate is preferred by at least half the voters over all members of the set. The Condorcet dimension, which is the minimum cardinality of a Condorcet winning set, is known to be at most logarithmic in the number of candidates. We study the case of elections where voters and candidates are located in a $2$-dimensional space with preferences based upon proximity voting. Our main result is that the Condorcet dimension is at most $3$, under both the Manhattan norm and the infinity norm, natural measures in electoral systems.",
    "source": "arXiv"
  },
  {
    "title": "FlatQuant: Flatness Matters for LLM Quantization",
    "title_es": "FlatQuant: Flatness Matters for LLM Quantization",
    "url": "https://arxiv.org/abs/2410.09426",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.09426v4 Announce Type: replace \nAbstract: Recently, quantization has been widely used for the compression and acceleration of large language models (LLMs). Due to the outliers in LLMs, it is crucial to flatten weights and activations to minimize quantization error with equally spaced quantization points. Prior research explores various pre-quantization transformations to suppress outliers, such as per-channel scaling and Hadamard transformation. However, we observe that these transformed weights and activations can still exhibit steep and dispersed distributions. In this paper, we propose FlatQuant (Fast and Learnable Affine Transformation), a new post-training quantization approach that enhances the flatness of weights and activations. Our approach identifies optimal affine transformations for each linear layer, calibrated in hours via a lightweight objective. To reduce runtime overhead of affine transformation, we apply Kronecker product with two lightweight matrices, and fuse all operations in FlatQuant into a single kernel. Extensive experiments demonstrate that FlatQuant establishes a new state-of-the-art benchmark for quantization. For example, it achieves less than 1\\% accuracy drop for W4A4 quantization on the LLaMA-3-70B model, surpassing SpinQuant by 7.5\\%. Additionally, it provides up to 2.3x prefill speedup and 1.7x decoding speedup compared to the FP16 model. Code is available at: https://github.com/ruikangliu/FlatQuant.",
    "source": "arXiv"
  },
  {
    "title": "A Communication Consistent Approach to Signal Temporal Logic Task Decomposition in Multi-Agent Systems",
    "title_es": "A Communication Consistent Approach to Signal Temporal Logic Task Decomposition in Multi-Agent Systems",
    "url": "https://arxiv.org/abs/2410.12563",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.12563v2 Announce Type: replace \nAbstract: We consider the problem of decomposing a global task assigned to a multi-agent system, expressed as a formula within a fragment of Signal Temporal Logic (STL), under range-limited communication. Given a global task expressed as a conjunction of local tasks defined over the individual and relative states of agents in the system, we propose representing task dependencies among agents as edges of a suitably defined task graph. At the same time, range-limited communication naturally induces the definition of a communication graph that defines which agents have access to each other's states. Within these settings, inconsistencies arise when a task dependency between a pair of agents is not supported by a corresponding communication link due to the limited communication range. As a result, state feedback control laws previously derived to achieve the tasks' satisfaction can not be leveraged. We propose a task decomposition mechanism to distribute tasks assigned to pairs of non-communicating agents in the system as conjunctions of tasks defined over the relative states of communicating agents, thus enforcing consistency between task and communication graphs. Assuming the super-level sets of the predicate functions composing the STL tasks are bounded polytopes, our task decomposition mechanism can be cast as a parameter optimization problem and solved via state-of-the-art decentralized convex optimization algorithms. To guarantee the soundness of our approach, we present various conditions under which the tasks defined in the applied STL fragment are unsatisfiable, and we show sufficient conditions such that our decomposition approach yields satisfiable global tasks after decomposition.",
    "source": "arXiv"
  },
  {
    "title": "Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts",
    "title_es": "Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts",
    "url": "https://arxiv.org/abs/2410.12777",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.12777v2 Announce Type: replace \nAbstract: With the rapid progress of diffusion-based content generation, significant efforts are being made to unlearn harmful or copyrighted concepts from pretrained diffusion models (DMs) to prevent potential model misuse. However, it is observed that even when DMs are properly unlearned before release, malicious finetuning can compromise this process, causing DMs to relearn the unlearned concepts. This occurs partly because certain benign concepts (e.g., \"skin\") retained in DMs are related to the unlearned ones (e.g., \"nudity\"), facilitating their relearning via finetuning. To address this, we propose meta-unlearning on DMs. Intuitively, a meta-unlearned DM should behave like an unlearned DM when used as is; moreover, if the meta-unlearned DM undergoes malicious finetuning on unlearned concepts, the related benign concepts retained within it will be triggered to self-destruct, hindering the relearning of unlearned concepts. Our meta-unlearning framework is compatible with most existing unlearning methods, requiring only the addition of an easy-to-implement meta objective. We validate our approach through empirical experiments on meta-unlearning concepts from Stable Diffusion models (SD-v1-4 and SDXL), supported by extensive ablation studies. Our code is available at https://github.com/sail-sg/Meta-Unlearning.",
    "source": "arXiv"
  },
  {
    "title": "Harmony: A Human-Aware, Responsive, Modular Assistant with a Locally Deployed Large Language Model",
    "title_es": "Harmony: A Human-Aware, Responsive, Modular Assistant with a Locally Deployed Large Language Model",
    "url": "https://arxiv.org/abs/2410.14252",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.14252v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) offer powerful capabilities for natural language understanding, enabling more intelligent smart home assistants. However, existing systems often rely on cloud-based LLMs, raising concerns around user privacy and system dependency on external connectivity. In this work, we present Harmony, a privacy-preserving and robust smart home assistant powered by the locally deployable Llama3-8B model. Beyond protecting user data, Harmony also addresses reliability challenges of smaller models, such as hallucination and instruction misinterpretation, through structured prompting and modular agent design. Experimental results in both virtual environments and user studies show that Harmony achieves performance comparable to GPT-4-based systems, while enabling offline, proactive, and personalized smart home interaction.",
    "source": "arXiv"
  },
  {
    "title": "UoMo: A Universal Model of Mobile Traffic Forecasting for Wireless Network Optimization",
    "title_es": "UoMo: A Universal Model of Mobile Traffic Forecasting for Wireless Network Optimization",
    "url": "https://arxiv.org/abs/2410.15322",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.15322v4 Announce Type: replace \nAbstract: Mobile traffic forecasting allows operators to anticipate network dynamics and performance in advance, offering substantial potential for enhancing service quality and improving user experience. However, existing models are often task-oriented and are trained with tailored data, which limits their effectiveness in diverse mobile network tasks of Base Station (BS) deployment, resource allocation, energy optimization, etc. and hinders generalization across different urban environments. Foundation models have made remarkable strides across various domains of NLP and CV due to their multi-tasking adaption and zero/few-shot learning capabilities. In this paper, we propose an innovative Foundation model for Mo}bile traffic forecasting (FoMo), aiming to handle diverse forecasting tasks of short/long-term predictions and distribution generation across multiple cities to support network planning and optimization. FoMo combines diffusion models and transformers, where various spatio-temporal masks are proposed to enable FoMo to learn intrinsic features of different tasks, and a contrastive learning strategy is developed to capture the correlations between mobile traffic and urban contexts, thereby improving its transfer learning capability. Extensive experiments on 9 real-world datasets demonstrate that FoMo outperforms current models concerning diverse forecasting tasks and zero/few-shot learning, showcasing a strong universality.",
    "source": "arXiv"
  },
  {
    "title": "Learning How to Vote with Principles: Axiomatic Insights Into the Collective Decisions of Neural Networks",
    "title_es": "Learning How to Vote with Principles: Axiomatic Insights Into the Collective Decisions of Neural Networks",
    "url": "https://arxiv.org/abs/2410.16170",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.16170v2 Announce Type: replace \nAbstract: Can neural networks be applied in voting theory, while satisfying the need for transparency in collective decisions? We propose axiomatic deep voting: a framework to build and evaluate neural networks that aggregate preferences, using the well-established axiomatic method of voting theory. Our findings are: (1) Neural networks, despite being highly accurate, often fail to align with the core axioms of voting rules, revealing a disconnect between mimicking outcomes and reasoning. (2) Training with axiom-specific data does not enhance alignment with those axioms. (3) By solely optimizing axiom satisfaction, neural networks can synthesize new voting rules that often surpass and substantially differ from existing ones. This offers insights for both fields: For AI, important concepts like bias and value-alignment are studied in a mathematically rigorous way; for voting theory, new areas of the space of voting rules are explored.",
    "source": "arXiv"
  },
  {
    "title": "ADAM-SINDy: An Efficient Optimization Framework for Parameterized Nonlinear Dynamical System Identification",
    "title_es": "ADAM-SINDy: An Efficient Optimization Framework for Parameterized Nonlinear Dynamical System Identification",
    "url": "https://arxiv.org/abs/2410.16528",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.16528v3 Announce Type: replace \nAbstract: Identifying dynamical systems characterized by nonlinear parameters presents significant challenges in deriving mathematical models that enhance understanding of physics. Traditional methods, such as Sparse Identification of Nonlinear Dynamics (SINDy) and symbolic regression, can extract governing equations from observational data; however, they also come with distinct advantages and disadvantages. This paper introduces a novel method within the SINDy framework, termed ADAM-SINDy, which synthesizes the strengths of established approaches by employing the ADAM optimization algorithm. This facilitates the simultaneous optimization of nonlinear parameters and coefficients associated with nonlinear candidate functions, enabling precise parameter estimation without requiring prior knowledge of nonlinear characteristics such as trigonometric frequencies, exponential bandwidths, or polynomial exponents, thereby addressing a key limitation of SINDy. Through an integrated global optimization, ADAM-SINDy dynamically adjusts all unknown variables in response to data, resulting in an adaptive identification procedure that reduces the sensitivity to the library of candidate functions. The performance of the ADAM-SINDy methodology is demonstrated across a spectrum of dynamical systems, including benchmark coupled nonlinear ordinary differential equations such as oscillators, chaotic fluid flows, reaction kinetics, pharmacokinetics, as well as nonlinear partial differential equations (wildfire transport). The results demonstrate significant improvements in identifying parameterized dynamical systems and underscore the importance of concurrently optimizing all parameters, particularly those characterized by nonlinear parameters. These findings highlight the potential of ADAM-SINDy to extend the applicability of the SINDy framework in addressing more complex challenges in dynamical system identification.",
    "source": "arXiv"
  },
  {
    "title": "EfficientEQA: An Efficient Approach to Open-Vocabulary Embodied Question Answering",
    "title_es": "EfficientEQA: An Efficient Approach to Open-Vocabulary Embodied Question Answering",
    "url": "https://arxiv.org/abs/2410.20263",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.20263v2 Announce Type: replace \nAbstract: Embodied Question Answering (EQA) is an essential yet challenging task for robot assistants. Large vision-language models (VLMs) have shown promise for EQA, but existing approaches either treat it as static video question answering without active exploration or restrict answers to a closed set of choices. These limitations hinder real-world applicability, where a robot must explore efficiently and provide accurate answers in open-vocabulary settings. To overcome these challenges, we introduce EfficientEQA, a novel framework that couples efficient exploration with free-form answer generation. EfficientEQA features three key innovations: (1) Semantic-Value-Weighted Frontier Exploration (SFE) with Verbalized Confidence (VC) from a black-box VLM to prioritize semantically important areas to explore, enabling the agent to gather relevant information faster; (2) a BLIP relevancy-based mechanism to stop adaptively by flagging highly relevant observations as outliers to indicate whether the agent has collected enough information; and (3) a Retrieval-Augmented Generation (RAG) method for the VLM to answer accurately based on pertinent images from the agent's observation history without relying on predefined choices. Our experimental results show that EfficientEQA achieves over 15% higher answer accuracy and requires over 20% fewer exploration steps than state-of-the-art methods. Our code is available at: https://github.com/chengkaiAcademyCity/EfficientEQA",
    "source": "arXiv"
  },
  {
    "title": "SparseTem: Boosting the Efficiency of CNN-Based Video Encoders by Exploiting Temporal Continuity",
    "title_es": "SparseTem: Boosting the Efficiency of CNN-Based Video Encoders by Exploiting Temporal Continuity",
    "url": "https://arxiv.org/abs/2410.20790",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.20790v2 Announce Type: replace \nAbstract: Deep learning models have become pivotal in the field of video processing and is increasingly critical in practical applications such as autonomous driving and object detection. Although Vision Transformers (ViTs) have demonstrated their power, Convolutional Neural Networks (CNNs) remain a highly efficient and high-performance choice for feature extraction and encoding. However, the intensive computational demands of convolution operations hinder its broader adoption as a video encoder. Given the inherent temporal continuity in video frames, changes between consecutive frames are minimal, allowing for the skipping of redundant computations. This technique, which we term as Diff Computation, presents two primary challenges. First, Diff Computation requires to cache intermediate feature maps to ensure the correctness of non-linear computations, leading to significant memory consumption. Second, the imbalance of sparsity among layers, introduced by Diff Computation, incurs accuracy degradation. To address these issues, we propose a memory-efficient scheduling method to eliminate memory overhead and an online adjustment mechanism to minimize accuracy degradation. We integrate these techniques into our framework, SparseTem, to seamlessly support various CNN-based video encoders. SparseTem achieves speedup of 1.79x for EfficientDet and 4.72x for CRNN, with minimal accuracy drop and no additional memory overhead. Extensive experimental results demonstrate that SparseTem sets a new state-of-the-art by effectively utilizing temporal continuity to accelerate CNN-based video encoders.",
    "source": "arXiv"
  },
  {
    "title": "Chatbot Companionship: A Mixed-Methods Study of Companion Chatbot Usage Patterns and Their Relationship to Loneliness in Active Users",
    "title_es": "Chatbot Companionship: A Mixed-Methods Study of Companion Chatbot Usage Patterns and Their Relationship to Loneliness in Active Users",
    "url": "https://arxiv.org/abs/2410.21596",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.21596v3 Announce Type: replace \nAbstract: Companion chatbots offer a potential solution to the growing epidemic of loneliness, but their impact on users' psychosocial well-being remains poorly understood, raising critical ethical questions about their deployment and design. This study presents a large-scale survey (n = 404) of regular users of companion chatbots, investigating the relationship between chatbot usage and loneliness. We develop a model explaining approximately 50% of variance in loneliness; while usage does not directly predict loneliness, we identify factors including neuroticism, social network size, and problematic use. Through cluster analysis and mixed-methods thematic analysis combining manual coding with automated theme extraction, we identify seven distinct user profiles demonstrating that companion chatbots can either enhance or potentially harm psychological well-being depending on user characteristics. Different usage patterns can lead to markedly different outcomes, with some users experiencing enhanced social confidence while others risk further isolation. These findings have significant implications for responsible AI development, suggesting that one-size-fits-all approaches to AI companionship may be ethically problematic. Our work contributes to the ongoing dialogue about the role of AI in social and emotional support, offering insights for developing more targeted and ethical approaches to AI companionship that complement rather than replace human connections.",
    "source": "arXiv"
  },
  {
    "title": "Language-Driven Policy Distillation for Cooperative Driving in Multi-Agent Reinforcement Learning",
    "title_es": "Language-Driven Policy Distillation for Cooperative Driving in Multi-Agent Reinforcement Learning",
    "url": "https://arxiv.org/abs/2410.24152",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.24152v2 Announce Type: replace \nAbstract: The cooperative driving technology of Connected and Autonomous Vehicles (CAVs) is crucial for improving the efficiency and safety of transportation systems. Learning-based methods, such as Multi-Agent Reinforcement Learning (MARL), have demonstrated strong capabilities in cooperative decision-making tasks. However, existing MARL approaches still face challenges in terms of learning efficiency and performance. In recent years, Large Language Models (LLMs) have rapidly advanced and shown remarkable abilities in various sequential decision-making tasks. To enhance the learning capabilities of cooperative agents while ensuring decision-making efficiency and cost-effectiveness, we propose LDPD, a language-driven policy distillation method for guiding MARL exploration. In this framework, a teacher agent based on LLM trains smaller student agents to achieve cooperative decision-making through its own decision-making demonstrations. The teacher agent enhances the observation information of CAVs and utilizes LLMs to perform complex cooperative decision-making reasoning, which also leverages carefully designed decision-making tools to achieve expert-level decisions, providing high-quality teaching experiences. The student agent then refines the teacher's prior knowledge into its own model through gradient policy updates. The experiments demonstrate that the students can rapidly improve their capabilities with minimal guidance from the teacher and eventually surpass the teacher's performance. Extensive experiments show that our approach demonstrates better performance and learning efficiency compared to baseline methods.",
    "source": "arXiv"
  },
  {
    "title": "Zero-Shot Voice Conversion via Content-Aware Timbre Ensemble and Conditional Flow Matching",
    "title_es": "Zero-Shot Voice Conversion via Content-Aware Timbre Ensemble and Conditional Flow Matching",
    "url": "https://arxiv.org/abs/2411.02026",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.02026v2 Announce Type: replace \nAbstract: Despite recent advances in zero-shot voice conversion (VC), achieving speaker similarity and naturalness comparable to ground-truth recordings remains a significant challenge. In this letter, we propose CTEFM-VC, a zero-shot VC framework that integrates content-aware timbre ensemble modeling with conditional flow matching. Specifically, CTEFM-VC decouples utterances into content and timbre representations and leverages a conditional flow matching model to reconstruct the Mel-spectrogram of the source speech. To enhance its timbre modeling capability and naturalness of generated speech, we first introduce a context-aware timbre ensemble modeling approach that adaptively integrates diverse speaker verification embeddings and enables the effective utilization of source content and target timbre elements through a cross-attention module. Furthermore, a structural similarity-based timbre loss is presented to jointly train CTEFM-VC end-to-end. Experiments show that CTEFM-VC consistently achieves the best performance in all metrics assessing speaker similarity, speech naturalness, and intelligibility, significantly outperforming state-of-the-art zero-shot VC systems.",
    "source": "arXiv"
  },
  {
    "title": "An information-matching approach to optimal experimental design and active learning",
    "title_es": "An information-matching approach to optimal experimental design and active learning",
    "url": "https://arxiv.org/abs/2411.02740",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.02740v3 Announce Type: replace \nAbstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.",
    "source": "arXiv"
  },
  {
    "title": "TDDBench: A Benchmark for Training data detection",
    "title_es": "TDDBench: A Benchmark for Training data detection",
    "url": "https://arxiv.org/abs/2411.03363",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.03363v2 Announce Type: replace \nAbstract: Training Data Detection (TDD) is a task aimed at determining whether a specific data instance is used to train a machine learning model. In the computer security literature, TDD is also referred to as Membership Inference Attack (MIA). Given its potential to assess the risks of training data breaches, ensure copyright authentication, and verify model unlearning, TDD has garnered significant attention in recent years, leading to the development of numerous methods. Despite these advancements, there is no comprehensive benchmark to thoroughly evaluate the effectiveness of TDD methods. In this work, we introduce TDDBench, which consists of 13 datasets spanning three data modalities: image, tabular, and text. We benchmark 21 different TDD methods across four detection paradigms and evaluate their performance from five perspectives: average detection performance, best detection performance, memory consumption, and computational efficiency in both time and memory. With TDDBench, researchers can identify bottlenecks and areas for improvement in TDD algorithms, while practitioners can make informed trade-offs between effectiveness and efficiency when selecting TDD algorithms for specific use cases. Our extensive experiments also reveal the generally unsatisfactory performance of TDD algorithms across different datasets. To enhance accessibility and reproducibility, we open-source TDDBench for the research community at https://github.com/zzh9568/TDDBench.",
    "source": "arXiv"
  },
  {
    "title": "Detection of Technical Debt in Java Source Code",
    "title_es": "Detection of Technical Debt in Java Source Code",
    "url": "https://arxiv.org/abs/2411.05457",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.05457v2 Announce Type: replace \nAbstract: Technical debt (TD) describes the additional costs that emerge when developers have opted for a quick and easy solution to a problem, rather than a more effective and well-designed, but time-consuming approach. Self-Admitted Technical Debts (SATDs) are a specific type of technical debts that developers intentionally document and acknowledge, typically via textual comments. While these comments are a useful tool for identifying TD, most of the existing approaches focus on capturing tokens associated with various categories of TD, neglecting the rich information embedded within the source code. Recent research has focused on detecting SATDs by analyzing comments, and there has been little work dealing with TD contained in the source code. In this study, through the analysis of comments and their source code from 974 Java projects, we curated the first ever dataset of TD identified by code comments, coupled with its code. We found that including the classified code significantly improves the accuracy in predicting various types of technical debt. We believe that our dataset will catalyze future work in the domain, inspiring various research related to the recognition of technical debt; The proposed classifiers may serve as baselines for studies on the detection of TD.",
    "source": "arXiv"
  },
  {
    "title": "Flow Matching Posterior Sampling: A Training-free Conditional Generation for Flow Matching",
    "title_es": "Flow Matching Posterior Sampling: A Training-free Conditional Generation for Flow Matching",
    "url": "https://arxiv.org/abs/2411.07625",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.07625v3 Announce Type: replace \nAbstract: Training-free conditional generation based on flow matching aims to leverage pre-trained unconditional flow matching models to perform conditional generation without retraining. Recently, a successful training-free conditional generation approach incorporates conditions via posterior sampling, which relies on the availability of a score function in the unconditional diffusion model. However, flow matching models do not possess an explicit score function, rendering such a strategy inapplicable. Approximate posterior sampling for flow matching has been explored, but it is limited to linear inverse problems. In this paper, we propose Flow Matching-based Posterior Sampling (FMPS) to expand its application scope. We introduce a correction term by steering the velocity field. This correction term can be reformulated to incorporate a surrogate score function, thereby bridging the gap between flow matching models and score-based posterior sampling. Hence, FMPS enables the posterior sampling to be adjusted within the flow matching framework. Further, we propose two practical implementations of the correction mechanism: one aimed at improving generation quality, and the other focused on computational efficiency. Experimental results on diverse conditional generation tasks demonstrate that our method achieves superior generation quality compared to existing state-of-the-art approaches, validating the effectiveness and generality of FMPS.",
    "source": "arXiv"
  },
  {
    "title": "Minimally Conservative Controlled-Invariant Set Synthesis Using Control Barrier Certificates",
    "title_es": "Minimally Conservative Controlled-Invariant Set Synthesis Using Control Barrier Certificates",
    "url": "https://arxiv.org/abs/2411.07640",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.07640v4 Announce Type: replace \nAbstract: Finding a controlled-invariant set for a system with state and control constraints is crucial for safety-critical applications. However, existing methods often produce overly conservative solutions. This paper presents a method for generating controlled-invariant (safe) sets for nonlinear polynomial control-affine systems using Control Barrier Certificates (CBCs). We formulate CBC conditions as Sum-of-Squares (SOS) constraints and solve them via an SOS Program (SOSP). First, we generalize existing SOSPs for CBC synthesis to handle environments with complex unsafe state representations. Then, we propose an iterative algorithm that progressively enlarges the safe set constructed by the synthesized CBCs by maximizing boundary expansion at each iteration. We theoretically prove that our method guarantees strict safe set expansion at every step. Finally, we validate our approach with numerical simulations in 2D and 3D for single-input and multi-input systems. Empirical results show that the safe set generated by our method covers in most part a larger portion of the state space compared to two state-of-the-art techniques.",
    "source": "arXiv"
  },
  {
    "title": "Steering AI-Driven Personalization of Scientific Text for General Audiences",
    "title_es": "Steering AI-Driven Personalization of Scientific Text for General Audiences",
    "url": "https://arxiv.org/abs/2411.09969",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.09969v2 Announce Type: replace \nAbstract: Digital media platforms (e.g., science blogs) offer opportunities to communicate scientific content to general audiences at scale. However, these audiences vary in their scientific expertise, literacy levels, and personal backgrounds, making effective science communication challenging. To address this challenge, we designed TranSlider, an AI-powered tool that generates personalized translations of scientific text based on individual user profiles (e.g., hobbies, location, and education). Our tool features an interactive slider that allows users to steer the degree of personalization from 0 (weakly relatable) to 100 (strongly relatable), leveraging LLMs to generate the translations with chosen degrees. Through an exploratory study with 15 participants, we investigated both the utility of these AI-personalized translations and how interactive reading features influenced users' understanding and reading experiences. We found that participants who preferred higher degrees of personalization appreciated the relatable and contextual translations, while those who preferred lower degrees valued concise translations with subtle contextualization. Furthermore, participants reported the compounding effect of multiple translations on their understanding of scientific content. Drawing on these findings, we discuss several implications for facilitating science communication and designing steerable interfaces to support human-AI alignment.",
    "source": "arXiv"
  },
  {
    "title": "Towards Understanding the Impact of Data Bugs on Deep Learning Models in Software Engineering",
    "title_es": "Towards Understanding the Impact of Data Bugs on Deep Learning Models in Software Engineering",
    "url": "https://arxiv.org/abs/2411.12137",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.12137v3 Announce Type: replace \nAbstract: Deep learning (DL) techniques have achieved significant success in various software engineering tasks (e.g., code completion by Copilot). However, DL systems are prone to bugs from many sources, including training data. Existing literature suggests that bugs in training data are highly prevalent, but little research has focused on understanding their impacts on the models used in software engineering tasks. In this paper, we address this research gap through a comprehensive empirical investigation focused on three types of data prevalent in software engineering tasks: code-based, text-based, and metric-based. Using state-of-the-art baselines, we compare the models trained on clean datasets with those trained on datasets with quality issues and without proper preprocessing. By analysing the gradients, weights, and biases from neural networks under training, we identify the symptoms of data quality and preprocessing issues. Our analysis reveals that quality issues in code data cause biased learning and gradient instability, whereas problems in text data lead to overfitting and poor generalisation of models. On the other hand, quality issues in metric data result in exploding gradients and model overfitting, and inadequate preprocessing exacerbates these effects across all three data types. Finally, we demonstrate the validity and generalizability of our findings using six new datasets. Our research provides a better understanding of the impact and symptoms of data bugs in software engineering datasets. Practitioners and researchers can leverage these findings to develop better monitoring systems and data-cleaning methods to help detect and resolve data bugs in deep learning systems.",
    "source": "arXiv"
  },
  {
    "title": "Strengthening False Information Propagation Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques in comparison to BERT",
    "title_es": "Strengthening False Information Propagation Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques in comparison to BERT",
    "url": "https://arxiv.org/abs/2411.12703",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.12703v3 Announce Type: replace \nAbstract: The rapid spread of misinformation, particularly through online platforms, underscores the urgent need for reliable detection systems. This study explores the utilization of machine learning and natural language processing, specifically Support Vector Machines (SVM) and BERT, to detect fake news. We employ three distinct text vectorization methods for SVM: Term Frequency Inverse Document Frequency (TF-IDF), Word2Vec, and Bag of Words (BoW), evaluating their effectiveness in distinguishing between genuine and fake news. Additionally, we compare these methods against the transformer large language model, BERT. Our comprehensive approach includes detailed preprocessing steps, rigorous model implementation, and thorough evaluation to determine the most effective techniques. The results demonstrate that while BERT achieves superior accuracy with 99.98% and an F1-score of 0.9998, the SVM model with a linear kernel and BoW vectorization also performs exceptionally well, achieving 99.81% accuracy and an F1-score of 0.9980. These findings highlight that, despite BERT's superior performance, SVM models with BoW and TF-IDF vectorization methods come remarkably close, offering highly competitive performance with the advantage of lower computational requirements.",
    "source": "arXiv"
  },
  {
    "title": "Solving Zero-Shot 3D Visual Grounding as Constraint Satisfaction Problems",
    "title_es": "Solving Zero-Shot 3D Visual Grounding as Constraint Satisfaction Problems",
    "url": "https://arxiv.org/abs/2411.14594",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.14594v2 Announce Type: replace \nAbstract: 3D visual grounding (3DVG) aims to locate objects in a 3D scene with natural language descriptions. Supervised methods have achieved decent accuracy, but have a closed vocabulary and limited language understanding ability. Zero-shot methods utilize large language models (LLMs) to handle natural language descriptions, where the LLM either produces grounding results directly or generates programs that compute results (symbolically). In this work, we propose a zero-shot method that reformulates the 3DVG task as a Constraint Satisfaction Problem (CSP), where the variables and constraints represent objects and their spatial relations, respectively. This allows a global symbolic reasoning of all relevant objects, producing grounding results of both the target and anchor objects. Moreover, we demonstrate the flexibility of our framework by handling negation- and counting-based queries with only minor extra coding efforts. Our system, Constraint Satisfaction Visual Grounding (CSVG), has been extensively evaluated on the public datasets ScanRefer and Nr3D datasets using only open-source LLMs. Results show the effectiveness of CSVG and superior grounding accuracy over current state-of-the-art zero-shot 3DVG methods with improvements of $+7.0\\%$ (Acc@0.5 score) and $+11.2\\%$ on the ScanRefer and Nr3D datasets, respectively. The code of our system is available at https://asig-x.github.io/csvg_web.",
    "source": "arXiv"
  },
  {
    "title": "Quadratic Gaussian Splatting: High Quality Surface Reconstruction with Second-order Geometric Primitives",
    "title_es": "Quadratic Gaussian Splatting: High Quality Surface Reconstruction with Second-order Geometric Primitives",
    "url": "https://arxiv.org/abs/2411.16392",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.16392v3 Announce Type: replace \nAbstract: We propose Quadratic Gaussian Splatting (QGS), a novel representation that replaces static primitives with deformable quadric surfaces (e.g., ellipse, paraboloids) to capture intricate geometry. Unlike prior works that rely on Euclidean distance for primitive density modeling--a metric misaligned with surface geometry under deformation--QGS introduces geodesic distance-based density distributions. This innovation ensures that density weights adapt intrinsically to the primitive curvature, preserving consistency during shape changes (e.g., from planar disks to curved paraboloids). By solving geodesic distances in closed form on quadric surfaces, QGS enables surface-aware splatting, where a single primitive can represent complex curvature that previously required dozens of planar surfels, potentially reducing memory usage while maintaining efficient rendering via fast ray-quadric intersection. Experiments on DTU, Tanks and Temples, and MipNeRF360 datasets demonstrate state-of-the-art surface reconstruction, with QGS reducing geometric error (chamfer distance) by 33% over 2DGS and 27% over GOF on the DTU dataset. Crucially, QGS retains competitive appearance quality, bridging the gap between geometric precision and visual fidelity for applications like robotics and immersive reality.",
    "source": "arXiv"
  },
  {
    "title": "sbi reloaded: a toolkit for simulation-based inference workflows",
    "title_es": "sbi reloaded: a toolkit for simulation-based inference workflows",
    "url": "https://arxiv.org/abs/2411.17337",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.17337v2 Announce Type: replace \nAbstract: Scientists and engineers use simulators to model empirically observed phenomena. However, tuning the parameters of a simulator to ensure its outputs match observed data presents a significant challenge. Simulation-based inference (SBI) addresses this by enabling Bayesian inference for simulators, identifying parameters that match observed data and align with prior knowledge. Unlike traditional Bayesian inference, SBI only needs access to simulations from the model and does not require evaluations of the likelihood function. In addition, SBI algorithms do not require gradients through the simulator, allow for massive parallelization of simulations, and can perform inference for different observations without further simulations or training, thereby amortizing inference. Over the past years, we have developed, maintained, and extended sbi, a PyTorch-based package that implements Bayesian SBI algorithms based on neural networks. The sbi toolkit implements a wide range of inference methods, neural network architectures, sampling methods, and diagnostic tools. In addition, it provides well-tested default settings, but also offers flexibility to fully customize every step of the simulation-based inference workflow. Taken together, the sbi toolkit enables scientists and engineers to apply state-of-the-art SBI methods to black-box simulators, opening up new possibilities for aligning simulations with empirically observed data.",
    "source": "arXiv"
  },
  {
    "title": "Privacy-Preserving Behaviour of Chatbot Users: Steering Through Trust Dynamics",
    "title_es": "Privacy-Preserving Behaviour of Chatbot Users: Steering Through Trust Dynamics",
    "url": "https://arxiv.org/abs/2411.17589",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.17589v2 Announce Type: replace \nAbstract: Introduction: The use of chatbots is becoming increasingly important across various aspects of daily life. However, the privacy concerns associated with these communications have not yet been thoroughly addressed. The aim of this study was to investigate user awareness of privacy risks in chatbot interactions, the privacy-preserving behaviours users practice, and how these behaviours relate to their awareness of privacy threats, even when no immediate threat is perceived. Methods: We developed a novel \"privacy-safe\" setup to analyse user behaviour under the guarantees of anonymization and non-sharing. We employed a mixed-methods approach, starting with the quantification of broader trends by coding responses, followed by conducting a qualitative content analysis to gain deeper insights. Results: Overall, there was a substantial lack of understanding among users about how chatbot providers handle data (27% of the participants) and the basics of privacy risks (76% of the participants). Older users, in particular, expressed fears that chatbot providers might sell their data. Moreover, even users with privacy knowledge do not consistently exhibit privacy-preserving behaviours when assured of transparent data processing by chatbots. Notably, under-protective behaviours were observed among more expert users. Discussion: These findings highlight the need for a strategic approach to enhance user education on privacy concepts to ensure informed decision when interacting with chatbot technology. This includes the development of tools to help users monitor and control the information they share with chatbots",
    "source": "arXiv"
  },
  {
    "title": "VideoSAVi: Self-Aligned Video Language Models without Human Supervision",
    "title_es": "VideoSAVi: Self-Aligned Video Language Models without Human Supervision",
    "url": "https://arxiv.org/abs/2412.00624",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.00624v3 Announce Type: replace \nAbstract: Recent advances in video-large language models (Video-LLMs) have led to significant progress in video understanding. Current preference optimization methods often rely on proprietary APIs or human-annotated captions to generate preference data (i.e., pairs of model outputs ranked by quality or alignment with human judgment), which is then used to train models for video-language alignment. This approach is both costly and labor-intensive. To address this limitation, we introduce VideoSAVi (Self-Aligned Video Language Model), a self-training pipeline that enables Video-LLMs to learn from video content without external supervision. Our approach includes a self-critiquing mechanism that identifies reasoning errors in the model's initial responses and generates improved alternatives, creating preference pairs directly from video content. VideoSAVi then applies Direct Preference Optimization (DPO) to iteratively train the model using the preference data, thus enhancing its temporal and spatial reasoning for video understanding. Experiments show that VideoSAVi delivers significant improvements across multiple benchmarks, including a +4.2 percentage point gain on MVBench, +3.9 on PerceptionTest, and +6.8 on the challenging EgoSchema dataset compared to baseline models. Our model-agnostic approach is computationally efficient, requiring only 32 frames, offering a promising direction for self-aligned video understanding without reliance on external models or annotations.",
    "source": "arXiv"
  },
  {
    "title": "DuoCast: Duo-Probabilistic Diffusion for Precipitation Nowcasting",
    "title_es": "DuoCast: Duo-Probabilistic Diffusion for Precipitation Nowcasting",
    "url": "https://arxiv.org/abs/2412.01091",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.01091v3 Announce Type: replace \nAbstract: Accurate short-term precipitation forecasting is critical for weather-sensitive decision-making in agriculture, transportation, and disaster response. Existing deep learning approaches often struggle to balance global structural consistency with local detail preservation, especially under complex meteorological conditions. We propose DuoCast, a dual-diffusion framework that decomposes precipitation forecasting into low- and high-frequency components modeled in orthogonal latent subspaces. We theoretically prove that this frequency decomposition reduces prediction error compared to conventional single branch U-Net diffusion models. In DuoCast, the low-frequency model captures large-scale trends via convolutional encoders conditioned on weather front dynamics, while the high-frequency model refines fine-scale variability using a self-attention-based architecture. Experiments on four benchmark radar datasets show that DuoCast consistently outperforms state-of-the-art baselines, achieving superior accuracy in both spatial detail and temporal evolution.",
    "source": "arXiv"
  },
  {
    "title": "BadPatch: Diffusion-Based Generation of Physical Adversarial Patches",
    "title_es": "BadPatch: Diffusion-Based Generation of Physical Adversarial Patches",
    "url": "https://arxiv.org/abs/2412.01440",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.01440v5 Announce Type: replace \nAbstract: Physical adversarial patches printed on clothing can enable individuals to evade person detectors, but most existing methods prioritize attack effectiveness over stealthiness, resulting in aesthetically unpleasing patches. While generative adversarial networks and diffusion models can produce more natural-looking patches, they often fail to balance stealthiness with attack effectiveness and lack flexibility for user customization. To address these limitations, we propose BadPatch, a novel diffusion-based framework for generating customizable and naturalistic adversarial patches. Our approach allows users to start from a reference image (rather than random noise) and incorporates masks to create patches of various shapes, not limited to squares. To preserve the original semantics during the diffusion process, we employ Null-text inversion to map random noise samples to a single input image and generate patches through Incomplete Diffusion Optimization (IDO). Our method achieves attack performance comparable to state-of-the-art non-naturalistic patches while maintaining a natural appearance. Using BadPatch, we construct AdvT-shirt-1K, the first physical adversarial T-shirt dataset comprising over a thousand images captured in diverse scenarios. AdvT-shirt-1K can serve as a useful dataset for training or testing future defense methods.",
    "source": "arXiv"
  },
  {
    "title": "WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image",
    "title_es": "WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image",
    "url": "https://arxiv.org/abs/2412.02141",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.02141v4 Announce Type: replace \nAbstract: Recent advancements in computational pathology have produced patch-level Multi-modal Large Language Models (MLLMs), but these models are limited by their inability to analyze whole slide images (WSIs) comprehensively and their tendency to bypass crucial morphological features that pathologists rely on for diagnosis. To address these challenges, we first introduce WSI-Bench, a large-scale morphology-aware benchmark containing 180k VQA pairs from 9,850 WSIs across 30 cancer types, designed to evaluate MLLMs' understanding of morphological characteristics crucial for accurate diagnosis. Building upon this benchmark, we present WSI-LLaVA, a novel framework for gigapixel WSI understanding that employs a three-stage training approach: WSI-text alignment, feature space alignment, and task-specific instruction tuning. To better assess model performance in pathological contexts, we develop two specialized WSI metrics: WSI-Precision and WSI-Relevance. Experimental results demonstrate that WSI-LLaVA outperforms existing models across all capability dimensions, with a significant improvement in morphological analysis, establishing a clear correlation between morphological understanding and diagnostic accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Graph-Powered Defense: Controller Area Network Intrusion Detection for Unmanned Aerial Vehicles",
    "title_es": "Graph-Powered Defense: Controller Area Network Intrusion Detection for Unmanned Aerial Vehicles",
    "url": "https://arxiv.org/abs/2412.02539",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.02539v2 Announce Type: replace \nAbstract: The network of services, including delivery, farming, and environmental monitoring, has experienced exponential expansion in the past decade with Unmanned Aerial Vehicles (UAVs). Yet, UAVs are not robust enough against cyberattacks, especially on the Controller Area Network (CAN) bus. The CAN bus is a general-purpose vehicle-bus standard to enable microcontrollers and in-vehicle computers to interact, primarily connecting different Electronic Control Units (ECUs). In this study, we focus on solving some of the most critical security weaknesses in UAVs by developing a novel graph-based intrusion detection system (IDS) leveraging the Uncomplicated Application-level Vehicular Communication and Networking (UAVCAN) protocol. First, we decode CAN messages based on UAVCAN protocol specification; second, we present a comprehensive method of transforming tabular UAVCAN messages into graph structures. Lastly, we apply various graph-based machine learning models for detecting cyber-attacks on the CAN bus, including graph convolutional neural networks (GCNNs), graph attention networks (GATs), Graph Sample and Aggregate Networks (GraphSAGE), and graph structure-based transformers. Our findings show that inductive models such as GATs, GraphSAGE, and graph-based transformers can achieve competitive and even better accuracy than transductive models like GCNNs in detecting various types of intrusions, with minimum information on protocol specification, thus providing a generic robust solution for CAN bus security for the UAVs. We also compared our results with baseline single-layer Long Short-Term Memory (LSTM) and found that all our graph-based models perform better without using any decoded features based on the UAVCAN protocol, highlighting higher detection performance with protocol-independent capability.",
    "source": "arXiv"
  },
  {
    "title": "Understanding and Mitigating Memorization in Generative Models via Sharpness of Probability Landscapes",
    "title_es": "Understanding and Mitigating Memorization in Generative Models via Sharpness of Probability Landscapes",
    "url": "https://arxiv.org/abs/2412.04140",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.04140v4 Announce Type: replace \nAbstract: In this paper, we introduce a geometric framework to analyze memorization in diffusion models through the sharpness of the log probability density. We mathematically justify a previously proposed score-difference-based memorization metric by demonstrating its effectiveness in quantifying sharpness. Additionally, we propose a novel memorization metric that captures sharpness at the initial stage of image generation in latent diffusion models, offering early insights into potential memorization. Leveraging this metric, we develop a mitigation strategy that optimizes the initial noise of the generation process using a sharpness-aware regularization term.",
    "source": "arXiv"
  },
  {
    "title": "LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation",
    "title_es": "LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation",
    "url": "https://arxiv.org/abs/2412.05148",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.05148v2 Announce Type: replace \nAbstract: Recent advancements in image generation models have enabled personalized image creation with both user-defined subjects (content) and styles. Prior works achieved personalization by merging corresponding low-rank adapters (LoRAs) through optimization-based methods, which are computationally demanding and unsuitable for real-time use on resource-constrained devices like smartphones. To address this, we introduce LoRA$.$rar, a method that not only improves image quality but also achieves a remarkable speedup of over $4000\\times$ in the merging process. We collect a dataset of style and subject LoRAs and pre-train a hypernetwork on a diverse set of content-style LoRA pairs, learning an efficient merging strategy that generalizes to new, unseen content-style pairs, enabling fast, high-quality personalization. Moreover, we identify limitations in existing evaluation metrics for content-style quality and propose a new protocol using multimodal large language models (MLLMs) for more accurate assessment. Our method significantly outperforms the current state of the art in both content and style fidelity, as validated by MLLM assessments and human evaluations.",
    "source": "arXiv"
  },
  {
    "title": "Approximating Analytic Spectra of Hyperbolic Systems with Summation-by-Parts Finite Difference Operators",
    "title_es": "Approximating Analytic Spectra of Hyperbolic Systems with Summation-by-Parts Finite Difference Operators",
    "url": "https://arxiv.org/abs/2412.05399",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.05399v3 Announce Type: replace \nAbstract: In this work we explore the fidelity of numerical approximations to the analytic spectra of hyperbolic partial differential equation systems with variable coefficients. We are particularly interested in the ability of discrete methods to accurately discover sources of physical instabilities. By considering the perturbed equations that arise in linearized problems, we study systems in which a lower-order term can act as a source of internal energy within the system. We apply high-order accurate summation-by-parts finite difference operators, with weak enforcement of boundary conditions through the simultaneous-approximation-term technique, which leads to a provably stable numerical discretization with formal order of accuracy given by $p = 2, 3, 4$ and $5$. We derive analytic solutions using Laplace transform methods, which provide important ground truth to ensure numerical convergence at the correct theoretical rate. We derive the analytic spectrum and find that it is better captured with mesh refinement, although dissipative strict stability (where the growth rate of the discrete problem is bounded above by the analytic) is not obtained. We also find that sole reliance on mesh refinement can be a problematic means for determining physical growth rates as some eigenvalues emerge (and persist with mesh refinement) based on spatial order of accuracy but are non-physical. We suggest that numerical methods be used to approximate the spectra when numerical stability is guaranteed and convergence of the numerical spectra is evident with both mesh refinement and increasing order of accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Street Gaussians without 3D Object Tracker",
    "title_es": "Street Gaussians without 3D Object Tracker",
    "url": "https://arxiv.org/abs/2412.05548",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.05548v3 Announce Type: replace \nAbstract: Realistic scene reconstruction in driving scenarios poses significant challenges due to fast-moving objects. Most existing methods rely on labor-intensive manual labeling of object poses to reconstruct dynamic objects in canonical space and move them based on these poses during rendering. While some approaches attempt to use 3D object trackers to replace manual annotations, the limited generalization of 3D trackers -- caused by the scarcity of large-scale 3D datasets -- results in inferior reconstructions in real-world settings. In contrast, 2D foundation models demonstrate strong generalization capabilities. To eliminate the reliance on 3D trackers and enhance robustness across diverse environments, we propose a stable object tracking module by leveraging associations from 2D deep trackers within a 3D object fusion strategy. We address inevitable tracking errors by further introducing a motion learning strategy in an implicit feature space that autonomously corrects trajectory errors and recovers missed detections. Experimental results on Waymo-NOTR and KITTI show that our method outperforms existing approaches. Our code will be made publicly available.",
    "source": "arXiv"
  },
  {
    "title": "FOF-X: Towards Real-time Detailed Human Reconstruction from a Single Image",
    "title_es": "FOF-X: Towards Real-time Detailed Human Reconstruction from a Single Image",
    "url": "https://arxiv.org/abs/2412.05961",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.05961v3 Announce Type: replace \nAbstract: We introduce FOF-X for real-time reconstruction of detailed human geometry from a single image. Balancing real-time speed against high-quality results is a persistent challenge, mainly due to the high computational demands of existing 3D representations. To address this, we propose Fourier Occupancy Field (FOF), an efficient 3D representation by learning the Fourier series. The core of FOF is to factorize a 3D occupancy field into a 2D vector field, retaining topology and spatial relationships within the 3D domain while facilitating compatibility with 2D convolutional neural networks. Such a representation bridges the gap between 3D and 2D domains, enabling the integration of human parametric models as priors and enhancing the reconstruction robustness. Based on FOF, we design a new reconstruction framework, FOF-X, to avoid the performance degradation caused by texture and lighting. This enables our real-time reconstruction system to better handle the domain gap between training images and real images. Additionally, in FOF-X, we enhance the inter-conversion algorithms between FOF and mesh representations with a Laplacian constraint and an automaton-based discontinuity matcher, improving both quality and robustness. We validate the strengths of our approach on different datasets and real-captured data, where FOF-X achieves new state-of-the-art results. The code has already been released for research purposes at https://cic.tju.edu.cn/faculty/likun/projects/FOFX/index.html.",
    "source": "arXiv"
  },
  {
    "title": "Unbiased Region-Language Alignment for Open-Vocabulary Dense Prediction",
    "title_es": "Unbiased Region-Language Alignment for Open-Vocabulary Dense Prediction",
    "url": "https://arxiv.org/abs/2412.06244",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.06244v3 Announce Type: replace \nAbstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated impressive zero-shot recognition capability, but still underperform in dense prediction tasks. Self-distillation recently is emerging as a promising approach for fine-tuning VLMs to better adapt to local regions without requiring extensive annotations. However, previous state-of-the-art approaches often suffer from significant `foreground bias', where models tend to wrongly identify background regions as foreground objects. To alleviate this issue, we propose DenseVLM, a framework designed to learn unbiased region-language alignment from powerful pre-trained VLM representations. To alleviate this issue, we propose DenseVLM, a framework designed to learn unbiased region-language alignment from powerful pre-trained VLM representations. DenseVLM leverages the pre-trained VLM to retrieve categories for unlabeled regions and then decouples the interference between foreground and background features. We show that DenseVLM can directly replace the original VLM in open-vocabulary object detection and image segmentation methods, leading to notable performance improvements. Furthermore, it exhibits promising zero-shot scalability when training on more extensive and diverse datasets. Our code is available at https://github.com/HVision-NKU/DenseVLM.",
    "source": "arXiv"
  },
  {
    "title": "CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction",
    "title_es": "CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction",
    "url": "https://arxiv.org/abs/2412.06782",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.06782v3 Announce Type: replace \nAbstract: In robotic visuomotor policy learning, diffusion-based models have achieved significant success in improving the accuracy of action trajectory generation compared to traditional autoregressive models. However, they suffer from inefficiency due to multiple denoising steps and limited flexibility from complex constraints. In this paper, we introduce Coarse-to-Fine AutoRegressive Policy (CARP), a novel paradigm for visuomotor policy learning that redefines the autoregressive action generation process as a coarse-to-fine, next-scale approach. CARP decouples action generation into two stages: first, an action autoencoder learns multi-scale representations of the entire action sequence; then, a GPT-style transformer refines the sequence prediction through a coarse-to-fine autoregressive process. This straightforward and intuitive approach produces highly accurate and smooth actions, matching or even surpassing the performance of diffusion-based policies while maintaining efficiency on par with autoregressive policies. We conduct extensive evaluations across diverse settings, including single-task and multi-task scenarios on state-based and image-based simulation benchmarks, as well as real-world tasks. CARP achieves competitive success rates, with up to a 10% improvement, and delivers 10x faster inference compared to state-of-the-art policies, establishing a high-performance, efficient, and flexible paradigm for action generation in robotic tasks.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Multidimensional Checkworthiness: Designing AI-assisted Claim Prioritization for Human Fact-checkers",
    "title_es": "Exploring Multidimensional Checkworthiness: Designing AI-assisted Claim Prioritization for Human Fact-checkers",
    "url": "https://arxiv.org/abs/2412.08185",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.08185v3 Announce Type: replace \nAbstract: Given the volume of potentially false claims online, claim prioritization is essential in allocating limited human resources available for fact-checking. In this study, we perceive claim prioritization as an information retrieval (IR) task: just as multidimensional IR relevance, with many factors influencing which search results a user deems relevant, checkworthiness is also multi-faceted, subjective, and even personal, with many factors influencing how fact-checkers triage and select which claims to check. Our study investigates both the multidimensional nature of checkworthiness and effective tool support to assist fact-checkers in claim prioritization. Methodologically, we pursue Research through Design combined with mixed-method evaluation.\n  Specifically, we develop an AI-assisted claim prioritization prototype as a probe to explore how fact-checkers use multidimensional checkworthy factors to prioritize claims, simultaneously probing fact-checker needs and exploring the design space to meet those needs. With 16 professional fact-checkers participating in our study, we uncover a hierarchical prioritization strategy fact-checkers implicitly use, revealing an underexplored aspect of their workflow, with actionable design recommendations for improving claim triage across multidimensional checkworthiness and tailoring this process with LLM integration.",
    "source": "arXiv"
  },
  {
    "title": "B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal Tokens",
    "title_es": "B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal Tokens",
    "url": "https://arxiv.org/abs/2412.09919",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.09919v2 Announce Type: replace \nAbstract: Recently, Vision Large Language Models (VLLMs) integrated with vision encoders have shown promising performance in vision understanding. The key of VLLMs is to encode visual content into sequences of visual tokens, enabling VLLMs to simultaneously process both visual and textual content. However, understanding videos, especially long videos, remain a challenge to VLLMs as the number of visual tokens grows rapidly when encoding videos, resulting in the risk of exceeding the context window of VLLMs and introducing heavy computation burden. To restrict the number of visual tokens, existing VLLMs either: (1) uniformly downsample videos into a fixed number of frames or (2) reducing the number of visual tokens encoded from each frame. We argue the former solution neglects the rich temporal cue in videos and the later overlooks the spatial details in each frame. In this work, we present Balanced-VLLM (B-VLLM): a novel VLLM framework that aims to effectively leverage task relevant spatio-temporal cues while restricting the number of visual tokens under the VLLM context window length. At the core of our method, we devise a text-conditioned adaptive frame selection module to identify frames relevant to the visual understanding task. The selected frames are then de-duplicated using a temporal frame token merging technique. The visual tokens of the selected frames are processed through a spatial token sampling module and an optional spatial token merging strategy to achieve precise control over the token count. Experimental results show that B-VLLM is effective in balancing the number of frames and visual tokens in video understanding, yielding superior performance on various video understanding benchmarks. Our code is available at https://github.com/zhuqiangLu/B-VLLM.",
    "source": "arXiv"
  },
  {
    "title": "POEX: Towards Policy Executable Jailbreak Attacks Against the LLM-based Robots",
    "title_es": "POEX: Towards Policy Executable Jailbreak Attacks Against the LLM-based Robots",
    "url": "https://arxiv.org/abs/2412.16633",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.16633v3 Announce Type: replace \nAbstract: The integration of LLMs into robots has witnessed significant growth, where LLMs can convert instructions into executable robot policies. However, the inherent vulnerability of LLMs to jailbreak attacks brings critical security risks from the digital domain to the physical world. An attacked LLM-based robot could execute harmful policies and cause physical harm. In this paper, we investigate the feasibility and rationale of jailbreak attacks against LLM-based robots and answer three research questions: (1) How applicable are existing LLM jailbreak attacks against LLM-based robots? (2) What unique challenges arise if they are not directly applicable? (3) How to defend against such jailbreak attacks? To this end, we first construct a \"human-object-environment\" robot risks-oriented Harmful-RLbench and then conduct a measurement study on LLM-based robot systems. Our findings conclude that traditional LLM jailbreak attacks are inapplicable in robot scenarios, and we identify two unique challenges: determining policy-executable optimization directions and accurately evaluating robot-jailbroken policies. To enable a more thorough security analysis, we introduce POEX (POlicy EXecutable) jailbreak, a red-teaming framework that induces harmful yet executable policy to jailbreak LLM-based robots. POEX incorporates hidden layer gradient optimization to guarantee jailbreak success and policy execution as well as a multi-agent evaluator to accurately assess the practical executability of policies. Experiments conducted on the real-world robotic systems and in simulation demonstrate the efficacy of POEX, highlighting critical security vulnerabilities and its transferability across LLMs. Finally, we propose prompt-based and model-based defenses to mitigate attacks. Our findings underscore the urgent need for security measures to ensure the safe deployment of LLM-based robots in critical applications.",
    "source": "arXiv"
  },
  {
    "title": "TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction",
    "title_es": "TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction",
    "url": "https://arxiv.org/abs/2412.16919",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.16919v3 Announce Type: replace \nAbstract: We present TAR3D, a novel framework that consists of a 3D-aware Vector Quantized-Variational AutoEncoder (VQ-VAE) and a Generative Pre-trained Transformer (GPT) to generate high-quality 3D assets. The core insight of this work is to migrate the multimodal unification and promising learning capabilities of the next-token prediction paradigm to conditional 3D object generation. To achieve this, the 3D VQ-VAE first encodes a wide range of 3D shapes into a compact triplane latent space and utilizes a set of discrete representations from a trainable codebook to reconstruct fine-grained geometries under the supervision of query point occupancy. Then, the 3D GPT, equipped with a custom triplane position embedding called TriPE, predicts the codebook index sequence with prefilling prompt tokens in an autoregressive manner so that the composition of 3D geometries can be modeled part by part. Extensive experiments on ShapeNet and Objaverse demonstrate that TAR3D can achieve superior generation quality over existing methods in text-to-3D and image-to-3D tasks",
    "source": "arXiv"
  },
  {
    "title": "A Research Agenda for Usability and Generalisation in Reinforcement Learning",
    "title_es": "A Research Agenda for Usability and Generalisation in Reinforcement Learning",
    "url": "https://arxiv.org/abs/2412.16970",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.16970v2 Announce Type: replace \nAbstract: It is common practice in reinforcement learning (RL) research to train and deploy agents in bespoke simulators, typically implemented by engineers directly in general-purpose programming languages or hardware acceleration frameworks such as CUDA or JAX. This means that programming and engineering expertise is not only required to develop RL algorithms, but is also required to use already developed algorithms for novel problems. The latter poses a problem in terms of the usability of RL, in particular for private individuals and small organisations without substantial engineering expertise. We also perceive this as a challenge for effective generalisation in RL, in the sense that is no standard, shared formalism in which different problems are represented. As we typically have no consistent representation through which to provide information about any novel problem to an agent, our agents also cannot instantly or rapidly generalise to novel problems. In this position paper, we advocate for a research agenda centred around the use of user-friendly description languages for describing problems, such that (i) users with little to no engineering expertise can formally describe the problems they would like to be tackled by RL algorithms, and (ii) algorithms can leverage problem descriptions to effectively generalise among all problems describable in the language of choice.",
    "source": "arXiv"
  },
  {
    "title": "D-Judge: How Far Are We? Assessing the Discrepancies Between AI-synthesized and Natural Images through Multimodal Guidance",
    "title_es": "D-Judge: How Far Are We? Assessing the Discrepancies Between AI-synthesized and Natural Images through Multimodal Guidance",
    "url": "https://arxiv.org/abs/2412.17632",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.17632v4 Announce Type: replace \nAbstract: In the rapidly evolving field of Artificial Intelligence Generated Content (AIGC), a central challenge is distinguishing AI-synthesized images from natural ones. Despite the impressive capabilities of advanced generative models in producing visually compelling images, significant discrepancies remain when compared to natural images. To systematically investigate and quantify these differences, we construct a large-scale multimodal dataset, D-ANI, comprising 5,000 natural images and over 440,000 AIGI samples generated by nine representative models using both unimodal and multimodal prompts, including Text-to-Image (T2I), Image-to-Image (I2I), and Text-and-Image-to-Image (TI2I). We then introduce an AI-Natural Image Discrepancy assessment benchmark (D-Judge) to address the critical question: how far are AI-generated images (AIGIs) from truly realistic images? Our fine-grained evaluation framework assesses the D-ANI dataset across five dimensions: naive visual quality, semantic alignment, aesthetic appeal, downstream task applicability, and coordinated human validation. Extensive experiments reveal substantial discrepancies across these dimensions, highlighting the importance of aligning quantitative metrics with human judgment to achieve a comprehensive understanding of AI-generated image quality. Code: https://github.com/ryliu68/DJudge ; Data: https://huggingface.co/datasets/Renyang/DANI.",
    "source": "arXiv"
  },
  {
    "title": "Observation Interference in Partially Observable Assistance Games",
    "title_es": "Observation Interference in Partially Observable Assistance Games",
    "url": "https://arxiv.org/abs/2412.17797",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.17797v2 Announce Type: replace \nAbstract: We study partially observable assistance games (POAGs), a model of the human-AI value alignment problem which allows the human and the AI assistant to have partial observations. Motivated by concerns of AI deception, we study a qualitatively new phenomenon made possible by partial observability: would an AI assistant ever have an incentive to interfere with the human's observations? First, we prove that sometimes an optimal assistant must take observation-interfering actions, even when the human is playing optimally, and even when there are otherwise-equivalent actions available that do not interfere with observations. Though this result seems to contradict the classic theorem from single-agent decision making that the value of information is nonnegative, we resolve this seeming contradiction by developing a notion of interference defined on entire policies. This can be viewed as an extension of the classic result that the value of information is nonnegative into the cooperative multiagent setting. Second, we prove that if the human is simply making decisions based on their immediate outcomes, the assistant might need to interfere with observations as a way to query the human's preferences. We show that this incentive for interference goes away if the human is playing optimally, or if we introduce a communication channel for the human to communicate their preferences to the assistant. Third, we show that if the human acts according to the Boltzmann model of irrationality, this can create an incentive for the assistant to interfere with observations. Finally, we use an experimental model to analyze tradeoffs faced by the AI assistant in practice when considering whether or not to take observation-interfering actions.",
    "source": "arXiv"
  },
  {
    "title": "MomentMix Augmentation with Length-Aware DETR for Temporally Robust Moment Retrieval",
    "title_es": "MomentMix Augmentation with Length-Aware DETR for Temporally Robust Moment Retrieval",
    "url": "https://arxiv.org/abs/2412.20816",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.20816v2 Announce Type: replace \nAbstract: Video Moment Retrieval (MR) aims to localize moments within a video based on a given natural language query. Given the prevalent use of platforms like YouTube for information retrieval, the demand for MR techniques is significantly growing. Recent DETR-based models have made notable advances in performance but still struggle with accurately localizing short moments. Through data analysis, we identified limited feature diversity in short moments, which motivated the development of MomentMix. MomentMix employs two augmentation strategies: ForegroundMix and BackgroundMix, each enhancing the feature representations of the foreground and background, respectively. Additionally, our analysis of prediction bias revealed that short moments particularly struggle with accurately predicting their center positions of moments. To address this, we propose a Length-Aware Decoder, which conditions length through a novel bipartite matching process. Our extensive studies demonstrate the efficacy of our length-aware approach, especially in localizing short moments, leading to improved overall performance. Our method surpasses state-of-the-art DETR-based methods on benchmark datasets, achieving the highest R1 and mAP on QVHighlights and the highest R1@0.7 on TACoS and Charades-STA (such as a 2.46% gain in R1@0.7 and a 2.57% gain in mAP average for QVHighlights). The code is available at https://github.com/sjpark5800/LA-DETR.",
    "source": "arXiv"
  },
  {
    "title": "Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense",
    "title_es": "Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense",
    "url": "https://arxiv.org/abs/2412.21051",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.21051v3 Announce Type: replace \nAbstract: The rapid evolution of cloud computing technologies and the increasing number of cloud applications have provided numerous benefits in our daily lives. However, the diversity and complexity of different components pose a significant challenge to cloud security, especially when dealing with sophisticated and advanced cyberattacks such as Denial of Service (DoS). Recent advancements in the large language models (LLMs) offer promising solutions for security intelligence. By exploiting the powerful capabilities in language understanding, data analysis, task inference, action planning, and code generation, we present LLM-PD, a novel defense architecture that proactively mitigates various DoS threats in cloud networks. LLM-PD can efficiently make decisions through comprehensive data analysis and sequential reasoning, as well as dynamically create and deploy actionable defense mechanisms. Furthermore, it can flexibly self-evolve based on experience learned from previous interactions and adapt to new attack scenarios without additional training. Our case study on three distinct DoS attacks demonstrates its remarkable ability in terms of defense effectiveness and efficiency when compared with other existing methods.",
    "source": "arXiv"
  },
  {
    "title": "Global Compression Commander: Plug-and-Play Inference Acceleration for High-Resolution Large Vision-Language Models",
    "title_es": "Global Compression Commander: Plug-and-Play Inference Acceleration for High-Resolution Large Vision-Language Models",
    "url": "https://arxiv.org/abs/2501.05179",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.05179v5 Announce Type: replace \nAbstract: Large vision-language models (LVLMs) excel at visual understanding, but face efficiency challenges due to quadratic complexity in processing long multi-modal contexts. While token compression can reduce computational costs, existing approaches are designed for single-view LVLMs and fail to consider the unique multi-view characteristics of high-resolution LVLMs with dynamic cropping. Existing methods treat all tokens uniformly, but our analysis reveals that global thumbnails can naturally guide the compression of local crops by providing holistic context for informativeness evaluation. In this paper, we first analyze dynamic cropping strategy, revealing both the complementary nature between thumbnails and crops, and the distinctive characteristics across different crops. Based on our observations, we propose \"Global Compression Commander\" (GlobalCom$^2$), a novel plug-and-play token compression framework for HR-LVLMs. GlobalCom$^2$ leverages thumbnail as the \"commander\" to guide the compression of local crops, adaptively preserving informative details while eliminating redundancy. Extensive experiments show that GlobalCom$^2$ maintains over 90% performance while compressing 90% visual tokens, reducing FLOPs and peak memory to 9.1% and 60%. Our code is available at https://github.com/xuyang-liu16/GlobalCom2.",
    "source": "arXiv"
  },
  {
    "title": "A Direct Proof of the Short-Side Advantage in Random Matching Markets",
    "title_es": "A Direct Proof of the Short-Side Advantage in Random Matching Markets",
    "url": "https://arxiv.org/abs/2501.05574",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.05574v2 Announce Type: replace \nAbstract: We study the stable matching problem under the random matching model where the preferences of the doctors and hospitals are sampled uniformly and independently at random. In a balanced market with $n$ doctors and $n$ hospitals, the doctor-proposal deferred-acceptance algorithm gives doctors an expected rank of order $\\log n$ for their partners and hospitals an expected rank of order $\\frac{n}{\\log n}$ for their partners. This situation is reversed in an unbalanced market with $n+1$ doctors and $n$ hospitals, a phenomenon known as the short-side advantage. The current proofs of this fact are indirect, counter-intuitively being based upon analyzing the hospital-proposal deferred-acceptance algorithm. In this paper we provide a direct proof of the short-side advantage, explicitly analyzing the doctor-proposal deferred-acceptance algorithm. Our proof sheds light on how and why the phenomenon arises.",
    "source": "arXiv"
  },
  {
    "title": "Semantic Mapping in Indoor Embodied AI -- A Survey on Advances, Challenges, and Future Directions",
    "title_es": "Semantic Mapping in Indoor Embodied AI -- A Survey on Advances, Challenges, and Future Directions",
    "url": "https://arxiv.org/abs/2501.05750",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.05750v3 Announce Type: replace \nAbstract: Intelligent embodied agents (e.g. robots) need to perform complex semantic tasks in unfamiliar environments. Among many skills that the agents need to possess, building and maintaining a semantic map of the environment is most crucial in long-horizon tasks. A semantic map captures information about the environment in a structured way, allowing the agent to reference it for advanced reasoning throughout the task. While existing surveys in embodied AI focus on general advancements or specific tasks like navigation and manipulation, this paper provides a comprehensive review of semantic map-building approaches in embodied AI, specifically for indoor navigation. We categorize these approaches based on their structural representation (spatial grids, topological graphs, dense point-clouds or hybrid maps) and the type of information they encode (implicit features or explicit environmental data). We also explore the strengths and limitations of the map building techniques, highlight current challenges, and propose future research directions. We identify that the field is moving towards developing open-vocabulary, queryable, task-agnostic map representations, while high memory demands and computational inefficiency still remaining to be open challenges. This survey aims to guide current and future researchers in advancing semantic mapping techniques for embodied AI systems.",
    "source": "arXiv"
  },
  {
    "title": "Recommender Systems for Social Good: The Role of Accountability and Sustainability",
    "title_es": "Recommender Systems for Social Good: The Role of Accountability and Sustainability",
    "url": "https://arxiv.org/abs/2501.05964",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.05964v2 Announce Type: replace \nAbstract: This work examines the role of recommender systems in promoting sustainability, social responsibility, and accountability, with a focus on alignment with the United Nations Sustainable Development Goals (SDGs). As recommender systems become increasingly integrated into daily interactions, they must go beyond personalization to support responsible consumption, reduce environmental impact, and foster social good. We explore strategies to mitigate the carbon footprint of recommendation models, ensure fairness, and implement accountability mechanisms. By adopting these approaches, recommender systems can contribute to sustainable and socially beneficial outcomes, aligning technological advancements with the SDGs focused on environmental sustainability and social well-being.",
    "source": "arXiv"
  },
  {
    "title": "Generative AI for Cel-Animation: A Survey",
    "title_es": "Generative AI for Cel-Animation: A Survey",
    "url": "https://arxiv.org/abs/2501.06250",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.06250v3 Announce Type: replace \nAbstract: Traditional Celluloid (Cel) Animation production pipeline encompasses multiple essential steps, including storyboarding, layout design, keyframe animation, inbetweening, and colorization, which demand substantial manual effort, technical expertise, and significant time investment. These challenges have historically impeded the efficiency and scalability of Cel-Animation production. The rise of generative artificial intelligence (GenAI), encompassing large language models, multimodal models, and diffusion models, offers innovative solutions by automating tasks such as inbetween frame generation, colorization, and storyboard creation. This survey explores how GenAI integration is revolutionizing traditional animation workflows by lowering technical barriers, broadening accessibility for a wider range of creators through tools like AniDoc, ToonCrafter, and AniSora, and enabling artists to focus more on creative expression and artistic innovation. Despite its potential, challenges like visual consistency, stylistic coherence, and ethical considerations persist. Additionally, this paper explores future directions and advancements in AI-assisted animation. For further exploration and resources, please visit our GitHub repository: https://github.com/yunlong10/Awesome-AI4Animation",
    "source": "arXiv"
  },
  {
    "title": "WebWalker: Benchmarking LLMs in Web Traversal",
    "title_es": "WebWalker: Benchmarking LLMs in Web Traversal",
    "url": "https://arxiv.org/abs/2501.07572",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.07572v3 Announce Type: replace \nAbstract: Retrieval-augmented generation (RAG) demonstrates remarkable performance across tasks in open-domain question-answering. However, traditional search engines may retrieve shallow content, limiting the ability of LLMs to handle complex, multi-layered information. To address it, we introduce WebWalkerQA, a benchmark designed to assess the ability of LLMs to perform web traversal. It evaluates the capacity of LLMs to traverse a website's subpages to extract high-quality data systematically. We propose WebWalker, which is a multi-agent framework that mimics human-like web navigation through an explore-critic paradigm. Extensive experimental results show that WebWalkerQA is challenging and demonstrates the effectiveness of RAG combined with WebWalker, through the horizontal and vertical integration in real-world scenarios.",
    "source": "arXiv"
  },
  {
    "title": "DAViD: Modeling Dynamic Affordance of 3D Objects Using Pre-trained Video Diffusion Models",
    "title_es": "DAViD: Modeling Dynamic Affordance of 3D Objects Using Pre-trained Video Diffusion Models",
    "url": "https://arxiv.org/abs/2501.08333",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.08333v3 Announce Type: replace \nAbstract: Modeling how humans interact with objects is crucial for AI to effectively assist or mimic human behaviors. Existing studies for learning such ability primarily focus on static human-object interaction (HOI) patterns, such as contact and spatial relationships, while dynamic HOI patterns, capturing the movement of humans and objects over time, remain relatively underexplored. In this paper, we present a novel framework for learning Dynamic Affordance across various target object categories. To address the scarcity of 4D HOI datasets, our method learns the 3D dynamic affordance from synthetically generated 4D HOI samples. Specifically, we propose a pipeline that first generates 2D HOI videos from a given 3D target object using a pre-trained video diffusion model, then lifts them into 3D to generate 4D HOI samples. Leveraging these synthesized 4D HOI samples, we train DAViD, our generative 4D human-object interaction model, which is composed of two key components: (1) a human motion diffusion model (MDM) with Low-Rank Adaptation (LoRA) module to fine-tune a pre-trained MDM to learn the HOI motion concepts from limited HOI motion samples, (2) a motion diffusion model for 4D object poses conditioned by produced human interaction motions. Interestingly, DAViD can integrate newly learned HOI motion concepts with pre-trained human motions to create novel HOI motions, even for multiple HOI motion concepts, demonstrating the advantage of our pipeline with LoRA in integrating dynamic HOI concepts. Through extensive experiments, we demonstrate that DAViD outperforms baselines in synthesizing HOI motion.",
    "source": "arXiv"
  },
  {
    "title": "Scheduling Coflows for Minimizing the Maximum Completion Time in Heterogeneous Parallel Networks",
    "title_es": "Scheduling Coflows for Minimizing the Maximum Completion Time in Heterogeneous Parallel Networks",
    "url": "https://arxiv.org/abs/2501.09293",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.09293v2 Announce Type: replace \nAbstract: Coflow represents a network abstraction that models communication patterns within data centers. Scheduling coflows is a significant issue in large data center environments and is classified as an $\\mathcal{NP}$-hard problem. This paper focuses on the scheduling of coflows in heterogeneous parallel networks, which are characterized by architectures that feature multiple network cores operating simultaneously. We introduce two pseudo-polynomial-time algorithms and two polynomial-time approximation algorithms aimed at minimizing the maximum completion time, known as makespan, in these heterogeneous parallel networks. Our approach includes a randomized algorithm with an expected approximation ratio of 1.5. Building on this, we present a deterministic algorithm that employs derandomization techniques, offering a performance guarantee of $1.5 + \\frac{1}{2 \\cdot LB}$, where $LB$ is the lower bound of the makespan for each instance. To tackle concerns regarding time complexity, we implement an exponential partitioning of time intervals and propose a randomized algorithm with an expected approximation ratio of $1.5 + \\epsilon$ in polynomial time, where $\\epsilon>0$. Furthermore, we develop a deterministic algorithm with a performance guarantee of $1.5+\\frac{1}{2\\cdot LB}+\\epsilon$, also within polynomial time. When the flow size is sufficiently large, this algorithm can achieve an approximation ratio of $1.5+\\epsilon$. These advancements significantly improve the best-known approximation ratio, previously $2+\\epsilon$.",
    "source": "arXiv"
  },
  {
    "title": "Aligning Instruction Tuning with Pre-training",
    "title_es": "Aligning Instruction Tuning with Pre-training",
    "url": "https://arxiv.org/abs/2501.09368",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.09368v4 Announce Type: replace \nAbstract: Instruction tuning enhances large language models (LLMs) to follow human instructions across diverse tasks, relying on high-quality datasets to guide behavior. However, these datasets, whether manually curated or synthetically generated, are often narrowly focused and misaligned with the broad distributions captured during pre-training, limiting LLM generalization and effective use of pre-trained knowledge. We propose Aligning Instruction Tuning with Pre-training (AITP), a method that bridges this gap by identifying coverage shortfalls in instruction-tuning datasets and rewriting underrepresented pre-training data into high-quality instruction-response pairs. This approach enriches dataset diversity while preserving task-specific objectives. Evaluations on three fully open LLMs across eight benchmarks demonstrate consistent performance improvements with AITP. Ablations highlight the benefits of adaptive data selection, controlled rewriting, and balanced integration, emphasizing the importance of aligning instruction tuning with pre-training distributions to unlock the full potential of LLMs.",
    "source": "arXiv"
  },
  {
    "title": "$\\ell_0$-Regularized Quadratic Surface Support Vector Machines",
    "title_es": "$\\ell_0$-Regularized Quadratic Surface Support Vector Machines",
    "url": "https://arxiv.org/abs/2501.11268",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.11268v3 Announce Type: replace \nAbstract: Kernel-free quadratic surface support vector machines have recently gained traction due to their flexibility in modeling nonlinear decision boundaries without relying on kernel functions. However, the introduction of a full quadratic classifier significantly increases the number of model parameters, scaling quadratically with data dimensionality, which often leads to overfitting and makes interpretation difficult. To address these challenges, we propose a sparse variant of the QSVM by enforcing a cardinality constraint on the model parameters. While enhancing generalization and promoting sparsity, leveraging the $\\ell_0$-norm inevitably incurs additional computational complexity. To tackle this, we develop a penalty decomposition algorithm capable of producing solutions that provably satisfy the first-order Lu-Zhang optimality conditions. Our approach accommodates both hinge and quadratic loss functions. In both cases, we demonstrate that the subproblems arising within the algorithm either admit closed-form solutions or can be solved efficiently through dual formulations, which contributes to the method's overall effectiveness. We also analyze the convergence behavior of the algorithm under both loss settings. Finally, we validate our approach on several real-world datasets, demonstrating its ability to reduce overfitting while maintaining strong classification performance. The complete implementation and experimental code are publicly available at https://github.com/raminzandvakili/L0-QSVM.",
    "source": "arXiv"
  },
  {
    "title": "DWTNeRF: Boosting Few-shot Neural Radiance Fields via Discrete Wavelet Transform",
    "title_es": "DWTNeRF: Boosting Few-shot Neural Radiance Fields via Discrete Wavelet Transform",
    "url": "https://arxiv.org/abs/2501.12637",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.12637v3 Announce Type: replace \nAbstract: Neural Radiance Fields (NeRF) has achieved superior performance in novel view synthesis and 3D scene representation, but its practical applications are hindered by slow convergence and reliance on dense training views. To this end, we present DWTNeRF, a unified framework based on Instant-NGP's fast-training hash encoding. It is coupled with regularization terms designed for few-shot NeRF, which operates on sparse training views. Our DWTNeRF additionally includes a novel Discrete Wavelet loss that allows explicit prioritization of low frequencies directly in the training objective, reducing few-shot NeRF's overfitting on high frequencies in earlier training stages. We also introduce a model-based approach, based on multi-head attention, that is compatible with INGP, which are sensitive to architectural changes. On the 3-shot LLFF benchmark, DWTNeRF outperforms Vanilla INGP by 15.07% in PSNR, 24.45% in SSIM and 36.30% in LPIPS. Our approach encourages a re-thinking of current few-shot approaches for fast-converging implicit representations like INGP or 3DGS.",
    "source": "arXiv"
  },
  {
    "title": "Ehrenfeucht-Haussler Rank and Chain of Thought",
    "title_es": "Ehrenfeucht-Haussler Rank and Chain of Thought",
    "url": "https://arxiv.org/abs/2501.12997",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.12997v2 Announce Type: replace \nAbstract: The notion of \\emph{rank} of a Boolean function has been a cornerstone in PAC learning theory, enabling quasipolynomial-time learning algorithms for polynomial-size decision trees. We present a novel characterization of rank, grounded in the well-known Transformer architecture. We show that the rank of a function $f$ corresponds to the minimum number of \\emph{Chain of Thought} (CoT) steps required by a single-layer Transformer with hard attention to compute $f$. Based on this characterization we establish tight bounds on the number of CoT steps required for specific problems, showing that \\(\\ell\\)-fold function composition necessitates exactly \\(\\ell\\) CoT steps. Furthermore, we analyze the problem of identifying the position of the \\(k\\)-th occurrence of 1 in a Boolean sequence, proving that it requires \\(k\\) CoT steps. Finally, we introduce the notion of the multi-head rank that captures multi-head single-layer transformers, and perform the analysis of PAC-learnability of the classes of functions with bounded multi-head rank.",
    "source": "arXiv"
  },
  {
    "title": "Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models",
    "title_es": "Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models",
    "url": "https://arxiv.org/abs/2501.13428",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.13428v4 Announce Type: replace \nAbstract: Large language models have achieved remarkable success in recent years, primarily due to the implementation of self-attention mechanisms. However, traditional Softmax attention suffers from numerical instability and reduced performance as the length of inference tokens increases. This paper addresses these issues by proposing a new design principle for attention, viewing it as a two-stage process. We first decompose the Softmax operation into a non-linear positivity transformation and an $l_1$-normalisation step, identifying the latter as essential for maintaining model performance. In the first stage, we replace the standard exponential function with the more numerically stable Softplus activation and introduce a dynamic scale factor based on invariance entropy, creating a novel attention mechanism that outperforms conventional Softmax attention. In the second stage, we introduce a re-weighting mechanism that sharpens the attention distribution, amplifying significant weights while diminishing weaker ones. This enables the model to concentrate more effectively on relevant tokens and fundamentally improves length extrapolation. When combined, this two-stage approach ensures numerical stability and dramatically improves length extrapolation, maintaining a nearly constant validation loss at 16$\\times$ the training length while achieving superior results on challenging long-context retrieval tasks and standard downstream benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Unveiling the Potential of iMarkers: Invisible Fiducial Markers for Advanced Robotics",
    "title_es": "Unveiling the Potential of iMarkers: Invisible Fiducial Markers for Advanced Robotics",
    "url": "https://arxiv.org/abs/2501.15505",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.15505v4 Announce Type: replace \nAbstract: Fiducial markers are widely used in various robotics tasks, facilitating enhanced navigation, object recognition, and scene understanding. Despite their advantages for robots and Augmented Reality (AR) applications, they often disrupt the visual aesthetics of environments because they are visible to humans, making them unsuitable for non-intrusive use cases. To address this gap, this paper presents \"iMarkers\"-innovative, unobtrusive fiducial markers detectable exclusively by robots equipped with specialized sensors. These markers offer high flexibility in production, allowing customization of their visibility range and encoding algorithms to suit various demands. The paper also introduces the hardware designs and software algorithms developed for detecting iMarkers, highlighting their adaptability and robustness in the detection and recognition stages. Various evaluations have demonstrated the effectiveness of iMarkers compared to conventional (printed) and blended fiducial markers and confirmed their applicability in diverse robotics scenarios.",
    "source": "arXiv"
  },
  {
    "title": "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint",
    "title_es": "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint",
    "url": "https://arxiv.org/abs/2501.15509",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.15509v4 Announce Type: replace \nAbstract: Model fingerprinting is a widely adopted approach to safeguard the intellectual property rights of open-source models by preventing their unauthorized reuse. It is promising and convenient since it does not necessitate modifying the protected model. In this paper, we revisit existing fingerprinting methods and reveal that they are vulnerable to false claim attacks where adversaries falsely assert ownership of any third-party model. We demonstrate that this vulnerability mostly stems from their untargeted nature, where they generally compare the outputs of given samples on different models instead of the similarities to specific references. Motivated by these findings, we propose a targeted fingerprinting paradigm (i.e., FIT-Print) to counteract false claim attacks. Specifically, FIT-Print transforms the fingerprint into a targeted signature via optimization. Building on the principles of FIT-Print, we develop bit-wise and list-wise black-box model fingerprinting methods, i.e., FIT-ModelDiff and FIT-LIME, which exploit the distance between model outputs and the feature attribution of specific samples as the fingerprint, respectively. Extensive experiments on benchmark models and datasets verify the effectiveness, conferrability, and resistance to false claim attacks of our FIT-Print.",
    "source": "arXiv"
  },
  {
    "title": "MatCLIP: Light- and Shape-Insensitive Assignment of PBR Material Models",
    "title_es": "MatCLIP: Light- and Shape-Insensitive Assignment of PBR Material Models",
    "url": "https://arxiv.org/abs/2501.15981",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.15981v2 Announce Type: replace \nAbstract: Assigning realistic materials to 3D models remains a significant challenge in computer graphics. We propose MatCLIP, a novel method that extracts shape- and lighting-insensitive descriptors of Physically Based Rendering (PBR) materials to assign plausible textures to 3D objects based on images, such as the output of Latent Diffusion Models (LDMs) or photographs. Matching PBR materials to static images is challenging because the PBR representation captures the dynamic appearance of materials under varying viewing angles, shapes, and lighting conditions. By extending an Alpha-CLIP-based model on material renderings across diverse shapes and lighting, and encoding multiple viewing conditions for PBR materials, our approach generates descriptors that bridge the domains of PBR representations with photographs or renderings, including LDM outputs. This enables consistent material assignments without requiring explicit knowledge of material relationships between different parts of an object. MatCLIP achieves a top-1 classification accuracy of 76.6%, outperforming state-of-the-art methods such as PhotoShape and MatAtlas by over 15 percentage points on publicly available datasets. Our method can be used to construct material assignments for 3D shape datasets such as ShapeNet, 3DCoMPaT++, and Objaverse. All code and data will be released.",
    "source": "arXiv"
  },
  {
    "title": "CITYWALK: Enhancing LLM-Based C++ Unit Test Generation via Project-Dependency Awareness and Language-Specific Knowledge",
    "title_es": "CITYWALK: Enhancing LLM-Based C++ Unit Test Generation via Project-Dependency Awareness and Language-Specific Knowledge",
    "url": "https://arxiv.org/abs/2501.16155",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.16155v2 Announce Type: replace \nAbstract: Unit testing plays a pivotal role in the software development lifecycle, as it ensures code quality. However, writing high-quality unit tests remains a time-consuming task for developers in practice. More recently, the application of large language models (LLMs) in automated unit test generation has demonstrated promising results. Existing approaches primarily focus on interpreted programming languages (e.g., Java), while mature solutions tailored to compiled programming languages like C++ are yet to be explored. The intricate language features of C++, such as pointers, templates, and virtual functions, pose particular challenges for LLMs in generating both executable and high-coverage unit tests. To tackle the aforementioned problems, this paper introduces CITYWALK, a novel LLM-based framework for C++ unit test generation. CITYWALK enhances LLMs by providing a comprehensive understanding of the dependency relationships within the project under test via program analysis. Furthermore, CITYWALK incorporates language-specific knowledge about C++ derived from project documentation and empirical observations, significantly improving the correctness of the LLM-generated unit tests. We implement CITYWALK by employing the widely popular LLM GPT-4o. The experimental results show that CITYWALK outperforms current state-of-the-art approaches on a collection of ten popular C++ projects. Our findings demonstrate the effectiveness of CITYWALK in generating high-quality C++ unit tests.",
    "source": "arXiv"
  },
  {
    "title": "Improving Your Model Ranking on Chatbot Arena by Vote Rigging",
    "title_es": "Improving Your Model Ranking on Chatbot Arena by Vote Rigging",
    "url": "https://arxiv.org/abs/2501.17858",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.17858v2 Announce Type: replace \nAbstract: Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles, where users vote for their preferred response from two randomly sampled anonymous models. While Chatbot Arena is widely regarded as a reliable LLM ranking leaderboard, we show that crowdsourced voting can be rigged to improve (or decrease) the ranking of a target model $m_{t}$. We first introduce a straightforward target-only rigging strategy that focuses on new battles involving $m_{t}$, identifying it via watermarking or a binary classifier, and exclusively voting for $m_{t}$ wins. However, this strategy is practically inefficient because there are over $190$ models on Chatbot Arena and on average only about $1\\%$ of new battles will involve $m_{t}$. To overcome this, we propose omnipresent rigging strategies, exploiting the Elo rating mechanism of Chatbot Arena that any new vote on a battle can influence the ranking of the target model $m_{t}$, even if $m_{t}$ is not directly involved in the battle. We conduct experiments on around $1.7$ million historical votes from the Chatbot Arena Notebook, showing that omnipresent rigging strategies can improve model rankings by rigging only hundreds of new votes. While we have evaluated several defense mechanisms, our findings highlight the importance of continued efforts to prevent vote rigging. Our code is available at https://github.com/sail-sg/Rigging-ChatbotArena.",
    "source": "arXiv"
  },
  {
    "title": "StructuredField: Unifying Structured Geometry and Radiance Field",
    "title_es": "StructuredField: Unifying Structured Geometry and Radiance Field",
    "url": "https://arxiv.org/abs/2501.18152",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.18152v2 Announce Type: replace \nAbstract: Recent point-based differentiable rendering techniques have achieved significant success in high-fidelity reconstruction and fast rendering. However, due to the unstructured nature of point-based representations, they are difficult to apply to modern graphics pipelines designed for structured meshes, as well as to a variety of simulation and editing algorithms that work well with structured mesh representations. To this end, we propose StructuredField, a novel representation that achieves both a structured geometric representation of the reconstructed object and high-fidelity rendering reconstruction. We employ structured tetrahedral meshes to represent the reconstructed object. We reparameterize the geometric attributes of these tetrahedra into the parameters of 3D Gaussian primitives, thereby enabling differentiable, high-fidelity rendering directly from the mesh. Furthermore, a hierarchical implicit subdivision strategy is utilized to ensure a conformal mesh structure while empowering the representation to capture multi-scale details. To maintain geometric integrity during optimization, we propose a novel inversion-free homeomorphism that constrains the tetrahedral mesh, guaranteeing it remains both inversion-free and self-intersection-free during the optimization process and in the final result. Based on our proposed StructuredField, we achieve high-quality structured meshes that are completely inversion-free and conformal, while also attaining reconstruction results comparable to those of 3DGS. We also demonstrate the applicability of our representation to various applications such as physical simulation, deformation, and level-of-detail.",
    "source": "arXiv"
  },
  {
    "title": "chebgreen: Learning and Interpolating Continuous Empirical Green's Functions from Data",
    "title_es": "chebgreen: Learning and Interpolating Continuous Empirical Green's Functions from Data",
    "url": "https://arxiv.org/abs/2501.18715",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.18715v4 Announce Type: replace \nAbstract: In this work, we present a mesh-independent, data-driven library, chebgreen, to mathematically model one-dimensional systems, possessing an associated control parameter, and whose governing partial differential equation is unknown. The proposed method learns an Empirical Green's Function for the associated, but hidden, boundary value problem, in the form of a Rational Neural Network from which we subsequently construct a bivariate representation in a Chebyshev basis. We uncover the Green's function, at an unseen control parameter value, by interpolating the left and right singular functions within a suitable library, expressed as points on a manifold of Quasimatrices, while the associated singular values are interpolated with Lagrange polynomials.",
    "source": "arXiv"
  },
  {
    "title": "Preconditioning without a preconditioner: faster ridge-regression and Gaussian sampling with randomized block Krylov subspace methods",
    "title_es": "Preconditioning without a preconditioner: faster ridge-regression and Gaussian sampling with randomized block Krylov subspace methods",
    "url": "https://arxiv.org/abs/2501.18717",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.18717v2 Announce Type: replace \nAbstract: We describe a randomized variant of the block conjugate gradient method for solving a single positive-definite linear system of equations. Our method provably outperforms preconditioned conjugate gradient with a broad-class of Nystr\\\"om-based preconditioners, without ever explicitly constructing a preconditioner. In analyzing our algorithm, we derive theoretical guarantees for new variants of Nystr\\\"om preconditioned conjugate gradient which may be of separate interest. We also describe how our approach yields state-of-the-art algorithms for key data-science tasks such as computing the entire ridge regression regularization path and generating multiple independent samples from a high-dimensional Gaussian distribution.",
    "source": "arXiv"
  },
  {
    "title": "Covering Multiple Objectives with a Small Set of Solutions Using Bayesian Optimization",
    "title_es": "Covering Multiple Objectives with a Small Set of Solutions Using Bayesian Optimization",
    "url": "https://arxiv.org/abs/2501.19342",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.19342v3 Announce Type: replace \nAbstract: In multi-objective black-box optimization, the goal is typically to find solutions that optimize a set of $T$ black-box objective functions, $f_1$, ..., $f_T$, simultaneously. Traditional approaches often seek a single Pareto-optimal set that balances trade-offs among all objectives. In this work, we consider a problem setting that departs from this paradigm: finding a small set of K < T solutions, that collectively \"covers\" the T objectives. A set of solutions is defined as \"covering\" if, for each objective $f_1$, ..., $f_T$, there is at least one good solution. A motivating example for this problem setting occurs in drug design. For example, we may have T pathogens and aim to identify a set of K < T antibiotics such that at least one antibiotic can be used to treat each pathogen. To address this problem, we propose Multi-Objective Coverage Bayesian Optimization (MOCOBO), a principled algorithm designed to efficiently find a covering set. We validate our approach through experiments on challenging high-dimensional tasks, including applications in peptide and molecular design, where MOCOBO is shown to find high-performing covering sets of solutions. The results show that the coverage of the K < T solutions found by MOCOBO matches or nearly matches the coverage of T solutions obtained by optimizing each objective individually. Furthermore, in in vitro experiments, the peptides found by MOCOBO exhibited high potency against drug-resistant pathogens, further demonstrating the potential of MOCOBO for drug discovery. We make code available here: https://github.com/nataliemaus/mocobo.",
    "source": "arXiv"
  },
  {
    "title": "Mitigating Traffic Oscillations in Mixed Traffic Flow with Scalable Deep Koopman Predictive Control",
    "title_es": "Mitigating Traffic Oscillations in Mixed Traffic Flow with Scalable Deep Koopman Predictive Control",
    "url": "https://arxiv.org/abs/2502.00043",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.00043v3 Announce Type: replace \nAbstract: Mitigating traffic oscillations in mixed flows of connected automated vehicles (CAVs) and human-driven vehicles (HDVs) is critical for enhancing traffic stability. A key challenge lies in modeling the nonlinear, heterogeneous behaviors of HDVs within computationally tractable predictive control frameworks. This study proposes an adaptive deep Koopman predictive control framework (AdapKoopPC) to address this issue. The framework features a novel deep Koopman network, AdapKoopnet, which represents complex HDV car-following dynamics as a linear system in a high-dimensional space by adaptively learning from naturalistic data. This learned linear representation is then embedded into a Model Predictive Control (MPC) scheme, enabling real-time, scalable, and optimal control of CAVs. We validate our framework using the HighD dataset and extensive numerical simulations. Results demonstrate that AdapKoopnet achieves superior trajectory prediction accuracy over baseline models. Furthermore, the complete AdapKoopPC controller significantly dampens traffic oscillations with lower computational cost, exhibiting strong performance even at low CAV penetration rates. The proposed framework offers a scalable and data-driven solution for enhancing stability in realistic mixed traffic environments. The code is made publicly available.",
    "source": "arXiv"
  },
  {
    "title": "A Differentiated Reward Method for Reinforcement Learning based Multi-Vehicle Cooperative Decision-Making Algorithms",
    "title_es": "A Differentiated Reward Method for Reinforcement Learning based Multi-Vehicle Cooperative Decision-Making Algorithms",
    "url": "https://arxiv.org/abs/2502.00352",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.00352v3 Announce Type: replace \nAbstract: Reinforcement learning (RL) shows great potential for optimizing multi-vehicle cooperative driving strategies through the state-action-reward feedback loop, but it still faces challenges such as low sample efficiency. This paper proposes a differentiated reward method based on steady-state transition systems, which incorporates state transition gradient information into the reward design by analyzing traffic flow characteristics, aiming to optimize action selection and policy learning in multi-vehicle cooperative decision-making. The performance of the proposed method is validated in RL algorithms such as MAPPO, MADQN, and QMIX under varying autonomous vehicle penetration. The results show that the differentiated reward method significantly accelerates training convergence and outperforms centering reward and others in terms of traffic efficiency, safety, and action rationality. Additionally, the method demonstrates strong scalability and environmental adaptability, providing a novel approach for multi-agent cooperative decision-making in complex traffic scenarios.",
    "source": "arXiv"
  },
  {
    "title": "MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization",
    "title_es": "MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization",
    "url": "https://arxiv.org/abs/2502.00425",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.00425v2 Announce Type: replace \nAbstract: Multimodal large language models (MLLMs) have garnered widespread attention due to their ability to understand multimodal input. However, their large parameter sizes and substantial computational demands severely hinder their practical deployment and application.While quantization is an effective way to reduce model size and inference latency, its application to MLLMs remains underexplored. In this paper, we propose MQuant, a post-training quantization (PTQ) framework designed to tackle the unique challenges of multimodal large language models (MLLMs). Conventional quantization often struggles with MLLMs because of (a) high inference latency from large visual token counts, (b) distributional disparities between visual and textual tokens, and (c) extreme outliers introduced by Hadamard-based transformations. To address these issues, MQuant introduces: Modality-Specific Static Quantization (MSQ), assigning distinct static scales for visual vs. textual tokens; Attention-Invariant Flexible Switching (AIFS), reordering tokens to preserve casual attention while eliminating expensive token-wise scale computations; Rotation Magnitude Suppression (RMS), mitigating weight outliers arising from online Hadamard rotations. On five mainstream MLLMs (including Qwen-VL, MiniCPM-V, CogVLM2), MQuant under W4A8 achieves near-floating-point accuracy (<1% degradation) while reducing inference latency by up to 30%, significantly outperforming existing PTQ baselines. Our MQuant effectively bridges the gap for efficient and accurate MLLMs inference in resource-constrained devices. Code has been released in https://github.com/StiphyJay/MQuant.",
    "source": "arXiv"
  },
  {
    "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "title_es": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "url": "https://arxiv.org/abs/2502.01105",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.01105v2 Announce Type: replace \nAbstract: Generating cognitive-aligned layered SVGs remains challenging due to existing methods' tendencies toward either oversimplified single-layer outputs or optimization-induced shape redundancies. We propose LayerTracer, a diffusion transformer based framework that bridges this gap by learning designers' layered SVG creation processes from a novel dataset of sequential design operations. Our approach operates in two phases: First, a text-conditioned DiT generates multi-phase rasterized construction blueprints that simulate human design workflows. Second, layer-wise vectorization with path deduplication produces clean, editable SVGs. For image vectorization, we introduce a conditional diffusion mechanism that encodes reference images into latent tokens, guiding hierarchical reconstruction while preserving structural integrity. Extensive experiments demonstrate LayerTracer's superior performance against optimization-based and neural baselines in both generation quality and editability, effectively aligning AI-generated vectors with professional design cognition.",
    "source": "arXiv"
  },
  {
    "title": "ReGLA: Refining Gated Linear Attention",
    "title_es": "ReGLA: Refining Gated Linear Attention",
    "url": "https://arxiv.org/abs/2502.01578",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.01578v3 Announce Type: replace \nAbstract: Recent advancements in Large Language Models (LLMs) have set themselves apart with their exceptional performance in complex language modelling tasks. However, these models are also known for their significant computational and storage requirements, primarily due to the quadratic computation complexity of softmax attention. To mitigate this issue, linear attention has been designed to reduce the quadratic space-time complexity that is inherent in standard transformers. In this work, we embarked on a comprehensive exploration of three key components that substantially impact the performance of the Gated Linear Attention module: feature maps, normalization, and the gating mechanism. We developed a feature mapping function to address some crucial issues that previous suggestions overlooked. Then we offered further rationale for the integration of normalization layers to stabilize the training process. Moreover, we explored the saturation phenomenon of the gating mechanism and augmented it with a refining module. We conducted extensive experiments and showed our architecture outperforms previous Gated Linear Attention mechanisms in extensive tasks including training from scratch and post-linearization with continual pre-training.",
    "source": "arXiv"
  },
  {
    "title": "Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs",
    "title_es": "Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs",
    "url": "https://arxiv.org/abs/2502.01926",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.01926v3 Announce Type: replace \nAbstract: Algorithmic fairness has conventionally adopted the mathematically convenient perspective of racial color-blindness (i.e., difference unaware treatment). However, we contend that in a range of important settings, group difference awareness matters. For example, differentiating between groups may be necessary in legal contexts (e.g., the U.S. compulsory draft applies to men but not women) and harm assessments (e.g., referring to girls as ``terrorists'' may be less harmful than referring to Muslim people as such). Thus, in contrast to most fairness work, we study fairness through the perspective of treating people differently -- when it is contextually appropriate to. We first introduce an important distinction between descriptive (fact-based), normative (value-based), and correlation (association-based) benchmarks. This distinction is significant because each category requires separate interpretation and mitigation tailored to its specific characteristics. Then, we present a benchmark suite composed of eight different scenarios for a total of 16k questions that enables us to assess difference awareness. Finally, we show results across ten models that demonstrate difference awareness is a distinct dimension to fairness where existing bias mitigation strategies may backfire.",
    "source": "arXiv"
  },
  {
    "title": "On the Emergence of Position Bias in Transformers",
    "title_es": "On the Emergence of Position Bias in Transformers",
    "url": "https://arxiv.org/abs/2502.01951",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.01951v4 Announce Type: replace \nAbstract: Recent studies have revealed various manifestations of position bias in transformer architectures, from the \"lost-in-the-middle\" phenomenon to attention sinks, yet a comprehensive theoretical understanding of how attention masks and positional encodings shape these biases remains elusive. This paper presents a graph-theoretic framework for analyzing position bias in multi-layer attention. Modeling attention masks as directed graphs, we quantify how tokens interact with contextual information based on their sequential positions. We uncover two key insights: First, causal masking inherently biases attention toward earlier positions, as tokens in deeper layers attend to increasingly more contextualized representations of earlier tokens. Second, we characterize the competing effects of the causal mask and relative positional encodings, such as the decay mask and rotary positional encoding (RoPE): while both mechanisms introduce distance-based decay within individual attention maps, their aggregate effect across multiple attention layers$\\unicode{x2013}$coupled with the causal mask$\\unicode{x2013}$leads to a trade-off between the long-term decay effects and the cumulative importance of early sequence positions. Through controlled numerical experiments, we not only validate our theoretical findings but also reproduce position biases observed in real-world LLMs. Our framework offers a principled foundation for understanding positional biases in transformers, shedding light on the complex interplay of attention mechanism components and guiding more informed architectural design.",
    "source": "arXiv"
  },
  {
    "title": "Schema-Guided Scene-Graph Reasoning based on Multi-Agent Large Language Model System",
    "title_es": "Schema-Guided Scene-Graph Reasoning based on Multi-Agent Large Language Model System",
    "url": "https://arxiv.org/abs/2502.03450",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.03450v2 Announce Type: replace \nAbstract: Scene graphs have emerged as a structured and serializable environment representation for grounded spatial reasoning with Large Language Models (LLMs). In this work, we propose SG^2, an iterative Schema-Guided Scene-Graph reasoning framework based on multi-agent LLMs. The agents are grouped into two modules: a (1) Reasoner module for abstract task planning and graph information queries generation, and a (2) Retriever module for extracting corresponding graph information based on code-writing following the queries. Two modules collaborate iteratively, enabling sequential reasoning and adaptive attention to graph information. The scene graph schema, prompted to both modules, serves to not only streamline both reasoning and retrieval process, but also guide the cooperation between two modules. This eliminates the need to prompt LLMs with full graph data, reducing the chance of hallucination due to irrelevant information. Through experiments in multiple simulation environments, we show that our framework surpasses existing LLM-based approaches and baseline single-agent, tool-based Reason-while-Retrieve strategy in numerical Q\\&A and planning tasks.",
    "source": "arXiv"
  },
  {
    "title": "Chaos into Order: Neural Framework for Expected Value Estimation of Stochastic Partial Differential Equations",
    "title_es": "Chaos into Order: Neural Framework for Expected Value Estimation of Stochastic Partial Differential Equations",
    "url": "https://arxiv.org/abs/2502.03670",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.03670v2 Announce Type: replace \nAbstract: Stochastic partial differential equations (SPDEs) describe the evolution of random processes over space and time, but their solutions are often analytically intractable and computationally expensive to estimate. In this paper, we propose the Learned Expectation Collapser (LEC), a physics-informed neural framework designed to approximate the expected value of linear SPDE solutions without requiring domain discretization. By leveraging randomized sampling of both space-time coordinates and noise realizations during training, LEC trains standard feedforward neural networks to minimize residual loss across multiple stochastic samples. We hypothesize and empirically confirm that this training regime drives the network to converge toward the expected value of the solution of the SPDE. Using the stochastic heat equation as a testbed, we evaluate performance across a diverse set of 144 experimental configurations that span multiple spatial dimensions, noise models, and forcing functions. The results show that the model consistently learns accurate approximations of the expected value of the solution in lower dimensions and a predictable decrease in accuracy with increased spatial dimensions, with improved stability and robustness under increased Monte Carlo sampling. Our findings offer new insight into how neural networks implicitly learn statistical structure from stochastic differential operators and suggest a pathway toward scalable, simulator-free SPDE solvers.",
    "source": "arXiv"
  },
  {
    "title": "Frontend Diffusion: Empowering Self-Representation of Junior Researchers and Designers Through Multi-agent System",
    "title_es": "Frontend Diffusion: Empowering Self-Representation of Junior Researchers and Designers Through Multi-agent System",
    "url": "https://arxiv.org/abs/2502.03788",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.03788v2 Announce Type: replace \nAbstract: With the continuous development of generative AI's logical reasoning abilities, AI's growing code-generation potential poses challenges for both technical and creative professionals. But how can these advances be directed toward empowering junior researchers and designers who often require additional help to build and express their professional and personal identities? We introduce Frontend Diffusion, a multi-agent coding system transforming user-drawn layouts and textual prompts into refined website code, thereby supporting self-representation goals. A user study with 13 junior researchers and designers shows AI as a human capability enhancer rather than a replacement, and highlights the importance of bidirectional human-AI alignment. We then discuss future work such as leveraging AI for career development and fostering bidirectional human-AI alignment of multi-agent systems.",
    "source": "arXiv"
  },
  {
    "title": "Active Learning of Model Discrepancy with Bayesian Experimental Design",
    "title_es": "Active Learning of Model Discrepancy with Bayesian Experimental Design",
    "url": "https://arxiv.org/abs/2502.05372",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.05372v2 Announce Type: replace \nAbstract: Digital twins have been actively explored in many engineering applications, such as manufacturing and autonomous systems. However, model discrepancy is ubiquitous in most digital twin models and has significant impacts on the performance of using those models. In recent years, data-driven modeling techniques have been demonstrated promising in characterizing the model discrepancy in existing models, while the training data for the learning of model discrepancy is often obtained in an empirical way and an active approach of gathering informative data can potentially benefit the learning of model discrepancy. On the other hand, Bayesian experimental design (BED) provides a systematic approach to gathering the most informative data, but its performance is often negatively impacted by the model discrepancy. In this work, we build on sequential BED and propose an efficient approach to iteratively learn the model discrepancy based on the data from the BED. The performance of the proposed method is validated by a classical numerical example governed by a convection-diffusion equation, for which full BED is still feasible. The proposed method is then further studied in the same numerical example with a high-dimensional model discrepancy, which serves as a demonstration for the scenarios where full BED is not practical anymore. An ensemble-based approximation of information gain is further utilized to assess the data informativeness and to enhance learning model discrepancy. The results show that the proposed method is efficient and robust to the active learning of high-dimensional model discrepancy, using data suggested by the sequential BED. We also demonstrate that the proposed method is compatible with both classical numerical solvers and modern auto-differentiable solvers.",
    "source": "arXiv"
  },
  {
    "title": "DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control",
    "title_es": "DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control",
    "url": "https://arxiv.org/abs/2502.05855",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.05855v3 Announce Type: replace \nAbstract: Enabling robots to perform diverse tasks across varied environments is a central challenge in robot learning. While vision-language-action (VLA) models have shown promise for generalizable robot skills, realizing their full potential requires addressing limitations in action representation and efficient training. Current VLA models often focus on scaling the vision-language model (VLM) component, while the action space representation remains a critical bottleneck. This paper introduces DexVLA, a novel framework designed to enhance the efficiency and generalization capabilities of VLAs for complex, long-horizon tasks across diverse robot embodiments. DexVLA features a novel diffusion-based action expert, scaled to one billion parameters, designed for cross-embodiment learning. A novel embodiment curriculum learning strategy facilitates efficient training: (1) pre-training the diffusion expert that is separable from the VLA on cross-embodiment data, (2) aligning the VLA model to specific embodiments, and (3) post-training for rapid adaptation to new tasks. We conduct comprehensive experiments across multiple embodiments, including single-arm, bimanual, and dexterous hand, demonstrating DexVLA's adaptability to challenging tasks without task-specific adaptation, its ability to learn dexterous skills on novel embodiments with limited data, and its capacity to complete complex, long-horizon tasks using only direct language prompting, such as laundry folding. In all settings, our method demonstrates superior performance compared to state-of-the-art models like Octo, OpenVLA, and Diffusion Policy.",
    "source": "arXiv"
  },
  {
    "title": "Optimistic Interior Point Methods for Sequential Hypothesis Testing by Betting",
    "title_es": "Optimistic Interior Point Methods for Sequential Hypothesis Testing by Betting",
    "url": "https://arxiv.org/abs/2502.07774",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.07774v2 Announce Type: replace \nAbstract: The technique of ``testing by betting\" frames nonparametric sequential hypothesis testing as a multiple-round game, where a player bets on future observations that arrive in a streaming fashion, accumulates wealth that quantifies evidence against the null hypothesis, and rejects the null once the wealth exceeds a specified threshold while controlling the false positive error. Designing an online learning algorithm that achieves a small regret in the game can help rapidly accumulate the bettor's wealth, which in turn can shorten the time to reject the null hypothesis under the alternative $H_1$. However, many of the existing works employ the Online Newton Step (ONS) to update within a halved decision space to avoid a gradient explosion issue, which is potentially conservative for rapid wealth accumulation. In this paper, we introduce a novel strategy utilizing interior-point methods in optimization that allows updates across the entire interior of the decision space without the risk of gradient explosion. Our approach not only maintains strong statistical guarantees but also facilitates faster null hypothesis rejection, while being as computationally lightweight as ONS thanks to its closed-form updates.",
    "source": "arXiv"
  },
  {
    "title": "Active Advantage-Aligned Online Reinforcement Learning with Offline Data",
    "title_es": "Active Advantage-Aligned Online Reinforcement Learning with Offline Data",
    "url": "https://arxiv.org/abs/2502.07937",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.07937v3 Announce Type: replace \nAbstract: Online reinforcement learning (RL) enhances policies through direct interactions with the environment, but faces challenges related to sample efficiency. In contrast, offline RL leverages extensive pre-collected data to learn policies, but often produces suboptimal results due to limited data coverage. Recent efforts integrate offline and online RL in order to harness the advantages of both approaches. However, effectively combining online and offline RL remains challenging due to issues that include catastrophic forgetting, lack of robustness to data quality and limited sample efficiency in data utilization. In an effort to address these challenges, we introduce A3RL, which incorporates a novel confidence aware Active Advantage Aligned (A3) sampling strategy that dynamically prioritizes data aligned with the policy's evolving needs from both online and offline sources, optimizing policy improvement. Moreover, we provide theoretical insights into the effectiveness of our active sampling strategy and conduct diverse empirical experiments and ablation studies, demonstrating that our method outperforms competing online RL techniques that leverage offline data.",
    "source": "arXiv"
  },
  {
    "title": "Delayed takedown of illegal content on social media makes moderation ineffective",
    "title_es": "Delayed takedown of illegal content on social media makes moderation ineffective",
    "url": "https://arxiv.org/abs/2502.08841",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.08841v2 Announce Type: replace \nAbstract: Illegal content on social media poses significant societal harm and necessitates timely removal. However, the impact of the speed of content removal on prevalence, reach, and exposure to illegal content remains underexplored. This study examines the relationship with a systematic analysis of takedown delays using data from the EU Digital Services Act Transparency Database, covering five major platforms over a one-year period. We find substantial variation in takedown delay, with some content remaining online for weeks or even months. To evaluate how these delays affect the prevalence and reach of illegal content and exposure to it, we develop an agent-based model and calibrate it to empirical data. We simulate illegal content diffusion, revealing that rapid takedown (within hours) significantly reduces prevalence, reach, and exposure to illegal content, while longer delays fail to reduce its spread. Though the effect of delay may seem intuitive, our simulations quantify exactly how takedown speed shapes the spread of illegal content. Building on these results, we point to the benefits of faster content removal to effectively curb the spread of illegal content, while also considering the limitations of strict enforcement policies.",
    "source": "arXiv"
  },
  {
    "title": "Scalable Private Partition Selection via Adaptive Weighting",
    "title_es": "Scalable Private Partition Selection via Adaptive Weighting",
    "url": "https://arxiv.org/abs/2502.08878",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.08878v2 Announce Type: replace \nAbstract: In the differentially private partition selection problem (a.k.a. private set union, private key discovery), users hold subsets of items from an unbounded universe. The goal is to output as many items as possible from the union of the users' sets while maintaining user-level differential privacy. Solutions to this problem are a core building block for many privacy-preserving ML applications including vocabulary extraction in a private corpus, computing statistics over categorical data and learning embeddings over user-provided items.\n  We propose an algorithm for this problem, MaxAdaptiveDegree (MAD), which adaptively reroutes weight from items with weight far above the threshold needed for privacy to items with smaller weight, thereby increasing the probability that less frequent items are output. Our algorithm can be efficiently implemented in massively parallel computation systems allowing scalability to very large datasets. We prove that our algorithm stochastically dominates the standard parallel algorithm for this problem. We also develop a two-round version of our algorithm, MAD2R, where results of the computation in the first round are used to bias the weighting in the second round to maximize the number of items output. In experiments, our algorithms provide the best results among parallel algorithms and scale to datasets with hundreds of billions of items, up to three orders of magnitude larger than those analyzed by prior sequential algorithms.",
    "source": "arXiv"
  },
  {
    "title": "Fenchel-Young Variational Learning",
    "title_es": "Fenchel-Young Variational Learning",
    "url": "https://arxiv.org/abs/2502.10295",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.10295v2 Announce Type: replace \nAbstract: From a variational perspective, many statistical learning criteria involve seeking a distribution that balances empirical risk and regularization. In this paper, we broaden this perspective by introducing a new general class of variational methods based on Fenchel-Young (FY) losses, treated as divergences that generalize (and encompass) the familiar Kullback-Leibler divergence at the core of classical variational learning. Our proposed formulation -- FY variational learning -- includes as key ingredients new notions of FY free energy, FY evidence, FY evidence lower bound, and FY posterior. We derive alternating minimization and gradient backpropagation algorithms to compute (or lower bound) the FY evidence, which enables learning a wider class of models than previous variational formulations. This leads to generalized FY variants of classical algorithms, such as an FY expectation-maximization (FYEM) algorithm, and latent-variable models, such as an FY variational autoencoder (FYVAE). Our new methods are shown to be empirically competitive, often outperforming their classical counterparts, and most importantly, to have qualitatively novel features. For example, FYEM has an adaptively sparse E-step, while the FYVAE can support models with sparse observations and sparse posteriors.",
    "source": "arXiv"
  },
  {
    "title": "Large Model Empowered Metaverse: State-of-the-Art, Challenges and Opportunities",
    "title_es": "Large Model Empowered Metaverse: State-of-the-Art, Challenges and Opportunities",
    "url": "https://arxiv.org/abs/2502.10397",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.10397v2 Announce Type: replace \nAbstract: The Metaverse represents a transformative shift beyond traditional mobile Internet, creating an immersive, persistent digital ecosystem where users can interact, socialize, and work within 3D virtual environments. Powered by large models such as ChatGPT and Sora, the Metaverse benefits from precise large-scale real-world modeling, automated multimodal content generation, realistic avatars, and seamless natural language understanding, which enhance user engagement and enable more personalized, intuitive interactions. However, challenges remain, including limited scalability, constrained responsiveness, and low adaptability in dynamic environments. This paper investigates the integration of large models within the Metaverse, examining their roles in enhancing user interaction, perception, content creation, and service quality. To address existing challenges, we propose a generative AI-based framework for optimizing Metaverse rendering. This framework includes a cloud-edge-end collaborative model to allocate rendering tasks with minimal latency, a mobility-aware pre-rendering mechanism that dynamically adjusts to user movement, and a diffusion model-based adaptive rendering strategy to fine-tune visual details. Experimental results demonstrate the effectiveness of our approach in enhancing rendering efficiency and reducing rendering overheads, advancing large model deployment for a more responsive and immersive Metaverse.",
    "source": "arXiv"
  },
  {
    "title": "Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration",
    "title_es": "Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration",
    "url": "https://arxiv.org/abs/2502.12204",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.12204v2 Announce Type: replace \nAbstract: Automatic depression detection provides cues for early clinical intervention by clinicians. Clinical interviews for depression detection involve dialogues centered around multiple themes. Existing studies primarily design end-to-end neural network models to capture the hierarchical structure of clinical interview dialogues. However, these methods exhibit defects in modeling the thematic content of clinical interviews: 1) they fail to capture intra-theme and inter-theme correlation explicitly, and 2) they do not allow clinicians to intervene and focus on themes of interest. To address these issues, this paper introduces an interactive depression detection framework. This framework leverages in-context learning techniques to identify themes in clinical interviews and then models both intra-theme and inter-theme correlation. Additionally, it employs AI-driven feedback to simulate the interests of clinicians, enabling interactive adjustment of theme importance. PDIMC achieves absolute improvements of 35\\% and 12\\% compared to the state-of-the-art on the depression detection dataset DAIC-WOZ, which demonstrates the effectiveness of modeling theme correlation and incorporating interactive external feedback.",
    "source": "arXiv"
  },
  {
    "title": "Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement Learning for Enabling Adaptive and Feasible Master Stowage Planning",
    "title_es": "Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement Learning for Enabling Adaptive and Feasible Master Stowage Planning",
    "url": "https://arxiv.org/abs/2502.12756",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.12756v5 Announce Type: replace \nAbstract: Reinforcement learning (RL) has shown promise in solving various combinatorial optimization problems. However, conventional RL faces challenges when dealing with complex, real-world constraints, especially when action space feasibility is explicit and dependent on the corresponding state or trajectory. In this work, we address stochastic sequential dynamic decision-making problems with state-dependent constraints. As a relevant and real-world case study, we focus on the master stowage planning problem in container shipping, which aims to optimize revenue and operational costs under demand uncertainty and operational constraints. We propose a deep RL framework with an encoder-decoder model and feasibility layers that satisfy convex constraints and maintain unbiased gradient flow, which embed problem instances, current solutions, and demand uncertainty to guide learning. Experiments show that our model efficiently finds adaptive, feasible solutions that generalize across varying distributions and scale to larger instances, outperforming state-of-the-art baselines in constrained RL and stochastic programming. By uniting artificial intelligence and operations research, our policy empowers humans to make adaptive, uncertainty-aware decisions for resilient and sustainable planning.",
    "source": "arXiv"
  },
  {
    "title": "On the Duality between Gradient Transformations and Adapters",
    "title_es": "On the Duality between Gradient Transformations and Adapters",
    "url": "https://arxiv.org/abs/2502.13811",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.13811v2 Announce Type: replace \nAbstract: We study memory-efficient optimization of neural networks (in particular language models) with linear gradient transformations, where the gradients are linearly mapped to a lower dimensional space than the full parameter space, thus saving memory required for gradient accumulation and optimizer state persistence. The model parameters are updated by first performing an optimization step in the lower dimensional space and then going back into the original parameter space via the linear map's transpose. We show that optimizing the model in this transformed space is equivalent to reparameterizing the original model through a linear adapter that additively modifies the model parameters, and then only optimizing the adapter's parameters. When the transformation is Kronecker-factored, this establishes an equivalence between GaLore and one-sided LoRA. We show that this duality between gradient transformations and adapter-based reparameterizations unifies existing approaches to memory-efficient training and suggests new techniques for improving training efficiency and memory use.",
    "source": "arXiv"
  },
  {
    "title": "SageServe: Optimizing LLM Serving on Cloud Data Centers with Forecast Aware Auto-Scaling",
    "title_es": "SageServe: Optimizing LLM Serving on Cloud Data Centers with Forecast Aware Auto-Scaling",
    "url": "https://arxiv.org/abs/2502.14617",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.14617v2 Announce Type: replace \nAbstract: Global cloud service providers handle inference workloads for Large Language Models (LLMs) that span latency-sensitive (e.g., chatbots) and insensitive (e.g., report writing) tasks, resulting in diverse and often conflicting Service Level Agreement (SLA) requirements. Managing such mixed workloads is challenging due to the complexity of the inference serving stack, which encompasses multiple models, GPU hardware, and global data centers. Existing solutions often silo such fast and slow tasks onto separate GPU resource pools with different SLAs, but this leads to significant under-utilization of expensive accelerators due to load mismatch. In this article, we characterize the LLM serving workloads at Microsoft Office 365, one of the largest users of LLMs within Microsoft Azure cloud with over 10 million requests per day, and highlight key observations across workloads in different data center regions and across time. This is one of the first such public studies of Internet-scale LLM workloads. We use these insights to propose SageServe, a comprehensive LLM serving framework that dynamically adapts to workload demands using multi-timescale control knobs. It combines short-term request routing to data centers with long-term scaling of GPU VMs and model placement with higher lead times, and co-optimizes the routing and resource allocation problem using a traffic forecast model and an Integer Linear Programming (ILP) solution. We evaluate SageServe through real runs and realistic simulations on 10 million production requests across three regions and four open-source models. We achieve up to 25% savings in GPU-hours compared to the current baseline deployment and reduce GPU-hour wastage due to inefficient auto-scaling by 80%, resulting in a potential monthly cost savings of up to $2.5 million, while maintaining tail latency and meeting SLAs.",
    "source": "arXiv"
  },
  {
    "title": "Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models",
    "title_es": "Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models",
    "url": "https://arxiv.org/abs/2502.14819",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.14819v3 Announce Type: replace \nAbstract: A long-standing goal in AI is to build agents that can solve a variety of tasks across different environments, including previously unseen ones. Two dominant approaches tackle this challenge: (i) reinforcement learning (RL), which learns policies through trial and error, and (ii) optimal control, which plans actions using a learned or known dynamics model. However, their relative strengths and weaknesses remain underexplored in the setting where agents must learn from offline trajectories without reward annotations. In this work, we systematically analyze the performance of different RL and control-based methods under datasets of varying quality. On the RL side, we consider goal-conditioned and zero-shot approaches. On the control side, we train a latent dynamics model using the Joint Embedding Predictive Architecture (JEPA) and use it for planning. We study how dataset properties-such as data diversity, trajectory quality, and environment variability-affect the performance of these approaches. Our results show that model-free RL excels when abundant, high-quality data is available, while model-based planning excels in generalization to novel environment layouts, trajectory stitching, and data-efficiency. Notably, planning with a latent dynamics model emerges as a promising approach for zero-shot generalization from suboptimal data.",
    "source": "arXiv"
  },
  {
    "title": "ALFA: Aligning LLMs to Ask Good Questions A Case Study in Clinical Reasoning",
    "title_es": "ALFA: Aligning LLMs to Ask Good Questions A Case Study in Clinical Reasoning",
    "url": "https://arxiv.org/abs/2502.14860",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.14860v2 Announce Type: replace \nAbstract: Large language models (LLMs) often fail to ask effective questions under uncertainty, making them unreliable in domains where proactive information-gathering is essential for decision-making. We present ALignment via Fine-grained Attributes, (ALFA) a framework that improves LLM question-asking by (i) decomposing the notion of a \"good\" question into a set of theory-grounded attributes (e.g., clarity, relevance), (ii) controllably synthesizing attribute-specific question variations, and (iii) aligning models via preference-based optimization to explicitly learn to ask better questions along these fine-grained attributes. Focusing on clinical reasoning as a case study, we introduce the MediQ-AskDocs dataset, composed of 17k real-world clinical interactions augmented with 80k attribute-specific preference pairs of follow-up questions, as well as a novel expert-annotated interactive healthcare QA task to evaluate question-asking abilities. Models aligned with ALFA reduce diagnostic errors by 56.6% on MediQ-AskDocs compared to SoTA instruction-tuned LLMs, with a question-level win-rate of 64.4% and strong generalizability. Our findings suggest that explicitly guiding question-asking with structured, fine-grained attributes offers a scalable path to improve LLMs, especially in expert application domains.",
    "source": "arXiv"
  },
  {
    "title": "Real-Time Moving Flock Detection in Pedestrian Trajectories Using Sequential Deep Learning Models",
    "title_es": "Real-Time Moving Flock Detection in Pedestrian Trajectories Using Sequential Deep Learning Models",
    "url": "https://arxiv.org/abs/2502.15252",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.15252v2 Announce Type: replace \nAbstract: Understanding collective pedestrian movement is crucial for applications in crowd management, autonomous navigation, and human-robot interaction. This paper investigates the use of sequential deep learning models, including Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Transformers, for real-time flock detection in multi-pedestrian trajectories. Our proposed approach consists of a two-stage process: first, a pre-trained binary classification model is used for pairwise trajectory classification, and second, the learned representations are applied to identify multi-agent flocks dynamically.\n  We validate our method using real-world group movement datasets, demonstrating its robustness across varying sequence lengths and diverse movement patterns. Experimental results indicate that our model consistently detects pedestrian flocks with high accuracy and stability, even in dynamic and noisy environments. Furthermore, we extend our approach to identify other forms of collective motion, such as convoys and swarms, paving the way for more comprehensive multi-agent behavior analysis.",
    "source": "arXiv"
  },
  {
    "title": "Confidence-Based Annotation Of Brain Tumours In Ultrasound",
    "title_es": "Confidence-Based Annotation Of Brain Tumours In Ultrasound",
    "url": "https://arxiv.org/abs/2502.15484",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.15484v2 Announce Type: replace \nAbstract: Purpose: An investigation of the challenge of annotating discrete segmentations of brain tumours in ultrasound, with a focus on the issue of aleatoric uncertainty along the tumour margin, particularly for diffuse tumours. A segmentation protocol and method is proposed that incorporates this margin-related uncertainty while minimising the interobserver variance through reduced subjectivity, thereby diminishing annotator epistemic uncertainty. Approach: A sparse confidence method for annotation is proposed, based on a protocol designed using computer vision and radiology theory. Results: Output annotations using the proposed method are compared with the corresponding professional discrete annotation variance between the observers. A linear relationship was measured within the tumour margin region, with a Pearson correlation of 0.8. The downstream application was explored, comparing training using confidence annotations as soft labels with using the best discrete annotations as hard labels. In all evaluation folds, the Brier score was superior for the soft-label trained network. Conclusion: A formal framework was constructed to demonstrate the infeasibility of discrete annotation of brain tumours in B-mode ultrasound. Subsequently, a method for sparse confidence-based annotation is proposed and evaluated. Keywords: Brain tumours, ultrasound, confidence, annotation.",
    "source": "arXiv"
  },
  {
    "title": "Subspace and DOA estimation under coarse quantization",
    "title_es": "Subspace and DOA estimation under coarse quantization",
    "url": "https://arxiv.org/abs/2502.17037",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.17037v2 Announce Type: replace \nAbstract: We study direction-of-arrival (DOA) estimation from coarsely quantized data. We focus on a two-step approach which first estimates the signal subspace via covariance estimation and then extracts DOA angles by the ESPRIT algorithm. In particular, we analyze two stochastic quantization schemes which use dithering: a one-bit quantizer combined with rectangular dither and a multi-bit quantizer with triangular dither. For each quantizer, we derive rigorous high probability bounds for the distances between the true and estimated signal subspaces and DOA angles. Using our analysis, we identify scenarios in which subspace and DOA estimation via triangular dithering qualitatively outperforms rectangular dithering. We verify in numerical simulations that our estimates are optimal in their dependence on the smallest non-zero eigenvalue of the target matrix. The resulting subspace estimation guarantees are equally applicable in the analysis of other spectral estimation algorithms and related problems.",
    "source": "arXiv"
  },
  {
    "title": "Extremum Seeking Control for Antenna Pointing via Symmetric Product Approximation",
    "title_es": "Extremum Seeking Control for Antenna Pointing via Symmetric Product Approximation",
    "url": "https://arxiv.org/abs/2502.17252",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.17252v2 Announce Type: replace \nAbstract: This paper investigates extremum seeking control for a torque-controlled antenna pointing system without direct angular measurements. We consider a two-degree-of-freedom (2-DOF) antenna system that receives an unknown signal from its environment, where the signal strength varies with the antenna orientation. It is assumed that only real-time measurements of the signal are available. We develop an extremum seeking control strategy that enables the antenna to autonomously adjust its direction to maximize the received signal strength based on the symmetric product approximation. Under suitable assumptions on the signal function, we prove local practical uniform asymptotic stability for the closed-loop system.",
    "source": "arXiv"
  },
  {
    "title": "GaussianFlowOcc: Sparse and Weakly Supervised Occupancy Estimation using Gaussian Splatting and Temporal Flow",
    "title_es": "GaussianFlowOcc: Sparse and Weakly Supervised Occupancy Estimation using Gaussian Splatting and Temporal Flow",
    "url": "https://arxiv.org/abs/2502.17288",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.17288v3 Announce Type: replace \nAbstract: Occupancy estimation has become a prominent task in 3D computer vision, particularly within the autonomous driving community. In this paper, we present a novel approach to occupancy estimation, termed GaussianFlowOcc, which is inspired by Gaussian Splatting and replaces traditional dense voxel grids with a sparse 3D Gaussian representation. Our efficient model architecture based on a Gaussian Transformer significantly reduces computational and memory requirements by eliminating the need for expensive 3D convolutions used with inefficient voxel-based representations that predominantly represent empty 3D spaces. GaussianFlowOcc effectively captures scene dynamics by estimating temporal flow for each Gaussian during the overall network training process, offering a straightforward solution to a complex problem that is often neglected by existing methods. Moreover, GaussianFlowOcc is designed for scalability, as it employs weak supervision and does not require costly dense 3D voxel annotations based on additional data (e.g., LiDAR). Through extensive experimentation, we demonstrate that GaussianFlowOcc significantly outperforms all previous methods for weakly supervised occupancy estimation on the nuScenes dataset while featuring an inference speed that is 50 times faster than current SOTA.",
    "source": "arXiv"
  },
  {
    "title": "URO-Bench: Towards Comprehensive Evaluation for End-to-End Spoken Dialogue Models",
    "title_es": "URO-Bench: Towards Comprehensive Evaluation for End-to-End Spoken Dialogue Models",
    "url": "https://arxiv.org/abs/2502.17810",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.17810v3 Announce Type: replace \nAbstract: Recent advances in large language models (LLMs) have driven significant progress in end-to-end spoken dialogue models (SDMs). In contrast to text-based LLMs, the evaluation framework for SDMs should encompass both cognitive dimensions (e.g., logical reasoning, knowledge) and speech-related aspects (e.g., paralinguistic cues, audio quality). However, there is still a lack of comprehensive evaluations for SDMs in speech-to-speech (S2S) scenarios. To address this gap, we propose URO-Bench, an extensive benchmark for SDMs. Notably, URO-Bench is the first S2S benchmark that covers evaluations about multilingualism, multi-round dialogues, and paralinguistics. Our benchmark is divided into two difficulty levels: basic track and pro track, each comprising 20 test sets, evaluating the spoken dialogue model's abilities in Understanding, Reasoning, and Oral conversation. Evaluations on our proposed benchmark reveal that current open-source SDMs perform rather well in daily QA tasks, but lag behind their backbone LLMs in terms of instruction-following ability and also suffer from catastrophic forgetting. Their performance in advanced evaluations of paralinguistic information and audio understanding remains subpar, highlighting the need for further research in this direction. We hope that URO-Bench can facilitate the development of spoken dialogue models by providing a multifaceted evaluation of existing models and helping to track progress in this area.",
    "source": "arXiv"
  },
  {
    "title": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models",
    "title_es": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models",
    "url": "https://arxiv.org/abs/2502.19918",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.19918v4 Announce Type: replace \nAbstract: Large Language Models (LLMs) struggle with high computational time and error propagation during inference time, especially for complex tasks like math, puzzles, or coding requiring multi-step thinking. While existing reasoning models with chain-of-thoughts (CoT) can enable LLMs to do step-wise analysis and reflection, they often face the issue of wasting computation on less productive solutions and fail to make progress during inference time. In this paper, we propose Meta-Reasoner, a new framework to enable LLMs ``Think about how to think'', i.e., optimize the inference compute by adjusting strategies on how to reason during inference time. Inspired by dual-process theory, our method decouples the high-level strategy generation (e.g., backtracking, switching approaches, or restarting) from stepwise CoT generation via a lightweight progress report. The strategy module only consider the summarized version from the previous CoTs to propose new strategies accordingly. We employ the contextual multi-armed bandits (CMABs) for this module to iteratively evaluate the previous reasoning states and dynamically adjust the strategy to avoid reasoning get stuck in less productive paths during inference. Evaluations on math problems (e.g., Game-of-24, TheoremQA) and scientific problems (e.g., SciBench) demonstrate that our method improves performance by 9-12\\% over previous SOTA methods while reducing inference time by 28-35\\%. This approach also generalizes to other domains like creative writing, demonstrating its versatility for diverse reasoning-intensive problems using LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Advancing AI-Powered Medical Image Synthesis: Insights from MedVQA-GI Challenge Using CLIP, Fine-Tuned Stable Diffusion, and Dream-Booth + LoRA",
    "title_es": "Advancing AI-Powered Medical Image Synthesis: Insights from MedVQA-GI Challenge Using CLIP, Fine-Tuned Stable Diffusion, and Dream-Booth + LoRA",
    "url": "https://arxiv.org/abs/2502.20667",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.20667v2 Announce Type: replace \nAbstract: The MEDVQA-GI challenge addresses the integration of AI-driven text-to-image generative models in medical diagnostics, aiming to enhance diagnostic capabilities through synthetic image generation. Existing methods primarily focus on static image analysis and lack the dynamic generation of medical imagery from textual descriptions. This study intends to partially close this gap by introducing a novel approach based on fine-tuned generative models to generate dynamic, scalable, and precise images from textual descriptions. Particularly, our system integrates fine-tuned Stable Diffusion and DreamBooth models, as well as Low-Rank Adaptation (LORA), to generate high-fidelity medical images. The problem is around two sub-tasks namely: image synthesis (IS) and optimal prompt production (OPG). The former creates medical images via verbal prompts, whereas the latter provides prompts that produce high-quality images in specified categories. The study emphasizes the limitations of traditional medical image generation methods, such as hand sketching, constrained datasets, static procedures, and generic models. Our evaluation measures showed that Stable Diffusion surpasses CLIP and DreamBooth + LORA in terms of producing high-quality, diversified images. Specifically, Stable Diffusion had the lowest Fr\\'echet Inception Distance (FID) scores (0.099 for single center, 0.064 for multi-center, and 0.067 for combined), indicating higher image quality. Furthermore, it had the highest average Inception Score (2.327 across all datasets), indicating exceptional diversity and quality. This advances the field of AI-powered medical diagnosis. Future research will concentrate on model refining, dataset augmentation, and ethical considerations for efficiently implementing these advances into clinical practice",
    "source": "arXiv"
  },
  {
    "title": "Reviewing Clinical Knowledge in Medical Large Language Models: Training and Beyond",
    "title_es": "Reviewing Clinical Knowledge in Medical Large Language Models: Training and Beyond",
    "url": "https://arxiv.org/abs/2502.20988",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.20988v2 Announce Type: replace \nAbstract: The large-scale development of large language models (LLMs) in medical contexts, such as diagnostic assistance and treatment recommendations, necessitates that these models possess accurate medical knowledge and deliver traceable decision-making processes. Clinical knowledge, encompassing the insights gained from research on the causes, prognosis, diagnosis, and treatment of diseases, has been extensively examined within real-world medical practices. Recently, there has been a notable increase in research efforts aimed at integrating this type of knowledge into LLMs, encompassing not only traditional text and multimodal data integration but also technologies such as knowledge graphs (KGs) and retrieval-augmented generation (RAG). In this paper, we review the various initiatives to embed clinical knowledge into training-based, KG-supported, and RAG-assisted LLMs. We begin by gathering reliable knowledge sources from the medical domain, including databases and datasets. Next, we evaluate implementations for integrating clinical knowledge through specialized datasets and collaborations with external knowledge sources such as KGs and relevant documentation. Furthermore, we discuss the applications of the developed medical LLMs in the industrial sector to assess the disparity between models developed in academic settings and those in industry. We conclude the survey by presenting evaluation systems applicable to relevant tasks and identifying potential challenges facing this field. In this review, we do not aim for completeness, since any ostensibly complete review would soon be outdated. Our goal is to illustrate diversity by selecting representative and accessible items from current research and industry practices, reflecting real-world situations rather than claiming completeness. Thus, we emphasize showcasing diverse approaches.",
    "source": "arXiv"
  },
  {
    "title": "Vehicle Top Tag Assisted Vehicle-Road Cooperative Localization For Autonomous Public Buses",
    "title_es": "Vehicle Top Tag Assisted Vehicle-Road Cooperative Localization For Autonomous Public Buses",
    "url": "https://arxiv.org/abs/2503.00546",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.00546v2 Announce Type: replace \nAbstract: Accurate vehicle localization is indispensable to autonomous vehicles, but is difficult to realize in complicated application scenarios. Intersection scenarios that suffer from environmental shielding and crowded dynamic objects are especially crucial and challenging. To handle difficult intersection scenarios, the methodology of vehicle top tag assisted vehicle-road cooperative localization or for short vehicle top tag assisted localization is proposed. The proposed methodology has merits of satisfying all the feasibility, reliability, explainability, society and economy concerns. Concrete solutions of vehicle top tag detection and vehicle top tag localization that instantiate the core part of the proposed methodology are presented. Simulation results are provided to demonstrate effectiveness of the presented solutions. The proposed methodology of vehicle top tag assisted localization also has the potential to be extended to a much wider range of practical applications than our intended ones involving autonomous public buses.",
    "source": "arXiv"
  },
  {
    "title": "Instructor-Worker Large Language Model System for Policy Recommendation: a Case Study on Air Quality Analysis of the January 2025 Los Angeles Wildfires",
    "title_es": "Instructor-Worker Large Language Model System for Policy Recommendation: a Case Study on Air Quality Analysis of the January 2025 Los Angeles Wildfires",
    "url": "https://arxiv.org/abs/2503.00566",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.00566v3 Announce Type: replace \nAbstract: The Los Angeles wildfires of January 2025 caused more than 250 billion dollars in damage and lasted for nearly an entire month before containment. Following our previous work, the Digital Twin Building, we modify and leverage the multi-agent large language model framework as well as the cloud-mapping integration to study the air quality during the Los Angeles wildfires. Recent advances in large language models have allowed for out-of-the-box automated large-scale data analysis. We use a multi-agent large language system comprised of an Instructor agent and Worker agents. Upon receiving the users' instructions, the Instructor agent retrieves the data from the cloud platform and produces instruction prompts to the Worker agents. The Worker agents then analyze the data and provide summaries. The summaries are finally input back into the Instructor agent, which then provides the final data analysis. We test this system's capability for data-based policy recommendation by assessing our Instructor-Worker LLM system's health recommendations based on air quality during the Los Angeles wildfires.",
    "source": "arXiv"
  },
  {
    "title": "OceanSim: A GPU-Accelerated Underwater Robot Perception Simulation Framework",
    "title_es": "OceanSim: A GPU-Accelerated Underwater Robot Perception Simulation Framework",
    "url": "https://arxiv.org/abs/2503.01074",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.01074v2 Announce Type: replace \nAbstract: Underwater simulators offer support for building robust underwater perception solutions. Significant work has recently been done to develop new simulators and to advance the performance of existing underwater simulators. Still, there remains room for improvement on physics-based underwater sensor modeling and rendering efficiency. In this paper, we propose OceanSim, a high-fidelity GPU-accelerated underwater simulator to address this research gap. We propose advanced physics-based rendering techniques to reduce the sim-to-real gap for underwater image simulation. We develop OceanSim to fully leverage the computing advantages of GPUs and achieve real-time imaging sonar rendering and fast synthetic data generation. We evaluate the capabilities and realism of OceanSim using real-world data to provide qualitative and quantitative results. The code and detailed documentation are made available on the project website to support the marine robotics community: https://umfieldrobotics.github.io/OceanSim.",
    "source": "arXiv"
  },
  {
    "title": "MeshPad: Interactive Sketch-Conditioned Artist-Reminiscent Mesh Generation and Editing",
    "title_es": "MeshPad: Interactive Sketch-Conditioned Artist-Reminiscent Mesh Generation and Editing",
    "url": "https://arxiv.org/abs/2503.01425",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.01425v3 Announce Type: replace \nAbstract: We introduce MeshPad, a generative approach that creates 3D meshes from sketch inputs. Building on recent advances in artist-reminiscent triangle mesh generation, our approach addresses the need for interactive mesh creation. To this end, we focus on enabling consistent edits by decomposing editing into 'deletion' of regions of a mesh, followed by 'addition' of new mesh geometry. Both operations are invoked by simple user edits of a sketch image, facilitating an iterative content creation process and enabling the construction of complex 3D meshes. Our approach is based on a triangle sequence-based mesh representation, exploiting a large Transformer model for mesh triangle addition and deletion. In order to perform edits interactively, we introduce a vertex-aligned speculative prediction strategy on top of our additive mesh generator. This speculator predicts multiple output tokens corresponding to a vertex, thus significantly reducing the computational cost of inference and accelerating the editing process, making it possible to execute each editing step in only a few seconds. Comprehensive experiments demonstrate that MeshPad outperforms state-of-the-art sketch-conditioned mesh generation methods, achieving more than 22% mesh quality improvement in Chamfer distance, and being preferred by 90% of participants in perceptual evaluations.",
    "source": "arXiv"
  },
  {
    "title": "Robustness to Geographic Distribution Shift Using Location Encoders",
    "title_es": "Robustness to Geographic Distribution Shift Using Location Encoders",
    "url": "https://arxiv.org/abs/2503.02036",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.02036v2 Announce Type: replace \nAbstract: Geographic distribution shift arises when the distribution of locations on Earth in a training dataset is different from what is seen at test time. The most common approaches to tackling geographic distribution shift treat regions delimited by administrative boundaries such as countries or continents as separate domains and apply standard domain adaptation methods, ignoring geographic coordinates that are often available as metadata. This paper proposes the use of location encoders for modeling continuous, learnable domain assignment. We show how both non-parametric sine-cosine encoders and pre-trained location encoders can be used in conjunction with standard domain adaptation methods for improved robustness to geographic distribution shift. Our proposed methods achieve new state-of-the-art results on two geo-tagged remote sensing datasets from the WILDS benchmark. We have made our code publicly available at: https://github.com/crastoru/wilds-geoshift.",
    "source": "arXiv"
  },
  {
    "title": "Average-DICE: Stationary Distribution Correction by Regression",
    "title_es": "Average-DICE: Stationary Distribution Correction by Regression",
    "url": "https://arxiv.org/abs/2503.02125",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.02125v2 Announce Type: replace \nAbstract: Off-policy policy evaluation (OPE), an essential component of reinforcement learning, has long suffered from stationary state distribution mismatch, undermining both stability and accuracy of OPE estimates. While existing methods correct distribution shifts by estimating density ratios, they often rely on expensive optimization or backward Bellman-based updates and struggle to outperform simpler baselines. We introduce AVG-DICE, a computationally simple Monte Carlo estimator for the density ratio that averages discounted importance sampling ratios, providing an unbiased and consistent correction. AVG-DICE extends naturally to nonlinear function approximation using regression, which we roughly tune and test on OPE tasks based on Mujoco Gym environments and compare with state-of-the-art density-ratio estimators using their reported hyperparameters. In our experiments, AVG-DICE is at least as accurate as state-of-the-art estimators and sometimes offers orders-of-magnitude improvements. However, a sensitivity analysis shows that best-performing hyperparameters may vary substantially across different discount factors, so a re-tuning is suggested.",
    "source": "arXiv"
  },
  {
    "title": "Mesostructural origins of the anisotropic compressive properties of low-density closed-cell foams: A deeper understanding",
    "title_es": "Mesostructural origins of the anisotropic compressive properties of low-density closed-cell foams: A deeper understanding",
    "url": "https://arxiv.org/abs/2503.03847",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.03847v2 Announce Type: replace \nAbstract: Many closed-cell foams exhibit an elongated cell shape in the foam rise direction, resulting in anisotropic compressive properties. Nevertheless, the underlying deformation mechanisms and how cell shape anisotropy induces this mechanical anisotropy are not yet fully understood, in particular for the foams with a high cell face fraction and low relative density. Moreover, the impacts of mesostructural stochastics are often overlooked. This contribution conducts a systematic numerical study on the anisotropic compressive behaviour of low-density closed-cell foams, which accounts for cell shape anisotropy, cell structure and different mesostructural stochastics. Representative volume elements (RVE) of foam mesostructures are modeled, with cell walls described as Reissner-Mindlin shells in a finite rotation setting. A mixed stress-strain driven homogenization scheme is introduced, which allows for enforcing an overall uniaxial stress state. Quantitative analysis of the cell wall deformation behaviour confirms the dominant role of membrane deformation in the initial elastic region, while the bending contribution gets important only after buckling, followed by membrane yielding. Based on the identified deformation mechanisms, analytical models are developed that relates mechanical anisotropy to cell shape anisotropy. It is found that cell shape anisotropy translates into the anisotropy of compressive properties through three pathways, cell load-bearing area fraction, cell wall buckling strength and cell wall inclination angle. Besides, the resulting mechanical anisotropy is strongly affected by the cell shape anisotropy stochastics while almost insensitive to the cell size and cell wall thickness stochastics. The present findings provide deeper insights into the relationships between the anisotropic compressive properties and mesostructures of low-density closed-cell foams.",
    "source": "arXiv"
  },
  {
    "title": "Invisible Walls in Cities: Leveraging Large Language Models to Predict Urban Segregation Experience with Social Media Content",
    "title_es": "Invisible Walls in Cities: Leveraging Large Language Models to Predict Urban Segregation Experience with Social Media Content",
    "url": "https://arxiv.org/abs/2503.04773",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.04773v3 Announce Type: replace \nAbstract: Understanding experienced segregation in urban daily life is crucial for addressing societal inequalities and fostering inclusivity. The abundance of user-generated reviews on social media encapsulates nuanced perceptions and feelings associated with different places, offering rich insights into segregation. However, leveraging this data poses significant challenges due to its vast volume, ambiguity, and confluence of diverse perspectives. To tackle these challenges, we propose using Large Language Models (LLMs) to automate online review mining for segregation prediction. We design a Reflective LLM Coder to digest social media content into insights consistent with real-world feedback, and eventually produce a codebook capturing key dimensions that signal segregation experience, such as cultural resonance and appeal, accessibility and convenience, and community engagement and local involvement. Guided by the codebook, LLMs can generate both informative review summaries and ratings for segregation prediction. Moreover, we design a REasoning-and-EMbedding (RE'EM) framework, which combines the reasoning and embedding capabilities of language models to integrate multi-channel features for segregation prediction. Experiments on real-world data demonstrate that our framework greatly improves prediction accuracy, with a 22.79% elevation in R2 and a 9.33% reduction in MSE. The derived codebook is generalizable across three different cities, consistently improving prediction accuracy. Moreover, our user study confirms that the codebook-guided summaries provide cognitive gains for human participants in perceiving POIs' social inclusiveness. Our study marks an important step toward understanding implicit social barriers and inequalities, demonstrating the great potential of promoting social inclusiveness with AI.",
    "source": "arXiv"
  },
  {
    "title": "ElementaryNet: A Non-Strategic Neural Network for Predicting Human Behavior in Normal-Form Games",
    "title_es": "ElementaryNet: A Non-Strategic Neural Network for Predicting Human Behavior in Normal-Form Games",
    "url": "https://arxiv.org/abs/2503.05925",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.05925v2 Announce Type: replace \nAbstract: Behavioral game theory models serve two purposes: yielding insights into how human decision-making works, and predicting how people would behave in novel strategic settings. A system called GameNet represents the state of the art for predicting human behavior in the setting of unrepeated simultaneous-move games, combining a simple \"level-k\" model of strategic reasoning with a complex neural network model of non-strategic \"level-0\" behavior. Although this reliance on well-established ideas from cognitive science ought to make GameNet interpretable, the flexibility of its level-0 model raises the possibility that it is able to emulate strategic reasoning. In this work, we prove that GameNet's level-0 model is indeed too general. We then introduce ElementaryNet, a novel neural network that is provably incapable of expressing strategic behavior. We show that these additional restrictions are empirically harmless, leading ElementaryNet to statistically indistinguishable predictive performance vs GameNet. We then show how it is possible to derive insights about human behavior by varying ElementaryNet's features and interpreting its parameters, finding evidence of iterative reasoning, learning about the depth of this reasoning process, and showing the value of a rich level-0 specification.",
    "source": "arXiv"
  },
  {
    "title": "X2I: Seamless Integration of Multimodal Understanding into Diffusion Transformer via Attention Distillation",
    "title_es": "X2I: Seamless Integration of Multimodal Understanding into Diffusion Transformer via Attention Distillation",
    "url": "https://arxiv.org/abs/2503.06134",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.06134v3 Announce Type: replace \nAbstract: Text-to-image (T2I) models are well known for their ability to produce highly realistic images, while multimodal large language models (MLLMs) are renowned for their proficiency in understanding and integrating multiple modalities. However, currently there is no straightforward and efficient framework to transfer the multimodal comprehension abilities of MLLMs to T2I models to enable them to understand multimodal inputs. In this paper, we propose the X2I framework, which endows Diffusion Transformer (DiT) models with the capability to comprehend various modalities, including multilingual text, screenshot documents, images, videos, and audio. X2I is trained using merely 100K English corpus with 160 GPU hours. Building on the DiT teacher model, we adopt an innovative distillation method to extract the inference capabilities of the teacher model and design a lightweight AlignNet structure to serve as an intermediate bridge. Compared to the teacher model, X2I shows a decrease in performance degradation of less than 1\\% while gaining various multimodal understanding abilities, including multilingual to image, image to image, image-text to image, video to image, audio to image, and utilizing creative fusion to enhance imagery. Furthermore, it is applicable for LoRA training in the context of image-text to image generation, filling a void in the industry in this area. We further design a simple LightControl to enhance the fidelity of instructional image editing. Finally, extensive experiments demonstrate the effectiveness, efficiency, multifunctionality, and transferability of our X2I. The open-source code and checkpoints for X2I can be found at the following link: https://github.com/OPPO-Mente-Lab/X2I.",
    "source": "arXiv"
  },
  {
    "title": "A Taxonomy of Inefficiencies in LLM-Generated Python Code",
    "title_es": "A Taxonomy of Inefficiencies in LLM-Generated Python Code",
    "url": "https://arxiv.org/abs/2503.06327",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.06327v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) are widely adopted for automated code generation with promising results. Although prior research has assessed LLM-generated code and identified various quality issues -- such as redundancy, poor maintainability, and sub-optimal performance a systematic understanding and categorization of these inefficiencies remain unexplored. Without such knowledge, practitioners struggle to optimize LLM-generated code for real-world applications, limiting its adoption. This study can also guide improving code LLMs, enhancing the quality and efficiency of code generation. Therefore, in this study, we empirically investigate inefficiencies in LLM-generated code by state-of-the-art models, i.e., CodeLlama, DeepSeek-Coder, and CodeGemma. To do so, we analyze 492 generated code snippets in the HumanEval++ dataset. We then construct a taxonomy of inefficiencies in LLM-generated code that includes 5 categories General Logic, Performance, Readability, Maintainability, and Errors) and 19 subcategories of inefficiencies. We then validate the proposed taxonomy through an online survey with 58 LLM practitioners and researchers. Our study indicates that logic and performance-related inefficiencies are the most popular, relevant, and frequently co-occur and impact overall code quality inefficiency. Our taxonomy provides a structured basis for evaluating the quality LLM-generated code and guiding future research to improve code generation efficiency.",
    "source": "arXiv"
  },
  {
    "title": "TextInPlace: Indoor Visual Place Recognition in Repetitive Structures with Scene Text Spotting and Verification",
    "title_es": "TextInPlace: Indoor Visual Place Recognition in Repetitive Structures with Scene Text Spotting and Verification",
    "url": "https://arxiv.org/abs/2503.06501",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.06501v2 Announce Type: replace \nAbstract: Visual Place Recognition (VPR) is a crucial capability for long-term autonomous robots, enabling them to identify previously visited locations using visual information. However, existing methods remain limited in indoor settings due to the highly repetitive structures inherent in such environments. We observe that scene texts frequently appear in indoor spaces and can help distinguish visually similar but different places. This inspires us to propose TextInPlace, a simple yet effective VPR framework that integrates Scene Text Spotting (STS) to mitigate visual perceptual ambiguity in repetitive indoor environments. Specifically, TextInPlace adopts a dual-branch architecture within a local parameter sharing network. The VPR branch employs attention-based aggregation to extract global descriptors for coarse-grained retrieval, while the STS branch utilizes a bridging text spotter to detect and recognize scene texts. Finally, the discriminative texts are filtered to compute text similarity and re-rank the top-K retrieved images. To bridge the gap between current text-based repetitive indoor scene datasets and the typical scenarios encountered in robot navigation, we establish an indoor VPR benchmark dataset, called Maze-with-Text. Extensive experiments on both custom and public datasets demonstrate that TextInPlace achieves superior performance over existing methods that rely solely on appearance information. The dataset, code, and trained models are publicly available at https://github.com/HqiTao/TextInPlace.",
    "source": "arXiv"
  },
  {
    "title": "From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers",
    "title_es": "From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers",
    "url": "https://arxiv.org/abs/2503.06923",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.06923v2 Announce Type: replace \nAbstract: Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99$\\times$ on FLUX and 5.00$\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$$\\times$ acceleration. %Our code is provided in the supplementary materials and will be made publicly available on GitHub. Our codes have been released in Github:https://github.com/Shenyi-Z/TaylorSeer",
    "source": "arXiv"
  },
  {
    "title": "MambaFlow: A Mamba-Centric Architecture for End-to-End Optical Flow Estimation",
    "title_es": "MambaFlow: A Mamba-Centric Architecture for End-to-End Optical Flow Estimation",
    "url": "https://arxiv.org/abs/2503.07046",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.07046v3 Announce Type: replace \nAbstract: Recently, the Mamba architecture has demonstrated significant successes in various computer vision tasks, such as classification and segmentation. However, its application to optical flow estimation remains unexplored. In this paper, we introduce MambaFlow, a novel framework designed to leverage the high accuracy and efficiency of the Mamba architecture for capturing locally correlated features while preserving global information in end-to-end optical flow estimation. To our knowledge, MambaFlow is the first architecture centered around the Mamba design tailored specifically for optical flow estimation. It comprises two key components: (1) PolyMamba, which enhances feature representation through a dual-Mamba architecture, incorporating a Self-Mamba module for intra-token modeling and a Cross-Mamba module for inter-modality interaction, enabling both deep contextualization and effective feature fusion; and (2) PulseMamba, which leverages an Attention Guidance Aggregator (AGA) to adaptively integrate features with dynamically learned weights in contrast to naive concatenation, and then employs the intrinsic recurrent mechanism of Mamba to perform autoregressive flow decoding, facilitating efficient flow information dissemination. Extensive experiments demonstrate that MambaFlow achieves remarkable results comparable to mainstream methods on benchmark datasets. Compared to SEA-RAFT, MambaFlow attains higher accuracy on the Sintel benchmark, demonstrating stronger potential for real-world deployment on resource-constrained devices. The source code will be made publicly available upon acceptance of the paper.",
    "source": "arXiv"
  },
  {
    "title": "Unleashing the Potential of Large Language Models for Text-to-Image Generation through Autoregressive Representation Alignment",
    "title_es": "Unleashing the Potential of Large Language Models for Text-to-Image Generation through Autoregressive Representation Alignment",
    "url": "https://arxiv.org/abs/2503.07334",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.07334v3 Announce Type: replace \nAbstract: We present Autoregressive Representation Alignment (ARRA), a new training framework that unlocks global-coherent text-to-image generation in autoregressive LLMs without architectural modifications. Different from prior works that require complex architectural redesigns, ARRA aligns LLM's hidden states with visual representations from external visual foundational models via a global visual alignment loss and a hybrid token, [object Object]. This token enforces dual constraints: local next-token prediction and global semantic distillation, enabling LLMs to implicitly learn spatial and contextual coherence while retaining their original autoregressive paradigm. Extensive experiments validate ARRA's plug-and-play versatility. When training T2I LLMs from scratch, ARRA reduces FID by 16.6% (ImageNet), 12.0% (LAION-COCO) for autoregressive LLMs like LlamaGen, without modifying original architecture and inference mechanism. For training from text-generation-only LLMs, ARRA reduces FID by 25.5% (MIMIC-CXR), 8.8% (DeepEyeNet) for advanced LLMs like Chameleon. For domain adaptation, ARRA aligns general-purpose LLMs with specialized models (e.g., BioMedCLIP), achieving an 18.6% FID reduction over direct fine-tuning on medical imaging (MIMIC-CXR). These results demonstrate that training objective redesign, rather than architectural modifications, can resolve cross-modal global coherence challenges. ARRA offers a complementary paradigm for advancing autoregressive models. The code is available at https://github.com/xiexing0916/ARRA.",
    "source": "arXiv"
  },
  {
    "title": "From Limited Labels to Open Domains:An Efficient Learning Method for Drone-view Geo-Localization",
    "title_es": "From Limited Labels to Open Domains:An Efficient Learning Method for Drone-view Geo-Localization",
    "url": "https://arxiv.org/abs/2503.07520",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.07520v2 Announce Type: replace \nAbstract: Traditional supervised drone-view geo-localization (DVGL) methods heavily depend on paired training data and encounter difficulties in learning cross-view correlations from unpaired data. Moreover, when deployed in a new domain, these methods require obtaining the new paired data and subsequent retraining for model adaptation, which significantly increases computational overhead. Existing unsupervised methods have enabled to generate pseudo-labels based on cross-view similarity to infer the pairing relationships. However, geographical similarity and spatial continuity often cause visually analogous features at different geographical locations. The feature confusion compromises the reliability of pseudo-label generation, where incorrect pseudo-labels drive negative optimization. Given these challenges inherent in both supervised and unsupervised DVGL methods, we propose a novel cross-domain invariant knowledge transfer network (CDIKTNet) with limited supervision, whose architecture consists of a cross-domain invariance sub-network (CDIS) and a cross-domain transfer sub-network (CDTS). This architecture facilitates a closed-loop framework for invariance feature learning and knowledge transfer. The CDIS is designed to learn cross-view structural and spatial invariance from a small amount of paired data that serves as prior knowledge. It endows the shared feature space of unpaired data with similar implicit cross-view correlations at initialization, which alleviates feature confusion. Based on this, the CDTS employs dual-path contrastive learning to further optimize each subspace while preserving consistency in a shared feature space. Extensive experiments demonstrate that CDIKTNet achieves state-of-the-art performance under full supervision compared with those supervised methods, and further surpasses existing unsupervised methods in both few-shot and cross-domain initialization.",
    "source": "arXiv"
  },
  {
    "title": "FunGraph: Functionality Aware 3D Scene Graphs for Language-Prompted Scene Interaction",
    "title_es": "FunGraph: Functionality Aware 3D Scene Graphs for Language-Prompted Scene Interaction",
    "url": "https://arxiv.org/abs/2503.07909",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.07909v2 Announce Type: replace \nAbstract: The concept of 3D scene graphs is increasingly recognized as a powerful semantic and hierarchical representation of the environment. Current approaches often address this at a coarse, object-level resolution. In contrast, our goal is to develop a representation that enables robots to directly interact with their environment by identifying both the location of functional interactive elements and how these can be used. To achieve this, we focus on detecting and storing objects at a finer resolution, focusing on affordance-relevant parts. The primary challenge lies in the scarcity of data that extends beyond instance-level detection and the inherent difficulty of capturing detailed object features using robotic sensors. We leverage currently available 3D resources to generate 2D data and train a detector, which is then used to augment the standard 3D scene graph generation pipeline. Through our experiments, we demonstrate that our approach achieves functional element segmentation comparable to state-of-the-art 3D models and that our augmentation enables task-driven affordance grounding with higher accuracy than the current solutions. See our project page at https://fungraph.github.io.",
    "source": "arXiv"
  },
  {
    "title": "Elastic Motion Policy: An Adaptive Dynamical System for Robust and Efficient One-Shot Imitation Learning",
    "title_es": "Elastic Motion Policy: An Adaptive Dynamical System for Robust and Efficient One-Shot Imitation Learning",
    "url": "https://arxiv.org/abs/2503.08029",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.08029v2 Announce Type: replace \nAbstract: Behavior cloning (BC) has become a staple imitation learning paradigm in robotics due to its ease of teaching robots complex skills directly from expert demonstrations. However, BC suffers from an inherent generalization issue. To solve this, the status quo solution is to gather more data. Yet, regardless of how much training data is available, out-of-distribution performance is still sub-par, lacks any formal guarantee of convergence and success, and is incapable of allowing and recovering from physical interactions with humans. These are critical flaws when robots are deployed in ever-changing human-centric environments. Thus, we propose Elastic Motion Policy (EMP), a one-shot imitation learning framework that allows robots to adjust their behavior based on the scene change while respecting the task specification. Trained from a single demonstration, EMP follows the dynamical systems paradigm where motion planning and control are governed by first-order differential equations with convergence guarantees. We leverage Laplacian editing in full end-effector space, $\\mathbb{R}^3\\times SO(3)$, and online convex learning of Lyapunov functions, to adapt EMP online to new contexts, avoiding the need to collect new demonstrations. We extensively validate our framework in real robot experiments, demonstrating its robust and efficient performance in dynamic environments, with obstacle avoidance and multi-step task capabilities. Project Website: https://elastic-motion-policy.github.io/EMP/",
    "source": "arXiv"
  },
  {
    "title": "New Constructions of Locally Perfect Nonlinear Functions and Their Application to Sequence Sets With Low Ambiguity Zone",
    "title_es": "New Constructions of Locally Perfect Nonlinear Functions and Their Application to Sequence Sets With Low Ambiguity Zone",
    "url": "https://arxiv.org/abs/2503.09172",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.09172v3 Announce Type: replace \nAbstract: Low Ambiguity Zone (LAZ) sequences play a pivotal role in modern integrated sensing and communication (ISAC) systems. Recently, Wang \\textit{et al.} [arXiv:2501.11313] proposed a definition of locally perfect nonlinear functions (LPNFs) and constructed three classes of both periodic and aperiodic LAZ sequence sets with flexible parameters by applying such functions and interleaving techniques. Some of these LAZ sequence sets are asymptotically optimal with respect to the Ye-Zhou-Fan-Liu-Lei-Tang bounds under certain conditions. In this paper, we present constructions of three new classes of LPNFs with new parameters. Based on these LPNFs, we further propose a series of LAZ sequence sets that offer more flexible parameters. Furthermore, our results show that some of these classes are asymptotically optimal in both the periodic and aperiodic cases, respectively.",
    "source": "arXiv"
  },
  {
    "title": "A Planning Compilation to Reason about Goal Achievement at Planning Time",
    "title_es": "A Planning Compilation to Reason about Goal Achievement at Planning Time",
    "url": "https://arxiv.org/abs/2503.09545",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.09545v2 Announce Type: replace \nAbstract: Identifying the specific actions that achieve goals when solving a planning task might be beneficial for various planning applications. Traditionally, this identification occurs post-search, as some actions may temporarily achieve goals that are later undone and re-achieved by other actions. In this paper, we propose a compilation that extends the original planning task with commit actions that enforce the persistence of specific goals once achieved, allowing planners to identify permanent goal achievement during planning. Experimental results indicate that solving the reformulated tasks does not incur on any additional overhead both when performing optimal and suboptimal planning, while providing useful information for some downstream tasks.",
    "source": "arXiv"
  },
  {
    "title": "Mapless Collision-Free Flight via MPC using Dual KD-Trees in Cluttered Environments",
    "title_es": "Mapless Collision-Free Flight via MPC using Dual KD-Trees in Cluttered Environments",
    "url": "https://arxiv.org/abs/2503.10141",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.10141v3 Announce Type: replace \nAbstract: Collision-free flight in cluttered environments is a critical capability for autonomous quadrotors. Traditional methods often rely on detailed 3D map construction, trajectory generation, and tracking. However, this cascade pipeline can introduce accumulated errors and computational delays, limiting flight agility and safety. In this paper, we propose a novel method for enabling collision-free flight in cluttered environments without explicitly constructing 3D maps or generating and tracking collision-free trajectories. Instead, we leverage Model Predictive Control (MPC) to directly produce safe actions from sparse waypoints and point clouds from a depth camera. These sparse waypoints are dynamically adjusted online based on nearby obstacles detected from point clouds. To achieve this, we introduce a dual KD-Tree mechanism: the Obstacle KD-Tree quickly identifies the nearest obstacle for avoidance, while the Edge KD-Tree provides a robust initial guess for the MPC solver, preventing it from getting stuck in local minima during obstacle avoidance. We validate our approach through extensive simulations and real-world experiments. The results show that our approach significantly outperforms the mapping-based methods and is also superior to imitation learning-based methods, demonstrating reliable obstacle avoidance at up to 12 m/s in simulations and 6 m/s in real-world tests. Our method provides a simple and robust alternative to existing methods. The code is publicly available at https://github.com/SJTU-ViSYS-team/avoid-mpc.",
    "source": "arXiv"
  },
  {
    "title": "ROODI: Reconstructing Occluded Objects with Denoising Inpainters",
    "title_es": "ROODI: Reconstructing Occluded Objects with Denoising Inpainters",
    "url": "https://arxiv.org/abs/2503.10256",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.10256v2 Announce Type: replace \nAbstract: While the quality of novel-view images has improved dramatically with 3D Gaussian Splatting, extracting specific objects from scenes remains challenging. Isolating individual 3D Gaussian primitives for each object and handling occlusions in scenes remains far from being solved. We propose a novel object extraction method based on two key principles: (1) object-centric reconstruction through removal of irrelevant primitives; and (2) leveraging generative inpainting to compensate for missing observations caused by occlusions. For pruning, we propose to remove irrelevant Gaussians by looking into how close they are to its K-nearest neighbors and removing those that are statistical outliers. Importantly, these distances must take into account the actual spatial extent they cover -- we thus propose to use Wasserstein distances. For inpainting, we employ an off-the-shelf diffusion-based inpainter combined with occlusion reasoning, utilizing the 3D representation of the entire scene. Our findings highlight the crucial synergy between proper pruning and inpainting, both of which significantly enhance extraction performance. We evaluate our method on a standard real-world dataset and introduce a synthetic dataset for quantitative analysis. Our approach outperforms the state-of-the-art, demonstrating its effectiveness in object extraction from complex scenes.",
    "source": "arXiv"
  },
  {
    "title": "VFM-UDA++: Improving Network Architectures and Data Strategies for Unsupervised Domain Adaptive Semantic Segmentation",
    "title_es": "VFM-UDA++: Improving Network Architectures and Data Strategies for Unsupervised Domain Adaptive Semantic Segmentation",
    "url": "https://arxiv.org/abs/2503.10685",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.10685v2 Announce Type: replace \nAbstract: Unsupervised Domain Adaptation (UDA) enables strong generalization from a labeled source domain to an unlabeled target domain, often with limited data. In parallel, Vision Foundation Models (VFMs) pretrained at scale without labels have also shown impressive downstream performance and generalization. This motivates us to explore how UDA can best leverage VFMs. Prior work (VFM-UDA) demonstrated that replacing a standard ImageNet-pretrained encoder with a VFM improves generalization. However, it also showed that commonly used feature distance losses harm performance when applied to VFMs. Additionally, VFM-UDA does not incorporate multi-scale inductive biases, which are known to improve semantic segmentation. Building on these insights, we propose VFM-UDA++, which (1) investigates the role of multi-scale features, (2) adapts feature distance loss to be compatible with ViT-based VFMs and (3) evaluates how UDA benefits from increased synthetic source and real target data. By addressing these questions, we can improve performance on the standard GTA5 $\\rightarrow$ Cityscapes benchmark by +1.4 mIoU. While prior non-VFM UDA methods did not scale with more data, VFM-UDA++ shows consistent improvement and achieves a further +2.4 mIoU gain when scaling the data, demonstrating that VFM-based UDA continues to benefit from increased data availability.",
    "source": "arXiv"
  },
  {
    "title": "X-EcoMLA: Upcycling Pre-Trained Attention into MLA for Efficient and Extreme KV Compression",
    "title_es": "X-EcoMLA: Upcycling Pre-Trained Attention into MLA for Efficient and Extreme KV Compression",
    "url": "https://arxiv.org/abs/2503.11132",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.11132v3 Announce Type: replace \nAbstract: Multi-head latent attention (MLA) is designed to optimize KV cache memory through low-rank key-value joint compression. Rather than caching keys and values separately, MLA stores their compressed latent representations, reducing memory overhead while maintaining the performance. While MLA improves memory efficiency without compromising language model accuracy, its major limitation lies in its integration during the pre-training phase, requiring models to be trained from scratch. This raises a key question: can we use MLA's benefits fully or partially in models that have already been pre-trained with different attention mechanisms? In this paper, we propose X-EcoMLA to deploy post training distillation to enable the upcycling of Transformer-based attention into an efficient hybrid MLA variant through lightweight post-training adaptation, bypassing the need for extensive pre-training. We demonstrate that leveraging the dark knowledge of a well-trained model can enhance training accuracy and enable extreme KV cache compression in MLA without compromising model performance. The experimental results show that our proposed method can effectively compress the KV cache while preserving the performance on the benchmarks; specifically, for Llama3.2-1B-Instruct baseline, a 6.4x compression achieves the same average score by using only 3.6B training tokens and 70 GPU hours on AMD MI300, whereas a 10.6x compression have less than 0.1% average score drop with 7B training tokens and 140 GPU hours. The code for this work is available at https://github.com/AMD-AIG-AIMA/AMD-Hybrid-Models.",
    "source": "arXiv"
  },
  {
    "title": "AR-1-to-3: Single Image to Consistent 3D Object Generation via Next-View Prediction",
    "title_es": "AR-1-to-3: Single Image to Consistent 3D Object Generation via Next-View Prediction",
    "url": "https://arxiv.org/abs/2503.12929",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.12929v4 Announce Type: replace \nAbstract: Novel view synthesis (NVS) is a cornerstone for image-to-3d creation. However, existing works still struggle to maintain consistency between the generated views and the input views, especially when there is a significant camera pose difference, leading to poor-quality 3D geometries and textures. We attribute this issue to their treatment of all target views with equal priority according to our empirical observation that the target views closer to the input views exhibit higher fidelity. With this inspiration, we propose AR-1-to-3, a novel next-view prediction paradigm based on diffusion models that first generates views close to the input views, which are then utilized as contextual information to progressively synthesize farther views. To encode the generated view subsequences as local and global conditions for the next-view prediction, we accordingly develop a stacked local feature encoding strategy (Stacked-LE) and an LSTM-based global feature encoding strategy (LSTM-GE). Extensive experiments demonstrate that our method significantly improves the consistency between the generated views and the input views, producing high-fidelity 3D assets.",
    "source": "arXiv"
  },
  {
    "title": "Gradient Extrapolation for Debiased Representation Learning",
    "title_es": "Gradient Extrapolation for Debiased Representation Learning",
    "url": "https://arxiv.org/abs/2503.13236",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.13236v2 Announce Type: replace \nAbstract: Machine learning classification models trained with empirical risk minimization (ERM) often inadvertently rely on spurious correlations. When absent in the test data, these unintended associations between non-target attributes and target labels lead to poor generalization. This paper addresses this problem from a model optimization perspective and proposes a novel method, Gradient Extrapolation for Debiased Representation Learning (GERNE), designed to learn debiased representations in both known and unknown attribute training cases. GERNE uses two distinct batches with different amounts of spurious correlations and defines the target gradient as a linear extrapolation of the gradients computed from each batch's loss. Our analysis shows that when the extrapolated gradient points toward the batch gradient with fewer spurious correlations, it effectively guides training toward learning a debiased model. GERNE serves as a general framework for debiasing, encompassing ERM and Resampling methods as special cases. We derive the theoretical upper and lower bounds of the extrapolation factor employed by GERNE. By tuning this factor, GERNE can adapt to maximize either Group-Balanced Accuracy (GBA) or Worst-Group Accuracy (WGA). We validate GERNE on five vision and one NLP benchmarks, demonstrating competitive and often superior performance compared to state-of-the-art baselines. The project page is available at: https://gerne-debias.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "Empirical Analysis of Privacy-Fairness-Accuracy Trade-offs in Federated Learning: A Step Towards Responsible AI",
    "title_es": "Empirical Analysis of Privacy-Fairness-Accuracy Trade-offs in Federated Learning: A Step Towards Responsible AI",
    "url": "https://arxiv.org/abs/2503.16233",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.16233v2 Announce Type: replace \nAbstract: Federated Learning (FL) enables collaborative model training while preserving data privacy; however, balancing privacy preservation (PP) and fairness poses significant challenges. In this paper, we present the first unified large-scale empirical study of privacy-fairness-utility trade-offs in FL, advancing toward responsible AI deployment. Specifically, we systematically compare Differential Privacy (DP), Homomorphic Encryption (HE), and Secure Multi-Party Computation (SMC) with fairness-aware optimizers including q-FedAvg, q-MAML, Ditto, evaluating their performance under IID and non-IID scenarios using benchmark (MNIST, Fashion-MNIST) and real-world datasets (Alzheimer's MRI, credit-card fraud detection). Our analysis reveals HE and SMC significantly outperform DP in achieving equitable outcomes under data skew, although at higher computational costs. Remarkably, we uncover unexpected interactions: DP mechanisms can negatively impact fairness, and fairness-aware optimizers can inadvertently reduce privacy effectiveness. We conclude with practical guidelines for designing robust FL systems that deliver equitable, privacy-preserving, and accurate outcomes.",
    "source": "arXiv"
  },
  {
    "title": "EDiT: Efficient Diffusion Transformers with Linear Compressed Attention",
    "title_es": "EDiT: Efficient Diffusion Transformers with Linear Compressed Attention",
    "url": "https://arxiv.org/abs/2503.16726",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.16726v2 Announce Type: replace \nAbstract: Diffusion Transformers (DiTs) have emerged as a leading architecture for text-to-image synthesis, producing high-quality and photorealistic images. However, the quadratic scaling properties of the attention in DiTs hinder image generation with higher resolution or on devices with limited resources. This work introduces an efficient diffusion transformer (EDiT) to alleviate these efficiency bottlenecks in conventional DiTs and Multimodal DiTs (MM-DiTs). First, we present a novel linear compressed attention method that uses a multi-layer convolutional network to modulate queries with local information while keys and values are aggregated spatially. Second, we formulate a hybrid attention scheme for multimodal inputs that combines linear attention for image-to-image interactions and standard scaled dot-product attention for interactions involving prompts. Merging these two approaches leads to an expressive, linear-time Multimodal Efficient Diffusion Transformer (MM-EDiT). We demonstrate the effectiveness of the EDiT and MM-EDiT architectures by integrating them into PixArt-Sigma (conventional DiT) and Stable Diffusion 3.5-Medium (MM-DiT), achieving up to 2.2x speedup with comparable image quality after distillation.",
    "source": "arXiv"
  },
  {
    "title": "Generating, Fast and Slow: Scalable Parallel Video Generation with Video Interface Networks",
    "title_es": "Generating, Fast and Slow: Scalable Parallel Video Generation with Video Interface Networks",
    "url": "https://arxiv.org/abs/2503.17539",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.17539v2 Announce Type: replace \nAbstract: Diffusion Transformers (DiTs) can generate short photorealistic videos, yet directly training and sampling longer videos with full attention across the video remains computationally challenging. Alternative methods break long videos down into sequential generation of short video segments, requiring multiple sampling chain iterations and specialized consistency modules. To overcome these challenges, we introduce a new paradigm called Video Interface Networks (VINs), which augment DiTs with an abstraction module to enable parallel inference of video chunks. At each diffusion step, VINs encode global semantics from the noisy input of local chunks and the encoded representations, in turn, guide DiTs in denoising chunks in parallel. The coupling of VIN and DiT is learned end-to-end on the denoising objective. Further, the VIN architecture maintains fixed-size encoding tokens that encode the input via a single cross-attention step. Disentangling the encoding tokens from the input thus enables VIN to scale to long videos and learn essential semantics. Experiments on VBench demonstrate that VINs surpass existing chunk-based methods in preserving background consistency and subject coherence. We then show via an optical flow analysis that our approach attains state-of-the-art motion smoothness while using 25-40% fewer FLOPs than full generation. Finally, human raters favorably assessed the overall video quality and temporal consistency of our method in a user study.",
    "source": "arXiv"
  },
  {
    "title": "Learning 3D Object Spatial Relationships from Pre-trained 2D Diffusion Models",
    "title_es": "Learning 3D Object Spatial Relationships from Pre-trained 2D Diffusion Models",
    "url": "https://arxiv.org/abs/2503.19914",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.19914v2 Announce Type: replace \nAbstract: We present a method for learning 3D spatial relationships between object pairs, referred to as object-object spatial relationships (OOR), by leveraging synthetically generated 3D samples from pre-trained 2D diffusion models. We hypothesize that images synthesized by 2D diffusion models inherently capture realistic OOR cues, enabling efficient collection of a 3D dataset to learn OOR for various unbounded object categories. Our approach synthesizes diverse images that capture plausible OOR cues, which we then uplift into 3D samples. Leveraging our diverse collection of 3D samples for the object pairs, we train a score-based OOR diffusion model to learn the distribution of their relative spatial relationships. Additionally, we extend our pairwise OOR to multi-object OOR by enforcing consistency across pairwise relations and preventing object collisions. Extensive experiments demonstrate the robustness of our method across various object-object spatial relationships, along with its applicability to 3D scene arrangement tasks and human motion synthesis using our OOR diffusion model.",
    "source": "arXiv"
  },
  {
    "title": "Learning Adaptive Dexterous Grasping from Single Demonstrations",
    "title_es": "Learning Adaptive Dexterous Grasping from Single Demonstrations",
    "url": "https://arxiv.org/abs/2503.20208",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.20208v2 Announce Type: replace \nAbstract: How can robots learn dexterous grasping skills efficiently and apply them adaptively based on user instructions? This work tackles two key challenges: efficient skill acquisition from limited human demonstrations and context-driven skill selection. We introduce AdaDexGrasp, a framework that learns a library of grasping skills from a single human demonstration per skill and selects the most suitable one using a vision-language model (VLM). To improve sample efficiency, we propose a trajectory following reward that guides reinforcement learning (RL) toward states close to a human demonstration while allowing flexibility in exploration. To learn beyond the single demonstration, we employ curriculum learning, progressively increasing object pose variations to enhance robustness. At deployment, a VLM retrieves the appropriate skill based on user instructions, bridging low-level learned skills with high-level intent. We evaluate AdaDexGrasp in both simulation and real-world settings, showing that our approach significantly improves RL efficiency and enables learning human-like grasp strategies across varied object configurations. Finally, we demonstrate zero-shot transfer of our learned policies to a real-world PSYONIC Ability Hand, with a 90% success rate across objects, significantly outperforming the baseline.",
    "source": "arXiv"
  },
  {
    "title": "Both Direct and Indirect Evidence Contribute to Dative Alternation Preferences in Language Models",
    "title_es": "Both Direct and Indirect Evidence Contribute to Dative Alternation Preferences in Language Models",
    "url": "https://arxiv.org/abs/2503.20850",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.20850v3 Announce Type: replace \nAbstract: Language models (LMs) tend to show human-like preferences on a number of syntactic phenomena, but the extent to which these are attributable to direct exposure to the phenomena or more general properties of language is unclear. We explore this with the English dative alternation (DO: \"gave Y the X\" vs. PO: \"gave the X to Y\"), using a controlled rearing paradigm wherein we iteratively train small LMs on systematically manipulated input. We focus on two properties that affect the choice of alternant: length and animacy. Both properties are directly present in datives but also reflect more global tendencies for shorter elements to precede longer ones and animates to precede inanimates. First, by manipulating and ablating datives for these biases in the input, we show that direct evidence of length and animacy matters, but easy-first preferences persist even without such evidence. Then, using LMs trained on systematically perturbed datasets to manipulate global length effects (re-linearizing sentences globally while preserving dependency structure), we find that dative preferences can emerge from indirect evidence. We conclude that LMs' emergent syntactic preferences come from a mix of direct and indirect sources.",
    "source": "arXiv"
  },
  {
    "title": "Uncertainty propagation in feed-forward neural network models",
    "title_es": "Uncertainty propagation in feed-forward neural network models",
    "url": "https://arxiv.org/abs/2503.21059",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.21059v3 Announce Type: replace \nAbstract: We develop new uncertainty propagation methods for feed-forward neural network architectures with leaky ReLU activation functions subject to random perturbations in the input vectors. In particular, we derive analytical expressions for the probability density function (PDF) of the neural network output and its statistical moments as a function of the input uncertainty and the parameters of the network, i.e., weights and biases. A key finding is that an appropriate linearization of the leaky ReLU activation function yields accurate statistical results even for large perturbations in the input vectors. This can be attributed to the way information propagates through the network. We also propose new analytically tractable Gaussian copula surrogate models to approximate the full joint PDF of the neural network output. To validate our theoretical results, we conduct Monte Carlo simulations and a thorough error analysis on a multi-layer neural network representing a nonlinear integro-differential operator between two polynomial function spaces. Our findings demonstrate excellent agreement between the theoretical predictions and Monte Carlo simulations.",
    "source": "arXiv"
  },
  {
    "title": "GAITGen: Disentangled Motion-Pathology Impaired Gait Generative Model -- Bringing Motion Generation to the Clinical Domain",
    "title_es": "GAITGen: Disentangled Motion-Pathology Impaired Gait Generative Model -- Bringing Motion Generation to the Clinical Domain",
    "url": "https://arxiv.org/abs/2503.22397",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.22397v2 Announce Type: replace \nAbstract: Gait analysis is crucial for the diagnosis and monitoring of movement disorders like Parkinson's Disease. While computer vision models have shown potential for objectively evaluating parkinsonian gait, their effectiveness is limited by scarce clinical datasets and the challenge of collecting large and well-labelled data, impacting model accuracy and risk of bias. To address these gaps, we propose GAITGen, a novel framework that generates realistic gait sequences conditioned on specified pathology severity levels. GAITGen employs a Conditional Residual Vector Quantized Variational Autoencoder to learn disentangled representations of motion dynamics and pathology-specific factors, coupled with Mask and Residual Transformers for conditioned sequence generation. GAITGen generates realistic, diverse gait sequences across severity levels, enriching datasets and enabling large-scale model training in parkinsonian gait analysis. Experiments on our new PD-GaM (real) dataset demonstrate that GAITGen outperforms adapted state-of-the-art models in both reconstruction fidelity and generation quality, accurately capturing critical pathology-specific gait features. A clinical user study confirms the realism and clinical relevance of our generated sequences. Moreover, incorporating GAITGen-generated data into downstream tasks improves parkinsonian gait severity estimation, highlighting its potential for advancing clinical gait analysis.",
    "source": "arXiv"
  },
  {
    "title": "SSM-RDU: A Reconfigurable Dataflow Unit for Long-Sequence State-Space Models",
    "title_es": "SSM-RDU: A Reconfigurable Dataflow Unit for Long-Sequence State-Space Models",
    "url": "https://arxiv.org/abs/2503.22937",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.22937v2 Announce Type: replace \nAbstract: Long-sequence state-space models (SSMs) such as Hyena and Mamba replace the quadratic complexity of self-attention with more efficient FFT and scan operations. However, modern accelerators like GPUs are poorly suited to these non-GEMM workloads due to rigid execution models and specialization for dense matrix operations. This paper proposes architectural extensions to a baseline Reconfigurable Dataflow Unit (RDU) that efficiently support FFT-based and scan-based SSMs. By introducing lightweight interconnect enhancements within compute tiles, the extended RDU enables spatial mapping of FFT and scan dataflows with less than 1% area and power overhead. The resulting architecture achieves a 5.95X speedup over the GPU and a 1.95X speedup over the baseline RDU for Hyena, and a 2.12X and 1.75X speedup over the GPU and baseline RDU, respectively, for Mamba.",
    "source": "arXiv"
  },
  {
    "title": "Learning 3D-Gaussian Simulators from RGB Videos",
    "title_es": "Learning 3D-Gaussian Simulators from RGB Videos",
    "url": "https://arxiv.org/abs/2503.24009",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.24009v2 Announce Type: replace \nAbstract: Realistic simulation is critical for applications ranging from robotics to animation. Learned simulators have emerged as a possibility to capture real world physics directly from video data, but very often require privileged information such as depth information, particle tracks and hand-engineered features to maintain spatial and temporal consistency. These strong inductive biases or ground truth 3D information help in domains where data is sparse but limit scalability and generalization in data rich regimes. To overcome the key limitations, we propose 3DGSim, a learned 3D simulator that directly learns physical interactions from multi-view RGB videos. 3DGSim unifies 3D scene reconstruction, particle dynamics prediction and video synthesis into an end-to-end trained framework. It adopts MVSplat to learn a latent particle-based representation of 3D scenes, a Point Transformer for particle dynamics, a Temporal Merging module for consistent temporal aggregation and Gaussian Splatting to produce novel view renderings. By jointly training inverse rendering and dynamics forecasting, 3DGSim embeds the physical properties into point-wise latent features. This enables the model to capture diverse physical behaviors, from rigid to elastic, cloth-like dynamics, and boundary conditions (e.g. fixed cloth corner), along with realistic lighting effects that also generalize to unseen multibody interactions and novel scene edits.",
    "source": "arXiv"
  },
  {
    "title": "Organizations, teams, and job mobility: A social microdynamics approach",
    "title_es": "Organizations, teams, and job mobility: A social microdynamics approach",
    "url": "https://arxiv.org/abs/2503.24117",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.24117v2 Announce Type: replace \nAbstract: Most of the modeling approaches used to understand organizational worker mobility are highly stylized, using idealizations such as structureless organizations, indistinguishable workers, and a lack of social bonding of the workers. In this article, aided by a decade of precise, temporally resolved data of a large civilian organization of the US Army in which employees can change jobs in a similar way to many private organizations, we introduce a new framework to describe organizations as composites of teams within which individuals perform specific tasks and where social connections develop. By tracking the personnel composition of organizational teams, we find that workers who change jobs are highly influenced by preferring to reunite with past coworkers. In this organization, 34% of all moves across temporally stable teams (and 32% of the totality of moves) lead to worker reunions, percentages that have not been reported and are well-above intuitive expectation. To assess the importance of worker reunions in determining job moves, we compare them to labor supply and demand with or without occupational specialization. The comparison shows that the most consistent information about job change is provided by reunions. We find that the greater the time workers spend together or the smaller the team they share both increase their likelihood to reunite, supporting the notion of increased familiarity and trust behind such reunions and the dominant role of social capital in the evolution of large organizations. Our study of this organization supports the idea that to correctly forecast job mobility inside large organizations, their teams structures and the social ties formed in those teams play a key role in shaping internal job change.",
    "source": "arXiv"
  },
  {
    "title": "$\\mu$KE: Matryoshka Unstructured Knowledge Editing of Large Language Models",
    "title_es": "$\\mu$KE: Matryoshka Unstructured Knowledge Editing of Large Language Models",
    "url": "https://arxiv.org/abs/2504.01196",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.01196v2 Announce Type: replace \nAbstract: Large language models (LLMs) have emerged as powerful knowledge bases yet are limited by static training data, leading to issues such as hallucinations and safety risks. Editing a model's internal knowledge through the locate-and-edit paradigm has proven a cost-effective alternative to retraining, though current unstructured approaches, especially window-based autoregressive methods, often disrupt the causal dependency between early memory updates and later output tokens. In this work, we first theoretically analyze these limitations and then introduce Matryoshka Unstructured Knowledge Editing ($\\mu$KE), a novel memory update mechanism that preserves such dependencies via a Matryoshka-style objective and adaptive loss coefficients. Empirical evaluations on two models across four benchmarks demonstrate that $\\mu$KE improves edit efficacy by up to 12.33% over state-of-the-art methods, and remains robust when applied to diverse formatted edits, underscoring its potential for effective unstructured knowledge editing in LLMs.",
    "source": "arXiv"
  },
  {
    "title": "UniCalib: Targetless LiDAR-Camera Calibration via Probabilistic Flow on Unified Depth Representations",
    "title_es": "UniCalib: Targetless LiDAR-Camera Calibration via Probabilistic Flow on Unified Depth Representations",
    "url": "https://arxiv.org/abs/2504.01416",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.01416v2 Announce Type: replace \nAbstract: Precise LiDAR-camera calibration is crucial for integrating these two sensors into robotic systems to achieve robust perception. In applications like autonomous driving, online targetless calibration enables a prompt sensor misalignment correction from mechanical vibrations without extra targets. However, existing methods exhibit limitations in effectively extracting consistent features from LiDAR and camera data and fail to prioritize salient regions, compromising cross-modal alignment robustness. To address these issues, we propose DF-Calib, a LiDAR-camera calibration method that reformulates calibration as an intra-modality depth flow estimation problem. DF-Calib estimates a dense depth map from the camera image and completes the sparse LiDAR projected depth map, using a shared feature encoder to extract consistent depth-to-depth features, effectively bridging the 2D-3D cross-modal gap. Additionally, we introduce a reliability map to prioritize valid pixels and propose a perceptually weighted sparse flow loss to enhance depth flow estimation. Experimental results across multiple datasets validate its accuracy and generalization,with DF-Calib achieving a mean translation error of 0.635cm and rotation error of 0.045 degrees on the KITTI dataset.",
    "source": "arXiv"
  },
  {
    "title": "FastER: Fast On-Demand Entity Resolution in Property Graphs",
    "title_es": "FastER: Fast On-Demand Entity Resolution in Property Graphs",
    "url": "https://arxiv.org/abs/2504.01557",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.01557v2 Announce Type: replace \nAbstract: Entity resolution (ER) is the problem of identifying and linking database records that refer to the same real-world entity. Traditional ER methods use batch processing, which becomes impractical with growing data volumes due to high computational costs and lack of real-time capabilities. In many applications, users need to resolve entities for only a small portion of their data, making full data processing unnecessary -- a scenario known as \"ER-on-demand\". This paper proposes FastER, an efficient ER-on-demand framework for property graphs. Our approach uses graph differential dependencies (GDDs) as a knowledge encoding language to design effective filtering mechanisms that leverage both structural and attribute semantics of graphs. We construct a blocking graph from filtered subgraphs to reduce the number of candidate entity pairs requiring comparison. Additionally, FastER incorporates Progressive Profile Scheduling (PPS), allowing the system to incrementally produce results throughout the resolution process. Extensive evaluations on multiple benchmark datasets demonstrate that FastER significantly outperforms state-of-the-art ER methods in computational efficiency and real-time processing for on-demand tasks while ensuring reliability. We make FastER publicly available at: https://anonymous.4open.science/r/On_Demand_Entity_Resolution-9DFB",
    "source": "arXiv"
  },
  {
    "title": "Overcoming Vocabulary Constraints with Pixel-level Fallback",
    "title_es": "Overcoming Vocabulary Constraints with Pixel-level Fallback",
    "url": "https://arxiv.org/abs/2504.02122",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.02122v2 Announce Type: replace \nAbstract: Subword tokenization requires balancing computational efficiency and vocabulary coverage, which often leads to suboptimal performance on languages and scripts not prioritized during training. We propose to augment pretrained language models with a vocabulary-free encoder that generates input embeddings from text rendered as pixels. Through experiments on English-centric language models, we demonstrate that our approach substantially improves machine translation performance and facilitates effective cross-lingual transfer, outperforming tokenizer-based methods. Furthermore, we find that pixel-based representations outperform byte-level approaches and standard vocabulary expansion. Our approach enhances the multilingual capabilities of monolingual language models without extensive retraining and reduces decoding latency via input compression.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging Sparse Annotations for Leukemia Diagnosis on the Large Leukemia Dataset",
    "title_es": "Leveraging Sparse Annotations for Leukemia Diagnosis on the Large Leukemia Dataset",
    "url": "https://arxiv.org/abs/2504.02602",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.02602v2 Announce Type: replace \nAbstract: Leukemia is the 10th most frequently diagnosed cancer and one of the leading causes of cancer-related deaths worldwide. Realistic analysis of leukemia requires white blood cell (WBC) localization, classification, and morphological assessment. Despite deep learning advances in medical imaging, leukemia analysis lacks a large, diverse multi-task dataset, while existing small datasets lack domain diversity, limiting real-world applicability. To overcome dataset challenges, we present a large-scale WBC dataset named Large Leukemia Dataset (LLD) and novel methods for detecting WBC with their attributes. Our contribution here is threefold. First, we present a large-scale Leukemia dataset collected through Peripheral Blood Films (PBF) from 48 patients, through multiple microscopes, multi-cameras, and multi-magnification. To enhance diagnosis explainability and medical expert acceptance, each leukemia cell is annotated at 100x with 7 morphological attributes, ranging from Cell Size to Nuclear Shape. Secondly, we propose a multi-task model that not only detects WBCs but also predicts their attributes, providing an interpretable and clinically meaningful solution. Third, we propose a method for WBC detection with attribute analysis using sparse annotations. This approach reduces the annotation burden on hematologists, requiring them to mark only a small area within the field of view. Our method enables the model to leverage the entire field of view rather than just the annotated regions, enhancing learning efficiency and diagnostic accuracy. From diagnosis explainability to overcoming domain-shift challenges, the presented datasets can be used for many challenging aspects of microscopic image analysis. The datasets, code, and demo are available at: https://im.itu.edu.pk/sparse-leukemiaattri/",
    "source": "arXiv"
  },
  {
    "title": "How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge, Truthfulness, Refusal, and Confidence",
    "title_es": "How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge, Truthfulness, Refusal, and Confidence",
    "url": "https://arxiv.org/abs/2504.02904",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.02904v2 Announce Type: replace \nAbstract: Post-training is essential for the success of large language models (LLMs), transforming pre-trained base models into more useful and aligned post-trained models. While plenty of works have studied post-training algorithms and evaluated post-training models by their outputs, it remains understudied how post-training reshapes LLMs internally. In this paper, we compare base and post-trained LLMs mechanistically from four perspectives to better understand post-training effects. Our findings across model families and datasets reveal that: (1) Post-training does not change the factual knowledge storage locations, and it adapts knowledge representations from the base model while developing new knowledge representations; (2) Both truthfulness and refusal can be represented by vectors in the hidden representation space. The truthfulness direction is highly similar between the base and post-trained model, and it is effectively transferable for interventions; (3) The refusal direction is different between the base and post-trained models, and it shows limited forward transferability; (4) Differences in confidence between the base and post-trained models cannot be attributed to entropy neurons. Our study provides insights into the fundamental mechanisms preserved and altered during post-training, facilitates downstream tasks like model steering, and could potentially benefit future research in interpretability and LLM post-training. Our code is publicly available at https://github.com/HZD01/post-training-mechanistic-analysis.",
    "source": "arXiv"
  },
  {
    "title": "Bidirectional Hierarchical Protein Multi-Modal Representation Learning",
    "title_es": "Bidirectional Hierarchical Protein Multi-Modal Representation Learning",
    "url": "https://arxiv.org/abs/2504.04770",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.04770v2 Announce Type: replace \nAbstract: Protein representation learning is critical for numerous biological tasks. Recently, large transformer-based protein language models (pLMs) pretrained on large scale protein sequences have demonstrated significant success in sequence-based tasks. However, pLMs lack structural context. Conversely, graph neural networks (GNNs) designed to leverage 3D structural information have shown promising generalization in protein-related prediction tasks, but their effectiveness is often constrained by the scarcity of labeled structural data. Recognizing that sequence and structural representations are complementary perspectives of the same protein entity, we propose a multimodal bidirectional hierarchical fusion framework to effectively merge these modalities. Our framework employs attention and gating mechanisms to enable effective interaction between pLMs-generated sequential representations and GNN-extracted structural features, improving information exchange and enhancement across layers of the neural network. This bidirectional and hierarchical (Bi-Hierarchical) fusion approach leverages the strengths of both modalities to capture richer and more comprehensive protein representations. Based on the framework, we further introduce local Bi-Hierarchical Fusion with gating and global Bi-Hierarchical Fusion with multihead self-attention approaches. Our method demonstrates consistent improvements over strong baselines and existing fusion techniques in a variety of protein representation learning benchmarks, including enzyme EC classification, model quality assessment, protein-ligand binding affinity prediction, protein-protein binding site prediction, and B cell epitopes prediction. Our method establishes a new state-of-the-art for multimodal protein representation learning, emphasizing the efficacy of Bi-Hierarchical Fusion in bridging sequence and structural modalities.",
    "source": "arXiv"
  },
  {
    "title": "NoveltyBench: Evaluating Language Models for Humanlike Diversity",
    "title_es": "NoveltyBench: Evaluating Language Models for Humanlike Diversity",
    "url": "https://arxiv.org/abs/2504.05228",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.05228v4 Announce Type: replace \nAbstract: Language models have demonstrated remarkable capabilities on standard benchmarks, yet they struggle increasingly from mode collapse, the inability to generate diverse and novel outputs. Our work introduces NoveltyBench, a benchmark specifically designed to evaluate the ability of language models to produce multiple distinct and high-quality outputs. NoveltyBench utilizes prompts curated to elicit diverse answers and filtered real-world user queries. Evaluating 20 leading language models, we find that current state-of-the-art systems generate significantly less diversity than human writers. Notably, larger models within a family often exhibit less diversity than their smaller counterparts, challenging the notion that capability on standard benchmarks translates directly to generative utility. While prompting strategies like in-context regeneration can elicit diversity, our findings highlight a fundamental lack of distributional diversity in current models, reducing their utility for users seeking varied responses and suggesting the need for new training and evaluation paradigms that prioritize diversity alongside quality.",
    "source": "arXiv"
  },
  {
    "title": "Model-Agnostic Policy Explanations with Large Language Models",
    "title_es": "Model-Agnostic Policy Explanations with Large Language Models",
    "url": "https://arxiv.org/abs/2504.05625",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.05625v2 Announce Type: replace \nAbstract: Intelligent agents, such as robots, are increasingly deployed in real-world, human-centric environments. To foster appropriate human trust and meet legal and ethical standards, these agents must be able to explain their behavior. However, state-of-the-art agents are typically driven by black-box models like deep neural networks, limiting their interpretability. We propose a method for generating natural language explanations of agent behavior based only on observed states and actions -- without access to the agent's underlying model. Our approach learns a locally interpretable surrogate model of the agent's behavior from observations, which then guides a large language model to generate plausible explanations with minimal hallucination. Empirical results show that our method produces explanations that are more comprehensible and correct than those from baselines, as judged by both language models and human evaluators. Furthermore, we find that participants in a user study more accurately predicted the agent's future actions when given our explanations, suggesting improved understanding of agent behavior.",
    "source": "arXiv"
  },
  {
    "title": "Resource-efficient Inference with Foundation Model Programs",
    "title_es": "Resource-efficient Inference with Foundation Model Programs",
    "url": "https://arxiv.org/abs/2504.07247",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.07247v2 Announce Type: replace \nAbstract: The inference-time resource costs of large language and vision models present a growing challenge in production deployments. We propose the use of foundation model programs, i.e., programs that can invoke foundation models with varying resource costs and performance, as an approach to this problem. Specifically, we present a method that translates a task into a program, then learns a policy for resource allocation that, on each input, selects foundation model \"backends\" for each program module. The policy uses smaller, cheaper backends to handle simpler subtasks, while allowing more complex subtasks to leverage larger, more capable models. We evaluate the method on two new \"streaming\" visual question-answering tasks in which a system answers a question on a sequence of inputs, receiving ground-truth feedback after each answer. Compared to monolithic multi-modal models, our implementation achieves up to 98% resource savings with minimal accuracy loss, demonstrating its potential for scalable and resource-efficient multi-modal inference.",
    "source": "arXiv"
  },
  {
    "title": "Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with Question Answering",
    "title_es": "Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with Question Answering",
    "url": "https://arxiv.org/abs/2504.07583",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.07583v3 Announce Type: replace \nAbstract: Despite the steady progress in machine translation evaluation, existing automatic metrics struggle to capture how well meaning is preserved beyond sentence boundaries. We posit that reliance on a single intrinsic quality score, trained to mimic human judgments, might be insufficient for evaluating translations of long, complex passages, and a more ``pragmatic'' approach that assesses how accurately key information is conveyed by a translation in context is needed. We introduce TREQA (Translation Evaluation via Question-Answering), a framework that extrinsically evaluates translation quality by assessing how accurately candidate translations answer reading comprehension questions that target key information in the original source or reference texts. In challenging domains that require long-range understanding, such as literary texts, we show that TREQA is competitive with and, in some cases, outperforms state-of-the-art neural and LLM-based metrics in ranking alternative paragraph-level translations, despite never being explicitly optimized to correlate with human judgments. Furthermore, the generated questions and answers offer interpretability: empirical analysis shows that they effectively target translation errors identified by experts in evaluated datasets. Our code is available at https://github.com/deep-spin/treqa",
    "source": "arXiv"
  },
  {
    "title": "Scaling Laws for Native Multimodal Models",
    "title_es": "Scaling Laws for Native Multimodal Models",
    "url": "https://arxiv.org/abs/2504.07951",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.07951v4 Announce Type: replace \nAbstract: Building general-purpose models that can effectively perceive the world through multimodal signals has been a long-standing goal. Current approaches involve integrating separately pre-trained components, such as connecting vision encoders to LLMs and continuing multimodal training. While such approaches exhibit remarkable sample efficiency, it remains an open question whether such late-fusion architectures are inherently superior. In this work, we revisit the architectural design of native multimodal models (NMMs)-those trained from the ground up on all modalities-and conduct an extensive scaling laws study, spanning 457 trained models with different architectures and training mixtures. Our investigation reveals no inherent advantage to late-fusion architectures over early-fusion ones, which do not rely on image encoders or tokenizers. On the contrary, early-fusion exhibits stronger performance at lower parameter counts, is more efficient to train, and is easier to deploy. Motivated by the strong performance of the early-fusion architectures, we show that incorporating Mixture of Experts (MoEs) allows models to learn modality-specific weights, significantly benefiting performance.",
    "source": "arXiv"
  },
  {
    "title": "How Relevance Emerges: Interpreting LoRA Fine-Tuning in Reranking LLMs",
    "title_es": "How Relevance Emerges: Interpreting LoRA Fine-Tuning in Reranking LLMs",
    "url": "https://arxiv.org/abs/2504.08780",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.08780v3 Announce Type: replace \nAbstract: We conduct a behavioral exploration of LoRA fine-tuned LLMs for Passage Reranking to understand how relevance signals are learned and deployed by Large Language Models. By fine-tuning Mistral-7B, LLaMA3.1-8B, and Pythia-6.9B on MS MARCO under diverse LoRA configurations, we investigate how relevance modeling evolves across checkpoints, the impact of LoRA rank (1, 2, 8, 32), and the relative importance of updated MHA vs. MLP components. Our ablations reveal which layers and projections within LoRA transformations are most critical for reranking accuracy. These findings offer fresh explanations into LoRA's adaptation mechanisms, setting the stage for deeper mechanistic studies in Information Retrieval. All models used in this study have been shared.",
    "source": "arXiv"
  },
  {
    "title": "Where Does Academic Database Research Go From Here?",
    "title_es": "Where Does Academic Database Research Go From Here?",
    "url": "https://arxiv.org/abs/2504.08948",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.08948v3 Announce Type: replace \nAbstract: Panel proposal for an open forum to discuss and debate the future of database research in the context of industry, other research communities, and AI. Includes summaries of past panels, positions from panelists, as well as positions from a sample of the data management community.",
    "source": "arXiv"
  },
  {
    "title": "Should you use LLMs to simulate opinions? Quality checks for early-stage deliberation",
    "title_es": "Should you use LLMs to simulate opinions? Quality checks for early-stage deliberation",
    "url": "https://arxiv.org/abs/2504.08954",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.08954v3 Announce Type: replace \nAbstract: The emergent capabilities of large language models (LLMs) have prompted interest in using them as surrogates for human subjects in opinion surveys. However, prior evaluations of LLM-based opinion simulation have relied heavily on costly, domain-specific survey data, and mixed empirical results leave their reliability in question. To enable cost-effective, early-stage evaluation, we introduce a quality control assessment designed to test the viability of LLM-simulated opinions on Likert-scale tasks without requiring large-scale human data for validation. This assessment comprises two key tests: \\emph{logical consistency} and \\emph{alignment with stakeholder expectations}, offering a low-cost, domain-adaptable validation tool. We apply our quality control assessment to an opinion simulation task relevant to AI-assisted content moderation and fact-checking workflows -- a socially impactful use case -- and evaluate seven LLMs using a baseline prompt engineering method (backstory prompting), as well as fine-tuning and in-context learning variants. None of the models or methods pass the full assessment, revealing several failure modes. We conclude with a discussion of the risk management implications and release \\texttt{TopicMisinfo}, a benchmark dataset with paired human and LLM annotations simulated by various models and approaches, to support future research.",
    "source": "arXiv"
  },
  {
    "title": "Linear complementary dual quasi-cyclic codes of index 2",
    "title_es": "Linear complementary dual quasi-cyclic codes of index 2",
    "url": "https://arxiv.org/abs/2504.09126",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.09126v2 Announce Type: replace \nAbstract: We provide a polynomial approach to investigate linear complementary dual (LCD) quasi-cyclic codes over finite fields. We establish necessary and sufficient conditions for LCD quasi-cyclic codes of index 2 with respect to the Euclidean, Hermitian, and symplectic inner products. As a consequence of these characterizations, we derive necessary and sufficient conditions for LCD one-generator quasi-cyclic codes. Furthermore, using these characterizations, we construct some new quasi-cyclic LCD codes over small fields.",
    "source": "arXiv"
  },
  {
    "title": "Self-Supervised Autoencoder Network for Robust Heart Rate Extraction from Noisy Photoplethysmogram: Applying Blind Source Separation to Biosignal Analysis",
    "title_es": "Self-Supervised Autoencoder Network for Robust Heart Rate Extraction from Noisy Photoplethysmogram: Applying Blind Source Separation to Biosignal Analysis",
    "url": "https://arxiv.org/abs/2504.09132",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.09132v3 Announce Type: replace \nAbstract: Biosignals can be viewed as mixtures measuring particular physiological events, and blind source separation (BSS) aims to extract underlying source signals from mixtures. This paper proposes a self-supervised multi-encoder autoencoder (MEAE) to separate heartbeat-related source signals from photoplethysmogram (PPG), enhancing heart rate (HR) detection in noisy PPG data. The MEAE is trained on PPG signals from a large open polysomnography database without any pre-processing or data selection. The trained network is then applied to a noisy PPG dataset collected during the daily activities of nine subjects. The extracted heartbeat-related source signal significantly improves HR detection as compared to the original PPG. The absence of pre-processing and the self-supervised nature of the proposed method, combined with its strong performance, highlight the potential of MEAE for BSS in biosignal analysis.",
    "source": "arXiv"
  },
  {
    "title": "QUDsim: Quantifying Discourse Similarities in LLM-Generated Text",
    "title_es": "QUDsim: Quantifying Discourse Similarities in LLM-Generated Text",
    "url": "https://arxiv.org/abs/2504.09373",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.09373v2 Announce Type: replace \nAbstract: As large language models become increasingly capable at various writing tasks, their weakness at generating unique and creative content becomes a major liability. Although LLMs have the ability to generate text covering diverse topics, there is an overall sense of repetitiveness across texts that we aim to formalize and quantify via a similarity metric. The familiarity between documents arises from the persistence of underlying discourse structures. However, existing similarity metrics dependent on lexical overlap and syntactic patterns largely capture $\\textit{content}$ overlap, thus making them unsuitable for detecting $\\textit{structural}$ similarities. We introduce an abstraction based on linguistic theories in Questions Under Discussion (QUD) and question semantics to help quantify differences in discourse progression. We then use this framework to build $\\textbf{QUDsim}$, a similarity metric that can detect discursive parallels between documents. Using QUDsim, we find that LLMs often reuse discourse structures (more so than humans) across samples, even when content differs. Furthermore, LLMs are not only repetitive and structurally uniform, but are also divergent from human authors in the types of structures they use.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical Relation-augmented Representation Generalization for Few-shot Action Recognition",
    "title_es": "Hierarchical Relation-augmented Representation Generalization for Few-shot Action Recognition",
    "url": "https://arxiv.org/abs/2504.10079",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.10079v2 Announce Type: replace \nAbstract: Few-shot action recognition (FSAR) aims to recognize novel action categories with few exemplars. Existing methods typically learn frame-level representations for each video by designing inter-frame temporal modeling strategies or inter-video interaction at the coarse video-level granularity. However, they treat each episode task in isolation and neglect fine-grained temporal relation modeling between videos, thus failing to capture shared fine-grained temporal patterns across videos and reuse temporal knowledge from historical tasks. In light of this, we propose HR2G-shot, a Hierarchical Relation-augmented Representation Generalization framework for FSAR, which unifies three types of relation modeling (inter-frame, inter-video, and inter-task) to learn task-specific temporal patterns from a holistic view. Going beyond conducting inter-frame temporal interactions, we further devise two components to respectively explore inter-video and inter-task relationships: i) Inter-video Semantic Correlation (ISC) performs cross-video frame-level interactions in a fine-grained manner, thereby capturing task-specific query features and enhancing both intra-class consistency and inter-class separability; ii) Inter-task Knowledge Transfer (IKT) retrieves and aggregates relevant temporal knowledge from the bank, which stores diverse temporal patterns from historical episode tasks. Extensive experiments on five benchmarks show that HR2G-shot outperforms current top-leading FSAR methods.",
    "source": "arXiv"
  },
  {
    "title": "Simplified and Verified: A Second Look at a Proof-Producing Union-Find Algorithm",
    "title_es": "Simplified and Verified: A Second Look at a Proof-Producing Union-Find Algorithm",
    "url": "https://arxiv.org/abs/2504.10246",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.10246v2 Announce Type: replace \nAbstract: Using Isabelle/HOL, we verify a union-find data structure with an explain operation due to Nieuwenhuis and Oliveras. We devise a simpler, more naive version of the explain operation whose soundness and completeness is easy to verify. Then, we prove the original formulation of the explain operation to be equal to our version. Finally, we refine this data structure to Imperative HOL, enabling us to export efficient imperative code. The formalisation provides a stepping stone towards the verification of proof-producing congruence closure algorithms which are a core ingredient of Satisfiability Modulo Theories (SMT) solvers.",
    "source": "arXiv"
  },
  {
    "title": "Anchor Token Matching: Implicit Structure Locking for Training-free AR Image Editing",
    "title_es": "Anchor Token Matching: Implicit Structure Locking for Training-free AR Image Editing",
    "url": "https://arxiv.org/abs/2504.10434",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.10434v2 Announce Type: replace \nAbstract: Text-to-image generation has seen groundbreaking advancements with diffusion models, enabling high-fidelity synthesis and precise image editing through cross-attention manipulation. Recently, autoregressive (AR) models have re-emerged as powerful alternatives, leveraging next-token generation to match diffusion models. However, existing editing techniques designed for diffusion models fail to translate directly to AR models due to fundamental differences in structural control. Specifically, AR models suffer from spatial poverty of attention maps and sequential accumulation of structural errors during image editing, which disrupt object layouts and global consistency. In this work, we introduce Implicit Structure Locking (ISLock), the first training-free editing strategy for AR visual models. Rather than relying on explicit attention manipulation or fine-tuning, ISLock preserves structural blueprints by dynamically aligning self-attention patterns with reference images through the Anchor Token Matching (ATM) protocol. By implicitly enforcing structural consistency in latent space, our method ISLock enables structure-aware editing while maintaining generative autonomy. Extensive experiments demonstrate that ISLock achieves high-quality, structure-consistent edits without additional training and is superior or comparable to conventional editing techniques. Our findings pioneer the way for efficient and flexible AR-based image editing, further bridging the performance gap between diffusion and autoregressive generative models. The code will be publicly available at https://github.com/hutaiHang/ATM",
    "source": "arXiv"
  },
  {
    "title": "TFMPathy: Tabular Foundation Model for Privacy-Aware, Generalisable Empathy Detection from Videos",
    "title_es": "TFMPathy: Tabular Foundation Model for Privacy-Aware, Generalisable Empathy Detection from Videos",
    "url": "https://arxiv.org/abs/2504.10808",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.10808v2 Announce Type: replace \nAbstract: Detecting empathy from video interactions is an emerging area of research, particularly in healthcare and social robotics. However, privacy and ethical concerns often prevent the release of raw video data, with many datasets instead shared as pre-extracted tabular features. Previous work on such datasets has established classical tree-based models as the state of the art. Motivated by recent successes of large-scale foundation models for text, we investigate the potential of tabular foundation models (TFMs) for empathy detection from video-derived tabular data. Our proposed system, TFMPathy, is demonstrated with two recent TFMs (TabPFN v2 and TabICL) under both in-context learning and fine-tuning paradigms. On a public human-robot interaction benchmark, TFMPathy significantly improves empathy detection accuracy reported in the literature. While the established evaluation protocol in the literature does not ensure cross-subject generalisation, our evaluation scheme also captures such generalisation. We show that TFMPathy under a fine-tuning setup has better cross-subject generalisation capacity over baseline methods (accuracy: $0.590 \\rightarrow 0.730$; AUC: $0.564 \\rightarrow 0.669$). Given the ongoing privacy and ethical constraints around raw video sharing, the proposed TFMPathy system provides a practical and scalable path toward building AI systems dependent on human-centred video datasets. Our code is publicly available at https://github.com/hasan-rakibul/TFMPathy (will be made available upon acceptance of this paper).",
    "source": "arXiv"
  },
  {
    "title": "Crane: Context-Guided Prompt Learning and Attention Refinement for Zero-Shot Anomaly Detection",
    "title_es": "Crane: Context-Guided Prompt Learning and Attention Refinement for Zero-Shot Anomaly Detection",
    "url": "https://arxiv.org/abs/2504.11055",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.11055v2 Announce Type: replace \nAbstract: Anomaly Detection involves identifying deviations from normal data distributions and is critical in fields such as medical diagnostics and industrial defect detection. Traditional AD methods typically require the availability of normal training samples; however, this assumption is not always feasible. Recently, the rich pretraining knowledge of CLIP has shown promising zero-shot generalization in detecting anomalies without the need for training samples from target domains. However, CLIP's coarse-grained image-text alignment limits localization and detection performance for fine-grained anomalies due to: (1) spatial misalignment, and (2) the limited sensitivity of global features to local anomalous patterns. In this paper, we propose Crane which tackles both problems. First, we introduce a correlation-based attention module to retain spatial alignment more accurately. Second, to boost the model's awareness of fine-grained anomalies, we condition the learnable prompts of the text encoder on image context extracted from the vision encoder and perform a local-to-global representation fusion. Moreover, our method can incorporate vision foundation models such as DINOv2 to further enhance spatial understanding and localization. The key insight of Crane is to balance learnable adaptations for modeling anomalous concepts with non-learnable adaptations that preserve and exploit generalized pretrained knowledge, thereby minimizing in-domain overfitting and maximizing performance on unseen domains. Extensive evaluation across 14 diverse industrial and medical datasets demonstrates that Crane consistently improves the state-of-the-art ZSAD from 2% to 28%, at both image and pixel levels, while remaining competitive in inference speed. The code is available at https://github.com/AlirezaSalehy/Crane.",
    "source": "arXiv"
  },
  {
    "title": "Time Marching Neural Operator FE Coupling: AI Accelerated Physics Modeling",
    "title_es": "Time Marching Neural Operator FE Coupling: AI Accelerated Physics Modeling",
    "url": "https://arxiv.org/abs/2504.11383",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.11383v4 Announce Type: replace \nAbstract: Numerical solvers for PDEs often struggle to balance computational cost with accuracy, especially in multiscale and time-dependent systems. Neural operators offer a promising way to accelerate simulations, but their practical deployment is hindered by several challenges: they typically require large volumes of training data generated from high-fidelity solvers, tend to accumulate errors over time in dynamical settings, and often exhibit poor generalization in multiphysics scenarios. This work introduces a novel hybrid framework that integrates physics-informed deep operator network with FEM through domain decomposition and leverages numerical analysis for time marching. Our innovation lies in efficient coupling FE and DeepONet subdomains via a Schwarz method, expecting to solve complex and nonlinear regions by a pretrained DeepONet, while the remainder is handled by conventional FE. To address the challenges of dynamic systems, we embed a time stepping scheme directly into the DeepONet, substantially reducing long-term error propagation. Furthermore, an adaptive subdomain evolution strategy enables the ML-resolved region to expand dynamically, capturing fine-scale features without remeshing. Our framework shows accelerated convergence rates (up to 20% improvement in convergence rates compared to conventional FE coupling approaches) while preserving solution fidelity with error margins consistently below 3%. Our study shows that our proposed hybrid solver: (1) reduces computational costs by eliminating fine mesh requirements, (2) mitigates error accumulation in time-dependent simulations, and (3) enables automatic adaptation to evolving physical phenomena. This work establishes a new paradigm for coupling state of the art physics based and machine learning solvers in a unified framework, offering a robust, reliable, and scalable pathway for high fidelity multiscale simulations.",
    "source": "arXiv"
  },
  {
    "title": "DamageCAT: A Deep Learning Transformer Framework for Typology-Based Post-Disaster Building Damage Categorization",
    "title_es": "DamageCAT: A Deep Learning Transformer Framework for Typology-Based Post-Disaster Building Damage Categorization",
    "url": "https://arxiv.org/abs/2504.11637",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.11637v2 Announce Type: replace \nAbstract: Rapid, accurate, and descriptive building damage assessment is critical for directing post-disaster resources, yet current automated methods typically provide only binary (damaged/undamaged) or ordinal severity scales. This paper introduces DamageCAT, a framework that advances damage assessment through typology-based categorical classifications. We contribute: (1) the BD-TypoSAT dataset containing satellite image triplets from Hurricane Ida with four damage categories - partial roof damage, total roof damage, partial structural collapse, and total structural collapse - and (2) a hierarchical U-Net-based transformer architecture for processing pre- and post-disaster image pairs. Our model achieves 0.737 IoU and 0.846 F1-score overall, with cross-event evaluation demonstrating transferability across Hurricane Harvey, Florence, and Michael data. While performance varies across damage categories due to class imbalance, the framework shows that typology-based classifications can provide more actionable damage assessments than traditional severity-based approaches, enabling targeted emergency response and resource allocation.",
    "source": "arXiv"
  },
  {
    "title": "Interpreting the linear structure of vision-language model embedding spaces",
    "title_es": "Interpreting the linear structure of vision-language model embedding spaces",
    "url": "https://arxiv.org/abs/2504.11695",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.11695v3 Announce Type: replace \nAbstract: Vision-language models encode images and text in a joint space, minimizing the distance between corresponding image and text pairs. How are language and images organized in this joint space, and how do the models encode meaning and modality? To investigate this, we train and release sparse autoencoders (SAEs) on the embedding spaces of four vision-language models (CLIP, SigLIP, SigLIP2, and AIMv2). SAEs approximate model embeddings as sparse linear combinations of learned directions, or \"concepts\". We find that, compared to other methods of linear feature learning, SAEs are better at reconstructing the real embeddings, while also able to retain the most sparsity. Retraining SAEs with different seeds or different data diet leads to two findings: the rare, specific concepts captured by the SAEs are liable to change drastically, but we also show that commonly-activating concepts are remarkably stable across runs. Interestingly, while most concepts activate primarily for one modality, we find they are not merely encoding modality per se. Many are almost orthogonal to the subspace that defines modality, and the concept directions do not function as good modality classifiers, suggesting that they encode cross-modal semantics. To quantify this bridging behavior, we introduce the Bridge Score, a metric that identifies concept pairs which are both co-activated across aligned image-text inputs and geometrically aligned in the shared space. This reveals that even single-modality concepts can collaborate to support cross-modal integration. We release interactive demos of the SAEs for all models, allowing researchers to explore the organization of the concept spaces. Overall, our findings uncover a sparse linear structure within VLM embedding spaces that is shaped by modality, yet stitched together through latent bridges, offering new insight into how multimodal meaning is constructed.",
    "source": "arXiv"
  },
  {
    "title": "Just Say the Word: Annotation-Free Fine-Grained Object Counting",
    "title_es": "Just Say the Word: Annotation-Free Fine-Grained Object Counting",
    "url": "https://arxiv.org/abs/2504.11705",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.11705v2 Announce Type: replace \nAbstract: Fine-grained object counting remains a major challenge for class-agnostic counting models, which overcount visually similar but incorrect instances (e.g., jalape\\~no vs. poblano). Addressing this by annotating new data and fully retraining the model is time-consuming and does not guarantee generalization to additional novel categories at test time. Instead, we propose an alternative paradigm: Given a category name, tune a compact concept embedding derived from the prompt using synthetic images and pseudo-labels generated by a text-to-image diffusion model. This embedding conditions a specialization module that refines raw overcounts from any frozen counter into accurate, category-specific estimates\\textemdash without requiring real images or human annotations. We validate our approach on \\textsc{Lookalikes}, a challenging new benchmark containing 1,037 images across 27 fine-grained subcategories, and show substantial improvements over strong baselines. Code and data will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Video-Based Driver Activity Recognition under Noisy Labels",
    "title_es": "Exploring Video-Based Driver Activity Recognition under Noisy Labels",
    "url": "https://arxiv.org/abs/2504.11966",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.11966v2 Announce Type: replace \nAbstract: As an open research topic in the field of deep learning, learning with noisy labels has attracted much attention and grown rapidly over the past ten years. Learning with label noise is crucial for driver distraction behavior recognition, as real-world video data often contains mislabeled samples, impacting model reliability and performance. However, label noise learning is barely explored in the driver activity recognition field. In this paper, we propose the first label noise learning approach for the driver activity recognition task. Based on the cluster assumption, we initially enable the model to learn clustering-friendly low-dimensional representations from given videos and assign the resultant embeddings into clusters. We subsequently perform co-refinement within each cluster to smooth the classifier outputs. Furthermore, we propose a flexible sample selection strategy that combines two selection criteria without relying on any hyperparameters to filter clean samples from the training dataset. We also incorporate a self-adaptive parameter into the sample selection process to enforce balancing across classes. A comprehensive variety of experiments on the public Drive&Act dataset for all granularity levels demonstrates the superior performance of our method in comparison with other label-denoising methods derived from the image classification field. The source code is available at https://github.com/ilonafan/DAR-noisy-labels.",
    "source": "arXiv"
  },
  {
    "title": "Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation",
    "title_es": "Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation",
    "url": "https://arxiv.org/abs/2504.12436",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.12436v2 Announce Type: replace \nAbstract: Adapting Vision-Language Models (VLMs) to new domains with few labeled samples remains a significant challenge due to severe overfitting and computational constraints. State-of-the-art solutions, such as low-rank reparameterization, mitigate these issues but often struggle with generalization and require extensive hyperparameter tuning. In this paper, a novel Sparse Optimization (SO) framework is proposed. Unlike low-rank approaches that typically constrain updates to a fixed subspace, our SO method leverages high sparsity to dynamically adjust very few parameters. We introduce two key paradigms. First, we advocate for \\textit{local sparsity and global density}, which updates a minimal subset of parameters per iteration while maintaining overall model expressiveness. As a second paradigm, we advocate for \\textit{local randomness and global importance}, which sparsifies the gradient using random selection while pruning the first moment based on importance. This combination significantly mitigates overfitting and ensures stable adaptation in low-data regimes. Extensive experiments on 11 diverse datasets show that SO achieves state-of-the-art few-shot adaptation performance while reducing memory overhead.",
    "source": "arXiv"
  },
  {
    "title": "The Dual Personas of Social Media Bots",
    "title_es": "The Dual Personas of Social Media Bots",
    "url": "https://arxiv.org/abs/2504.12498",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.12498v3 Announce Type: replace \nAbstract: Social media bots are AI agents that participate in online conversations. Most studies focus on the general bot and the malicious nature of these agents. However, bots have many different personas, each specialized towards a specific behavioral or content trait. Neither are bots singularly bad, because they are used for both good and bad information dissemination. In this article, we introduce fifteen agent personas of social media bots. These personas have two main categories: Content-Based Bot Persona and Behavior-Based Bot Persona. We also form yardsticks of the good-bad duality of the bots, elaborating on metrics of good and bad bot agents. Our work puts forth a guideline to inform bot detection regulation, emphasizing that policies should focus on how these agents are employed, rather than collectively terming bot agents as bad.",
    "source": "arXiv"
  },
  {
    "title": "SOPHY: Learning to Generate Simulation-Ready Objects with Physical Materials",
    "title_es": "SOPHY: Learning to Generate Simulation-Ready Objects with Physical Materials",
    "url": "https://arxiv.org/abs/2504.12684",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.12684v3 Announce Type: replace \nAbstract: We present SOPHY, a generative model for 3D physics-aware shape synthesis. Unlike existing 3D generative models that focus solely on static geometry or 4D models that produce physics-agnostic animations, our method jointly synthesizes shape, texture, and material properties related to physics-grounded dynamics, making the generated objects ready for simulations and interactive, dynamic environments. To train our model, we introduce a dataset of 3D objects annotated with detailed physical material attributes, along with an efficient pipeline for material annotation. Our method enables applications such as text-driven generation of interactive, physics-aware 3D objects and single-image reconstruction of physically plausible shapes. Furthermore, our experiments show that jointly modeling shape and material properties enhances the realism and fidelity of the generated shapes, improving performance on both generative geometry and physical plausibility.",
    "source": "arXiv"
  },
  {
    "title": "Science Hierarchography: Hierarchical Organization of Science Literature",
    "title_es": "Science Hierarchography: Hierarchical Organization of Science Literature",
    "url": "https://arxiv.org/abs/2504.13834",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.13834v3 Announce Type: replace \nAbstract: Scientific knowledge is growing rapidly, making it difficult to track progress and high-level conceptual links across broad disciplines. While tools like citation networks and search engines help retrieve related papers, they lack the abstraction needed to capture the needed to represent the density and structure of activity across subfields.\n  We motivate SCIENCE HIERARCHOGRAPHY, the goal of organizing scientific literature into a high-quality hierarchical structure that spans multiple levels of abstraction -- from broad domains to specific studies. Such a representation can provide insights into which fields are well-explored and which are under-explored. To achieve this goal, we develop a hybrid approach that combines efficient embedding-based clustering with LLM-based prompting, striking a balance between scalability and semantic precision. Compared to LLM-heavy methods like iterative tree construction, our approach achieves superior quality-speed trade-offs. Our hierarchies capture different dimensions of research contributions, reflecting the interdisciplinary and multifaceted nature of modern science. We evaluate its utility by measuring how effectively an LLM-based agent can navigate the hierarchy to locate target papers. Results show that our method improves interpretability and offers an alternative pathway for exploring scientific literature beyond traditional search methods. Code, data and demo are available: https://github.com/JHU-CLSP/science-hierarchography",
    "source": "arXiv"
  },
  {
    "title": "CAOTE: KV Cache Eviction for LLMs via Attention Output Error-Based Token Selection",
    "title_es": "CAOTE: KV Cache Eviction for LLMs via Attention Output Error-Based Token Selection",
    "url": "https://arxiv.org/abs/2504.14051",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.14051v4 Announce Type: replace \nAbstract: While long context support of large language models has extended their abilities, it also incurs challenges in memory and compute which becomes crucial bottlenecks in resource-restricted devices. Token eviction, a widely adopted post-training methodology designed to alleviate the bottlenecks by evicting less important tokens from the cache, typically uses attention scores as proxy metrics for token importance. However, one major limitation of attention score as a token-wise importance metrics is that it lacks the information about contribution of tokens to the attention output. In this paper, we propose a simple eviction criterion based on the contribution of cached tokens to attention outputs. Our method, CAOTE, optimizes for eviction error due to token eviction, by seamlessly integrating attention scores and value vectors. This is the first method which uses value vector information on top of attention-based eviction scores. Additionally, CAOTE can act as a meta-heuristic method with flexible usage with any token eviction method. We show that CAOTE, when combined with the state-of-the-art attention score-based methods, always improves accuracies on the downstream task, indicating the importance of leveraging information from values during token eviction process.",
    "source": "arXiv"
  },
  {
    "title": "Prompt-Hacking: The New p-Hacking?",
    "title_es": "Prompt-Hacking: The New p-Hacking?",
    "url": "https://arxiv.org/abs/2504.14571",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.14571v2 Announce Type: replace \nAbstract: As Large Language Models (LLMs) become increasingly embedded in empirical research workflows, their use as analytical tools for quantitative or qualitative data raises pressing concerns for scientific integrity. This opinion paper draws a parallel between \"prompt-hacking\", the strategic tweaking of prompts to elicit desirable outputs from LLMs, and the well-documented practice of \"p-hacking\" in statistical analysis. We argue that the inherent biases, non-determinism, and opacity of LLMs make them unsuitable for data analysis tasks demanding rigor, impartiality, and reproducibility. We emphasize how researchers may inadvertently, or even deliberately, adjust prompts to confirm hypotheses while undermining research validity. We advocate for a critical view of using LLMs in research, transparent prompt documentation, and clear standards for when LLM use is appropriate. We discuss how LLMs can replace traditional analytical methods, whereas we recommend that LLMs should only be used with caution, oversight, and justification.",
    "source": "arXiv"
  },
  {
    "title": "Beauty and the Bias: Exploring the Impact of Attractiveness on Multimodal Large Language Models",
    "title_es": "Beauty and the Bias: Exploring the Impact of Attractiveness on Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2504.16104",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.16104v3 Announce Type: replace \nAbstract: Physical attractiveness matters. It has been shown to influence human perception and decision-making, often leading to biased judgments that favor those deemed attractive in what is referred to as the \"attractiveness halo effect\". While extensively studied in human judgments in a broad set of domains, including hiring, judicial sentencing or credit granting, the role that attractiveness plays in the assessments and decisions made by multimodal large language models (MLLMs) is unknown. To address this gap, we conduct an empirical study with 7 diverse open-source MLLMs evaluated on 91 socially relevant scenarios and a diverse dataset of 924 face images - corresponding to 462 individuals both with and without beauty filters applied to them. Our analysis reveals that attractiveness impacts the decisions made by MLLMs in 86.2% of the scenarios on average, demonstrating substantial bias in model behavior in what we refer to as an attractiveness bias. Similarly to humans, we find empirical evidence of the existence of the attractiveness halo effect in 94.8% of the relevant scenarios: attractive individuals are more likely to be attributed positive traits, such as intelligence or confidence, by MLLMs than unattractive individuals. Furthermore, we uncover gender, age and race biases in a significant portion of the scenarios which are also impacted by attractiveness, particularly in the case of gender, highlighting the intersectional nature of the algorithmic attractiveness bias. Our findings suggest that societal stereotypes and cultural norms intersect with perceptions of attractiveness in MLLMs in a complex manner. Our work emphasizes the need to account for intersectionality in algorithmic bias detection and mitigation efforts and underscores the challenges of addressing biases in modern MLLMs.",
    "source": "arXiv"
  },
  {
    "title": "Decoupled Global-Local Alignment for Improving Compositional Understanding",
    "title_es": "Decoupled Global-Local Alignment for Improving Compositional Understanding",
    "url": "https://arxiv.org/abs/2504.16801",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.16801v2 Announce Type: replace \nAbstract: Contrastive Language-Image Pre-training (CLIP) has achieved success on multiple downstream tasks by aligning image and text modalities. However, the nature of global contrastive learning limits CLIP's ability to comprehend compositional concepts, such as relations and attributes. Although recent studies employ global hard negative samples to improve compositional understanding, these methods significantly compromise the model's inherent general capabilities by forcibly distancing textual negative samples from images in the embedding space. To overcome this limitation, we introduce a Decoupled Global-Local Alignment (DeGLA) framework that improves compositional understanding while substantially mitigating losses in general capabilities. To optimize the retention of the model's inherent capabilities, we incorporate a self-distillation mechanism within the global alignment process, aligning the learnable image-text encoder with a frozen teacher model derived from an exponential moving average. Under the constraint of self-distillation, it effectively mitigates the catastrophic forgetting of pretrained knowledge during fine-tuning. To improve compositional understanding, we first leverage the in-context learning capability of Large Language Models (LLMs) to construct about 2M high-quality negative captions across five types. Subsequently, we propose the Image-Grounded Contrast (IGC) loss and Text-Grounded Contrast (TGC) loss to enhance vision-language compositionally. Extensive experimental results demonstrate the effectiveness of the DeGLA framework. Compared to previous state-of-the-art methods, DeGLA achieves an average enhancement of 3.5% across the VALSE, SugarCrepe, and ARO benchmarks. Concurrently, it obtains an average performance improvement of 13.0% on zero-shot classification tasks across eleven datasets. Our code will be released at https://github.com/xiaoxing2001/DeGLA",
    "source": "arXiv"
  },
  {
    "title": "GreenMind: A Next-Generation Vietnamese Large Language Model for Structured and Logical Reasoning",
    "title_es": "GreenMind: A Next-Generation Vietnamese Large Language Model for Structured and Logical Reasoning",
    "url": "https://arxiv.org/abs/2504.16832",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.16832v2 Announce Type: replace \nAbstract: Chain-of-Thought (CoT) is a robust approach for tackling LLM tasks that require intermediate reasoning steps prior to generating a final answer. In this paper, we present GreenMind-Medium-14B-R1, the Vietnamese reasoning model inspired by the finetuning strategy based on Group Relative Policy Optimization. We also leverage a high-quality Vietnamese synthesized reasoning dataset and design two reward functions to tackle the main limitations of this technique: (i) language mixing, where we explicitly detect the presence of biased language characters during the process of sampling tokens, and (ii) we leverage Sentence Transformer-based models to ensure that the generated reasoning content maintains factual correctness and does not distort the final output. Experimental results on the Vietnamese dataset from the VLSP 2023 Challenge demonstrate that our model outperforms prior works and enhances linguistic consistency in its responses. Furthermore, we extend our evaluation to SeaExam-a multilingual multiple-choice dataset, showing the effectiveness of our reasoning method compared to few-shot prompting techniques.",
    "source": "arXiv"
  },
  {
    "title": "Planning with Diffusion Models for Target-Oriented Dialogue Systems",
    "title_es": "Planning with Diffusion Models for Target-Oriented Dialogue Systems",
    "url": "https://arxiv.org/abs/2504.16858",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.16858v2 Announce Type: replace \nAbstract: Target-Oriented Dialogue (TOD) remains a significant challenge in the LLM era, where strategic dialogue planning is crucial for directing conversations toward specific targets. However, existing dialogue planning methods generate dialogue plans in a step-by-step sequential manner, and may suffer from compounding errors and myopic actions. To address these limitations, we introduce a novel dialogue planning framework, DiffTOD, which leverages diffusion models to enable non-sequential dialogue planning. DiffTOD formulates dialogue planning as a trajectory generation problem with conditional guidance, and leverages a diffusion language model to estimate the likelihood of the dialogue trajectory. To optimize the dialogue action strategies, DiffTOD introduces three tailored guidance mechanisms for different target types, offering flexible guidance toward diverse TOD targets at test time. Extensive experiments across three diverse TOD settings show that DiffTOD can effectively perform non-myopic lookahead exploration and optimize action strategies over a long horizon through non-sequential dialogue planning, and demonstrates strong flexibility across complex and diverse dialogue scenarios. Our code and data are accessible through https://github.com/ninglab/DiffTOD.",
    "source": "arXiv"
  },
  {
    "title": "Steering the CensorShip: Uncovering Representation Vectors for LLM \"Thought\" Control",
    "title_es": "Steering the CensorShip: Uncovering Representation Vectors for LLM \"Thought\" Control",
    "url": "https://arxiv.org/abs/2504.17130",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.17130v3 Announce Type: replace \nAbstract: Large language models (LLMs) have transformed the way we access information. These models are often tuned to refuse to comply with requests that are considered harmful and to produce responses that better align with the preferences of those who control the models. To understand how this \"censorship\" works. We use representation engineering techniques to study open-weights safety-tuned models. We present a method for finding a refusal--compliance vector that detects and controls the level of censorship in model outputs. We also analyze recent reasoning LLMs, distilled from DeepSeek-R1, and uncover an additional dimension of censorship through \"thought suppression\". We show a similar approach can be used to find a vector that suppresses the model's reasoning process, allowing us to remove censorship by applying the negative multiples of this vector. Our code is publicly available at: https://github.com/hannahxchen/llm-censorship-steering",
    "source": "arXiv"
  },
  {
    "title": "MAT-DiSMech: A Discrete Differential Geometry-based Computational Tool for Simulation of Rods, Shells, and Soft Robots",
    "title_es": "MAT-DiSMech: A Discrete Differential Geometry-based Computational Tool for Simulation of Rods, Shells, and Soft Robots",
    "url": "https://arxiv.org/abs/2504.17186",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.17186v2 Announce Type: replace \nAbstract: Accurate and efficient simulation tools are essential in robotics, enabling the visualization of system dynamics and the validation of control laws before committing resources to physical experimentation. Developing physically accurate simulation tools is particularly challenging in soft robotics, largely due to the prevalence of geometrically nonlinear deformation. A variety of robot simulators tackle this challenge by using simplified modeling techniques -- such as lumped mass models -- which lead to physical inaccuracies in real-world applications. On the other hand, high-fidelity simulation methods for soft structures, like finite element analysis, offer increased accuracy but lead to higher computational costs. In light of this, we present a Discrete Differential Geometry-based simulator that provides a balance between physical accuracy and computational speed. Building on an extensive body of research on rod and shell-based representations of soft robots, our tool provides a pathway to accurately model soft robots in a computationally tractable manner. Our open-source MATLAB-based framework is capable of simulating the deformations of rods, shells, and their combinations, primarily utilizing implicit integration techniques. The software design is modular for the user to customize the code, for example, add new external forces and impose custom boundary conditions. The implementations for prevalent forces encountered in robotics, including gravity, contact, kinetic and viscous friction, and aerodynamic drag, have been provided. We provide several illustrative examples that showcase the capabilities and validate the physical accuracy of the simulator. The open-source code is available at https://github.com/StructuresComp/dismech-matlab.git. We anticipate that the proposed simulator can serve as an effective digital twin tool, enhancing the Sim2Real pathway in soft robotics research.",
    "source": "arXiv"
  },
  {
    "title": "Unveiling 3D Ocean Biogeochemical Provinces in the North Atlantic: A Systematic Comparison and Validation of Clustering Methods",
    "title_es": "Unveiling 3D Ocean Biogeochemical Provinces in the North Atlantic: A Systematic Comparison and Validation of Clustering Methods",
    "url": "https://arxiv.org/abs/2504.18181",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.18181v2 Announce Type: replace \nAbstract: Defining ocean regions and water masses helps to understand marine processes and can serve downstream tasks such as defining marine protected areas. However, such definitions often result from subjective decisions potentially producing misleading, unreproducible outcomes. Here, the aim was to objectively define regions of the North Atlantic through systematic comparison of clustering methods within the Native Emergent Manifold Interrogation (NEMI) framework (Sonnewald, 2023). About 300 million measured salinity, temperature, and oxygen, nitrate, phosphate and silicate concentration values served as input for various clustering methods (k-Means, agglomerative Ward, and Density-Based Spatial Clustering of Applications with Noise (DBSCAN)). Uniform Manifold Approximation and Projection (UMAP) emphasised (dis-)similarities in the data while reducing dimensionality. Based on systematic validation of clustering methods and their hyperparameters using internal, external and relative validation techniques, results showed that UMAP-DBSCAN best represented the data. Strikingly, internal validation metrics proved systematically unreliable for comparing clustering methods. To address stochastic variability, 100 UMAP-DBSCAN clustering runs were conducted and aggregated following NEMI, yielding a final set of 321 clusters. Reproducibility was evaluated via ensemble overlap ($88.81\\pm1.8\\%$) and mean grid cell-wise uncertainty ($15.49\\pm20\\%$). Case studies of the Mediterranean Sea, deep Atlantic waters and Labrador Sea showed strong agreement with common water mass definitions. This study revealed a more detailed regionalisation compared to previous concepts such as the Longhurst provinces through systematic clustering method comparison. The applied method is objective, efficient and reproducible and will support future research on biogeochemical differences and changes in oceanic regions.",
    "source": "arXiv"
  },
  {
    "title": "DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering",
    "title_es": "DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering",
    "url": "https://arxiv.org/abs/2504.18243",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.18243v2 Announce Type: replace \nAbstract: Multi-Hop Question Answering (MHQA) tasks permeate real-world applications, posing challenges in orchestrating multi-step reasoning across diverse knowledge domains. While existing approaches have been improved with iterative retrieval, they still struggle to identify and organize dynamic knowledge. To address this, we propose DualRAG, a synergistic dual-process framework that seamlessly integrates reasoning and retrieval. DualRAG operates through two tightly coupled processes: Reasoning-augmented Querying (RaQ) and progressive Knowledge Aggregation (pKA). They work in concert: as RaQ navigates the reasoning path and generates targeted queries, pKA ensures that newly acquired knowledge is systematically integrated to support coherent reasoning. This creates a virtuous cycle of knowledge enrichment and reasoning refinement. Through targeted fine-tuning, DualRAG preserves its sophisticated reasoning and retrieval capabilities even in smaller-scale models, demonstrating its versatility and core advantages across different scales. Extensive experiments demonstrate that this dual-process approach substantially improves answer accuracy and coherence, approaching, and in some cases surpassing, the performance achieved with oracle knowledge access. These results establish DualRAG as a robust and efficient solution for complex multi-hop reasoning tasks.",
    "source": "arXiv"
  },
  {
    "title": "RAIR: Retrieval-Augmented Iterative Refinement for Chinese Spelling Correction",
    "title_es": "RAIR: Retrieval-Augmented Iterative Refinement for Chinese Spelling Correction",
    "url": "https://arxiv.org/abs/2504.18938",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.18938v2 Announce Type: replace \nAbstract: Chinese Spelling Correction (CSC) aims to detect and correct erroneous tokens in sentences. Traditional CSC focuses on equal length correction and uses pretrained language models (PLMs). While Large Language Models (LLMs) have shown remarkable success in identifying and rectifying potential errors, they often struggle with adapting to domain-specific corrections, especially when encountering terminologies in specialized domains. To address domain adaptation, we propose a \\textbf{R}etrieval-\\textbf{A}ugmented \\textbf{I}terative \\textbf{R}efinement (RAIR) framework. Our approach constructs a retrieval corpus adaptively from domain-specific training data and dictionaries, employing a fine-tuned retriever to ensure that the retriever catches the error correction pattern. We also extend equal-length into variable-length correction scenarios. Extensive experiments demonstrate that our framework outperforms current approaches in domain spelling correction and significantly improves the performance of LLMs in variable-length scenarios.",
    "source": "arXiv"
  },
  {
    "title": "CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback",
    "title_es": "CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback",
    "url": "https://arxiv.org/abs/2504.19860",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.19860v2 Announce Type: replace \nAbstract: Score Distillation Sampling (SDS) has achieved remarkable success in text-to-3D content generation. However, SDS-based methods struggle to maintain semantic fidelity for user prompts, particularly when involving multiple objects with intricate interactions. While existing approaches often address 3D consistency through multiview diffusion model fine-tuning on 3D datasets, this strategy inadvertently exacerbates text-3D alignment degradation. The limitation stems from SDS's inherent accumulation of view-independent biases during optimization, which progressively diverges from the ideal text alignment direction. To alleviate this limitation, we propose a novel SDS objective, dubbed as Textual Coherent Score Distillation (TCSD), which integrates alignment feedback from multimodal large language models (MLLMs). Our TCSD leverages cross-modal understanding capabilities of MLLMs to assess and guide the text-3D correspondence during the optimization. We further develop 3DLLaVA-CRITIC - a fine-tuned MLLM specialized for evaluating multiview text alignment in 3D generations. Additionally, we introduce an LLM-layout initialization that significantly accelerates optimization convergence through semantic-aware spatial configuration. Our framework, CoherenDream, achieves consistent improvement across multiple metrics on TIFA subset.As the first study to incorporate MLLMs into SDS optimization, we also conduct extensive ablation studies to explore optimal MLLM adaptations for 3D generation tasks.",
    "source": "arXiv"
  },
  {
    "title": "Should AI Mimic People? Understanding AI-Supported Writing Technology Among Black Users",
    "title_es": "Should AI Mimic People? Understanding AI-Supported Writing Technology Among Black Users",
    "url": "https://arxiv.org/abs/2505.00821",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.00821v3 Announce Type: replace \nAbstract: AI-supported writing technologies (AISWT) that provide grammatical suggestions, autocomplete sentences, or generate and rewrite text are now a regular feature integrated into many people's workflows. However, little is known about how people perceive the suggestions these tools provide. In this paper, we investigate how Black American users perceive AISWT, motivated by prior findings in natural language processing that highlight how the underlying large language models can contain racial biases. Using interviews and observational user studies with 13 Black American users of AISWT, we found a strong tradeoff between the perceived benefits of using AISWT to enhance their writing style and feeling like \"it wasn't built for us\". Specifically, participants reported AISWT's failure to recognize commonly used names and expressions in African American Vernacular English, experiencing its corrections as hurtful and alienating and fearing it might further minoritize their culture. We end with a reflection on the tension between AISWT that fail to include Black American culture and language, and AISWT that attempt to mimic it, with attention to accuracy, authenticity, and the production of social difference.",
    "source": "arXiv"
  },
  {
    "title": "Quasi-Static IRS: 3D Shaped Beamforming for Area Coverage Enhancement",
    "title_es": "Quasi-Static IRS: 3D Shaped Beamforming for Area Coverage Enhancement",
    "url": "https://arxiv.org/abs/2505.01076",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.01076v2 Announce Type: replace \nAbstract: Intelligent reflecting surface (IRS) is a promising paradigm to reconfigure the wireless environment for enhanced communication coverage and quality. However, to compensate for the double pathloss effect, massive IRS elements are required, raising concerns on the scalability of cost and complexity. This paper introduces a new architecture of quasi-static IRS (QS-IRS), which tunes element phases via mechanical adjustment or manually re-arranging the array topology. QS-IRS relies on massive production/assembly of purely passive elements only, and thus is suitable for ultra low-cost and large-scale deployment to enhance long-term coverage. To achieve this end, an IRS-aided area coverage problem is formulated, which explicitly considers the element radiation pattern (ERP), with the newly introduced shape masks for the mainlobe, and the sidelobe constraints to reduce energy leakage. An alternating optimization (AO) algorithm based on the difference-of-convex (DC) and successive convex approximation (SCA) procedure is proposed, which achieves shaped beamforming with power gains close to that of the joint optimization algorithm, but with significantly reduced computational complexity.",
    "source": "arXiv"
  },
  {
    "title": "Forecasting at Full Spectrum: Holistic Multi-Granular Traffic Modeling under High-Throughput Inference Regimes",
    "title_es": "Forecasting at Full Spectrum: Holistic Multi-Granular Traffic Modeling under High-Throughput Inference Regimes",
    "url": "https://arxiv.org/abs/2505.01279",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.01279v2 Announce Type: replace \nAbstract: Notably, current intelligent transportation systems rely heavily on accurate traffic forecasting and swift inference provision to make timely decisions. While Graph Convolutional Networks (GCNs) have shown benefits in modeling complex traffic dependencies, the existing GCN-based approaches cannot fully extract and fuse multi-granular spatiotemporal features across various spatial and temporal scales sufficiently in a complete manner, proven to yield less accurate results. Besides, as extracting multi-granular features across scales has been a promising strategy across domains such as computer vision, natural language processing, and time-series forecasting, pioneering studies have attempted to leverage a similar mechanism for spatiotemporal traffic data mining. However, additional feature extraction branches introduced in prior studies critically increased model complexity and extended inference time, making it challenging to provide fast forecasts. In this paper, we propose MultiGran-STGCNFog, an efficient fog distributed inference system with a novel traffic forecasting model that employs multi-granular spatiotemporal feature fusion on generated dynamic traffic graphs to fully capture interdependent traffic dynamics. The proposed scheduling algorithm GA-DPHDS, optimizing layer execution order and layer-device scheduling scheme simultaneously, contributes to considerable inference throughput improvement by coordinating heterogeneous fog devices in a pipelined manner. Extensive experiments on real-world datasets demonstrate the superiority of the proposed method over selected GCN baselines.",
    "source": "arXiv"
  },
  {
    "title": "Proven Approximation Guarantees in Multi-Objective Optimization: SPEA2 Beats NSGA-II",
    "title_es": "Proven Approximation Guarantees in Multi-Objective Optimization: SPEA2 Beats NSGA-II",
    "url": "https://arxiv.org/abs/2505.01323",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.01323v3 Announce Type: replace \nAbstract: Together with the NSGA-II and SMS-EMOA, the strength Pareto evolutionary algorithm 2 (SPEA2) is one of the most prominent dominance-based multi-objective evolutionary algorithms (MOEAs). Different from the NSGA-II, it does not employ the crowding distance (essentially the distance to neighboring solutions) to compare pairwise non-dominating solutions but a complex system of $\\sigma$-distances that builds on the distances to all other solutions. In this work, we give a first mathematical proof showing that this more complex system of distances can be superior. More specifically, we prove that a simple steady-state SPEA2 can compute optimal approximations of the Pareto front of the OneMinMax benchmark in polynomial time. The best proven guarantee for a comparable variant of the NSGA-II only assures approximation ratios of roughly a factor of two, and both mathematical analyses and experiments indicate that optimal approximations are not found efficiently.",
    "source": "arXiv"
  },
  {
    "title": "El Agente: An Autonomous Agent for Quantum Chemistry",
    "title_es": "El Agente: An Autonomous Agent for Quantum Chemistry",
    "url": "https://arxiv.org/abs/2505.02484",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.02484v2 Announce Type: replace \nAbstract: Computational chemistry tools are widely used to study the behaviour of chemical phenomena. Yet, the complexity of these tools can make them inaccessible to non-specialists and challenging even for experts. In this work, we introduce El Agente Q, an LLM-based multi-agent system that dynamically generates and executes quantum chemistry workflows from natural language user prompts. The system is built on a novel cognitive architecture featuring a hierarchical memory framework that enables flexible task decomposition, adaptive tool selection, post-analysis, and autonomous file handling and submission. El Agente Q is benchmarked on six university-level course exercises and two case studies, demonstrating robust problem-solving performance (averaging >87% task success) and adaptive error handling through in situ debugging. It also supports longer-term, multi-step task execution for more complex workflows, while maintaining transparency through detailed action trace logs. Together, these capabilities lay the foundation for increasingly autonomous and accessible quantum chemistry.",
    "source": "arXiv"
  },
  {
    "title": "FedSDAF: Leveraging Source Domain Awareness for Enhanced Federated Domain Generalization",
    "title_es": "FedSDAF: Leveraging Source Domain Awareness for Enhanced Federated Domain Generalization",
    "url": "https://arxiv.org/abs/2505.02515",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.02515v3 Announce Type: replace \nAbstract: Traditional Federated Domain Generalization (FedDG) methods focus on learning domain-invariant features or adapting to unseen target domains, often overlooking the unique knowledge embedded within the source domain, especially in strictly isolated federated learning environments. Through experimentation, we discovered a counterintuitive phenomenon.: features learned from a complete source domain have superior generalization capabilities compared to those learned directly from the target domain. This insight leads us to propose the Federated Source Domain Awareness Framework (FedSDAF), the first systematic approach to enhance FedDG by leveraging source domain-aware features. FedSDAF employs a dual-adapter architecture that decouples \"local expertise\" from \"global generalization consensus\". A Domain-Aware Adapter, retained locally, extracts and protects the unique discriminative knowledge of each source domain, while a Domain-Invariant Adapter, shared across clients, builds a robust global consensus. To enable knowledge exchange, we introduce a Bidirectional Knowledge Distillation mechanism that facilitates efficient dialogue between the adapters. Extensive experiments on four benchmark datasets (OfficeHome, PACS, VLCS, DomainNet) show that FedSDAF significantly outperforms existing FedDG methods.The source code is available at https://github.com/pizzareapers/FedSDAF.",
    "source": "arXiv"
  },
  {
    "title": "A Practical Approach Towards Inertia Estimation Using Ambient Synchrophasor Data",
    "title_es": "A Practical Approach Towards Inertia Estimation Using Ambient Synchrophasor Data",
    "url": "https://arxiv.org/abs/2505.02978",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.02978v2 Announce Type: replace \nAbstract: Real-time tracking of inertia is important because it reflects the power system's ability to withstand contingencies and maintain frequency security. This paper proposes a practical approach to estimate inertia using ambient phasor measurement unit (PMU) data and a partitioned form of the swing equation. The approach accounts for (bounded) uncertainties in network parameters and PMU measurements, enabling precise estimation of inertia and damping constants, as well as mechanical power inputs. Instead of assuming constant mechanical power input throughout, the approach leverages knowledge of power system operations to determine intervals when it is actually constant to maintain estimation consistency. Simulation results on the IEEE 14-bus system and IEEE 39 bus system integrated with renewable energy sources affirm the method's accuracy and applicability.",
    "source": "arXiv"
  },
  {
    "title": "3D Gaussian Splatting Data Compression with Mixture of Priors",
    "title_es": "3D Gaussian Splatting Data Compression with Mixture of Priors",
    "url": "https://arxiv.org/abs/2505.03310",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.03310v2 Announce Type: replace \nAbstract: 3D Gaussian Splatting (3DGS) data compression is crucial for enabling efficient storage and transmission in 3D scene modeling. However, its development remains limited due to inadequate entropy models and suboptimal quantization strategies for both lossless and lossy compression scenarios, where existing methods have yet to 1) fully leverage hyperprior information to construct robust conditional entropy models, and 2) apply fine-grained, element-wise quantization strategies for improved compression granularity. In this work, we propose a novel Mixture of Priors (MoP) strategy to simultaneously address these two challenges. Specifically, inspired by the Mixture-of-Experts (MoE) paradigm, our MoP approach processes hyperprior information through multiple lightweight MLPs to generate diverse prior features, which are subsequently integrated into the MoP feature via a gating mechanism. To enhance lossless compression, the resulting MoP feature is utilized as a hyperprior to improve conditional entropy modeling. Meanwhile, for lossy compression, we employ the MoP feature as guidance information in an element-wise quantization procedure, leveraging a prior-guided Coarse-to-Fine Quantization (C2FQ) strategy with a predefined quantization step value. Specifically, we expand the quantization step value into a matrix and adaptively refine it from coarse to fine granularity, guided by the MoP feature, thereby obtaining a quantization step matrix that facilitates element-wise quantization. Extensive experiments demonstrate that our proposed 3DGS data compression framework achieves state-of-the-art performance across multiple benchmarks, including Mip-NeRF360, BungeeNeRF, DeepBlending, and Tank&Temples.",
    "source": "arXiv"
  },
  {
    "title": "WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch",
    "title_es": "WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch",
    "url": "https://arxiv.org/abs/2505.03733",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.03733v2 Announce Type: replace \nAbstract: LLM-based agents have demonstrated great potential in generating and managing code within complex codebases. In this paper, we introduce WebGen-Bench, a novel benchmark designed to measure an LLM-based agent's ability to create multi-file website codebases from scratch. It contains diverse instructions for website generation, created through the combined efforts of human annotators and GPT-4o. These instructions span three major categories and thirteen minor categories, encompassing nearly all important types of web applications. To assess the quality of the generated websites, we use GPT-4o to generate test cases targeting each functionality described in the instructions, and then manually filter, adjust, and organize them to ensure accuracy, resulting in 647 test cases. Each test case specifies an operation to be performed on the website and the expected result after the operation. To automate testing and improve reproducibility, we employ a powerful web-navigation agent to execute tests on the generated websites and determine whether the observed responses align with the expected results. We evaluate three high-performance code-agent frameworks, Bolt.diy, OpenHands, and Aider, using multiple proprietary and open-source LLMs as engines. The best-performing combination, Bolt.diy powered by DeepSeek-R1, achieves only 27.8\\% accuracy on the test cases, highlighting the challenging nature of our benchmark. Additionally, we construct WebGen-Instruct, a training set consisting of 6,667 website-generation instructions. Training Qwen2.5-Coder-32B-Instruct on Bolt.diy trajectories generated from a subset of this training set achieves an accuracy of 38.2\\%, surpassing the performance of the best proprietary model.",
    "source": "arXiv"
  },
  {
    "title": "mAIstro: an open-source multi-agentic system for automated end-to-end development of radiomics and deep learning models for medical imaging",
    "title_es": "mAIstro: an open-source multi-agentic system for automated end-to-end development of radiomics and deep learning models for medical imaging",
    "url": "https://arxiv.org/abs/2505.03785",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.03785v2 Announce Type: replace \nAbstract: Agentic systems built on large language models (LLMs) offer promising capabilities for automating complex workflows in healthcare AI. We introduce mAIstro, an open-source, autonomous multi-agentic framework for end-to-end development and deployment of medical AI models. The system orchestrates exploratory data analysis, radiomic feature extraction, image segmentation, classification, and regression through a natural language interface, requiring no coding from the user. Built on a modular architecture, mAIstro supports both open- and closed-source LLMs, and was evaluated using a large and diverse set of prompts across 16 open-source datasets, covering a wide range of imaging modalities, anatomical regions, and data types. The agents successfully executed all tasks, producing interpretable outputs and validated models. This work presents the first agentic framework capable of unifying data analysis, AI model development, and inference across varied healthcare applications, offering a reproducible and extensible foundation for clinical and research AI integration. The code is available at: https://github.com/eltzanis/mAIstro",
    "source": "arXiv"
  },
  {
    "title": "QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian Initialization",
    "title_es": "QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian Initialization",
    "url": "https://arxiv.org/abs/2505.05591",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.05591v2 Announce Type: replace \nAbstract: Surface reconstruction is fundamental to computer vision and graphics, enabling applications in 3D modeling, mixed reality, robotics, and more. Existing approaches based on volumetric rendering obtain promising results, but optimize on a per-scene basis, resulting in a slow optimization that can struggle to model under-observed or textureless regions. We introduce QuickSplat, which learns data-driven priors to generate dense initializations for 2D gaussian splatting optimization of large-scale indoor scenes. This provides a strong starting point for the reconstruction, which accelerates the convergence of the optimization and improves the geometry of flat wall structures. We further learn to jointly estimate the densification and update of the scene parameters during each iteration; our proposed densifier network predicts new Gaussians based on the rendering gradients of existing ones, removing the needs of heuristics for densification. Extensive experiments on large-scale indoor scene reconstruction demonstrate the superiority of our data-driven optimization. Concretely, we accelerate runtime by 8x, while decreasing depth errors by up to 48% in comparison to state of the art methods.",
    "source": "arXiv"
  },
  {
    "title": "Not Like Us, Hunty: Measuring Perceptions and Behavioral Effects of Minoritized Anthropomorphic Cues in LLMs",
    "title_es": "Not Like Us, Hunty: Measuring Perceptions and Behavioral Effects of Minoritized Anthropomorphic Cues in LLMs",
    "url": "https://arxiv.org/abs/2505.05660",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.05660v3 Announce Type: replace \nAbstract: As large language models (LLMs) increasingly adapt and personalize to diverse sets of users, there is an increased risk of systems appropriating sociolects, i.e., language styles or dialects that are associated with specific minoritized lived experiences (e.g., African American English, Queer slang). In this work, we examine whether sociolect usage by an LLM agent affects user reliance on its outputs and user perception (satisfaction, frustration, trust, and social presence). We designed and conducted user studies where 498 African American English (AAE) speakers and 487 Queer slang speakers performed a set of question-answering tasks with LLM-based suggestions in either standard American English (SAE) or their self-identified sociolect. Our findings showed that sociolect usage by LLMs influenced both reliance and perceptions, though in some surprising ways. Results suggest that both AAE and Queer slang speakers relied more on the SAE agent, and had more positive perceptions of the SAE agent. Yet, only Queer slang speakers felt more social presence from the Queer slang agent over the SAE one, whereas only AAE speakers preferred and trusted the SAE agent over the AAE one. These findings emphasize the need to test for behavioral outcomes rather than simply assume that personalization would lead to a better and safer reliance outcome. They also highlight the nuanced dynamics of minoritized language in machine interactions, underscoring the need for LLMs to be carefully designed to respect cultural and linguistic boundaries while fostering genuine user engagement and trust.",
    "source": "arXiv"
  },
  {
    "title": "Visual Evolutionary Optimization on Graph-Structured Combinatorial Problems with MLLMs: A Case Study of Influence Maximization",
    "title_es": "Visual Evolutionary Optimization on Graph-Structured Combinatorial Problems with MLLMs: A Case Study of Influence Maximization",
    "url": "https://arxiv.org/abs/2505.06850",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.06850v2 Announce Type: replace \nAbstract: Graph-structured combinatorial problems in complex networks are prevalent in many domains, and are computationally demanding due to their complexity and non-linear nature. Traditional evolutionary algorithms (EAs), while robust, often face obstacles due to content-shallow encoding limitations and lack of structural awareness, necessitating hand-crafted modifications for effective application. In this work, we introduce an original framework, visual evolutionary ptimization (VEO), leveraging multimodal large language models (MLLMs) as the backbone evolutionary optimizer in this context. Specifically, we propose a context-aware encoding way, representing the solution of the network as an image. In this manner, we can utilize MLLMs' image processing capabilities to intuitively comprehend network configurations, thus enabling machines to solve these problems in a human-like way. We have developed MLLM-based operators tailored for various evolutionary optimization stages, including initialization, crossover, and mutation. Furthermore, we propose that graph sparsification can effectively enhance the applicability and scalability of VEO on large-scale networks, owing to the scale-free nature of real-world networks. We demonstrate the effectiveness of our method using a well-known task in complex networks, influence maximization, and validate it on eight different real-world networks of various structures. The results have confirmed VEO's reliability and enhanced effectiveness compared to traditional evolutionary optimization.",
    "source": "arXiv"
  },
  {
    "title": "Embodied intelligent industrial robotics: Concepts and techniques",
    "title_es": "Embodied intelligent industrial robotics: Concepts and techniques",
    "url": "https://arxiv.org/abs/2505.09305",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.09305v4 Announce Type: replace \nAbstract: In order to work more efficiently, accurately, reliably, and safely in industrial scenarios, robots should have at least general knowledge, working-environment knowledge, and operating-object knowledge. These pose significant challenges to existing embodied intelligent robotics (EIR) techniques. Thus, this paper first briefly reviews the history of industrial robotics and analyzes the limitations of mainstream EIR frameworks. Then, a knowledge-driven technical framework of embodied intelligent industrial robotics (EIIR) is proposed for various industrial environments. It has five modules: a world model, a high-level task planner, a low-level skill controller, a simulator, and a physical system. The development of techniques related to each module are also thoroughly reviewed, and recent progress regarding their adaption to industrial applications are discussed. A case study is given to demonstrate the newly proposed EIIR framework's applicability to real-world assembly system. Finally, the key challenges that EIIR encounters in industrial scenarios are summarized and future research directions are suggested. The authors believe that EIIR technology is shaping the next generation of industrial robotics and EIIR-based industrial systems supply a new technological paradigm for intelligent manufacturing. It is expected that this review could serve as a valuable reference for scholars and engineers that are interested in industrial embodied intelligence. Together, scholars can use this research to drive their rapid advancement and application of EIIR techniques. The interested authors would continue to track and contribute new studies in the project page https://github.com/jackyzengl/EIIR.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization",
    "title_es": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization",
    "url": "https://arxiv.org/abs/2505.09930",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.09930v3 Announce Type: replace \nAbstract: Prompt optimization (PO) provides a practical way to improve response quality when users lack the time or expertise to manually craft effective prompts. Existing methods typically rely on LLMs' self-generation ability to optimize prompts. However, due to limited downward compatibility, the instruction-heavy prompts generated by advanced LLMs can overwhelm lightweight inference models and degrade response quality, while also lacking interpretability due to implicit optimization. In this work, we rethink prompt optimization through the lens of explicit and interpretable design. We first identify a set of model-agnostic prompt quality merits and empirically validate their effectiveness in enhancing prompt and response quality. We then introduce MePO, a merit-guided, locally deployable prompt optimizer trained on our merit-guided prompt preference dataset generated by a lightweight LLM. MePO avoids online optimization, reduces privacy concerns, and, by learning clear, interpretable merits, generalizes effectively to both large-scale and lightweight inference models. Experiments demonstrate that MePO achieves better results across diverse tasks and model types, offering a scalable and robust solution for real-world deployment.The code, model and dataset can be found in https://github.com/MidiyaZhu/MePO",
    "source": "arXiv"
  },
  {
    "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning",
    "title_es": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning",
    "url": "https://arxiv.org/abs/2505.10347",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.10347v2 Announce Type: replace \nAbstract: Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task Learning by addressing issues like conflicting gradients and differing gradient norms, which hinder equal-weighted task training. However, recent critiques suggest that equally weighted tasks can achieve competitive results compared to SMTOs, arguing that previous SMTO results were influenced by poor hyperparameter optimization and lack of regularization. In this work, we evaluate these claims through an extensive empirical evaluation of SMTOs, including some of the latest methods, on more complex multi-task problems to clarify this behavior. Our findings indicate that SMTOs perform well compared to uniform loss and that fixed weights can achieve competitive performance compared to SMTOs. Furthermore, we demonstrate why uniform loss perform similarly to SMTOs in some instances. The source code is available at https://github.com/Gabriel-SGama/UnitScal_vs_SMTOs.",
    "source": "arXiv"
  },
  {
    "title": "Decoding the Multimodal Mind: Generalizable Brain-to-Text Translation via Multimodal Alignment and Adaptive Routing",
    "title_es": "Decoding the Multimodal Mind: Generalizable Brain-to-Text Translation via Multimodal Alignment and Adaptive Routing",
    "url": "https://arxiv.org/abs/2505.10356",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.10356v2 Announce Type: replace \nAbstract: Decoding language from the human brain remains a grand challenge for Brain-Computer Interfaces (BCIs). Current approaches typically rely on unimodal brain representations, neglecting the brain's inherently multimodal processing. Inspired by the brain's associative mechanisms, where viewing an image can evoke related sounds and linguistic representations, we propose a unified framework that leverages Multimodal Large Language Models (MLLMs) to align brain signals with a shared semantic space encompassing text, images, and audio. A router module dynamically selects and fuses modality-specific brain features according to the characteristics of each stimulus. Experiments on various fMRI datasets with textual, visual, and auditory stimuli demonstrate state-of-the-art performance, achieving an 8.48% improvement on the most commonly used benchmark. We further extend our framework to EEG and MEG data, demonstrating flexibility and robustness across varying temporal and spatial resolutions. To our knowledge, this is the first unified BCI architecture capable of robustly decoding multimodal brain activity across diverse brain signals and stimulus types, offering a flexible solution for real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "AORRTC: Almost-Surely Asymptotically Optimal Planning with RRT-Connect",
    "title_es": "AORRTC: Almost-Surely Asymptotically Optimal Planning with RRT-Connect",
    "url": "https://arxiv.org/abs/2505.10542",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.10542v3 Announce Type: replace \nAbstract: Finding high-quality solutions quickly is an important objective in motion planning. This is especially true for high-degree-of-freedom robots. Satisficing planners have traditionally found feasible solutions quickly but provide no guarantees on their optimality, while almost-surely asymptotically optimal (a.s.a.o.) planners have probabilistic guarantees on their convergence towards an optimal solution but are more computationally expensive.\n  This paper uses the AO-x meta-algorithm to extend the satisficing RRT-Connect planner to optimal planning. The resulting Asymptotically Optimal RRT-Connect (AORRTC) finds initial solutions in similar times as RRT-Connect and uses any additional planning time to converge towards the optimal solution in an anytime manner. It is proven to be probabilistically complete and a.s.a.o.\n  AORRTC was tested with the Panda (7 DoF) and Fetch (8 DoF) robotic arms on the MotionBenchMaker dataset. These experiments show that AORRTC finds initial solutions as fast as RRT-Connect and faster than the tested state-of-the-art a.s.a.o. algorithms while converging to better solutions faster. AORRTC finds solutions to difficult high-DoF planning problems in milliseconds where the other a.s.a.o. planners could not consistently find solutions in seconds. This performance was demonstrated both with and without single instruction/multiple data (SIMD) acceleration.",
    "source": "arXiv"
  },
  {
    "title": "Reasoning Capabilities of Large Language Models on Dynamic Tasks",
    "title_es": "Reasoning Capabilities of Large Language Models on Dynamic Tasks",
    "url": "https://arxiv.org/abs/2505.10543",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.10543v2 Announce Type: replace \nAbstract: Large language models excel on static benchmarks, but their ability as self-learning agents in dynamic environments remains unclear. We evaluate three prompting strategies: self-reflection, heuristic mutation, and planning across dynamic tasks with open-source models. We find that larger models generally outperform smaller ones, but that strategic prompting can close this performance gap. Second, an overly long prompt can negatively impact smaller models on basic reactive tasks, while larger models show more robust behaviour. Third, advanced prompting techniques primarily benefit smaller models on complex games, but offer less improvement for already high-performing large language models. Yet, we find that advanced reasoning methods yield highly variable outcomes: while capable of significantly improving performance when reasoning and decision-making align, they also introduce instability and can lead to big performance drops. Compared to human performance, our findings reveal little evidence of true emergent reasoning. Instead, large language model performance exhibits persistent limitations in areas like planning and spatial coordination, suggesting that large language models still suffer fundamental shortcomings that may not be fully overcome through self-reflective prompting alone. Reasoning is a multi-faceted task, and while methods like Chain-of-thought improve multi-step reasoning on math word problems, our findings using dynamic benchmarks highlight important shortcomings in general reasoning capabilities, indicating a need to move beyond static benchmarks to capture the complexity of reasoning.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Irregular Time Series Forecasting: A Simple yet Effective Baseline",
    "title_es": "Rethinking Irregular Time Series Forecasting: A Simple yet Effective Baseline",
    "url": "https://arxiv.org/abs/2505.11250",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.11250v3 Announce Type: replace \nAbstract: The forecasting of irregular multivariate time series (IMTS) is a critical task in domains like healthcare and climate science. However, this task faces two significant hurdles: 1) the inherent non-uniformity and missing data in IMTS complicate the modeling of temporal dynamics, and 2) existing methods often rely on computationally expensive architectures. To address these dual challenges, we introduce APN, a general and efficient forecasting framework. At the core of APN is a novel Time-Aware Patch Aggregation (TAPA) module that introduces an aggregation-based paradigm for adaptive patching, moving beyond the limitations of fixed-span segmentation and interpolation-based methods. TAPA first learns dynamic temporal boundaries to define data-driven segments. Crucially, instead of resampling or interpolating, it directly computes patch representations via a time-aware weighted aggregation of all raw observations, where weights are determined by each observation's temporal relevance to the segment. This approach provides two key advantages: it preserves data fidelity by avoiding the introduction of artificial data points and ensures complete information coverage by design.The resulting regularized and information-rich patch representations enable the use of a lightweight query module for historical context aggregation and a simple MLP for final prediction. Extensive experiments on multiple real-world datasets demonstrate that APN establishes a new state-of-the-art, significantly outperforming existing methods in both prediction accuracy and computational efficiency.",
    "source": "arXiv"
  },
  {
    "title": "TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text",
    "title_es": "TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text",
    "url": "https://arxiv.org/abs/2505.11988",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.11988v2 Announce Type: replace \nAbstract: Accurately identifying adversarial techniques in security texts is critical for effective cyber defense. However, existing methods face a fundamental trade-off: they either rely on generic models with limited domain precision or require resource-intensive pipelines that depend on large labeled datasets and task-specific optimizations, such as custom hard-negative mining and denoising, resources rarely available in specialized domains.\n  We propose TechniqueRAG, a domain-specific retrieval-augmented generation (RAG) framework that bridges this gap by integrating off-the-shelf retrievers, instruction-tuned LLMs, and minimal text-technique pairs. Our approach addresses data scarcity by fine-tuning only the generation component on limited in-domain examples, circumventing the need for resource-intensive retrieval training. While conventional RAG mitigates hallucination by coupling retrieval and generation, its reliance on generic retrievers often introduces noisy candidates, limiting domain-specific precision. To address this, we enhance retrieval quality and domain specificity through zero-shot LLM re-ranking, which explicitly aligns retrieved candidates with adversarial techniques.\n  Experiments on multiple security benchmarks demonstrate that TechniqueRAG achieves state-of-the-art performance without extensive task-specific optimizations or labeled data, while comprehensive analysis provides further insights.",
    "source": "arXiv"
  },
  {
    "title": "The taggedPBC: Annotating a massive parallel corpus for crosslinguistic investigations",
    "title_es": "The taggedPBC: Annotating a massive parallel corpus for crosslinguistic investigations",
    "url": "https://arxiv.org/abs/2505.12560",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.12560v2 Announce Type: replace \nAbstract: Existing datasets available for crosslinguistic investigations have tended to focus on large amounts of data for a small group of languages or a small amount of data for a large number of languages. This means that claims based on these datasets are limited in what they reveal about universal properties of the human language faculty. While this has begun to change through the efforts of projects seeking to develop tagged corpora for a large number of languages, such efforts are still constrained by limits on resources. The current paper reports on a large tagged parallel dataset which has been developed to partially address this issue. The taggedPBC contains POS-tagged parallel text data from more than 1,940 languages, representing 155 language families and 78 isolates, dwarfing previously available resources. The accuracy of particular tags in this dataset is shown to correlate well with both existing SOTA taggers for high-resource languages (SpaCy, Trankit) as well as hand-tagged corpora (Universal Dependencies Treebanks). Additionally, a novel measure derived from this dataset, the N1 ratio, correlates with expert determinations of intransitive word order in three typological databases (WALS, Grambank, Autotyp) such that a Gaussian Naive Bayes classifier trained on this feature can accurately identify basic intransitive word order for languages not in those databases. While much work is still needed to expand and develop this dataset, the taggedPBC is an important step to enable corpus-based crosslinguistic investigations, and is made available for research and collaboration via GitHub.",
    "source": "arXiv"
  },
  {
    "title": "Interpolation for the two-way modal mu-calculus",
    "title_es": "Interpolation for the two-way modal mu-calculus",
    "url": "https://arxiv.org/abs/2505.12899",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.12899v3 Announce Type: replace \nAbstract: The two-way modal mu-calculus is the extension of the (standard) one-way mu-calculus with converse (backward-looking) modalities. For this logic we introduce two new sequent-style proof calculi: a non-wellfounded system admitting infinite branches and a finitary, cyclic version of this that employs annotations. As is common in sequent systems for two-way modal logics, our calculi feature an analytic cut rule. What distinguishes our approach is the use of so-called trace atoms, which serve to apply Vardi's two-way automata in a proof-theoretic setting. We prove soundness and completeness for both systems and subsequently use the cyclic calculus to show that the two-way mu-calculus has the (local) Craig interpolation property, with respect to both propositions and modalities. Our proof uses a version of Maehara's method adapted to cyclic proof systems. As a corollary we prove that the two-way mu-calculus also enjoys Beth's definability property.",
    "source": "arXiv"
  },
  {
    "title": "Transfer Learning from Visual Speech Recognition to Mouthing Recognition in German Sign Language",
    "title_es": "Transfer Learning from Visual Speech Recognition to Mouthing Recognition in German Sign Language",
    "url": "https://arxiv.org/abs/2505.13784",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.13784v2 Announce Type: replace \nAbstract: Sign Language Recognition (SLR) systems primarily focus on manual gestures, but non-manual features such as mouth movements, specifically mouthing, provide valuable linguistic information. This work directly classifies mouthing instances to their corresponding words in the spoken language while exploring the potential of transfer learning from Visual Speech Recognition (VSR) to mouthing recognition in German Sign Language. We leverage three VSR datasets: one in English, one in German with unrelated words and one in German containing the same target words as the mouthing dataset, to investigate the impact of task similarity in this setting. Our results demonstrate that multi-task learning improves both mouthing recognition and VSR accuracy as well as model robustness, suggesting that mouthing recognition should be treated as a distinct but related task to VSR. This research contributes to the field of SLR by proposing knowledge transfer from VSR to SLR datasets with limited mouthing annotations.",
    "source": "arXiv"
  },
  {
    "title": "Unintended Bias in 2D+ Image Segmentation and Its Effect on Attention Asymmetry",
    "title_es": "Unintended Bias in 2D+ Image Segmentation and Its Effect on Attention Asymmetry",
    "url": "https://arxiv.org/abs/2505.14105",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.14105v2 Announce Type: replace \nAbstract: Supervised pretrained models have become widely used in deep learning, especially for image segmentation tasks. However, when applied to specialized datasets such as biomedical imaging, pretrained weights often introduce unintended biases. These biases cause models to assign different levels of importance to different slices, leading to inconsistencies in feature utilization, which can be observed as asymmetries in saliency map distributions. This transfer of color distributions from natural images to non-natural datasets can compromise model performance and reduce the reliability of results. In this study, we investigate the effects of these biases and propose strategies to mitigate them. Through a series of experiments, we test both pretrained and randomly initialized models, comparing their performance and saliency map distributions. Our proposed methods, which aim to neutralize the bias introduced by pretrained color channel weights, demonstrate promising results, offering a practical approach to improving model explainability while maintaining the benefits of pretrained models. This publication presents our findings, providing insights into addressing pretrained weight biases across various deep learning tasks.",
    "source": "arXiv"
  },
  {
    "title": "Functional Controllability, Functional Stabilizability, and the Generalized Separation Principle",
    "title_es": "Functional Controllability, Functional Stabilizability, and the Generalized Separation Principle",
    "url": "https://arxiv.org/abs/2505.14176",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.14176v2 Announce Type: replace \nAbstract: This paper introduces the new concepts of Functional Controllability and Functional Stabilizability, and establishes their duality with Functional Observability and Functional Detectability, respectively. A Generalized Separation Principle is presented, under which the classical Separation Principle emerges as a special case. Conditions for the existence of functional controllers of a specified order are derived. Notably, the proposed design framework does not require full controllability. In addition, a functional observer-based controller design is developed for systems that may be both uncontrollable and unobservable. The results presented extend and generalize the classical full-state observer based feedback control paradigm.",
    "source": "arXiv"
  },
  {
    "title": "Identification of Probabilities of Causation: A Complete Characterization",
    "title_es": "Identification of Probabilities of Causation: A Complete Characterization",
    "url": "https://arxiv.org/abs/2505.15274",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.15274v2 Announce Type: replace \nAbstract: Probabilities of causation are fundamental to modern decision-making. Pearl first introduced three binary probabilities of causation, and Tian and Pearl later derived tight bounds for them using Balke's linear programming. The theoretical characterization of probabilities of causation with multi-valued treatments and outcomes has remained unresolved for decades, limiting the scope of causality-based decision-making. In this paper, we resolve this foundational gap by proposing a complete set of representative probabilities of causation and proving that they are sufficient to characterize all possible probabilities of causation within the framework of Structural Causal Models (SCMs). We then formally derive tight bounds for these representative quantities using formal mathematical proofs. Finally, we demonstrate the practical relevance of our results through illustrative toy examples.",
    "source": "arXiv"
  },
  {
    "title": "Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization",
    "title_es": "Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization",
    "url": "https://arxiv.org/abs/2505.15918",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.15918v2 Announce Type: replace \nAbstract: In this work, we evaluate the potential of Large Language Models (LLMs) in building Bayesian Networks (BNs) by approximating domain expert priors. LLMs have demonstrated potential as factual knowledge bases; however, their capability to generate probabilistic knowledge about real-world events remains understudied. We explore utilizing the probabilistic knowledge inherent in LLMs to derive probability estimates for statements regarding events and their relationships within a BN. Using LLMs in this context allows for the parameterization of BNs, enabling probabilistic modeling within specific domains. Our experiments on eighty publicly available Bayesian Networks, from healthcare to finance, demonstrate that querying LLMs about the conditional probabilities of events provides meaningful results when compared to baselines, including random and uniform distributions, as well as approaches based on next-token generation probabilities. We explore how these LLM-derived distributions can serve as expert priors to refine distributions extracted from data, especially when data is scarce. Overall, this work introduces a promising strategy for automatically constructing Bayesian Networks by combining probabilistic knowledge extracted from LLMs with real-world data. Additionally, we establish the first comprehensive baseline for assessing LLM performance in extracting probabilistic knowledge.",
    "source": "arXiv"
  },
  {
    "title": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning",
    "title_es": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning",
    "url": "https://arxiv.org/abs/2505.16341",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.16341v3 Announce Type: replace \nAbstract: This paper studies the long-tailed semi-supervised learning (LTSSL) with distribution mismatch, where the class distribution of the labeled training data follows a long-tailed distribution and mismatches with that of the unlabeled training data. Most existing methods introduce auxiliary classifiers (experts) to model various unlabeled data distributions and produce pseudo-labels, but the expertises of various experts are not fully utilized. We observe that different experts are good at predicting different intervals of samples, e.g., long-tailed expert is skilled in samples located in the head interval and uniform expert excels in samples located in the medium interval. Therefore, we propose a dynamic expert assignment module that can estimate the class membership (i.e., head, medium, or tail class) of samples, and dynamically assigns suitable expert to each sample based on the estimated membership to produce high-quality pseudo-label in the training phase and produce prediction in the testing phase. We also theoretically reveal that integrating different experts' strengths will lead to a smaller generalization error bound. Moreover, we find that the deeper features are more biased toward the head class but with more discriminative ability, while the shallower features are less biased but also with less discriminative ability. We, therefore, propose a multi-depth feature fusion module to utilize different depth features to mitigate the model bias. Our method demonstrates its effectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT, and SVHN-LT datasets across various settings.",
    "source": "arXiv"
  },
  {
    "title": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving",
    "title_es": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving",
    "url": "https://arxiv.org/abs/2505.16646",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.16646v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) have achieved remarkable results on a variety of mathematical benchmarks. However, concerns remain as to whether these successes reflect genuine reasoning or superficial pattern recognition. Common evaluation methods, which focus on the either the final answer or the reasoning process, fail to assess the entire problem-solving procedure. To address these limitations, we introduce SMART: a Self-Generating and Self-Validating Multi-Dimensional Assessment Framework, together with its corresponding benchmark, SMART-Bench. SMART decomposes the entire problem solving process into four distinct cognitive dimensions: Understanding, Reasoning, Arithmetic, and Reflection \\& Refinement. Each dimension is evaluated independently through tailored tasks, enabling interpretable and fine-grained analysis of LLM behavior. We apply SMART to 21 state-of-the-art open- and closed-source LLMs, uncovering significant discrepancies in their abilities across different dimensions. Our findings reveal genuine weaknesses in current LLMs and motivate a new metric, the All-Pass Score, to better capture true problem-solving capabilities. Code and benchmarks will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration",
    "title_es": "Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration",
    "url": "https://arxiv.org/abs/2505.17066",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.17066v3 Announce Type: replace \nAbstract: Using LLMs in a production environment presents security challenges that include vulnerabilities to jailbreaks and prompt injections, which can result in harmful outputs for humans or the enterprise. The challenge is amplified when working within a specific domain, as topics generally accepted for LLMs to address may be irrelevant to that field. These problems can be mitigated, for example, by fine-tuning large language models with domain-specific and security-focused data. However, these alone are insufficient, as jailbreak techniques evolve. Additionally, API-accessed models do not offer the flexibility needed to tailor behavior to industry-specific objectives, and in-context learning is not always sufficient or reliable. In response to these challenges, we introduce Archias, an expert model adept at distinguishing between in-domain and out-of-domain communications. Archias classifies user inquiries into several categories: in-domain (specifically for the automotive industry), malicious questions, price injections, prompt injections, and out-of-domain examples. Our methodology integrates outputs from the expert model (Archias) into prompts, which are then processed by the LLM to generate responses. This method increases the model's ability to understand the user's intention and give appropriate answers. Archias can be adjusted, fine-tuned, and used for many different purposes due to its small size. Therefore, it can be easily customized to the needs of any industry. To validate our approach, we created a benchmark dataset for the automotive industry. Furthermore, in the interest of advancing research and development, we release our benchmark dataset to the community.",
    "source": "arXiv"
  },
  {
    "title": "Is Single-View Mesh Reconstruction Ready for Robotics?",
    "title_es": "Is Single-View Mesh Reconstruction Ready for Robotics?",
    "url": "https://arxiv.org/abs/2505.17966",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.17966v2 Announce Type: replace \nAbstract: This paper evaluates single-view mesh reconstruction models for their potential in enabling instant digital twin creation for real-time planning and dynamics prediction using physics simulators for robotic manipulation. Recent single-view 3D reconstruction advances offer a promising avenue toward an automated real-to-sim pipeline: directly mapping a single observation of a scene into a simulation instance by reconstructing scene objects as individual, complete, and physically plausible 3D meshes. However, their suitability for physics simulations and robotics applications under immediacy, physical fidelity, and simulation readiness remains underexplored. We establish robotics-specific benchmarking criteria for 3D reconstruction, including handling typical inputs, collision-free and stable geometry, occlusions robustness, and meeting computational constraints. Our empirical evaluation using realistic robotics datasets shows that despite success on computer vision benchmarks, existing approaches fail to meet robotics-specific requirements. We quantitively examine limitations of single-view reconstruction for practical robotics implementation, in contrast to prior work that focuses on multi-view approaches. Our findings highlight critical gaps between computer vision advances and robotics needs, guiding future research at this intersection.",
    "source": "arXiv"
  },
  {
    "title": "FP4 All the Way: Fully Quantized Training of LLMs",
    "title_es": "FP4 All the Way: Fully Quantized Training of LLMs",
    "url": "https://arxiv.org/abs/2505.19115",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.19115v2 Announce Type: replace \nAbstract: We demonstrate, for the first time, fully quantized training (FQT) of large language models (LLMs) using predominantly 4-bit floating-point (FP4) precision for weights, activations, and gradients on datasets up to 200 billion tokens. We extensively investigate key design choices for FP4, including block sizes, scaling formats, and rounding methods. Our analysis shows that the NVFP4 format, where each block of 16 FP4 values (E2M1) shares a scale represented in E4M3, provides optimal results. We use stochastic rounding for backward and update passes and round-to-nearest for the forward pass to enhance stability. Additionally, we identify a theoretical and empirical threshold for effective quantized training: when the gradient norm falls below approximately $\\sqrt{3}$ times the quantization noise, quantized training becomes less effective. Leveraging these insights, we successfully train a 7-billion-parameter model on 256 Intel Gaudi2 accelerators. The resulting FP4-trained model achieves downstream task performance comparable to a standard BF16 baseline, confirming that FP4 training is a practical and highly efficient approach for large-scale LLM training. A reference implementation is supplied in https://github.com/Anonymous1252022/fp4-all-the-way .",
    "source": "arXiv"
  },
  {
    "title": "Toward Patient-specific Partial Point Cloud to Surface Completion for Pre- to Intra-operative Registration in Image-guided Liver Interventions",
    "title_es": "Toward Patient-specific Partial Point Cloud to Surface Completion for Pre- to Intra-operative Registration in Image-guided Liver Interventions",
    "url": "https://arxiv.org/abs/2505.19518",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.19518v2 Announce Type: replace \nAbstract: Intra-operative data captured during image-guided surgery lacks sub-surface information, where key regions of interest, such as vessels and tumors, reside. Image-to-physical registration enables the fusion of pre-operative information and intra-operative data, typically represented as a point cloud. However, this registration process struggles due to partial visibility of the intra-operative point cloud. In this research, we propose a patient-specific point cloud completion approach to assist with the registration process. Specifically, we leverage VN-OccNet to generate a complete liver surface from a partial intra-operative point cloud. The network is trained in a patient-specific manner, where simulated deformations from the pre-operative model are used to train the model. First, we conduct an in-depth analysis of VN-OccNet's rotation-equivariant property and its effectiveness in recovering complete surfaces from partial intra-operative surfaces. Next, we integrate the completed intra-operative surface into the Go-ICP registration algorithm to demonstrate its utility in improving initial rigid registration outcomes. Our results highlight the promise of this patient-specific completion approach in mitigating the challenges posed by partial intra-operative visibility. The rotation equivariant and surface generation capabilities of VN-OccNet hold strong promise for developing robust registration frameworks for variations of the intra-operative point cloud.",
    "source": "arXiv"
  },
  {
    "title": "Learning to Reason without External Rewards",
    "title_es": "Learning to Reason without External Rewards",
    "url": "https://arxiv.org/abs/2505.19590",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.19590v2 Announce Type: replace \nAbstract: Training large language models (LLMs) for complex reasoning via Reinforcement Learning with Verifiable Rewards (RLVR) is effective but limited by reliance on costly, domain-specific supervision. We explore Reinforcement Learning from Internal Feedback (RLIF), a framework that enables LLMs to learn from intrinsic signals without external rewards or labeled data. We propose Intuitor, an RLIF method that uses a model's own confidence, termed self-certainty, as its sole reward signal. Intuitor replaces external rewards in Group Relative Policy Optimization (GRPO) with self-certainty scores, enabling fully unsupervised learning. Experiments demonstrate that Intuitor matches GRPO's performance on mathematical benchmarks while achieving superior generalization to out-of-domain tasks like code generation, without requiring gold solutions or test cases. Our findings show that intrinsic model signals can drive effective learning across domains, offering a scalable alternative to RLVR for autonomous AI systems where verifiable rewards are unavailable. Code is available at https://github.com/sunblaze-ucb/Intuitor",
    "source": "arXiv"
  },
  {
    "title": "Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents",
    "title_es": "Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents",
    "url": "https://arxiv.org/abs/2505.19997",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.19997v2 Announce Type: replace \nAbstract: Large language models (LLMs) are revolutionizing education, with LLM-based agents playing a key role in simulating student behavior. A major challenge in student simulation is modeling the diverse learning patterns of students at various cognitive levels. However, current LLMs, typically trained as ``helpful assistants'', target at generating perfect responses. As a result, they struggle to simulate students with diverse cognitive abilities, as they often produce overly advanced answers, missing the natural imperfections that characterize student learning and resulting in unrealistic simulations. To address this issue, we propose a training-free framework for student simulation. We begin by constructing a cognitive prototype for each student using a knowledge graph, which captures their understanding of concepts from past learning records. This prototype is then mapped to new tasks to predict student performance. Next, we simulate student solutions based on these predictions and iteratively refine them using a beam search method to better replicate realistic mistakes. To validate our approach, we construct the \\texttt{Student\\_100} dataset, consisting of $100$ students working on Python programming and $5,000$ learning records. Experimental results show that our method consistently outperforms baseline models, achieving $100\\%$ improvement in simulation accuracy.",
    "source": "arXiv"
  },
  {
    "title": "NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-Identification",
    "title_es": "NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-Identification",
    "url": "https://arxiv.org/abs/2505.20001",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.20001v4 Announce Type: replace \nAbstract: Multi-modal object Re-Identification (ReID) aims to obtain accurate identity features across heterogeneous modalities. However, most existing methods rely on implicit feature fusion modules, making it difficult to model fine-grained recognition patterns under various challenges in real world. Benefiting from the powerful Multi-modal Large Language Models (MLLMs), the object appearances are effectively translated into descriptive captions. In this paper, we propose a reliable caption generation pipeline based on attribute confidence, which significantly reduces the unknown recognition rate of MLLMs and improves the quality of generated text. Additionally, to model diverse identity patterns, we propose a novel ReID framework, named NEXT, the Multi-grained Mixture of Experts via Text-Modulation for Multi-modal Object Re-Identification. Specifically, we decouple the recognition problem into semantic and structural branches to separately capture fine-grained appearance features and coarse-grained structure features. For semantic recognition, we first propose a Text-Modulated Semantic Experts (TMSE), which randomly samples high-quality captions to modulate experts capturing semantic features and mining inter-modality complementary cues. Second, to recognize structure features, we propose a Context-Shared Structure Experts (CSSE), which focuses on the holistic object structure and maintains identity structural consistency via a soft routing mechanism. Finally, we propose a Multi-Grained Features Aggregation (MGFA), which adopts a unified fusion strategy to effectively integrate multi-grained experts into the final identity representations. Extensive experiments on four public datasets demonstrate the effectiveness of our method and show that it significantly outperforms existing state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "EF-VI: Enhancing End-Frame Injection for Video Inbetweening",
    "title_es": "EF-VI: Enhancing End-Frame Injection for Video Inbetweening",
    "url": "https://arxiv.org/abs/2505.21205",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.21205v2 Announce Type: replace \nAbstract: Video inbetweening aims to synthesize intermediate video sequences conditioned on the given start and end frames. Current state-of-the-art methods primarily extend large-scale pre-trained Image-to-Video Diffusion Models (I2V-DMs) by incorporating the end-frame condition via direct fine-tuning or temporally bidirectional sampling. However, the former results in a weak end-frame constraint, while the latter inevitably disrupts the input representation of video frames, leading to suboptimal performance. To improve the end-frame constraint while avoiding disruption of the input representation, we propose a novel video inbetweening framework specific to recent and more powerful transformer-based I2V-DMs, termed EF-VI. It efficiently strengthens the end-frame constraint by utilizing an enhanced injection. This is based on our proposed well-designed lightweight module, termed EF-Net, which encodes only the end frame and expands it into temporally adaptive frame-wise features injected into the I2V-DM. Extensive experiments demonstrate the superiority of our EF-VI compared with other baselines.",
    "source": "arXiv"
  },
  {
    "title": "WebDancer: Towards Autonomous Information Seeking Agency",
    "title_es": "WebDancer: Towards Autonomous Information Seeking Agency",
    "url": "https://arxiv.org/abs/2505.22648",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.22648v3 Announce Type: replace \nAbstract: Addressing intricate real-world problems necessitates in-depth information seeking and multi-step reasoning. Recent progress in agentic systems, exemplified by Deep Research, underscores the potential for autonomous multi-step research. In this work, we present a cohesive paradigm for building end-to-end agentic information seeking agents from a data-centric and training-stage perspective. Our approach consists of four key stages: (1) browsing data construction, (2) trajectories sampling, (3) supervised fine-tuning for effective cold start, and (4) reinforcement learning for enhanced generalisation. We instantiate this framework in a web agent based on the ReAct, WebDancer. Empirical evaluations on the challenging information seeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of WebDancer, achieving considerable results and highlighting the efficacy of our training paradigm. Further analysis of agent training provides valuable insights and actionable, systematic pathways for developing more capable agentic models. The codes and demo will be released in https://github.com/Alibaba-NLP/WebAgent.",
    "source": "arXiv"
  },
  {
    "title": "Rhetorical Text-to-Image Generation via Two-layer Diffusion Policy Optimization",
    "title_es": "Rhetorical Text-to-Image Generation via Two-layer Diffusion Policy Optimization",
    "url": "https://arxiv.org/abs/2505.22792",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.22792v2 Announce Type: replace \nAbstract: Generating images from rhetorical languages remains a critical challenge for text-to-image models. Even state-of-the-art (SOTA) multimodal large language models (MLLM) fail to generate images based on the hidden meaning inherent in rhetorical language--despite such content being readily mappable to visual representations by humans. A key limitation is that current models emphasize object-level word embedding alignment, causing metaphorical expressions to steer image generation towards their literal visuals and overlook the intended semantic meaning. To address this, we propose Rhet2Pix, a framework that formulates rhetorical text-to-image generation as a multi-step policy optimization problem, incorporating a two-layer MDP diffusion module. In the outer layer, Rhet2Pix converts the input prompt into incrementally elaborated sub-sentences and executes corresponding image-generation actions, constructing semantically richer visuals. In the inner layer, Rhet2Pix mitigates reward sparsity during image generation by discounting the final reward and optimizing every adjacent action pair along the diffusion denoising trajectory. Extensive experiments demonstrate the effectiveness of Rhet2Pix in rhetorical text-to-image generation. Our model outperforms SOTA MLLMs such as GPT-4o, Grok-3 and leading academic baselines across both qualitative and quantitative evaluations. The code and dataset used in this work are publicly available.",
    "source": "arXiv"
  },
  {
    "title": "HiGarment: Cross-modal Harmony Based Diffusion Model for Flat Sketch to Realistic Garment Image",
    "title_es": "HiGarment: Cross-modal Harmony Based Diffusion Model for Flat Sketch to Realistic Garment Image",
    "url": "https://arxiv.org/abs/2505.23186",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.23186v2 Announce Type: replace \nAbstract: Diffusion-based garment synthesis tasks primarily focus on the design phase in the fashion domain, while the garment production process remains largely underexplored. To bridge this gap, we introduce a new task: Flat Sketch to Realistic Garment Image (FS2RG), which generates realistic garment images by integrating flat sketches and textual guidance. FS2RG presents two key challenges: 1) fabric characteristics are solely guided by textual prompts, providing insufficient visual supervision for diffusion-based models, which limits their ability to capture fine-grained fabric details; 2) flat sketches and textual guidance may provide conflicting information, requiring the model to selectively preserve or modify garment attributes while maintaining structural coherence. To tackle this task, we propose HiGarment, a novel framework that comprises two core components: i) a multi-modal semantic enhancement mechanism that enhances fabric representation across textual and visual modalities, and ii) a harmonized cross-attention mechanism that dynamically balances information from flat sketches and text prompts, allowing controllable synthesis by generating either sketch-aligned (image-biased) or text-guided (text-biased) outputs. Furthermore, we collect Multi-modal Detailed Garment, the largest open-source dataset for garment generation. Experimental results and user studies demonstrate the effectiveness of HiGarment in garment synthesis. The code and dataset are available at https://github.com/Maple498/HiGarment.",
    "source": "arXiv"
  },
  {
    "title": "Document Valuation in LLM Summaries: A Cluster Shapley Approach",
    "title_es": "Document Valuation in LLM Summaries: A Cluster Shapley Approach",
    "url": "https://arxiv.org/abs/2505.23842",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.23842v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are increasingly used in systems that retrieve and summarize content from multiple sources, such as search engines and AI assistants. While these models enhance user experience by generating coherent summaries, they obscure the contributions of original content creators, raising concerns about credit attribution and compensation. We address the challenge of valuing individual documents used in LLM-generated summaries. We propose using Shapley values, a game-theoretic method that allocates credit based on each document's marginal contribution. Although theoretically appealing, Shapley values are expensive to compute at scale. We therefore propose Cluster Shapley, an efficient approximation algorithm that leverages semantic similarity between documents. By clustering documents using LLM-based embeddings and computing Shapley values at the cluster level, our method significantly reduces computation while maintaining attribution quality. We demonstrate our approach to a summarization task using Amazon product reviews. Cluster Shapley significantly reduces computational complexity while maintaining high accuracy, outperforming baseline methods such as Monte Carlo sampling and Kernel SHAP with a better efficient frontier. Our approach is agnostic to the exact LLM used, the summarization process used, and the evaluation procedure, which makes it broadly applicable to a variety of summarization settings.",
    "source": "arXiv"
  },
  {
    "title": "CADRE: Customizable Assurance of Data Readiness in Privacy-Preserving Federated Learning",
    "title_es": "CADRE: Customizable Assurance of Data Readiness in Privacy-Preserving Federated Learning",
    "url": "https://arxiv.org/abs/2505.23849",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.23849v2 Announce Type: replace \nAbstract: Privacy-Preserving Federated Learning (PPFL) is a decentralized machine learning approach where multiple clients train a model collaboratively. PPFL preserves the privacy and security of a client's data without exchanging it. However, ensuring that data at each client is of high quality and ready for federated learning (FL) is a challenge due to restricted data access. In this paper, we introduce CADRE (Customizable Assurance of Data Readiness) for federated learning (FL), a novel framework that allows users to define custom data readiness (DR) metrics, rules, and remedies tailored to specific FL tasks. CADRE generates comprehensive DR reports based on the user-defined metrics, rules, and remedies to ensure datasets are prepared for FL while preserving privacy. We demonstrate a practical application of CADRE by integrating it into an existing PPFL framework. We conducted experiments across six datasets and addressed seven different DR issues. The results illustrate the versatility and effectiveness of CADRE in ensuring DR across various dimensions, including data quality, privacy, and fairness. This approach enhances the performance and reliability of FL models as well as utilizes valuable resources.",
    "source": "arXiv"
  },
  {
    "title": "MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection",
    "title_es": "MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection",
    "url": "https://arxiv.org/abs/2505.23870",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.23870v2 Announce Type: replace \nAbstract: We present a new adaptation method MaCP, Minimal yet Mighty adaptive Cosine Projection, that achieves exceptional performance while requiring minimal parameters and memory for fine-tuning large foundation models. Its general idea is to exploit the superior energy compaction and decorrelation properties of cosine projection to improve both model efficiency and accuracy. Specifically, it projects the weight change from the low-rank adaptation into the discrete cosine space. Then, the weight change is partitioned over different levels of the discrete cosine spectrum, and each partition's most critical frequency components are selected. Extensive experiments demonstrate the effectiveness of MaCP across a wide range of single-modality tasks, including natural language understanding, natural language generation, text summarization, as well as multi-modality tasks such as image classification and video understanding. MaCP consistently delivers superior accuracy, significantly reduced computational complexity, and lower memory requirements compared to existing alternatives.",
    "source": "arXiv"
  },
  {
    "title": "Interactive Imitation Learning for Dexterous Robotic Manipulation: Challenges and Perspectives -- A Survey",
    "title_es": "Interactive Imitation Learning for Dexterous Robotic Manipulation: Challenges and Perspectives -- A Survey",
    "url": "https://arxiv.org/abs/2506.00098",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.00098v2 Announce Type: replace \nAbstract: Dexterous manipulation is a crucial yet highly complex challenge in humanoid robotics, demanding precise, adaptable, and sample-efficient learning methods. As humanoid robots are usually designed to operate in human-centric environments and interact with everyday objects, mastering dexterous manipulation is critical for real-world deployment. Traditional approaches, such as reinforcement learning and imitation learning, have made significant strides, but they often struggle due to the unique challenges of real-world dexterous manipulation, including high-dimensional control, limited training data, and covariate shift. This survey provides a comprehensive overview of these challenges and reviews existing learning-based methods for real-world dexterous manipulation, spanning imitation learning, reinforcement learning, and hybrid approaches. A promising yet underexplored direction is interactive imitation learning, where human feedback actively refines a robots behavior during training. While interactive imitation learning has shown success in various robotic tasks, its application to dexterous manipulation remains limited. To address this gap, we examine current interactive imitation learning techniques applied to other robotic tasks and discuss how these methods can be adapted to enhance dexterous manipulation. By synthesizing state-of-the-art research, this paper highlights key challenges, identifies gaps in current methodologies, and outlines potential directions for leveraging interactive imitation learning to improve dexterous robotic skills.",
    "source": "arXiv"
  },
  {
    "title": "Verbal Werewolf: Engage Users with Verbalized Agentic Werewolf Game Framework",
    "title_es": "Verbal Werewolf: Engage Users with Verbalized Agentic Werewolf Game Framework",
    "url": "https://arxiv.org/abs/2506.00160",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.00160v2 Announce Type: replace \nAbstract: The growing popularity of social deduction games has created an increasing need for intelligent frameworks where humans can collaborate with AI agents, particularly in post-pandemic contexts with heightened psychological and social pressures. Social deduction games like Werewolf, traditionally played through verbal communication, present an ideal application for Large Language Models (LLMs) given their advanced reasoning and conversational capabilities. Prior studies have shown that LLMs can outperform humans in Werewolf games, but their reliance on external modules introduces latency that left their contribution in academic domain only, and omit such game should be user-facing. We propose \\textbf{Verbal Werewolf}, a novel LLM-based Werewolf game system that optimizes two parallel pipelines: gameplay powered by state-of-the-art LLMs and a fine-tuned Text-to-Speech (TTS) module that brings text output to life. Our system operates in near real-time without external decision-making modules, leveraging the enhanced reasoning capabilities of modern LLMs like DeepSeek V3 to create a more engaging and anthropomorphic gaming experience that significantly improves user engagement compared to existing text-only frameworks.",
    "source": "arXiv"
  },
  {
    "title": "PersianMedQA: Evaluating Large Language Models on a Persian-English Bilingual Medical Question Answering Benchmark",
    "title_es": "PersianMedQA: Evaluating Large Language Models on a Persian-English Bilingual Medical Question Answering Benchmark",
    "url": "https://arxiv.org/abs/2506.00250",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.00250v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) have achieved remarkable performance on a wide range of Natural Language Processing (NLP) benchmarks, often surpassing human-level accuracy. However, their reliability in high-stakes domains such as medicine, particularly in low-resource languages, remains underexplored. In this work, we introduce PersianMedQA, a large-scale dataset of 20,785 expert-validated multiple-choice Persian medical questions from 14 years of Iranian national medical exams, spanning 23 medical specialties and designed to evaluate LLMs in both Persian and English. We benchmark 40 state-of-the-art models, including general-purpose, Persian fine-tuned, and medical LLMs, in zero-shot and chain-of-thought (CoT) settings. Our results show that closed-source general models (e.g., GPT-4.1) consistently outperform all other categories, achieving 83.09% accuracy in Persian and 80.7% in English, while Persian fine-tuned models such as Dorna underperform significantly (e.g., 34.9% in Persian), often struggling with both instruction-following and domain reasoning. We also analyze the impact of translation, showing that while English performance is generally higher, 3-10% of questions can only be answered correctly in Persian due to cultural and clinical contextual cues that are lost in translation. Finally, we demonstrate that model size alone is insufficient for robust performance without strong domain or language adaptation. PersianMedQA provides a foundation for evaluating bilingual and culturally grounded medical reasoning in LLMs. The PersianMedQA dataset is available: https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA .",
    "source": "arXiv"
  },
  {
    "title": "Video Signature: In-generation Watermarking for Latent Video Diffusion Models",
    "title_es": "Video Signature: In-generation Watermarking for Latent Video Diffusion Models",
    "url": "https://arxiv.org/abs/2506.00652",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.00652v2 Announce Type: replace \nAbstract: The rapid development of Artificial Intelligence Generated Content (AIGC) has led to significant progress in video generation but also raises serious concerns about intellectual property protection and reliable content tracing. Watermarking is a widely adopted solution to this issue, but existing methods for video generation mainly follow a post-generation paradigm, which introduces additional computational overhead and often fails to effectively balance the trade-off between video quality and watermark extraction. To address these issues, we propose Video Signature (VIDSIG), an in-generation watermarking method for latent video diffusion models, which enables implicit and adaptive watermark integration during generation. Specifically, we achieve this by partially fine-tuning the latent decoder, where Perturbation-Aware Suppression (PAS) pre-identifies and freezes perceptually sensitive layers to preserve visual quality. Beyond spatial fidelity, we further enhance temporal consistency by introducing a lightweight Temporal Alignment module that guides the decoder to generate coherent frame sequences during fine-tuning. Experimental results show that VIDSIG achieves the best overall performance in watermark extraction, visual quality, and generation efficiency. It also demonstrates strong robustness against both spatial and temporal tampering, highlighting its practicality in real-world scenarios. Our code is available at \\href{https://github.com/hardenyu21/Video-Signature}{here}",
    "source": "arXiv"
  },
  {
    "title": "HERGC: Heterogeneous Experts Representation and Generative Completion for Multimodal Knowledge Graphs",
    "title_es": "HERGC: Heterogeneous Experts Representation and Generative Completion for Multimodal Knowledge Graphs",
    "url": "https://arxiv.org/abs/2506.00826",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.00826v2 Announce Type: replace \nAbstract: Multimodal knowledge graphs (MMKGs) enrich traditional knowledge graphs (KGs) by incorporating diverse modalities such as images and text. multimodal knowledge graph completion (MMKGC) seeks to exploit these heterogeneous signals to infer missing facts, thereby mitigating the intrinsic incompleteness of MMKGs. Existing MMKGC methods typically leverage only the information contained in the MMKGs under the closed-world assumption and adopt discriminative training objectives, which limits their reasoning capacity during completion. Recent large language models (LLMs), empowered by massive parameter scales and pretraining on vast corpora, have demonstrated strong reasoning abilities across various tasks. However, their potential in MMKGC remains largely unexplored. To bridge this gap, we propose HERGC, a flexible Heterogeneous Experts Representation and Generative Completion framework for MMKGs. HERGC first deploys a Heterogeneous Experts Representation Retriever that enriches and fuses multimodal information and retrieves a compact candidate set for each incomplete triple. It then uses a Generative LLM Predictor, implemented via either in-context learning or lightweight fine-tuning, to accurately identify the correct answer from these candidates. Extensive experiments on three standard MMKG benchmarks demonstrate HERGC's effectiveness and robustness, achieving superior performance over existing methods.",
    "source": "arXiv"
  },
  {
    "title": "ACCESS DENIED INC: The First Benchmark Environment for Sensitivity Awareness",
    "title_es": "ACCESS DENIED INC: The First Benchmark Environment for Sensitivity Awareness",
    "url": "https://arxiv.org/abs/2506.00964",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.00964v2 Announce Type: replace \nAbstract: Large language models (LLMs) are increasingly becoming valuable to corporate data management due to their ability to process text from various document formats and facilitate user interactions through natural language queries. However, LLMs must consider the sensitivity of information when communicating with employees, especially given access restrictions. Simple filtering based on user clearance levels can pose both performance and privacy challenges. To address this, we propose the concept of sensitivity awareness (SA), which enables LLMs to adhere to predefined access rights rules. In addition, we developed a benchmarking environment called ACCESS DENIED INC to evaluate SA. Our experimental findings reveal significant variations in model behavior, particularly in managing unauthorized data requests while effectively addressing legitimate queries. This work establishes a foundation for benchmarking sensitivity-aware language models and provides insights to enhance privacy-centric AI systems in corporate environments.",
    "source": "arXiv"
  },
  {
    "title": "SVarM: Linear Support Varifold Machines for Classification and Regression on Geometric Data",
    "title_es": "SVarM: Linear Support Varifold Machines for Classification and Regression on Geometric Data",
    "url": "https://arxiv.org/abs/2506.01189",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.01189v2 Announce Type: replace \nAbstract: Despite progress in the rapidly developing field of geometric deep learning, performing statistical analysis on geometric data--where each observation is a shape such as a curve, graph, or surface--remains challenging due to the non-Euclidean nature of shape spaces, which are defined as equivalence classes under invariance groups. Building machine learning frameworks that incorporate such invariances, notably to shape parametrization, is often crucial to ensure generalizability of the trained models to new observations. This work proposes \\textit{SVarM} to exploit varifold representations of shapes as measures and their duality with test functions $h:\\mathbb{R}^n \\times S^{n-1} \\rightarrow \\mathbb{R}$. This method provides a general framework akin to linear support vector machines but operating instead over the infinite-dimensional space of varifolds. We develop classification and regression models on shape datasets by introducing a neural network-based representation of the trainable test function $h$. This approach demonstrates strong performance and robustness across various shape graph and surface datasets, achieving results comparable to state-of-the-art methods while significantly reducing the number of trainable parameters.",
    "source": "arXiv"
  },
  {
    "title": "Iola Walker: A Mobile Footfall Detection System for Music Composition",
    "title_es": "Iola Walker: A Mobile Footfall Detection System for Music Composition",
    "url": "https://arxiv.org/abs/2506.01211",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.01211v3 Announce Type: replace \nAbstract: This outing is part of a larger music technology research project. The objective is to find a method for materially enhancing music using hardware and software. There is a strong likelihood that there exists a new medium for experiencing music via a wearable device that ordinary listeners prefer over the current state of the art. If such a medium is discovered, it is a step towards altruistic, prosocial reform in the music industry. A new playback system infrastructure has a chance to soothe some of the societal problems tied to the larger entertainment industry ecosystem. Iola walker is a music playback system that allows musicians to compose music that changes in accordance with the listener's gait. Artifacts are available here: https://github.com/willbjames/iolawalker",
    "source": "arXiv"
  },
  {
    "title": "Learning Perceptually Relevant Temporal Envelope Morphing",
    "title_es": "Learning Perceptually Relevant Temporal Envelope Morphing",
    "url": "https://arxiv.org/abs/2506.01588",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.01588v3 Announce Type: replace \nAbstract: Temporal envelope morphing, the process of interpolating between the amplitude dynamics of two audio signals, is an emerging problem in generative audio systems that lacks sufficient perceptual grounding. Morphing of temporal envelopes in a perceptually intuitive manner should enable new methods for sound blending in creative media and for probing perceptual organization in psychoacoustics. However, existing audio morphing techniques often fail to produce intermediate temporal envelopes when input sounds have distinct temporal structures; many morphers effectively overlay both temporal structures, leading to perceptually unnatural results. In this paper, we introduce a novel workflow for learning envelope morphing with perceptual guidance: we first derive perceptually grounded morphing principles through human listening studies, then synthesize large-scale datasets encoding these principles, and finally train machine learning models to create perceptually intermediate morphs. Specifically, we present: (1) perceptual principles that guide envelope morphing, derived from our listening studies, (2) a supervised framework to learn these principles, (3) an autoencoder that learns to compress temporal envelope structures into latent representations, and (4) benchmarks for evaluating audio envelope morphs, using both synthetic and naturalistic data, and show that our approach outperforms existing methods in producing temporally intermediate morphs. All code, models, and checkpoints are available at https://github.com/TemporalMorphing/EnvelopeMorphing.",
    "source": "arXiv"
  },
  {
    "title": "Zoom-Refine: Boosting High-Resolution Multimodal Understanding via Localized Zoom and Self-Refinement",
    "title_es": "Zoom-Refine: Boosting High-Resolution Multimodal Understanding via Localized Zoom and Self-Refinement",
    "url": "https://arxiv.org/abs/2506.01663",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.01663v2 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLM) often struggle to interpret high-resolution images accurately, where fine-grained details are crucial for complex visual understanding. We introduce Zoom-Refine, a novel training-free method that enhances MLLM capabilities to address this issue. Zoom-Refine operates through a synergistic process of \\textit{Localized Zoom} and \\textit{Self-Refinement}. In the \\textit{Localized Zoom} step, Zoom-Refine leverages the MLLM to provide a preliminary response to an input query and identifies the most task-relevant image region by predicting its bounding box coordinates. During the \\textit{Self-Refinement} step, Zoom-Refine then integrates fine-grained details from the high-resolution crop (identified by \\textit{Localized Zoom}) with its initial reasoning to re-evaluate and refine its preliminary response. Our method harnesses the MLLM's inherent capabilities for spatial localization, contextual reasoning and comparative analysis without requiring additional training or external experts. Comprehensive experiments demonstrate the efficacy of Zoom-Refine on two challenging high-resolution multimodal benchmarks. Code is available at \\href{https://github.com/xavier-yu114/Zoom-Refine}{\\color{magenta}github.com/xavier-yu114/Zoom-Refine}",
    "source": "arXiv"
  },
  {
    "title": "How Far Are We from Generating Missing Modalities with Foundation Models?",
    "title_es": "How Far Are We from Generating Missing Modalities with Foundation Models?",
    "url": "https://arxiv.org/abs/2506.03530",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.03530v2 Announce Type: replace \nAbstract: Multimodal foundation models have demonstrated impressive capabilities across diverse tasks. However, their potential as plug-and-play solutions for missing modality reconstruction remains underexplored. To bridge this gap, we identify and formalize three potential paradigms for missing modality reconstruction, and perform a comprehensive evaluation across these paradigms, covering 42 model variants in terms of reconstruction accuracy and adaptability to downstream tasks. Our analysis reveals that current foundation models often fall short in two critical aspects: (i) fine-grained semantic extraction from the available modalities, and (ii) robust validation of generated modalities. These limitations lead to suboptimal and, at times, misaligned generations. To address these challenges, we propose an agentic framework tailored for missing modality reconstruction. This framework dynamically formulates modality-aware mining strategies based on the input context, facilitating the extraction of richer and more discriminative semantic features. In addition, we introduce a self-refinement mechanism, which iteratively verifies and enhances the quality of generated modalities through internal feedback. Experimental results show that our method reduces FID for missing image reconstruction by at least 14\\% and MER for missing text reconstruction by at least 10\\% compared to baselines. Code are released at: https://github.com/Guanzhou-Ke/AFM2.",
    "source": "arXiv"
  },
  {
    "title": "Scaling Transformers for Discriminative Recommendation via Generative Pretraining",
    "title_es": "Scaling Transformers for Discriminative Recommendation via Generative Pretraining",
    "url": "https://arxiv.org/abs/2506.03699",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.03699v2 Announce Type: replace \nAbstract: Discriminative recommendation tasks, such as CTR (click-through rate) and CVR (conversion rate) prediction, play critical roles in the ranking stage of large-scale industrial recommender systems. However, training a discriminative model encounters a significant overfitting issue induced by data sparsity. Moreover, this overfitting issue worsens with larger models, causing them to underperform smaller ones. To address the overfitting issue and enhance model scalability, we propose a framework named GPSD (\\textbf{G}enerative \\textbf{P}retraining for \\textbf{S}calable \\textbf{D}iscriminative Recommendation), drawing inspiration from generative training, which exhibits no evident signs of overfitting. GPSD leverages the parameters learned from a pretrained generative model to initialize a discriminative model, and subsequently applies a sparse parameter freezing strategy. Extensive experiments conducted on both industrial-scale and publicly available datasets demonstrate the superior performance of GPSD. Moreover, it delivers remarkable improvements in online A/B tests. GPSD offers two primary advantages: 1) it substantially narrows the generalization gap in model training, resulting in better test performance; and 2) it leverages the scalability of Transformers, delivering consistent performance gains as models are scaled up. Specifically, we observe consistent performance improvements as the model dense parameters scale from 13K to 0.3B, closely adhering to power laws. These findings pave the way for unifying the architectures of recommendation models and language models, enabling the direct application of techniques well-established in large language models to recommendation models. The code is available at https://github.com/chqiwang/gpsd-rec.",
    "source": "arXiv"
  },
  {
    "title": "Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification",
    "title_es": "Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification",
    "url": "https://arxiv.org/abs/2506.04450",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.04450v3 Announce Type: replace \nAbstract: Purpose: This study proposes a framework for fine-tuning large language models (LLMs) with differential privacy (DP) to perform multi-abnormality classification on radiology report text. By injecting calibrated noise during fine-tuning, the framework seeks to mitigate the privacy risks associated with sensitive patient data and protect against data leakage while maintaining classification performance. Materials and Methods: We used 50,232 radiology reports from the publicly available MIMIC-CXR chest radiography and CT-RATE computed tomography datasets, collected between 2011 and 2019. Fine-tuning of LLMs was conducted to classify 14 labels from MIMIC-CXR dataset, and 18 labels from CT-RATE dataset using Differentially Private Low-Rank Adaptation (DP-LoRA) in high and moderate privacy regimes (across a range of privacy budgets = {0.01, 0.1, 1.0, 10.0}). Model performance was evaluated using weighted F1 score across three model architectures: BERT-medium, BERT-small, and ALBERT-base. Statistical analyses compared model performance across different privacy levels to quantify the privacy-utility trade-off. Results: We observe a clear privacy-utility trade-off through our experiments on 2 different datasets and 3 different models. Under moderate privacy guarantees the DP fine-tuned models achieved comparable weighted F1 scores of 0.88 on MIMIC-CXR and 0.59 on CT-RATE, compared to non-private LoRA baselines of 0.90 and 0.78, respectively. Conclusion: Differentially private fine-tuning using LoRA enables effective and privacy-preserving multi-abnormality classification from radiology reports, addressing a key challenge in fine-tuning LLMs on sensitive medical data.",
    "source": "arXiv"
  },
  {
    "title": "Tech-ASan: Two-stage check for Address Sanitizer",
    "title_es": "Tech-ASan: Two-stage check for Address Sanitizer",
    "url": "https://arxiv.org/abs/2506.05022",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.05022v3 Announce Type: replace \nAbstract: Address Sanitizer (ASan) is a sharp weapon for detecting memory safety violations, including temporal and spatial errors hidden in C/C++ programs during execution. However, ASan incurs significant runtime overhead, which limits its efficiency in testing large software. The overhead mainly comes from sanitizer checks due to the frequent and expensive shadow memory access. Over the past decade, many methods have been developed to speed up ASan by eliminating and accelerating sanitizer checks, however, they either fail to adequately eliminate redundant checks or compromise detection capabilities. To address this issue, this paper presents Tech-ASan, a two-stage check based technique to accelerate ASan with safety assurance. First, we propose a novel two-stage check algorithm for ASan, which leverages magic value comparison to reduce most of the costly shadow memory accesses. Second, we design an efficient optimizer to eliminate redundant checks, which integrates a novel algorithm for removing checks in loops. Third, we implement Tech-ASan as a memory safety tool based on the LLVM compiler infrastructure. Our evaluation using the SPEC CPU2006 benchmark shows that Tech-ASan outperforms the state-of-the-art methods with 33.70% and 17.89% less runtime overhead than ASan and ASan--, respectively. Moreover, Tech-ASan detects 56 fewer false negative cases than ASan and ASan-- when testing on the Juliet Test Suite under the same redzone setting.",
    "source": "arXiv"
  },
  {
    "title": "Leaps Beyond the Seen: Reinforced Reasoning Augmented Generation for Clinical Notes",
    "title_es": "Leaps Beyond the Seen: Reinforced Reasoning Augmented Generation for Clinical Notes",
    "url": "https://arxiv.org/abs/2506.05386",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.05386v3 Announce Type: replace \nAbstract: Clinical note generation aims to produce free-text summaries of a patient's condition and diagnostic process, with discharge instructions being a representative long-form example. While recent LLM-based methods pre-trained on general clinical corpora show promise in clinical text generation, they fall short in producing long-form notes from limited patient information. In this paper, we propose ReinRAG, a reinforced reasoning augmented generation (RAG) for long-form discharge instructions based on pre-admission information. ReinRAG retrieves reasoning paths from a medical knowledge graph to provide explicit semantic guidance to the LLM. To bridge the information gap, we propose group-based retriever optimization (GRO) which improves retrieval quality with group-normalized rewards, encouraging reasoning leaps for deeper inference by the LLM. Comprehensive experiments on the real-world dataset show that ReinRAG outperforms baselines in both clinical efficacy and natural language generation metrics. Further analysis reveals that ReinRAG fills semantic gaps in sparse input scenarios, and retrieved reasoning paths help LLMs avoid clinical misinterpretation by focusing on key evidence and following coherent reasoning.",
    "source": "arXiv"
  },
  {
    "title": "Winner-takes-all for Multivariate Probabilistic Time Series Forecasting",
    "title_es": "Winner-takes-all for Multivariate Probabilistic Time Series Forecasting",
    "url": "https://arxiv.org/abs/2506.05515",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.05515v2 Announce Type: replace \nAbstract: We introduce TimeMCL, a method leveraging the Multiple Choice Learning (MCL) paradigm to forecast multiple plausible time series futures. Our approach employs a neural network with multiple heads and utilizes the Winner-Takes-All (WTA) loss to promote diversity among predictions. MCL has recently gained attention due to its simplicity and ability to address ill-posed and ambiguous tasks. We propose an adaptation of this framework for time-series forecasting, presenting it as an efficient method to predict diverse futures, which we relate to its implicit quantization objective. We provide insights into our approach using synthetic data and evaluate it on real-world time series, demonstrating its promising performance at a light computational cost.",
    "source": "arXiv"
  },
  {
    "title": "MLOps with Microservices: A Case Study on the Maritime Domain",
    "title_es": "MLOps with Microservices: A Case Study on the Maritime Domain",
    "url": "https://arxiv.org/abs/2506.06202",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.06202v2 Announce Type: replace \nAbstract: This case study describes challenges and lessons learned on building Ocean Guard: a Machine Learning-Enabled System (MLES) for anomaly detection in the maritime domain. First, the paper presents the system's specification, and architecture. Ocean Guard was designed with a microservices' architecture to enable multiple teams to work on the project in parallel. Then, the paper discusses how the developers adapted contract-based design to MLOps for achieving that goal. As a MLES, Ocean Guard employs code, model, and data contracts to establish guidelines between its services. This case study hopes to inspire software engineers, machine learning engineers, and data scientists to leverage similar approaches for their systems.",
    "source": "arXiv"
  },
  {
    "title": "AI-Generated Compromises for Coalition Formation",
    "title_es": "AI-Generated Compromises for Coalition Formation",
    "url": "https://arxiv.org/abs/2506.06837",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.06837v3 Announce Type: replace \nAbstract: The challenge of finding compromises between agent proposals is fundamental to AI subfields such as argumentation, mediation, and negotiation. Building on this tradition, Elkind et al. (2021) introduced a process for coalition formation that seeks majority-supported proposals preferable to the status quo, using a metric space where each agent has an ideal point. A crucial step in this process involves identifying compromise proposals around which agent coalitions can unite. How to effectively find such compromise proposals remains an open question. We address this gap by formalizing a model that incorporates agent bounded rationality and uncertainty, and by developing AI methods to generate compromise proposals. We focus on the domain of collaborative document writing, such as the democratic drafting of a community constitution. Our approach uses natural language processing techniques and large language models to induce a semantic metric space over text. Based on this space, we design algorithms to suggest compromise points likely to receive broad support. To evaluate our methods, we simulate coalition formation processes and show that AI can facilitate large-scale democratic text editing, a domain where traditional tools are limited.",
    "source": "arXiv"
  },
  {
    "title": "Original-energy-dissipation-preserving methods for the incompressible Navier-Stokes equations",
    "title_es": "Original-energy-dissipation-preserving methods for the incompressible Navier-Stokes equations",
    "url": "https://arxiv.org/abs/2506.07141",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.07141v2 Announce Type: replace \nAbstract: This paper introduces a robust reformulation of the incompressible Navier-Stokes equations, establishing a foundational framework for designing efficient, structure-preserving algorithms that strictly conserve the original energy dissipation law. By leveraging Crank-Nicolson schemes and backward differentiation formulas, we develop four first- and second-order time-discrete schemes. These schemes exactly preserve the original energy dissipation law at each time step, requiring only the solutions of three linear Stokes systems and one $2\\times 2$ system of linear equations. Furthermore, the finite difference approximation on a staggered grid is employed for these time-discrete systems to derive fully discrete structure-preserving schemes. We rigorously prove that all proposed fully discrete methods both maintain the original energy dissipation law and admit unique solutions. Moreover, we present their efficient implementation. Extensive numerical experiments are carried out to verify the accuracy, efficacy, and advantageous performance of our newly developed methods.",
    "source": "arXiv"
  },
  {
    "title": "Structure-Augmented Reasoning Generation",
    "title_es": "Structure-Augmented Reasoning Generation",
    "url": "https://arxiv.org/abs/2506.08364",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.08364v3 Announce Type: replace \nAbstract: Retrieval-Augmented Generation (RAG) systems fail at complex multi-hop reasoning because they rely on large language models to implicitly connect information from unstructured document collections. This fundamental limitation stems from treating retrieved passages as independent context rather than recognizing the intricate relationships that enable coherent reasoning chains.\n  We introduce SARG (Structure-Augmented Reasoning Generation), a post-retrieval framework that transforms traditional RAG pipelines by materializing explicit reasoning structures. SARG extracts {cause, relation, effect} triples from retrieved documents, constructs domain-adaptive graphs, and performs multi-hop traversal to discover reasoning chains that bridge query concepts to answers. Unlike existing approaches that modify retrieval mechanisms, SARG operates as a plug-and-play reasoning layer compatible with any RAG system.\n  Extensive evaluation across diverse domains: general QA, biomedical literature, and financial analysis demonstrates that SARG achieves substantial improvements over state-of-the-art RAG baselines. Crucially, SARG also provides full reasoning traceability through explicit inference chains, addressing the critical interpretability gap in current RAG systems.\n  Our results establish that explicit structural reasoning is not merely beneficial but essential for reliable complex question answering, offering a solution to RAG's implicit reasoning bottleneck.",
    "source": "arXiv"
  },
  {
    "title": "Support bound for differential elimination in polynomial dynamical systems",
    "title_es": "Support bound for differential elimination in polynomial dynamical systems",
    "url": "https://arxiv.org/abs/2506.08824",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.08824v2 Announce Type: replace \nAbstract: We study an important special case of the differential elimination problem: given a polynomial parametric dynamical system $\\mathbf{x}' = \\mathbf{g}(\\boldsymbol{\\mu}, \\mathbf{x})$ and a polynomial observation function $y = f(\\boldsymbol{\\mu}, \\mathbf{x})$, find the minimal differential equation satisfied by $y$. In our previous work, for the case $y = x_1$, we established a bound on the support of such a differential equation for the non-parametric case and shown that it can be turned into an algorithm via the evaluation-interpolation approach. The main contribution of the present paper is a generalization of the aforementioned result in two directions: to allow any polynomial function $y = f(\\mathbf{x})$, not just a single coordinate, and to allow $\\mathbf{g}$ and $f$ depend on unknown symbolic parameters. We conduct computation experiments to evaluate the accuracy of our new bound and show that the approach allows to perform elimination for some cases out of reach for the state of the art software.",
    "source": "arXiv"
  },
  {
    "title": "Show Me Your Best Side: Characteristics of User-Preferred Perspectives for 3D Graph Drawings",
    "title_es": "Show Me Your Best Side: Characteristics of User-Preferred Perspectives for 3D Graph Drawings",
    "url": "https://arxiv.org/abs/2506.09212",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.09212v2 Announce Type: replace \nAbstract: The visual analysis of graphs in 3D has become increasingly popular, accelerated by the rise of immersive technology, such as augmented and virtual reality. Unlike 2D drawings, 3D graph layouts are highly viewpoint-dependent, making perspective selection critical for revealing structural and relational patterns. Despite its importance, there is limited empirical evidence guiding what constitutes an effective or preferred viewpoint from the user's perspective. In this paper, we present a systematic investigation into user-preferred viewpoints in 3D graph visualisations. We conducted a controlled study with 23 participants in a virtual reality environment, where users selected their most and least preferred viewpoints for 36 different graphs varying in size and layout. From this data, enriched by qualitative feedback, we distil common strategies underlying viewpoint choice. We further analyse the alignment of user preferences with classical 2D aesthetic criteria (e.g., Crossings), 3D-specific measures (e.g., Node-Node Occlusion), and introduce a novel measure capturing the perceivability of a graph's principal axes (Isometric Viewpoint Deviation). Our data-driven analysis indicates that Stress, Crossings, Gabriel Ratio, Edge-Node Overlap, and Isometric Viewpoint Deviation are key indicators of viewpoint preference. Beyond our findings, we contribute a publicly available dataset consisting of the graphs and computed aesthetic measures, supporting further research and the development of viewpoint evaluation measures for 3D graph drawing.",
    "source": "arXiv"
  },
  {
    "title": "Wasserstein Barycenter Soft Actor-Critic",
    "title_es": "Wasserstein Barycenter Soft Actor-Critic",
    "url": "https://arxiv.org/abs/2506.10167",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.10167v3 Announce Type: replace \nAbstract: Deep off-policy actor-critic algorithms have emerged as the leading framework for reinforcement learning in continuous control domains. However, most of these algorithms suffer from poor sample efficiency, especially in environments with sparse rewards. In this paper, we take a step towards addressing this issue by providing a principled directed exploration strategy. We propose Wasserstein Barycenter Soft Actor-Critic (WBSAC) algorithm, which benefits from a pessimistic actor for temporal difference learning and an optimistic actor to promote exploration. This is achieved by using the Wasserstein barycenter of the pessimistic and optimistic policies as the exploration policy and adjusting the degree of exploration throughout the learning process. We compare WBSAC with state-of-the-art off-policy actor-critic algorithms and show that WBSAC is more sample-efficient on MuJoCo continuous control tasks.",
    "source": "arXiv"
  },
  {
    "title": "DanceChat: Large Language Model-Guided Music-to-Dance Generation",
    "title_es": "DanceChat: Large Language Model-Guided Music-to-Dance Generation",
    "url": "https://arxiv.org/abs/2506.10574",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.10574v2 Announce Type: replace \nAbstract: Music-to-dance generation aims to synthesize human dance motion conditioned on musical input. Despite recent progress, significant challenges remain due to the semantic gap between music and dance motion, as music offers only abstract cues, such as melody, groove, and emotion, without explicitly specifying the physical movements. Moreover, a single piece of music can produce multiple plausible dance interpretations. This one-to-many mapping demands additional guidance, as music alone provides limited information for generating diverse dance movements. The challenge is further amplified by the scarcity of paired music and dance data, which restricts the model\\^a\\u{A}\\'Zs ability to learn diverse dance patterns. In this paper, we introduce DanceChat, a Large Language Model (LLM)-guided music-to-dance generation approach. We use an LLM as a choreographer that provides textual motion instructions, offering explicit, high-level guidance for dance generation. This approach goes beyond implicit learning from music alone, enabling the model to generate dance that is both more diverse and better aligned with musical styles. Our approach consists of three components: (1) an LLM-based pseudo instruction generation module that produces textual dance guidance based on music style and structure, (2) a multi-modal feature extraction and fusion module that integrates music, rhythm, and textual guidance into a shared representation, and (3) a diffusion-based motion synthesis module together with a multi-modal alignment loss, which ensures that the generated dance is aligned with both musical and textual cues. Extensive experiments on AIST++ and human evaluations show that DanceChat outperforms state-of-the-art methods both qualitatively and quantitatively.",
    "source": "arXiv"
  },
  {
    "title": "Simple Radiology VLLM Test-time Scaling with Thought Graph Traversal",
    "title_es": "Simple Radiology VLLM Test-time Scaling with Thought Graph Traversal",
    "url": "https://arxiv.org/abs/2506.11989",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.11989v2 Announce Type: replace \nAbstract: Test-time scaling offers a promising way to improve the reasoning performance of vision-language large models (VLLMs) without additional training. In this paper, we explore a simple but effective approach for applying test-time scaling to radiology report generation. Specifically, we introduce a lightweight Thought Graph Traversal (TGT) framework that guides the model to reason through organ-specific findings in a medically coherent order. This framework integrates structured medical priors into the prompt, enabling deeper and more logical analysis with no changes to the underlying model. To further enhance reasoning depth, we apply a reasoning budget forcing strategy that adjusts the model's inference depth at test time by dynamically extending its generation process. This simple yet powerful combination allows a frozen radiology VLLM to self-correct and generate more accurate, consistent chest X-ray reports. Our method outperforms baseline prompting approaches on standard benchmarks, and also reveals dataset biases through traceable reasoning paths. Code and prompts are open-sourced for reproducibility at https://github.com/glerium/Thought-Graph-Traversal.",
    "source": "arXiv"
  },
  {
    "title": "Inference-Time Gaze Refinement for Micro-Expression Recognition: Enhancing Event-Based Eye Tracking with Motion-Aware Post-Processing",
    "title_es": "Inference-Time Gaze Refinement for Micro-Expression Recognition: Enhancing Event-Based Eye Tracking with Motion-Aware Post-Processing",
    "url": "https://arxiv.org/abs/2506.12524",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.12524v3 Announce Type: replace \nAbstract: Event-based eye tracking holds significant promise for fine-grained cognitive state inference, offering high temporal resolution and robustness to motion artifacts, critical features for decoding subtle mental states such as attention, confusion, or fatigue. In this work, we introduce a model-agnostic, inference-time refinement framework designed to enhance the output of existing event-based gaze estimation models without modifying their architecture or requiring retraining. Our method comprises two key post-processing modules: (i) Motion-Aware Median Filtering, which suppresses blink-induced spikes while preserving natural gaze dynamics, and (ii) Optical Flow-Based Local Refinement, which aligns gaze predictions with cumulative event motion to reduce spatial jitter and temporal discontinuities. To complement traditional spatial accuracy metrics, we propose a novel Jitter Metric that captures the temporal smoothness of predicted gaze trajectories based on velocity regularity and local signal complexity. Together, these contributions significantly improve the consistency of event-based gaze signals, making them better suited for downstream tasks such as micro-expression analysis and mind-state decoding. Our results demonstrate consistent improvements across multiple baseline models on controlled datasets, laying the groundwork for future integration with multimodal affect recognition systems in real-world environments. Our code implementations can be found at https://github.com/eye-tracking-for-physiological-sensing/EyeLoRiN.",
    "source": "arXiv"
  },
  {
    "title": "Position: Certified Robustness Does Not (Yet) Imply Model Security",
    "title_es": "Position: Certified Robustness Does Not (Yet) Imply Model Security",
    "url": "https://arxiv.org/abs/2506.13024",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.13024v2 Announce Type: replace \nAbstract: While certified robustness is widely promoted as a solution to adversarial examples in Artificial Intelligence systems, significant challenges remain before these techniques can be meaningfully deployed in real-world applications. We identify critical gaps in current research, including the paradox of detection without distinction, the lack of clear criteria for practitioners to evaluate certification schemes, and the potential security risks arising from users' expectations surrounding ``guaranteed\" robustness claims. These create an alignment issue between how certifications are presented and perceived, relative to their actual capabilities. This position paper is a call to arms for the certification research community, proposing concrete steps to address these fundamental challenges and advance the field toward practical applicability.",
    "source": "arXiv"
  },
  {
    "title": "DAGR: Decomposition Augmented Graph Retrieval with LLMs",
    "title_es": "DAGR: Decomposition Augmented Graph Retrieval with LLMs",
    "url": "https://arxiv.org/abs/2506.13380",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.13380v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) excel at many Natural Language Processing (NLP) tasks, but struggle with multi-hop reasoning and factual consistency, limiting their effectiveness on knowledge-intensive tasks like complex question answering (QA). Linking Knowledge Graphs (KG) and LLMs has shown promising results, but LLMs generally lack the ability to reason efficiently over graph-structured information. To address this challenge, we introduce DAGR, a retrieval method that leverages both complex questions and their decomposition in subquestions to extract relevant, linked textual subgraphs. DAGR first breaks down complex queries, retrieves subgraphs guided by a weighted similarity function over both the original and decomposed queries, and creates a question-specific knowledge graph to guide answer generation. The resulting Graph-RAG pipeline is suited to handle complex multi-hop questions and effectively reason over graph-structured data. We evaluate DAGR on standard multi-hop QA benchmarks and show that it achieves comparable or superior performance to competitive existing methods, using smaller models and fewer LLM calls.",
    "source": "arXiv"
  },
  {
    "title": "Personalized Constitutionally-Aligned Agentic Superego: Secure AI Behavior Aligned to Diverse Human Values",
    "title_es": "Personalized Constitutionally-Aligned Agentic Superego: Secure AI Behavior Aligned to Diverse Human Values",
    "url": "https://arxiv.org/abs/2506.13774",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.13774v2 Announce Type: replace \nAbstract: Agentic AI systems, possessing capabilities for autonomous planning and action, show great potential across diverse domains. However, their practical deployment is hindered by challenges in aligning their behavior with varied human values, complex safety requirements, and specific compliance needs. Existing alignment methodologies often falter when faced with the complex task of providing personalized context without inducing confabulation or operational inefficiencies. This paper introduces a novel solution: a 'superego' agent, designed as a personalized oversight mechanism for agentic AI. This system dynamically steers AI planning by referencing user-selected 'Creed Constitutions' encapsulating diverse rule sets -- with adjustable adherence levels to fit non-negotiable values. A real-time compliance enforcer validates plans against these constitutions and a universal ethical floor before execution. We present a functional system, including a demonstration interface with a prototypical constitution-sharing portal, and successful integration with third-party models via the Model Context Protocol (MCP). Comprehensive benchmark evaluations (HarmBench, AgentHarm) demonstrate that our Superego agent dramatically reduces harmful outputs -- achieving up to a 98.3% harm score reduction and near-perfect refusal rates (e.g., 100% with Claude Sonnet 4 on AgentHarm's harmful set) for leading LLMs like Gemini 2.5 Flash and GPT-4o. This approach substantially simplifies personalized AI alignment, rendering agentic systems more reliably attuned to individual and cultural contexts, while also enabling substantial safety improvements. An overview on this research with examples is available at https://superego.creed.space.",
    "source": "arXiv"
  },
  {
    "title": "From Permissioned to Proof-of-Stake Consensus",
    "title_es": "From Permissioned to Proof-of-Stake Consensus",
    "url": "https://arxiv.org/abs/2506.14124",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.14124v2 Announce Type: replace \nAbstract: This paper presents the first generic compiler that transforms any permissioned consensus protocol into a proof-of-stake permissionless consensus protocol. For each of the following properties, if the initial permissioned protocol satisfies that property in the partially synchronous setting, the consequent proof-of-stake protocol also satisfies that property in the partially synchronous and quasi-permissionless setting (with the same fault-tolerance): consistency; liveness; optimistic responsiveness; every composable log-specific property; and message complexity of a given order. Moreover, our transformation ensures that the output protocol satisfies accountability (identifying culprits in the event of a consistency violation), whether or not the original permissioned protocol satisfied it.",
    "source": "arXiv"
  },
  {
    "title": "3DGS-IEval-15K: A Large-scale Image Quality Evaluation Database for 3D Gaussian-Splatting",
    "title_es": "3DGS-IEval-15K: A Large-scale Image Quality Evaluation Database for 3D Gaussian-Splatting",
    "url": "https://arxiv.org/abs/2506.14642",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.14642v2 Announce Type: replace \nAbstract: 3D Gaussian Splatting (3DGS) has emerged as a promising approach for novel view synthesis, offering real-time rendering with high visual fidelity. However, its substantial storage requirements present significant challenges for practical applications. While recent state-of-the-art (SOTA) 3DGS methods increasingly incorporate dedicated compression modules, there is a lack of a comprehensive framework to evaluate their perceptual impact. Therefore we present 3DGS-IEval-15K, the first large-scale image quality assessment (IQA) dataset specifically designed for compressed 3DGS representations. Our dataset encompasses 15,200 images rendered from 10 real-world scenes through 6 representative 3DGS algorithms at 20 strategically selected viewpoints, with different compression levels leading to various distortion effects. Through controlled subjective experiments, we collect human perception data from 60 viewers. We validate dataset quality through scene diversity and MOS distribution analysis, and establish a comprehensive benchmark with 30 representative IQA metrics covering diverse types. As the largest-scale 3DGS quality assessment dataset to date, our work provides a foundation for developing 3DGS specialized IQA metrics, and offers essential data for investigating view-dependent quality distribution patterns unique to 3DGS. The database is publicly available at https://github.com/YukeXing/3DGS-IEval-15K.",
    "source": "arXiv"
  },
  {
    "title": "CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal Diffusion",
    "title_es": "CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal Diffusion",
    "url": "https://arxiv.org/abs/2506.14769",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.14769v2 Announce Type: replace \nAbstract: Diffusion Policy (DP) enables robots to learn complex behaviors by imitating expert demonstrations through action diffusion. However, in practical applications, hardware limitations often degrade data quality, while real-time constraints restrict model inference to instantaneous state and scene observations. These limitations seriously reduce the efficacy of learning from expert demonstrations, resulting in failures in object localization, grasp planning, and long-horizon task execution. To address these challenges, we propose Causal Diffusion Policy (CDP), a novel transformer-based diffusion model that enhances action prediction by conditioning on historical action sequences, thereby enabling more coherent and context-aware visuomotor policy learning. To further mitigate the computational cost associated with autoregressive inference, a caching mechanism is also introduced to store attention key-value pairs from previous timesteps, substantially reducing redundant computations during execution. Extensive experiments in both simulated and real-world environments, spanning diverse 2D and 3D manipulation tasks, demonstrate that CDP uniquely leverages historical action sequences to achieve significantly higher accuracy than existing methods. Moreover, even when faced with degraded input observation quality, CDP maintains remarkable precision by reasoning through temporal continuity, which highlights its practical robustness for robotic control under realistic, imperfect conditions.",
    "source": "arXiv"
  },
  {
    "title": "Reinforcement Learning for Hybrid Charging Stations Planning and Operation Considering Fixed and Mobile Chargers",
    "title_es": "Reinforcement Learning for Hybrid Charging Stations Planning and Operation Considering Fixed and Mobile Chargers",
    "url": "https://arxiv.org/abs/2506.16764",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.16764v2 Announce Type: replace \nAbstract: The success of vehicle electrification relies on efficient and adaptable charging infrastructure. Fixed-location charging stations often suffer from underutilization or congestion due to fluctuating demand, while mobile chargers offer flexibility by relocating as needed. This paper studies the optimal planning and operation of hybrid charging infrastructures that combine both fixed and mobile chargers within urban road networks. We formulate the Hybrid Charging Station Planning and Operation (HCSPO) problem, jointly optimizing the placement of fixed stations and the scheduling of mobile chargers. A charging demand prediction model based on Model Predictive Control (MPC) supports dynamic decision-making. To solve the HCSPO problem, we propose a deep reinforcement learning approach enhanced with heuristic scheduling. Experiments on real-world urban scenarios show that our method improves infrastructure availability - achieving up to 244.4% increase in coverage - and reduces user inconvenience with up to 79.8% shorter waiting times, compared to existing solutions.",
    "source": "arXiv"
  },
  {
    "title": "Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes",
    "title_es": "Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes",
    "url": "https://arxiv.org/abs/2506.16805",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.16805v3 Announce Type: replace \nAbstract: Humans exhibit a remarkable ability to recognize co-visibility-the 3D regions simultaneously visible in multiple images-even when these images are sparsely distributed across a complex scene. This ability is foundational to 3D vision, robotic perception, and relies not only on low-level feature matching but also on high-level spatial reasoning and cognitive integration. Yet, it remains unclear whether current vision models can replicate this human-level proficiency. In this work, we introduce the Co-VisiON benchmark, designed to evaluate human-inspired co-visibility reasoning across more than 1,000 sparse-view indoor scenarios. Our results show that while co-visibility is often approached as a low-level feature-matching task, it remains challenging for existing vision models under sparse conditions. Notably, a proprietary vision-language model surpasses all vision-only baselines, but all models fall significantly short of human performance. This gap underscores the limitations of current architectures and motivates the need for models that integrate spatial and semantic information in a human-like manner. Inspired by human visual cognition, we propose a novel multi-view baseline, Covis, which achieves top performance among pure vision models and narrows the gap to the proprietary VLM. We hope our benchmark and findings will spur further advancements in developing vision models capable of robust, cognitively inspired reasoning in challenging, sparse environments. Our dataset and source code can be found at https://ai4ce.github.io/CoVISION.",
    "source": "arXiv"
  },
  {
    "title": "PersonalAI: A Systematic Comparison of Knowledge Graph Storage and Retrieval Approaches for Personalized LLM agents",
    "title_es": "PersonalAI: A Systematic Comparison of Knowledge Graph Storage and Retrieval Approaches for Personalized LLM agents",
    "url": "https://arxiv.org/abs/2506.17001",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.17001v2 Announce Type: replace \nAbstract: Personalizing language models by effectively incorporating user interaction history remains a central challenge in the development of adaptive AI systems. While large language models (LLMs) combined with Retrieval-Augmented Generation (RAG) have improved factual accuracy, they often lack structured memory and fail to scale in complex, long-term interactions. To address this, we propose a flexible external memory framework based on knowledge graphs, automatically constructed and updated by the LLM itself, and capable of encoding information in multiple formats-including nodes, triplets, higher-order propositions, and episodic traces. Building upon the AriGraph architecture, we introduce a novel hybrid graph design that supports both standard edges and two types of hyperedges, enabling rich and dynamic semantic and temporal representations. Our framework also supports diverse retrieval mechanisms, including A*, water-circle propagation, beam search, and hybrid methods, making it adaptable to different datasets and LLM capacities. We evaluate our system on three benchmarks-TriviaQA, HotpotQA, and DiaASQ-demonstrating that different memory and retrieval configurations yield optimal performance depending on the task. Additionally, we extend the DiaASQ benchmark with temporal annotations and internally contradictory statements, showing that our system remains robust and effective in managing temporal dependencies and context-aware reasoning.",
    "source": "arXiv"
  },
  {
    "title": "MMET: A Multi-Input and Multi-Scale Transformer for Efficient PDEs Solving",
    "title_es": "MMET: A Multi-Input and Multi-Scale Transformer for Efficient PDEs Solving",
    "url": "https://arxiv.org/abs/2506.17230",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.17230v2 Announce Type: replace \nAbstract: Partial Differential Equations (PDEs) are fundamental for modeling physical systems, yet solving them in a generic and efficient manner using machine learning-based approaches remains challenging due to limited multi-input and multi-scale generalization capabilities, as well as high computational costs. This paper proposes the Multi-input and Multi-scale Efficient Transformer (MMET), a novel framework designed to address the above challenges. MMET decouples mesh and query points as two sequences and feeds them into the encoder and decoder, respectively, and uses a Gated Condition Embedding (GCE) layer to embed input variables or functions with varying dimensions, enabling effective solutions for multi-scale and multi-input problems. Additionally, a Hilbert curve-based reserialization and patch embedding mechanism decrease the input length. This significantly reduces the computational cost when dealing with large-scale geometric models. These innovations enable efficient representations and support multi-scale resolution queries for large-scale and multi-input PDE problems. Experimental evaluations on diverse benchmarks spanning different physical fields demonstrate that MMET outperforms SOTA methods in both accuracy and computational efficiency. This work highlights the potential of MMET as a robust and scalable solution for real-time PDE solving in engineering and physics-based applications, paving the way for future explorations into pre-trained large-scale models in specific domains. This work is open-sourced at https://github.com/YichenLuo-0/MMET.",
    "source": "arXiv"
  },
  {
    "title": "DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving",
    "title_es": "DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving",
    "url": "https://arxiv.org/abs/2506.17590",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.17590v2 Announce Type: replace \nAbstract: Understanding the short-term motion of vulnerable road users (VRUs) like pedestrians and cyclists is critical for safe autonomous driving, especially in urban scenarios with ambiguous or high-risk behaviors. While vision-language models (VLMs) have enabled open-vocabulary perception, their utility for fine-grained intent reasoning remains underexplored. Notably, no existing benchmark evaluates multi-class intent prediction in safety-critical situations, To address this gap, we introduce DRAMA-X, a fine-grained benchmark constructed from the DRAMA dataset via an automated annotation pipeline. DRAMA-X contains 5,686 accident-prone frames labeled with object bounding boxes, a nine-class directional intent taxonomy, binary risk scores, expert-generated action suggestions for the ego vehicle, and descriptive motion summaries. These annotations enable a structured evaluation of four interrelated tasks central to autonomous decision-making: object detection, intent prediction, risk assessment, and action suggestion. As a reference baseline, we propose SGG-Intent, a lightweight, training-free framework that mirrors the ego vehicle's reasoning pipeline. It sequentially generates a scene graph from visual input using VLM-backed detectors, infers intent, assesses risk, and recommends an action using a compositional reasoning stage powered by a large language model. We evaluate a range of recent VLMs, comparing performance across all four DRAMA-X tasks. Our experiments demonstrate that scene-graph-based reasoning enhances intent prediction and risk assessment, especially when contextual cues are explicitly modeled.",
    "source": "arXiv"
  },
  {
    "title": "CLGRPO: Reasoning Ability Enhancement for Small VLMs",
    "title_es": "CLGRPO: Reasoning Ability Enhancement for Small VLMs",
    "url": "https://arxiv.org/abs/2506.18048",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.18048v2 Announce Type: replace \nAbstract: Small Vision Language Models (SVLMs) generally refer to models with parameter sizes less than or equal to 2B. Their low cost and power consumption characteristics confer high commercial value. However, their reasoning abilities are limited by the number of parameters. To address this issue, this paper proposes a post-training optimization paradigm called the Incremental Training Strategy to enhance the reasoning ability of SVLMs. Firstly, we constructed a Self-Supervised Chain-of-Thought (COT) Data Construction System, which leverages multiple LVLMs with 7B parameters or more to transform original data into COT data in a self-supervised manner. Our proposed Incremental Training Strategy consists of four stages. Stage 1 injects domain knowledge by performing Supervised Fine-Tuning (SFT) to the pretrained model on the COT data. Stage 2 aligns the COT data format by conducting a small amount of Group Relative Policy Optimization (GRPO) training constrained only by format rewards on the COT data. Stage 3 enhances reasoning ability by applying GRPO training on the COT data with constraints on both format and accuracy rewards. The resulting model shows significant improvement compared to the baseline. Stage 4 addresses the limited capacity of the SVLMs and the weak ability to capture complex patterns by proposing ClipLow GRPO (CLGRPO) to constrain the capture space of the training process. We conducted extensive comparative and ablation experiments on the abstract semantic recognition dataset EMOSet-118K. Experimental results demonstrate that our method significantly improves the reasoning ability of 1B SVLM. Compared to the baseline model fine-tuned on the original data, accuracy increased by 2.77 and recall by 0.69, achieving performance comparable to that of 8B models.",
    "source": "arXiv"
  },
  {
    "title": "Granular-Ball-Induced Multiple Kernel K-Means",
    "title_es": "Granular-Ball-Induced Multiple Kernel K-Means",
    "url": "https://arxiv.org/abs/2506.18637",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.18637v2 Announce Type: replace \nAbstract: Most existing multi-kernel clustering algorithms, such as multi-kernel K-means, often struggle with computational efficiency and robustness when faced with complex data distributions. These challenges stem from their dependence on point-to-point relationships for optimization, which can lead to difficulty in accurately capturing data sets' inherent structure and diversity. Additionally, the intricate interplay between multiple kernels in such algorithms can further exacerbate these issues, effectively impacting their ability to cluster data points in high-dimensional spaces. In this paper, we leverage granular-ball computing to improve the multi-kernel clustering framework. The core of granular-ball computing is to adaptively fit data distribution by balls from coarse to acceptable levels. Each ball can enclose data points based on a density consistency measurement. Such ball-based data description thus improves the computational efficiency and the robustness to unknown noises. Specifically, based on granular-ball representations, we introduce the granular-ball kernel (GBK) and its corresponding granular-ball multi-kernel K-means framework (GB-MKKM) for efficient clustering. Using granular-ball relationships in multiple kernel spaces, the proposed GB-MKKM framework shows its superiority in efficiency and clustering performance in the empirical evaluation of various clustering tasks.",
    "source": "arXiv"
  },
  {
    "title": "Robust Behavior Cloning Via Global Lipschitz Regularization",
    "title_es": "Robust Behavior Cloning Via Global Lipschitz Regularization",
    "url": "https://arxiv.org/abs/2506.19250",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.19250v2 Announce Type: replace \nAbstract: Behavior Cloning (BC) is an effective imitation learning technique and has even been adopted in some safety-critical domains such as autonomous vehicles. BC trains a policy to mimic the behavior of an expert by using a dataset composed of only state-action pairs demonstrated by the expert, without any additional interaction with the environment. However, During deployment, the policy observations may contain measurement errors or adversarial disturbances. Since the observations may deviate from the true states, they can mislead the agent into making sub-optimal actions. In this work, we use a global Lipschitz regularization approach to enhance the robustness of the learned policy network. We then show that the resulting global Lipschitz property provides a robustness certificate to the policy with respect to different bounded norm perturbations. Then, we propose a way to construct a Lipschitz neural network that ensures the policy robustness. We empirically validate our theory across various environments in Gymnasium. Keywords: Robust Reinforcement Learning; Behavior Cloning; Lipschitz Neural Network",
    "source": "arXiv"
  },
  {
    "title": "UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot CLIP Adaptation",
    "title_es": "UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot CLIP Adaptation",
    "url": "https://arxiv.org/abs/2506.19694",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.19694v2 Announce Type: replace \nAbstract: Precise anomaly detection in medical images is critical for clinical decision-making. While recent unsupervised or semi-supervised anomaly detection methods trained on large-scale normal data show promising results, they lack fine-grained differentiation, such as benign vs. malignant tumors. Additionally, ultrasound (US) imaging is highly sensitive to devices and acquisition parameter variations, creating significant domain gaps in the resulting US images. To address these challenges, we propose UltraAD, a vision-language model (VLM)-based approach that leverages few-shot US examples for generalized anomaly localization and fine-grained classification. To enhance localization performance, the image-level token of query visual prototypes is first fused with learnable text embeddings. This image-informed prompt feature is then further integrated with patch-level tokens, refining local representations for improved accuracy. For fine-grained classification, a memory bank is constructed from few-shot image samples and corresponding text descriptions that capture anatomical and abnormality-specific features. During training, the stored text embeddings remain frozen, while image features are adapted to better align with medical data. UltraAD has been extensively evaluated on three breast US datasets, outperforming state-of-the-art methods in both lesion localization and fine-grained medical classification. The code will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017",
    "title_es": "Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017",
    "url": "https://arxiv.org/abs/2506.19877",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.19877v2 Announce Type: replace \nAbstract: Identifying suitable machine learning paradigms for intrusion detection remains critical for building effective and generalizable security solutions. In this study, we present a controlled comparison of four representative models - Multi-Layer Perceptron (MLP), 1D Convolutional Neural Network (CNN), One-Class Support Vector Machine (OCSVM) and Local Outlier Factor (LOF) - on the CICIDS2017 dataset under two scenarios: detecting known attack types and generalizing to previously unseen threats. Our results show that supervised MLP and CNN achieve near-perfect accuracy on familiar attacks but suffer drastic recall drops on novel attacks. Unsupervised LOF attains moderate overall accuracy and high recall on unknown threats at the cost of elevated false alarms, while boundary-based OCSVM balances precision and recall best, demonstrating robust detection across both scenarios. These findings offer practical guidance for selecting IDS models in dynamic network environments.",
    "source": "arXiv"
  },
  {
    "title": "CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation",
    "title_es": "CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation",
    "url": "https://arxiv.org/abs/2506.19952",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.19952v2 Announce Type: replace \nAbstract: Large language models (LLMs), despite their ability to perform few-shot machine translation (MT), often lag behind dedicated MT systems trained on parallel corpora, which are crucial for high quality machine translation (MT). However, parallel corpora are often scarce or non-existent for low-resource languages. In this paper, we propose CycleDistill, a bootstrapping approach leveraging LLMs and few-shot translation to obtain high-quality MT systems. CycleDistill involves iteratively generating synthetic parallel corpora from monolingual corpora via zero- or few-shot MT, which is then used to fine-tune the model that was used for generating said data for MT. CycleDistill does not need parallel corpora beyond 1 to 4 few-shot examples, and in our experiments focusing on three Indian languages, by relying solely on monolingual corpora, it can achieve high-quality machine translation, improving upon a few-shot baseline model by over 20-30 chrF points on average in the first iteration. We also study the effect of leveraging softmax activations during the distillation process and observe mild improvements in translation quality.",
    "source": "arXiv"
  },
  {
    "title": "When Domains Collide: An Activity Theory Exploration of Cross-Disciplinary Collaboration",
    "title_es": "When Domains Collide: An Activity Theory Exploration of Cross-Disciplinary Collaboration",
    "url": "https://arxiv.org/abs/2506.20063",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.20063v3 Announce Type: replace \nAbstract: Background: Software development teams are increasingly diverse, embedded, and cross-disciplinary. Domain experts (DEs) from different disciplines collaborate with professional software developers (SDEs), bringing complementary expertise in creating and maintaining complex production software. However, contested expectations, divergent problem-solving perspectives, and conflicting priorities lead to friction. Aims: This study aims to investigate the dynamics of emerging collaboration of cross-disciplinary software development (CDSD) by exploring the expectations held by DEs and SDEs and understanding how these frictions manifest in practice. Method: We utilize Activity Theory (AT), a well-established socio-technical framework, as an analytical lens in a grounded, empirical investigation, conducted through a mixed-method study involving 24 interviews (12 DEs and 12 SDEs) and a large-scale validation survey with 293 participants (161 DEs and 132 SDEs). Results: We conceptualize and empirically ground the CDSD dynamics. We identified eight expectations held by SDEs and six by DEs. By mapping these expectations to AT components, we revealed 21 frictions in CDSD and illustrated where and how they arise. Conclusions: This study offers a theoretical lens for understanding the dynamics and frictions in CDSD and provides actionable insights for future research, practitioners, and infrastructure design.",
    "source": "arXiv"
  },
  {
    "title": "Temporal Rate Reduction Clustering for Human Motion Segmentation",
    "title_es": "Temporal Rate Reduction Clustering for Human Motion Segmentation",
    "url": "https://arxiv.org/abs/2506.21249",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.21249v2 Announce Type: replace \nAbstract: Human Motion Segmentation (HMS), which aims to partition videos into non-overlapping human motions, has attracted increasing research attention recently. Existing approaches for HMS are mainly dominated by subspace clustering methods, which are grounded on the assumption that high-dimensional temporal data align with a Union-of-Subspaces (UoS) distribution. However, the frames in video capturing complex human motions with cluttered backgrounds may not align well with the UoS distribution. In this paper, we propose a novel approach for HMS, named Temporal Rate Reduction Clustering ($\\text{TR}^2\\text{C}$), which jointly learns structured representations and affinity to segment the sequences of frames in video. Specifically, the structured representations learned by $\\text{TR}^2\\text{C}$ enjoy temporally consistency and are aligned well with a UoS structure, which is favorable for addressing the HMS task. We conduct extensive experiments on five benchmark HMS datasets and achieve state-of-the-art performances with different feature extractors. The code is available at: https://github.com/mengxianghan123/TR2C.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Adapter Design Tradeoffs for Low Resource Music Generation",
    "title_es": "Exploring Adapter Design Tradeoffs for Low Resource Music Generation",
    "url": "https://arxiv.org/abs/2506.21298",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.21298v2 Announce Type: replace \nAbstract: Fine-tuning large-scale music generation models, such as MusicGen and Mustango, is a computationally expensive process, often requiring updates to billions of parameters and, therefore, significant hardware resources. Parameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based methods, have emerged as a promising alternative, enabling adaptation with minimal trainable parameters while preserving model performance. However, the design choices for adapters, including their architecture, placement, and size, are numerous, and it is unclear which of these combinations would produce optimal adapters and why, for a given case of low-resource music genre. In this paper, we attempt to answer this question by studying various adapter configurations for two AI music models, MusicGen and Mustango, on two genres: Hindustani Classical and Turkish Makam music.\n  Our findings reveal distinct trade-offs: convolution-based adapters excel in capturing fine-grained local musical details such as ornamentations and short melodic phrases, while transformer-based adapters better preserve long-range dependencies crucial for structured improvisation. Additionally, we analyze computational resource requirements across different adapter scales, demonstrating how mid-sized adapters (40M parameters) achieve an optimal balance between expressivity and quality. Furthermore, we find that Mustango, a diffusion-based model, generates more diverse outputs with better adherence to the description in the input prompt while lacking in providing stability in notes, rhythm alignment, and aesthetics. Also, it is computationally intensive and requires significantly more time to train. In contrast, autoregressive models like MusicGen offer faster training and are more efficient, and can produce better quality output in comparison, but have slightly higher redundancy in their generations.",
    "source": "arXiv"
  },
  {
    "title": "Optimal solutions employing an algebraic Variational Multiscale approach Part II: Application to Navier-Stokes",
    "title_es": "Optimal solutions employing an algebraic Variational Multiscale approach Part II: Application to Navier-Stokes",
    "url": "https://arxiv.org/abs/2506.21395",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.21395v2 Announce Type: replace \nAbstract: This work presents a nonlinear extension of the high-order discretisation framework based on the Variational Multiscale (VMS) method previously introduced for steady linear problems. Building on the concept of an optimal projector defined via the symmetric part of the governing operator, we generalise the formulation to treat the 2D incompressible Navier-Stokes equations. The approach maintains a clear separation between resolved and unresolved scales, with the fine-scale contribution approximated through the approximate Fine-Scale Greens' function of the associated symmetric operator. This enables a consistent variational treatment of nonlinearity while preserving high-order accuracy. We show that the method yields numerical solutions that closely approximate the optimal projection of the continuous/highly-resolved solution and inherits desirable conservation properties. Particularly, the formulation guarantees discrete conservation of mass, energy, and vorticity, where enstrophy conservation is also achieved when exact or over-integration is employed. Numerical results confirm the framework's robustness, accuracy, and its potential for application to a broad class of nonlinear multiscale problems.",
    "source": "arXiv"
  },
  {
    "title": "GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles",
    "title_es": "GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles",
    "url": "https://arxiv.org/abs/2506.21839",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.21839v2 Announce Type: replace \nAbstract: We challenge text-to-image models with generating escape room puzzle images that are visually appealing, logically solid, and intellectually stimulating. While base image models struggle with spatial relationships and affordance reasoning, we propose a hierarchical multi-agent framework that decomposes this task into structured stages: functional design, symbolic scene graph reasoning, layout synthesis, and local image editing. Specialized agents collaborate through iterative feedback to ensure the scene is visually coherent and functionally solvable. Experiments show that agent collaboration improves output quality in terms of solvability, shortcut avoidance, and affordance clarity, while maintaining visual quality.",
    "source": "arXiv"
  },
  {
    "title": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation",
    "title_es": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation",
    "url": "https://arxiv.org/abs/2506.21931",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.21931v2 Announce Type: replace \nAbstract: Retrieval-Augmented Generation (RAG) has shown promise in enhancing recommendation systems by incorporating external context into large language model prompts. However, existing RAG-based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval-Augmented Generation framework for Personalized Recommendation, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user preferences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outperforms standard RAG and recency-based baselines, achieving up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an ablation study to analyse the effect by different components of ARAG. Our findings highlight the effectiveness of integrating agentic reasoning into retrieval-augmented recommendation and provide new directions for LLM-based personalization.",
    "source": "arXiv"
  },
  {
    "title": "MDC-R: The Minecraft Dialogue Corpus with Reference",
    "title_es": "MDC-R: The Minecraft Dialogue Corpus with Reference",
    "url": "https://arxiv.org/abs/2506.22062",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.22062v2 Announce Type: replace \nAbstract: We introduce the Minecraft Dialogue Corpus with Reference (MDC-R). MDC-R is a new language resource that supplements the original Minecraft Dialogue Corpus (MDC) with expert annotations of anaphoric and deictic reference. MDC's task-orientated, multi-turn, situated dialogue in a dynamic environment has motivated multiple annotation efforts, owing to the interesting linguistic phenomena that this setting gives rise to. We believe it can serve as a valuable resource when annotated with reference, too. Here, we discuss our method of annotation and the resulting corpus, and provide both a quantitative and a qualitative analysis of the data. Furthermore, we carry out a short experiment demonstrating the usefulness of our corpus for referring expression comprehension.",
    "source": "arXiv"
  },
  {
    "title": "Probabilistic Optimality for Inference-time Scaling",
    "title_es": "Probabilistic Optimality for Inference-time Scaling",
    "url": "https://arxiv.org/abs/2506.22376",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.22376v2 Announce Type: replace \nAbstract: Inference-time scaling has emerged as a powerful technique for enhancing the reasoning performance of Large Language Models (LLMs). However, existing approaches often rely on heuristic strategies for parallel sampling, lacking a principled foundation. To address this gap, we propose a probabilistic framework that formalizes the optimality of inference-time scaling under the assumption that parallel samples are independently and identically distributed (i.i.d.), and where the Best-of-N selection strategy follows a probability distribution that can be estimated. Within this framework, we derive a theoretical lower bound on the required number of samples to achieve a target performance level, providing the first principled guidance for compute-efficient scaling. Leveraging this insight, we develop OptScale, a practical algorithm that dynamically determines the optimal number of sampled responses. OptScale employs a language model-based predictor to estimate probabilistic prior parameters, enabling the decision of the minimal number of samples needed that satisfy predefined performance thresholds and confidence levels. Extensive experiments on mathematical reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC) demonstrate that OptScale significantly reduces sampling overhead while remaining better or on par with state-of-the-art reasoning performance. Our work offers both a theoretical foundation and a practical solution for principled inference-time scaling, addressing a critical gap in the efficient deployment of LLMs for complex reasoning. The source code is publicly available at https://github.com/Albertwyk/OptScale.",
    "source": "arXiv"
  },
  {
    "title": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models",
    "title_es": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2506.23009",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.23009v2 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) have achieved remarkable visual reasoning abilities in natural images, text-rich documents, and graphic designs. However, their ability to interpret music sheets remains underexplored. To bridge this gap, we introduce MusiXQA, the first comprehensive dataset for evaluating and advancing MLLMs in music sheet understanding. MusiXQA features high-quality synthetic music sheets generated via MusiXTeX, with structured annotations covering note pitch and duration, chords, clefs, key/time signatures, and text, enabling diverse visual QA tasks. Through extensive evaluations, we reveal significant limitations of current state-of-the-art MLLMs in this domain. Beyond benchmarking, we developed Phi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant performance gains over GPT-based methods. The proposed dataset and model establish a foundation for future advances in MLLMs for music sheet understanding. Code, data, and model will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation",
    "title_es": "PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation",
    "url": "https://arxiv.org/abs/2506.23257",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.23257v2 Announce Type: replace \nAbstract: Large-scale simulations on supercomputers have become important tools for users. However, their scalability remains a problem due to the huge communication cost among parallel processes. Most of the existing communication latency analysis methods rely on the physical link layer information, which is only available to administrators. In this paper, a framework called PCLVis is proposed to help general users analyze process communication latency (PCL) events. Instead of the physical link layer information, the PCLVis uses the MPI process communication data for the analysis. First, a spatial PCL event locating method is developed. All processes with high correlation are classified into a single cluster by constructing a process-correlation tree. Second, the propagation path of PCL events is analyzed by constructing a communication-dependency-based directed acyclic graph (DAG), which can help users interactively explore a PCL event from the temporal evolution of a located PCL event cluster. In this graph, a sliding window algorithm is designed to generate the PCL events abstraction. Meanwhile, a new glyph called the communication state glyph (CS-Glyph) is designed for each process to show its communication states, including its in/out messages and load balance. Each leaf node can be further unfolded to view additional information. Third, a PCL event attribution strategy is formulated to help users optimize their simulations. The effectiveness of the PCLVis framework is demonstrated by analyzing the PCL events of several simulations running on the TH-1A supercomputer. By using the proposed framework, users can greatly improve the efficiency of their simulations.",
    "source": "arXiv"
  },
  {
    "title": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning",
    "title_es": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning",
    "url": "https://arxiv.org/abs/2506.23998",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.23998v2 Announce Type: replace \nAbstract: Congenital heart disease (CHD) presents complex, lifelong challenges often underrepresented in traditional clinical metrics. While unstructured narratives offer rich insights into patient and caregiver experiences, manual thematic analysis (TA) remains labor-intensive and unscalable. We propose a fully automated large language model (LLM) pipeline that performs end-to-end TA on clinical narratives, which eliminates the need for manual coding or full transcript review. Our system employs a novel multi-agent framework, where specialized LLM agents assume roles to enhance theme quality and alignment with human analysis. To further improve thematic relevance, we optionally integrate reinforcement learning from human feedback (RLHF). This supports scalable, patient-centered analysis of large qualitative datasets and allows LLMs to be fine-tuned for specific clinical contexts.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective",
    "title_es": "Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective",
    "url": "https://arxiv.org/abs/2506.24006",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.24006v2 Announce Type: replace \nAbstract: The progress of Large Language Models (LLMs) like ChatGPT raises the question of how they can be integrated into education. One hope is that they can support mathematics learning, including word-problem solving. Since LLMs can handle textual input with ease, they appear well-suited for solving mathematical word problems. Yet their real competence, whether they can make sense of the real-world context, and the implications for classrooms remain unclear. We conducted a scoping review from a mathematics-education perspective, including three parts: a technical overview, a systematic review of word problems used in research, and a state-of-the-art empirical evaluation of LLMs on mathematical word problems. First, in the technical overview, we contrast the conceptualization of word problems and their solution processes between LLMs and students. In computer-science research this is typically labeled mathematical reasoning, a term that does not align with usage in mathematics education. Second, our literature review of 213 studies shows that the most popular word-problem corpora are dominated by s-problems, which do not require a consideration of realities of their real-world context. Finally, our evaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, o3, and GPT-5 on 287 word problems shows that most recent LLMs solve these s-problems with near-perfect accuracy, including a perfect score on 20 problems from PISA. LLMs still showed weaknesses in tackling problems where the real-world context is problematic or non-sensical. In sum, we argue based on all three aspects that LLMs have mastered a superficial solution process but do not make sense of word problems, which potentially limits their value as instructional tools in mathematics classrooms.",
    "source": "arXiv"
  },
  {
    "title": "On the Intensity-based Inversion Method for Quantitative Quasi-Static Elastography",
    "title_es": "On the Intensity-based Inversion Method for Quantitative Quasi-Static Elastography",
    "url": "https://arxiv.org/abs/2507.01207",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.01207v2 Announce Type: replace \nAbstract: In this paper, we consider the intensity-based inversion method (IIM) for quantitative material parameter estimation in quasi-static elastography. In particular, we consider the problem of estimating the material parameters of a given sample from two internal measurements, one obtained before and one after applying some form of deformation. These internal measurements can be obtained via any imaging modality of choice, for example ultrasound, optical coherence or photo-acoustic tomography. Compared to two-step approaches to elastography, which first estimate internal displacement fields or strains and then reconstruct the material parameters from them, the IIM is a one-step approach which computes the material parameters directly from the internal measurements. To do so, the IIM combines image registration together with a model-based, regularized parameter reconstruction approach. This combination has the advantage of avoiding some approximations and derivative computations typically found in two-step approaches, and results in the IIM being generally more stable to measurement noise. In the paper, we provide a full convergence analysis of the IIM within the framework of inverse problems, and detail its application to linear elastography. Furthermore, we discuss the numerical implementation of the IIM and provide numerical examples simulating an optical coherence elastography (OCE) experiment.",
    "source": "arXiv"
  },
  {
    "title": "PAE MobiLLM: Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning",
    "title_es": "PAE MobiLLM: Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning",
    "url": "https://arxiv.org/abs/2507.01216",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.01216v2 Announce Type: replace \nAbstract: There is a huge gap between numerous intriguing applications fostered by on-device large language model (LLM) fine-tuning (FT) from fresh mobile data and the limited resources of a mobile device. While existing server-assisted methods (e.g., split learning or side-tuning) may enable LLM FT on the local mobile device, they suffer from heavy communication burdens of activation transmissions, and may disclose data and labels to the server. To address those issues, we develop PAE MobiLLM, a a privacy-aware and efficient LLM FT method which can be deployed on the mobile device via server-assisted additive side-tuning. To further accelerate FT convergence and improve computing efficiency, PAE MobiLLM integrates activation caching on the server side, which allows the server to reuse historical activations and saves the mobile device from repeatedly computing forward passes for the recurring data samples. Besides, to reduce communication cost, PAE MobiLLM develops an activation shortcut that transmits only the token involved in the loss calculation instead of full activation matrices to guide the side network tuning. Last but not least, PAE MobiLLM introduces the additive adapter side-network design which makes the server train the adapter modules based on device-defined prediction differences rather than raw ground-truth labels. In this way, the server can only assist device-defined side-network computing, and learn nothing about data and labels. Extensive experimental results demonstrate PAE MobiLLM's superiority.",
    "source": "arXiv"
  },
  {
    "title": "CPKD: Clinical Prior Knowledge-Constrained Diffusion Models for Surgical Phase Recognition in Endoscopic Submucosal Dissection",
    "title_es": "CPKD: Clinical Prior Knowledge-Constrained Diffusion Models for Surgical Phase Recognition in Endoscopic Submucosal Dissection",
    "url": "https://arxiv.org/abs/2507.03295",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.03295v2 Announce Type: replace \nAbstract: Gastrointestinal malignancies constitute a leading cause of cancer-related mortality worldwide, with advanced-stage prognosis remaining particularly dismal. Originating as a groundbreaking technique for early gastric cancer treatment, Endoscopic Submucosal Dissection has evolved into a versatile intervention for diverse gastrointestinal lesions. While computer-assisted systems significantly enhance procedural precision and safety in ESD, their clinical adoption faces a critical bottleneck: reliable surgical phase recognition within complex endoscopic workflows. Current state-of-the-art approaches predominantly rely on multi-stage refinement architectures that iteratively optimize temporal predictions. In this paper, we present Clinical Prior Knowledge-Constrained Diffusion (CPKD), a novel generative framework that reimagines phase recognition through denoising diffusion principles while preserving the core iterative refinement philosophy. This architecture progressively reconstructs phase sequences starting from random noise and conditioned on visual-temporal features. To better capture three domain-specific characteristics, including positional priors, boundary ambiguity, and relation dependency, we design a conditional masking strategy. Furthermore, we incorporate clinical prior knowledge into the model training to improve its ability to correct phase logical errors. Comprehensive evaluations on ESD820, Cholec80, and external multi-center demonstrate that our proposed CPKD achieves superior or comparable performance to state-of-the-art approaches, validating the effectiveness of diffusion-based generative paradigms for surgical phase recognition.",
    "source": "arXiv"
  },
  {
    "title": "Direction Estimation of Sound Sources Using Microphone Arrays and Signal Strength",
    "title_es": "Direction Estimation of Sound Sources Using Microphone Arrays and Signal Strength",
    "url": "https://arxiv.org/abs/2507.03466",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.03466v2 Announce Type: replace \nAbstract: Sound-tracking refers to the process of determining the direction from which a sound originates, making it a fundamental component of sound source localization. This capability is essential in a variety of applications, including security systems, acoustic monitoring, and speaker tracking, where accurately identifying the direction of a sound source enables real-time responses, efficient resource allocation, and improved situational awareness. While sound-tracking is closely related to localization, it specifically focuses on identifying the direction of the sound source rather than estimating its exact position in space. Despite its utility, sound-tracking systems face several challenges, such as maintaining directional accuracy and precision, along with the need for sophisticated hardware configurations and complex signal processing algorithms. This paper presents a sound-tracking method using three electret microphones. We estimate the direction of a sound source using a lightweight method that analyzes signals from three strategically placed microphones. By comparing the average power of the received signals, the system infers the most probable direction of the sound. The results indicate that the power level from each microphone effectively determines the sound source direction. Our system employs a straightforward and cost-effective hardware design, ensuring simplicity and affordability in implementation. It achieves a localization error of less than 6 degrees and a precision of 98%. Additionally, its effortless integration with various systems makes it versatile and adaptable. Consequently, this technique presents a robust and reliable solution for sound-tracking and localization, with potential applications spanning diverse domains such as security systems, smart homes, and acoustic monitoring.",
    "source": "arXiv"
  },
  {
    "title": "Foundation versus Domain-specific Models: Performance Comparison, Fusion, and Explainability in Face Recognition",
    "title_es": "Foundation versus Domain-specific Models: Performance Comparison, Fusion, and Explainability in Face Recognition",
    "url": "https://arxiv.org/abs/2507.03541",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.03541v2 Announce Type: replace \nAbstract: In this paper, we address the following question: How do generic foundation models (e.g., CLIP, BLIP, GPT-4o, Grok-4) compare against a domain-specific face recognition model (viz., AdaFace or ArcFace) on the face recognition task? Through a series of experiments involving several foundation models and benchmark datasets, we report the following findings: (a) In all face benchmark datasets considered, domain-specific models outperformed zero-shot foundation models. (b) The performance of zero-shot generic foundation models improved on over-segmented face images compared to tightly cropped faces, thereby suggesting the importance of contextual clues. (c) A simple score-level fusion of a foundation model with a domain-specific face recognition model improved the accuracy at low false match rates. (d) Foundation models, such as GPT-4o and Grok-4, are able to provide explainability to the face recognition pipeline. In some instances, foundation models are even able to resolve low-confidence decisions made by AdaFace, thereby reiterating the importance of combining domain-specific face recognition models with generic foundation models in a judicious manner.",
    "source": "arXiv"
  },
  {
    "title": "Addressing The Devastating Effects Of Single-Task Data Poisoning In Exemplar-Free Continual Learning",
    "title_es": "Addressing The Devastating Effects Of Single-Task Data Poisoning In Exemplar-Free Continual Learning",
    "url": "https://arxiv.org/abs/2507.04106",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.04106v2 Announce Type: replace \nAbstract: Our research addresses the overlooked security concerns related to data poisoning in continual learning (CL). Data poisoning - the intentional manipulation of training data to affect the predictions of machine learning models - was recently shown to be a threat to CL training stability. While existing literature predominantly addresses scenario-dependent attacks, we propose to focus on a more simple and realistic single-task poison (STP) threats. In contrast to previously proposed poisoning settings, in STP adversaries lack knowledge and access to the model, as well as to both previous and future tasks. During an attack, they only have access to the current task within the data stream. Our study demonstrates that even within these stringent conditions, adversaries can compromise model performance using standard image corruptions. We show that STP attacks are able to strongly disrupt the whole continual training process: decreasing both the stability (its performance on past tasks) and plasticity (capacity to adapt to new tasks) of the algorithm. Finally, we propose a high-level defense framework for CL along with a poison task detection method based on task vectors. The code is available at https://github.com/stapaw/STP.git .",
    "source": "arXiv"
  },
  {
    "title": "Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions",
    "title_es": "Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions",
    "url": "https://arxiv.org/abs/2507.04377",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.04377v3 Announce Type: replace \nAbstract: Tombstones are historically and culturally rich artifacts, encapsulating individual lives, community memory, historical narratives and artistic expression. Yet, many tombstones today face significant preservation challenges, including physical erosion, vandalism, environmental degradation, and political shifts. In this paper, we introduce a novel multi-modal framework for tombstones digitization, aiming to improve the interpretation, organization and retrieval of tombstone content. Our approach leverages vision-language models (VLMs) to translate tombstone images into structured Tombstone Meaning Representations (TMRs), capturing both image and text information. To further enrich semantic parsing, we incorporate retrieval-augmented generation (RAG) for integrate externally dependent elements such as toponyms, occupation codes, and ontological concepts. Compared to traditional OCR-based pipelines, our method improves parsing accuracy from an F1 score of 36.1 to 89.5. We additionally evaluate the model's robustness across diverse linguistic and cultural inscriptions, and simulate physical degradation through image fusion to assess performance under noisy or damaged conditions. Our work represents the first attempt to formalize tombstone understanding using large vision-language models, presenting implications for heritage preservation.",
    "source": "arXiv"
  },
  {
    "title": "EduCoder: An Open-Source Annotation System for Education Transcript Data",
    "title_es": "EduCoder: An Open-Source Annotation System for Education Transcript Data",
    "url": "https://arxiv.org/abs/2507.05385",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.05385v3 Announce Type: replace \nAbstract: We introduce EduCoder, a domain-specialized tool designed to support utterance-level annotation of educational dialogue. While general-purpose text annotation tools for NLP and qualitative research abound, few address the complexities of coding education dialogue transcripts -- with diverse teacher-student and peer interactions. Common challenges include defining codebooks for complex pedagogical features, supporting both open-ended and categorical coding, and contextualizing utterances with external features, such as the lesson's purpose and the pedagogical value of the instruction. EduCoder is designed to address these challenges by providing a platform for researchers and domain experts to collaboratively define complex codebooks based on observed data. It incorporates both categorical and open-ended annotation types along with contextual materials. Additionally, it offers a side-by-side comparison of multiple annotators' responses, allowing comparison and calibration of annotations with others to improve data reliability. The system is open-source, with a demo video available.",
    "source": "arXiv"
  },
  {
    "title": "LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance",
    "title_es": "LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance",
    "url": "https://arxiv.org/abs/2507.06272",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.06272v3 Announce Type: replace \nAbstract: While large multi-modal models (LMMs) demonstrate promising capabilities in segmentation and comprehension, they still struggle with two limitations: inaccurate segmentation and hallucinated comprehension. These challenges stem primarily from constraints in weak visual comprehension and a lack of fine-grained perception. To alleviate these limitations, we propose LIRA, a framework that capitalizes on the complementary relationship between visual comprehension and segmentation via two key components: (1) Semantic-Enhanced Feature Extractor (SEFE) improves object attribute inference by fusing semantic and pixel-level features, leading to more accurate segmentation; (2) Interleaved Local Visual Coupling (ILVC) autoregressively generates local descriptions after extracting local features based on segmentation masks, offering fine-grained supervision to mitigate hallucinations. Furthermore, we find that the precision of object segmentation is positively correlated with the latent related semantics of the  token. To quantify this relationship and the model's potential semantic inferring ability, we introduce the Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA achieves state-of-the-art performance in both segmentation and comprehension tasks. Code will be available at https://github.com/echo840/LIRA.",
    "source": "arXiv"
  },
  {
    "title": "When Trackers Date Fish: A Benchmark and Framework for Underwater Multiple Fish Tracking",
    "title_es": "When Trackers Date Fish: A Benchmark and Framework for Underwater Multiple Fish Tracking",
    "url": "https://arxiv.org/abs/2507.06400",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.06400v2 Announce Type: replace \nAbstract: Multiple object tracking (MOT) technology has made significant progress in terrestrial applications, but underwater tracking scenarios remain underexplored despite their importance to marine ecology and aquaculture. In this paper, we present Multiple Fish Tracking Dataset 2025 (MFT25), a comprehensive dataset specifically designed for underwater multiple fish tracking, featuring 15 diverse video sequences with 408,578 meticulously annotated bounding boxes across 48,066 frames. Our dataset captures various underwater environments, fish species, and challenging conditions including occlusions, similar appearances, and erratic motion patterns. Additionally, we introduce Scale-aware and Unscented Tracker (SU-T), a specialized tracking framework featuring an Unscented Kalman Filter (UKF) optimized for non-linear swimming patterns of fish and a novel Fish-Intersection-over-Union (FishIoU) matching that accounts for the unique morphological characteristics of aquatic species. Extensive experiments demonstrate that our SU-T baseline achieves state-of-the-art performance on MFT25, with 34.1 HOTA and 44.6 IDF1, while revealing fundamental differences between fish tracking and terrestrial object tracking scenarios. The dataset and codes are released at https://vranlee.github.io/SU-T/.",
    "source": "arXiv"
  },
  {
    "title": "Towards Designing Social Interventions For Online Climate Change Denialism Discussions",
    "title_es": "Towards Designing Social Interventions For Online Climate Change Denialism Discussions",
    "url": "https://arxiv.org/abs/2507.06561",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.06561v2 Announce Type: replace \nAbstract: As conspiracy theories gain traction, it has become crucial to research effective intervention strategies that can foster evidence and science-based discussions in conspiracy theory communities online. This study presents a novel framework using insider language to contest conspiracy theory ideology in climate change denialism on Reddit. Focusing on discussions in two Reddit communities, our research investigates reactions to pro-social and evidence-based intervention messages for two cohorts of users: climate change deniers and climate change supporters. Specifically, we combine manual and generative AI-based methods to craft intervention messages and deploy the interventions as replies on Reddit posts and comments through transparently labeled bot accounts. On the one hand, we find that evidence-based interventions with neutral language foster positive engagement, encouraging open discussions among believers of climate change denialism. On the other, climate change supporters respond positively, actively participating and presenting additional evidence. Our study contributes valuable insights into the process and challenges of automatically delivering interventions in conspiracy theory communities on social media, and helps inform future research on social media interventions.",
    "source": "arXiv"
  },
  {
    "title": "Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching",
    "title_es": "Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching",
    "url": "https://arxiv.org/abs/2507.07192",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.07192v3 Announce Type: replace \nAbstract: Existing generative models for time series forecasting often transform simple priors (typically Gaussian) into complex data distributions. However, their sampling initialization, independent of historical data, hinders the capture of temporal dependencies, limiting predictive accuracy. They also treat residuals merely as optimization targets, ignoring that residuals often exhibit meaningful patterns like systematic biases or nontrivial distributional structures. To address these, we propose Conditional Guided Flow Matching (CGFM), a novel model-agnostic framework that extends flow matching by integrating outputs from an auxiliary predictive model. This enables learning from the probabilistic structure of prediction residuals, leveraging the auxiliary model's prediction distribution as a source to reduce learning difficulty and refine forecasts. CGFM incorporates historical data as both conditions and guidance, uses two-sided conditional paths (with source and target conditioned on the same history), and employs affine paths to expand the path space, avoiding path crossing without complex mechanisms, preserving temporal consistency, and strengthening distribution alignment. Experiments across datasets and baselines show CGFM consistently outperforms state-of-the-art models, advancing forecasting.",
    "source": "arXiv"
  },
  {
    "title": "DMF2Mel: A Dynamic Multiscale Fusion Network for EEG-Driven Mel Spectrogram Reconstruction",
    "title_es": "DMF2Mel: A Dynamic Multiscale Fusion Network for EEG-Driven Mel Spectrogram Reconstruction",
    "url": "https://arxiv.org/abs/2507.07526",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.07526v3 Announce Type: replace \nAbstract: Decoding speech from brain signals is a challenging research problem. Although existing technologies have made progress in reconstructing the mel spectrograms of auditory stimuli at the word or letter level, there remain core challenges in the precise reconstruction of minute-level continuous imagined speech: traditional models struggle to balance the efficiency of temporal dependency modeling and information retention in long-sequence decoding. To address this issue, this paper proposes the Dynamic Multiscale Fusion Network (DMF2Mel), which consists of four core components: the Dynamic Contrastive Feature Aggregation Module (DC-FAM), the Hierarchical Attention-Guided Multi-Scale Network (HAMS-Net), the SplineMap attention mechanism, and the bidirectional state space module (convMamba). Specifically, the DC-FAM separates speech-related \"foreground features\" from noisy \"background features\" through local convolution and global attention mechanisms, effectively suppressing interference and enhancing the representation of transient signals. HAMS-Net, based on the U-Net framework,achieves cross-scale fusion of high-level semantics and low-level details. The SplineMap attention mechanism integrates the Adaptive Gated Kolmogorov-Arnold Network (AGKAN) to combine global context modeling with spline-based local fitting. The convMamba captures long-range temporal dependencies with linear complexity and enhances nonlinear dynamic modeling capabilities. Results on the SparrKULee dataset show that DMF2Mel achieves a Pearson correlation coefficient of 0.074 in mel spectrogram reconstruction for known subjects (a 48% improvement over the baseline) and 0.048 for unknown subjects (a 35% improvement over the baseline).Code is available at: https://github.com/fchest/DMF2Mel.",
    "source": "arXiv"
  },
  {
    "title": "AI Feedback Enhances Community-Based Content Moderation through Engagement with Counterarguments",
    "title_es": "AI Feedback Enhances Community-Based Content Moderation through Engagement with Counterarguments",
    "url": "https://arxiv.org/abs/2507.08110",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.08110v2 Announce Type: replace \nAbstract: Today, social media platforms are significant sources of news and political communication, but their role in spreading misinformation has raised significant concerns. In response, these platforms have implemented various content moderation strategies. One such method, Community Notes on X, relies on crowdsourced fact-checking and has gained traction, though it faces challenges such as partisan bias and delays in verification. This study explores an AI-assisted hybrid moderation framework in which participants receive AI-generated feedback -supportive, neutral, or argumentative -on their notes and are asked to revise them accordingly. The results show that incorporating feedback improves the quality of notes, with the most substantial gains resulting from argumentative feedback. This underscores the value of diverse perspectives and direct engagement in human-AI collective intelligence. The research contributes to ongoing discussions about AI's role in political content moderation, highlighting the potential of generative AI and the importance of informed design.",
    "source": "arXiv"
  },
  {
    "title": "Carbon-Aware Workflow Scheduling with Fixed Mapping and Deadline Constraint",
    "title_es": "Carbon-Aware Workflow Scheduling with Fixed Mapping and Deadline Constraint",
    "url": "https://arxiv.org/abs/2507.08725",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.08725v2 Announce Type: replace \nAbstract: Large data and computing centers consume a significant share of the world's energy consumption. A prominent subset of the workloads in such centers are workflows with interdependent tasks, usually represented as directed acyclic graphs (DAGs). To reduce the carbon emissions resulting from executing such workflows in centers with a mixed (renewable and non-renewable) energy supply, it is advisable to move task executions to time intervals with sufficient green energy when possible. To this end, we formalize the above problem as a scheduling problem with a given mapping and ordering of the tasks. We show that this problem can be solved in polynomial time in the uniprocessor case. For at least two processors, however, the problem becomes NP-hard. Hence, we propose a heuristic framework called CaWoSched that combines several greedy approaches with local search. To assess the 16 heuristics resulting from different combinations, we also devise a simple baseline algorithm and an exact ILP-based solution. Our experimental results show that our heuristics provide significant savings in carbon emissions compared to the baseline.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal Visual Transformer for Sim2real Transfer in Visual Reinforcement Learning",
    "title_es": "Multimodal Visual Transformer for Sim2real Transfer in Visual Reinforcement Learning",
    "url": "https://arxiv.org/abs/2507.09180",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.09180v3 Announce Type: replace \nAbstract: Depth information is robust to scene appearance variations and inherently carries 3D spatial details. In this paper, a visual backbone based on the vision transformer is proposed to fuse RGB and depth modalities for enhancing generalization. Different modalities are first processed by separate CNN stems, and the combined convolutional features are delivered to the scalable vision transformer to obtain visual representations. Moreover, a contrastive unsupervised learning scheme is designed with masked and unmasked tokens to accelerate the sample efficiency during the reinforcement learning process. Simulation results demonstrate that our visual backbone can focus more on task-related regions and exhibit better generalization in unseen scenarios. For sim2real transfer, a flexible curriculum learning schedule is developed to deploy domain randomization over training processes. Finally, the feasibility of our model is validated to perform real-world manipulation tasks via zero-shot transfer.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Target Speaker Extraction with Explicit Speaker Consistency Modeling",
    "title_es": "Enhancing Target Speaker Extraction with Explicit Speaker Consistency Modeling",
    "url": "https://arxiv.org/abs/2507.09510",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.09510v3 Announce Type: replace \nAbstract: Target Speaker Extraction (TSE) uses a reference cue to extract the target speech from a mixture. In TSE systems relying on audio cues, the speaker embedding from the enrolled speech is crucial to performance. However, these embeddings may suffer from speaker identity confusion. Unlike previous studies that focus on improving speaker embedding extraction, we improve TSE performance from the perspective of speaker consistency. In this paper, we propose a speaker consistency-aware target speaker extraction method that incorporates a centroid-based speaker consistency loss. This approach enhances TSE performance by ensuring speaker consistency between the enrolled and extracted speech. In addition, we integrate conditional loss suppression into the training process. The experimental results validate the effectiveness of our proposed methods in advancing the TSE performance. A speech demo is available online:https://sc-tse.netlify.app/",
    "source": "arXiv"
  },
  {
    "title": "Phase transition of the Sinkhorn-Knopp algorithm",
    "title_es": "Phase transition of the Sinkhorn-Knopp algorithm",
    "url": "https://arxiv.org/abs/2507.09711",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.09711v2 Announce Type: replace \nAbstract: The matrix scaling problem, particularly the Sinkhorn-Knopp algorithm, has been studied for over 60 years. In practice, the algorithm often yields high-quality approximations within just a few iterations. Theoretically, however, the best-known upper bound places it in the class of pseudopolynomial-time approximation algorithms. Meanwhile, the lower-bound landscape remains largely unexplored. Two fundamental questions persist: what accounts for the algorithm's strong empirical performance, and can a tight bound on its iteration count be established?\n  For an $n\\times n$ matrix, its normalized version is obtained by dividing each entry by its largest entry. We say that a normalized matrix has a density $\\gamma$ if there exists a constant $\\rho > 0$ such that one row or column has exactly $\\lceil \\gamma n \\rceil$ entries with values at least $\\rho$, and every other row and column has at least $\\lceil \\gamma n \\rceil$ such entries.\n  For the upper bound, we show that the Sinkhorn-Knopp algorithm produces a nearly doubly stochastic matrix in $O(\\log n - \\log \\varepsilon)$ iterations and $\\widetilde{O}(n^2)$ time for all nonnegative square matrices whose normalized version has a density $\\gamma > 1/2$. Such matrices cover both the algorithm's principal practical inputs and its typical theoretical regime, and the $\\widetilde{O}(n^2)$ runtime is optimal.\n  For the lower bound, we establish a tight bound of $\\widetilde{\\Omega}\\left(n^{1/2}/\\varepsilon\\right)$ iterations for positive matrices under the $\\ell_2$-norm error measure. Moreover, for every $\\gamma < 1/2$, there exists a matrix with density $\\gamma$ for which the algorithm requires $\\Omega\\left(n^{1/2}/\\varepsilon\\right)$ iterations.\n  In summary, our results reveal a sharp phase transition in the Sinkhorn-Knopp algorithm at the density threshold $\\gamma = 1/2$.",
    "source": "arXiv"
  },
  {
    "title": "Qualitative Study for LLM-assisted Design Study Process: Strategies, Challenges, and Roles",
    "title_es": "Qualitative Study for LLM-assisted Design Study Process: Strategies, Challenges, and Roles",
    "url": "https://arxiv.org/abs/2507.10024",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.10024v3 Announce Type: replace \nAbstract: Design studies aim to create visualization solutions for real-world problems of different application domains. Recently, the emergence of large language models (LLMs) has introduced new opportunities to enhance the design study process, providing capabilities such as creative problem-solving, data handling, and insightful analysis. However, despite their growing popularity, there remains a lack of systematic understanding of how LLMs can effectively assist researchers in visualization-specific design studies. In this paper, we conducted a multi-stage qualitative study to fill this gap, involving 30 design study researchers from diverse backgrounds and expertise levels. Through in-depth interviews and carefully-designed questionnaires, we investigated strategies for utilizing LLMs, the challenges encountered, and the practices used to overcome them. We further compiled and summarized the roles that LLMs can play across different stages of the design study process. Our findings highlight practical implications to inform visualization practitioners, and provide a framework for leveraging LLMs to enhance the design study process in visualization research.",
    "source": "arXiv"
  },
  {
    "title": "LifelongPR: Lifelong point cloud place recognition based on sample replay and prompt learning",
    "title_es": "LifelongPR: Lifelong point cloud place recognition based on sample replay and prompt learning",
    "url": "https://arxiv.org/abs/2507.10034",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.10034v2 Announce Type: replace \nAbstract: Point cloud place recognition (PCPR) determines the geo-location within a prebuilt map and plays a crucial role in geoscience and robotics applications such as autonomous driving, intelligent transportation, and augmented reality. In real-world large-scale deployments of a geographic positioning system, PCPR models must continuously acquire, update, and accumulate knowledge to adapt to diverse and dynamic environments, i.e., the ability known as continual learning (CL). However, existing PCPR models often suffer from catastrophic forgetting, leading to significant performance degradation in previously learned scenes when adapting to new environments or sensor types. This results in poor model scalability, increased maintenance costs, and system deployment difficulties, undermining the practicality of PCPR. To address these issues, we propose LifelongPR, a novel continual learning framework for PCPR, which effectively extracts and fuses knowledge from sequential point cloud data. First, to alleviate the knowledge loss, we propose a replay sample selection method that dynamically allocates sample sizes according to each dataset's information quantity and selects spatially diverse samples for maximal representativeness. Second, to handle domain shifts, we design a prompt learning-based CL framework with a lightweight prompt module and a two-stage training strategy, enabling domain-specific feature adaptation while minimizing forgetting. Comprehensive experiments on large-scale public and self-collected datasets are conducted to validate the effectiveness of the proposed method. Compared with state-of-the-art (SOTA) methods, our method achieves 6.50% improvement in mIR@1, 7.96% improvement in mR@1, and an 8.95% reduction in F. The code and pre-trained models are publicly available at https://github.com/zouxianghong/LifelongPR.",
    "source": "arXiv"
  },
  {
    "title": "Helveg: Diagrams for Software Documentation",
    "title_es": "Helveg: Diagrams for Software Documentation",
    "url": "https://arxiv.org/abs/2507.10244",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.10244v2 Announce Type: replace \nAbstract: Software developers often have to gain an understanding of a codebase. Be it programmers getting onboarded onto a team project or, for example, developers striving to grasp an external open-source library. In either case, they frequently turn to the project's documentation. However, documentation in its traditional textual form is ill-suited for this kind of high-level exploratory analysis, since it is immutable from the readers' perspective and thus forces them to follow a predefined path. We have designed an approach bringing aspects of software architecture visualization to API reference documentation. It utilizes a highly interactive node-link diagram with expressive node glyphs and flexible filtering capabilities, providing a high-level overview of the codebase as well as details on demand. To test our design, we have implemented a prototype named Helveg, capable of automatically generating diagrams of C\\# codebases. User testing of Helveg confirmed its potential, but it also revealed problems with the readability, intuitiveness, and user experience of our tool. Therefore, in this paper, which is an extended version of our VISSOFT paper with DOI 10.1109/VISSOFT64034.2024.00012, we address many of these problems through major changes to the glyph design, means of interaction, and user interface of the tool. To assess the improvements, this new version of Helveg was evaluated again with the same group of participants as the previous version.",
    "source": "arXiv"
  },
  {
    "title": "RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening",
    "title_es": "RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening",
    "url": "https://arxiv.org/abs/2507.10461",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.10461v2 Announce Type: replace \nAbstract: Pansharpening refers to the process of integrating a high resolution panchromatic (PAN) image with a lower resolution multispectral (MS) image to generate a fused product, which is pivotal in remote sensing. Despite the effectiveness of CNNs in addressing this challenge, they are inherently constrained by the uniform application of convolutional kernels across all spatial positions, overlooking local content variations. To overcome this issue, we introduce RAPNet, a new architecture that leverages content-adaptive convolution. At its core, RAPNet employs the Receptive-field Adaptive Pansharpening Convolution (RAPConv), designed to produce spatially adaptive kernels responsive to local feature context, thereby enhancing the precision of spatial detail extraction. Additionally, the network integrates the Pansharpening Dynamic Feature Fusion (PAN-DFF) module, which incorporates an attention mechanism to achieve an optimal balance between spatial detail enhancement and spectral fidelity. Comprehensive evaluations on publicly available datasets confirm that RAPNet delivers superior performance compared to existing approaches, as demonstrated by both quantitative metrics and qualitative assessments. Ablation analyses further substantiate the effectiveness of the proposed adaptive components.",
    "source": "arXiv"
  },
  {
    "title": "ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space",
    "title_es": "ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space",
    "url": "https://arxiv.org/abs/2507.10638",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.10638v3 Announce Type: replace \nAbstract: We introduce a novel classification framework, ZClassifier, that replaces conventional deterministic logits with diagonal Gaussian-distributed logits. Our method simultaneously addresses temperature scaling and manifold approximation by minimizing the KL divergence between the predicted Gaussian distributions and a unit isotropic Gaussian. This unifies uncertainty calibration and latent control in a principled probabilistic manner, enabling a natural interpretation of class confidence and geometric consistency. Experiments on CIFAR-10 and CIFAR-100 demonstrate that ZClassifier improves over softmax classifiers in robustness, calibration, and latent separation, with consistent benefits across small-scale and large-scale classification settings.",
    "source": "arXiv"
  },
  {
    "title": "Accelerating seismic inversion and uncertainty quantification with efficient high-rank Hessian approximations",
    "title_es": "Accelerating seismic inversion and uncertainty quantification with efficient high-rank Hessian approximations",
    "url": "https://arxiv.org/abs/2507.10804",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.10804v2 Announce Type: replace \nAbstract: Efficient high-rank approximations of the Hessian can accelerate seismic full waveform inversion (FWI) and uncertainty quantification (UQ). In FWI, approximations of the inverse of the Hessian may be used as preconditioners for Newton-type or quasi-Newton algorithms, reducing computational costs and improving recovery in deeper subsurface regions. In Bayesian UQ, Hessian approximations enable the construction of Markov chain Monte Carlo (MCMC) proposals that capture the directional scalings of the posterior, enhancing the efficiency of MCMC. Computing the exact Hessian is intractable for large-scale problems because the Hessian is accessible only through matrix-vector products, and performing each matrix-vector product requires costly solution of wave equations. Moreover, the Hessian is high-rank, which means that low-rank methods, often employed in large-scale inverse problems, are inefficient. We adapt two existing high-rank Hessian approximations -- the point spread function method and the pseudo-differential operator probing method. Building on an observed duality between these approaches, we develop a novel method that unifies their complementary strengths. We validate these methods on a synthetic quadratic model and on the Marmousi model. Numerical experiments show that these high-rank Hessian approximations substantially reduce the computational costs in FWI. In UQ, MCMC samples computed using no Hessian approximation or a low-rank approximation explore the posterior slowly, providing little meaningful statistical information after tens of thousands of iterations and underestimating the variance. At the same time, the effective sample size is overestimated, providing false confidence. In contrast, MCMC samples generated using the high-rank Hessian approximations provide meaningful statistical information about the posterior and more accurately assess the posterior variance.",
    "source": "arXiv"
  },
  {
    "title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array",
    "title_es": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array",
    "url": "https://arxiv.org/abs/2507.11331",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.11331v3 Announce Type: replace \nAbstract: Transformer models rely heavily on scaled dot-product attention (SDPA), typically implemented using the FlashAttention algorithm. However, current systolic-array-based accelerators face significant challenges when executing FlashAttention. Systolic arrays achieve high utilization primarily for consecutive and large matrix multiplications, whereas FlashAttention requires frequent interleaving of matrix multiplications and softmax operations.\n  The frequent data swaps between matrix multiplications on the systolic array and softmax operations on external units result in low array utilization. Moreover, when these computations run concurrently, the softmax stage contends with matrix multiplication for register file and SRAM ports, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array architecture that enables the FlashAttention algorithm to run entirely within a single systolic array, eliminating the need for external vector units. At the core of FSA is SystolicAttention, a novel scheduling algorithm that maps FlashAttention operations onto systolic arrays with fine-grained, element-wise overlap. This approach significantly improves array utilization while preserving the original floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against state-of-the-art commercial accelerators. Our results show that FSA achieves 1.77 and 4.83 times higher attention FLOPs/s utilization compared to AWS Neuron v2 and Google TPUv5e, respectively, with only 12% area overhead.",
    "source": "arXiv"
  },
  {
    "title": "From Time-series Generation, Model Selection to Transfer Learning: A Comparative Review of Pixel-wise Approaches for Large-scale Crop Mapping",
    "title_es": "From Time-series Generation, Model Selection to Transfer Learning: A Comparative Review of Pixel-wise Approaches for Large-scale Crop Mapping",
    "url": "https://arxiv.org/abs/2507.12590",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.12590v2 Announce Type: replace \nAbstract: Crop mapping involves identifying and classifying crop types using spatial data, primarily derived from remote sensing imagery. This study presents the first comprehensive review of large-scale, pixel-wise crop mapping workflows, encompassing both conventional supervised methods and emerging transfer learning approaches. To identify the optimal time-series generation approaches and supervised crop mapping models, we conducted systematic experiments, comparing six widely adopted satellite image-based preprocessing methods, alongside eleven supervised pixel-wise classification models. Additionally, we assessed the synergistic impact of varied training sample sizes and variable combinations. Moreover, we identified optimal transfer learning techniques for different magnitudes of domain shift. The evaluation of optimal methods was conducted across five diverse agricultural sites. Landsat 8 served as the primary satellite data source. Labels come from CDL trusted pixels and field surveys.\n  Our findings reveal three key insights. First, fine-scale interval preprocessing paired with Transformer models consistently delivered optimal performance for both supervised and transferable workflows. RF offered rapid training and competitive performance in conventional supervised learning and direct transfer to similar domains. Second, transfer learning techniques enhanced workflow adaptability, with UDA being effective for homogeneous crop classes while fine-tuning remains robust across diverse scenarios. Finally, workflow choice depends heavily on the availability of labeled samples. With a sufficient sample size, supervised training typically delivers more accurate and generalizable results. Below a certain threshold, transfer learning that matches the level of domain shift is a viable alternative to achieve crop mapping. All code is publicly available to encourage reproducibility practice.",
    "source": "arXiv"
  },
  {
    "title": "Leveraging LLMs for Formal Software Requirements -- Challenges and Prospects",
    "title_es": "Leveraging LLMs for Formal Software Requirements -- Challenges and Prospects",
    "url": "https://arxiv.org/abs/2507.14330",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.14330v2 Announce Type: replace \nAbstract: Software correctness is ensured mathematically through formal verification, which involves the resources of generating formal requirement specifications and having an implementation that must be verified. Tools such as model-checkers and theorem provers ensure software correctness by verifying the implementation against the specification. Formal methods deployment is regularly enforced in the development of safety-critical systems e.g. aerospace, medical devices and autonomous systems. Generating these specifications from informal and ambiguous natural language requirements remains the key challenge. Our project, VERIFAI^{1}, aims to investigate automated and semi-automated approaches to bridge this gap, using techniques from Natural Language Processing (NLP), ontology-based domain modelling, artefact reuse, and large language models (LLMs). This position paper presents a preliminary synthesis of relevant literature to identify recurring challenges and prospective research directions in the generation of verifiable specifications from informal requirements.",
    "source": "arXiv"
  },
  {
    "title": "Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking",
    "title_es": "Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking",
    "url": "https://arxiv.org/abs/2507.14455",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.14455v2 Announce Type: replace \nAbstract: Time-delay embedding is a technique that uses snapshots of state history over time to build a linear state space model of a nonlinear smooth system. We demonstrate that periodic non-smooth or hybrid system can also be modeled as a linear state space system using this approach as long as its behavior is consistent in modes and timings. We extend time-delay embeddings to generate a linear model of two periodic hybrid systems: the bouncing pendulum and the simplest walker with control inputs. This leads to a state history augmented linear quadratic regulator (LQR) which uses current and past state history for feedback control. Example code can be found at https://github.com/Chun-MingYang/koopman-timeDelay-lqr.git",
    "source": "arXiv"
  },
  {
    "title": "ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding",
    "title_es": "ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding",
    "url": "https://arxiv.org/abs/2507.14533",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.14533v2 Announce Type: replace \nAbstract: The rapid advancement of educational applications, artistic creation, and AI-generated content (AIGC) technologies has substantially increased practical requirements for comprehensive Image Aesthetics Assessment (IAA), particularly demanding methods capable of delivering both quantitative scoring and professional understanding. Multimodal Large Language Model (MLLM)-based IAA methods demonstrate stronger perceptual and generalization capabilities compared to traditional approaches, yet they suffer from modality bias (score-only or text-only) and lack fine-grained attribute decomposition, thereby failing to support further aesthetic assessment. In this paper, we present:(1) ArtiMuse, an innovative MLLM-based IAA model with Joint Scoring and Expert-Level Understanding capabilities; (2) ArtiMuse-10K, the first expert-curated image aesthetic dataset comprising 10,000 images spanning 5 main categories and 15 subcategories, each annotated by professional experts with 8-dimensional attributes analysis and a holistic score. Both the model and dataset will be made public to advance the field.",
    "source": "arXiv"
  },
  {
    "title": "An Efficient Algorithm for Generating Minimal Unique-Cause MC/DC Test cases for Singular Boolean Expressions",
    "title_es": "An Efficient Algorithm for Generating Minimal Unique-Cause MC/DC Test cases for Singular Boolean Expressions",
    "url": "https://arxiv.org/abs/2507.14687",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.14687v3 Announce Type: replace \nAbstract: Modified Condition/Decision Coverage (MC/DC) is a mandatory structural coverage criterion for ensuring the reliability and safety of critical systems. While its strictest form, Unique-Cause MC/DC, offers the highest assurance, research on its efficient test generation has been lacking. This gap is particularly significant, as an analysis of large-scale avionics systems shows that 99.7% of all conditional decisions are, in fact, Singular Boolean Expressions (SBEs) the ideal structure for applying Unique-Cause MC/DC. This paper proposes 'Robin's Rule', a deterministic algorithm that directly constructs a minimal test set of N + 1 cases to guarantee 100% Unique-Cause MC/DC for SBEs with N conditions, without generating a full truth table. To validate our approach, we constructed a benchmark by reformulating the TCAS-II specifications into SBEs and verified the results using an industry-standard, certified commercial tool. The results confirm that our method consistently achieves 100% coverage with the theoretical minimum number of tests and is more efficient than the commercial tool. This work provides a practical and provably optimal solution for verifying safety-critical systems, ensuring both rigor and efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Gait Transitions in Load-Pulling Quadrupeds: Insights from Sled Dogs and a Minimal SLIP Model",
    "title_es": "Gait Transitions in Load-Pulling Quadrupeds: Insights from Sled Dogs and a Minimal SLIP Model",
    "url": "https://arxiv.org/abs/2507.14727",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.14727v2 Announce Type: replace \nAbstract: Quadrupedal animals employ diverse galloping strategies to optimize speed, stability, and energy efficiency. However, the biomechanical mechanisms that enable adaptive gait transitions during high-speed locomotion under load remain poorly understood. In this study, we present new empirical and modeling insights into the biomechanics of load-pulling quadrupeds, using sprint sled dogs as a model system. High-speed video and force recordings reveal that sled dogs often switch between rotary and transverse galloping gaits within just a few strides and without any observable changes in speed, stride duration, or terrain, providing clear evidence of locomotor multistability during high-speed load-pulling. To investigate the mechanical basis of these transitions, a physics-based quadrupedal Spring-Loaded Inverted Pendulum model with hybrid dynamics and prescribed footfall sequences to reproduce the asymmetric galloping patterns observed in racing sled dogs. Through trajectory optimization, we replicate experimentally observed gait sequences and identify swing-leg stiffness modulation as a key control mechanism for inducing transitions. This work provides a much-needed biomechanical perspective on high-speed animal draft and establishes a modeling framework for studying locomotion in pulling quadrupeds, with implications for both biological understanding and the design of adaptive legged systems.",
    "source": "arXiv"
  },
  {
    "title": "Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry",
    "title_es": "Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry",
    "url": "https://arxiv.org/abs/2507.14931",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.14931v2 Announce Type: replace \nAbstract: Forensic mental health care involves the treatment of individuals with severe mental disorders who have committed violent offences. These settings are often characterized by high levels of bureaucracy, risk avoidance, and restricted autonomy. Patients frequently experience a profound loss of control over their lives, leading to heightened psychological stress-sometimes resulting in isolation as a safety measure. In this study, we explore how co-design can be used to collaboratively develop a companion robot that helps monitor and regulate stress while maintaining tracking of the patients' interaction behaviours for long-term intervention. We conducted four co-design workshops in a forensic psychiatric clinic with patients, caregivers, and therapists. Our process began with the presentation of an initial speculative prototype to therapists, enabling reflection on shared concerns, ethical risks, and desirable features. This was followed by a creative ideation session with patients, a third workshop focused on defining desired functions and emotional responses, and we are planning a final prototype demo to gather direct patient feedback. Our findings emphasize the importance of empowering patients in the design process and adapting proposals based on their current emotional state. The goal was to empower the patient in the design process and ensure each patient's voice was heard.",
    "source": "arXiv"
  },
  {
    "title": "AMPED: Accelerating MTTKRP for Billion-Scale Sparse Tensor Decomposition on Multiple GPUs",
    "title_es": "AMPED: Accelerating MTTKRP for Billion-Scale Sparse Tensor Decomposition on Multiple GPUs",
    "url": "https://arxiv.org/abs/2507.15121",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.15121v2 Announce Type: replace \nAbstract: Matricized Tensor Times Khatri-Rao Product (MTTKRP) is the computational bottleneck in sparse tensor decomposition. As real-world sparse tensors grow to billions of nonzeros, they increasingly demand higher memory capacity and compute throughput from hardware accelerators. In this work, we present AMPED, a multi-GPU parallel algorithm designed to accelerate MTTKRP on billion-scale sparse tensors. AMPED scales beyond the limits of a single GPU, meeting both the memory and performance requirements of large-scale workloads. We introduce a partitioning strategy combined with a dynamic load balancing scheme to distribute computation and minimize GPU idle time. On real-world billion-scale tensors, AMPED achieves a 5.1x geometric mean speedup in total execution time over state-of-the-art GPU baselines using 4 GPUs on a single CPU node.",
    "source": "arXiv"
  },
  {
    "title": "TalkLess: Blending Extractive and Abstractive Speech Summarization for Editing Speech to Preserve Content and Style",
    "title_es": "TalkLess: Blending Extractive and Abstractive Speech Summarization for Editing Speech to Preserve Content and Style",
    "url": "https://arxiv.org/abs/2507.15202",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.15202v2 Announce Type: replace \nAbstract: Millions of people listen to podcasts, audio stories, and lectures, but editing speech remains tedious and time-consuming. Creators remove unnecessary words, cut tangential discussions, and even re-record speech to make recordings concise and engaging. Prior work automatically summarized speech by removing full sentences (extraction), but rigid extraction limits expressivity. AI tools can summarize then re-synthesize speech (abstraction), but abstraction strips the speaker's style. We present TalkLess, a system that flexibly combines extraction and abstraction to condense speech while preserving its content and style. To edit speech, TalkLess first generates possible transcript edits, selects edits to maximize compression, coverage, and audio quality, then uses a speech editing model to translate transcript edits into audio edits. TalkLess's interface provides creators control over automated edits by separating low-level wording edits (via the compression pane) from major content edits (via the outline pane). TalkLess achieves higher coverage and removes more speech errors than a state-of-the-art extractive approach. A comparison study (N=12) showed that TalkLess significantly decreased cognitive load and editing effort in speech editing. We further demonstrate TalkLess's potential in an exploratory study (N=3) where creators edited their own speech.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation",
    "title_es": "Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation",
    "url": "https://arxiv.org/abs/2507.15709",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.15709v2 Announce Type: replace \nAbstract: Face image quality assessment (FIQA) is essential for various face-related applications. Although FIQA has been extensively studied and achieved significant progress, the computational complexity of FIQA algorithms remains a key concern for ensuring scalability and practical deployment in real-world systems. In this paper, we aim to develop a computationally efficient FIQA method that can be easily deployed in real-world applications. Specifically, our method consists of two stages: training a powerful teacher model and distilling a lightweight student model from it. To build a strong teacher model, we adopt a self-training strategy to improve its capacity. We first train the teacher model using labeled face images, then use it to generate pseudo-labels for a set of unlabeled images. These pseudo-labeled samples are used in two ways: (1) to distill knowledge into the student model, and (2) to combine with the original labeled images to further enhance the teacher model through self-training. The enhanced teacher model is used to further pseudo-label another set of unlabeled images for distilling the student models. The student model is trained using a combination of labeled images, pseudo-labeled images from the original teacher model, and pseudo-labeled images from the enhanced teacher model. Experimental results demonstrate that our student model achieves comparable performance to the teacher model with an extremely low computational overhead. Moreover, our method achieved first place in the ICCV 2025 VQualA FIQA Challenge. The code is available at https://github.com/sunwei925/Efficient-FIQA.git.",
    "source": "arXiv"
  },
  {
    "title": "R4ec: A Reasoning, Reflection, and Refinement Framework for Recommendation Systems",
    "title_es": "R4ec: A Reasoning, Reflection, and Refinement Framework for Recommendation Systems",
    "url": "https://arxiv.org/abs/2507.17249",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.17249v2 Announce Type: replace \nAbstract: Harnessing Large Language Models (LLMs) for recommendation systems has emerged as a prominent avenue, drawing substantial research interest. However, existing approaches primarily involve basic prompt techniques for knowledge acquisition, which resemble System-1 thinking. This makes these methods highly sensitive to errors in the reasoning path, where even a small mistake can lead to an incorrect inference. To this end, in this paper, we propose $R^{4}$ec, a reasoning, reflection and refinement framework that evolves the recommendation system into a weak System-2 model. Specifically, we introduce two models: an actor model that engages in reasoning, and a reflection model that judges these responses and provides valuable feedback. Then the actor model will refine its response based on the feedback, ultimately leading to improved responses. We employ an iterative reflection and refinement process, enabling LLMs to facilitate slow and deliberate System-2-like thinking. Ultimately, the final refined knowledge will be incorporated into a recommendation backbone for prediction. We conduct extensive experiments on Amazon-Book and MovieLens-1M datasets to demonstrate the superiority of $R^{4}$ec. We also deploy $R^{4}$ec on a large scale online advertising platform, showing 2.2\\% increase of revenue. Furthermore, we investigate the scaling properties of the actor model and reflection model.",
    "source": "arXiv"
  },
  {
    "title": "Realisability and Complementability of Multiparty Session Types",
    "title_es": "Realisability and Complementability of Multiparty Session Types",
    "url": "https://arxiv.org/abs/2507.17354",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.17354v2 Announce Type: replace \nAbstract: Multiparty session types (MPST) are a type-based approach for specifying message-passing distributed systems. They rely on the notion of global type specifying the global behaviour and local types, which are the projections of the global behaviour onto each local participant. An essential property of global types is realisability, i.e., whether the composition of the local behaviours conforms to those specified by the global type. We explore how realisability of MPST relates to their complementability, i.e., whether there exists a global type that describes the complementary behaviour of the original global type. First, we show that if a global type is realisable with p2p communications, then it is realisable with synchronous communications. Second, we show that if a global type is realisable in the synchronous model, then it is complementable, in the sense that there exists a global type that describes the complementary behaviour of the original global type.  Third, we give an algorithm to decide whether a complementable global type, given with an explicit complement, is realisable in p2p. As a side contribution, we propose a complementation construction for global types with sender-driven choice, and more generally commutation-deterministic, with a linear blowup in the size of the global type.",
    "source": "arXiv"
  },
  {
    "title": "WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM Pre-training",
    "title_es": "WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM Pre-training",
    "url": "https://arxiv.org/abs/2507.17634",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.17634v2 Announce Type: replace \nAbstract: Recent advances in learning rate (LR) scheduling have demonstrated the effectiveness of decay-free approaches that eliminate the traditional decay phase while maintaining competitive performance. Model merging techniques have emerged as particularly promising solutions in this domain. We present Warmup-Stable and Merge (WSM), a general framework that establishes a formal connection between learning rate decay and model merging. WSM provides a unified theoretical foundation for emulating various decay strategies-including cosine decay, linear decay and inverse square root decay-as principled model averaging schemes, while remaining fully compatible with diverse optimization methods. Through extensive experiments, we identify merge duration-the training window for checkpoint aggregation-as the most critical factor influencing model performance, surpassing the importance of both checkpoint interval and merge quantity. Our framework consistently outperforms the widely-adopted Warmup-Stable-Decay (WSD) approach across multiple benchmarks, achieving significant improvements of +3.5% on MATH, +2.9% on HumanEval, and +5.5% on MMLU-Pro. The performance advantages extend to supervised fine-tuning scenarios, highlighting WSM's potential for long-term model refinement.",
    "source": "arXiv"
  },
  {
    "title": "Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models",
    "title_es": "Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models",
    "url": "https://arxiv.org/abs/2507.17702",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.17702v3 Announce Type: replace \nAbstract: Mixture-of-Experts (MoE) has become a dominant architecture for scaling Large Language Models (LLMs) efficiently by decoupling total parameters from computational cost. However, this decoupling creates a critical challenge: predicting the model capacity of a given MoE configurations (e.g., expert activation ratio and granularity) remains an unresolved problem. To address this gap, we introduce Efficiency Leverage (EL), a metric quantifying the computational advantage of an MoE model over a dense equivalent. We conduct a large-scale empirical study, training over 300 models up to 28B parameters, to systematically investigate the relationship between MoE architectural configurations and EL. Our findings reveal that EL is primarily driven by the expert activation ratio and the total compute budget, both following predictable power laws, while expert granularity acts as a non-linear modulator with a clear optimal range. We integrate these discoveries into a unified scaling law that accurately predicts the EL of an MoE architecture based on its configuration. To validate our derived scaling laws, we designed and trained Ling-mini-beta, a pilot model for Ling-2.0 series with only 0.85B active parameters, alongside a 6.1B dense model for comparison. When trained on an identical 1T high-quality token dataset, Ling-mini-beta matched the performance of the 6.1B dense model while consuming over 7x fewer computational resources, thereby confirming the accuracy of our scaling laws. This work provides a principled and empirically-grounded foundation for the scaling of efficient MoE models.",
    "source": "arXiv"
  },
  {
    "title": "A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation",
    "title_es": "A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation",
    "url": "https://arxiv.org/abs/2507.17856",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.17856v3 Announce Type: replace \nAbstract: Designing a model predictive control (MPC) scheme that enables a mobile robot to safely navigate through an obstacle-filled environment is a complicated yet essential task in robotics. In this technical report, safety refers to ensuring that the robot respects state and input constraints while avoiding collisions with obstacles despite the presence of disturbances and measurement noise. This report offers a step-by-step approach to implementing nonlinear model predictive control (NMPC) schemes addressing these safety requirements. Numerous books and survey papers provide comprehensive overviews of linear MPC (LMPC), NMPC, and their applications in various domains, including robotics. This report does not aim to replicate those exhaustive reviews. Instead, it focuses specifically on NMPC as a foundation for safe mobile robot navigation. The goal is to provide a practical and accessible path from theoretical concepts to mathematical proofs and implementation, emphasizing safety and performance guarantees. It is intended for researchers, robotics engineers, and practitioners seeking to bridge the gap between theoretical NMPC formulations and real-world robotic applications.\n  This report is not necessarily meant to remain fixed over time. If someone finds an error in the presented theory, please reach out via the given email addresses. We are happy to update the document if necessary.",
    "source": "arXiv"
  },
  {
    "title": "AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation",
    "title_es": "AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation",
    "url": "https://arxiv.org/abs/2507.17957",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.17957v2 Announce Type: replace \nAbstract: In Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS), a model is trained on labeled source domain data (e.g., synthetic images) and adapted to an unlabeled target domain (e.g., real-world images) without access to target annotations. Existing UDA-SS methods often struggle to balance fine-grained local details with global contextual information, leading to segmentation errors in complex regions. To address this, we introduce the Adaptive Feature Refinement (AFR) module, which enhances segmentation accuracy by refining highresolution features using semantic priors from low-resolution logits. AFR also integrates high-frequency components, which capture fine-grained structures and provide crucial boundary information, improving object delineation. Additionally, AFR adaptively balances local and global information through uncertaintydriven attention, reducing misclassifications. Its lightweight design allows seamless integration into HRDA-based UDA methods, leading to state-of-the-art segmentation performance. Our approach improves existing UDA-SS methods by 1.05% mIoU on GTA V --> Cityscapes and 1.04% mIoU on Synthia-->Cityscapes. The implementation of our framework is available at: https://github.com/Masrur02/AFRDA",
    "source": "arXiv"
  },
  {
    "title": "How is science discussed on Bluesky?",
    "title_es": "How is science discussed on Bluesky?",
    "url": "https://arxiv.org/abs/2507.18840",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.18840v2 Announce Type: replace \nAbstract: Amid the migration of academics from X, the social media platform Bluesky has emerged as a potential alternative. To assess its viability and relevance for science communication, this study presents the first large-scale analysis of scholarly article dissemination on Bluesky, exploring its potential as a new source of social media metrics. We collected and analysed over 2.6 million Bluesky posts referencing 532,302 scholarly articles from January 2023 to July 2025, integrating metadata from the OpenAlex database. Temporal trends, disciplinary coverage, language use, textual characteristics, and user engagement were examined. A sharp increase in scholarly activity on Bluesky was observed from November 2024 to January 2025, coinciding with broader academic shifts away from X. As on X, Bluesky posts primarily concern the health, social, and environmental sciences and are predominantly written in English. Nevertheless, Bluesky posts demonstrate substantially higher levels of interaction (likes, reposts, replies, and quotes) and greater textual originality than previously reported for X, suggesting both stronger interactive and more interpretive engagement. These findings highlight Bluesky's emerging role as a credible platform for science communication and a promising source for altmetrics. The platform may facilitate not only early visibility of research outputs but also more meaningful scholarly dialogue in the evolving social media landscape.",
    "source": "arXiv"
  },
  {
    "title": "A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation",
    "title_es": "A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation",
    "url": "https://arxiv.org/abs/2507.19045",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.19045v2 Announce Type: replace \nAbstract: In multi-center scenarios, One-Shot Federated Learning (OSFL) has attracted increasing attention due to its low communication overhead, requiring only a single round of transmission. However, existing generative model-based OSFL methods suffer from low training efficiency and potential privacy leakage in the healthcare domain. Additionally, achieving convergence within a single round of model aggregation is challenging under non-Independent and Identically Distributed (non-IID) data. To address these challenges, in this paper a modified OSFL framework is proposed, in which a new Feature-Guided Rectified Flow Model (FG-RF) and Dual-Layer Knowledge Distillation (DLKD) aggregation method are developed. FG-RF on the client side accelerates generative modeling in medical imaging scenarios while preserving privacy by synthesizing feature-level images rather than pixel-level images. To handle non-IID distributions, DLKD enables the global student model to simultaneously mimic the output logits and align the intermediate-layer features of client-side teacher models during aggregation. Experimental results on three non-IID medical imaging datasets show that our new framework and method outperform multi-round federated learning approaches, achieving up to 21.73% improvement, and exceeds the baseline FedISCA by an average of 21.75%. Furthermore, our experiments demonstrate that feature-level synthetic images significantly reduce privacy leakage risks compared to pixel-level synthetic images. The code is available at https://github.com/LMIAPC/one-shot-fl-medical.",
    "source": "arXiv"
  },
  {
    "title": "ChipletPart: Cost-Aware Partitioning for 2.5D Systems",
    "title_es": "ChipletPart: Cost-Aware Partitioning for 2.5D Systems",
    "url": "https://arxiv.org/abs/2507.19819",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.19819v2 Announce Type: replace \nAbstract: Industry adoption of chiplets has been increasing as a cost-effective option for making larger high-performance systems. Consequently, partitioning large systems into chiplets is increasingly important. In this work, we introduce ChipletPart - a cost-driven 2.5D system partitioner that addresses the unique constraints of chiplet systems, including complex objective functions, limited reach of inter-chiplet I/O transceivers, and the assignment of heterogeneous manufacturing technologies to different chiplets. ChipletPart integrates a sophisticated chiplet cost model with its underlying genetic algorithm-based technology assignment and partitioning methodology, along with a simulated annealing-based chiplet floorplanner. Our results show that: (i) ChipletPart reduces chiplet cost by up to 58% (20% geometric mean) compared to state-of-the-art min-cut partitioners, which often yield floorplan-infeasible solutions; (ii) ChipletPart generates partitions with up to 47% (6% geometric mean) lower cost as compared to the prior work Floorplet; and (iii) for the testcases we study, heterogeneous integration reduces cost by up to 43% (15% geometric mean) compared to homogeneous implementations. Additionally, we explore Bayesian optimization (BO) for finding low cost and floorplan-feasible chiplet solutions with technology assignments. On some testcases, our BO framework achieves better system cost (up to 5.3% improvement) with higher runtime overhead (up to 4x) compared to our GA framework. We also present case studies that show how changes in packaging and inter-chiplet signaling technologies can affect partitioning solutions. Finally, we make ChipletPart, the underlying chiplet cost model, and a chiplet testcase generator available as open-source tools for the community.",
    "source": "arXiv"
  },
  {
    "title": "FROSS: Faster-than-Real-Time Online 3D Semantic Scene Graph Generation from RGB-D Images",
    "title_es": "FROSS: Faster-than-Real-Time Online 3D Semantic Scene Graph Generation from RGB-D Images",
    "url": "https://arxiv.org/abs/2507.19993",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.19993v2 Announce Type: replace \nAbstract: The ability to abstract complex 3D environments into simplified and structured representations is crucial across various domains. 3D semantic scene graphs (SSGs) achieve this by representing objects as nodes and their interrelationships as edges, facilitating high-level scene understanding. Existing methods for 3D SSG generation, however, face significant challenges, including high computational demands and non-incremental processing that hinder their suitability for real-time open-world applications. To address this issue, we propose FROSS (Faster-than-Real-Time Online 3D Semantic Scene Graph Generation), an innovative approach for online and faster-than-real-time 3D SSG generation that leverages the direct lifting of 2D scene graphs to 3D space and represents objects as 3D Gaussian distributions. This framework eliminates the dependency on precise and computationally-intensive point cloud processing. Furthermore, we extend the Replica dataset with inter-object relationship annotations, creating the ReplicaSSG dataset for comprehensive evaluation of FROSS. The experimental results from evaluations on ReplicaSSG and 3DSSG datasets show that FROSS can achieve superior performance while operating significantly faster than prior 3D SSG generation methods. Our implementation and dataset are publicly available at https://github.com/Howardkhh/FROSS.",
    "source": "arXiv"
  },
  {
    "title": "A generalized ENO reconstruction in compact GKS for compressible flow simulations",
    "title_es": "A generalized ENO reconstruction in compact GKS for compressible flow simulations",
    "url": "https://arxiv.org/abs/2507.20461",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.20461v2 Announce Type: replace \nAbstract: This paper presents a generalized ENO (GENO)-type nonlinear reconstruction scheme for compressible flow simulations. The proposed reconstruction preserves the accuracy of the linear scheme while maintaining essentially non-oscillatory behavior at discontinuities. By generalizing the adaptive philosophy of ENO schemes, the method employs a smooth path function that directly connects high-order linear reconstruction with a reliable lower-order alternative. This direct adaptive approach significantly simplifies the construction of nonlinear schemes, particularly for very high-order methods on unstructured meshes. A comparative analysis with various WENO methods demonstrates the reliability and accuracy of the proposed reconstruction, which provides an optimal transition between linear and nonlinear reconstructions across all limiting cases based on stencil smoothness. The consistency and performance of the GENO reconstruction are validated through implementation in both high-order compact gas-kinetic schemes (GKS) and non-compact Riemann-solver-based methods. Benchmark tests confirm the robustness and shock-capturing capabilities of GENO, with particularly superior performance when integrated with compact schemes. This work advances the construction methodology of nonlinear schemes and establishes ENO-type reconstruction as a mature and practical approach for engineering applications.",
    "source": "arXiv"
  },
  {
    "title": "Learning Phonetic Context-Dependent Viseme for Enhancing Speech-Driven 3D Facial Animation",
    "title_es": "Learning Phonetic Context-Dependent Viseme for Enhancing Speech-Driven 3D Facial Animation",
    "url": "https://arxiv.org/abs/2507.20568",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.20568v2 Announce Type: replace \nAbstract: Speech-driven 3D facial animation aims to generate realistic facial movements synchronized with audio. Traditional methods primarily minimize reconstruction loss by aligning each frame with ground-truth. However, this frame-wise approach often fails to capture the continuity of facial motion, leading to jittery and unnatural outputs due to coarticulation. To address this, we propose a novel phonetic context-aware loss, which explicitly models the influence of phonetic context on viseme transitions. By incorporating a viseme coarticulation weight, we assign adaptive importance to facial movements based on their dynamic changes over time, ensuring smoother and perceptually consistent animations. Extensive experiments demonstrate that replacing the conventional reconstruction loss with ours improves both quantitative metrics and visual quality. It highlights the importance of explicitly modeling phonetic context-dependent visemes in synthesizing natural speech-driven 3D facial animation. Project page: https://cau-irislab.github.io/interspeech25/",
    "source": "arXiv"
  },
  {
    "title": "TARS: MinMax Token-Adaptive Preference Strategy for MLLM Hallucination Reduction",
    "title_es": "TARS: MinMax Token-Adaptive Preference Strategy for MLLM Hallucination Reduction",
    "url": "https://arxiv.org/abs/2507.21584",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.21584v3 Announce Type: replace \nAbstract: Multimodal large language models (MLLMs) enable vision-language reasoning, yet often generate plausible outputs that are factually incorrect or visually ungrounded, thereby compromising their reliability. Direct preference optimization (DPO) is a common strategy for correcting hallucinations by aligning model outputs with human preferences. Existing DPO strategies typically treat hallucination-related preferences as fixed targets, relying on static supervision signals during training. This approach tends to overfit to superficial linguistic cues in preference data, leading to distributional rigidity and spurious correlations that impair grounding in causally relevant visual information. To overcome this limitation, we propose TARS, a token-adaptive preference strategy that reformulates DPO as a min-max optimization problem. TARS maximizes token-level distributional shifts under semantic constraints to simulate alignment uncertainty, and simultaneously minimizes the expected preference loss under these controlled perturbations. This joint objective preserves causal grounding while mitigating overfitting to preference patterns, thereby reducing hallucinations in multimodal reasoning. We evaluate TARS on multiple hallucination benchmarks and find consistently strong performance. Using only 4.8k preference samples and no expert feedback, TARS reduces hallucination rates from 26.4% to 13.2% and decreases cognition value from 2.5 to 0.4. It outperforms standard DPO and matches GPT-4o on several key metrics.",
    "source": "arXiv"
  },
  {
    "title": "UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding",
    "title_es": "UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding",
    "url": "https://arxiv.org/abs/2507.22025",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.22025v3 Announce Type: replace \nAbstract: The emergence of Multimodal Large Language Models (MLLMs) has driven significant advances in Graphical User Interface (GUI) agent capabilities. Nevertheless, existing GUI agent training and inference techniques still suffer from a dilemma for reasoning designs, ineffective reward, and visual noise. To address these issues, we introduce UI-AGILE for enhancing GUI agents at both training and inference. For training, we propose a suite of improvements to the Supervised Fine-Tuning (SFT) process: 1) a continuous reward function to incentivize high-precision grounding; 2) a ``Simple Thinking'' reward to balance planning with speed and grounding accuracy; and 3) a cropping-based resampling strategy to mitigate the sparse reward problem and improve learning on complex tasks. For inference, we present decomposed grounding with selection to dramatically improve grounding accuracy on high-resolution displays by breaking the image into smaller, manageable parts. Experiments show that UI-AGILE achieves the state-of-the-art grounding performance on two benchmarks ScreenSpot-Pro and ScreenSpot-v2 while it also exhibits strong general agent capabilities. For instance, using both our training and inference enhancement methods brings 23\\% grounding accuracy improvement over the best baseline on ScreenSpot-Pro. We provide the code in https://github.com/KDEGroup/UI-AGILE.",
    "source": "arXiv"
  },
  {
    "title": "IntentFlow: Interactive Support for Communicating Intent with LLMs in Writing Tasks",
    "title_es": "IntentFlow: Interactive Support for Communicating Intent with LLMs in Writing Tasks",
    "url": "https://arxiv.org/abs/2507.22134",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.22134v2 Announce Type: replace \nAbstract: While large language models (LLMs) are widely used for writing, users often struggle to express their nuanced and evolving intents through prompt-based interfaces. Intents -- low-level strategies or preferences for achieving a writing goal -- are often vague, fluid, or even subconscious, making it difficult for users to articulate and adjust them. To address this, we present IntentFlow, which supports the communication of dynamically evolving intents throughout LLM-assisted writing. IntentFlow extracts goals and intents from user prompts and presents them as editable interface components, which users can revise, remove, or refine via direct manipulation or follow-up prompts. Visual links connect each component to the output segments it influences, helping users understand model behavior. In a within-subjects study (N=12), participants using IntentFlow, compared to a chat-based baseline, expressed their intents more easily and in detail, engaged in more meaningful actions to communicate intents, such as adjusting and deleting, and produced outputs that better aligned with their evolving intents. We found that editable intent representations help users refine and consolidate a final set of intents, which can be reused across similar tasks to support consistent and transferable LLM-assisted writing.",
    "source": "arXiv"
  },
  {
    "title": "A Node on the Constellation: The Role of Feminist Makerspaces in Building and Sustaining Alternative Cultures of Technology Production",
    "title_es": "A Node on the Constellation: The Role of Feminist Makerspaces in Building and Sustaining Alternative Cultures of Technology Production",
    "url": "https://arxiv.org/abs/2507.22329",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.22329v2 Announce Type: replace \nAbstract: Feminist makerspaces offer community led alternatives to dominant tech cultures by centering care, mutual aid, and collective knowledge production. While prior CSCW research has explored their inclusive practices, less is known about how these spaces sustain themselves over time. Drawing on interviews with 18 founders and members across 8 U.S. feminist makerspaces as well as autoethnographic reflection, we examine the organizational and relational practices that support long-term endurance. We find that sustainability is not achieved through growth or institutionalization, but through care-driven stewardship, solidarity with local justice movements, and shared governance. These social practices position feminist makerspaces as prefigurative counterspaces - sites that enact, rather than defer, feminist values in everyday practice. This paper offers empirical insight into how feminist makerspaces persist amid structural precarity, and highlights the forms of labor and coalition-building that underpin alternative sociotechnical infrastructures.",
    "source": "arXiv"
  },
  {
    "title": "Language Arithmetics: Towards Systematic Language Neuron Identification and Manipulation",
    "title_es": "Language Arithmetics: Towards Systematic Language Neuron Identification and Manipulation",
    "url": "https://arxiv.org/abs/2507.22608",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.22608v2 Announce Type: replace \nAbstract: Large language models (LLMs) exhibit strong multilingual abilities, yet the neural mechanisms behind language-specific processing remain unclear. We analyze language-specific neurons in Llama-3.1-8B, Mistral-Nemo-12B, and Aya-Expanse-8B & 32B across 21 typologically diverse languages, identifying neurons that control language behavior. Using the Language Activation Probability Entropy (LAPE) method, we show that these neurons cluster in deeper layers, with non-Latin scripts showing greater specialization. Related languages share overlapping neurons, reflecting internal representations of linguistic proximity.\n  Through language arithmetics, i.e. systematic activation addition and multiplication, we steer models to deactivate unwanted languages and activate desired ones, outperforming simpler replacement approaches. These interventions effectively guide behavior across five multilingual tasks: language forcing, translation, QA, comprehension, and NLI. Manipulation is more successful for high-resource languages, while typological similarity improves effectiveness. We also demonstrate that cross-lingual neuron steering enhances downstream performance and reveal internal \"fallback\" mechanisms for language selection when neurons are progressively deactivated. Our code is made publicly available at https://github.com/d-gurgurov/Language-Neurons-Manipulation.",
    "source": "arXiv"
  },
  {
    "title": "A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for Reinforcement Learning under a Generative Model",
    "title_es": "A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for Reinforcement Learning under a Generative Model",
    "url": "https://arxiv.org/abs/2507.22854",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.22854v2 Announce Type: replace \nAbstract: We propose novel classical and quantum online algorithms for learning finite-horizon and infinite-horizon average-reward Markov Decision Processes (MDPs). Our algorithms are based on a hybrid exploration-generative reinforcement learning (RL) model wherein the agent can, from time to time, freely interact with the environment in a generative sampling fashion, i.e., by having access to a \"simulator\". By employing known classical and new quantum algorithms for approximating optimal policies under a generative model within our learning algorithms, we show that it is possible to avoid several paradigms from RL like \"optimism in the face of uncertainty\" and \"posterior sampling\" and instead compute and use optimal policies directly, which yields better regret bounds compared to previous works. For finite-horizon MDPs, our quantum algorithms obtain regret bounds which only depend logarithmically on the number of time steps $T$, thus breaking the $O(\\sqrt{T})$ classical barrier. This matches the time dependence of the prior quantum works of Ganguly et al. (arXiv'23) and Zhong et al. (ICML'24), but with improved dependence on other parameters like state space size $S$ and action space size $A$. For infinite-horizon MDPs, our classical and quantum bounds still maintain the $O(\\sqrt{T})$ dependence but with better $S$ and $A$ factors. Nonetheless, we propose a novel measure of regret for infinite-horizon MDPs with respect to which our quantum algorithms have $\\operatorname{poly}\\log{T}$ regret, exponentially better compared to classical algorithms. Finally, we generalise all of our results to compact state spaces.",
    "source": "arXiv"
  },
  {
    "title": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations",
    "title_es": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations",
    "url": "https://arxiv.org/abs/2507.22919",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.22919v2 Announce Type: replace \nAbstract: Objectives: With accurate estimates of expected safety results, clinical trials could be better designed and monitored. We evaluated methods for predicting serious adverse event (SAE) results in clinical trials using information only from their registrations prior to the trial. Material and Methods: We analyzed 22,107 two-arm parallel interventional clinical trials from ClinicalTrials.gov with structured summary results. Two prediction models were developed: a classifier predicting whether a greater proportion of participants in an experimental arm would have SAEs (area under the receiver operating characteristic curve; AUC) compared to the control arm, and a regression model to predict the proportion of participants with SAEs in the control arms (root mean squared error; RMSE). A transfer learning approach using pretrained language models (e.g., ClinicalT5, BioBERT) was used for feature extraction, combined with a downstream model for prediction. To maintain semantic representation in long trial texts exceeding localized language model input limits, a sliding window method was developed for embedding extraction. Results: The best model (ClinicalT5+Transformer+MLP) had 77.6% AUC when predicting which trial arm had a higher proportion of SAEs. When predicting SAE proportion in the control arm, the same model achieved RMSE of 18.6%. The sliding window approach consistently outperformed direct comparisons. Across 12 classifiers, the average absolute AUC increase was 2.00%, and absolute RMSE reduction was 1.58% across 12 regressors. Discussion: Summary results data from ClinicalTrials.gov remains underutilized. Predicted results of publicly reported trials provides an opportunity to identify discrepancies between expected and reported safety results.",
    "source": "arXiv"
  },
  {
    "title": "In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion",
    "title_es": "In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion",
    "url": "https://arxiv.org/abs/2507.23053",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.23053v2 Announce Type: replace \nAbstract: Quadruped robots face persistent challenges in achieving versatile locomotion due to limitations in reference motion data diversity. To address these challenges, we introduce an in-between motion generation based multi-style quadruped robot locomotion framework. We propose a CVAE based motion generator, synthesizing multi-style dynamically feasible locomotion sequences between arbitrary start and end states. By embedding physical constraints and leveraging joint poses based phase manifold continuity, this component produces physically plausible motions spanning multiple gait modalities while ensuring kinematic compatibility with robotic morphologies. We train the imitation policy based on generated data, which validates the effectiveness of generated motion data in enhancing controller stability and improving velocity tracking performance. The proposed framework demonstrates significant improvements in velocity tracking and deployment stability. We successfully deploy the framework on a real-world quadruped robot, and the experimental validation confirms the framework's capability to generate and execute complex motion profiles, including gallop, tripod, trotting and pacing.",
    "source": "arXiv"
  },
  {
    "title": "MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction",
    "title_es": "MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction",
    "url": "https://arxiv.org/abs/2507.23597",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.23597v3 Announce Type: replace \nAbstract: We present MoGA, a novel method to reconstruct high-fidelity 3D Gaussian avatars from a single-view image. The main challenge lies in inferring unseen appearance and geometric details while ensuring 3D consistency and realism. Most previous methods rely on 2D diffusion models to synthesize unseen views; however, these generated views are sparse and inconsistent, resulting in unrealistic 3D artifacts and blurred appearance. To address these limitations, we leverage a generative avatar model, that can generate diverse 3D avatars by sampling deformed Gaussians from a learned prior distribution. Due to limited 3D training data, such a 3D model alone cannot capture all image details of unseen identities. Consequently, we integrate it as a prior, ensuring 3D consistency by projecting input images into its latent space and enforcing additional 3D appearance and geometric constraints. Our novel approach formulates Gaussian avatar creation as model inversion by fitting the generative avatar to synthetic views from 2D diffusion models. The generative avatar provides an initialization for model fitting, enforces 3D regularization, and helps in refining pose. Experiments show that our method surpasses state-of-the-art techniques and generalizes well to real-world scenarios. Our Gaussian avatars are also inherently animatable. For code, see https://zj-dong.github.io/MoGA/.",
    "source": "arXiv"
  },
  {
    "title": "TextQuests: How Good are LLMs at Text-Based Video Games?",
    "title_es": "TextQuests: How Good are LLMs at Text-Based Video Games?",
    "url": "https://arxiv.org/abs/2507.23701",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.23701v2 Announce Type: replace \nAbstract: Evaluating AI agents within complex, interactive environments that mirror real-world challenges is critical for understanding their practical capabilities. While existing agent benchmarks effectively assess skills like tool use or performance on structured tasks, they often do not fully capture an agent's ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. To spur the development of agents capable of more robust intrinsic reasoning over long horizons, we introduce TextQuests, a benchmark based on the Infocom suite of interactive fiction games. These text-based adventures, which can take human players over 30 hours and require hundreds of precise actions to solve, serve as an effective proxy for evaluating AI agents on focused, stateful tasks. The benchmark is specifically designed to assess an LLM agent's capacity for self-contained problem-solving by precluding the use of external tools, thereby focusing on intrinsic long-context reasoning capabilities in an exploratory environment characterized by the need for trial-and-error learning and sustained problem-solving within a single interactive session. We release TextQuests at https://textquests.ai.",
    "source": "arXiv"
  },
  {
    "title": "Is neural semantic parsing good at ellipsis resolution, or isn't it?",
    "title_es": "Is neural semantic parsing good at ellipsis resolution, or isn't it?",
    "url": "https://arxiv.org/abs/2508.00121",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.00121v2 Announce Type: replace \nAbstract: Neural semantic parsers have shown good overall performance for a variety of linguistic phenomena, reaching semantic matching scores of more than 90%. But how do such parsers perform on strongly context-sensitive phenomena, where large pieces of semantic information need to be duplicated to form a meaningful semantic representation? A case in point is English verb phrase ellipsis, a construct where entire verb phrases can be abbreviated by a single auxiliary verb. Are the otherwise known as powerful semantic parsers able to deal with ellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with their fully resolved meaning representation and used this as a challenge set for a large battery of neural semantic parsers. Although these parsers performed very well on the standard test set, they failed in the instances with ellipsis. Data augmentation helped improve the parsing results. The reason for the difficulty of parsing elided phrases is not that copying semantic material is hard, but that usually occur in linguistically complicated contexts causing most of the parsing errors.",
    "source": "arXiv"
  },
  {
    "title": "STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers",
    "title_es": "STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers",
    "url": "https://arxiv.org/abs/2508.00387",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.00387v3 Announce Type: replace \nAbstract: Transformer-based Spiking Neural Networks (SNNs) suffer from a great performance gap compared to floating-point \\mbox{Artificial} Neural Networks (ANNs) due to the binary nature of spike trains. Recent efforts have introduced deep-level feedback loops to transmit high-level semantic information to narrow this gap. However, these designs often span \\mbox{multiple} deep layers, resulting in costly feature transformations, higher parameter overhead, increased energy consumption, and longer inference latency. To address this issue, we propose Shallow-level Temporal Feedback (STF), a lightweight plug-and-play module for the encoding layer, which consists of Temporal-Spatial Position Embedding (TSPE) and Temporal Feedback (TF). Extensive experiments show that STF consistently improves performance across various Transformer-based SNN backbones on static datasets, including CIFAR-10, CIFAR-100, and ImageNet-1K, under different spike timestep settings. Further analysis reveals that STF enhances the diversity of spike patterns, which is key to performance gain. Moreover, evaluations on adversarial robustness and temporal sensitivity confirm that STF outperforms direct coding and its variants, highlighting its potential as a new spike encoding scheme for static scenarios. Our code will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network",
    "title_es": "ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network",
    "url": "https://arxiv.org/abs/2508.00429",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.00429v3 Announce Type: replace \nAbstract: Graph Neural Networks (GNNs) have achieved remarkable success in graph-based learning by propagating information among neighbor nodes via predefined aggregation mechanisms. However, such fixed schemes often suffer from two key limitations. First, they cannot handle the imbalance in node informativeness -- some nodes are rich in information, while others remain sparse. Second, predefined message passing primarily leverages local structural similarity while ignoring global semantic relationships across the graph, limiting the model's ability to capture distant but relevant information. We propose Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework that empowers each node with autonomous, node-level decision-making. Each node acts as an agent that independently plans its next action based on its internal memory, enabling node-level planning and adaptive message propagation. Additionally, retrieval-augmented generation (RAG) allows nodes to access semantically relevant content and build global relationships in the graph. ReaGAN achieves competitive performance under few-shot in-context settings using a frozen LLM backbone without fine-tuning, showcasing the potential of agentic planning and local-global retrieval in graph learning.",
    "source": "arXiv"
  },
  {
    "title": "DGEMM without FP64 Arithmetic -- Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme",
    "title_es": "DGEMM without FP64 Arithmetic -- Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme",
    "url": "https://arxiv.org/abs/2508.00441",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.00441v2 Announce Type: replace \nAbstract: As the demand for AI computations rapidly increases, more hardware is being developed to efficiently perform the low-precision matrix multiplications required by such workloads. However, these operations are generally not directly applicable to scientific computations due to accuracy requirements. The Ozaki scheme -- an accurate matrix multiplication method proposed by Ozaki et al. in 2012 -- enables FP64 matrix multiplication (DGEMM) using low-precision matrix multiplication units, such as FP16 Tensor Cores. This approach has since been extended to utilize integer arithmetic, offering lower computational cost compared to floating-point-based implementations. In fact, it has achieved higher performance than hardware FP64 operations on GPUs equipped with fast INT8 Tensor Cores designed for AI workloads. However, recent hardware trends have shifted toward improving the performance of low-precision floating-point operations, such as FP8, rather than integer operations. Motivated by this shift, this study revisits the use of low-precision floating-point operations in the Ozaki scheme. Specifically, we explore the use of FP8 Tensor Cores to perform DGEMM. In addition, for processors that support very slow or no FP64 operations, we also consider FP64 emulation based on integer arithmetic. Furthermore, we explore the use of blocking in the inner-product direction to accelerate FP16-based implementations. We demonstrate the effectiveness of these methods by evaluating the performance on an NVIDIA Blackwell architecture GPU.",
    "source": "arXiv"
  },
  {
    "title": "A Frame for Communication Control",
    "title_es": "A Frame for Communication Control",
    "url": "https://arxiv.org/abs/2508.00485",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.00485v2 Announce Type: replace \nAbstract: We are experiencing the rise of ChatGPT-like systems or LLMs in political turbulent times. We assume the need to regulate their use because of their bubble-shaping and polarizing potential. To regulate, we need a language that allows interests and compromises to be discussed. In this context, we can think of such a shared language as a jargon, a specialized vocabulary for law-making. To the extent that such a jargon exists, it is now being corrupted by LLMs. This situation appears paradoxical. The issue includes persistent communication failures, between disciplines that cannot translate their technical vocabulary into accessible terms, and between political movements that operate in incompatible worldviews. We show that a frame integrating four specialist languages, those of governance, economy, community and science, is able to address these failures case-wise, which we consider helpful. However, for reasons noted, we cannot create the more generic jargon needed on our own. We conclude that our frame provides the knowledge to design and apply RAG-LLM architectures for researching their jargon generating potential in a future project. We show its feasibility in the appendix.",
    "source": "arXiv"
  },
  {
    "title": "EngiBench: A Framework for Data-Driven Engineering Design Research",
    "title_es": "EngiBench: A Framework for Data-Driven Engineering Design Research",
    "url": "https://arxiv.org/abs/2508.00831",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.00831v2 Announce Type: replace \nAbstract: Engineering design optimization seeks to automatically determine the shapes, topologies, or parameters of components that maximize performance under given conditions. This process often depends on physics-based simulations, which are difficult to install, computationally expensive, and require domain-specific expertise. To mitigate these challenges, we introduce EngiBench, the first open-source library and datasets spanning diverse domains for data-driven engineering design. EngiBench provides a unified API and a curated set of benchmarks -- covering aeronautics, heat conduction, photonics, and more -- that enable fair, reproducible comparisons of optimization and machine learning algorithms, such as generative or surrogate models. We also release EngiOpt, a companion library offering a collection of such algorithms compatible with the EngiBench interface. Both libraries are modular, letting users plug in novel algorithms or problems, automate end-to-end experiment workflows, and leverage built-in utilities for visualization, dataset generation, feasibility checks, and performance analysis. We demonstrate their versatility through experiments comparing state-of-the-art techniques across multiple engineering design problems, an undertaking that was previously prohibitively time-consuming to perform. Finally, we show that these problems pose significant challenges for standard machine learning methods due to highly sensitive and constrained design manifolds.",
    "source": "arXiv"
  },
  {
    "title": "H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving",
    "title_es": "H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.01158",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.01158v2 Announce Type: replace \nAbstract: Deep learning (DL) has shown state-of-the-art performance in trajectory prediction, which is critical to safe navigation in autonomous driving (AD). However, most DL-based methods suffer from catastrophic forgetting, where adapting to a new distribution may cause significant performance degradation in previously learned ones. Such inability to retain learned knowledge limits their applicability in the real world, where AD systems need to operate across varying scenarios with dynamic distributions. As revealed by neuroscience, the hippocampal circuit plays a crucial role in memory replay, effectively reconstructing learned knowledge based on limited resources. Inspired by this, we propose a hippocampal circuit-inspired continual learning method (H2C) for trajectory prediction across varying scenarios. H2C retains prior knowledge by selectively recalling a small subset of learned samples. First, two complementary strategies are developed to select the subset to represent learned knowledge. Specifically, one strategy maximizes inter-sample diversity to represent the distinctive knowledge, and the other estimates the overall knowledge by equiprobable sampling. Then, H2C updates via a memory replay loss function calculated by these selected samples to retain knowledge while learning new data. Experiments based on various scenarios from the INTERACTION dataset are designed to evaluate H2C. Experimental results show that H2C reduces catastrophic forgetting of DL baselines by 22.71% on average in a task-free manner, without relying on manually informed distributional shifts. The implementation is available at https://github.com/BIT-Jack/H2C-lifelong.",
    "source": "arXiv"
  },
  {
    "title": "Self-Navigated Residual Mamba for Universal Industrial Anomaly Detection",
    "title_es": "Self-Navigated Residual Mamba for Universal Industrial Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.01591",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.01591v2 Announce Type: replace \nAbstract: In this paper, we propose Self-Navigated Residual Mamba (SNARM), a novel framework for universal industrial anomaly detection that leverages ``self-referential learning'' within test images to enhance anomaly discrimination. Unlike conventional methods that depend solely on pre-trained features from normal training data, SNARM dynamically refines anomaly detection by iteratively comparing test patches against adaptively selected in-image references. Specifically, we first compute the ``inter-residuals'' features by contrasting test image patches with the training feature bank. Patches exhibiting small-norm residuals (indicating high normality) are then utilized as self-generated reference patches to compute ``intra-residuals'', amplifying discriminative signals. These inter- and intra-residual features are concatenated and fed into a novel Mamba module with multiple heads, which are dynamically navigated by residual properties to focus on anomalous regions. Finally, AD results are obtained by aggregating the outputs of a self-navigated Mamba in an ensemble learning paradigm. Extensive experiments on MVTec AD, MVTec 3D, and VisA benchmarks demonstrate that SNARM achieves state-of-the-art (SOTA) performance, with notable improvements in all metrics, including Image-AUROC, Pixel-AURC, PRO, and AP.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Robot-Assisted Surgery with Hierarchical Class-Incremental Semantic Segmentation",
    "title_es": "Dynamic Robot-Assisted Surgery with Hierarchical Class-Incremental Semantic Segmentation",
    "url": "https://arxiv.org/abs/2508.01713",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.01713v2 Announce Type: replace \nAbstract: Robot-assisted surgeries rely on accurate and real-time scene understanding to safely guide surgical instruments. However, segmentation models trained on static datasets face key limitations when deployed in these dynamic and evolving surgical environments. Class-incremental semantic segmentation (CISS) allows models to continually adapt to new classes while avoiding catastrophic forgetting of prior knowledge, without training on previous data. In this work, we build upon the recently introduced Taxonomy-Oriented Poincar\\'e-regularized Incremental Class Segmentation (TOPICS) approach and propose an enhanced variant, termed TOPICS+, specifically tailored for robust segmentation of surgical scenes. Concretely, we incorporate the Dice loss into the hierarchical loss formulation to handle strong class imbalances, introduce hierarchical pseudo-labeling, and design tailored label taxonomies for robotic surgery environments. We also propose six novel CISS benchmarks designed for robotic surgery environments including multiple incremental steps and several semantic categories to emulate realistic class-incremental settings in surgical environments. In addition, we introduce a refined set of labels with more than 144 classes on the Syn-Mediverse synthetic dataset, hosted online as an evaluation benchmark. We make the code and trained models publicly available at http://topics.cs.uni-freiburg.de.",
    "source": "arXiv"
  },
  {
    "title": "HeadZoom: Hands-Free Zooming and Panning for 2D Image Navigation Using Head Motion",
    "title_es": "HeadZoom: Hands-Free Zooming and Panning for 2D Image Navigation Using Head Motion",
    "url": "https://arxiv.org/abs/2508.01765",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.01765v2 Announce Type: replace \nAbstract: We introduce \\textit{HeadZoom}, a hands-free interaction technique for navigating two-dimensional visual content using head movements. HeadZoom enables fluid zooming and panning using only real-time head tracking. It supports natural control in applications such as map exploration, radiograph inspection, and image browsing, where physical interaction is limited. We evaluated HeadZoom in a within-subjects study comparing three interaction techniques-Static, Tilt Zoom, and Parallel Zoom-across spatial, error, and subjective metrics. Parallel Zoom significantly reduced total head movement compared to Static and Tilt modes. Users reported significantly lower perceived exertion for Parallel Zoom, confirming its suitability for prolonged or precision-based tasks. By minimizing movement demands while maintaining task effectiveness, HeadZoom advances the design of head-based 2D interaction in VR and creates new opportunities for accessible hands-free systems for image exploration.",
    "source": "arXiv"
  },
  {
    "title": "StarPose: 3D Human Pose Estimation via Spatial-Temporal Autoregressive Diffusion",
    "title_es": "StarPose: 3D Human Pose Estimation via Spatial-Temporal Autoregressive Diffusion",
    "url": "https://arxiv.org/abs/2508.02056",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02056v2 Announce Type: replace \nAbstract: Monocular 3D human pose estimation remains a challenging task due to inherent depth ambiguities and occlusions. Compared to traditional methods based on Transformers or Convolutional Neural Networks (CNNs), recent diffusion-based approaches have shown superior performance, leveraging their probabilistic nature and high-fidelity generation capabilities. However, these methods often fail to account for the spatial and temporal correlations across predicted frames, resulting in limited temporal consistency and inferior accuracy in predicted 3D pose sequences. To address these shortcomings, this paper proposes StarPose, an autoregressive diffusion framework that effectively incorporates historical 3D pose predictions and spatial-temporal physical guidance to significantly enhance both the accuracy and temporal coherence of pose predictions. Unlike existing approaches, StarPose models the 2D-to-3D pose mapping as an autoregressive diffusion process. By synergically integrating previously predicted 3D poses with 2D pose inputs via a Historical Pose Integration Module (HPIM), the framework generates rich and informative historical pose embeddings that guide subsequent denoising steps, ensuring temporally consistent predictions. In addition, a fully plug-and-play Spatial-Temporal Physical Guidance (STPG) mechanism is tailored to refine the denoising process in an iterative manner, which further enforces spatial anatomical plausibility and temporal motion dynamics, rendering robust and realistic pose estimates. Extensive experiments on benchmark datasets demonstrate that StarPose outperforms state-of-the-art methods, achieving superior accuracy and temporal consistency in 3D human pose estimation. Code is available at https://github.com/wileychan/StarPose.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical MoE: Continuous Multimodal Emotion Recognition with Incomplete and Asynchronous Inputs",
    "title_es": "Hierarchical MoE: Continuous Multimodal Emotion Recognition with Incomplete and Asynchronous Inputs",
    "url": "https://arxiv.org/abs/2508.02133",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02133v2 Announce Type: replace \nAbstract: Multimodal emotion recognition (MER) is crucial for human-computer interaction, yet real-world challenges like dynamic modality incompleteness and asynchrony severely limit its robustness. Existing methods often assume consistently complete data or lack dynamic adaptability. To address these limitations, we propose a novel Hi-MoE~(Hierarchical Mixture-of-Experts) framework for robust continuous emotion prediction. This framework employs a dual-layer expert structure. A Modality Expert Bank utilizes soft routing to dynamically handle missing modalities and achieve robust information fusion. A subsequent Emotion Expert Bank leverages differential-attention routing to flexibly attend to emotional prototypes, enabling fine-grained emotion representation. Additionally, a cross-modal alignment module explicitly addresses temporal shifts and semantic inconsistencies between modalities. Extensive experiments on benchmark datasets DEAP and DREAMER demonstrate our model's state-of-the-art performance in continuous emotion regression, showcasing exceptional robustness under challenging conditions such as dynamic modality absence and asynchronous sampling. This research significantly advances the development of intelligent emotion systems adaptable to complex real-world environments.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Treatment-DML: Causal Estimation for Multi-Dimensional Continuous Treatments with Monotonicity Constraints in Personal Loan Risk Optimization",
    "title_es": "Multi-Treatment-DML: Causal Estimation for Multi-Dimensional Continuous Treatments with Monotonicity Constraints in Personal Loan Risk Optimization",
    "url": "https://arxiv.org/abs/2508.02183",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02183v2 Announce Type: replace \nAbstract: Optimizing credit limits, interest rates, and loan terms is crucial for managing borrower risk and lifetime value (LTV) in personal loan platform. However, counterfactual estimation of these continuous, multi-dimensional treatments faces significant challenges: randomized trials are often prohibited by risk controls and long repayment cycles, forcing reliance on biased observational data. Existing causal methods primarily handle binary/discrete treatments and struggle with continuous, multi-dimensional settings. Furthermore, financial domain knowledge mandates provably monotonic treatment-outcome relationships (e.g., risk increases with credit limit).To address these gaps, we propose Multi-Treatment-DML, a novel framework leveraging Double Machine Learning (DML) to: (i) debias observational data for causal effect estimation; (ii) handle arbitrary-dimensional continuous treatments; and (iii) enforce monotonic constraints between treatments and outcomes, guaranteeing adherence to domain requirements.Extensive experiments on public benchmarks and real-world industrial datasets demonstrate the effectiveness of our approach. Furthermore, online A/B testing conducted on a realworld personal loan platform, confirms the practical superiority of Multi-Treatment-DML in real-world loan operations.",
    "source": "arXiv"
  },
  {
    "title": "A Methodological Framework for LLM-Based Mining of Software Repositories",
    "title_es": "A Methodological Framework for LLM-Based Mining of Software Repositories",
    "url": "https://arxiv.org/abs/2508.02233",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02233v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are increasingly used in software engineering research, offering new opportunities for automating repository mining tasks. However, despite their growing popularity, the methodological integration of LLMs into Mining Software Repositories (MSR) remains poorly understood. Existing studies tend to focus on specific capabilities or performance benchmarks, providing limited insight into how researchers utilize LLMs across the full research pipeline. To address this gap, we conduct a mixed-method study that combines a rapid review and questionnaire survey in the field of LLM4MSR. We investigate (1) the approaches and (2) the threats that affect the empirical rigor of researchers involved in this field. Our findings reveal 15 methodological approaches, nine main threats, and 25 mitigation strategies. Building on these findings, we present PRIMES 2.0, a refined empirical framework organized into six stages, comprising 23 methodological substeps, each mapped to specific threats and corresponding mitigation strategies, providing prescriptive and adaptive support throughout the lifecycle of LLM-based MSR studies. Our work contributes to establishing a more transparent and reproducible foundation for LLM-based MSR research.",
    "source": "arXiv"
  },
  {
    "title": "SGAD: Semantic and Geometric-aware Descriptor for Local Feature Matching",
    "title_es": "SGAD: Semantic and Geometric-aware Descriptor for Local Feature Matching",
    "url": "https://arxiv.org/abs/2508.02278",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02278v2 Announce Type: replace \nAbstract: Local feature matching remains a fundamental challenge in computer vision. Recent Area to Point Matching (A2PM) methods have improved matching accuracy. However, existing research based on this framework relies on inefficient pixel-level comparisons and complex graph matching that limit scalability. In this work, we introduce the Semantic and Geometric-aware Descriptor Network (SGAD), which fundamentally rethinks area-based matching by generating highly discriminative area descriptors that enable direct matching without complex graph optimization. This approach significantly improves both accuracy and efficiency of area matching. We further improve the performance of area matching through a novel supervision strategy that decomposes the area matching task into classification and ranking subtasks. Finally, we introduce the Hierarchical Containment Redundancy Filter (HCRF) to eliminate overlapping areas by analyzing containment graphs. SGAD demonstrates remarkable performance gains, reducing runtime by 60x (0.82s vs. 60.23s) compared to MESA. Extensive evaluations show consistent improvements across multiple point matchers: SGAD+LoFTR reduces runtime compared to DKM, while achieving higher accuracy (0.82s vs. 1.51s, 65.98 vs. 61.11) in outdoor pose estimation, and SGAD+ROMA delivers +7.39% AUC@5{\\deg} in indoor pose estimation, establishing a new state-of-the-art.",
    "source": "arXiv"
  },
  {
    "title": "Zero-shot Compositional Action Recognition with Neural Logic Constraints",
    "title_es": "Zero-shot Compositional Action Recognition with Neural Logic Constraints",
    "url": "https://arxiv.org/abs/2508.02320",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02320v2 Announce Type: replace \nAbstract: Zero-shot compositional action recognition (ZS-CAR) aims to identify unseen verb-object compositions in the videos by exploiting the learned knowledge of verb and object primitives during training. Despite compositional learning's progress in ZS-CAR, two critical challenges persist: 1) Missing compositional structure constraint, leading to spurious correlations between primitives; 2) Neglecting semantic hierarchy constraint, leading to semantic ambiguity and impairing the training process. In this paper, we argue that human-like symbolic reasoning offers a principled solution to these challenges by explicitly modeling compositional and hierarchical structured abstraction. To this end, we propose a logic-driven ZS-CAR framework LogicCAR that integrates dual symbolic constraints: Explicit Compositional Logic and Hierarchical Primitive Logic. Specifically, the former models the restrictions within the compositions, enhancing the compositional reasoning ability of our model. The latter investigates the semantical dependencies among different primitives, empowering the models with fine-to-coarse reasoning capacity. By formalizing these constraints in first-order logic and embedding them into neural network architectures, LogicCAR systematically bridges the gap between symbolic abstraction and existing models. Extensive experiments on the Sth-com dataset demonstrate that our LogicCAR outperforms existing baseline methods, proving the effectiveness of our logic-driven constraints.",
    "source": "arXiv"
  },
  {
    "title": "Improving Knowledge Graph Understanding with Contextual Views -- Extended",
    "title_es": "Improving Knowledge Graph Understanding with Contextual Views -- Extended",
    "url": "https://arxiv.org/abs/2508.02413",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02413v2 Announce Type: replace \nAbstract: Navigating, visualizing, and discovery in graph data is frequently a difficult prospect. This is especially true for knowledge graphs (KGs), due to high number of possible labeled connections to other data. However, KGs are frequently equipped with an ontology as a schema. That is, it informs how the relationships between data may be constrained. This additional information can be leveraged to improve how (knowledge) graph data can be navigated, visualized, or otherwise utilized in a discovery process. In this manuscript, we introduce the Interactive Knowledge (InK) Browser. This tool specifically takes advantage ontological information (i.e., knowledge) when found in KGs. Specifically, we use modular views that provide various perspectives over the graph, including an interactive schema view, data listings based on type, neighborhood connections, and geospatial depiction (where appropriate). For this manuscript, we have evaluated the basic premise of this tool over a user group ($n= With this grown user survey, we continue to evaluate how scalable tools, including flexible views, can make KG exploration easier for a range of applications.)",
    "source": "arXiv"
  },
  {
    "title": "Engagement Prediction of Short Videos with Large Multimodal Models",
    "title_es": "Engagement Prediction of Short Videos with Large Multimodal Models",
    "url": "https://arxiv.org/abs/2508.02516",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02516v2 Announce Type: replace \nAbstract: The rapid proliferation of user-generated content (UGC) on short-form video platforms has made video engagement prediction increasingly important for optimizing recommendation systems and guiding content creation. However, this task remains challenging due to the complex interplay of factors such as semantic content, visual quality, audio characteristics, and user background. Prior studies have leveraged various types of features from different modalities, such as visual quality, semantic content, background sound, etc., but often struggle to effectively model their cross-feature and cross-modality interactions. In this work, we empirically investigate the potential of large multimodal models (LMMs) for video engagement prediction. We adopt two representative LMMs: VideoLLaMA2, which integrates audio, visual, and language modalities, and Qwen2.5-VL, which models only visual and language modalities. Specifically, VideoLLaMA2 jointly processes key video frames, text-based metadata, and background sound, while Qwen2.5-VL utilizes only key video frames and text-based metadata. Trained on the SnapUGC dataset, both models demonstrate competitive performance against state-of-the-art baselines, showcasing the effectiveness of LMMs in engagement prediction. Notably, VideoLLaMA2 consistently outperforms Qwen2.5-VL, highlighting the importance of audio features in engagement prediction. By ensembling two types of models, our method achieves first place in the ICCV VQualA 2025 EVQA-SnapUGC Challenge on short-form video engagement prediction. The code is available at https://github.com/sunwei925/LMM-EVQA.git.",
    "source": "arXiv"
  },
  {
    "title": "xDeepServe: Model-as-a-Service on Huawei CloudMatrix384",
    "title_es": "xDeepServe: Model-as-a-Service on Huawei CloudMatrix384",
    "url": "https://arxiv.org/abs/2508.02520",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02520v5 Announce Type: replace \nAbstract: The rise of scaled-out LLMs and scaled-up SuperPods signals a new era in large-scale AI infrastructure. LLMs continue to scale out via MoE, as seen in recent models like DeepSeek, Kimi, and Qwen. In parallel, AI hardware is scaling up, with Huawei's CloudMatrix384 SuperPod offering hundreds of GB/s high-speed interconnects. Running large MoE models on SuperPod-scale hardware brings new challenges. It requires new execution models, scalable scheduling, efficient expert load balancing, and elimination of single points of failure. This paper presents xDeepServe, Huawei Cloud's LLM serving system designed for SuperPod-scale infrastructure. At its core is Transformerless, a disaggregated architecture that decomposes transformer models into modular units--attention, feedforward, and MoE--executed independently on NPUs connected via high-speed fabric. We implement this design in two forms: disaggregated prefill-decode and disaggregated MoE-attention. This fully disaggregated setup enables independent scaling of compute and memory without sacrificing performance. To support this architecture, we propose XCCL, a communication library that leverages CloudMatrix384's global shared memory to implement efficient point-to-point and all-to-all primitives. We also extend our serving engine FlowServe with system-level techniques, enabling scalable inference across hundreds of NPUs.",
    "source": "arXiv"
  },
  {
    "title": "Exponential convergence rate for Iterative Markovian Fitting",
    "title_es": "Exponential convergence rate for Iterative Markovian Fitting",
    "url": "https://arxiv.org/abs/2508.02770",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02770v2 Announce Type: replace \nAbstract: We consider the discrete-time Schr\\\"odinger bridge problem on a finite state space. Although it has been known that the Iterative Markovian Fitting (IMF) algorithm converges in Kullback-Leibler divergence to the ground truth solution, the speed of that convergence remained unquantified. In this work, we establish for the first time that IMF exhibits exponential convergence with an explicit contraction factor.",
    "source": "arXiv"
  },
  {
    "title": "Modeling and Simulation of an Active Car Suspension with a Robust LQR Controller under Road Disturbance, Parameter Uncertainty and White Noise",
    "title_es": "Modeling and Simulation of an Active Car Suspension with a Robust LQR Controller under Road Disturbance, Parameter Uncertainty and White Noise",
    "url": "https://arxiv.org/abs/2508.02906",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02906v3 Announce Type: replace \nAbstract: Vehicle suspension is important for passengers to travel comfortably and to be less exposed to effects such as vibration and shock. A good suspension system increases the road holding of vehicles, allows them to take turns safely, and reduces the risk of traffic accidents. A passive suspension system is the most widely used suspension system in vehicles due to its simple structure and low cost. Passive suspension systems do not have an actuator and therefore do not have a controller. Active suspension systems have an actuator and a controller. Although their structures are more complex and costly, they are safer. PID controller is widely used in active suspension systems due to its simple structure, reasonable cost, and easy adjustment of coefficients. In this study, a more robust LQR-controlled active suspension was designed than a passive suspension and a PID-controlled active suspension. Robustness analyses were performed for passive suspension, PID-controlled active suspension, and LQR-controlled active suspension. Suspension travel, sprung mass acceleration, and sprung mass motion simulations were performed for all three suspensions under road disturbance, under simultaneous road disturbance and parameter uncertainty and under road disturbance with white noise. A comparative analysis was performed by obtaining the rise time, overshoot, and settling time data of the suspensions under different conditions. It was observed that the LQR-controlled active suspension showed the fastest rise time, the least overshoot and had the shortest settling time. In this case, it was proven that the LQRcontrolled active suspension provided a more comfortable and safe ride compared to the other two suspension systems.",
    "source": "arXiv"
  },
  {
    "title": "BoostTransformer: Enhancing Transformer Models with Subgrid Selection and Importance Sampling",
    "title_es": "BoostTransformer: Enhancing Transformer Models with Subgrid Selection and Importance Sampling",
    "url": "https://arxiv.org/abs/2508.02924",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02924v2 Announce Type: replace \nAbstract: Transformer architectures dominate modern NLP but often demand heavy computational resources and intricate hyperparameter tuning. To mitigate these challenges, we propose a novel framework, BoostTransformer, that augments transformers with boosting principles through subgrid token selection and importance-weighted sampling. Our method incorporates a least square boosting objective directly into the transformer pipeline, enabling more efficient training and improved performance. Across multiple fine-grained text classification benchmarks, BoostTransformer demonstrates both faster convergence and higher accuracy, surpassing standard transformers while minimizing architectural search overhead.",
    "source": "arXiv"
  },
  {
    "title": "HiTeC: Hierarchical Contrastive Learning on Text-Attributed Hypergraph with Semantic-Aware Augmentation",
    "title_es": "HiTeC: Hierarchical Contrastive Learning on Text-Attributed Hypergraph with Semantic-Aware Augmentation",
    "url": "https://arxiv.org/abs/2508.03104",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03104v2 Announce Type: replace \nAbstract: Contrastive learning (CL) has become a dominant paradigm for self-supervised hypergraph learning, enabling effective training without costly labels. However, node entities in real-world hypergraphs are often associated with rich textual information, which is overlooked in prior works. Directly applying existing CL-based methods to such text-attributed hypergraphs (TAHGs) leads to three key limitations: (1) The common use of graph-agnostic text encoders overlooks the correlations between textual content and hypergraph topology, resulting in suboptimal representations. (2) Their reliance on random data augmentations introduces noise and weakens the contrastive objective. (3) The primary focus on node- and hyperedge-level contrastive signals limits the ability to capture long-range dependencies, which is essential for expressive representation learning. Although HyperBERT pioneers CL on TAHGs, its co-training paradigm suffers from poor scalability. To fill the research gap, we introduce HiTeC, a two-stage hierarchical contrastive learning framework with semantic-aware augmentation for scalable and effective self-supervised learning on TAHGs. In the first stage, we pre-train the text encoder with a structure-aware contrastive objective to overcome the graph-agnostic nature of conventional methods. In the second stage, we introduce two semantic-aware augmentation strategies, including prompt-enhanced text augmentation and semantic-aware hyperedge drop, to facilitate informative view generation. Furthermore, we propose a multi-scale contrastive loss that extends existing objectives with an $s$-walk-based subgraph-level contrast to better capture long-range dependencies. By decoupling text encoder pretraining from hypergraph contrastive learning, this two-stage design enhances scalability without compromising representation quality. Extensive experiments confirm the effectiveness of HiTeC.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models",
    "title_es": "Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models",
    "url": "https://arxiv.org/abs/2508.03199",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03199v2 Announce Type: replace \nAbstract: Research on bias in Text-to-Image (T2I) models has primarily focused on demographic representation and stereotypical attributes, overlooking a fundamental question: how does grammatical gender influence visual representation across languages? We introduce a cross-linguistic benchmark examining words where grammatical gender contradicts stereotypical gender associations (e.g., ``une sentinelle'' - grammatically feminine in French but referring to the stereotypically masculine concept ``guard''). Our dataset spans five gendered languages (French, Spanish, German, Italian, Russian) and two gender-neutral control languages (English, Chinese), comprising 800 unique prompts that generated 28,800 images across three state-of-the-art T2I models. Our analysis reveals that grammatical gender dramatically influences image generation: masculine grammatical markers increase male representation to 73\\% on average (compared to 22\\% with gender-neutral English), while feminine grammatical markers increase female representation to 38\\% (compared to 28\\% in English). These effects vary systematically by language resource availability and model architecture, with high-resource languages showing stronger effects. Our findings establish that language structure itself, not just content, shapes AI-generated visual outputs, introducing a new dimension for understanding bias and fairness in multilingual, multimodal systems.",
    "source": "arXiv"
  },
  {
    "title": "Probing Syntax in Large Language Models: Successes and Remaining Challenges",
    "title_es": "Probing Syntax in Large Language Models: Successes and Remaining Challenges",
    "url": "https://arxiv.org/abs/2508.03211",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03211v2 Announce Type: replace \nAbstract: The syntactic structures of sentences can be readily read-out from the activations of large language models (LLMs). However, the ``structural probes'' that have been developed to reveal this phenomenon are typically evaluated on an indiscriminate set of sentences. Consequently, it remains unclear whether structural and/or statistical factors systematically affect these syntactic representations. To address this issue, we conduct an in-depth analysis of structural probes on three controlled benchmarks. Our results are three-fold. First, structural probes are biased by a superficial property: the closer two words are in a sentence, the more likely structural probes will consider them as syntactically linked. Second, structural probes are challenged by linguistic properties: they poorly represent deep syntactic structures, and get interfered by interacting nouns or ungrammatical verb forms. Third, structural probes do not appear to be affected by the predictability of individual words. Overall, this work sheds light on the current challenges faced by structural probes. Providing a benchmark made of controlled stimuli to better evaluate their performance.",
    "source": "arXiv"
  },
  {
    "title": "Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration",
    "title_es": "Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration",
    "url": "https://arxiv.org/abs/2508.03337",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03337v3 Announce Type: replace \nAbstract: The practical application of Multimodal Large Language Models (MLLMs) to Video Question Answering (Video-QA) is severely hindered by the high token cost of processing numerous video frames. While increasing the number of sampled frames is a common strategy, we observe a \"less is more\" phenomenon where excessive frames can paradoxically degrade performance due to context dilution. Concurrently, state-of-the-art keyframe selection methods, while effective, still yield significant temporal redundancy, which we term 'visual echoes'. To address these dual challenges, we propose Adaptive Frame-Pruning (AFP), a novel post-processing method that intelligently prunes the selected keyframes. AFP employs an adaptive hierarchical clustering algorithm on a fused ResNet-50 and CLIP feature space to identify and merge these echoes into single representatives. To compensate for information loss, we then introduce a lightweight, text-based semantic graph that provides critical context with minimal token overhead. Conducting extensive experiments on the LongVideoBench and VideoMME benchmarks across multiple leading MLLMs, our full approach demonstrates a drastic reduction in required frames by up to 86.9% and total input tokens by up to 83.2%. Crucially, by providing a concise, high-quality set of frames, our method not only enhances efficiency but often improves accuracy over baselines that use more frames. The code will be released upon publication.",
    "source": "arXiv"
  },
  {
    "title": "Game Reasoning Arena: A Framework and Benchmark for Assessing Reasoning Capabilites of Large Language Models via Game Play",
    "title_es": "Game Reasoning Arena: A Framework and Benchmark for Assessing Reasoning Capabilites of Large Language Models via Game Play",
    "url": "https://arxiv.org/abs/2508.03368",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03368v2 Announce Type: replace \nAbstract: The Game Reasoning Arena library provides a framework for evaluating the decision making abilities of large language models (LLMs) through strategic board games implemented in Google OpenSpiel library. The framework enables systematic comparisons between LLM based agents and other agents (random, heuristic, reinforcement learning agents, etc.) in various game scenarios by wrapping multiple board and matrix games and supporting different agent types. It integrates API access to models via liteLLM, local model deployment via vLLM, and offers distributed execution through Ray. This paper summarises the library structure, key characteristics, and motivation of the repository, highlighting how it contributes to the empirical evaluation of the reasoning of LLM and game theoretic behaviour.",
    "source": "arXiv"
  },
  {
    "title": "When Cars Have Stereotypes: Auditing Demographic Bias in Objects from Text-to-Image Models",
    "title_es": "When Cars Have Stereotypes: Auditing Demographic Bias in Objects from Text-to-Image Models",
    "url": "https://arxiv.org/abs/2508.03483",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03483v2 Announce Type: replace \nAbstract: While prior research on text-to-image generation has predominantly focused on biases in human depictions, we investigate a more subtle yet pervasive phenomenon: demographic bias in generated objects (e.g., cars). We introduce SODA (Stereotyped Object Diagnostic Audit), a novel framework for systematically measuring such biases. Our approach compares visual attributes of objects generated with demographic cues (e.g., \"for young people'') to those from neutral prompts, across 2,700 images produced by three state-of-the-art models (GPT Image-1, Imagen 4, and Stable Diffusion) in five object categories. Through a comprehensive analysis, we uncover strong associations between specific demographic groups and visual attributes, such as recurring color patterns prompted by gender or ethnicity cues. These patterns reflect and reinforce not only well-known stereotypes but also more subtle and unintuitive biases. We also observe that some models generate less diverse outputs, which in turn amplifies the visual disparities compared to neutral prompts. Our proposed auditing framework offers a practical approach for testing, revealing how stereotypes still remain embedded in today's generative models. We see this as an essential step toward more systematic and responsible AI development.",
    "source": "arXiv"
  },
  {
    "title": "LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for Advertiser Keyphrase Recommendations at eBay",
    "title_es": "LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for Advertiser Keyphrase Recommendations at eBay",
    "url": "https://arxiv.org/abs/2508.03628",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03628v2 Announce Type: replace \nAbstract: Sellers at eBay are recommended keyphrases to bid on to enhance the performance of their advertising campaigns. The relevance of these keyphrases is crucial in avoiding the overcrowding of search systems with irrelevant items and maintaining a positive seller perception. It is essential that keyphrase recommendations align with both seller and Search judgments regarding auctions. Due to the difficulty in procuring negative human judgment at scale, employing LLM-as-a-judge to mimic seller judgment has been established as the norm in several studies. This study introduces a novel two-step LLM distillation process from a LLM-judge used to debias our Embedding Based Retrieval (EBR) model from the various biases that exist in click-data. We distill from an LLM teacher via a cross-encoder assistant into a bi-encoder student using a multi-task training approach, ultimately employing the student bi-encoder to retrieve relevant advertiser keyphrases. We show that integrating a knowledge distillation process from LLMs in a multi-task training setup enhances bi-encoder performance in retrieving relevant advertiser keyphrases at eBay.",
    "source": "arXiv"
  },
  {
    "title": "Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images",
    "title_es": "Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images",
    "url": "https://arxiv.org/abs/2508.03643",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03643v3 Announce Type: replace \nAbstract: Reconstructing and semantically interpreting 3D scenes from sparse 2D views remains a fundamental challenge in computer vision. Conventional methods often decouple semantic understanding from reconstruction or necessitate costly per-scene optimization, thereby restricting their scalability and generalizability. In this paper, we introduce Uni3R, a novel feed-forward framework that jointly reconstructs a unified 3D scene representation enriched with open-vocabulary semantics, directly from unposed multi-view images. Our approach leverages a Cross-View Transformer to robustly integrate information across arbitrary multi-view inputs, which then regresses a set of 3D Gaussian primitives endowed with semantic feature fields. This unified representation facilitates high-fidelity novel view synthesis, open-vocabulary 3D semantic segmentation, and depth prediction, all within a single, feed-forward pass. Extensive experiments demonstrate that Uni3R establishes a new state-of-the-art across multiple benchmarks, including 25.07 PSNR on RE10K and 55.84 mIoU on ScanNet. Our work signifies a novel paradigm towards generalizable, unified 3D scene reconstruction and understanding. The code is available at https://github.com/HorizonRobotics/Uni3R.",
    "source": "arXiv"
  },
  {
    "title": "An Entity Linking Agent for Question Answering",
    "title_es": "An Entity Linking Agent for Question Answering",
    "url": "https://arxiv.org/abs/2508.03865",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03865v3 Announce Type: replace \nAbstract: Some Question Answering (QA) systems rely on knowledge bases (KBs) to provide accurate answers. Entity Linking (EL) plays a critical role in linking natural language mentions to KB entries. However, most existing EL methods are designed for long contexts and do not perform well on short, ambiguous user questions in QA tasks. We propose an entity linking agent for QA, based on a Large Language Model that simulates human cognitive workflows. The agent actively identifies entity mentions, retrieves candidate entities, and makes decision. To verify the effectiveness of our agent, we conduct two experiments: tool-based entity linking and QA task evaluation. The results confirm the robustness and effectiveness of our agent.",
    "source": "arXiv"
  },
  {
    "title": "Managing Data for Scalable and Interactive Event Sequence Visualization",
    "title_es": "Managing Data for Scalable and Interactive Event Sequence Visualization",
    "url": "https://arxiv.org/abs/2508.03974",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03974v2 Announce Type: replace \nAbstract: Parallel event sequences, such as those collected in program execution traces and automated manufacturing pipelines, are typically visualized as interactive parallel timelines. As the dataset size grows, these charts frequently experience lag during common interactions such as zooming, panning, and filtering. Summarization approaches can improve interaction performance, but at the cost of accuracy in representation. To address this challenge, we introduce ESeMan (Event Sequence Manager), an event sequence management system designed to support interactive rendering of timeline visualizations with tunable accuracy. ESeMan employs hierarchical data structures and intelligent caching to provide visualizations with only the data necessary to generate accurate summarizations with significantly reduced data fetch time. We evaluate ESeMan's query times against summed area tables, M4 aggregation, and statistical sub-sampling on a variety of program execution traces. Our results demonstrate ESeMan provides better performance, achieving sub-100ms fetch times while maintaining visualization accuracy at the pixel level. We further present our benchmarking harness, enabling future performance evaluations for event sequence visualization.",
    "source": "arXiv"
  },
  {
    "title": "Investigating the Impact of Large-Scale Pre-training on Nutritional Content Estimation from 2D Images",
    "title_es": "Investigating the Impact of Large-Scale Pre-training on Nutritional Content Estimation from 2D Images",
    "url": "https://arxiv.org/abs/2508.03996",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.03996v2 Announce Type: replace \nAbstract: Estimating the nutritional content of food from images is a critical task with significant implications for health and dietary monitoring. This is challenging, especially when relying solely on 2D images, due to the variability in food presentation, lighting, and the inherent difficulty in inferring volume and mass without depth information. Furthermore, reproducibility in this domain is hampered by the reliance of state-of-the-art methods on proprietary datasets for large-scale pre-training. In this paper, we investigate the impact of large-scale pre-training datasets on the performance of deep learning models for nutritional estimation using only 2D images. We fine-tune and evaluate Vision Transformer (ViT) models pre-trained on two large public datasets, ImageNet and COYO, comparing their performance against baseline CNN models (InceptionV2 and ResNet-50) and a state-of-the-art method pre-trained on the proprietary JFT-300M dataset. We conduct extensive experiments on the Nutrition5k dataset, a large-scale collection of real-world food plates with high-precision nutritional annotations. Our evaluation using Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAE%) reveals that models pre-trained on JFT-300M significantly outperform those pre-trained on public datasets. Unexpectedly, the model pre-trained on the massive COYO dataset performs worse than the model pre-trained on ImageNet for this specific regression task, refuting our initial hypothesis. Our analysis provides quantitative evidence highlighting the critical role of pre-training dataset characteristics, including scale, domain relevance, and curation quality, for effective transfer learning in 2D nutritional estimation.",
    "source": "arXiv"
  },
  {
    "title": "DS$^2$Net: Detail-Semantic Deep Supervision Network for Medical Image Segmentation",
    "title_es": "DS$^2$Net: Detail-Semantic Deep Supervision Network for Medical Image Segmentation",
    "url": "https://arxiv.org/abs/2508.04131",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04131v2 Announce Type: replace \nAbstract: Deep Supervision Networks exhibit significant efficacy for the medical imaging community. Nevertheless, existing work merely supervises either the coarse-grained semantic features or fine-grained detailed features in isolation, which compromises the fact that these two types of features hold vital relationships in medical image analysis. We advocate the powers of complementary feature supervision for medical image segmentation, by proposing a Detail-Semantic Deep Supervision Network (DS$^2$Net). DS$^2$Net navigates both low-level detailed and high-level semantic feature supervision through Detail Enhance Module (DEM) and Semantic Enhance Module (SEM). DEM and SEM respectively harness low-level and high-level feature maps to create detail and semantic masks for enhancing feature supervision. This is a novel shift from single-view deep supervision to multi-view deep supervision. DS$^2$Net is also equipped with a novel uncertainty-based supervision loss that adaptively assigns the supervision strength of features within distinct scales based on their uncertainty, thus circumventing the sub-optimal heuristic design that typifies previous works. Through extensive experiments on six benchmarks captured under either colonoscopy, ultrasound and microscope, we demonstrate that DS$^2$Net consistently outperforms state-of-the-art methods for medical image analysis.",
    "source": "arXiv"
  },
  {
    "title": "Industrial Robot Motion Planning with GPUs: Integration of cuRobo for Extended DOF Systems",
    "title_es": "Industrial Robot Motion Planning with GPUs: Integration of cuRobo for Extended DOF Systems",
    "url": "https://arxiv.org/abs/2508.04146",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04146v2 Announce Type: replace \nAbstract: Efficient motion planning remains a key challenge in industrial robotics, especially for multi-axis systems operating in complex environments. This paper addresses that challenge by integrating GPU-accelerated motion planning through NVIDIA's cuRobo library into Vention's modular automation platform. By leveraging accurate CAD-based digital twins and real-time parallel optimization, our system enables rapid trajectory generation and dynamic collision avoidance for pick-and-place tasks. We demonstrate this capability on robots equipped with additional degrees of freedom, including a 7th-axis gantry, and benchmark performance across various scenarios. The results show significant improvements in planning speed and robustness, highlighting the potential of GPU-based planning pipelines for scalable, adaptable deployment in modern industrial workflows.",
    "source": "arXiv"
  },
  {
    "title": "Approximation Algorithms for Scheduling Crowdsourcing Tasks in Mobile Social Networks",
    "title_es": "Approximation Algorithms for Scheduling Crowdsourcing Tasks in Mobile Social Networks",
    "url": "https://arxiv.org/abs/2508.04159",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04159v2 Announce Type: replace \nAbstract: This paper addresses the scheduling problem in mobile social networks. We begin by proving that the approximation ratio analysis presented in the paper by Zhang \\textit{et al.} (IEEE Transactions on Mobile Computing, 2025) is incorrect, and we provide the correct analysis results. Furthermore, when the required service time for a task exceeds the total contact time between the requester and the crowd worker, we demonstrate that the approximation ratio of the Largest-Ratio-First task scheduling algorithm can reach $2 - \\frac{1}{m}$. Next, we introduce a randomized approximation algorithm to minimize mobile social networks' total weighted completion time. This algorithm achieves an expected approximation ratio of $1.5 + \\epsilon$ for $\\epsilon>0$. Finally, we present a deterministic approximation algorithm that minimizes mobile social networks' total weighted completion time. This deterministic algorithm achieves an approximation ratio of $\\max\\left\\{2.5,1+\\epsilon\\right\\}$ for $\\epsilon>0$. Additionally, when the task's required service time or the total contact time between the requester and the crowd worker is sufficiently large, this algorithm can reach an approximation ratio of $1.5+\\epsilon$ for $\\epsilon>0$.",
    "source": "arXiv"
  },
  {
    "title": "Continual Multiple Instance Learning for Hematologic Disease Diagnosis",
    "title_es": "Continual Multiple Instance Learning for Hematologic Disease Diagnosis",
    "url": "https://arxiv.org/abs/2508.04368",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04368v2 Announce Type: replace \nAbstract: The dynamic environment of laboratories and clinics, with streams of data arriving on a daily basis, requires regular updates of trained machine learning models for consistent performance. Continual learning is supposed to help train models without catastrophic forgetting. However, state-of-the-art methods are ineffective for multiple instance learning (MIL), which is often used in single-cell-based hematologic disease diagnosis (e.g., leukemia detection). Here, we propose the first continual learning method tailored specifically to MIL. Our method is rehearsal-based over a selection of single instances from various bags. We use a combination of the instance attention score and distance from the bag mean and class mean vectors to carefully select which samples and instances to store in exemplary sets from previous tasks, preserving the diversity of the data. Using the real-world input of one month of data from a leukemia laboratory, we study the effectiveness of our approach in a class incremental scenario, comparing it to well-known continual learning methods. We show that our method considerably outperforms state-of-the-art methods, providing the first continual learning approach for MIL. This enables the adaptation of models to shifting data distributions over time, such as those caused by changes in disease occurrence or underlying genetic alterations.",
    "source": "arXiv"
  },
  {
    "title": "TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding",
    "title_es": "TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding",
    "url": "https://arxiv.org/abs/2508.04369",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04369v3 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) have demonstrated significant progress in vision-language tasks, yet they still face challenges when processing long-duration video inputs. The limitation arises from MLLMs' context limit and training costs, necessitating sparse frame sampling before feeding videos into MLLMs. However, building a trainable sampling method remains challenging due to the unsupervised and non-differentiable nature of sparse frame sampling in Video-MLLMs. To address these problems, we propose Temporal Sampling Policy Optimization (TSPO), advancing MLLMs' long-form video-language understanding via reinforcement learning. Specifically, we first propose a trainable event-aware temporal agent, which captures event-query correlation for performing probabilistic keyframe selection. Then, we propose the TSPO reinforcement learning paradigm, which models keyframe selection and language generation as a joint decision-making process, enabling end-to-end group relative optimization for the temporal sampling policy. Furthermore, we propose a dual-style long video training data construction pipeline, balancing comprehensive temporal understanding and key segment localization. Finally, we incorporate rule-based answering accuracy and temporal locating reward mechanisms to optimize the temporal sampling policy. Comprehensive experiments show that our TSPO achieves state-of-the-art performance across multiple long video understanding benchmarks, and shows transferable ability across different cutting-edge Video-MLLMs. Our code is available at https://github.com/Hui-design/TSPO",
    "source": "arXiv"
  },
  {
    "title": "Live Music Models",
    "title_es": "Live Music Models",
    "url": "https://arxiv.org/abs/2508.04651",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04651v2 Announce Type: replace \nAbstract: We introduce a new class of generative models for music called live music models that produce a continuous stream of music in real-time with synchronized user control. We release Magenta RealTime, an open-weights live music model that can be steered using text or audio prompts to control acoustic style. On automatic metrics of music quality, Magenta RealTime outperforms other open-weights music generation models, despite using fewer parameters and offering first-of-its-kind live generation capabilities. We also release Lyria RealTime, an API-based model with extended controls, offering access to our most powerful model with wide prompt coverage. These models demonstrate a new paradigm for AI-assisted music creation that emphasizes human-in-the-loop interaction for live music performance.",
    "source": "arXiv"
  },
  {
    "title": "Inequality in the Age of Pseudonymity",
    "title_es": "Inequality in the Age of Pseudonymity",
    "url": "https://arxiv.org/abs/2508.04668",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04668v3 Announce Type: replace \nAbstract: Inequality measures such as the Gini coefficient are used to inform and motivate policymaking, and are increasingly applied to digital platforms. We analyze how measures fare in pseudonymous settings that are common in the digital age. One key challenge of such environments is the ability of actors to create fake identities under fictitious false names, also known as ``Sybils.'' While some actors may do so to preserve their privacy, we show that this can inadvertently hamper inequality measurements. As we prove, it is impossible for measures satisfying the literature's canonical set of desired properties to assess the inequality of an economy that may harbor Sybils. We characterize the class of all Sybil-proof measures, and prove that they must satisfy relaxed version of the aforementioned properties. Furthermore, we show that the structure imposed restricts the ability to assess inequality at a fine-grained level. By applying our results, we prove that large classes of popular measures are not Sybil-proof, with the famous Gini coefficient being but one example out of many. Finally, we examine the dynamics leading to the creation of Sybils in digital and traditional settings.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Analytical Processing in the GPU Era",
    "title_es": "Rethinking Analytical Processing in the GPU Era",
    "url": "https://arxiv.org/abs/2508.04701",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04701v2 Announce Type: replace \nAbstract: The era of GPU-powered data analytics has arrived. In this paper, we argue that recent advances in hardware (e.g., larger GPU memory, faster interconnect and IO, and declining cost) and software (e.g., composable data systems and mature libraries) have removed the key barriers that have limited the wider adoption of GPU data analytics. We present Sirius, a prototype open-source GPU-native SQL engine that offers drop-in acceleration for diverse data systems. Sirius treats GPU as the primary engine and leverages libraries like libcudf for high-performance relational operators. It provides drop-in acceleration for existing databases by leveraging the standard Substrait query representation, replacing the CPU engine without changing the user-facing interface. On TPC-H, Sirius achieves 7x speedup when integrated with DuckDB in a single node at the same hardware rental cost, and up to 12.5x speedup when integrated with Apache Doris in a distributed setting.",
    "source": "arXiv"
  },
  {
    "title": "OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks",
    "title_es": "OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks",
    "url": "https://arxiv.org/abs/2508.04833",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04833v2 Announce Type: replace \nAbstract: Gossip algorithms are pivotal in the dissemination of information within decentralized systems. Consequently, numerous gossip libraries have been developed and widely utilized especially in blockchain protocols for the propagation of blocks and transactions. A well-established library is libp2p, which provides two gossip algorithms: floodsup and gossibsup. These algorithms enable the delivery of published messages to a set of peers. In this work we aim to enhance the performance and reliability of libp2p by introducing OPTIMUMP2P, a novel gossip algorithm that leverages the capabilities of Random Linear Network Coding (RLNC) to expedite the dissemination of information in a peer-to-peer (P2P) network while ensuring reliable delivery, even in the presence of malicious actors capable of corrupting the transmitted data. Preliminary research from the Ethereum Foundation has demonstrated the use of RLNC in the significant improvement in the block propagation time [14]. Here we present extensive evaluation results both in simulation and real-world environments that demonstrate the performance gains of OPTIMUMP2P over the Gossipsub protocol.",
    "source": "arXiv"
  },
  {
    "title": "Graffiti: Enabling an Ecosystem of Personalized and Interoperable Social Applications",
    "title_es": "Graffiti: Enabling an Ecosystem of Personalized and Interoperable Social Applications",
    "url": "https://arxiv.org/abs/2508.04889",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04889v2 Announce Type: replace \nAbstract: Most social applications, from Twitter to Wikipedia, have rigid one-size-fits-all designs, but building new social applications is both technically challenging and results in applications that are siloed away from existing communities. We present Graffiti, a system that can be used to build a wide variety of personalized social applications with relative ease that also interoperate with each other. People can freely move between a plurality of designs -- each with its own aesthetic, feature set, and moderation -- all without losing their friends or data.\n  Our concept of total reification makes it possible for seemingly contradictory designs, including conflicting moderation rules, to interoperate. Conversely, our concept of channels prevents interoperation from occurring by accident, avoiding context collapse.\n  Graffiti applications interact through a minimal client-side API, which we show admits at least two decentralized implementations. Above the API, we built a Vue plugin, which we use to develop applications similar to Twitter, Messenger, and Wikipedia using only client-side code. Our case studies explore how these and other novel applications interoperate, as well as the broader ecosystem that Graffiti enables.",
    "source": "arXiv"
  },
  {
    "title": "RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory",
    "title_es": "RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory",
    "url": "https://arxiv.org/abs/2508.04903",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04903v2 Announce Type: replace \nAbstract: Multi-agent large language model (LLM) systems have shown strong potential in complex reasoning and collaborative decision-making tasks. However, most existing coordination schemes rely on static or full-context routing strategies, which lead to excessive token consumption, redundant memory exposure, and limited adaptability across interaction rounds. We introduce RCR-Router, a modular and role-aware context routing framework designed to enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge, this is the first routing approach that dynamically selects semantically relevant memory subsets for each agent based on its role and task stage, while adhering to a strict token budget. A lightweight scoring policy guides memory selection, and agent outputs are iteratively integrated into a shared memory store to facilitate progressive context refinement. To better evaluate model behavior, we further propose an Answer Quality Score metric that captures LLM-generated explanations beyond standard QA accuracy. Experiments on three multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate that RCR-Router reduces token usage (up to 30%) while improving or maintaining answer quality. These results highlight the importance of structured memory routing and output-aware evaluation in advancing scalable multi-agent LLM systems.",
    "source": "arXiv"
  },
  {
    "title": "Toward Errorless Training ImageNet-1k",
    "title_es": "Toward Errorless Training ImageNet-1k",
    "url": "https://arxiv.org/abs/2508.04941",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.04941v2 Announce Type: replace \nAbstract: In this paper, we describe a feedforward artificial neural network trained on the ImageNet 2012 contest dataset [7] with the new method of [5] to an accuracy rate of 98.3% with a 99.69 Top-1 rate, and an average of 285.9 labels that are perfectly classified over the 10 batch partitions of the dataset. The best performing model uses 322,430,160 parameters, with 4 decimal places precision. We conjecture that the reason our model does not achieve a 100% accuracy rate is due to a double-labeling problem, by which there are duplicate images in the dataset with different labels.",
    "source": "arXiv"
  },
  {
    "title": "AU-IQA: A Benchmark Dataset for Perceptual Quality Assessment of AI-Enhanced User-Generated Content",
    "title_es": "AU-IQA: A Benchmark Dataset for Perceptual Quality Assessment of AI-Enhanced User-Generated Content",
    "url": "https://arxiv.org/abs/2508.05016",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05016v2 Announce Type: replace \nAbstract: AI-based image enhancement techniques have been widely adopted in various visual applications, significantly improving the perceptual quality of user-generated content (UGC). However, the lack of specialized quality assessment models has become a significant limiting factor in this field, limiting user experience and hindering the advancement of enhancement methods. While perceptual quality assessment methods have shown strong performance on UGC and AIGC individually, their effectiveness on AI-enhanced UGC (AI-UGC) which blends features from both, remains largely unexplored. To address this gap, we construct AU-IQA, a benchmark dataset comprising 4,800 AI-UGC images produced by three representative enhancement types which include super-resolution, low-light enhancement, and denoising. On this dataset, we further evaluate a range of existing quality assessment models, including traditional IQA methods and large multimodal models. Finally, we provide a comprehensive analysis of how well current approaches perform in assessing the perceptual quality of AI-UGC. The access link to the AU-IQA is https://github.com/WNNGGU/AU-IQA-Dataset.",
    "source": "arXiv"
  },
  {
    "title": "Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations",
    "title_es": "Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations",
    "url": "https://arxiv.org/abs/2508.05097",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05097v2 Announce Type: replace \nAbstract: The growing rate of multimodal misinformation, where claims are supported by both text and images, poses significant challenges to fact-checking systems that rely primarily on textual evidence. In this work, we have proposed a unified framework for fine-grained multimodal fact verification called \"MultiCheck\", designed to reason over structured textual and visual signals. Our architecture combines dedicated encoders for text and images with a fusion module that captures cross-modal relationships using element-wise interactions. A classification head then predicts the veracity of a claim, supported by a contrastive learning objective that encourages semantic alignment between claim-evidence pairs in a shared latent space. We evaluate our approach on the Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially outperforming the baseline. These results highlight the effectiveness of explicit multimodal reasoning and demonstrate the potential of our approach for scalable and interpretable fact-checking in complex, real-world scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Community-Aware Social Community Recommendation",
    "title_es": "Community-Aware Social Community Recommendation",
    "url": "https://arxiv.org/abs/2508.05107",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05107v2 Announce Type: replace \nAbstract: Social recommendation, which seeks to leverage social ties among users to alleviate the sparsity issue of user-item interactions, has emerged as a popular technique for elevating personalized services in recommender systems. Despite being effective, existing social recommendation models are mainly devised for recommending regular items such as blogs, images, and products, and largely fail for community recommendations due to overlooking the unique characteristics of communities. Distinctly, communities are constituted by individuals, who present high dynamicity and relate to rich structural patterns in social networks. To our knowledge, limited research has been devoted to comprehensively exploiting this information for recommending communities.\n  To bridge this gap, this paper presents CASO, a novel and effective model specially designed for social community recommendation. Under the hood, CASO harnesses three carefully-crafted encoders for user embedding, wherein two of them extract community-related global and local structures from the social network via social modularity maximization and social closeness aggregation, while the third one captures user preferences using collaborative filtering with observed user-community affiliations. To further eliminate feature redundancy therein, we introduce a mutual exclusion between social and collaborative signals. Finally, CASO includes a community detection loss in the model optimization, thereby producing community-aware embeddings for communities. Our extensive experiments evaluating CASO against nine strong baselines on six real-world social networks demonstrate its consistent and remarkable superiority over the state of the art in terms of community recommendation performance.",
    "source": "arXiv"
  },
  {
    "title": "FDC-Net: Rethinking the association between EEG artifact removal and multi-dimensional affective computing",
    "title_es": "FDC-Net: Rethinking the association between EEG artifact removal and multi-dimensional affective computing",
    "url": "https://arxiv.org/abs/2508.05231",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05231v2 Announce Type: replace \nAbstract: Electroencephalogram (EEG)-based emotion recognition holds significant value in affective computing and brain-computer interfaces. However, in practical applications, EEG recordings are susceptible to the effects of various physiological artifacts. Current approaches typically treat denoising and emotion recognition as independent tasks using cascaded architectures, which not only leads to error accumulation, but also fails to exploit potential synergies between these tasks. Moreover, conventional EEG-based emotion recognition models often rely on the idealized assumption of \"perfectly denoised data\", lacking a systematic design for noise robustness. To address these challenges, a novel framework that deeply couples denoising and emotion recognition tasks is proposed for end-to-end noise-robust emotion recognition, termed as Feedback-Driven Collaborative Network for Denoising-Classification Nexus (FDC-Net). Our primary innovation lies in establishing a dynamic collaborative mechanism between artifact removal and emotion recognition through: (1) bidirectional gradient propagation with joint optimization strategies; (2) a gated attention mechanism integrated with frequency-adaptive Transformer using learnable band-position encoding. Two most popular EEG-based emotion datasets (DEAP and DREAMER) with multi-dimensional emotional labels were employed to compare the artifact removal and emotion recognition performance between FDC-Net and nine state-of-the-art methods. In terms of the denoising task, FDC-Net obtains a maximum correlation coefficient (CC) value of 96.30% on DEAP and a maximum CC value of 90.31% on DREAMER. In terms of the emotion recognition task under physiological artifact interference, FDC-Net achieves emotion recognition accuracies of 82.3+7.1% on DEAP and 88.1+0.8% on DREAMER.",
    "source": "arXiv"
  },
  {
    "title": "Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms",
    "title_es": "Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms",
    "url": "https://arxiv.org/abs/2508.05387",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05387v2 Announce Type: replace \nAbstract: Modern RL-based post-training for large language models (LLMs) co-locate trajectory sampling and policy optimisation on the same GPU cluster, forcing the system to switch between inference and training workloads. This serial context switching violates the single-program-multiple-data (SPMD) assumption underlying today's distributed training systems. We present Echo, the RL system that cleanly decouples these two phases across heterogeneous \"inference\" and \"training\" swarms while preserving statistical efficiency. Echo introduces two lightweight synchronization protocols: a sequential pull mode that refreshes policy weights according to API call for minimal bias, and an asynchronous push-pull mode that streams version-tagged rollouts through a replay buffer to maximise hardware utilisation. Training three representative RL workloads with Qwen3-4B, Qwen2.5-7B and Qwen3-32B on a geographically distributed cluster, Echo matches a fully co-located Verl baseline in convergence speed and final reward while off-loading trajectory generation to commodity edge hardware. These promising results demonstrate that large-scale RL for LLMs could achieve datacentre-grade performance using decentralised, heterogeneous resources.",
    "source": "arXiv"
  },
  {
    "title": "On the Reliability of Sampling Strategies in Offline Recommender Evaluation",
    "title_es": "On the Reliability of Sampling Strategies in Offline Recommender Evaluation",
    "url": "https://arxiv.org/abs/2508.05398",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05398v2 Announce Type: replace \nAbstract: Offline evaluation plays a central role in benchmarking recommender systems when online testing is impractical or risky. However, it is susceptible to two key sources of bias: exposure bias, where users only interact with items they are shown, and sampling bias, introduced when evaluation is performed on a subset of logged items rather than the full catalog. While prior work has proposed methods to mitigate sampling bias, these are typically assessed on fixed logged datasets rather than for their ability to support reliable model comparisons under varying exposure conditions or relative to true user preferences. In this paper, we investigate how different combinations of logging and sampling choices affect the reliability of offline evaluation. Using a fully observed dataset as ground truth, we systematically simulate diverse exposure biases and assess the reliability of common sampling strategies along four dimensions: sampling resolution (recommender model separability), fidelity (agreement with full evaluation), robustness (stability under exposure bias), and predictive power (alignment with ground truth). Our findings highlight when and how sampling distorts evaluation outcomes and offer practical guidance for selecting strategies that yield faithful and robust offline comparisons.",
    "source": "arXiv"
  },
  {
    "title": "Fuzzy Decisions on Fluid Instabilities: Autoencoder-Based Reconstruction meets Rule-Based Anomaly Classification",
    "title_es": "Fuzzy Decisions on Fluid Instabilities: Autoencoder-Based Reconstruction meets Rule-Based Anomaly Classification",
    "url": "https://arxiv.org/abs/2508.05418",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05418v2 Announce Type: replace \nAbstract: Shockwave classification in shadowgraph imaging is challenging due to limited labeled data and complex flow structures. This study presents a hybrid framework that combines unsupervised autoencoder models with a fuzzy inference system to generate and interpret anomaly maps. Among the evaluated methods, the hybrid $\\beta$-VAE autoencoder with a fuzzy rule-based system most effectively captured coherent shock features, integrating spatial context to enhance anomaly classification. The resulting approach enables interpretable, unsupervised classification of flow disruptions and lays the groundwork for real-time, physics-informed diagnostics in experimental and industrial fluid applications.",
    "source": "arXiv"
  },
  {
    "title": "LAG: Logic-Augmented Generation from a Cartesian Perspective",
    "title_es": "LAG: Logic-Augmented Generation from a Cartesian Perspective",
    "url": "https://arxiv.org/abs/2508.05509",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05509v2 Announce Type: replace \nAbstract: Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet exhibit critical limitations in knowledge-intensive tasks, often generating hallucinations when faced with questions requiring specialized expertise. While retrieval-augmented generation (RAG) mitigates this by integrating external knowledge, it struggles with complex reasoning scenarios due to its reliance on direct semantic retrieval and lack of structured logical organization. Inspired by Cartesian principles from \\textit{Discours de la m\\'ethode}, this paper introduces Logic-Augmented Generation (LAG), a novel paradigm that reframes knowledge augmentation through systematic question decomposition and dependency-aware reasoning. Specifically, LAG first decomposes complex questions into atomic sub-questions ordered by logical dependencies. It then resolves these sequentially, using prior answers to guide context retrieval for subsequent sub-questions, ensuring stepwise grounding in logical chain. To prevent error propagation, LAG incorporates a logical termination mechanism that halts inference upon encountering unanswerable sub-questions and reduces wasted computation on excessive reasoning. Finally, it synthesizes all sub-resolutions to generate verified responses. Experiments on four benchmark datasets demonstrate that LAG significantly enhances reasoning robustness, reduces hallucination, and aligns LLM problem-solving with human cognition, offering a principled alternative to existing RAG systems.",
    "source": "arXiv"
  },
  {
    "title": "MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media",
    "title_es": "MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media",
    "url": "https://arxiv.org/abs/2508.05557",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05557v2 Announce Type: replace \nAbstract: Social media has evolved into a complex multimodal environment where text, images, and other signals interact to shape nuanced meanings, often concealing harmful intent. Identifying such intent, whether sarcasm, hate speech, or misinformation, remains challenging due to cross-modal contradictions, rapid cultural shifts, and subtle pragmatic cues. To address these challenges, we propose MV-Debate, a multi-view agent debate framework with dynamic reflection gating for unified multimodal harmful content detection. MV-Debate assembles four complementary debate agents, a surface analyst, a deep reasoner, a modality contrast, and a social contextualist, to analyze content from diverse interpretive perspectives. Through iterative debate and reflection, the agents refine responses under a reflection-gain criterion, ensuring both accuracy and efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate significantly outperforms strong single-model and existing multi-agent debate baselines. This work highlights the promise of multi-agent debate in advancing reliable social intent detection in safety-critical online contexts.",
    "source": "arXiv"
  },
  {
    "title": "Numerical analysis of the stochastic Navier-Stokes equations",
    "title_es": "Numerical analysis of the stochastic Navier-Stokes equations",
    "url": "https://arxiv.org/abs/2508.05564",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05564v2 Announce Type: replace \nAbstract: The developments over the last five decades concerning numerical discretisations of the incompressible Navier--Stokes equations have lead to reliable tools for their approximation: those include stable methods to properly address the incompressibility constraint, stable discretisations to account for convection dominated problems, efficient time (splitting) methods, and methods to tackle their nonlinear character. While these tools may successfully be applied to reliably simulate even more complex fluid flow PDE models, their understanding requires a fundamental revision in the case of stochastic fluid models, which are gaining increased importance nowadays.\n  This work motivates and surveys optimally convergent numerical methods for the stochastic Stokes and Navier--Stokes equations that were obtained in the last decades. Furtheremore, we computationally illustrate the failure of some of those methods from the deterministic setting, if they are straight-forwardly applied to the stochastic case. In fact, we explain why some of these deterministic methods perform sub-optimally by highlighting crucial analytical differences between the deterministic and stochastic equations -- and how modifications of the deterministic methods restore their optimal performance if they properly address the probabilistic nature of the stochastic problem.\n  Next to the numerical analysis of schemes, we propose a general benchmark of prototypic fluid flow problems driven by different types of noise to also compare new algorithms by simulations in terms of complexities, efficiencies, and possible limitations. The driving motivation is to reach a better comparison of simulations for new schemes in terms of accuracy and complexities, and to also complement theoretical performance studies for restricted settings of data by more realistic ones.",
    "source": "arXiv"
  },
  {
    "title": "MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy",
    "title_es": "MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy",
    "url": "https://arxiv.org/abs/2508.05592",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05592v2 Announce Type: replace \nAbstract: Large language models have achieved substantial progress in mathematical reasoning, yet their advancement is limited by the scarcity of high-quality, high-difficulty training data. Existing synthesis methods largely rely on transforming human-written templates, limiting both diversity and scalability. We propose MathSmith, a novel framework for synthesizing challenging mathematical problems to enhance LLM reasoning. Rather than modifying existing problems, MathSmith constructs new ones from scratch by randomly sampling concept-explanation pairs from PlanetMath, ensuring data independence and avoiding contamination. To increase difficulty, we design nine predefined strategies as soft constraints during rationales. We further adopts reinforcement learning to jointly optimize structural validity, reasoning complexity, and answer consistency. The length of the reasoning trace generated under autoregressive prompting is used to reflect cognitive complexity, encouraging the creation of more demanding problems aligned with long-chain-of-thought reasoning. Experiments across five benchmarks, categorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025, OlympiadBench), show that MathSmith consistently outperforms existing baselines under both short and long CoT settings. Additionally, a weakness-focused variant generation module enables targeted improvement on specific concepts. Overall, MathSmith exhibits strong scalability, generalization, and transferability, highlighting the promise of high-difficulty synthetic data in advancing LLM reasoning capabilities.",
    "source": "arXiv"
  },
  {
    "title": "Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards",
    "title_es": "Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards",
    "url": "https://arxiv.org/abs/2508.05658",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05658v2 Announce Type: replace \nAbstract: Various (text) prompt filters and (image) safety checkers have been implemented to mitigate the misuse of Text-to-Image (T2I) models in creating Not-Safe-For-Work (NSFW) content. In order to expose potential security vulnerabilities of such safeguards, multimodal jailbreaks have been studied. However, existing jailbreaks are limited to prompt-specific and image-specific perturbations, which suffer from poor scalability and time-consuming optimization. To address these limitations, we propose Universally Unfiltered and Unseen (U3)-Attack, a multimodal jailbreak attack method against T2I safeguards. Specifically, U3-Attack optimizes an adversarial patch on the image background to universally bypass safety checkers and optimizes a safe paraphrase set from a sensitive word to universally bypass prompt filters while eliminating redundant computations. Extensive experimental results demonstrate the superiority of our U3-Attack on both open-source and commercial T2I models. For example, on the commercial Runway-inpainting model with both prompt filter and safety checker, our U3-Attack achieves $~4\\times$ higher success rates than the state-of-the-art multimodal jailbreak attack, MMA-Diffusion.",
    "source": "arXiv"
  },
  {
    "title": "Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty",
    "title_es": "Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty",
    "url": "https://arxiv.org/abs/2508.05659",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05659v2 Announce Type: replace \nAbstract: Causal loop diagrams (CLDs) are widely used in health and environmental research to represent hypothesized causal structures underlying complex problems. However, as qualitative and static representations, CLDs are limited in their ability to support dynamic analysis and inform intervention strategies. Additionally, quantitative CLD analysis methods like network centrality analysis often lead to false inference. We propose Diagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory system dynamics models (SDMs) in the absence of empirical data. With minimal user input - following a protocol to label variables as stocks, flows or auxiliaries, and constants - D2D leverages the structural information already encoded in CLDs, namely, link existence and polarity, to simulate hypothetical interventions and explore potential leverage points under uncertainty. Results suggest that D2D helps distinguish between high- and low-ranked leverage points. We compare D2D to a data-driven SDM constructed from the same CLD and variable labels. D2D showed greater consistency with the data-driven model than network centrality analysis, while providing uncertainty estimates and guidance for future data collection. The method is implemented in an open-source Python package and a web-based application to support further testing and lower the barrier to dynamic modeling for researchers working with CLDs. We expect additional validation will further establish the approach's utility across a broad range of cases and domains.",
    "source": "arXiv"
  },
  {
    "title": "WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent",
    "title_es": "WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent",
    "url": "https://arxiv.org/abs/2508.05748",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05748v2 Announce Type: replace \nAbstract: Web agents such as Deep Research have demonstrated superhuman cognitive abilities, capable of solving highly challenging information-seeking problems. However, most research remains primarily text-centric, overlooking visual information in the real world. This makes multimodal Deep Research highly challenging, as such agents require much stronger reasoning abilities in perception, logic, knowledge, and the use of more sophisticated tools compared to text-based agents. To address this limitation, we introduce WebWatcher, a multi-modal Agent for Deep Research equipped with enhanced visual-language reasoning capabilities. It leverages high-quality synthetic multimodal trajectories for efficient cold start training, utilizes various tools for deep reasoning, and further enhances generalization through reinforcement learning. To better evaluate the capabilities of multimodal agents, we propose BrowseComp-VL, a benchmark with BrowseComp-style that requires complex information retrieval involving both visual and textual information. Experimental results show that WebWatcher significantly outperforms proprietary baseline, RAG workflow and open-source agents in four challenging VQA benchmarks, which paves the way for solving complex multimodal information-seeking tasks.",
    "source": "arXiv"
  },
  {
    "title": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models",
    "title_es": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.06038",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06038v2 Announce Type: replace \nAbstract: Vision-Language Models (VLMs) typically replace the predefined image placeholder token () in textual instructions with visual features from an image encoder, forming the input to a backbone Large Language Model (LLM). However, the large number of vision tokens significantly increases the context length, leading to high computational overhead and inference latency. While previous efforts mitigate this by selecting only important visual features or leveraging learnable queries to reduce token count, they often compromise performance or introduce substantial extra costs. In response, we propose Fourier-VLM, a simple yet efficient method that compresses visual representations in the frequency domain. Our approach is motivated by the observation that vision features output from the vision encoder exhibit concentrated energy in low-frequency components. Leveraging this, we apply a low-pass filter to the vision features using a two-dimensional Discrete Cosine Transform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier Transform (FFT) operator with a time complexity of $\\mathcal{O}(n\\log n)$, minimizing the extra computational cost while introducing no additional parameters. Extensive experiments across various image-based benchmarks demonstrate that Fourier-VLM achieves competitive performance with strong generalizability across both LLaVA and Qwen-VL architectures. Crucially, it reduce inference FLOPs by up to 83.8% and boots generation speed by 31.2% compared to LLaVA-v1.5, highlighting the superior efficiency and practicality.",
    "source": "arXiv"
  },
  {
    "title": "A Game-Theoretic Foundation for Bitcoin's Price: A Security-Utility Equilibrium",
    "title_es": "A Game-Theoretic Foundation for Bitcoin's Price: A Security-Utility Equilibrium",
    "url": "https://arxiv.org/abs/2508.06071",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06071v2 Announce Type: replace \nAbstract: This paper introduces a structural game-theoretic model to value decentralized digital assets like Bitcoin. Instead of relying on speculative beliefs, it frames the asset's price within a Rational-Expectations Security-Utility Nash Equilibrium (RESUNE). This equilibrium is a fixed point where the market-clearing price dictates the hash rate through a free-entry mining model, which in turn endogenously sets the network's security. The security, defined as one minus the probability of a 51% attack, is determined via a global games model of attacker coordination, providing a unique and continuous security function. We prove the existence of a RESUNE and offer conditions for its uniqueness and stability. The model predicts that the stabilizing direct effect of price on demand must outweigh the potentially destabilizing feedback from price to security. The framework generates testable predictions, such as a protocol halving causing a contraction in both hash rate and price. A structural Vector Autoregression (VAR) model is proposed to test this mechanism. The model decomposes Bitcoin's value into transactional utility, security, and speculative components and explains the observed unidirectional causality from price to hash rate.",
    "source": "arXiv"
  },
  {
    "title": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model",
    "title_es": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model",
    "url": "https://arxiv.org/abs/2508.06206",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06206v2 Announce Type: replace \nAbstract: Affordance grounding focuses on predicting the specific regions of objects that are associated with the actions to be performed by robots. It plays a vital role in the fields of human-robot interaction, human-object interaction, embodied manipulation, and embodied perception. Existing models often neglect the affordance shared among different objects because they lack the Chain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD) generalization and explicit reasoning capabilities. To address these challenges, we propose Affordance-R1, the first unified affordance grounding framework that integrates cognitive CoT guided Group Relative Policy Optimization (GRPO) within a reinforcement learning paradigm. Specifically, we designed a sophisticated affordance function, which contains format, perception, and cognition rewards to effectively guide optimization directions. Furthermore, we constructed a high-quality affordance-centric reasoning dataset, ReasonAff, to support training. Trained exclusively via reinforcement learning with GRPO and without explicit reasoning data, Affordance-R1 achieves robust zero-shot generalization and exhibits emergent test-time reasoning capabilities. Comprehensive experiments demonstrate that our model outperforms well-established methods and exhibits open-world generalization. To the best of our knowledge, Affordance-R1 is the first to integrate GRPO-based RL with reasoning into affordance reasoning. The code of our method and our dataset is released on https://github.com/hq-King/Affordance-R1.",
    "source": "arXiv"
  },
  {
    "title": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution",
    "title_es": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution",
    "url": "https://arxiv.org/abs/2508.06225",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06225v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are widely used as automated judges, where practical value depends on both accuracy and trustworthy, risk-aware judgments. Existing approaches predominantly focus on accuracy, overlooking the necessity of well-calibrated confidence, which is vital for adaptive and reliable evaluation pipelines. In this work, we advocate a shift from accuracy-centric evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing the necessity of well-calibrated confidence for trustworthy and adaptive evaluation. We systematically identify the Overconfidence Phenomenon in current LLM-as-a-Judges, where predicted confidence significantly overstates actual correctness, undermining reliability in practical deployment. To quantify this phenomenon, we introduce TH-Score, a novel metric measuring confidence-accuracy alignment. Furthermore, we propose LLM-as-a-Fuser, an ensemble framework that transforms LLMs into reliable, risk-aware evaluators. Extensive experiments demonstrate that our approach substantially improves calibration and enables adaptive, confidence-driven evaluation pipelines, achieving superior reliability and accuracy compared to existing baselines.",
    "source": "arXiv"
  },
  {
    "title": "Symmetry breaking for inductive logic programming",
    "title_es": "Symmetry breaking for inductive logic programming",
    "url": "https://arxiv.org/abs/2508.06263",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06263v2 Announce Type: replace \nAbstract: The goal of inductive logic programming is to search for a hypothesis that generalises training data and background knowledge. The challenge is searching vast hypothesis spaces, which is exacerbated because many logically equivalent hypotheses exist. To address this challenge, we introduce a method to break symmetries in the hypothesis space. We implement our idea in answer set programming. Our experiments on multiple domains, including visual reasoning and game playing, show that our approach can reduce solving times from over an hour to just 17 seconds.",
    "source": "arXiv"
  },
  {
    "title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation",
    "title_es": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation",
    "url": "https://arxiv.org/abs/2508.06387",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06387v2 Announce Type: replace \nAbstract: Text-to-SQL bridges the gap between natural language and structured database language, thus allowing non-technical users to easily query databases. Traditional approaches model text-to-SQL as a direct translation task, where a given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances in large language models (LLMs) have significantly improved translation accuracy, however, these methods all require that the target database is pre-specified. This becomes problematic in scenarios with multiple extensive databases, where identifying the correct database becomes a crucial yet overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL framework to identify the user's intended database before generating SQL queries. Our approach leverages LLMs and prompt engineering to extract implicit information from natural language queries (NLQs) in the form of a ruleset. We then train a large db\\_id prediction model, which includes a RoBERTa-based finetuned encoder, to predict the correct Database identifier (db\\_id) based on both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL by using critic agents to correct errors. Experimental results demonstrate that our framework outperforms the current state-of-the-art models in both database intent prediction and SQL generation accuracy.",
    "source": "arXiv"
  },
  {
    "title": "A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images",
    "title_es": "A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images",
    "url": "https://arxiv.org/abs/2508.06409",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.06409v2 Announce Type: replace \nAbstract: Homelessness in the United States has surged to levels unseen since the Great Depression. However, existing methods for monitoring it, such as point-in-time (PIT) counts, have limitations in terms of frequency, consistency, and spatial detail. This study proposes a new approach using publicly available, crowdsourced data, specifically 311 Service Calls and street-level imagery, to track and forecast homeless tent trends in San Francisco. Our predictive model captures fine-grained daily and neighborhood-level variations, uncovering patterns that traditional counts often overlook, such as rapid fluctuations during the COVID-19 pandemic and spatial shifts in tent locations over time. By providing more timely, localized, and cost-effective information, this approach serves as a valuable tool for guiding policy responses and evaluating interventions aimed at reducing unsheltered homelessness.",
    "source": "arXiv"
  },
  {
    "title": "Accurate Measles Rash Detection via Vision Transformer Fine-Tuning",
    "title_es": "Accurate Measles Rash Detection via Vision Transformer Fine-Tuning",
    "url": "https://arxiv.org/abs/2005.09112",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2005.09112v5 Announce Type: replace-cross \nAbstract: Measles, a highly contagious disease declared eliminated in the United States in 2000 after decades of successful vaccination campaigns, resurged in 2025, with 1,356 confirmed cases reported as of August 5, 2025. Given its rapid spread among susceptible individuals, fast and reliable diagnostic systems are critical for early prevention and containment. In this work, we applied transfer learning to fine-tune a pretrained Data-efficient Image Transformer (DeiT) model for distinguishing measles rashes from other skin conditions. Trained on a diverse, curated skin rash image dataset, the DeiT model achieved a median classification accuracy of 96.38%, precision of 96.24%, recall of 96.38%, and an F1-score of 96.23%, demonstrating high effectiveness in accurate detection to aid outbreak control. We also compared the DeiT model with a convolutional neural network, ResNet-50, and discussed the directions for future research.",
    "source": "arXiv"
  },
  {
    "title": "Online Learning and Optimization for Queues with Unknown Demand Curve and Service Distribution",
    "title_es": "Online Learning and Optimization for Queues with Unknown Demand Curve and Service Distribution",
    "url": "https://arxiv.org/abs/2303.03399",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2303.03399v2 Announce Type: replace-cross \nAbstract: We investigate an optimization problem in a queueing system where the service provider selects the optimal service fee p and service capacity \\mu to maximize the cumulative expected profit (the service revenue minus the capacity cost and delay penalty). The conventional predict-then-optimize (PTO) approach takes two steps: first, it estimates the model parameters (e.g., arrival rate and service-time distribution) from data; second, it optimizes a model based on the estimated parameters. A major drawback of PTO is that its solution accuracy can often be highly sensitive to the parameter estimation errors because PTO is unable to properly link these errors (step 1) to the quality of the optimized solutions (step 2). To remedy this issue, we develop an online learning framework that automatically incorporates the aforementioned parameter estimation errors in the solution prescription process; it is an integrated method that can \"learn\" the optimal solution without needing to set up the parameter estimation as a separate step as in PTO. Effectiveness of our online learning approach is substantiated by (i) theoretical results including the algorithm convergence and analysis of the regret (\"cost\" to pay over time for the algorithm to learn the optimal policy), and (ii) engineering confirmation via simulation experiments of a variety of representative examples. We also provide careful comparisons for PTO and the online learning method.",
    "source": "arXiv"
  },
  {
    "title": "Thompson Exploration with Best Challenger Rule in Best Arm Identification",
    "title_es": "Thompson Exploration with Best Challenger Rule in Best Arm Identification",
    "url": "https://arxiv.org/abs/2310.00539",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2310.00539v4 Announce Type: replace-cross \nAbstract: This paper studies the fixed-confidence best arm identification (BAI) problem in the bandit framework in the canonical single-parameter exponential models. For this problem, many policies have been proposed, but most of them require solving an optimization problem at every round and/or are forced to explore an arm at least a certain number of times except those restricted to the Gaussian model. To address these limitations, we propose a novel policy that combines Thompson sampling with a computationally efficient approach known as the best challenger rule. While Thompson sampling was originally considered for maximizing the cumulative reward, we demonstrate that it can be used to naturally explore arms in BAI without forcing it. We show that our policy is asymptotically optimal for any two-armed bandit problems and achieves near optimality for general $K$-armed bandit problems for $K\\geq 3$. Nevertheless, in numerical experiments, our policy shows competitive performance compared to asymptotically optimal policies in terms of sample complexity while requiring less computation cost. In addition, we highlight the advantages of our policy by comparing it to the concept of $\\beta$-optimality, a relaxed notion of asymptotic optimality commonly considered in the analysis of a class of policies including the proposed one.",
    "source": "arXiv"
  },
  {
    "title": "A Deep Learning Based Resource Allocator for Communication Networks with Dynamic User Utility Demands",
    "title_es": "A Deep Learning Based Resource Allocator for Communication Networks with Dynamic User Utility Demands",
    "url": "https://arxiv.org/abs/2311.04600",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2311.04600v3 Announce Type: replace-cross \nAbstract: Deep learning (DL) based resource allocation (RA) has recently gained significant attention due to its performance efficiency. However, most related studies assume an ideal case where the number of users and their utility demands, e.g., data rate constraints, are fixed, and the designed DL-based RA scheme exploits a policy trained only for these fixed parameters. Consequently, computationally complex policy retraining is required whenever these parameters change. In this paper, we introduce a DL-based resource allocator (ALCOR) that allows users to adjust their utility demands freely, such as based on their application layer requirements. ALCOR employs deep neural networks (DNNs) as the policy in a time-sharing problem. The underlying optimization algorithm iteratively optimizes the on-off status of users to satisfy their utility demands in expectation. The policy performs unconstrained RA (URA) -- RA without considering user utility demands -- among active users to maximize the sum utility (SU) at each time instant. Depending on the chosen URA scheme, ALCOR can perform RA in either a centralized or distributed scenario. The derived convergence analyses provide theoretical guarantees for ALCOR's convergence, and numerical experiments corroborate its effectiveness compared to meta-learning and reinforcement learning approaches.",
    "source": "arXiv"
  },
  {
    "title": "Training 3D ResNets to Extract BSM Physics Parameters from Simulated Data",
    "title_es": "Training 3D ResNets to Extract BSM Physics Parameters from Simulated Data",
    "url": "https://arxiv.org/abs/2311.13060",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2311.13060v4 Announce Type: replace-cross \nAbstract: We report on a novel application of computer vision techniques to extract beyond the Standard Model parameters directly from high energy physics flavor data. We propose a novel data representation that transforms the angular and kinematic distributions into ``quasi-images\", which are used to train a convolutional neural network to perform regression tasks, similar to fitting. As a proof-of-concept, we train a 34-layer Residual Neural Network to regress on these images and determine information about the Wilson Coefficient $C_{9}$ in Monte Carlo simulations of $B^0 \\rightarrow K^{*0}\\mu^{+}\\mu^{-}$ decays. The method described here can be generalized and may find applicability across a variety of experiments.",
    "source": "arXiv"
  },
  {
    "title": "A variational Bayes approach to debiased inference for low-dimensional parameters in high-dimensional linear regression",
    "title_es": "A variational Bayes approach to debiased inference for low-dimensional parameters in high-dimensional linear regression",
    "url": "https://arxiv.org/abs/2406.12659",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.12659v2 Announce Type: replace-cross \nAbstract: We propose a scalable variational Bayes method for statistical inference for a single or low-dimensional subset of the coordinates of a high-dimensional parameter in sparse linear regression. Our approach relies on assigning a mean-field approximation to the nuisance coordinates and carefully modelling the conditional distribution of the target given the nuisance. This requires only a preprocessing step and preserves the computational advantages of mean-field variational Bayes, while ensuring accurate and reliable inference for the target parameter, including for uncertainty quantification. We investigate the numerical performance of our algorithm, showing that it performs competitively with existing methods. We further establish accompanying theoretical guarantees for estimation and uncertainty quantification in the form of a Bernstein--von Mises theorem.",
    "source": "arXiv"
  },
  {
    "title": "RNA-FrameFlow: Flow Matching for de novo 3D RNA Backbone Design",
    "title_es": "RNA-FrameFlow: Flow Matching for de novo 3D RNA Backbone Design",
    "url": "https://arxiv.org/abs/2406.13839",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.13839v4 Announce Type: replace-cross \nAbstract: We introduce RNA-FrameFlow, the first generative model for 3D RNA backbone design. We build upon SE(3) flow matching for protein backbone generation and establish protocols for data preparation and evaluation to address unique challenges posed by RNA modeling. We formulate RNA structures as a set of rigid-body frames and associated loss functions which account for larger, more conformationally flexible RNA backbones (13 atoms per nucleotide) vs. proteins (4 atoms per residue). Toward tackling the lack of diversity in 3D RNA datasets, we explore training with structural clustering and cropping augmentations. Additionally, we define a suite of evaluation metrics to measure whether the generated RNA structures are globally self-consistent (via inverse folding followed by forward folding) and locally recover RNA-specific structural descriptors. The most performant version of RNA-FrameFlow generates locally realistic RNA backbones of 40-150 nucleotides, over 40% of which pass our validity criteria as measured by a self-consistency TM-score >= 0.45, at which two RNAs have the same global fold. Open-source code: https://github.com/rish-16/rna-backbone-design",
    "source": "arXiv"
  },
  {
    "title": "Model Predictive Control on the Neural Manifold",
    "title_es": "Model Predictive Control on the Neural Manifold",
    "url": "https://arxiv.org/abs/2406.14801",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2406.14801v2 Announce Type: replace-cross \nAbstract: Neural manifolds are an attractive theoretical framework for characterizing the complex behaviors of neural populations. However, many of the tools for identifying these low-dimensional subspaces are correlational and provide limited insight into the underlying dynamics. The ability to precisely control the latent activity of a circuit would allow researchers to investigate the structure and function of neural manifolds. We simulate controlling the latent dynamics of a neural population using closed-loop, dynamically generated sensory inputs. Using a spiking neural network (SNN) as a model of a neural circuit, we find low-dimensional representations of both the network activity (the neural manifold) and a set of salient visual stimuli. The fields of classical and optimal control offer a range of methods to choose from for controlling dynamics on the neural manifold, which differ in performance, computational cost, and ease of implementation. Here, we focus on two commonly used control methods: proportional-integral-derivative (PID) control and model predictive control (MPC). PID is a computationally lightweight controller that is simple to implement. In contrast, MPC is a model-based, anticipatory controller with a much higher computational cost and engineering overhead. We evaluate both methods on trajectory-following tasks in latent space, under partial observability and in the presence of unknown noise. While both controllers in some cases were able to successfully control the latent dynamics on the neural manifold, MPC consistently produced more accurate control and required less hyperparameter tuning. These results demonstrate how MPC can be applied on the neural manifold using data-driven dynamics models, and provide a framework to experimentally test for causal relationships between manifold dynamics and external stimuli.",
    "source": "arXiv"
  },
  {
    "title": "Less is More: Skim Transformer for Light Field Image Super-resolution",
    "title_es": "Less is More: Skim Transformer for Light Field Image Super-resolution",
    "url": "https://arxiv.org/abs/2407.15329",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2407.15329v2 Announce Type: replace-cross \nAbstract: A light field image captures scenes through an array of micro-lenses, providing a rich representation that encompasses spatial and angular information. While this richness comes at the cost of significant data redundancy, most existing light field methods still tend to indiscriminately utilize all the information from sub-aperture images (SAIs) in an attempt to harness every visual cue regardless of their disparity significance. However, this paradigm inevitably leads to disparity entanglement, a fundamental cause of inefficiency in light field image processing. To address this limitation, we introduce the Skim Transformer, a novel architecture inspired by the ``less is more\" philosophy. Unlike conventional light field Transformers, our Skim Transformer features a multi-branch structure where each branch is dedicated to a specific disparity range by constructing its attention score matrix over a skimmed subset of SAIs, rather than all of them. Building upon this core component, we present SkimLFSR, an efficient yet powerful network for light field super-resolution (LFSR). Requiring only 67\\% of parameters, SkimLFSR achieves state-of-the-art results surpassing the best existing method by an average of 0.59 dB and 0.35 dB in PSNR at the 2x and 4x tasks, respectively. Through in-depth analyses, we reveal that SkimLFSR, guided by the predefined skimmed SAI sets as prior knowledge, demonstrates distinct disparity-aware behaviors in attending to visual cues. These findings highlight its effectiveness and adaptability as a promising paradigm for light field image processing.",
    "source": "arXiv"
  },
  {
    "title": "FQGA-single: Towards Fewer Training Epochs and Fewer Model Parameters for Image-to-Image Translation Tasks",
    "title_es": "FQGA-single: Towards Fewer Training Epochs and Fewer Model Parameters for Image-to-Image Translation Tasks",
    "url": "https://arxiv.org/abs/2408.09218",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.09218v4 Announce Type: replace-cross \nAbstract: This paper proposes a novel model inspired by CycleGAN: FQGA-single to produce high quality medical synthetic CT (sCT) generated images more efficiently. Evaluations were done on the SynthRAD Grand Challenge dataset with the CycleGAN model used for benchmarking and for comparing the quality of CBCT-to-sCT generated images from both a quantitative and qualitative perspective. Finally, this paper also explores ideas from the paper \"One Epoch Is All You Need\" to compare models trained on a single epoch versus multiple epochs. Astonishing results from FQGA-single were obtained during this exploratory experiment, which show that the performance of FQGA-single when trained on a single epoch surpasses itself when trained on multiple epochs. More surprising is that its performance also surpasses CycleGAN's multiple-epoch and single-epoch models, and even a modified version of CycleGAN.",
    "source": "arXiv"
  },
  {
    "title": "A nonlinear elasticity model in computer vision",
    "title_es": "A nonlinear elasticity model in computer vision",
    "url": "https://arxiv.org/abs/2408.17237",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2408.17237v4 Announce Type: replace-cross \nAbstract: The purpose of this paper is to analyze a nonlinear elasticity model introduced by the authors for comparing two images, regarded as bounded open subsets of $\\R^n$ together with associated vector-valued intensity maps. Optimal transformations between the images are sought as minimisers of an integral functional among orientation-preserving homeomorphisms. The existence of minimisers is proved under natural coercivity and polyconvexity conditions, assuming only that the intensity functions are bounded measurable. Variants of the existence theorem are also proved, first under the constraint that finite sets of landmark points in the two images are mapped one to the other, and second when one image is to be compared to an unknown part of another.\n  The question is studied as to whether for images related by an affine mapping the unique minimiser is given by that affine mapping. For a natural class of functional integrands an example is given guaranteeing that this property holds for pairs of images in which the second is a scaling of the first by a constant factor. However for the property to hold for arbitrary pairs of affinely related images it is shown that the integrand has to depend on the gradient of the transformation as a convex function of its determinant alone. This suggests a new model in which the integrand depends also on second derivatives of the transformation, and an example is given for which both existence of minimisers is assured and the above property holds for all pairs of affinely related images.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Theoretical Illumination for Efficient Low-Light Image Enhancement",
    "title_es": "Rethinking Theoretical Illumination for Efficient Low-Light Image Enhancement",
    "url": "https://arxiv.org/abs/2409.05274",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.05274v4 Announce Type: replace-cross \nAbstract: Enhancing low-light images remains a critical challenge in computer vision, as does designing lightweight models for edge devices that can handle the computational demands of deep learning. This article introduces an extended version of the Channel-Prior and Gamma-Estimation Network (CPGA-Net), termed CPGA-Net+, incorporating the theoretically-based Attentions for illumination in local and global processing. Additionally, we assess our approach through a theoretical analysis of the block design by introducing both an ultra-lightweight and a stronger version, following the same design principles. The lightweight version significantly reduces computational costs by over two-thirds by utilizing the local branch as an auxiliary component. Meanwhile, the stronger version achieves an impressive balance by maximizing local and global processing capabilities. Our proposed methods have been validated as effective compared to recent lightweight approaches, offering superior performance and scalable solutions with limited computational resources.",
    "source": "arXiv"
  },
  {
    "title": "EEG-Language Pretraining for Highly Label-Efficient Clinical Phenotyping",
    "title_es": "EEG-Language Pretraining for Highly Label-Efficient Clinical Phenotyping",
    "url": "https://arxiv.org/abs/2409.07480",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.07480v4 Announce Type: replace-cross \nAbstract: Multimodal language modeling has enabled breakthroughs for representation learning, yet remains unexplored in the realm of functional brain data for clinical phenotyping. This paper pioneers EEG-language models (ELMs) trained on clinical reports and 15000 EEGs. We propose to combine multimodal alignment in this novel domain with timeseries cropping and text segmentation, enabling an extension based on multiple instance learning to alleviate misalignment between irrelevant EEG or text segments. Our multimodal models significantly improve over EEG-only models across four clinical evaluations and for the first time enable zero-shot classification as well as retrieval of both neural signals and reports. In sum, these results highlight the potential of ELMs, representing significant progress for clinical applications.",
    "source": "arXiv"
  },
  {
    "title": "A Plug-and-Play Method for Guided Multi-contrast MRI Reconstruction based on Content/Style Modeling",
    "title_es": "A Plug-and-Play Method for Guided Multi-contrast MRI Reconstruction based on Content/Style Modeling",
    "url": "https://arxiv.org/abs/2409.13477",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.13477v4 Announce Type: replace-cross \nAbstract: Since multiple MRI contrasts of the same anatomy contain redundant information, one contrast can guide the reconstruction of an undersampled subsequent contrast. To this end, several end-to-end learning-based guided reconstruction methods have been proposed. However, a key challenge is the requirement of large paired training datasets comprising raw data and aligned reference images. We propose a modular two-stage approach addressing this issue, additionally providing an explanatory framework for the multi-contrast problem based on the shared and non-shared generative factors underlying two given contrasts. A content/style model of two-contrast image data is learned from a largely unpaired image-domain dataset and is subsequently applied as a plug-and-play operator in iterative reconstruction. The disentanglement of content and style allows explicit representation of contrast-independent and contrast-specific factors. Consequently, incorporating prior information into the reconstruction reduces to a simple replacement of the aliased content of the reconstruction iterate with high-quality content derived from the reference scan. Combining this component with a data consistency step and introducing a general corrective process for the content yields an iterative scheme. We name this novel approach PnP-CoSMo. Various aspects like interpretability and convergence are explored via simulations. Furthermore, its practicality is demonstrated on the public NYU fastMRI DICOM dataset, showing improved generalizability compared to end-to-end methods, and on two in-house multi-coil raw datasets, offering up to 32.6% more acceleration over learning-based non-guided reconstruction for a given SSIM.",
    "source": "arXiv"
  },
  {
    "title": "Blown up by an equilateral: Poncelet triangles about the incircle and their degeneracies",
    "title_es": "Blown up by an equilateral: Poncelet triangles about the incircle and their degeneracies",
    "url": "https://arxiv.org/abs/2409.19464",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.19464v5 Announce Type: replace-cross \nAbstract: We tour several Euclidean properties of Poncelet triangles inscribed in an ellipse and circumscribing the incircle, including loci of triangle centers and envelopes of key objects. We also show that a number of degenerate behaviors are triggered by the presence of an equilateral triangle in the family.",
    "source": "arXiv"
  },
  {
    "title": "\"What\" x \"When\" working memory representations using Laplace Neural Manifolds",
    "title_es": "\"What\" x \"When\" working memory representations using Laplace Neural Manifolds",
    "url": "https://arxiv.org/abs/2409.20484",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2409.20484v2 Announce Type: replace-cross \nAbstract: Working memory - the ability to remember recent events as they recede continuously into the past - requires the ability to represent any stimulus at any time delay. This property requires neurons coding working memory to show mixed selectivity, with conjunctive receptive fields (RFs) for stimuli and time, forming a representation of 'what' x 'when'. We study the properties of such a working memory in simple experiments where a single stimulus must be remembered for a short time. The requirement of conjunctive receptive fields allows the covariance matrix of the network to decouple neatly, allowing an understanding of the low-dimensional dynamics of the population. Different choices of temporal basis functions lead to qualitatively different dynamics. We study a specific choice - a Laplace space with exponential basis functions for time coupled to an \"Inverse Laplace\" space with circumscribed basis functions in time. We refer to this choice with basis functions that evenly tile log time as a Laplace Neural Manifold. Despite the fact that they are related to one another by a linear projection, the Laplace population shows a stable stimulus-specific subspace whereas the Inverse Laplace population shows rotational dynamics. The growth of the rank of the covariance matrix with time depends on the density of the temporal basis set; logarithmic tiling shows good agreement with data. We sketch a continuous attractor CANN that constructs a Laplace Neural Manifold. The attractor in the Laplace space appears as an edge; the attractor for the inverse space appears as a bump. This work provides a map for going from more abstract cognitive models of WM to circuit-level implementation using continuous attractor neural networks, and places constraints on the types of neural dynamics that support working memory.",
    "source": "arXiv"
  },
  {
    "title": "Quantum-data-driven dynamical transition in quantum learning",
    "title_es": "Quantum-data-driven dynamical transition in quantum learning",
    "url": "https://arxiv.org/abs/2410.01955",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.01955v2 Announce Type: replace-cross \nAbstract: Quantum neural networks, parameterized quantum circuits optimized under a specific cost function, provide a paradigm for achieving near-term quantum advantage in quantum information processing. Understanding QNN training dynamics is crucial for optimizing their performance, however, the role of quantum data in training for supervised learning such as classification and regression remains unclear. We reveal a quantum-data-driven dynamical transition where the target values and data determine the convergence of the training. Through analytical classification over the fixed points of the dynamical equation, we reveal a comprehensive `phase diagram' featuring seven distinct dynamics originating from a bifurcation with multiple codimension. Perturbative analyses identify both exponential and polynomial convergence class. We provide a non-perturbative theory to explain the transition via generalized restricted Haar ensemble. The analytical results are confirmed with numerical simulations and experimentation on IBM quantum devices. Our findings provide guidance on constructing the cost function to accelerate convergence in QNN training.",
    "source": "arXiv"
  },
  {
    "title": "Tensor Decomposition with Unaligned Observations",
    "title_es": "Tensor Decomposition with Unaligned Observations",
    "url": "https://arxiv.org/abs/2410.14046",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2410.14046v2 Announce Type: replace-cross \nAbstract: This paper presents a canonical polyadic (CP) tensor decomposition that addresses unaligned observations. The mode with unaligned observations is represented using functions in a reproducing kernel Hilbert space (RKHS). We introduce a versatile loss function that effectively accounts for various types of data, including binary, integer-valued, and positive-valued types. Additionally, we propose an optimization algorithm for computing tensor decompositions with unaligned observations, along with a stochastic gradient method to enhance computational efficiency. A sketching algorithm is also introduced to further improve efficiency when using the $\\ell_2$ loss function. To demonstrate the efficacy of our methods, we provide illustrative examples using both synthetic data and an early childhood human microbiome dataset.",
    "source": "arXiv"
  },
  {
    "title": "Gradient Descent Finds Over-Parameterized Neural Networks with Sharp Generalization for Nonparametric Regression",
    "title_es": "Gradient Descent Finds Over-Parameterized Neural Networks with Sharp Generalization for Nonparametric Regression",
    "url": "https://arxiv.org/abs/2411.02904",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.02904v5 Announce Type: replace-cross \nAbstract: We study nonparametric regression by an over-parameterized two-layer neural network trained by gradient descent (GD) in this paper. We show that, if the neural network is trained by GD with early stopping, then the trained network renders a sharp rate of the nonparametric regression risk of $\\mathcal{O}(\\epsilon_n^2)$, which is the same rate as that for the classical kernel regression trained by GD with early stopping, where $\\epsilon_n$ is the critical population rate of the Neural Tangent Kernel (NTK) associated with the network and $n$ is the size of the training data. It is remarked that our result does not require distributional assumptions about the covariate as long as the covariate is bounded, in a strong contrast with many existing results which rely on specific distributions of the covariates such as the spherical uniform data distribution or distributions satisfying certain restrictive conditions. The rate $\\mathcal{O}(\\epsilon_n^2)$ is known to be minimax optimal for specific cases, such as the case that the NTK has a polynomial eigenvalue decay rate which happens under certain distributional assumptions on the covariates. Our result formally fills the gap between training a classical kernel regression model and training an over-parameterized but finite-width neural network by GD for nonparametric regression without distributional assumptions on the bounded covariate. We also provide confirmative answers to certain open questions or address particular concerns in the literature of training over-parameterized neural networks by GD with early stopping for nonparametric regression, including the characterization of the stopping time, the lower bound for the network width, and the constant learning rate used in GD.",
    "source": "arXiv"
  },
  {
    "title": "Quantum Policy Gradient in Reproducing Kernel Hilbert Space",
    "title_es": "Quantum Policy Gradient in Reproducing Kernel Hilbert Space",
    "url": "https://arxiv.org/abs/2411.06650",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.06650v5 Announce Type: replace-cross \nAbstract: Parametrised quantum circuits offer expressive and data-efficient representations for machine learning. Due to quantum states residing in a high-dimensional Hilbert space, parametrised quantum circuits have a natural interpretation in terms of kernel methods. The representation of quantum circuits in terms of quantum kernels has been studied widely in quantum supervised learning, but has been overlooked in the context of quantum RL. This paper proposes the use of kernel policies and quantum policy gradient algorithms for quantum-accessible environments. After discussing the properties of such policies and a demonstration of classical policy gradient on a coherent policy in a quantum environment, we propose parametric and non-parametric policy gradient and actor-critic algorithms with quantum kernel policies in quantum environments. This approach, implemented with both numerical and analytical quantum policy gradient techniques, allows exploiting the many advantages of kernel methods, including data-driven forms for functions (and their gradients) as well as tunable expressiveness. The proposed approach is suitable for vector-valued action spaces and each of the formulations demonstrates a quadratic reduction in query complexity compared to their classical counterparts. We propose actor-critic algorithms based on stochastic policy gradient, deterministic policy gradient, and natural policy gradient, and demonstrate additional query complexity reductions compared to quantum policy gradient algorithms under favourable conditions.",
    "source": "arXiv"
  },
  {
    "title": "Pairwise Markov Chains for Volatility Forecasting",
    "title_es": "Pairwise Markov Chains for Volatility Forecasting",
    "url": "https://arxiv.org/abs/2411.11838",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.11838v3 Announce Type: replace-cross \nAbstract: The Pairwise Markov Chain (PMC) is a probabilistic graphical model extending the well-known Hidden Markov Model. This model, although highly effective for many tasks, has been scarcely utilized for continuous value prediction. This is mainly due to the issue of modeling observations inherent in generative probabilistic models. In this paper, we introduce a new algorithm for prediction with the PMC. On the one hand, this algorithm allows circumventing the feature problem, thus fully exploiting the capabilities of the PMC. On the other hand, it enables the PMC to extend any predictive model by introducing hidden states, updated at each time step, and allowing the introduction of non-stationarity for any model. We apply the PMC with its new algorithm for volatility forecasting, which we compare to the highly popular GARCH(1,1) and feedforward neural models across numerous pairs. This is particularly relevant given the regime changes that we can observe in volatility. For each scenario, our algorithm enhances the performance of the extended model, demonstrating the value of our approach.",
    "source": "arXiv"
  },
  {
    "title": "Characterizing and Transforming DAGs within the I-LCA Framework",
    "title_es": "Characterizing and Transforming DAGs within the I-LCA Framework",
    "url": "https://arxiv.org/abs/2411.14057",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2411.14057v2 Announce Type: replace-cross \nAbstract: We explore the connections between clusters and least common ancestors (LCAs) in directed acyclic graphs (DAGs), focusing on the interplay between so-called $I$-lca-relevant DAGs and DAGs with the $I$-lca-property. Here, $I$ denotes a set of integers. In $I$-lca-relevant DAGs, each vertex is the unique LCA for some subset $A$ of leaves of size $|A|\\in I$, whereas in a DAG with the $I$-lca-property there exists a unique LCA for every subset $A$ of leaves satisfying $|A|\\in I$. We elaborate on the difference between these two properties and establish their close relationship to pre-$I$-ary and $I$-ary set systems. This, in turn, generalizes results established for (pre-)binary and $k$-ary set systems. Moreover, we build upon recently established results that use a simple operator $\\ominus$, enabling the transformation of arbitrary DAGs into $I$-lca-relevant DAGs. This process reduces unnecessary complexity while preserving key structural properties of the original DAG. The set $C_G$ consists of all clusters in a DAG $G$, where clusters correspond to the descendant leaves of vertices. While in some cases $C_H = C_G$ when transforming $G$ into an $I$-lca-relevant DAG $H$, it often happens that certain clusters in $C_G$ do not appear as clusters in $H$. To understand this phenomenon in detail, we characterize the subset of clusters in $C_G$ that remain in $H$ for DAGs $G$ with the $I$-lca-property. Furthermore, we show that the set $W$ of vertices required to transform $G$ into $H = G \\ominus W$ is uniquely determined for such DAGs. This, in turn, allows us to show that the ``shortcut-free'' version of the transformed DAG $H$ is always a tree or a galled-tree whenever $C_G$ represents the clustering system of a tree or galled-tree and $G$ has the $I$-lca-property. In the latter case $C_H = C_G$ always holds.",
    "source": "arXiv"
  },
  {
    "title": "Reconstruction of boosted and resolved multi-Higgs-boson events with symmetry-preserving attention networks",
    "title_es": "Reconstruction of boosted and resolved multi-Higgs-boson events with symmetry-preserving attention networks",
    "url": "https://arxiv.org/abs/2412.03819",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.03819v3 Announce Type: replace-cross \nAbstract: The production of multiple Higgs bosons at the CERN LHC provides a direct way to measure the trilinear and quartic Higgs self-interaction strengths as well as potential access to beyond the standard model effects that can enhance production at large transverse momentum $p_{\\mathrm{T}}$. The largest event fraction arises from the fully hadronic final state in which every Higgs boson decays to a bottom quark-antiquark pair ($b\\bar{b}$). This introduces a combinatorial challenge known as the \\emph{jet assignment problem}: assigning jets to sets representing Higgs boson candidates. Symmetry-preserving attention networks (SPA-Nets) have been been developed to address this challenge. However, the complexity of jet assignment increases when simultaneously considering both $H\\rightarrow b\\bar{b}$ reconstruction possibilities, i.e., two \"resolved\" small-radius jets each containing a shower initiated by a $b$-quark or one \"boosted\" large-radius jet containing a merged shower initiated by a $b\\bar{b}$ pair. The latter improves the reconstruction efficiency at high $p_{\\mathrm{T}}$. In this work, we introduce a generalization to the SPA-Net approach to simultaneously consider both boosted and resolved reconstruction possibilities and unambiguously interpret an event as \"fully resolved'', \"fully boosted\", or in between. We report the performance of baseline methods, the original SPA-Net approach, and our generalized version on nonresonant $HH$ and $HHH$ production at the LHC. Considering both boosted and resolved topologies, our SPA-Net approach increases the Higgs boson reconstruction purity by 57--62\\% and the efficiency by 23--38\\% compared to the baseline method depending on the final state.",
    "source": "arXiv"
  },
  {
    "title": "Characterization of Exponential Families of Lumpable Stochastic Matrices",
    "title_es": "Characterization of Exponential Families of Lumpable Stochastic Matrices",
    "url": "https://arxiv.org/abs/2412.08400",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.08400v2 Announce Type: replace-cross \nAbstract: It is known that the set of lumpable Markov chains over a finite state space, with respect to a fixed lumping function, generally does not form an exponential family of stochastic matrices. In this work, we explore efficiently verifiable necessary and sufficient conditions for families of lumpable transition matrices to form exponential families. To this end, we develop a broadly applicable dimension-based method for determining whether a given family of stochastic matrices forms an exponential family.",
    "source": "arXiv"
  },
  {
    "title": "Mamba-based Deep Learning Approach for Sleep Staging on a Wireless Multimodal Wearable System without Electroencephalography",
    "title_es": "Mamba-based Deep Learning Approach for Sleep Staging on a Wireless Multimodal Wearable System without Electroencephalography",
    "url": "https://arxiv.org/abs/2412.15947",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.15947v3 Announce Type: replace-cross \nAbstract: Study Objectives: We investigate a Mamba-based deep learning approach for sleep staging on signals from ANNE One (Sibel Health, Evanston, IL), a non-intrusive dual-module wireless wearable system measuring chest electrocardiography (ECG), triaxial accelerometry, and chest temperature, and finger photoplethysmography and finger temperature.\n  Methods: We obtained wearable sensor recordings from 357 adults undergoing concurrent polysomnography (PSG) at a tertiary care sleep lab. Each PSG recording was manually scored and these annotations served as ground truth labels for training and evaluation of our models. PSG and wearable sensor data were automatically aligned using their ECG channels with manual confirmation by visual inspection. We trained a Mamba-based recurrent neural network architecture on these recordings. Ensembling of model variants with similar architectures was performed.\n  Results: After ensembling, the model attains a 3-class (wake, non rapid eye movement [NREM] sleep, rapid eye movement [REM] sleep) balanced accuracy of 84.02%, F1 score of 84.23%, Cohen's $\\kappa$ of 72.89%, and a Matthews correlation coefficient (MCC) score of 73.00%; a 4-class (wake, light NREM [N1/N2], deep NREM [N3], REM) balanced accuracy of 75.30%, F1 score of 74.10%, Cohen's $\\kappa$ of 61.51%, and MCC score of 61.95%; a 5-class (wake, N1, N2, N3, REM) balanced accuracy of 65.11%, F1 score of 66.15%, Cohen's $\\kappa$ of 53.23%, MCC score of 54.38%.\n  Conclusions: Our Mamba-based deep learning model can successfully infer major sleep stages from the ANNE One, a wearable system without electroencephalography (EEG), and can be applied to data from adults attending a tertiary care sleep clinic.",
    "source": "arXiv"
  },
  {
    "title": "Mean--Variance Portfolio Selection by Continuous-Time Reinforcement Learning: Algorithms, Regret Analysis, and Empirical Study",
    "title_es": "Mean--Variance Portfolio Selection by Continuous-Time Reinforcement Learning: Algorithms, Regret Analysis, and Empirical Study",
    "url": "https://arxiv.org/abs/2412.16175",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2412.16175v2 Announce Type: replace-cross \nAbstract: We study continuous-time mean--variance portfolio selection in markets where stock prices are diffusion processes driven by observable factors that are also diffusion processes, yet the coefficients of these processes are unknown. Based on the recently developed reinforcement learning (RL) theory for diffusion processes, we present a general data-driven RL algorithm that learns the pre-committed investment strategy directly without attempting to learn or estimate the market coefficients. For multi-stock Black--Scholes markets without factors, we further devise a baseline algorithm and prove its performance guarantee by deriving a sublinear regret bound in terms of the Sharpe ratio. For performance enhancement and practical implementation, we modify the baseline algorithm and carry out an extensive empirical study to compare its performance, in terms of a host of common metrics, with a large number of widely employed portfolio allocation strategies on S\\&P 500 constituents. The results demonstrate that the proposed continuous-time RL strategy is consistently among the best, especially in a volatile bear market, and decisively outperforms the model-based continuous-time counterparts by significant margins.",
    "source": "arXiv"
  },
  {
    "title": "Spectrum Sharing in Satellite-Terrestrial Integrated Networks: Frameworks, Approaches, and Opportunities",
    "title_es": "Spectrum Sharing in Satellite-Terrestrial Integrated Networks: Frameworks, Approaches, and Opportunities",
    "url": "https://arxiv.org/abs/2501.02750",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.02750v3 Announce Type: replace-cross \nAbstract: With the construction of low-earth orbit (LEO) satellite constellations, ubiquitous connectivity has been achieved. Terrestrial networks (TNs), such as cellular networks, are mainly deployed in specific urban areas and use licensed spectrum. However, in remote areas where terrestrial infrastructure is sparse, licensed spectrum bands are often underutilized. To accommodate the increasing communication needs, non-terrestrial networks (NTNs) can opportunistically access this idle spectrum to improve spectrum efficiency via spectrum sharing (SS). Therefore, bringing NTNs to a shared spectrum with TNs can improve network capacity under reasonable interference management. In satellite-terrestrial integrated networks (STINs), the comprehensive coverage of a satellite and the unbalanced communication resources of STINs make it challenging to manage mutual interference between NTN and TN effectively. This article presents the fundamentals and prospects of SS in STINs by introducing four SS frameworks, their potential application scenarios, and technical challenges. Furthermore, advanced SS approaches related to interference management in STINs and performance metrics of SS in STINs are introduced. Moreover, a preliminary performance evaluation showcases the potential for sharing the spectrum between NTN and TN. Finally, future research opportunities for SS in STINs are discussed.",
    "source": "arXiv"
  },
  {
    "title": "Accurate and thermodynamically consistent hydrogen equation of state for planetary modeling with flow matching",
    "title_es": "Accurate and thermodynamically consistent hydrogen equation of state for planetary modeling with flow matching",
    "url": "https://arxiv.org/abs/2501.10594",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.10594v2 Announce Type: replace-cross \nAbstract: Accurate determination of the equation of state of dense hydrogen is essential for understanding gas giants. Currently, there is still no consensus on methods for calculating its entropy, which play a fundamental role and can result in qualitatively different predictions for Jupiter's interior. Here, we investigate various aspects of entropy calculation for dense hydrogen based on ab initio molecular dynamics simulations. Specifically, we employ the recently developed flow matching method to validate the accuracy of the traditional thermodynamic integration approach. We then clearly identify pitfalls in previous attempts and propose a reliable framework for constructing the hydrogen equation of state, which is accurate and thermodynamically consistent across a wide range of temperature and pressure conditions. This allows us to conclusively address the long-standing discrepancies in Jupiter's adiabat among earlier studies, demonstrating the potential of our approach for providing reliable equations of state of diverse materials.",
    "source": "arXiv"
  },
  {
    "title": "Quantum advantage in decentralized control of POMDPs: A control-theoretic view of the Mermin-Peres square",
    "title_es": "Quantum advantage in decentralized control of POMDPs: A control-theoretic view of the Mermin-Peres square",
    "url": "https://arxiv.org/abs/2501.16690",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2501.16690v2 Announce Type: replace-cross \nAbstract: Consider a decentralized partially-observed Markov decision problem (POMDP) with multiple cooperative agents aiming to maximize a long-term-average reward criterion. We observe that the availability, at a fixed rate, of entangled states of a product quantum system between the agents, where each agent has access to one of the component systems, can result in strictly improved performance even compared to the scenario where common randomness is provided to the agents, i.e. there is a quantum advantage in decentralized control. This observation comes from a simple reinterpretation of the conclusions of the well-known Mermin-Peres square, which underpins the Mermin-Peres game. While quantum advantage has been demonstrated earlier in one-shot team problems of this kind, it is notable that there are examples where there is a quantum advantage for the one-shot criterion but it disappears in the dynamical scenario. The presence of a quantum advantage in dynamical scenarios is thus seen to be a novel finding relative to the current state of knowledge about the achievable performance in decentralized control problems.\n  This paper is dedicated to the memory of Pravin P. Varaiya.",
    "source": "arXiv"
  },
  {
    "title": "Heisenberg-limited calibration of entangling gates with robust phase estimation",
    "title_es": "Heisenberg-limited calibration of entangling gates with robust phase estimation",
    "url": "https://arxiv.org/abs/2502.06698",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.06698v2 Announce Type: replace-cross \nAbstract: The calibration of high-quality two-qubit entangling gates is an essential component in engineering large-scale, fault-tolerant quantum computers. However, many standard calibration techniques are based on randomized circuits that are only quadratically sensitive to calibration errors. As a result, these approaches are inefficient, requiring many experimental shots to achieve acceptable performance. In this work, we demonstrate that robust phase estimation can enable high-precision, Heisenberg-limited estimates of coherent errors in multi-qubit gates. Equipped with an efficient estimator, the calibration problem may be reduced to a simple optimization loop that minimizes the estimated coherent error. We experimentally demonstrate our calibration protocols by improving the operation of a two-qubit controlled-Z gate on a superconducting processor, and we validate the improved performance with gate set tomography. Our methods are applicable to gates in other quantum hardware platforms such as ion traps and neutral atoms, and on other multi-qubit gates, such as CNOT or iSWAP.",
    "source": "arXiv"
  },
  {
    "title": "ScaffoldGPT: A Scaffold-based GPT Model for Drug Optimization",
    "title_es": "ScaffoldGPT: A Scaffold-based GPT Model for Drug Optimization",
    "url": "https://arxiv.org/abs/2502.06891",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.06891v3 Announce Type: replace-cross \nAbstract: Drug optimization has become increasingly crucial in light of fast-mutating virus strains and drug-resistant cancer cells. Nevertheless, it remains challenging as it necessitates retaining the beneficial properties of the original drug while simultaneously enhancing desired attributes beyond its scope. In this work, we aim to tackle this challenge by introducing ScaffoldGPT, a novel Generative Pretrained Transformer (GPT) designed for drug optimization based on molecular scaffolds. Our work comprises three key components: (1) A three-stage drug optimization approach that integrates pretraining, finetuning, and decoding optimization. (2) A novel two-phase incremental pre-training strategy for scaffold-based drug optimization. (3) A token-level decoding optimization strategy, Top-N, that enabling controlled, reward-guided generation using the pretrained or finetuned GPT. We demonstrate via a comprehensive evaluation on COVID and cancer benchmarks that ScaffoldGPT outperforms the competing baselines in drug optimization benchmarks, while excelling in preserving original functional scaffold and enhancing desired properties.",
    "source": "arXiv"
  },
  {
    "title": "Collective Reasoning Among LLMs: A Framework for Answer Validation Without Ground Truth",
    "title_es": "Collective Reasoning Among LLMs: A Framework for Answer Validation Without Ground Truth",
    "url": "https://arxiv.org/abs/2502.20758",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2502.20758v3 Announce Type: replace-cross \nAbstract: We introduce a new approach in which several advanced large language models-specifically GPT-4-0125-preview, Meta-LLAMA-3-70B-Instruct, Claude-3-Opus, and Gemini-1.5-Flash-collaborate to both produce and answer intricate, doctoral-level probability problems without relying on any single \"correct\" reference. Rather than depending on an established ground truth, our investigation focuses on how agreement among diverse models can signal the reliability of their outputs and, by extension, reflect the overall quality of the generated questions. To measure this inter-model alignment, we apply a suite of statistical evaluations, including chi-square tests, Fleiss' Kappa coefficients, and confidence interval calculations, thereby capturing both precision in answers and clarity in question phrasing. Our analysis reveals that Claude and Gemini tend to frame questions more coherently and unambiguously, which is evidenced by their tighter confidence intervals and greater concordance with responding agents. In contrast, LLAMA exhibits wider confidence bands and a lower level of agreement, indicating more variability and reduced consistency in its question formulations. These observations support the notion that a multi-model collaborative strategy not only improves answer dependability but also offers an effective, data-driven mechanism for evaluating and refining question quality when no definitive solution exists. Ultimately, this work delivers actionable insights into enhancing AI-guided reasoning processes through coordinated interactions among heterogeneous language models.",
    "source": "arXiv"
  },
  {
    "title": "A Practical Introduction to Kernel Discrepancies: MMD, HSIC & KSD",
    "title_es": "A Practical Introduction to Kernel Discrepancies: MMD, HSIC & KSD",
    "url": "https://arxiv.org/abs/2503.04820",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.04820v2 Announce Type: replace-cross \nAbstract: This article provides a practical introduction to kernel discrepancies, focusing on the Maximum Mean Discrepancy (MMD), the Hilbert-Schmidt Independence Criterion (HSIC), and the Kernel Stein Discrepancy (KSD). Various estimators for these discrepancies are presented, including the commonly-used V-statistics and U-statistics, as well as several forms of the more computationally-efficient incomplete U-statistics. The importance of the choice of kernel bandwidth is stressed, showing how it affects the behaviour of the discrepancy estimation. Adaptive estimators are introduced, which combine multiple estimators with various kernels, addressing the problem of kernel selection.",
    "source": "arXiv"
  },
  {
    "title": "L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation",
    "title_es": "L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation",
    "url": "https://arxiv.org/abs/2503.05245",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.05245v4 Announce Type: replace-cross \nAbstract: Accurate analysis of prenatal ultrasound (US) is essential for early detection of developmental anomalies. However, operator dependency and technical limitations (e.g. intrinsic artefacts and effects, setting errors) can complicate image interpretation and the assessment of diagnostic uncertainty. We present L-FUSION (Laplacian Fetal US Segmentation with Integrated FoundatiON models), a framework that integrates uncertainty quantification through unsupervised, normative learning and large-scale foundation models for robust segmentation of fetal structures in normal and pathological scans. We propose to utilise the aleatoric logit distributions of Stochastic Segmentation Networks and Laplace approximations with fast Hessian estimations to estimate epistemic uncertainty only from the segmentation head. This enables us to achieve reliable abnormality quantification for instant diagnostic feedback. Combined with an integrated Dropout component, L-FUSION enables reliable differentiation of lesions from normal fetal anatomy with enhanced uncertainty maps and segmentation counterfactuals in US imaging. It improves epistemic and aleatoric uncertainty interpretation and removes the need for manual disease-labelling. Evaluations across multiple datasets show that L-FUSION achieves superior segmentation accuracy and consistent uncertainty quantification, supporting on-site decision-making and offering a scalable solution for advancing fetal ultrasound analysis in clinical settings.",
    "source": "arXiv"
  },
  {
    "title": "A Theory of Learning with Autoregressive Chain of Thought",
    "title_es": "A Theory of Learning with Autoregressive Chain of Thought",
    "url": "https://arxiv.org/abs/2503.07932",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.07932v2 Announce Type: replace-cross \nAbstract: For a given base class of sequence-to-next-token generators, we consider learning prompt-to-answer mappings obtained by iterating a fixed, time-invariant generator for multiple steps, thus generating a chain-of-thought, and then taking the final token as the answer. We formalize the learning problems both when the chain-of-thought is observed and when training only on prompt-answer pairs, with the chain-of-thought latent. We analyze the sample and computational complexity both in terms of general properties of the base class (e.g. its VC dimension) and for specific base classes such as linear thresholds. We present a simple base class that allows for universal representability and computationally tractable chain-of-thought learning. Central to our development is that time invariance allows for sample complexity that is independent of the length of the chain-of-thought. Attention arises naturally in our construction.",
    "source": "arXiv"
  },
  {
    "title": "Dual-domain Modulation Network for Lightweight Image Super-Resolution",
    "title_es": "Dual-domain Modulation Network for Lightweight Image Super-Resolution",
    "url": "https://arxiv.org/abs/2503.10047",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.10047v2 Announce Type: replace-cross \nAbstract: Lightweight image super-resolution (SR) aims to reconstruct high-resolution images from low-resolution images under limited computational costs. We find that existing frequency-based SR methods cannot balance the reconstruction of overall structures and high-frequency parts. Meanwhile, these methods are inefficient for handling frequency features and unsuitable for lightweight SR. In this paper, we show that introducing both wavelet and Fourier information allows our model to consider both high-frequency features and overall SR structure reconstruction while reducing costs. Specifically, we propose a Dual-domain Modulation Network that integrates both wavelet and Fourier information for enhanced frequency modeling. Unlike existing methods that rely on a single frequency representation, our design combines wavelet-domain modulation via a Wavelet-domain Modulation Transformer (WMT) with global Fourier supervision, enabling complementary spectral learning well-suited for lightweight SR. Experimental results show that our method achieves a comparable PSNR to SRFormer and MambaIR while with less than 50\\% and 60\\% of their FLOPs and achieving inference speeds 15.4x and 5.4x faster, respectively, demonstrating the effectiveness of our method on SR quality and lightweight. Code link: https://github.com/24wenjie-li/DMNet",
    "source": "arXiv"
  },
  {
    "title": "Evaluating structural uncertainty in accelerated MRI: are voxelwise measures useful surrogates?",
    "title_es": "Evaluating structural uncertainty in accelerated MRI: are voxelwise measures useful surrogates?",
    "url": "https://arxiv.org/abs/2503.10527",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.10527v2 Announce Type: replace-cross \nAbstract: Introducing accelerated reconstruction algorithms into clinical settings requires measures of uncertainty quantification that accurately assess the relevant uncertainty introduced by the reconstruction algorithm. Many currently deployed approaches quantifying uncertainty by focusing on measuring the variability in voxelwise intensity variation. Although these provide interpretable maps, they lack a structural interpretation and do not show a clear relationship to how the data will be analysed subsequently. In this work we show that voxel level uncertainty does not provide insight into morphological uncertainty. To do so, we use segmentation as a clinically-relevant downstream task and deploy ensembles of reconstruction modes to measure uncertainty in the reconstructions. We show that variability and bias in the morphological structures are present and within-ensemble variability cannot be predicted well with uncertainty measured only by voxel intensity variations.",
    "source": "arXiv"
  },
  {
    "title": "Exploration of Hepatitis B Virus Infection Dynamics through Physics-Informed Deep Learning Approach",
    "title_es": "Exploration of Hepatitis B Virus Infection Dynamics through Physics-Informed Deep Learning Approach",
    "url": "https://arxiv.org/abs/2503.10708",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.10708v2 Announce Type: replace-cross \nAbstract: Accurate forecasting of viral disease outbreaks is crucial for guiding public health responses and preventing widespread loss of life. In recent years, Physics-Informed Neural Networks (PINNs) have emerged as a promising framework that can capture the intricate dynamics of viral infection and reliably predict its future progression. However, despite notable advances, the application of PINNs in disease modeling remains limited. Standard PINNs are effective in simulating disease dynamics through forward modeling but often face challenges in estimating key biological parameters from sparse or noisy experimental data when applied in an inverse framework. To overcome these limitations, a recent extension known as Disease Informed Neural Networks (DINNs) has emerged, offering a more robust approach to parameter estimation tasks. In this work, we apply this DINNs technique on a recently proposed hepatitis B virus (HBV) infection dynamics model to predict infection transmission within the liver. This model consists of four compartments: uninfected and infected hepatocytes, rcDNA-containing capsids, and free viruses. Leveraging the power of DINNs, we study the impacts of (i) variations in parameter range, (ii) experimental noise in data, (iii) sample sizes, (iv) network architecture and (v) learning rate. We employ this methodology in experimental data collected from nine HBV-infected chimpanzees and observe that it reliably estimates the model parameters. DINNs can capture infection dynamics and predict their future progression even when data of some compartments of the system are missing. Additionally, it identifies the influential model parameters that determine whether the HBV infection is cleared or persists within the host.",
    "source": "arXiv"
  },
  {
    "title": "SCReedSolo: A Secure and Robust LSB Image Steganography Framework with Randomized Symmetric Encryption and Reed-Solomon Coding",
    "title_es": "SCReedSolo: A Secure and Robust LSB Image Steganography Framework with Randomized Symmetric Encryption and Reed-Solomon Coding",
    "url": "https://arxiv.org/abs/2503.12368",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.12368v2 Announce Type: replace-cross \nAbstract: Image steganography is an information-hiding technique that involves the surreptitious concealment of covert informational content within digital images. In this paper, we introduce ${\\rm SCR{\\small EED}S{\\small OLO}}$, a novel framework for concealing arbitrary binary data within images. Our approach synergistically leverages Random Shuffling, Fernet Symmetric Encryption, and Reed-Solomon Error Correction Codes to encode the secret payload, which is then discretely embedded into the carrier image using LSB (Least Significant Bit) Steganography. The combination of these methods addresses the vulnerability vectors of both security and resilience against bit-level corruption in the resultant stego-images. We show that our framework achieves a data payload of 3 bits per pixel for an RGB image, and mathematically assess the probability of successful transmission for the amalgamated $n$ message bits and $k$ error correction bits. Additionally, we find that ${\\rm SCR{\\small EED}S{\\small OLO}}$ yields good results upon being evaluated with multiple performance metrics, successfully eludes detection by various passive steganalysis tools, and is immune to simple active steganalysis attacks. Our code and data are available at https://github.com/Starscream-11813/SCReedSolo-Steganography.",
    "source": "arXiv"
  },
  {
    "title": "The Scott space of lattice of closed subsets with supremum operator as a topological semilattice",
    "title_es": "The Scott space of lattice of closed subsets with supremum operator as a topological semilattice",
    "url": "https://arxiv.org/abs/2503.17926",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2503.17926v2 Announce Type: replace-cross \nAbstract: We present several equivalent conditions of the continuity of the supremum function from the square of the Scott space of $C(X)$ to itself under mild assumptions, where $C(X)$ denotes the lattice of closed subsets of a $\\mathbf{T_0}$ topological space.\n  We also show that a $\\mathbf{T_0}$ space is quasicontinuous (quasialgebraic) iff the lattice of its closed subsets is a quasicontinuous (quasialgebraic) domain by using $n$-approximation. Furthermore, we provide a necessary condition for when a topological space possesses a Scott completion. This allows us to give more examples which do not have Scott completions.",
    "source": "arXiv"
  },
  {
    "title": "Improvement of Clamonds solution of the Colebrook-White equation: highest accuracy for engineering purposes with one iteration",
    "title_es": "Improvement of Clamonds solution of the Colebrook-White equation: highest accuracy for engineering purposes with one iteration",
    "url": "https://arxiv.org/abs/2504.03678",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.03678v3 Announce Type: replace-cross \nAbstract: The Colebrook-White equation is the widely used basis for the calculation of the friction factor lambda for flows in pipes and ducts. Because this equation is implicit in lambda, many solutions have been developed to ease the calculation in order to reduce the effort and to reach a sufficient accuracy. Clamond has proposed in 2008 an iterative solution that requires maximally two iterations to obtain the machine double precision. Here an improvement of this solution is presented, that achieves already with one iteration a maximal error of 2.79E-7, what is more than sufficient for most engineering purposes. This solution is compared in a chart of CPU time versus accuracy with 28 solutions from the literature and in the group of the fastest solutions, that require only two calls of the logarithm function, it proved to be by far the most accurate one.",
    "source": "arXiv"
  },
  {
    "title": "Multihead self-attention in cortico-thalamic circuits",
    "title_es": "Multihead self-attention in cortico-thalamic circuits",
    "url": "https://arxiv.org/abs/2504.06354",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.06354v3 Announce Type: replace-cross \nAbstract: Both biological cortico-thalamic networks and artificial transformer networks use canonical computations to perform a wide range of cognitive tasks. In this work, we propose that the structure of cortico-thalamic circuits is well suited to realize a computation analogous to multihead self-attention, the main algorithmic innovation of transformer networks. We assign distinct computational roles to superficial and deep pyramidal cells of the cortex: while superficial pyramidal cells maintain a key-value memory, deep pyramidal cells encode the current query, gain-modulated by the key-value memory in the superficial layer. We show that the structure of this computation matches the fine-grained structure of core and matrix projections from the thalamus to the cortex. We then suggest the parallel between one head of attention and a cortical area, and propose that a thalamo-cortico-thalamic pathway implements a computation akin to a multihead, unnormalized, linear self-attention block. Cross-attention corresponds to the key-value memory of one cortical area being used for retrieval by the query in another cortical area. Finally, as a first step towards a mechanistic theory of synaptic learning of cortical transformers, we derive the formal gradients of a typical loss function with respect to the parameters of such computation.",
    "source": "arXiv"
  },
  {
    "title": "Retuve: Automated Multi-Modality Analysis of Hip Dysplasia with Open Source AI",
    "title_es": "Retuve: Automated Multi-Modality Analysis of Hip Dysplasia with Open Source AI",
    "url": "https://arxiv.org/abs/2504.06422",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.06422v2 Announce Type: replace-cross \nAbstract: Developmental dysplasia of the hip (DDH) poses significant diagnostic challenges, hindering timely intervention. Current screening methodologies lack standardization, and AI-driven studies suffer from reproducibility issues due to limited data and code availability. To address these limitations, we introduce Retuve, an open-source framework for multi-modality DDH analysis, encompassing both ultrasound (US) and X-ray imaging. Retuve provides a complete and reproducible workflow, offering open datasets comprising expert-annotated US and X-ray images, pre-trained models with training code and weights, and a user-friendly Python Application Programming Interface (API). The framework integrates segmentation and landmark detection models, enabling automated measurement of key diagnostic parameters such as the alpha angle and acetabular index. By adhering to open-source principles, Retuve promotes transparency, collaboration, and accessibility in DDH research. This initiative has the potential to democratize DDH screening, facilitate early diagnosis, and ultimately improve patient outcomes by enabling widespread screening and early intervention. The GitHub repository/code can be found here: https://github.com/radoss-org/retuve",
    "source": "arXiv"
  },
  {
    "title": "Further Comments on Yablo's Construction",
    "title_es": "Further Comments on Yablo's Construction",
    "url": "https://arxiv.org/abs/2504.10370",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.10370v4 Announce Type: replace-cross \nAbstract: We continue our analysis of Yablo's coding of the liar paradox by infinite acyclic graphs. The present notes are based on and continue the author's previous results on the problem. In particular, our approach is often more systematic than before.",
    "source": "arXiv"
  },
  {
    "title": "A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography",
    "title_es": "A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography",
    "url": "https://arxiv.org/abs/2504.18400",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2504.18400v2 Announce Type: replace-cross \nAbstract: Shape measures have emerged as promising descriptors of white matter tractography, offering complementary insights into anatomical variability and associations with cognitive and clinical phenotypes. However, conventional methods for computing shape measures are computationally expensive and time-consuming for large-scale datasets due to reliance on voxel-based representations. We propose Tract2Shape, a novel multimodal deep learning framework that leverages geometric (point cloud) and scalar (tabular) features to predict ten white matter tractography shape measures. To enhance model efficiency, we utilize a dimensionality reduction algorithm for the model to predict five primary shape components. The model is trained and evaluated on two independently acquired datasets, the HCP-YA dataset, and the PPMI dataset. We evaluate the performance of Tract2Shape by training and testing it on the HCP-YA dataset and comparing the results with state-of-the-art models. To further assess its robustness and generalization ability, we also test Tract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep learning models across all ten shape measures, achieving the highest average Pearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows that both multimodal input and PCA contribute to performance gains. On the unseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low nMSE, demonstrating strong generalizability in cross-dataset evaluation. Tract2Shape enables fast, accurate, and generalizable prediction of white matter shape measures from tractography data, supporting scalable analysis across datasets. This framework lays a promising foundation for future large-scale white matter shape analysis.",
    "source": "arXiv"
  },
  {
    "title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?",
    "title_es": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?",
    "url": "https://arxiv.org/abs/2505.07078",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.07078v3 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) have recently been leveraged for asset pricing tasks and stock trading applications, enabling AI agents to generate investment decisions from unstructured financial data. However, most evaluations of LLM timing-based investing strategies are conducted on narrow timeframes and limited stock universes, overstating effectiveness due to survivorship and data-snooping biases. We critically assess their generalizability and robustness by proposing FINSABER, a backtesting framework evaluating timing-based strategies across longer periods and a larger universe of symbols. Systematic backtests over two decades and 100+ symbols reveal that previously reported LLM advantages deteriorate significantly under broader cross-section and over a longer-term evaluation. Our market regime analysis further demonstrates that LLM strategies are overly conservative in bull markets, underperforming passive benchmarks, and overly aggressive in bear markets, incurring heavy losses. These findings highlight the need to develop LLM strategies that are able to prioritise trend detection and regime-aware risk controls over mere scaling of framework complexity.",
    "source": "arXiv"
  },
  {
    "title": "RIDGECUT: Learning Graph Partitioning with Rings and Wedges",
    "title_es": "RIDGECUT: Learning Graph Partitioning with Rings and Wedges",
    "url": "https://arxiv.org/abs/2505.13986",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.13986v3 Announce Type: replace-cross \nAbstract: Reinforcement Learning (RL) has proven to be a powerful tool for combinatorial optimization (CO) problems due to its ability to learn heuristics that can generalize across problem instances. However, integrating knowledge that will steer the RL framework for CO solutions towards domain appropriate outcomes remains a challenging task. In this paper, we propose RIDGECUT, the first RL framework that constrains the action space to enforce structure-aware partitioning in the Normalized Cut problem. Using transportation networks as a motivating example, we introduce a novel concept that leverages domain knowledge about urban road topology -- where natural partitions often take the form of concentric rings and radial wedges. Our method reshapes the graph into a linear or circular structure to simplify the partitioning task so that we can apply sequential transformers and enables efficient learning via Proximal Policy Optimization. The resulting partitions are not only aligned with expected spatial layouts but also achieve lower normalized cuts compared to existing methods. While we focus on traffic data, our approach is broadly applicable and offers a mechanism for embedding structural priors into RL for graph partitioning.",
    "source": "arXiv"
  },
  {
    "title": "Efficient RAW Image Deblurring with Adaptive Frequency Modulation",
    "title_es": "Efficient RAW Image Deblurring with Adaptive Frequency Modulation",
    "url": "https://arxiv.org/abs/2505.24407",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2505.24407v3 Announce Type: replace-cross \nAbstract: Image deblurring plays a crucial role in enhancing visual clarity across various applications. Although most deep learning approaches primarily focus on sRGB images, which inherently lose critical information during the image signal processing pipeline, RAW images, being unprocessed and linear, possess superior restoration potential but remain underexplored. Deblurring RAW images presents unique challenges, particularly in handling frequency-dependent blur while maintaining computational efficiency. To address these issues, we propose Frequency Enhanced Network (FrENet), a framework specifically designed for RAW-to-RAW deblurring that operates directly in the frequency domain. We introduce a novel Adaptive Frequency Positional Modulation module, which dynamically adjusts frequency components according to their spectral positions, thereby enabling precise control over the deblurring process. Additionally, frequency domain skip connections are adopted to further preserve high-frequency details. Experimental results demonstrate that FrENet surpasses state-of-the-art deblurring methods in RAW image deblurring, achieving significantly better restoration quality while maintaining high efficiency in terms of reduced MACs. Furthermore, FrENet's adaptability enables it to be extended to sRGB images, where it delivers comparable or superior performance compared to methods specifically designed for sRGB data. The code will be available at https://github.com/WenlongJiao/FrENet .",
    "source": "arXiv"
  },
  {
    "title": "Markov Blanket Density and Free Energy Minimization",
    "title_es": "Markov Blanket Density and Free Energy Minimization",
    "url": "https://arxiv.org/abs/2506.05794",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.05794v5 Announce Type: replace-cross \nAbstract: This paper presents a continuous, information-theoretic extension of the Free Energy Principle through the concept of Markov blanket density, i.e., a scalar field that quantifies the degree of conditional independence between internal and external states at each point in space (ranging from 0 for full coupling to 1 for full separation). It demonstrates that active inference dynamics, including the minimization of variational and expected free energy, naturally emerge from spatial gradients in this density, making Markov blanket density a necessary foundation for the Free Energy Principle. These ideas are developed through a mathematically framework that links density gradients to precise and testable dynamics, offering a foundation for novel predictions and simulation paradigms.",
    "source": "arXiv"
  },
  {
    "title": "Physics-Informed Teleconnection-Aware Transformer for Global Subseasonal-to-Seasonal Forecasting",
    "title_es": "Physics-Informed Teleconnection-Aware Transformer for Global Subseasonal-to-Seasonal Forecasting",
    "url": "https://arxiv.org/abs/2506.08049",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.08049v3 Announce Type: replace-cross \nAbstract: Subseasonal-to-seasonal (S2S) forecasting, which predicts climate conditions from several weeks to months in advance, represents a critical frontier for agricultural planning, energy management, and disaster preparedness. However, it remains one of the most challenging problems in atmospheric science, due to the chaotic dynamics of atmospheric systems and complex interactions across multiple scales. Current approaches often fail to explicitly model underlying physical processes and teleconnections that are crucial at S2S timescales. We introduce \\textbf{TelePiT}, a novel deep learning architecture that enhances global S2S forecasting through integrated multi-scale physics and teleconnection awareness. Our approach consists of three key components: (1) Spherical Harmonic Embedding, which accurately encodes global atmospheric variables onto spherical geometry; (2) Multi-Scale Physics-Informed Neural ODE, which explicitly captures atmospheric physical processes across multiple learnable frequency bands; (3) Teleconnection-Aware Transformer, which models critical global climate interactions through explicitly modeling teleconnection patterns into the self-attention. Extensive experiments demonstrate that \\textbf{TelePiT} significantly outperforms state-of-the-art data-driven baselines and operational numerical weather prediction systems across all forecast horizons, marking a significant advance toward reliable S2S forecasting.",
    "source": "arXiv"
  },
  {
    "title": "OmniFluids: Physics Pre-trained Modeling of Fluid Dynamics",
    "title_es": "OmniFluids: Physics Pre-trained Modeling of Fluid Dynamics",
    "url": "https://arxiv.org/abs/2506.10862",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.10862v2 Announce Type: replace-cross \nAbstract: Computational fluid dynamics (CFD) drives progress in numerous scientific and engineering fields, yet high-fidelity simulations remain computationally prohibitive. While machine learning approaches offer computing acceleration, they typically specialize in single physical systems or require extensive training data, hindering their applicability in highly nonlinear and 3D flow scenarios. To overcome these limitations, we propose OmniFluids, a pure physics pre-trained model that captures fundamental fluid dynamics laws and adapts efficiently to diverse downstream tasks with minimal data. We develop a training framework combining physics-only pre-training, coarse-grid operator distillation, and few-shot fine-tuning. This enables OmniFluids to retain broad physics knowledge while delivering fast and accurate predictions. Architecturally, OmniFluids integrates a mixture of operators, a multi-frame decoder, and factorized Fourier layers, seamlessly incorporating physics-based supervision while allowing efficient and scalable modeling of diverse tasks. Extensive tests on a broad range of 2D and 3D benchmarks show that OmniFluids outperforms state-of-the-art AI-driven methods in terms of flow field prediction and turbulence statistics. It delivers 10--100$\\times$ speedups over traditional solvers while maintaining a comparable accuracy and accurately identifies unknown physical parameters from sparse, noisy data. This work demonstrates the potential of training a unified CFD solver exclusively from physics knowledge, offering a new approach for efficient and generalizable modeling across complex fluid systems.",
    "source": "arXiv"
  },
  {
    "title": "A Two-stage Optimization Method for Wide-range Single-electron Quantum Magnetic Sensing",
    "title_es": "A Two-stage Optimization Method for Wide-range Single-electron Quantum Magnetic Sensing",
    "url": "https://arxiv.org/abs/2506.13469",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.13469v2 Announce Type: replace-cross \nAbstract: Quantum magnetic sensing based on spin systems has emerged as a new paradigm for detecting ultra-weak magnetic fields with unprecedented sensitivity, revitalizing applications in navigation, geo-localization, biology, and beyond. At the heart of quantum magnetic sensing, from the protocol perspective, lies the design of optimal sensing parameters to manifest and then estimate the underlying signals of interest (SoI). Existing studies on this front mainly rely on adaptive algorithms based on black-box AI models or formula-driven principled searches. However, when the SoI spans a wide range and the quantum sensor has physical constraints, these methods may fail to converge efficiently or optimally, resulting in prolonged interrogation times and reduced sensing accuracy. In this work, we report the design of a new protocol using a two-stage optimization method. In the 1st Stage, a Bayesian neural network with a fixed set of sensing parameters is used to narrow the range of SoI. In the 2nd Stage, a federated reinforcement learning agent is designed to fine-tune the sensing parameters within a reduced search space. The proposed protocol is developed and evaluated in a challenging context of single-shot readout of an NV-center electron spin under a constrained total sensing time budget; and yet it achieves significant improvements in both accuracy and resource efficiency for wide-range D.C. magnetic field estimation compared to the state of the art.",
    "source": "arXiv"
  },
  {
    "title": "Coupled Entropy: A Goldilocks Generalization for Complex Systems",
    "title_es": "Coupled Entropy: A Goldilocks Generalization for Complex Systems",
    "url": "https://arxiv.org/abs/2506.17229",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.17229v3 Announce Type: replace-cross \nAbstract: The coupled entropy is proven to correct a flaw in the derivation of the Tsallis entropy and thereby solidify the theoretical foundations for analyzing the uncertainty of complex systems. The Tsallis entropy originated from considering power probabilities $p_i^q$ in which \\textit{q} independent, identically-distributed random variables share the same state. The maximum entropy distribution was derived to be a \\textit{q}-exponential, which is a member of the shape ($\\kappa$), scale ($\\sigma$) distributions. Unfortunately, the $q$-exponential parameters were treated as though valid substitutes for the shape and scale. This flaw causes a misinterpretation of the generalized temperature and an imprecise derivation of the generalized entropy. The coupled entropy is derived from the generalized Pareto distribution (GPD) and the Student's t distribution, whose shape derives from nonlinear sources and scale derives from linear sources of uncertainty. The Tsallis entropy of the GPD converges to one as $\\kappa\\rightarrow\\infty$, which makes it too cold. The normalized Tsallis entropy (NTE) introduces a nonlinear term multiplying the scale and the coupling, making it too hot. The coupled entropy provides perfect balance, ranging from $\\ln \\sigma$ for $\\kappa=0$ to $\\sigma$ as $\\kappa\\rightarrow\\infty$. One could say, the coupled entropy allows scientists, engineers, and analysts to eat their porridge, confident that its measure of uncertainty reflects the mathematical physics of the scale of non-exponential distributions while minimizing the dependence on the shape or nonlinear coupling. Examples of complex systems design including a coupled variation inference algorithm are reviewed.",
    "source": "arXiv"
  },
  {
    "title": "Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions",
    "title_es": "Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions",
    "url": "https://arxiv.org/abs/2506.22568",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.22568v3 Announce Type: replace-cross \nAbstract: Multi-objective optimization problems (MOPs) often require a trade-off between conflicting objectives, maximizing diversity and convergence in the objective space. This study presents an approach to improve the quality of MOP solutions by optimizing the dispersion in the decision space and the convergence in a specific region of the objective space. Our approach defines a Region of Interest (ROI) based on a cone representing the decision maker's preferences in the objective space, while enhancing the dispersion of solutions in the decision space using a uniformity measure. Combining solution concentration in the objective space with dispersion in the decision space intensifies the search for Pareto-optimal solutions while increasing solution diversity. When combined, these characteristics improve the quality of solutions and avoid the bias caused by clustering solutions in a specific region of the decision space. Preliminary experiments suggest that this method enhances multi-objective optimization by generating solutions that effectively balance dispersion and concentration, thereby mitigating bias in the decision space.",
    "source": "arXiv"
  },
  {
    "title": "Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos",
    "title_es": "Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos",
    "url": "https://arxiv.org/abs/2506.23759",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2506.23759v2 Announce Type: replace-cross \nAbstract: Surgical instrument segmentation under Federated Learning (FL) is a promising direction, which enables multiple surgical sites to collaboratively train the model without centralizing datasets. However, there exist very limited FL works in surgical data science, and FL methods for other modalities do not consider inherent characteristics in surgical domain: i) different scenarios show diverse anatomical backgrounds while highly similar instrument representation; ii) there exist surgical simulators which promote large-scale synthetic data generation with minimal efforts. In this paper, we propose a novel Personalized FL scheme, Spatio-Temporal Representation Decoupling and Enhancement (FedST), which wisely leverages surgical domain knowledge during both local-site and global-server training to boost segmentation. Concretely, our model embraces a Representation Separation and Cooperation (RSC) mechanism in local-site training, which decouples the query embedding layer to be trained privately, to encode respective backgrounds. Meanwhile, other parameters are optimized globally to capture the consistent representations of instruments, including the temporal layer to capture similar motion patterns. A textual-guided channel selection is further designed to highlight site-specific features, facilitating model adapta tion to each site. Moreover, in global-server training, we propose Synthesis-based Explicit Representation Quantification (SERQ), which defines an explicit representation target based on synthetic data to synchronize the model convergence during fusion for improving model generalization.",
    "source": "arXiv"
  },
  {
    "title": "Heights of butterfly trees",
    "title_es": "Heights of butterfly trees",
    "url": "https://arxiv.org/abs/2507.04505",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.04505v2 Announce Type: replace-cross \nAbstract: Binary search trees (BSTs) are fundamental data structures whose performance is largely governed by tree height. We introduce a block model for constructing BSTs by embedding internal BSTs into the nodes of an external BST -- a structure motivated by parallel data architectures -- corresponding to composite permutations formed via Kronecker or wreath products. Extending Devroye's result that the height $h_n$ of a random BST satisfies $h_n / \\log n \\to c^* \\approx 4.311$, we show that block BSTs with $nm$ nodes and fixed external size $m$ satisfy $h_{n,m} / \\log n \\to c^* + h_m$ in distribution. We then study butterfly trees: BSTs generated from permutations built using iterated Kronecker or wreath products. For simple butterfly trees (from iterated Kronecker products of $S_2$), we give a full distributional description showing polynomial height growth: $\\mathbb{E} h_n^{\\operatorname{B}} = \\Theta(N^\\alpha)$ with $\\alpha = \\log_2(3/2) \\approx 0.58496$. For nonsimple butterfly trees (from wreath products), we prove power-law bounds: $cN^\\alpha\\cdot (1 + o(1)) \\le \\mathbb{E} h_n^{\\operatorname{B}} \\le dN^\\beta\\cdot (1 + o(1))$, with $\\beta \\approx 0.913189$.",
    "source": "arXiv"
  },
  {
    "title": "Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data",
    "title_es": "Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data",
    "url": "https://arxiv.org/abs/2507.06828",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.06828v2 Announce Type: replace-cross \nAbstract: Image denoising is a fundamental task in computer vision, particularly in medical ultrasound (US) imaging, where speckle noise significantly degrades image quality. Although recent advancements in deep neural networks have led to substantial improvements in denoising for natural images, these methods cannot be directly applied to US speckle noise, as it is not purely random. Instead, US speckle arises from complex wave interference within the body microstructure, making it tissue-dependent. This dependency means that obtaining two independent noisy observations of the same scene, as required by pioneering Noise2Noise, is not feasible. Additionally, blind-spot networks also cannot handle US speckle noise due to its high spatial dependency. To address this challenge, we introduce Speckle2Self, a novel self-supervised algorithm for speckle reduction using only single noisy observations. The key insight is that applying a multi-scale perturbation (MSP) operation introduces tissue-dependent variations in the speckle pattern across different scales, while preserving the shared anatomical structure. This enables effective speckle suppression by modeling the clean image as a low-rank signal and isolating the sparse noise component. To demonstrate its effectiveness, Speckle2Self is comprehensively compared with conventional filter-based denoising algorithms and SOTA learning-based methods, using both realistic simulated US images and human carotid US images. Additionally, data from multiple US machines are employed to evaluate model generalization and adaptability to images from unseen domains. Project page: https://noseefood.github.io/us-speckle2self/",
    "source": "arXiv"
  },
  {
    "title": "Formulation of entropy-conservative discretizations for compressible flows of thermally perfect gases",
    "title_es": "Formulation of entropy-conservative discretizations for compressible flows of thermally perfect gases",
    "url": "https://arxiv.org/abs/2507.08115",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.08115v2 Announce Type: replace-cross \nAbstract: This study proposes a novel spatial discretization procedure for the compressible Euler equations that guarantees entropy conservation at a discrete level for thermally perfect gases. The procedure is based on a locally conservative formulation, and extends the entropy-conserving schemes to the more realistic case of thermally perfect gases, while still guaranteeing preservation of both linear invariants and kinetic energy. The proposed methodology, which can also be extended to multicomponent gases and to an Asymptotically Entropy-Conservative formulation, shows advantages in terms of accuracy and robustness when compared to existing similar approaches.",
    "source": "arXiv"
  },
  {
    "title": "Optimal and Practical Batched Linear Bandit Algorithm",
    "title_es": "Optimal and Practical Batched Linear Bandit Algorithm",
    "url": "https://arxiv.org/abs/2507.08438",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.08438v2 Announce Type: replace-cross \nAbstract: We study the linear bandit problem under limited adaptivity, known as the batched linear bandit. While existing approaches can achieve near-optimal regret in theory, they are often computationally prohibitive or underperform in practice. We propose BLAE, a novel batched algorithm that integrates arm elimination with regularized G-optimal design, achieving the minimax optimal regret (up to logarithmic factors in $T$) in both large-$K$ and small-$K$ regimes for the first time, while using only $O(\\log\\log T)$ batches. Our analysis introduces new techniques for batch-wise optimal design and refined concentration bounds. Crucially, BLAE demonstrates low computational overhead and strong empirical performance, outperforming state-of-the-art methods in extensive numerical evaluations. Thus, BLAE is the first algorithm to combine provable minimax-optimality in all regimes and practical superiority in batched linear bandits.",
    "source": "arXiv"
  },
  {
    "title": "AMix-1: A Pathway to Test-Time Scalable Protein Foundation Model",
    "title_es": "AMix-1: A Pathway to Test-Time Scalable Protein Foundation Model",
    "url": "https://arxiv.org/abs/2507.08920",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.08920v3 Announce Type: replace-cross \nAbstract: We introduce AMix-1, a powerful protein foundation model built on Bayesian Flow Networks and empowered by a systematic training methodology, encompassing pretraining scaling laws, emergent capability analysis, in-context learning mechanism, and test-time scaling algorithm. To guarantee robust scalability, we establish a predictive scaling law and reveal the progressive emergence of structural understanding via loss perspective, culminating in a strong 1.7-billion model. Building on this foundation, we devise a multiple sequence alignment (MSA)-based in-context learning strategy to unify protein design into a general framework, where AMix-1 recognizes deep evolutionary signals among MSAs and consistently generates structurally and functionally coherent proteins. This framework enables the successful design of a dramatically improved AmeR variant with an up to $50\\times$ activity increase over its wild type. Pushing the boundaries of protein engineering, we further empower AMix-1 with an evolutionary test-time scaling algorithm for in silico directed evolution that delivers substantial, scalable performance gains as verification budgets are intensified, laying the groundwork for next-generation lab-in-the-loop protein design.",
    "source": "arXiv"
  },
  {
    "title": "Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?",
    "title_es": "Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?",
    "url": "https://arxiv.org/abs/2507.11569",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.11569v2 Announce Type: replace-cross \nAbstract: Foundation models, pre-trained on large image datasets and capable of capturing rich feature representations, have recently shown potential for zero-shot image registration. However, their performance has mostly been tested in the context of rigid or less complex structures, such as the brain or abdominal organs, and it remains unclear whether these models can handle more challenging, deformable anatomy. Breast MRI registration is particularly difficult due to significant anatomical variation between patients, deformation caused by patient positioning, and the presence of thin and complex internal structure of fibroglandular tissue, where accurate alignment is crucial. Whether foundation model-based registration algorithms can address this level of complexity remains an open question. In this study, we provide a comprehensive evaluation of foundation model-based registration algorithms for breast MRI. We assess five pre-trained encoders, including DINO-v2, SAM, MedSAM, SSLSAM, and MedCLIP, across four key breast registration tasks that capture variations in different years and dates, sequences, modalities, and patient disease status (lesion versus no lesion). Our results show that foundation model-based algorithms such as SAM outperform traditional registration baselines for overall breast alignment, especially under large domain shifts, but struggle with capturing fine details of fibroglandular tissue. Interestingly, additional pre-training or fine-tuning on medical or breast-specific images in MedSAM and SSLSAM, does not improve registration performance and may even decrease it in some cases. Further work is needed to understand how domain-specific training influences registration and to explore targeted strategies that improve both global alignment and fine structure accuracy. We also publicly release our code at \\href{https://github.com/mazurowski-lab/Foundation-based-reg}{Github}.",
    "source": "arXiv"
  },
  {
    "title": "A Steel Surface Defect Detection Method Based on Lightweight Convolution Optimization",
    "title_es": "A Steel Surface Defect Detection Method Based on Lightweight Convolution Optimization",
    "url": "https://arxiv.org/abs/2507.15476",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.15476v2 Announce Type: replace-cross \nAbstract: Surface defect detection of steel, especially the recognition of multi-scale defects, has always been a major challenge in industrial manufacturing. Steel surfaces not only have defects of various sizes and shapes, which limit the accuracy of traditional image processing and detection methods in complex environments. However, traditional defect detection methods face issues of insufficient accuracy and high miss-detection rates when dealing with small target defects. To address this issue, this study proposes a detection framework based on deep learning, specifically YOLOv9s, combined with the C3Ghost module, SCConv module, and CARAFE upsampling operator, to improve detection accuracy and model performance. First, the SCConv module is used to reduce feature redundancy and optimize feature representation by reconstructing the spatial and channel dimensions. Second, the C3Ghost module is introduced to enhance the model's feature extraction ability by reducing redundant computations and parameter volume, thereby improving model efficiency. Finally, the CARAFE upsampling operator, which can more finely reorganize feature maps in a content-aware manner, optimizes the upsampling process and ensures detailed restoration of high-resolution defect regions. Experimental results demonstrate that the proposed model achieves higher accuracy and robustness in steel surface defect detection tasks compared to other methods, effectively addressing defect detection problems.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Lung Disease Diagnosis via Semi-Supervised Machine Learning",
    "title_es": "Enhancing Lung Disease Diagnosis via Semi-Supervised Machine Learning",
    "url": "https://arxiv.org/abs/2507.16845",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.16845v2 Announce Type: replace-cross \nAbstract: Lung diseases, including lung cancer and COPD, are significant health concerns globally. Traditional diagnostic methods can be costly, time-consuming, and invasive. This study investigates the use of semi supervised learning methods for lung sound signal detection using a model combination of MFCC+CNN. By introducing semi supervised learning modules such as Mix Match, Co-Refinement, and Co Refurbishing, we aim to enhance the detection performance while reducing dependence on manual annotations. With the add-on semi-supervised modules, the accuracy rate of the MFCC+CNN model is 92.9%, an increase of 3.8% to the baseline model. The research contributes to the field of lung disease sound detection by addressing challenges such as individual differences, feature insufficient labeled data.",
    "source": "arXiv"
  },
  {
    "title": "Optimal differentially private kernel learning with random projection",
    "title_es": "Optimal differentially private kernel learning with random projection",
    "url": "https://arxiv.org/abs/2507.17544",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.17544v2 Announce Type: replace-cross \nAbstract: Differential privacy has become a cornerstone in the development of privacy-preserving learning algorithms. This work addresses optimizing differentially private kernel learning within the empirical risk minimization (ERM) framework. We propose a novel differentially private kernel ERM algorithm based on random projection in the reproducing kernel Hilbert space using Gaussian processes. Our method achieves minimax-optimal excess risk for both the squared loss and Lipschitz-smooth convex loss functions under a local strong convexity condition. We further show that existing approaches based on alternative dimension reduction techniques, such as random Fourier feature mappings or $\\ell_2$ regularization, yield suboptimal generalization performance. Our key theoretical contribution also includes the derivation of dimension-free generalization bounds for objective perturbation-based private linear ERM -- marking the first such result that does not rely on noisy gradient-based mechanisms. Additionally, we obtain sharper generalization bounds for existing differentially private kernel ERM algorithms. Empirical evaluations support our theoretical claims, demonstrating that random projection enables statistically efficient and optimally private kernel learning. These findings provide new insights into the design of differentially private algorithms and highlight the central role of dimension reduction in balancing privacy and utility.",
    "source": "arXiv"
  },
  {
    "title": "aLLoyM: A large language model for alloy phase diagram prediction",
    "title_es": "aLLoyM: A large language model for alloy phase diagram prediction",
    "url": "https://arxiv.org/abs/2507.22558",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2507.22558v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) are general-purpose tools with wide-ranging applications, including in materials science. In this work, we introduce aLLoyM, a fine-tuned LLM specifically trained on alloy compositions, temperatures, and their corresponding phase information. To develop aLLoyM, we curated question-and-answer (Q&A) pairs for binary and ternary phase diagrams using the open-source Computational Phase Diagram Database (CPDDB) and assessments based on CALPHAD (CALculation of PHAse Diagrams). We fine-tuned Mistral, an open-source pre-trained LLM, for two distinct Q&A formats: multiple-choice and short-answer. Benchmark evaluations demonstrate that fine-tuning substantially enhances performance on multiple-choice phase diagram questions. Moreover, the short-answer model of aLLoyM exhibits the ability to generate novel phase diagrams from its components alone, underscoring its potential to accelerate the discovery of previously unexplored materials systems. To promote further research and adoption, we have publicly released the short-answer fine-tuned version of aLLoyM, along with the complete benchmarking Q&A dataset, on Hugging Face.",
    "source": "arXiv"
  },
  {
    "title": "Poncelet triangles: conic loci of the orthocenter and of the isogonal conjugate of a fixed point",
    "title_es": "Poncelet triangles: conic loci of the orthocenter and of the isogonal conjugate of a fixed point",
    "url": "https://arxiv.org/abs/2508.02368",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02368v2 Announce Type: replace-cross \nAbstract: We prove that over a Poncelet triangle family interscribed between two nested ellipses $\\E,\\E_c$, (i) the locus of the orthocenter is not only a conic, but it is axis-aligned and homothetic to a $90^o$-rotated copy of $\\E$, and (ii) the locus of the isogonal conjugate of a fixed point $P$ is also a conic (the expected degree was four); a parabola (resp. line) if $P$ is on the (degree-four) envelope of the circumcircle (resp. on $\\E$). We also show that the envelope of both the circumcircle and radical axis of incircle and circumcircle contain a conic component if and only if $\\E_c$ is a circle. The former case is the union of two circles!",
    "source": "arXiv"
  },
  {
    "title": "SpectrumFM: Redefining Spectrum Cognition via Foundation Modeling",
    "title_es": "SpectrumFM: Redefining Spectrum Cognition via Foundation Modeling",
    "url": "https://arxiv.org/abs/2508.02742",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.02742v2 Announce Type: replace-cross \nAbstract: The enhancement of spectrum efficiency and the realization of secure spectrum utilization are critically dependent on spectrum cognition. However, existing spectrum cognition methods often exhibit limited generalization and suboptimal accuracy when deployed across diverse spectrum environments and tasks. To overcome these challenges, we propose a spectrum foundation model, termed SpectrumFM, which provides a new paradigm for spectrum cognition. An innovative spectrum encoder that exploits the convolutional neural networks and the multi-head self attention mechanisms is proposed to effectively capture both fine-grained local signal structures and high-level global dependencies in the spectrum data. To enhance its adaptability, two novel self-supervised learning tasks, namely masked reconstruction and next-slot signal prediction, are developed for pre-training SpectrumFM, enabling the model to learn rich and transferable representations. Furthermore, low-rank adaptation (LoRA) parameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly adapt to various downstream spectrum cognition tasks, including spectrum sensing (SS), anomaly detection (AD), and wireless technology classification (WTC). Extensive experiments demonstrate the superiority of SpectrumFM over state-of-the-art methods. Specifically, it improves detection probability in the SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under the curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%.",
    "source": "arXiv"
  },
  {
    "title": "Fairness in Dysarthric Speech Synthesis: Understanding Intrinsic Bias in Dysarthric Speech Cloning using F5-TTS",
    "title_es": "Fairness in Dysarthric Speech Synthesis: Understanding Intrinsic Bias in Dysarthric Speech Cloning using F5-TTS",
    "url": "https://arxiv.org/abs/2508.05102",
    "published": "2025-08-12T04:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "arXiv:2508.05102v2 Announce Type: replace-cross \nAbstract: Dysarthric speech poses significant challenges in developing assistive technologies, primarily due to the limited availability of data. Recent advances in neural speech synthesis, especially zero-shot voice cloning, facilitate synthetic speech generation for data augmentation; however, they may introduce biases towards dysarthric speech. In this paper, we investigate the effectiveness of state-of-the-art F5-TTS in cloning dysarthric speech using TORGO dataset, focusing on intelligibility, speaker similarity, and prosody preservation. We also analyze potential biases using fairness metrics like Disparate Impact and Parity Difference to assess disparities across dysarthric severity levels. Results show that F5-TTS exhibits a strong bias toward speech intelligibility over speaker and prosody preservation in dysarthric speech synthesis. Insights from this study can help integrate fairness-aware dysarthric speech synthesis, fostering the advancement of more inclusive speech technologies.",
    "source": "arXiv"
  },
  {
    "title": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "title_es": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "url": "https://www.nature.com/articles/s41586-025-09407-y",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "source": "Nature"
  },
  {
    "title": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "title_es": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "url": "https://www.nature.com/articles/s41586-025-09485-y",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "source": "Nature"
  },
  {
    "title": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "title_es": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "url": "https://www.nature.com/articles/s41586-025-09464-3",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "source": "Nature"
  },
  {
    "title": "How does a forest return to abandoned land? I travel to find out",
    "title_es": "How does a forest return to abandoned land? I travel to find out",
    "url": "https://www.nature.com/articles/d41586-025-02517-7",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "How does a forest return to abandoned land? I travel to find out",
    "source": "Nature"
  },
  {
    "title": "How Indigenous values permeate my chemistry teaching and research",
    "title_es": "How Indigenous values permeate my chemistry teaching and research",
    "url": "https://www.nature.com/articles/d41586-025-02568-w",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "How Indigenous values permeate my chemistry teaching and research",
    "source": "Nature"
  },
  {
    "title": "Six questions to ask before jumping into a spreadsheet",
    "title_es": "Six questions to ask before jumping into a spreadsheet",
    "url": "https://www.nature.com/articles/d41586-025-02511-z",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Six questions to ask before jumping into a spreadsheet",
    "source": "Nature"
  },
  {
    "title": "Swift bricks, ancient tattoos and more: Books in brief",
    "title_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "url": "https://www.nature.com/articles/d41586-025-02556-0",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "source": "Nature"
  },
  {
    "title": "How animal paw pads got their toughness",
    "title_es": "How animal paw pads got their toughness",
    "url": "https://www.nature.com/articles/d41586-025-02474-1",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "How animal paw pads got their toughness",
    "source": "Nature"
  },
  {
    "title": "Can creativity in science be learnt? These researchers think so",
    "title_es": "Can creativity in science be learnt? These researchers think so",
    "url": "https://www.nature.com/articles/d41586-025-01913-3",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Can creativity in science be learnt? These researchers think so",
    "source": "Nature"
  },
  {
    "title": "Trump order gives political appointees vast powers over research grants",
    "title_es": "Trump order gives political appointees vast powers over research grants",
    "url": "https://www.nature.com/articles/d41586-025-02557-z",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Trump order gives political appointees vast powers over research grants",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: US researchers fight back on key climate report",
    "title_es": "Daily briefing: US researchers fight back on key climate report",
    "url": "https://www.nature.com/articles/d41586-025-02567-x",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Daily briefing: US researchers fight back on key climate report",
    "source": "Nature"
  },
  {
    "title": "Decolonize scientific institutions, don’t just diversify them",
    "title_es": "Decolonize scientific institutions, don’t just diversify them",
    "url": "https://www.nature.com/articles/d41586-025-02516-8",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Decolonize scientific institutions, don’t just diversify them",
    "source": "Nature"
  },
  {
    "title": "A rude awakening",
    "title_es": "A rude awakening",
    "url": "https://www.nature.com/articles/d41586-025-02488-9",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "A rude awakening",
    "source": "Nature"
  },
  {
    "title": "Roxie Laybourne, the first forensic ornithologist",
    "title_es": "Roxie Laybourne, the first forensic ornithologist",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx2662",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 582-582, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Revisiting the human sociobiology debate",
    "title_es": "Revisiting the human sociobiology debate",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady6081",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 580-581, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The membrane skeleton is constitutively remodeled in neurons by calcium signaling",
    "title_es": "The membrane skeleton is constitutively remodeled in neurons by calcium signaling",
    "url": "https://www.science.org/doi/abs/10.1126/science.adn6712",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice",
    "title_es": "Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp0240",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens",
    "title_es": "Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp0246",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli",
    "title_es": "An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp9583",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 618-622, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA",
    "title_es": "Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA",
    "url": "https://www.science.org/doi/abs/10.1126/science.ads3204",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth",
    "title_es": "Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu0043",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 637-643, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Imaging collective quantum fluctuations of the structure of a complex molecule",
    "title_es": "Imaging collective quantum fluctuations of the structure of a complex molecule",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu2637",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 650-654, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Single-photon detection enabled by negative differential conductivity in moiré superlattices",
    "title_es": "Single-photon detection enabled by negative differential conductivity in moiré superlattices",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu5329",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 644-649, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Three-dimensional nucleation and growth of deformation twins in magnesium",
    "title_es": "Three-dimensional nucleation and growth of deformation twins in magnesium",
    "url": "https://www.science.org/doi/abs/10.1126/science.adv3460",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 632-636, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing",
    "title_es": "Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing",
    "url": "https://www.science.org/doi/abs/10.1126/science.adt2741",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 623-631, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Predicting expression-altering promoter mutations with deep learning",
    "title_es": "Predicting expression-altering promoter mutations with deep learning",
    "url": "https://www.science.org/doi/abs/10.1126/science.ads7373",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The multifunctional immune system",
    "title_es": "The multifunctional immune system",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea8294",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 586-587, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Immune system influence on physiology",
    "title_es": "Immune system influence on physiology",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4380",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 594-599, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Sex differences in tissue-specific immunity and immunology",
    "title_es": "Sex differences in tissue-specific immunity and immunology",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4381",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 599-603, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Convergence and divergence of individual immune responses over the life course",
    "title_es": "Convergence and divergence of individual immune responses over the life course",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady9543",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 604-609, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Evolution of antiviral host defenses against a backdrop of endogenous retroelements",
    "title_es": "Evolution of antiviral host defenses against a backdrop of endogenous retroelements",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4379",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 588-593, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "How a diagnosis altered my path",
    "title_es": "How a diagnosis altered my path",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb1444",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 658-658, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "In Other Journals",
    "title_es": "In Other Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2040",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 611-612, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Moiré eyes detect the dim",
    "title_es": "Moiré eyes detect the dim",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea5235",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 570-570, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Opening the gateway to food-induced anaphylaxis",
    "title_es": "Opening the gateway to food-induced anaphylaxis",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz6439",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 573-574, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Hardening nature’s toughest teeth",
    "title_es": "Hardening nature’s toughest teeth",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8241",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 568-569, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Improving Alzheimer’s disease immunotherapy",
    "title_es": "Improving Alzheimer’s disease immunotherapy",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8959",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 571-572, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "NextGen Voices: National Assessments in Verse",
    "title_es": "NextGen Voices: National Assessments in Verse",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2043",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Brazil’s dangerous environmental licensing bill",
    "title_es": "Brazil’s dangerous environmental licensing bill",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea7981",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 583-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Community support for inclusive US education",
    "title_es": "Community support for inclusive US education",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz3963",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Brazil’s “devastation bill” empowers criminals",
    "title_es": "Brazil’s “devastation bill” empowers criminals",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz7734",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 583-583, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Study used DNA from thousands—without consent",
    "title_es": "Study used DNA from thousands—without consent",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2395",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 552-553, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Senate panel rejects Trump’s plan to slash NIH’s budget",
    "title_es": "Senate panel rejects Trump’s plan to slash NIH’s budget",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2396",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 554-555, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Thank ketchup, and interbreeding, for your French fries",
    "title_es": "Thank ketchup, and interbreeding, for your French fries",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2397",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 556-556, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Study reveals industrial-scale publishing fraud",
    "title_es": "Study reveals industrial-scale publishing fraud",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2398",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 557-558, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "AI-generated text surges in research papers",
    "title_es": "AI-generated text surges in research papers",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2399",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 558-559, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Losing protection",
    "title_es": "Losing protection",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2041",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 560-567, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Census in crisis—further erasure of Indigenous Peoples?",
    "title_es": "Census in crisis—further erasure of Indigenous Peoples?",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea0932",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "New Products",
    "title_es": "New Products",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb1446",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 655-655, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Quantum technology governance: A standards-first approach",
    "title_es": "Quantum technology governance: A standards-first approach",
    "url": "https://www.science.org/doi/abs/10.1126/science.adw0018",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 575-578, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "In Science Journals",
    "title_es": "In Science Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2039",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 610-612, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Globally recognized island is losing its trademark glaciers",
    "title_es": "Globally recognized island is losing its trademark glaciers",
    "url": "https://www.nature.com/articles/d41586-025-02473-2",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Globally recognized island is losing its trademark glaciers",
    "source": "Nature"
  },
  {
    "title": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "title_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "url": "https://www.nature.com/articles/d41586-025-02505-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "source": "Nature"
  },
  {
    "title": "How researcher visa curbs threaten science careers",
    "title_es": "How researcher visa curbs threaten science careers",
    "url": "https://www.nature.com/articles/d41586-025-02293-4",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "How researcher visa curbs threaten science careers",
    "source": "Nature"
  },
  {
    "title": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "title_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "url": "https://www.nature.com/articles/d41586-025-02512-y",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "source": "Nature"
  },
  {
    "title": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "title_es": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "url": "https://www.nature.com/articles/d41586-025-02515-9",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "source": "Nature"
  },
  {
    "title": "These genes can have the opposite effects depending on which parent they came from",
    "title_es": "These genes can have the opposite effects depending on which parent they came from",
    "url": "https://www.nature.com/articles/d41586-025-02499-6",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "These genes can have the opposite effects depending on which parent they came from",
    "source": "Nature"
  },
  {
    "title": "Alien planet glimpsed in star's 'habitable zone'",
    "title_es": "Alien planet glimpsed in star's 'habitable zone'",
    "url": "https://www.nature.com/articles/d41586-025-02549-z",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Alien planet glimpsed in star's 'habitable zone'",
    "source": "Nature"
  },
  {
    "title": "Monoclonal antibodies revolutionized biomedical science and health care",
    "title_es": "Monoclonal antibodies revolutionized biomedical science and health care",
    "url": "https://www.nature.com/articles/d41586-025-02452-7",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Monoclonal antibodies revolutionized biomedical science and health care",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "title_es": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "url": "https://www.nature.com/articles/d41586-025-02559-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "source": "Nature"
  },
  {
    "title": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "title_es": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "url": "https://www.nature.com/articles/s41586-025-09463-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "source": "Nature"
  },
  {
    "title": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "title_es": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "url": "https://www.nature.com/articles/s41586-025-09461-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "source": "Nature"
  },
  {
    "title": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "title_es": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "url": "https://www.nature.com/articles/s41586-025-09315-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "source": "Nature"
  },
  {
    "title": "Data anomalies and the economic commitment of climate change",
    "title_es": "Data anomalies and the economic commitment of climate change",
    "url": "https://www.nature.com/articles/s41586-025-09320-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Data anomalies and the economic commitment of climate change",
    "source": "Nature"
  },
  {
    "title": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "title_es": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "url": "https://www.nature.com/articles/s41586-025-09314-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "source": "Nature"
  },
  {
    "title": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "title_es": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "url": "https://www.nature.com/articles/s41586-025-09477-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "source": "Nature"
  },
  {
    "title": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "title_es": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "url": "https://www.nature.com/articles/s41586-025-09444-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "source": "Nature"
  },
  {
    "title": "The real problems with America's health",
    "title_es": "The real problems with America's health",
    "url": "https://www.nature.com/articles/d41586-025-02501-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "The real problems with America's health",
    "source": "Nature"
  },
  {
    "title": "Why did researchers stick a duck to a rock? To show off their super glue",
    "title_es": "Why did researchers stick a duck to a rock? To show off their super glue",
    "url": "https://www.nature.com/articles/d41586-025-02485-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Why did researchers stick a duck to a rock? To show off their super glue",
    "source": "Nature"
  },
  {
    "title": "Underwater glue shows its sticking power in rubber duck test",
    "title_es": "Underwater glue shows its sticking power in rubber duck test",
    "url": "https://www.nature.com/articles/d41586-025-02500-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Underwater glue shows its sticking power in rubber duck test",
    "source": "Nature"
  },
  {
    "title": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "title_es": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "url": "https://www.nature.com/articles/s41586-025-09272-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "source": "Nature"
  },
  {
    "title": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "title_es": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "url": "https://www.nature.com/articles/s41586-025-09329-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "source": "Nature"
  },
  {
    "title": "Hominins on Sulawesi during the Early Pleistocene",
    "title_es": "Hominins on Sulawesi during the Early Pleistocene",
    "url": "https://www.nature.com/articles/s41586-025-09348-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Hominins on Sulawesi during the Early Pleistocene",
    "source": "Nature"
  },
  {
    "title": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "title_es": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "url": "https://www.nature.com/articles/s41586-025-09310-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "source": "Nature"
  },
  {
    "title": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "title_es": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "url": "https://www.nature.com/articles/s41586-025-09379-z",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "source": "Nature"
  },
  {
    "title": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "title_es": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "url": "https://www.nature.com/articles/s41586-025-09362-8",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "source": "Nature"
  },
  {
    "title": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "title_es": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "url": "https://www.nature.com/articles/s41586-025-09299-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "source": "Nature"
  },
  {
    "title": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "title_es": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "url": "https://www.nature.com/articles/s41586-025-09306-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "source": "Nature"
  },
  {
    "title": "Structural basis of fast N-type inactivation in Kv channels",
    "title_es": "Structural basis of fast N-type inactivation in Kv channels",
    "url": "https://www.nature.com/articles/s41586-025-09339-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Structural basis of fast N-type inactivation in Kv channels",
    "source": "Nature"
  },
  {
    "title": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "title_es": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "url": "https://www.nature.com/articles/s41586-025-09372-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "source": "Nature"
  },
  {
    "title": "A diverse and distinct microbiome inside living trees",
    "title_es": "A diverse and distinct microbiome inside living trees",
    "url": "https://www.nature.com/articles/s41586-025-09316-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "A diverse and distinct microbiome inside living trees",
    "source": "Nature"
  },
  {
    "title": "Data-driven de novo design of super-adhesive hydrogels",
    "title_es": "Data-driven de novo design of super-adhesive hydrogels",
    "url": "https://www.nature.com/articles/s41586-025-09269-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Data-driven de novo design of super-adhesive hydrogels",
    "source": "Nature"
  },
  {
    "title": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "title_es": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "url": "https://www.nature.com/articles/s41586-025-09351-x",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "source": "Nature"
  },
  {
    "title": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "title_es": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "url": "https://www.nature.com/articles/s41586-025-09363-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "source": "Nature"
  },
  {
    "title": "Lithium deficiency and the onset of Alzheimer’s disease",
    "title_es": "Lithium deficiency and the onset of Alzheimer’s disease",
    "url": "https://www.nature.com/articles/s41586-025-09335-x",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Lithium deficiency and the onset of Alzheimer’s disease",
    "source": "Nature"
  },
  {
    "title": "A global humidity index with lateral hydrologic flows",
    "title_es": "A global humidity index with lateral hydrologic flows",
    "url": "https://www.nature.com/articles/s41586-025-09359-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "A global humidity index with lateral hydrologic flows",
    "source": "Nature"
  },
  {
    "title": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "title_es": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "url": "https://www.nature.com/articles/s41586-025-09378-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "source": "Nature"
  },
  {
    "title": "The science fiction science method",
    "title_es": "The science fiction science method",
    "url": "https://www.nature.com/articles/s41586-025-09194-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "The science fiction science method",
    "source": "Nature"
  },
  {
    "title": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "title_es": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "url": "https://www.nature.com/articles/s41586-025-09324-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "source": "Nature"
  },
  {
    "title": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "title_es": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "url": "https://www.nature.com/articles/s41586-025-09357-5",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "source": "Nature"
  },
  {
    "title": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "title_es": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "url": "https://www.nature.com/articles/s41586-025-09345-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "source": "Nature"
  },
  {
    "title": "The protein craze: scientists talk supplements — and who should take them",
    "title_es": "The protein craze: scientists talk supplements — and who should take them",
    "url": "https://www.nature.com/articles/d41586-025-02472-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "The protein craze: scientists talk supplements — and who should take them",
    "source": "Nature"
  },
  {
    "title": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "title_es": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "url": "https://www.nature.com/articles/d41586-025-02253-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "source": "Nature"
  },
  {
    "title": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "title_es": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "url": "https://www.nature.com/articles/d41586-025-02484-z",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "source": "Nature"
  },
  {
    "title": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "title_es": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "url": "https://www.nature.com/articles/d41586-025-02386-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "source": "Nature"
  },
  {
    "title": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "title_es": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "url": "https://www.nature.com/articles/d41586-025-02421-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "source": "Nature"
  },
  {
    "title": "Nuclear-weapons risks are back — and we need to act like it",
    "title_es": "Nuclear-weapons risks are back — and we need to act like it",
    "url": "https://www.nature.com/articles/d41586-025-02506-w",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Nuclear-weapons risks are back — and we need to act like it",
    "source": "Nature"
  },
  {
    "title": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "title_es": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "url": "https://www.nature.com/articles/d41586-025-02393-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "source": "Nature"
  },
  {
    "title": "The peer-review crisis: how to fix an overloaded system",
    "title_es": "The peer-review crisis: how to fix an overloaded system",
    "url": "https://www.nature.com/articles/d41586-025-02457-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "The peer-review crisis: how to fix an overloaded system",
    "source": "Nature"
  },
  {
    "title": "Ancient marine reptile was a silent swimmer",
    "title_es": "Ancient marine reptile was a silent swimmer",
    "url": "https://www.nature.com/articles/d41586-025-02464-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Ancient marine reptile was a silent swimmer",
    "source": "Nature"
  },
  {
    "title": "UK Royal Society adopts ‘subscribe to open’ publishing model",
    "title_es": "UK Royal Society adopts ‘subscribe to open’ publishing model",
    "url": "https://www.nature.com/articles/d41586-025-02483-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "UK Royal Society adopts ‘subscribe to open’ publishing model",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Reflections from a survivor of the Hiroshima bombing",
    "title_es": "Daily briefing: Reflections from a survivor of the Hiroshima bombing",
    "url": "https://www.nature.com/articles/d41586-025-02551-5",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Daily briefing: Reflections from a survivor of the Hiroshima bombing",
    "source": "Nature"
  },
  {
    "title": "New hope for Alzheimer’s: lithium supplement reverses memory loss in mice",
    "title_es": "New hope for Alzheimer’s: lithium supplement reverses memory loss in mice",
    "url": "https://www.nature.com/articles/d41586-025-02471-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "New hope for Alzheimer’s: lithium supplement reverses memory loss in mice",
    "source": "Nature"
  },
  {
    "title": "Parent-of-origin effects found for gene variants that affect human growth and metabolism",
    "title_es": "Parent-of-origin effects found for gene variants that affect human growth and metabolism",
    "url": "https://www.nature.com/articles/d41586-025-02391-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Parent-of-origin effects found for gene variants that affect human growth and metabolism",
    "source": "Nature"
  },
  {
    "title": "After you left",
    "title_es": "After you left",
    "url": "https://www.nature.com/articles/d41586-025-02467-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "After you left",
    "source": "Nature"
  },
  {
    "title": "OpenAI launches reasoning LLM that you can download and tweak",
    "title_es": "OpenAI launches reasoning LLM that you can download and tweak",
    "url": "https://www.nature.com/articles/d41586-025-02495-w",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "OpenAI launches reasoning LLM that you can download and tweak",
    "source": "Nature"
  },
  {
    "title": "AI learns from nature to design super-adhesive gels that work underwater",
    "title_es": "AI learns from nature to design super-adhesive gels that work underwater",
    "url": "https://www.nature.com/articles/d41586-025-02252-z",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "AI learns from nature to design super-adhesive gels that work underwater",
    "source": "Nature"
  },
  {
    "title": "Is your AI benchmark lying to you?",
    "title_es": "Is your AI benchmark lying to you?",
    "url": "https://www.nature.com/articles/d41586-025-02462-5",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Is your AI benchmark lying to you?",
    "source": "Nature"
  },
  {
    "title": "Does lithium deficiency contribute to Alzheimer’s disease?",
    "title_es": "Does lithium deficiency contribute to Alzheimer’s disease?",
    "url": "https://www.nature.com/articles/d41586-025-02255-w",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Does lithium deficiency contribute to Alzheimer’s disease?",
    "source": "Nature"
  },
  {
    "title": "Breed giant prawns to withstand disease and climate change",
    "title_es": "Breed giant prawns to withstand disease and climate change",
    "url": "https://www.nature.com/articles/d41586-025-02477-y",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "content_es": "Breed giant prawns to withstand disease and climate change",
    "source": "Nature"
  },
  {
    "title": "Conserve marine migratory species to protect ecological links between land and sea",
    "title_es": "Conserve marine migratory species to protect ecological links between land and sea",
    "url": "https://www.nature.com/articles/d41586-025-02475-0",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "content_es": "Conserve marine migratory species to protect ecological links between land and sea",
    "source": "Nature"
  },
  {
    "title": "Tackle fake citations generated by AI",
    "title_es": "Tackle fake citations generated by AI",
    "url": "https://www.nature.com/articles/d41586-025-02482-1",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "content_es": "Tackle fake citations generated by AI",
    "source": "Nature"
  },
  {
    "title": "Mystery of billions of sea-star deaths solved at last",
    "title_es": "Mystery of billions of sea-star deaths solved at last",
    "url": "https://www.nature.com/articles/d41586-025-02442-9",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "content_es": "Mystery of billions of sea-star deaths solved at last",
    "source": "Nature"
  },
  {
    "title": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "title_es": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "url": "https://www.cnic.es/es/node/235736",
    "published": "2025-08-01T12:08:23.000Z",
    "date": "2025-08-01",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDr. Claudia Monaco, Kennedy Institute of Rheumatology, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, University of Oxford, UK\n\n\n\nClaudia Monacoo trained as a cardiologist and PhD with Professor Attilio Maseri at the Catholic University of Rome, Italy, before moving to the Kennedy Institute of Rheumatology, Imperial College London to work with Professor Marc Feldmann. She moved to the University of Oxford in 2011, where she became Professor of Cardiovascular Inflammation. Her group was the first to establish innovative experimental methodology for the isolation, culture and targeting of live cells from human atheroma lesions. Her work allowed the elegant characterization of the inflammatory and synthetic properties of human atherosclerosis, establishing toll-like receptors as important activators of innate immunity in atherosclerosis. The Cardiovascular Inflammation Team is now focused on interpreting the functional diversity of immune cells in atherosclerosis with single cell biology techniques and devise strategies for their selective targeting.\n\nWhat is the role of macrophages in the development of atherosclerosis, and how has our understanding of their function evolved?\n\nWe are focused, in particular, on macrophages and what their function is in atherosclerosis. I think it’s quite interesting, because different types of macrophages have different functions in the development of atherosclerosis. Before, we thought that all macrophages were bad—that all macrophages and the whole immune system were actually promoting atherosclerosis. But now we know the picture is much more complex than that.\nIt’s very related to what macrophages are, where they’re seeded, and how they establish themselves in specific niches. There are some macrophages, like the lipid-associated macrophages, that definitely promote disease. But there are others—vascular macrophages that are already present within the vessel wall—that actually act like guardians of the artery and are protective.\nI think it’s very important—this direction we’re going in, toward more targeted therapies. The idea is not to block all macrophages, because some are actually your friends. You need to look after them, especially the ones in the artery, while others are really pushing things toward a dangerous, disease-promoting path. This duality is really important, especially from a therapeutic perspective. That’s why we’re so fixated on understanding this better.\n\nAnd how can you tell the difference between the “good” macrophages and the ones you want to block? What kind of techniques do you use?\n\nWe use single-cell biology a lot. We’re not yet in the clinical space, but we’ve identified good markers. If those markers prove reliable, it would be easy to translate this into new tools to look at different macrophages in vivo. There’s also the potential to tailor imaging—not just therapeutics, but also how we visualize these macrophages.\nThe key idea we want to get across is that there isn’t just “one” macrophage type. We always said that macrophages are very pleiotropic—that they can take on different phenotypes—but that didn’t always seem to matter because we thought they all eventually just changed into each other. But actually, that’s not quite true.\nThere is some dynamic flexibility, yes, but it's quite reproducible which path they take. They really adapt specifically to their environment. For example, in the adventitia, they adopt a very specific phenotype, and in the intima, a different one. And these phenotypes remain pretty stable during atherosclerosis, and also in health and disease. They’re not just switching randomly between states, they’re adapting in a niche-specific way, just like cells in any other organ. That’s important because it means we can start visualizing and treating patients differently more precisely.\n\nYou mentioned you're still in the experimental phase and not yet in clinical trials. How far is immunotherapy for cardiovascular disease?\n\nI think there have been some early trials, and there are more and more now that are targeting inflammation in atherosclerosis. It’s really a booming field. We waited a long time to get here. The field was slow to move in this direction because so much focus was on lowering cholesterol, which is of course important—but inflammation wasn’t really explored until recently.\nStudies like the CANTOS trial and others have started targeting cytokines, and I think we are going in the right direction. But progress is still very slow. One big reason is the lack of imaging tools. Imaging is only now reaching the level where we can maybe use it instead of relying on hard cardiovascular outcomes in trials.\nIf you look at cancer, for example, you can track things much faster, look at the size of the tumor, and see how the patient is responding. Same for diseases like rheumatoid arthritis, where you can scan the joints or use PET imaging. Those imaging methods have been around for decades, and they’ve made it possible to run smaller trials that are either based on imaging or give you very clear, early outcomes.\nBut with cardiovascular disease, we still have to look at how patients are doing over 5, 10 years. That’s a big challenge. These trials are very expensive, especially because biologic drugs cost so much. So pharmaceutical companies need to make a huge financial commitment. The more we can improve imaging, the more we’ll be able to run meaningful trials that evaluate new biologics or targeted agents, like nanotechnology-based ones.\nI think evolution isn’t just about immunology, it’s also about how we study this in the real world. Other fields can run smaller trials to understand how things work and then move on to larger outcome trials. But here, with trials like the CANTOS trial—which involved over 10,000 patients and a very expensive biologic—that kind of scale is almost unheard of in other diseases like rheumatoid arthritis.\nSo yes, the challenges are really at the clinical stage—how we bring all this incredible knowledge about the immune system into cardiovascular medicine. The real barrier is economic.\n\nYou’re a cardiologist—you worked in Rome for many years, and then you moved to Oxford. You trained as a cardiologist, and then you also shifted into doing experiments and research. How do you combine these two areas?\n\nWell, combining clinical duties and research is one of the biggest challenges you can attempt to do.  I think if you’re doing clinical research—like outcomes-based research or imaging studies—then it’s easier to combine with clinical work. But if you’re developing science at the molecular level, it’s much harder to do both. At least I couldn’t manage it as well as I would have liked.\nThere’s a big divide between what we think we know and what we actually know. We have this concept of how atherosclerosis develops, how the immune system contributes—but in reality, we don’t really understand the specific mechanisms at play. I felt that, to bridge this gap, I had to go back to the basics. That meant not only using experimental models but also working with human samples. I saw a huge opportunity in single-cell biology has been a big opportunity—for all of us—to understand human immunology at a very detailed level. Because if we only look at mice, then the gap between mouse and human, and then from preclinical to clinical stages, is massive.\nFor example, we really need access to human vascular tissue. But as cardiologists, we’ve moved so much toward percutaneous approaches to the coronary arteries, so we don’t actually remove them anymore. That’s why I work a lot with vascular surgeons. They still operate in a way that allows us to obtain human tissue—but that might not last. Even vascular surgery is moving more and more toward stenting, which means we’ll eventually lose the ability to get that tissue. We have this narrow window of opportunity where we can still work with tissue from patients, and I felt I had to take it. I’m very vocal about this having a short window before vascular surgery becomes entirely percutaneous, \n\nIt seems like improvements in clinical treatment are making things harder for basic science in a way.\n\nExactly. It’s advancing, but at the same time, it means that now we have this critical window. I always say vascular surgeons do research, collect tissue, because we need to analyze what the cells are really doing. Just relying on blood studies, on systemic inflammation, doesn’t tell us much about what’s happening in the atherosclerotic artery. The immune cells inside the artery are very different in their programming compared to circulating cells in the blood.\nMost cells come from the blood—but there are also some embryonic macrophages that form inside the artery and never circulate. And even the ones that come from the blood and stay in the artery for 10 years, they acquire very specialized instructions. You can take monocytes from blood and run as many blood tests as you want—but that doesn’t tell you what’s actually happening inside the artery.\nThey behave differently, they look different, they’ve changed their shape and function completely. This creates a gap in what we can understand—it seems like we’re missing something in these studies . We can’t see all the different effects a drug might have if we only look at peripheral blood. I think the real answers are also in the vascular tissue, in the atherosclerotic plaque itself. We need to go as close to the source as possible—to find real targets, and to see the real effects of drugs on atherosclerotic tissue.\nBecause a lot of clinical trials have targeted systemic inflammation. But that’s not the same as inflammation within the plaque. The drivers of plaque inflammation may be different.\nWe know systemic inflammation is a risk factor, yes, but what you see in the blood isn’t necessarily what’s happening in the plaque. We often assume it is—because it’s convenient. But in cardiovascular disease, especially cardiology, we never actually look at the plaque. We look at the lumen. Intravascular ultrasound (IVUS) is the only way to get a glimpse of the arterial wall. Experimentally, we might look at blood from the heart in very complex ways—but we’re still mainly looking at circulating markers. We’re not really studying the tissue itself.\n\n\nAs a cardiologist with experience of treating patients, do you think your clinical background influences the kinds of research questions you ask?\n\nYes. And there are two things that help me a lot, I think. And that’s why I never stop clinics, even though they told me several times to stop clinics. I think I... I don’t like to stop the clinics because I enjoy that interaction.\nI think, being a scientist, your rewards are very long-term. If you’re a doctor, the rewards are quite immediate, because the patient is happier, yes—you can give the treatment. So, I think it gives me a lot of motivation to serve the patient. But at the same time, I think research is also a good way to serve patients.\nBecause as a clinician I’ve learned a lot from basic scientists. They’re much better at developing techniques at the bench, and so I have great respect for my scientific colleagues. But sometimes, as a clinician, you can see what really matters. And it makes you particularly attached to a specific disease, you know? Basic scientists are sometimes across fields. This study gives me the determination and the drive to really try and solve atherosclerosis.",
    "source": "CNIC"
  },
  {
    "title": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "title_es": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "url": "https://www.cnic.es/es/noticias/dra-claudia-monaco-enfermedades-cardiovasculares-pensamos-que-sabemos-mucho-pero-realidad",
    "published": "2025-08-01T11:49:01.000Z",
    "date": "2025-08-01",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDra. Claudia Monaco:  Instituto Kennedy de Reumatología, Departamento Nuffield de Ortopedia, Reumatología y Ciencias Musculoesqueléticas, Universidad de Oxford, Reino Unido\n\n\n\nClaudia Monaco se formó como cardióloga y doctoró con el profesor Attilio Maseri en la Universidad Católica de Roma, Italia, antes de trasladarse al Instituto Kennedy de Reumatología del Imperial College de Londres para trabajar con el profesor Marc Feldmann. En 2011 se trasladó a la Universidad de Oxford, donde se convirtió en profesora de Inflamación Cardiovascular. Su grupo fue el primero en establecer una metodología experimental innovadora para el aislamiento, cultivo y selección de células vivas de lesiones ateromatosas humanas. Su trabajo permitió caracterizar de forma elegante las propiedades inflamatorias y sintéticas de la aterosclerosis humana, estableciendo los receptores toll-like como activadores importantes de la inmunidad innata en la aterosclerosis. Su grupo de inflamación cardiovascular se centra ahora en interpretar la diversidad funcional de las células inmunitarias en la aterosclerosis con técnicas de biología celular única y en diseñar estrategias para su selección selectiva.\n\n¿Cuál es el papel de los macrófagos en el desarrollo de la aterosclerosis y cómo ha evolucionado nuestra comprensión de su función?\n\nNos centramos, en particular, en los macrófagos y en cuál es su función en la aterosclerosis. Es muy interesante porque los diferentes tipos de macrófagos tienen diferentes funciones en el desarrollo de la aterosclerosis. Antes pensábamos que todos los macrófagos eran malos, que todos los macrófagos y todo el sistema inmunitario favorecían la aterosclerosis. Pero ahora sabemos que el panorama es mucho más complejo.\nEstá muy relacionado con lo que son los macrófagos, dónde se siembran y cómo se establecen en nichos específicos. Hay algunos macrófagos, como los macrófagos asociados a los lípidos, que sin duda favorecen la enfermedad. Pero hay otros, los macrófagos vasculares que ya están presentes en la pared de los vasos, que en realidad actúan como guardianes de la arteria y la protegen.\nCreo que es muy importante la dirección que estamos tomando, hacia terapias más específicas. La idea no es bloquear todos los macrófagos, porque algunos son realmente nuestros aliados. Hay que cuidarlos, especialmente los que se encuentran en las arterias, mientras que otros realmente empujan hacia un camino peligroso que favorece la enfermedad. Esta dualidad es muy importante, especialmente desde el punto de vista terapéutico. Por eso estamos tan obsesionadas con comprenderlo mejor.\n\n¿Cómo se puede distinguir entre los macrófagos «buenos» y los que se quieren bloquear? ¿Qué tipo de técnicas se utilizan?\n\nUtilizamos mucho la biología unicelular. Aún no estamos en el ámbito clínico, pero hemos identificado buenos marcadores. Si esos marcadores resultan fiables, sería fácil traducirlos en nuevas herramientas para observar diferentes macrófagos in vivo. También existe la posibilidad de adaptar las imágenes, no solo las terapéuticas, sino también la forma en que visualizamos estos macrófagos.\nLa idea clave que queremos transmitir es que no existe un único tipo de macrófago. Siempre hemos dicho que los macrófagos son muy pleiotrópicos, es decir, que pueden adoptar diferentes fenotipos, pero eso no siempre parecía importar porque pensábamos que, al final, todos se transformaban unos en otros. Pero, en realidad, eso no es del todo cierto.\nHay cierta flexibilidad dinámica, sí, pero la trayectoria que siguen es bastante reproducible. Se adaptan específicamente a su entorno. Por ejemplo, en la adventicia adoptan un fenotipo muy específico, y en la íntima, otro diferente. Y estos fenotipos se mantienen bastante estables durante la aterosclerosis, así como en la salud y la enfermedad. No cambian aleatoriamente entre estados, sino que se adaptan de forma específica a cada nicho, al igual que las células de cualquier otro órgano. Esto es importante porque significa que podemos empezar a visualizar y tratar a los pacientes de forma diferente y más precisa.\n\nHa mencionado que aún se encuentra en la fase experimental y que aún no se han realizado ensayos clínicos. ¿En qué punto se encuentra la inmunoterapia para las enfermedades cardiovasculares?\n\nCreo que se han realizado algunos ensayos preliminares y ahora hay cada vez más estudios que se centran en la inflamación en la aterosclerosis. Es un campo en auge. Hemos esperado mucho tiempo para llegar hasta aquí. El campo tardó en avanzar en esta dirección porque se prestaba mucha atención a la reducción del colesterol, lo cual es importante, por supuesto, pero la inflamación no se ha explorado realmente hasta hace poco.\nEstudios como el ensayo CANTOS y otros han comenzado a centrarse en las citocinas, y creo que vamos en la dirección correcta. Pero el progreso sigue siendo muy lento. Una de las principales razones es la falta de herramientas de imagen. Las técnicas de imagen están alcanzando ahora un nivel en el que quizá podamos utilizarlas en lugar de basarnos en los resultados cardiovasculares de los ensayos.\nSi nos fijamos en el cáncer, por ejemplo, se puede hacer un seguimiento mucho más rápido, observar el tamaño del tumor y ver cómo responde el paciente. Lo mismo ocurre con enfermedades como la artritis reumatoide, en las que se pueden escanear las articulaciones o utilizar imágenes PET. Estos métodos de imagen llevan décadas utilizándose y han permitido realizar ensayos más pequeños basados en imágenes o que ofrecen resultados muy claros y tempranos.\nSin embargo, en el caso de las enfermedades cardiovasculares, todavía tenemos que observar cómo evolucionan los pacientes a lo largo de 5 o 10 años. Eso supone un gran reto. Estos ensayos son muy caros, sobre todo porque los medicamentos biológicos cuestan mucho. Por lo tanto, las empresas farmacéuticas deben asumir un enorme compromiso financiero. Cuanto más mejoremos las imágenes, más podremos realizar ensayos significativos que evalúen nuevos productos biológicos o agentes dirigidos, como los basados en la nanotecnología.\nCreo que la evolución no se limita a la inmunología, sino que también tiene que ver con cómo estudiamos esto en el mundo real. Otros campos pueden realizar ensayos más pequeños para comprender cómo funcionan las cosas y luego pasar a ensayos de resultados más amplios. Pero aquí, con ensayos como el CANTOS, en el que participaron más de 10.000 pacientes y se utilizó un fármaco biológico muy caro, ese tipo de escala es casi inaudito en otras enfermedades como la artritis reumatoide.\nAsí que sí, los retos se encuentran realmente en la fase clínica: cómo trasladar todos estos increíbles conocimientos sobre el sistema inmunitario a la medicina cardiovascular. La verdadera barrera es económica.\n\nUsted es cardióloga, trabajó en Roma durante muchos años y luego se trasladó a Oxford. Se formó como cardióloga y luego también pasó a dedicarse a la experimentación y la investigación. ¿Cómo combina estas dos áreas?\n\nCombinar las tareas clínicas y la investigación es uno de los mayores retos a los que te puedes enfrentar.  Creo que, si una se dedica a la investigación clínica, como la investigación basada en resultados o los estudios de imagen, es más fácil combinarla con el trabajo clínico. Pero si se trabaja más en el desarrollo científico a nivel molecular, es mucho más difícil compaginar ambas cosas. Al menos yo no pude hacerlo tan bien como me hubiera gustado.\n Existe una gran diferencia entre lo que creemos saber y lo que realmente sabemos. Tenemos una idea de cómo se desarrolla la aterosclerosis, cómo contribuye el sistema inmunitario, pero en realidad no entendemos los mecanismos específicos que intervienen. Sentí que, para salvar esta brecha, tenía que volver a lo básico. Eso significaba no solo utilizar modelos experimentales, sino también trabajar con muestras humanas. Vi una gran oportunidad en la biología de células individuales, que ha sido una gran oportunidad para todos nosotros para comprender la inmunología humana a un nivel muy detallado. Porque si solo nos fijamos en los ratones, la brecha entre estos y los seres humanos, y luego entre las etapas preclínicas y clínicas, es enorme.\nPor ejemplo, realmente necesitamos acceso al tejido vascular humano. Pero como cardiólogos, hemos avanzado tanto hacia los abordajes percutáneos de las arterias coronarias que ya no las extirpamos. Por eso trabajo mucho con cirujanos vasculares. Ellos siguen operando de una manera que nos permite obtener tejido humano, pero eso podría no durar mucho tiempo. Incluso la cirugía vascular se está orientando cada vez más hacia la implantación de stents, lo que significa que, con el tiempo, perderemos la capacidad de obtener ese tejido. Tenemos una ventana de oportunidad muy estrecha en la que todavía podemos trabajar con tejido de pacientes, y sentí que tenía que aprovecharla. Soy muy clara al afirmar que tenemos poco tiempo antes de que la cirugía vascular se vuelva completamente percutánea, lo que, por supuesto, es un avance, pero también nos priva de la oportunidad de estudiar tejidos humanos reales.\n\nParece que las mejoras en el tratamiento clínico están dificultando en cierto modo la ciencia básica.\n\nExactamente. Está avanzando, pero al mismo tiempo significa que ahora tenemos esta ventana crítica. Siempre digo que los cirujanos vasculares investigan y recogen tejido porque necesitamos analizar lo que realmente hacen las células. Basarnos únicamente en los análisis de sangre y en la inflamación sistémica no nos dice mucho sobre lo que está sucediendo en la arteria aterosclerótica. Las células inmunitarias del interior de la arteria son muy diferentes en su programación en comparación con las células circulantes en la sangre.\nLa mayoría de las células provienen de la sangre, pero también hay algunos macrófagos embrionarios que se forman dentro de la arteria y nunca circulan. E incluso los que provienen de la sangre y permanecen en la arteria durante 10 años, adquieren instrucciones muy especializadas. Se pueden extraer monocitos de la sangre y realizar tantos análisis de sangre como se desee, pero eso no revela lo que realmente ocurre dentro de la arteria.\nSe comportan de manera diferente, tienen un aspecto diferente, han cambiado completamente su forma y función. Esto crea una brecha en lo que podemos entender, parece que nos estamos perdiendo algo en estos estudios. No podemos ver todos los diferentes efectos que puede tener un fármaco si solo miramos la sangre periférica. Creo que las respuestas reales también se encuentran en el tejido vascular, en la propia placa aterosclerótica. Tenemos que acercarnos lo más posible a la fuente para encontrar los objetivos reales y ver los efectos reales de los fármacos en el tejido aterosclerótico.\nPorque muchos ensayos clínicos se han centrado en la inflamación sistémica. Pero eso no es lo mismo que la inflamación dentro de la placa. Los factores que provocan la inflamación de la placa pueden ser diferentes.\nSabemos que la inflamación sistémica es un factor de riesgo, sí, pero lo que se ve en la sangre no es necesariamente lo que ocurre en la placa. A menudo asumimos que lo es, porque es conveniente. Pero en las enfermedades cardiovasculares, especialmente en cardiología, nunca miramos realmente la placa. Miramos la luz. La ecografía intravascular (IVUS) es la única forma de echar un vistazo a la pared arterial.\nDesde el punto de vista experimental, podemos analizar la sangre del corazón de formas muy complejas, pero seguimos centrándonos principalmente en los marcadores circulantes. En realidad, no estamos estudiando el tejido en sí.\n\nComo cardióloga con experiencia en el tratamiento de pacientes, ¿cree que su experiencia clínica influye en el tipo de preguntas de investigación que se plantea?\n\nSí. Y hay dos cosas que me ayudan mucho. Por eso nunca dejo de ejercer en la clínica, aunque me han dicho varias veces que lo haga. Creo que... no me gusta dejar la clínica porque disfruto de esa interacción.\nComo científica, las recompensas son a muy largo plazo. Si eres médico, las recompensas son bastante inmediatas, porque el paciente está más contento si puedes darle el tratamiento. Por lo tanto, creo que me motiva mucho atender al paciente. Pero, al mismo tiempo, pienso que la investigación también es una buena forma de atender a los pacientes.\nPorque, como médico, he aprendido mucho de los científicos básicos. Son mucho mejores desarrollando técnicas en el laboratorio, por lo que siento un gran respeto por mis colegas científicos. Pero a veces, como médico clínico, puedes ver lo que realmente importa. Y eso te hace sentir especialmente vinculado a una enfermedad concreta. Los científicos básicos a veces abarcan varios campos. Este estudio me da la determinación y el impulso para intentar resolver realmente la aterosclerosis.\n\n\n¿De niña, se imaginó dedicándose a la ciencia o la medicina y, finalmente, a la investigación?\n\nSiempre quise ser médico. De niña era un poco enfermiza, así que probablemente estuve muy expuesta al entorno médico. Por eso, siempre decía que quería ser médico. Pero luego decepcioné a mi padre a largo plazo, porque él pensaba que me convertiría en médico, no sé, un médico generalista, y así podría tenerme muy cerca de su casa. Pero en cambio, mi carrera me llevó al extranjero. No creo que él estuviera muy contento con mi marcha.\nEn particular, cuando era joven no quería ser científica. Me fascinaban los médicos. Probablemente tenía ese sentido de ayudar a la gente, de servir a la gente. Para mí eso es muy importante. Aprendí todo sobre cardiología en Italia, con el profesor Attilio Maseri, que fue un gran precursor en este campo: la activación de las células inmunitarias, especialmente en el síndrome coronario agudo. Aprendí mucho de él y sigo llevando esa huella en mi trabajo.\nTambién trabajé con otros buenos mentores en el Reino Unido, como el profesor Mark Feldman, y aprendí mucho de él sobre el sistema inmunitario y cómo detener la inflamación. Hago todo lo posible por seguir los pasos de estos dos gigantes para comprender el funcionamiento del sistema inmunitario en las arterias, tanto en la salud como en la enfermedad.\nMe encuentro en un entorno de reumatología e inmunología que también realiza investigaciones cardiovasculares. Puedo permanecer entre ambos campos, lo que me beneficia enormemente, ya que siempre estoy en la interfaz entre los inmunólogos y los especialistas cardiovasculares. Y creo que esto es algo bastante único. Es bastante difícil de replicar en todas partes.\nAhora, la inmunología cardiovascular se está consolidando cada vez más y habrá cada vez más interfaces de este tipo. Como la que hay aquí, en el CNIC, donde hay más interfaces de este tipo. Así que todo esto se está formando. Este es el futuro.\nCuando empecé, no se podía hacer esta combinación en ningún sitio. Por lo tanto, mis opciones estaban bastante limitadas. Ahora, tal vez podría plantearme mudarme a algún lugar de Europa, Estados Unidos, volver a Italia, si hay una estructura de financiación que permita el mismo nivel. Pero, por supuesto, ya sabes, en este momento hay problemas con la financiación en todos los países. Así que es un poco optimista. No iría a Italia solo por ir a Italia. El trabajo es muy importante para mí y necesito tener la combinación adecuada para mudarme a cualquier lugar.\n\nQuizás, primero podría venir aquí para investigar en el CNIC.\n\nSí, exactamente. ¿Por qué no? ¿Por qué no?\n\nHa mencionado que ha tenido muy buenos mentores en su carrera, y supongo que todavía los tiene. Pero ahora también asume esa función de mentoría con los estudiantes en su laboratorio. Entonces, ¿qué diferencias encuentra entre cuando era joven y estos jóvenes estudiantes de hoy?\n\nEsta es una pregunta difícil, porque es una pregunta en la que se pueden tomar dos caminos completamente diferentes. Uno sería: antes trabajábamos mucho más duro, y eso me molesta. No me agradan las personas que siguen ese camino. No me gusta decirlo, pero al final yo también lo sigo: antes nos quedábamos en el laboratorio hasta tarde...\nCreo que los nuevos estudiantes tienen una capacidad mucho mayor. Las nuevas generaciones son más completas en el sentido de que no quieren perderse por completo en el trabajo o la investigación, y creo que esto es algo positivo para sus vidas, sin duda. Considero que ese cambio es muy importante. Quizás porque en Oxford existe la tradición de que hay que tener una vida social en la universidad. Organizan actividades. Intentan crear un entorno en el que los estudiantes, incluso los de posgrado, puedan socializar si lo desean. Me gusta esa cultura. Y esto es típico de Oxford, y me encanta.\nPorque pueden hacer muchas cosas que yo no hice. Ya sabes, en nuestra época, existía la idea de que había que negarse a uno mismo, dedicarse a la disciplina sin límites, y creo que eso no es bueno a largo plazo.\nPero yo diría que las nuevas generaciones suelen conocer muy bien su tema, pero quizá no amplían sus horizontes tanto como deberían, no sienten curiosidad por otras disciplinas. Y yo lucho mucho contra eso. Ya sabes, se meten de lleno en su área, obtienen el doctorado, hacen la defensa de la tesis y solo saben eso. Ahora hay muchas áreas de interés a nuestro alcance. Probablemente, como consecuencia, perdieron muchas cosas. Pero siempre intento decirles que es importante ver cómo evolucionan otros campos. Quizás haya una idea que necesites. Quizás haya un camino que no habías pensado, pero que es importante en el cáncer y quizás también lo sea en las enfermedades cardiovasculares.\nSiempre pienso que, si estás en la interfaz entre dos campos, avanzas más rápido. Porque puedes aprender, otros colegas pueden inspirarte. Así que no te fijes solo en lo tuyo.\nY otra cosa que siempre les digo es que creo que, en las enfermedades cardiovasculares, pensamos que sabemos mucho. Pero en realidad, no es así. Y siempre tenemos que revisar las pruebas.\n\nEs posible que tengan una nueva forma, diferente, de ver sus vidas y sus carreras.\n\nSí, pero también, incluso en el campo del conocimiento de la aterosclerosis, siempre enseñamos a los estudiantes: así es como evoluciona la aterosclerosis. En realidad, las pruebas para nuestro modelo siempre son muy dispersas. Porque pueden estar en ratones o en otro sistema. Pero cómo es en los seres humanos, realmente no lo sabemos. Así que estad siempre preparados para cuestionar vuestras suposiciones. No sigáis siempre lo que os dicen los demás. Debéis tener vuestras propias ideas. Y siempre tenéis que desafiar el paradigma.",
    "source": "CNIC"
  },
  {
    "title": "The Columbia deal is a tragic wake-up call",
    "title_es": "The Columbia deal is a tragic wake-up call",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb0424",
    "published": "2025-07-31T06:00:37.000Z",
    "date": "2025-07-31",
    "content_es": "Science, Volume 389, Issue 6760, Page 551-551, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "title_es": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "url": "https://www.cnio.es/noticias/un-investigador-del-cnio-desarrolla-una-prueba-capaz-de-detectar-tumores-en-estadios-iniciales-con-una-muestra-de-sangre/",
    "published": "2025-07-31T10:48:44.000Z",
    "date": "2025-07-31",
    "content_es": "Los métodos actuales para diagnosticar el cáncer se basan en identificar marcadores –moléculas que indican un estado o proceso determinado del organismo– que provienen del tumor o de proteínas asociadas a él. Como es lógico, esos marcadores son más abundantes cuando el tumor ya se ha desarrollado de forma significativa. Y, cuanto más avanzado el […]\nLa entrada Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "CNIC en la Noche Europea de los Investigadores 2025",
    "title_es": "CNIC en la Noche Europea de los Investigadores 2025",
    "url": "https://www.cnic.es/es/noticias/cnic-noche-europea-investigadores-2025",
    "published": "2025-07-17T22:35:42.000Z",
    "date": "2025-07-17",
    "content_es": "14/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nVen al CNIC el próximo viernes 26 de septiembre con motivo de la XVI Noche Europea de los Investigadores de Madrid. Podrás participar en distintas actividades que te acercarán a la investigación que se realiza en el centro.\nLa Noche Europea de los Investigadores en el CNIC es una oportunidad de sumergirte en el emocionante mundo de la ciencia y la innovación. Desde experimentos asombrosos hasta conferencias inspiradoras, CNIC te brindará una ventana a los descubrimientos más recientes y las maravillas de la tecnología.\nPara asistir es necesario inscribirse en el siguiente link: https://www.cnic.es/es/solicitud-inscripcion-xvi-noche-europea-investigadores \nLa inscripción se abre el lunes 15 de septiembre a partir de las 9:00 hrs.\nTodas las actividades se llevarán a cabo en el Centro Nacional de Investigaciones Cardiovasculares (CNIC): C. de Melchor Fernández Almagro, 3, 28029 Madrid.\nInformación actividades:\n10:30 - 12:30 h. Enfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nPúblico: juvenil (desde 12 años) y adultos.\nEl principal objetivo de esta actividad es sensibilizar sobre los muchos desafíos que enfrentan los pacientes con enfermedades raras, y explicar cómo la investigación básica, utilizando modelos animales adecuados, es esencial para avanzar en la comprensión de estas enfermedades y encontrar terapias potenciales que permitan aliviar o curar a estos pacientes. Con este propósito, se organizan dos actividades: una charla de divulgación en lenguaje accesible; y una demostración en el laboratorio que permitirá a las personas participantes familiarizarse con técnicas utilizadas rutinariamente en la investigación básica para responder preguntas científicas relevantes en el estudio de enfermedades raras.\n10:30 - 13:30 h. ¿Cómo late nuestro corazón? Grupo: Silvia Priori.\nPúblico: juvenil (desde 12 años) y adultos.\nEsta actividad tiene como objetivo explicar cómo late el corazón, desde el nivel subcelular hasta el órgano completo, así como el desarrollo de una arritmia cardíaca dependiente del calcio. Estos temas se explicarán de forma sencilla y amena para que las personas participantes los conozcan de la mano de nuestras investigadoras e investigadores.  \n12:00 - 13:30 h. ¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\nPúblico: juvenil (14-18 años).\nLas personas participantes en esta actividad tendrán la oportunidad de conocer la relación entre el cáncer y el corazón desde el acercamiento al proyecto de investigación RESILIENCE, destinado a mejorar la vida de los pacientes con cáncer. La actividad consistirá en un workshop donde las personas participantes conocerán la aplicación de la tecnología (resonancia magnética cardíaca, ecocardiografía y tomografía cardíaca) y la innovación en este ensayo clínico, así como una mesa redonda donde se compartirán experiencias y se resolverán dudas.\n14:30 - 16:00 h. ¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\nPúblico: infantil (6 – 12 años).\nSe realizará una pequeña presentación sobre las diferencias de flujo sanguíneo laminar y oscilatorio en el contexto de aterosclerosis (con nuestros personajes de dibujos LAMI y OSCI); se hará un juego con preguntas básicas sobre la presentación donde las personas participantes ganarán piezas para montar su propia máquina de flujo laminar y oscilatorio; y habrá una demostración con una adaptación similar de las máquinas que se usan en el laboratorio para estimular las células a los dos tipos de flujo, con el uso de colorante alimentario y purpurina para que se puedan ver los diferentes patrones.\nDos turnos: 11:00-11:45 h (turno 1), 11:45-12.30 h (turno 2).   \n16:00 - 17:30 h. Taller de extracción de ADN. Grupo: Enrique Lara\nPúblico: infantil (8 – 12 años).\n¿Alguna vez te has preguntado qué podéis tener en común los plátanos y tú? ¡Los dos tenéis ADN! Os presentamos una actividad rápida, fácil y divertida, en la que vais a aprender a extraer el ADN de un plátano. Para ello usaremos ingredientes que cualquiera de vosotros tenéis en casa, así podéis sorprender al resto de la familia montando un pequeño laboratorio y ejerciendo de investigadores, ¿estáis dispuestos?\nTres turnos: 16:00 - 16:30 h (Turno 1), 16:30 - 17:00 h (Turno 2), 17:00 - 17:30 h (Turno 3).\n16:00 - 18:00 h. Modelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nPúblico: Infantil (desde 6 años), juvenil y adultos.\nEsta actividad comenzará con una breve charla introductoria para seguir con la preparación de áreas temáticas en el laboratorio especializadas en una cardiopatía congénita concreta, donde se explicarán en detalle sus rasgos morfológicos y cómo afectan a la salud humana. Las personas participantes realizarán una tinción histológica en la que podrán observar corazones de ratón y observarán, de manera práctica, las malformaciones explicadas en la charla de introducción. Con esto esperamos acercar a grandes rasgos lo que se hace en el laboratorio y la relevancia de la investigación básica y traslacional en el contexto de la cardiología.\n16:30 - 18:00 h. Cuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nPúblico: juvenil (desde 15 años) y adultos.\nEsta actividad consta de dos partes. Una primera en la que se les dará a las personas que participan una charla divulgativa adaptada a la edad del público, en la que se expondrá la importancia de los factores de riesgo cardiovasculares en el desarrollo de ciertas patologías relacionadas con el cerebro, así como el ictus o demencias. Posteriormente tendrá lugar una visita guiada en pequeños grupos al laboratorio del grupo donde se mostrarán diferentes técnicas empleadas de rutina en un laboratorio de neurociencia.\n17:00 - 18:00 h. El escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nPúblico: juvenil (desde 12 años) y adultos.\nEn este escape room científico, las personas participantes deberán usar su ingenio para resolver pruebas, enigmas o puzles y abrir un candado. Si lo logran, ¡descubrirán el secreto de la PCR y ganarán una recompensa final! De esta manera, a través de retos colaborativos inspirados en la biología molecular, las personas que jueguen aprenden conceptos clave de genética en un entorno lúdico y educativo.\n17:00 - 19:00 h. Da color a tu plato: convierte a tu corazón en un superhéroe con ritmo: Grupos: José Antonio Enríquez y David Sancho.\nPúblico: infantil (6-12 años).\nEn esta actividad interactiva se construirá un estetoscopio con materiales simples y reciclados (globos, tubos de plástico y botellas usadas), que las personas participantes podrán llevarse a casa. Con él, exploraremos cómo suena nuestro propio corazón, aprendiendo de manera directa y divertida sobre el ritmo cardíaco en condiciones de reposo y después del ejercicio, así como su importancia para la salud. Posteriormente se visualizará en una maqueta humana de poliespán a tamaño real cómo es nuestro sistema circulatorio, cómo la sangre llega a nuestro corazón y cómo alteraciones de la circulación pueden ocasionar ciertas patologías, como es la ateroesclerosis. También tendremos la oportunidad de ver cómo es nuestra sangre cuando tiene un exceso de grasa.  Ambas visualizaciones permitirán comprender por qué es fundamental, evitar el sedentarismo y cuidar nuestros hábitos alimenticios desde una edad temprana para prevenir enfermedades cardiovasculares.\n18:00 - 19:00 h. Diseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nPúblico: adultos (mayores de 18 años).\nEn esta actividad cinco participantes visualizarán con gafas de realidad mixta la estructura dinámica de proteínas y sus ligandos, entendiendo como se produce el efecto de un medicamento. Otros cinco participantes trabajarán en un ordenador cada uno en el proyecto colaborativo https://foldingathome.org. Las personas participantes irán terminando y saliendo, y un nuevo participante entrará para sustituirlos.\nFinanciación y menciones necesarias\n En todas las actividades:\n\nEl CNIC recibe apoyo del Instituto de Salud Carlos III (ISCIII), del Ministerio de Ciencia, Innovación y Universidades (MICIU) y es un Centro de Excelencia Severo Ochoa. Estas actividades han sido posibles gracias a los programas de investigación de CNIC: Programa Nuevos mecanismos de aterosclerosis, Programa Homeostasis miocárdica y daño cardiaco, Programa de Regeneración cardiovascular, Programa Nuevos mecanismos arritmogénicos, Programa Factores de riesgo cardiovascular y salud cerebral, Programa de Promoción de la salud cardiovascular, Programa de Desarrollo tecnológico, financiados por la ayuda CEX2020-001041-S por el MICIU/AEI/10.13039/501100011033.\n\nFinanciado por la Unión Europea. Las opiniones y puntos de vista expresados solo comprometen a su(s) autor(es) y no reflejan necesariamente los de la Unión Europea o los de la European Research Executive Agency (EREA). Ni la Unión Europea ni la EREA pueden ser considerados responsables de ellos.\nNIGHTMADRID es un proyecto de divulgación científica, coordinado por la Fundación madri+d y financiado por la Unión Europea dentro del Programa Horizonte Europa, bajo las acciones Marie Skłodowska-Curie con el acuerdo de subvención nº101.162.110\n\n\nMenciones específicas de cada actividad:\nEnfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nProject PID2022-141211OB-I00, funded by MCIU/AEI/10.13039/501100011033 y por FEDER, UE:\n\nProject “AC22/00020\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union NextGenerationEU:\n\n\nGRUPO CIBERCV CB16/11/00405\n\nProject \"FI23/00229\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union.\n\n\n¿Cómo late nuestro corazón?Grupo: Silvia Priori.\nEl proyecto que ha dado lugar a los resultados mostrados en esta actividad ha recibido el apoyo de la Fundación “la Caixa”, según el acuerdo LCF/PR/HR21-00233.\n\n¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\n\nThis project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No GA-945118\n\nEsta actividad es parte de la ayuda ICT2021-006950, financiada por MICIU y por la Unión Europea NextGenerationEU/PRTR\n\nGRUPO CIBERCV CB16/11/00358\n\n¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\n\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGrant PID2023-146414OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nEsta actividad se (co)financiará con cargo a programa de actividades de I+D entre grupos de Investigación con número de referencia TEC-2024/TEC-158 y acrónimo TecNanoBio-CM, subvencionado por la Comunidad de Madrid en la convocatoria de ayudas destinadas a la realización de programas de actividades de I+D entre grupos de investigación de la Comunidad de Madrid en Tecnologías 2024.\n\nEl proyecto de investigación Caveolin-1-dependent stromal remodeling: a potential novel target for cancer immunotherapy” Modalidad de temática general (Ref. PROYE20089DELP) y el proyecto Immunomechanics: a new paradigm for understanding cancer immune infiltration and improving immunotherapy Modalidad Investigador AECC 2024 (Ref. INVES245874LOLO) financiado por la Asociación Española Contra el Cáncer (AECC).\n\nThe project leading to these results has received funding from “la Caixa” Foundation, under agreement LCF/PR/HR20/52400015\n\nGrant JDC2022-049775-I funded by MICIU/AEI/ 10.13039/501100011033 by the “European Union NextGenerationEU/PRTR”\n\nAyuda FPU21/04003 financiada por:\n\nGrant PRE2021-097318 and PREP2023-001367 funded by MICIU/AEI /10.13039/501100011033 and “ESF+”\n\nFinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2024-TL/SAL-GL-32882 de la convocatoria 2024 de ayudas para la contratación de Ayudantes de Investigación y Técnicos de Laboratorio 2024 y cofinanciadas con el Fondo Social Europeo Plus (FSE+)\n\nco-funded by the European Union’s Horizon Europe research and innovation programme (Cure and Heart Brain project) under the Marie Skłodowska-Curie grant agreement No GA-101126521\n\nTaller de extracción de ADN. Grupo: Enrique Lara\nProyecto TED2021-129774B-C22 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nAyuda PRE2021-100726 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nProyecto PLEC2022-009235 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto PID2021-124629OB-I00 financiado por MICIU/ AEI /10.13039/501100011033/ y por FEDER Una manera de hacer Europa\n\nAyuda PRE2019-087458 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nThis project has received funding from the Horizon Europe Framework Programme (HORIZON) under the call EIC Pathfinder Challenges 2022 and with Project 101115416 — DCM-NEXT\nEl contrato del técnico está cofinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2023-TL/SAL-GL-28706 de la convocatoria 2023 de ayudas para la contratación de ayudantes de investigación y técnicos de laboratorio y cofinanciado en un 40% por el Fondo Social Europeo Plus (FSE+), 2021-2027.\n\n \nGRUPO CIBERCV CB16/11/00432\n\nModelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nLa Caixa “Cardiogenomics”, Plan Nacional, CIBERCV, Leducq foundation\nGrant PID2022-136942OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nFunding from ”la Caixa” Foundation under the project code LCF/PR/HR23/52430011\n\nGrant from the Leducq Foundation for Cardiovascular Research- TNE-24VD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGRUPO CIBERCV CB16/11/00399\n\nAyuda PRE2020-092102 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nAyudas PRE2022-102314 y PREP2022-000716 financiadas por MICIU/AEI /10.13039/501100011033 y por FSE+\nAyuda JDC2023-051982-I financiada por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda FPU18/01054 financiada por el Ministerio de Ciencia, Innovación y Universidades\n\nFinanciado a través de la Ayuda a la contratación de personal investigador predoctoral del año 2023 de la CAM con Expediente PIPF-2023/SAL-GL-29818\n\nCuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nGrant PID2022-140616OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nGrants from the Leducq Foundation for Cardiovascular Research-TNE-19CVD01 and TNE-21CVD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nAyudas PRE2021-099443, PREP2022-000650 y PRE2022-104379 financiadas por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda a la contratación de personal investigador predoctoral del año 2022 de la CAM con Expediente PIPF-2022/SAL-GL-26119\n\nSupport of a fellowship from the ”la Caixa” Foundation (ID 100010434). The fellowship code is LCF/BQ/DI22/11940002”.\n\nEl escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nAssociated funded projects that require dissemination (if applies). Logos and mentions:\n\nUE0EIC2201-HORIZON-EIC-2022_DCM-NEXT\n\nERN-Guard-Heart\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\n \nGRUPO CIBERCV CB16/11/00432\n\nDa color a tu plato: convierte a tu corazón en un superhéroe con ritmo. Grupos: José Antonio Enríquez y David Sancho\n\nJosé Antonio Enríquez:\n\nCentro de Investigación Biomédica en Red de Fragilidad y Envejecimiento Saludable (CIBERFES), Instituto de Salud Carlos III.\nGRUPO CIBERFES CB16/10/00289\n\nProyecto TED2021-131611B-I00 financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under the proposal n° 101198761 MINTRAF\n \n \nProyecto PID2021-127988OB-I00 financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430010\n\n\nDavid Sancho:\n\nProyecto CPP2021-008310 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009762 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\n \nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under grant agreement No 101158245.\n\nThis work was supported by the grant PRYGN246642SANC from the Scientific Foundation of the Spanish Association Against Cancer.\n\nThis work was supported by WORLWIDE CANCER RESEARCH 25-0080.\n\nProyecto PID2022-137712OB-I00 financiado por MICIU/AEI/10.13039/501100011033 y por FEDER, UE\n\nPROGRAMAS DE ACTIVIDADES DE I+D ENTRE GRUPOS DE INVESTIGACIÓN de la Comunidad de Madrid - BIOMEDICINA 2022 coordinado por la Dra. Almudena R Ramiro”-EXPEDIENTE: S2022/BMD-7333. Proyecto titulado “Estrategias inmunomoduladoras en el remodelado vascular: nuevas perspectivas diagnósticas y terapéuticas, acrónimo: INMUNOVAR”. IP del Grupo INMUNOBIOL.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR22/52420019.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430012\n\nProject “UNderstanding Lipid ImmunoMetabolIsm To trEat Disease, acronym: UNLIMITED” (MSCA-Doctoral Network) has received funding from the European Union’s Horizon 2024 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 101227259 \n\nDiseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nAyudas TED2021-132296B-C54 y TED2021-131611B-I00, financiadas por MICIU/ AEI/10.13039/501100011033/ y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009668, financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/PRTR (Plan de Recuperación, Transformación y Resiliencia)\n\nAyuda BIOMARCADORES DE PRECISION PARA LA MEJORA DEL DIAGNOSTICO Y TRATAMIENTO DE LA ENFERMEDAD INFLAMATORIA DEL MIOCARDIO (PreMyo) con expediente PMP22/00105, financiado con fondos públicos por el Instituto de Salud Carlos III y cofinanciado por Unión Europea – NextGenerationEU\n\nAyuda Plan de Formación en Inteligencia Artificial y Big Data para la salud Cardiovascular (CardiotrAIning) con Ref. SOLI/2024/0524/00240212 financiado por los fondos europeos NextGenerationEU en el marco del Plan de Recuperación, Transformación y Resiliencia a través de la iniciativa de los programas de atracción y retención de talento \n\nGRUPO CIBERCV CB22/11/00021\n\nProyecto PID2022-141527OB-I00 financiado por MCIN/AEI/10.13039/501100011033 y por FEDER, UE;\n\nAyuda EQC2024-008195-P financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe EU4Health Programme 2021-2027 under Grant Agreement 101126953. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or European Health and Digital Executive Agency (HADEA). Neither the European Union nor the granting authority can be held responsible for them.\n\nProyecto ALGORITMOS DE INTELIGENCIA ARTIFICIAL PARA PREDECIR EL RIESGO CARDIOVASCULAR, EN-PESA financiado por el Mecanismo de Recuperación y Resiliencia de la Unión Europea-Next Generation, en el marco de la convocatoria “Solicitud de Proyectos de I+D de Excelencia en Inteligencia Artificial de la Secretaría de Estado de Digitalización e Inteligencia Artificial”",
    "source": "CNIC"
  },
  {
    "title": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "title_es": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "url": "https://www.cnio.es/noticias/nuevo-ensayo-clinico-contra-el-cancer-de-piel-mas-frecuente-con-un-compuesto-derivado-de-descubrimientos-del-cnio/",
    "published": "2025-07-15T09:39:59.000Z",
    "date": "2025-07-15",
    "content_es": "Hace unos 15 años, en 2009, el equipo de la investigadora del Centro Nacional de Investigaciones Oncológicas (CNIO) Marisol Soengas descubrió una nueva forma de matar células tumorales: hacerles creer que han sido infectadas por un virus. Desarrollaron un compuesto, denominado BO-110, con una forma de actuación muy novedosa porque inducía la autodigestión de las […]\nLa entrada Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "title_es": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "url": "https://www.cnic.es/es/node/235399",
    "published": "2025-07-14T11:31:24.000Z",
    "date": "2025-07-14",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nA new study led by the CNIC has identified imidazole propionate (ImP), a metabolite produced by gut bacteria, as a driver of atherosclerosis— as a driver of atherosclerosis, the disease behind most heart attacks and strokes\n\n\n\nCardiovascular disease remains the world’s leading cause of death, and often originates in atherosclerosis, a chronic condition in which inflammation and fat deposits cause arteries to harden and narrow. Although clinical practice already targets causal factors like high cholesterol, hypertension, and smoking, detecting atherosclerosis in its early stages continues to be a significant challenge.\nNow, researchers at the Spanish National Center for Cardiovascular Research (CNIC) have identified a gut microbiota–derived metabolite, imidazole propionate (ImP), that appears in the blood during the early stages of active atherosclerosis.\n‘This metabolite is uniquely produced by intestinal bacteria,’ explains CNIC researcher Annalaura Mastrangelo, one of the study’s two first authors. ‘Our study shows that its presence in the bloodstream is associated with the development of active atherosclerosis in people who otherwise appear healthy.’\nThe discovery offers a promising alternative to current diagnostic tools, which typically involve costly and complex imaging techniques. ‘Detecting this blood marker offers a major advantage because current diagnostic tools rely on advanced imaging techniques that are complex, expensive, and not covered by public health systems. Blood levels of ImP provide a diagnostic marker that could help identify apparently healthy individuals with active atherosclerosis, and thus enable earlier treatment.’ says Mastrangelo.\nBut the discovery goes even further. Co–first author Iñaki Robles-Vera explains: ‘We not only observed elevated ImP levels in people with atherosclerosis, but also showed that ImP itself is a causal agent of the disease. In animal models of atherosclerosis, ImP administration led to the formation of arterial plaques. It does this by activating the imidazoline receptor type 1 (I1R), which increases systemic inflammation and promotes atherosclerosis development.’\nDavid Sancho, head of the CNIC Immunobiology Laboratory, lead author on the study and ERC grantee notes that ‘this discovery is important because it opens the way to a completely new line of treatment.’\nThe study shows that blocking the I1R receptor in animal models prevented plaque formation and slowed disease progression, even when the animals were fed a high-cholesterol diet. ‘This suggests that future treatment could combine I1R blockade with cholesterol-lowering drugs to produce a synergistic effect that prevents atherosclerosis development,’ explains Sancho.\n‘These findings open new possibilities for the early detection and personalised treatment of atherosclerosis,’ he continues. ‘Instead of focusing solely on cholesterol and other classic risk factors, we may soon be able to analyse blood for ImP as an early warning signal. At the CNIC, we are also working to develop drugs that block the detrimental effects of ImP.’\n\nThe CNIC-led study was conducted through extensive collaboration with researchers at multiple national and international centres: Mount Sinai Fuster Heart Hospital and the Icahn School of Medicine at Mount Sinai (New York, USA); the Fundación Jiménez Díaz Health Research Institute; the Universidad Autónoma de Madrid; the Spanish cardiovascular research network (CIBER-CV); the University of Gothenburg (Sweden); the University of Athens (Greece); Inmunotek S.L.; the University of Michigan (USA); Hospital de La Princesa; the Center for Metabolomics and Bioanalysis (CEMBIO) from Universidad CEU San Pablo; the University of Heidelberg (Germany); and the Sols-Morreale Biomedical Research Institute (IIBM-CSIC). \nThe study was supported by funding from the European Research Council (Consolidator and Proof of concept grants), Spanish Ministry of Science, Innovation, and Universities; the Spanish State Research Agency; the European Union’s NextGeneration funding mechanism; and the “la Caixa” Foundation.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D., Sancho, D., et al. (2025). Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature. https://doi.org/10.1038/s41586-025-09263-w",
    "source": "CNIC"
  },
  {
    "title": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "title_es": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "url": "https://www.cnic.es/es/noticias/nature-descubren-un-metabolito-microbiota-intestinal-que-favorece-aterosclerosis-podria",
    "published": "2025-07-14T11:08:07.000Z",
    "date": "2025-07-14",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nUn estudio liderado por el CNIC desvela que el propionato de imidazol, un metabolito producido por la microbiota intestinal, induce aterosclerosis, una enfermedad que puede desencadenar la obstrucción de las arterias que causa los infartos o accidentes cerebrovasculares\n\n\n\nLas enfermedades cardiovasculares son la principal causa de muerte global y suelen originarse en la aterosclerosis, un endurecimiento y estrechamiento de las arterias por inflamación y acumulación de grasa en la pared arterial. Aunque se controlan factores causales como colesterol, hipertensión o tabaquismo, la detección temprana de la enfermedad es necesaria. Los nuevos resultados liderados por el Centro Nacional de Investigaciones Cardiovasculares (CNIC) y publicados en la revista Nature han identificado que un metabolito generado por bacterias intestinales, el propionato de imidazol (ImP), se detecta en sangre de modo temprano en la aterosclerosis activa. El estudio ha contado con el apoyo de la Fundación “la Caixa” en su Convocatoria CaixaResearch de Investigación en Salud con 967.620,20 €.\nEste metabolito, “está producido exclusivamente por bacterias del intestino”, explica Annalaura Mastrangelo, investigadora del CNIC y primera autora del estudio. “En este trabajo hemos visto que su presencia en sangre se relaciona con el desarrollo de aterosclerosis activa en personas aparentemente sanas”.\nLo relevante de este hallazgo, destaca Mastrangelo, es que “detectar este marcador en sangre representa una gran ventaja dado que las pruebas actuales requieren técnicas de imagen avanzada complejas y costosas que no están cubiertas por la seguridad social. Los niveles de ImP en sangre ofrecen un marcador con valor diagnóstico para facilitar la identificación de personas sanas que tienen aterosclerosis activa y posibilitar su tratamiento temprano”.\n\nPero el hallazgo va más allá. Iñaki Robles-Vera, también primer autor del estudio, añade: “No solo observamos que el ImP está elevado en personas con aterosclerosis, sino que es un agente causal de la enfermedad. El consumo de ImP provocó la aparición de placas en las arterias en modelos animales de aterosclerosis. El ImP activa el receptor imidazolínico de tipo 1 (I1R) generando un aumento de la inflamación sistémica que contribuye al desarrollo de la aterosclerosis”.\nPara David Sancho, jefe del laboratorio de Inmunobiología y líder del estudio, “este descubrimiento es importante porque abre una nueva vía de tratamiento”.\nEn la investigación que se publica en ‘Nature’, añade, se ha visto que, el uso de bloqueantes del receptor I1R previene la inducción de aterosclerosis por ImP y reduce la progresión de aterosclerosis en modelos de ratón donde se induce la enfermedad con dieta alta en colesterol. “Esto abre la posibilidad futura de un tratamiento combinado del bloqueo de I1R junto al bloqueo de la producción de colesterol para lograr un efecto que esperamos que sea sinérgico y que prevenga el desarrollo de aterosclerosis”, asegura David Sancho.\nEstos hallazgos, agrega, “abren nuevas posibilidades para el diagnóstico precoz y el tratamiento personalizado y temprano de la aterosclerosis. Así, en lugar de centrarse únicamente en el colesterol y otros factores clásicos, se podría en el futuro analizar la presencia de ImP en sangre como señal de riesgo. En el CNIC estamos trabajando para desarrollar fármacos que bloqueen los efectos perjudiciales de ImP”.\n\nEste trabajo ha sido liderado por el CNIC pero representa una colaboración global a nivel nacional e internacional, con la participación de instituciones como Mount Sinai Fuster Heart Hospital, Icahn School of Medicine at Mount Sinai en Nueva York (EEUU); Instituto de investigación Sanitaria Fundación Jiménez Díaz; Universidad Autónoma de Madrid; Centro de Investigación biomédica en red de enfermedades cardiovasculares (CIBER-CV); Universidad de Gotemburgo (Suecia); Universidad de Atenas (Grecia);  Inmunotek S.L; Universidad de  Michigan (EEUU);  Hospital de La Princesa; Centro de Metabolómica y Bioanálisis (CEMBIO), de la Universidad CEU San Pablo; Universidad de Heidelberg (Alemania), y el  Instituto de Investigaciones Biomédicas Sols-Morreale IIBM-CSIC.\nEste proyecto ha recibido financiación del European Research Council (ayudas Consolidator y Proof of Concept: 2016-Consolidator Grant 725091; ERC-2023-PoC); Ministerio de Ciencia, Innovación y Universidades; Agencia Estatal de Investigación; Unión Europea a través de NextGeneration, y la Fundación “la Caixa”.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D. Sancho, D., et al. Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature (2025). https://doi.org/10.1038/s41586-025-09263-w",
    "source": "CNIC"
  },
  {
    "title": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "title_es": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "url": "https://www.cnic.es/es/noticias/ocho-mejores-estudiantes-bachillerato-espana-participan-programa-acercate",
    "published": "2025-07-11T12:07:09.000Z",
    "date": "2025-07-11",
    "content_es": "11/07/2025\n\n\nSobre el CNIC\nFormación\n\n\n\n\n\n\n\n\nEl objetivo del Programa Acércate es atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular\n\n\n\nUn año más, ocho de los mejores estudiantes de bachillerato de España han participado el programa ACÉRCATE, que organiza el Centro Nacional de Investigaciones Cardiovasculares (CNIC) dentro de su Plan de Formación CNIC-Joven. El objetivo de este plan, una apuesta personal del director general del centro, el Dr. Valentín Fuster, es “atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular”.\nLa convocatoria, abierta a bachilleres de todo el territorio nacional, se ha resuelto este año a favor de 6 alumnas y 2 alumnos de los más de 50 que reunían los requisitos y solicitaron participar en el programa. Este año las personas que participan en el programa proceden de Asturias, Extremadura, Galicia, Comunidad de Madrid, Castilla y León, Comunidad Valenciana y Andalucía.\nIncluyendo a los de esta convocatoria, en total ya han participado en el programa 136 estudiantes. Los jóvenes estudiantes, además de participar en el día a día de un centro de excelencia en investigación como el CNIC, han compartido sus experiencias y sus dudas con los investigadores del centro, pero también con el Dr. Fuster, director del CNIC. El Dr. Fuster considera que empezar el programa de formación en etapas educativas tan tempranas es clave para atraer a los investigadores del futuro porque los jóvenes son el “futuro de la investigación en nuestro país”.\nLas personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024\nEn esta ocasión, las personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024 (Concurso de la Unión Europea para Jóvenes Científicos), un certamen internacional que reconoce los mejores proyectos científicos de jóvenes de entre 14 y 20 años. Kvasnovska, fue seleccionada por su proyecto individual de biomedicina titulado «Biomarcadores potenciales de la inflamación crónica relacionada con la edad».\nLos participantes del programa Acércate al CNIC comparten una gran ilusión por vivir una experiencia enriquecedora que les permita acercarse al mundo real de la investigación biomédica. Así, Alba García Peña quiere profundizar en biomedicina para orientar su futuro profesional. María García Manchado, apasionada por la cardiología, desea conocer de cerca el trabajo investigador, mientras que Lucas Gómez Sánchez espera familiarizarse con el laboratorio y la tecnología aplicada a la medicina.\nLuka Pesich, por su parte, busca reforzar sus conocimientos y habilidades prácticas en biomedicina y Sofía Requena Skalska está interesada en el funcionamiento interno de los grupos de investigación y la conexión entre ciencia y práctica clínica.\nDescubrir el día a día en un laboratorio y confirmar su vocación científica es lo que espera Laura Sánchez Rodríguez, mientras que Carmen Vico Guerra valora la oportunidad de crecer personal y académicamente en un entorno de excelencia.\nPor último, Sara Baldo Muñiz espera comprender de forma directa la labor investigadora y aprender tanto de profesionales como de otros estudiantes con intereses afines.\nTecnología más puntera\nEste programa es el que se dirige a la captación de talento más joven de todos los de formación que hay en el CNIC. El apoyo sostenido de la Fundación Pro CNIC es indispensable para que, año tras año, pueda seguir celebrándose y captando el talento desde la etapa más precoz. “Estamos muy satisfechos de este concepto que comenzamos hace ya más de 20 años”, añade el Dr. Fuster. Y, concluye, “así, si tienen ese ‘gusanillo’ de la investigación, los animamos a seguir adelante”.\nAccede aquí al álbum de fotos de esta convocatoria\nSara Baldó Muñiz \n\nSara cursó sus estudios en el IES Velázquez de Madrid y ha decidido estudiar Bioquímica en la Universidad Autónoma de Madrid. Desde pequeña, ha sentido una fuerte atracción por la investigación científica, impulsada por su curiosidad innata y su deseo de comprender cómo funciona el mundo. \nAlba García Peña \n\nAlba cursó Bachillerato en el IES Álvaro Cunqueiro de Vigo y comenzará el próximo curso la carrera de Biotecnología en la Universidad de Santiago de Compostela. Eligió esta opción porque integra varias disciplinas científicas —Matemáticas, Física, Química y Biología— y le permitirá especializarse más adelante en áreas vinculadas a la investigación biosanitaria. \nMaría García Manchado \n\nMaría estudió en el IES San José de Villanueva de la Serena, Badajoz. Ha optado por estudiar Medicina en la Universidad de Extremadura. Desde niña ha sentido una gran pasión por el conocimiento, que la llevó a interesarse especialmente por Biología y Matemáticas.\nLucas Gómez Sánchez \n\nLucas estudió en el IES Ramiro de Maeztu de Madrid y ahora estudiará Ingeniería Biomédica en la Universidad Carlos III de Madrid. Su curiosidad científica comenzó a los 8 años, participando en actividades como la Noche de los Investigadores y la Semana de la Ciencia. \nLuka Pesich \n\nLuka curso Bachillerato en el Colegio Patrocinio San José de Estepona, Málaga. Ahora iniciará sus estudios en Ciencias Biológicas y Químicas en la Universidad de Limerick (Irlanda), con la intención de especializarse en genética. Su interés por la ciencia fue creciendo de forma natural, motivado por su amor por la naturaleza. \nSofía Requena Skalska \n\nSofía estudió en el CEU San Pablo Valencia de Puerto de Sagunto, Valencia. Sofía cursó parte de su formación secundaria en Quebec, donde tuvo su primer contacto directo con la investigación científica mediante prácticas de laboratorio. Posteriormente, el Bachillerato Internacional fortaleció su interés en la biología y el cuerpo humano. \nLaura Sánchez Rodríguez \n\nLaura estudió en el Colegio Salesiano Santo Ángel de Avilés, Asturias. Empezará el próximo curso la carrera de Biotecnología en la Universidad de Oviedo. Su interés por la ciencia surgió a través de proyectos escolares y viajes STEAM organizados por su centro educativo.\nCarmen Vico Guerra \n\nCarmen cursó Bachillerato en el IES Zorrilla de Valladolid. El próximo cursó comenzará a estudiar Biomedicina y Terapias Avanzadas en la Universidad de Valladolid. Su pasión por la ciencia comenzó en la infancia, cuando pasaba horas hojeando atlas de anatomía y viendo programas divulgativos.",
    "source": "CNIC"
  },
  {
    "title": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "title_es": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "url": "https://www.cnio.es/noticias/un-estudio-pionero-desvela-nuevos-mecanismos-geneticos-implicados-en-tumores-raros-de-cabeza-y-cuello/",
    "published": "2025-07-10T13:50:44.000Z",
    "date": "2025-07-10",
    "content_es": "Los paragangliomas y feocromocitomas son tumores neuroendocrinos muy raros (entre 3 y 8 casos por millón de habitantes) que aparecen en cabeza, cuello y torso, o en las glándulas suprarrenales, y que pueden diseminarse a otros órganos. Cerca de la mitad están causados por alteraciones genéticas heredadas, mutaciones que interesa mucho descubrir: conocerlas permite encontrar familiares portadores de […]\nLa entrada Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "title_es": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "url": "https://www.cnic.es/es/noticias/dr-miguel-torres-premio-nacional-genetica-2025-por-su-contribucion-al-desarrollo-terapias",
    "published": "2025-07-09T09:22:45.000Z",
    "date": "2025-07-09",
    "content_es": "09/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nLa Sociedad Española de Genética (SEG) reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa.\n\n\n\nEl investigador Miguel Torres Sánchez, coordinador del Programa de Regeneración Cardiovascular e investigador principal del grupo “Control Genético del Desarrollo y Regeneración de Órganos” en el Centro Nacional de Investigaciones Cardiovasculares (CNIC), ha sido galardonado con el Premio Nacional de Genética 2025 en la modalidad aplicada, otorgado por la Sociedad Española de Genética (SEG).\nEl jurado reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa, destacando especialmente su trabajo sobre cómo la actividad de los genes regula los procesos de regionalización durante el desarrollo embrionario.\nSus investigaciones han permitido desentrañar mecanismos genéticos implicados en el control de la calidad y la regeneración de órganos, sentando así las bases científicas para el desarrollo de terapias regenerativas dirigidas al corazón y al sistema vascular.\nEl fallo también resalta la proyección internacional del Dr. Torres y el alto impacto de sus publicaciones científicas, que lo sitúan como una figura de referencia en el campo de la biomedicina regenerativa.\nEl Dr. Torres lidera desde el CNIC una de las líneas de investigación más innovadoras en medicina regenerativa, con el objetivo de desarrollar nuevas estrategias terapéuticas que permitan reparar los tejidos dañados tras un infarto u otras patologías cardiovasculares, una de las principales causas de muerte en el mundo.\nProyecto REACTIVA\nEntre otros proyectos, el Dr. Torres dirige el proyecto REACTIVA, seleccionado para recibir una prestigiosa ERC Advanced Grant, financiación que respalda una línea de investigación innovadora centrada en la regeneración del tejido cardíaco, con el objetivo de abrir nuevas vías hacia terapias regenerativas del corazón.\nEl Premio Nacional de Genética, financiado por la Fundación Pryconsa, representa uno de los más altos reconocimientos a la excelencia investigadora en genética en nuestro país. Con él, la Sociedad Española de Genética desea rendir homenaje a la destacada trayectoria científica del Dr. Torres, su compromiso con el avance del conocimiento y el impacto significativo que su trabajo ha tenido en la comunidad científica.\nEste galardón, señala Teresa Roldán Arjona, Presidenta de la Sociedad Española de Genética, “enaltece no solo los logros personales del Dr. Torres, sino también a la institución a la que representa y al conjunto de la comunidad genética”.\nLos Premios Nacionales de Genética, impulsados por la SEG, distinguen cada año trayectorias científicas sobresalientes tanto en investigación básica como aplicada. Junto a Miguel Torres, el jurado ha premiado en la modalidad básica a Amparo Latorre Castillo, catedrática de Genética en la Universidad de València, por su pionera labor en el estudio de la variabilidad del ADN mitocondrial y los procesos evolutivos de simbiosis.",
    "source": "CNIC"
  },
  {
    "title": "Premio a la unidad de cáncer pediátrico del CNIO",
    "title_es": "Premio a la unidad de cáncer pediátrico del CNIO",
    "url": "https://www.cnio.es/noticias/premio-a-la-unidad-de-cancer-pediatrico-del-cnio/",
    "published": "2025-07-07T10:27:25.000Z",
    "date": "2025-07-07",
    "content_es": "Las terapias CAR-T son un tipo de inmunoterapia personalizada en que las células defensivas del paciente son modificadas en el laboratorio para reforzar su capacidad de reconocer y destruir las células tumorales. Su uso, cada vez más frecuente en adultos, es aún reducido en pediatría. La Sociedad Europea de Oncología Pediátrica ha alertado ya de […]\nLa entrada Premio a la unidad de cáncer pediátrico del CNIO se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "title_es": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "url": "https://www.cnio.es/noticias/gracias-a-nuestros-amigos-y-amigas-por-ayudarnos-a-acabar-con-el-cancer/",
    "published": "2025-07-07T07:59:05.000Z",
    "date": "2025-07-07",
    "content_es": "“La clave para frenar el cáncer podría estar en la comunicación entre proteínas. Pero sinceramente, creo que la verdadera clave está en nuestra comunicación, en cómo compartimos, cuestionamos y colaboramos; si seguimos manteniendo este diálogo abierto, creo que llegará el día en que realmente entendamos el cáncer… y lo detengamos”, dijo en la Jornada de […]\nLa entrada Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "title_es": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "url": "https://www.cnio.es/noticias/el-cnio-celebra-la-solidaridad-de-sus-amigos-as-clave-para-atraer-talento-y-avanzar-en-la-investigacion-del-cancer/",
    "published": "2025-07-04T11:09:50.000Z",
    "date": "2025-07-04",
    "content_es": "Una parte importante del conocimiento que genera el Centro Nacional de Investigaciones Oncológicas (CNIO), y que se orienta a mejorar la prevención, el diagnóstico y el tratamiento del cáncer, es fruto de la generosidad. La generosidad de las personas, empresas y fundaciones que realizan donaciones al centro a través del programa ‘Amigos/as del CNIO’.  Desde que se estableció, en 2015, todos los fondos […]\nLa entrada El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "title_es": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "url": "https://www.cnic.es/es/node/235158",
    "published": "2025-07-02T09:04:18.000Z",
    "date": "2025-07-02",
    "content_es": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nCNIC researchers have uncovered the evolutionary logic of the OxPhos system—the cell’s “engine”—and developed a tool to detect mutations that cause mitochondrial disease\n\n\n\nMitochondria are the body’s “energy factories,” and their proper function is essential for life. Inside mitochondria, a set of complexes called the oxidative phosphorylation (OxPhos) system acts like a biochemical assembly line, transforming oxygen and nutrients into usable energy.\nNow, the study, led by the GENOXPHOS group at the Spanish National Centre for Cardiovascular Research (CNIC) and the Biomedical Research Networking Centre in the area of Frailty and Healthy Ageing (CIBERFES), and directed by Dr. José Antonio Enríquez, has revealed how this system evolved over millions of years—from the first vertebrates to modern humans. “Understanding this evolution helps explain why some genetic mutations cause rare but serious diseases that affect the OxPhos system,” say José Luis Cabrera lead author of the article, whose research is supported by the ‘la Caixa’ Foundation.\nPublished in Cell Genomics, the study describes the molecular evolutionary strategies of the OxPhos system, the main site of metabolic and energy integration in the cell. It also shows how this information can be used to identify mutations that cause disease.\nWorking in collaboration with Fátima Sánchez-Cabo, head of the CNIC Computational Systems Biomedicine group, the researchers analyzed the interaction between the two types of DNA that encode OxPhos proteins: nuclear DNA (inherited from both parents) and mitochondrial DNA (inherited only from the mother).\nThe OxPhos system, explains José Antonio Enríquez—head of the CNIC Functional Genetics of the Oxidative Phosphorylation System (GENOXPHOS) group—comprises five large protein complexes: four that transport electrons and one, called ATP synthase, that produces ATP, the cell’s molecular “fuel.”\n“These complexes can work individually or in combination, depending on the cell’s energy needs. Together, they are made up of 103 proteins encoded by two different genomes: nuclear and mitochondrial,” Enríquez explains. “While nuclear DNA changes slowly over time and gains variation through genetic mixing during reproduction, mitochondrial DNA evolves much more rapidly but is passed only through the maternal line.”\nDr. Cabrera adds that the proteins encoded by mitochondrial DNA form the core of the respiratory complexes, “so proper function depends on precise compatibility between the nuclear and mitochondrial components.”\nThe study also introduces an innovative new tool: ConScore, a predictive index that assesses the clinical relevance of mutations in the 103 OxPhos proteins. “ConScore is based on the evolutionary divergence of these proteins across vertebrates—including primates and other mammals—and complements human population genetic data,” says Enríquez.\nThe authors affirm that ConScore provides a new framework for interpreting potentially pathogenic mutations, opening the door to improved diagnosis and treatment of mitochondrial diseases.\nUltimately, the researchers conclude, this study not only advances our understanding of how human cells evolved, but also brings us closer to new solutions for patients with rare genetic disease.\nThe study has received funding from the European Union's NextGenerationEU/Recovery, Transformation and Resilience Plan/PRTR, CIBERFES; Fundación ‘la Caixa’,Human Frontier Science Fundation; Severo Ochoa grant awarded by MICIU/AEI and the European Social Fund (ESF invests in your future).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "source": "CNIC"
  },
  {
    "title": "Cell Genomics: Revelan cómo ha evolucionado el sistema energético de las células y cómo puede ayudar a entender las enfermedades genéticas ",
    "title_es": "Cell Genomics: Revelan cómo ha evolucionado el sistema energético de las células y cómo puede ayudar a entender las enfermedades genéticas ",
    "url": "https://www.cnic.es/es/noticias/cell-genomics-revelan-como-ha-evolucionado-sistema-energetico-celulas-como-puede-ayudar",
    "published": "2025-07-02T08:56:37.000Z",
    "date": "2025-07-02",
    "content_es": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nInvestigadores del CNIC descubren las claves evolutivas del sistema OxPhos, el \"motor\" de la célula, y desarrollan una herramienta para detectar mutaciones que causan enfermedades mitocondriales.\n\n\n\nLas mitocondrias son las “fábricas de energía” de nuestro organismo y su funcionamiento correcto es vital para producir la energía que necesitamos. En su interior funciona el sistema de fosforilación oxidativa, OxPhos, un conjunto de proteínas que trabaja como una cadena para transformar el oxígeno y los nutrientes en energía.\nAhora, el estudio, liderado por el grupo GENOXPHOS del Centro Nacional de Investigaciones Cardiovasculares (CNIC) y del Centro de Investigación Biomédica en Red Fragilidad y Envejecimiento Saludable (CIBERFES), y dirigido por el Dr. José Antonio Enríquez, desvela cómo ha evolucionado este sistema a lo largo de millones de años, desde los primeros vertebrados hasta los seres humanos. “Comprender esta evolución ayuda a explicar por qué algunas mutaciones genéticas provocan enfermedades raras y graves que afectan a este sistema”, señala el Dr. José Luis Cabrera, autor principal del artículo cuya investigación cuenta con el apoyo de la Fundación ‘la Caixa’.\nEl estudio, publicado en la revista Cell Genomics, desvela las estrategias evolutivas a nivel molecular que ha seguido el principal centro de integración metabólico y energético de la célula, el sistema OxPhos, y describe como esta información puede ser utilizada para identificar en personas mutaciones causantes de enfermedades.\nLos investigadores, en colaboración con el grupo de Fátima Sánchez-Cabo, jefa del grupo de Biomedicina de Sistemas Computacional del CNIC,  han analizado cómo interactúan los dos tipos de ADN que codifican las proteínas del sistema OxPhos: el ADN nuclear (heredado del padre y la madre) y el ADN mitocondrial (que solo se hereda de la madre).\nEl sistema OxPhos, explica el Dr. Enríquez, jefe del grupo Genética Funcional del Sistema de Fosforilación Oxidativa (GENOXPHOS) del CNIC, está formado por cinco grandes bloques de proteínas: cuatro que transportan electrones y otro, llamado ATP-sintetasa, que produce energía en forma de ATP, el \"combustible\" celular.\n“Estos bloques pueden funcionar por separado o formar grupos según lo que necesite la célula. En total, están formados por unas 103 proteínas, codificadas por dos tipos de ADN: el nuclear y el mitocondrial. Y, mientras que el ADN nuclear cambia poco con el tiempo y gana variedad gracias a la mezcla genética durante la reproducción, el ADN mitocondrial se modifica mucho más rápido, aunque solo se transmite de madres a hijos”, aclara el Dr. Enríquez.\nAñade el Dr. Cabrera que las proteínas codificadas por el ADN mitocondrial constituyen el corazón de los complejos respiratorios, “cuyo correcto funcionamiento depende de que los componentes nucleares y los mitocondriales encajen adecuadamente”.\nAdemás, el estudio presenta una herramienta innovadora: ConScore, un índice de predicción funcional que permite evaluar la relevancia clínica de las mutaciones en las 103 proteínas que componen el sistema OxPhos. “Este índice se basa en la divergencia evolutiva de estas proteínas entre vertebrados —incluidos mamíferos y primates—, y complementa los estudios de variabilidad genética en poblaciones humanas”, señala el Dr. Enríquez.\nConScore ofrece un nuevo marco para interpretar mutaciones potencialmente patológicas, abriendo la puerta al desarrollo de mejores estrategias diagnósticas y terapéuticas frente a enfermedades mitocondriales, aseguran los investigadores.\nEsta investigación, concluyen sus autores, no solo ayuda a entender cómo hemos evolucionado a nivel celular, sino que también acerca nuevas soluciones para mejorar la salud de las personas que sufren enfermedades genéticas raras.\nEl estudio ha recibido financiación de la Unión Europea «NextGenerationEU»/Plan de Recuperación, Transformación y Resiliencia/PRTR, CIBERFES; Fundación ‘la Caixa’, Human Frontier Science Fundation; beca Severo Ochoa concedida por MICIU/AEI y por los Fondos Sociales Europeos (FSE invierte en tu futuro).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "source": "CNIC"
  },
  {
    "title": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "title_es": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "url": "https://www.cnio.es/noticias/los-danos-en-el-adn-derivados-de-la-contaminacion-atmosferica-podrian-contribuir-al-cancer-de-pulmon-en-personas-no-fumadoras-halla-un-estudio/",
    "published": "2025-07-02T15:17:44.000Z",
    "date": "2025-07-02",
    "content_es": "Una cuarta parte de los casos de cáncer de pulmón se dan en personas que no han fumado nunca. ¿Cuál es la causa de estos cánceres? Un estudio que analiza las alteraciones genéticas (mutaciones) en tumores de 871 personas no fumadoras de cuatro continentes apunta a la contaminación atmosférica como una de las posibles causas. […]\nLa entrada Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "title_es": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "url": "https://www.cnio.es/noticias/roger-castells-graells-recibe-el-premio-hawk-biosystems-de-la-sociedad-espanola-de-biofisica/",
    "published": "2025-06-27T13:52:15.000Z",
    "date": "2025-06-27",
    "content_es": "El investigador Roger Castells-Graells, del Centro Nacional de Investigaciones Oncológicas (CNIO), ha recibido el premio “Hawk Biosystems”, que otorga la Sociedad de Biofísica de España (SBE) en el marco de su XVIII Congreso Internacional. Castells-Graells se incorporó recientemente al CNIO para dirigir el nuevo Grupo de Diseño Biomolecular y Nanomedicina Estructural, dedicado a crear nanopartículas […]\nLa entrada Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "title_es": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "url": "https://www.cnio.es/noticias/mariano-barbacid-premio-valor-anadido-a-la-ciencia-e-investigacion/",
    "published": "2025-06-26T13:42:59.000Z",
    "date": "2025-06-26",
    "content_es": "Mariano Barbacid, descubridor del primer oncogén humano, ha recibido el Premio Valor Añadido a la Ciencia e Investigación, que reconoce la “labor de cultivo y perfeccionamiento de la investigación, descubrimiento e invención”. Los Premios Valor Añadido son una iniciativa de la Fundación Transforma España, en colaboración con BBVA, para «impulsar el reconocimiento de la aportación […]\nLa entrada Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El CNIO crea ‘nanopartículas de proteínas’ para acelerar el desarrollo de fármacos contra el cáncer",
    "title_es": "El CNIO crea ‘nanopartículas de proteínas’ para acelerar el desarrollo de fármacos contra el cáncer",
    "url": "https://www.cnio.es/noticias/el-cnio-crea-nanoparticulas-de-proteinas-para-acelerar-el-desarrollo-de-farmacos-contra-el-cancer/",
    "published": "2025-06-24T09:14:31.000Z",
    "date": "2025-06-24",
    "content_es": "Las proteínas son moléculas complejas que realizan funciones cruciales en el organismo. Conocerlas es esencial para comprender e intentar curar enfermedades: si se conoce la estructura tridimensional de una proteína implicada en cáncer, por ejemplo, se puede intentar diseñar una molécula capaz de modificar esa proteína para tratarlo.     El Grupo de Diseño Biomolecular y […]\nLa entrada El CNIO crea ‘nanopartículas de proteínas’ para acelerar el desarrollo de fármacos contra el cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Visita de la Universidad de Shanghai al CNIC para explorar futuras colaboraciones ",
    "title_es": "Visita de la Universidad de Shanghai al CNIC para explorar futuras colaboraciones ",
    "url": "https://www.cnic.es/es/noticias/visita-universidad-shanghai-al-cnic-para-explorar-futuras-colaboraciones",
    "published": "2025-06-20T07:13:34.000Z",
    "date": "2025-06-20",
    "content_es": "20/06/2025\n\n\nSobre el CNIC\nInvestigación\n\n\n\n\n\n\n\n\nUna delegación de la Universidad de Shanghai (China) ha visitado el CNIC con el objetivo de explorar posibles vías de colaboración en investigación biomédica.\nLa comitiva estuvo encabezada por Gou Yannan, vicepresidente de la Universidad de Shanghai, y contó con la participación de Liu Jinsong, director del Departamento de Activos; Xiao Junjie, decano de la Escuela de Ciencias de la Vida; Wang Haisong, arquitecto jefe de desarrollo del campus y vicedecano de la Academia de Bellas Artes de Shanghai, y Huang Pei, directora adjunta de la Oficina de Asuntos Internacionales.\nDurante la reunión, se discutieron posibles estrategias para establecer proyectos conjuntos de investigación y cooperación institucional entre ambas entidades.\nPor parte del CNIC, participaron Vicente Andrés, director de Investigación Básica; Beatriz Ferreiro, Directora Gestión Científica, y Enrique Lara Pezzi, líder del grupo de Regulación Molecular de la Insuficiencia Cardiaca.\nTras el encuentro, los representantes de la universidad china realizaron una visita a las instalaciones.\nEsta visita marca un primer paso en el establecimiento de lazos científicos entre el CNIC y la Universidad de Shanghai, con el propósito de impulsar el intercambio de conocimiento y el desarrollo de proyectos innovadores en el ámbito de la biomedicina.",
    "source": "CNIC"
  }
]