[
  {
    "title": "FIER: Fine-Grained and Efficient KV Cache Retrieval for Long-context LLM Inference",
    "title_es": "FIER: recuperación precisa y eficiente de la caché KV para la inferencia LLM de contexto largo",
    "url": "https://arxiv.org/abs/2508.08256",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08256v1 Tipo de anuncio: nuevo\nResumen: La latencia de lectura de la caché Key-Value (KV) aumenta significativamente con las longitudes de contexto, dificultando la eficiencia de la inferencia LLM de contexto largo. Para solucionar este problema, trabajos anteriores proponen retener una pequeña fracción de la caché KV en función de la importancia de los tokens. Por ejemplo, el desalojo de KV utiliza una heurística estática para retener los tokens, mientras que la recuperación de KV selecciona dinámicamente los tokens relevantes para la consulta para una gestión más adaptativa de la caché. Sin embargo, observamos que los tokens importantes suelen estar escasamente distribuidos en el contexto largo. Esta dispersión hace que la recuperación KV a nivel de página sea imprecisa, ya que cada página puede incluir tokens irrelevantes y omitir los críticos. En este trabajo, proponemos Fier, un método de recuperación de caché KV de grano fino y eficiente. Fier utiliza claves cuantificadas de 1 bit para estimar la importancia de cada token, lo que resulta en una recuperación eficiente y precisa. Los experimentos demuestran que Fier iguala el rendimiento completo de KV utilizando sólo el 11% del presupuesto de caché en varias tareas de contexto largo, reduciendo la latencia de descodificación entre 1,2 y 1,5 veces.",
    "source": "arXiv"
  },
  {
    "title": "Humanoid Robot Acrobatics Utilizing Complete Articulated Rigid Body Dynamics",
    "title_es": "Robot humanoide acrobático con dinámica de cuerpo rígido articulado completo",
    "url": "https://arxiv.org/abs/2508.08258",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08258v1 Tipo de anuncio: nuevo\nResumen: Dotar a los robots humanoides de la capacidad de realizar movimientos altamente dinámicos similares a las acrobacias humanas ha sido un reto desde hace mucho tiempo. Para realizar con éxito estas maniobras es necesario tener muy en cuenta la física subyacente tanto en la optimización de la trayectoria para la planificación como en el control durante la ejecución. Esto es especialmente difícil debido al elevado número de grados de libertad de los humanoides y a las complejidades de escalado exponencial asociadas, que hacen que la planificación de las ecuaciones explícitas de movimiento sea intratable. Las soluciones habituales incluyen métodos de linealización y aproximaciones de modelos. Sin embargo, ninguno de ellos es suficiente, ya que degradan el rendimiento del sistema robótico real. Este artículo presenta una arquitectura de control que comprende la optimización de la trayectoria y el control de todo el cuerpo, intermediado por una abstracción de modelo de correspondencia, que permite la ejecución de maniobras acrobáticas, incluidos los comportamientos de restricción y postura, condicionados a las ecuaciones de movimiento no abreviadas del modelo de cuerpo rígido articulado. Se ofrece una revisión de los métodos de modelado y control subyacentes, seguida de los detalles de implementación, incluida la abstracción del modelo, la optimización de la trayectoria y el controlador de cuerpo entero. La eficacia del sistema se analiza en simulación.",
    "source": "arXiv"
  },
  {
    "title": "Koopman Operator Based Linear Model Predictive Control for Quadruped Trotting",
    "title_es": "Control predictivo de modelos lineales basado en el operador Koopman para el trote de cuadrúpedos",
    "url": "https://arxiv.org/abs/2508.08259",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08259v1 Tipo de anuncio: nuevo\nResumen: El control óptimo en línea de robots cuadrúpedos les permitiría adaptarse a entradas variables y condiciones cambiantes en tiempo real. Una forma común de lograr esto es el control predictivo de modelos lineales (LMPC), donde un problema de programación cuadrática (QP) se formula sobre un horizonte finito con un coste cuadrático y restricciones lineales obtenidas mediante la linealización de las ecuaciones de movimiento y se resuelve sobre la marcha. Sin embargo, la linealización del modelo puede dar lugar a imprecisiones en el mismo. En este trabajo, utilizamos el operador Koopman para crear un modelo lineal del sistema cuadrúpedo en un espacio de alta dimensión que preserva la no linealidad de las ecuaciones de movimiento. A continuación, utilizando LMPC, demostramos alta fidelidad de seguimiento y rechazo de perturbaciones en un robot cuadrúpedo. Este es el primer trabajo que utiliza la teoría del operador de Koopman para el LMPC de locomoción cuadrúpeda.",
    "source": "arXiv"
  },
  {
    "title": "Argument Quality Annotation and Gender Bias Detection in Financial Communication through Large Language Models",
    "title_es": "Anotación de la calidad de los argumentos y detección de prejuicios sexistas en la comunicación financiera mediante grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.08262",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08262v1 Tipo de anuncio: nuevo\nResumen: Los argumentos financieros desempeñan un papel fundamental en la toma de decisiones de inversión y en la confianza del público en las instituciones financieras. Sin embargo, la evaluación de su calidad sigue estando poco estudiada en la literatura. En este trabajo, examinamos las capacidades de tres LLMs de última generación: GPT-4o, Llama 3.1 y Gemma 2 para anotar la calidad de los argumentos en comunicaciones financieras, utilizando el conjunto de datos FinArgQuality. Nuestra contribución es doble. En primer lugar, evaluamos la consistencia de las anotaciones generadas por LLM en múltiples ejecuciones y las comparamos con anotaciones humanas. En segundo lugar, introducimos un ataque adversario diseñado para inyectar sesgo de género al análisis de los modelos responde y garantiza la imparcialidad y robustez del modelo. Ambos experimentos se llevan a cabo en tres configuraciones de temperatura para evaluar su influencia en la estabilidad de las anotaciones y la alineación con las etiquetas humanas. Nuestros resultados revelan que las anotaciones basadas en LLM logran una mayor concordancia entre anotadores que sus homólogas humanas, aunque los modelos siguen mostrando diversos grados de sesgo de género. Proporcionamos un análisis multifacético de estos resultados y ofrecemos recomendaciones prácticas para guiar la investigación futura hacia metodologías de anotación más fiables, rentables y conscientes de los sesgos.",
    "source": "arXiv"
  },
  {
    "title": "Forecast-Driven MPC for Decentralized Multi-Robot Collision Avoidance",
    "title_es": "MPC basado en previsiones para evitar colisiones entre varios robots descentralizados",
    "url": "https://arxiv.org/abs/2508.08264",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08264v1 Tipo de anuncio: nuevo\nResumen: El Iterative Forecast Planner (IFP) es un enfoque de planificación geométrica que ofrece cálculos ligeros, escalables y soluciones reactivas para la planificación de rutas multi-robot en entornos descentralizados y sin comunicación. Sin embargo, tiene dificultades en configuraciones simétricas, donde las interacciones reflejadas a menudo provocan colisiones y bloqueos. Presentamos eIFP-MPC, una versión optimizada y ampliada de IFP que mejora la robustez y la coherencia de la trayectoria en entornos densos y dinámicos. El método refina la priorización de amenazas mediante una heurística de tiempo hasta la colisión, estabiliza la generación de rutas mediante la selección de puntos de paso basada en costes y garantiza la viabilidad dinámica incorporando el control predictivo de modelos (MPC) al proceso de planificación. Estas mejoras están estrechamente integradas en el IFP para preservar su eficiencia y mejorar su adaptabilidad y estabilidad. Simulaciones exhaustivas en escenarios simétricos y de alta densidad demuestran que el eIFP-MPC reduce significativamente las oscilaciones, garantiza un movimiento sin colisiones y mejora la eficiencia de la trayectoria. Los resultados demuestran que los planificadores geométricos pueden reforzarse mediante la optimización, lo que permite un rendimiento robusto a escala en entornos multiagente complejos.",
    "source": "arXiv"
  },
  {
    "title": "TurQUaz at CheckThat! 2025: Debating Large Language Models for Scientific Web Discourse Detection",
    "title_es": "¡TurQUaz en CheckThat! 2025: Debate sobre grandes modelos lingüísticos para la detección del discurso científico en la web",
    "url": "https://arxiv.org/abs/2508.08265",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08265v1 Tipo de anuncio: nuevo\n¡Resumen: En este artículo, presentamos nuestro trabajo desarrollado para la tarea de detección del discurso científico en la web (Tarea 4a) de CheckThat! 2025. Proponemos un novedoso método de debate en consejo que simula discusiones académicas estructuradas entre múltiples modelos de lenguaje de gran tamaño (LLMs) para identificar si un tweet dado contiene (i) una afirmación científica, (ii) una referencia a un estudio científico, o (iii) menciones a entidades científicas. Exploramos tres métodos de debate: i) debate individual, en el que dos LLM defienden posiciones opuestas mientras un tercero actúa como juez; ii) debate en equipo, en el que varios modelos colaboran en cada lado del debate; y iii) debate en consejo, en el que varios modelos expertos deliberan juntos para alcanzar un consenso, moderados por un modelo presidente. Elegimos el debate en consejo como modelo principal, ya que supera a los demás en el conjunto de pruebas de desarrollo. Aunque el método propuesto no obtuvo buenos resultados en la identificación de afirmaciones científicas (8º de 10) ni en la mención de entidades científicas (9º de 10), fue el primero en la detección de referencias a estudios científicos.",
    "source": "arXiv"
  },
  {
    "title": "Benchmarking Large Language Models for Geolocating Colonial Virginia Land Grants",
    "title_es": "Evaluación comparativa de grandes modelos lingüísticos para geolocalizar las concesiones de tierras de la Virginia colonial",
    "url": "https://arxiv.org/abs/2508.08266",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08266v1 Tipo de anuncio: nuevo\nResumen: Las patentes de tierras de Virginia de los siglos XVII y XVIII sobreviven principalmente como descripciones narrativas de medidas y límites, lo que limita el análisis espacial. Este estudio evalúa sistemáticamente la actual generación de grandes modelos lingüísticos (LLM) en la conversión de estos resúmenes en prosa en coordenadas de latitud/longitud geográficamente precisas dentro de un contexto de evaluación específico. Se publica un corpus digitalizado de 5.471 resúmenes de patentes de Virginia (1695-1732), con 43 casos de prueba rigurosamente verificados que sirven como punto de referencia inicial centrado geográficamente. Se probaron seis modelos de OpenAI en tres arquitecturas (o-series, GPT-4-class y GPT-3.5) bajo dos paradigmas: directo a coordenadas y cadena de pensamiento potenciada por herramientas que invocan API de geocodificación externas. Los resultados se compararon con los de un analista SIG de referencia, el geoparser NER de Stanford, Mordecai-3 y una heurística de centroide de condado.\n  El mejor modelo de llamada única, o3-2025-04-16, alcanzó un error medio de 23 km (mediana de 14 km), superando al LLM medio (37,4 km) en un 37,5%, al LLM más débil (50,3 km) en un 53,5%, y a las líneas de base externas en un 67% (analista GIS) y un 70% (Stanford NER). Un conjunto de cinco llamadas redujo aún más los errores a 19 km (mediana de 12 km) con un coste adicional mínimo (aproximadamente 0,20 USD por subvención), superando a la mediana del LLM en un 48,6%. La supresión de los nombres de las patentes aumentó el error en un 9%, lo que indica que se confía más en las descripciones textuales de los puntos de referencia y de adyacencia que en la memorización. El modelo rentable gpt-4o-2024-08-06 mantuvo un error medio de 28 km a 1,09 USD por cada 1.000 concesiones, estableciendo una sólida referencia de coste-precisión; las herramientas externas de geocodificación no ofrecieron ningún beneficio apreciable en esta evaluación.\n  Estos resultados demuestran el potencial de los LLM para una georreferenciación histórica escalable, precisa y rentable.",
    "source": "arXiv"
  },
  {
    "title": "emg2tendon: From sEMG Signals to Tendon Control in Musculoskeletal Hands",
    "title_es": "emg2tendon: De las señales sEMG al control tendinoso en manos musculoesqueléticas",
    "url": "https://arxiv.org/abs/2508.08269",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08269v1 Tipo de anuncio: nuevo\nResumen: Las manos robóticas accionadas por tendones ofrecen una destreza sin precedentes para tareas de manipulación, pero el aprendizaje de políticas de control para estos sistemas presenta retos únicos. A diferencia de las manos robóticas accionadas por articulaciones, los sistemas accionados por tendones carecen de un mapeo directo uno a uno entre los datos de captura de movimiento (mocap) y los controles del tendón, lo que hace que el proceso de aprendizaje sea complejo y costoso. Además, los métodos de seguimiento visual para aplicaciones reales son propensos a oclusiones e imprecisiones, lo que complica aún más el seguimiento de las articulaciones. Los sensores de electromiografía de superficie (sEMG) que se pueden llevar en la muñeca son una alternativa barata y robusta para capturar el movimiento de la mano. Sin embargo, la asignación de señales sEMG al control tendinoso sigue siendo un reto importante a pesar de la disponibilidad de conjuntos de datos EMG-a-postura y modelos basados en regresión en la literatura existente.\n  Presentamos el primer conjunto de datos a gran escala de EMG a control del tendón para manos robóticas, ampliando el conjunto de datos emg2pose, que incluye grabaciones de 193 sujetos, que abarcan 370 horas y 29 etapas con diversos gestos. Este conjunto de datos incorpora señales de control de tendones derivadas del modelo MyoHand de MyoSuite, lo que soluciona limitaciones como las poses no válidas de métodos anteriores. Proporcionamos tres modelos de regresión de referencia para demostrar la utilidad de emg2tendon y proponemos un nuevo modelo de regresión basado en la difusión para predecir el control tendinoso a partir de grabaciones de sEMG. Este conjunto de datos y el marco de modelado suponen un importante paso adelante para la manipulación robótica diestra basada en tendones, y sientan las bases para un control de tendones escalable y preciso en manos robóticas. https://emg2tendon.github.io/",
    "source": "arXiv"
  },
  {
    "title": "Doctor Sun: A Bilingual Multimodal Large Language Model for Biomedical AI",
    "title_es": "Doctor Sun: Un gran modelo lingüístico multimodal bilingüe para la IA biomédica",
    "url": "https://arxiv.org/abs/2508.08270",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08270v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos multimodales (LMMs) han demostrado un potencial significativo para proporcionar soluciones innovadoras para diversas tareas biomédicas, incluyendo el análisis de patologías, la generación de informes radiológicos y la asistencia biomédica. Sin embargo, la IA biomédica multimodal existente se basa normalmente en LLMs fundacionales, lo que dificulta la comprensión de conceptos médicos intrincados con datos de entrenamiento médico limitados. Además, los recientes LMM médicos inducidos por LLaVA tienen dificultades para captar eficazmente la intrincada relación entre los textos y las imágenes. Por lo tanto, presentamos Doctor Sun, un gran modelo generativo multimodal especializado en medicina, desarrollado para codificar, integrar e interpretar diversas modalidades de datos biomédicos como texto e imágenes. En concreto, Doctor Sun integra un codificador de visión preentrenado con un LLM médico y lleva a cabo un entrenamiento en dos etapas sobre diversos conjuntos de datos médicos, centrándose en la alineación de características y el ajuste de instrucciones. Además, publicamos SunMed-VL, un amplio conjunto de datos médicos multimodales bilingües, junto con todos los modelos, códigos y recursos asociados, para apoyar libremente el avance de la investigación biomédica multimodal.",
    "source": "arXiv"
  },
  {
    "title": "Heartificial Intelligence: Exploring Empathy in Language Models",
    "title_es": "Inteligencia auditiva: Exploración de la empatía en modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.08271",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08271v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos lingüísticos se han vuelto cada vez más comunes, siendo utilizados por millones de personas en todo el mundo tanto en contextos profesionales como personales. A medida que estos modelos siguen avanzando, con frecuencia sirven como asistentes y acompañantes virtuales. En las interacciones humanas, la comunicación eficaz suele implicar dos tipos de empatía: la empatía cognitiva (comprender los pensamientos y emociones de los demás) y la empatía afectiva (compartir emocionalmente los sentimientos de los demás). En este estudio, investigamos tanto la empatía cognitiva como la afectiva en varios modelos lingüísticos pequeños (SLM) y grandes (LLM) utilizando pruebas psicológicas estandarizadas. Nuestros resultados revelaron que los LLM superaban sistemáticamente a los humanos -incluidos los estudiantes de psicología- en tareas de empatía cognitiva. Sin embargo, a pesar de sus ventajas cognitivas, tanto los modelos lingüísticos pequeños como los grandes mostraron una empatía afectiva significativamente inferior a la de los participantes humanos. Estos resultados ponen de relieve los rápidos avances en la capacidad de los modelos lingüísticos para simular la empatía cognitiva, lo que sugiere un gran potencial para proporcionar compañía virtual eficaz y apoyo emocional personalizado. Además, su alta empatía cognitiva y su baja empatía afectiva permiten un apoyo emocional objetivo y coherente sin correr el riesgo de fatiga emocional o sesgo.",
    "source": "arXiv"
  },
  {
    "title": "Real-time News Story Identification",
    "title_es": "Identificación de noticias en tiempo real",
    "url": "https://arxiv.org/abs/2508.08272",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08272v1 Tipo de anuncio: nuevo\nResumen: Para mejorar la experiencia de lectura, muchos sitios de noticias organizan las noticias en colecciones temáticas, llamadas historias. En este trabajo, presentamos un enfoque para implementar la identificación de historias en tiempo real para un sistema de monitorización de noticias que recoge automáticamente los artículos de noticias a medida que aparecen en línea y los procesa de varias maneras. El objetivo de la identificación de noticias es asignar cada una de ellas a un tema concreto. El proceso es similar a la agrupación de textos y el modelado de temas, pero requiere que los artículos se agrupen en función de acontecimientos, lugares y personas concretos, en lugar de por similitudes generales de texto (como en la agrupación) o temas generales (predefinidos) (como en el modelado de temas). Presentamos un método de identificación de historias capaz de funcionar en tiempo real, asignando artículos a historias a medida que se publican en línea. En el enfoque propuesto, combinamos técnicas de representación del texto, algoritmos de agrupación y métodos de modelización de temas en línea. Combinamos varios métodos de representación de texto para extraer eventos específicos y entidades con nombre necesarias para la identificación de historias, demostrando que una mezcla de enfoques de modelado de temas en línea como BERTopic, DBStream y TextClust puede adaptarse para el descubrimiento de historias. Evaluamos nuestro método con un conjunto de datos de noticias de medios de comunicación eslovenos que cubren un periodo de un mes. Demostramos que nuestro planteamiento en tiempo real produce resultados razonables a juicio de evaluadores humanos.",
    "source": "arXiv"
  },
  {
    "title": "TT-XAI: Trustworthy Clinical Text Explanations via Keyword Distillation and LLM Reasoning",
    "title_es": "TT-XAI: explicaciones fiables de textos clínicos mediante destilación de palabras clave y razonamiento LLM",
    "url": "https://arxiv.org/abs/2508.08273",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08273v1 Tipo de anuncio: nuevo\nResumen: Los modelos de lenguaje clínico a menudo tienen dificultades para proporcionar predicciones y explicaciones fiables cuando se aplican a largas historias clínicas electrónicas no estructuradas. Este trabajo presenta TT-XAI, un marco ligero y eficaz que mejora tanto el rendimiento de la clasificación como la interpretabilidad a través de la destilación de palabras clave consciente del dominio y el razonamiento con grandes modelos de lenguaje (LLM). En primer lugar, demostramos que la destilación de notas de alta en bruto en representaciones concisas de palabras clave mejora significativamente el rendimiento del clasificador BERT y mejora la fidelidad de la explicación local a través de una variante enfocada de LIME. En segundo lugar, generamos explicaciones clínicas de cadena de pensamiento utilizando indicaciones guiadas por palabras clave para dirigir los LLM, produciendo un razonamiento más conciso y clínicamente relevante. Evaluamos la calidad de las explicaciones mediante métricas de fidelidad basadas en la eliminación, la autoevaluación mediante la puntuación LLaMA-3 y un estudio ciego en humanos con expertos en la materia. Todas las modalidades de evaluación favorecen de forma consistente el método de palabras clave aumentadas, lo que confirma que la destilación mejora tanto la interpretabilidad mecánica como la humana. TT-XAI ofrece una vía escalable hacia una IA fiable y auditable en el apoyo a la toma de decisiones clínicas.",
    "source": "arXiv"
  },
  {
    "title": "Distilling Knowledge from Large Language Models: A Concept Bottleneck Model for Hate and Counter Speech Recognition",
    "title_es": "Destilar el conocimiento de grandes modelos lingüísticos: Un modelo de cuello de botella conceptual para el reconocimiento del discurso de odio y contraataque",
    "url": "https://arxiv.org/abs/2508.08274",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08274v1 Tipo de anuncio: nuevo\nResumen: El rápido aumento del discurso del odio en las redes sociales ha expuesto un impacto sin precedentes en la sociedad, lo que hace que los métodos automatizados para detectar este tipo de contenido sean importantes. A diferencia de los modelos de caja negra anteriores, proponemos un nuevo método transparente para el reconocimiento automatizado del discurso del odio y el contra-discurso, es decir, \"Speech Concept Bottleneck Model\" (SCBM), utilizando adjetivos como conceptos de cuello de botella interpretables por humanos. El SCBM utiliza grandes modelos lingüísticos (LLM) para asignar textos de entrada a una representación abstracta basada en adjetivos, que luego se envía a un clasificador ligero para tareas posteriores. En cinco conjuntos de datos de referencia que abarcan varios idiomas y plataformas (por ejemplo, Twitter, Reddit, YouTube), SCBM logra una puntuación macro-F1 media de 0,69, que supera los resultados más recientes de la bibliografía en cuatro de los cinco conjuntos de datos. Además de una elevada precisión de reconocimiento, la MCE ofrece un alto nivel de interpretabilidad local y global. Por otra parte, la fusión de nuestra representación conceptual basada en adjetivos con las incrustaciones de transformadores da lugar a un aumento del rendimiento del 1,8% de media en todos los conjuntos de datos, lo que demuestra que la representación propuesta captura información complementaria. Nuestros resultados demuestran que las representaciones conceptuales basadas en adjetivos pueden servir como codificaciones compactas, interpretables y eficaces para el reconocimiento de discursos de odio y contra-discurso. Con adjetivos adaptados, nuestro método también puede aplicarse a otras tareas de PNL.",
    "source": "arXiv"
  },
  {
    "title": "MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis",
    "title_es": "MLLM-CBench: un punto de referencia exhaustivo para el ajuste continuo de instrucciones de LLM multimodales con análisis de razonamiento de cadena de pensamiento",
    "url": "https://arxiv.org/abs/2508.08275",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08275v1 Tipo de anuncio: nuevo\nResumen: Los Modelos Multimodales de Lenguaje Amplio (MLLMs) se basan en el ajuste continuo de las instrucciones para adaptarse a las demandas cambiantes de las aplicaciones del mundo real. Sin embargo, el progreso en esta área se ve obstaculizado por la falta de puntos de referencia rigurosos y sistemáticos. Para subsanar esta carencia, presentamos MLLM-CTBench, una prueba de evaluación exhaustiva con tres aportaciones clave: (1) Evaluación multidimensional: Combinamos la precisión de la respuesta final con una evaluación detallada de la calidad del razonamiento CoT, facilitada por un evaluador CoT especialmente formado; (2) Evaluación exhaustiva de algoritmos y paradigmas de entrenamiento: Evaluamos ocho algoritmos de aprendizaje continuo en cuatro categorías principales y comparamos sistemáticamente el aprendizaje por refuerzo con paradigmas de ajuste fino supervisado; (3) Tareas cuidadosamente seleccionadas: Seleccionamos y organizamos 16 conjuntos de datos a partir de trabajos existentes, que abarcan seis dominios difíciles. Entre nuestros principales hallazgos se incluyen: (i) Los modelos con capacidades generales más potentes muestran una mayor solidez frente al olvido durante el aprendizaje continuo; (ii) Las cadenas de razonamiento se degradan más lentamente que las respuestas finales, lo que apoya la hipótesis del olvido jerárquico; (iii) La eficacia de los algoritmos de aprendizaje continuo depende en gran medida tanto de la capacidad del modelo como del orden de las tareas; (iv) En entornos de aprendizaje por refuerzo, la incorporación de restricciones de divergencia KL ayuda a mantener la estabilidad de las políticas y desempeña un papel crucial en la mitigación del olvido. MLLM-CTBench establece una norma rigurosa para el ajuste de instrucción continua de los MLLM y ofrece orientación práctica para el diseño y la evaluación de algoritmos.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating Contrast Localizer for Identifying Causal Unitsin Social & Mathematical Tasks in Language Models",
    "title_es": "Evaluación del localizador de contrastes para identificar unidades causales en tareas sociales y matemáticas en modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.08276",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08276v1 Tipo de anuncio: nuevo\nResumen: Este trabajo adapta un localizador de contraste neurocientífico para identificar unidades causalmente relevantes para la Teoría de la Mente (ToM) y tareas de razonamiento matemático en grandes modelos de lenguaje (LLMs) y modelos de visión-lenguaje (VLMs). A través de 11 LLMs y 5 VLMs con un tamaño de entre 3B y 90B parámetros, localizamos las unidades más activadas utilizando conjuntos de estímulos contrastados y evaluamos su papel causal mediante ablaciones dirigidas. Comparamos el efecto de lesionar unidades seleccionadas funcionalmente frente a unidades de baja activación y seleccionadas aleatoriamente en la precisión descendente a través de puntos de referencia matemáticos y de ToM establecidos. Contrariamente a lo esperado, las unidades de baja activación produjeron a veces mayores caídas en el rendimiento que las de alta activación, y las unidades derivadas del localizador matemático a menudo perjudicaron el rendimiento ToM más que las del localizador ToM. Estos hallazgos cuestionan la relevancia causal de los localizadores basados en el contraste y subrayan la necesidad de conjuntos de estímulos más amplios y de capturar con mayor precisión las unidades específicas de la tarea.",
    "source": "arXiv"
  },
  {
    "title": "Objective Metrics for Evaluating Large Language Models Using External Data Sources",
    "title_es": "Métricas objetivas para evaluar grandes modelos lingüísticos con fuentes de datos externas",
    "url": "https://arxiv.org/abs/2508.08277",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08277v1 Tipo de anuncio: nuevo\nResumen: Evaluar el rendimiento de los Modelos de Lenguaje Extensos (LLMs) es una tarea crítica pero desafiante, particularmente cuando se pretende evitar evaluaciones subjetivas. Este artículo propone un marco para aprovechar las métricas subjetivas derivadas de los materiales textuales de clase a lo largo de diferentes semestres para evaluar los resultados de los LLM en varias tareas. Mediante el uso de puntos de referencia bien definidos, conjuntos de datos objetivos y procesos de evaluación estructurados, el enfoque garantiza mediciones coherentes, reproducibles y con un mínimo de sesgos. El marco hace hincapié en la automatización y la transparencia de la puntuación, reduciendo la dependencia de la interpretación humana y garantizando al mismo tiempo la alineación con las aplicaciones del mundo real. Este método aborda las limitaciones de los métodos de evaluación subjetiva, proporcionando una solución escalable para la evaluación del rendimiento en los ámbitos educativo, científico y otros en los que hay mucho en juego.",
    "source": "arXiv"
  },
  {
    "title": "Towards Heterogeneity-Aware and Energy-Efficient Topology Optimization for Decentralized Federated Learning in Edge Environment",
    "title_es": "Hacia una optimización de la topología consciente de la heterogeneidad y eficiente desde el punto de vista energético para el aprendizaje descentralizado federado en entornos periféricos",
    "url": "https://arxiv.org/abs/2508.08278",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08278v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje federado (FL) ha surgido como un paradigma prometedor dentro de los sistemas de computación de borde (EC), permitiendo que numerosos dispositivos de borde entrenen de forma colaborativa modelos de inteligencia artificial (IA), manteniendo la privacidad de los datos. Para superar los cuellos de botella en la comunicación asociados a los servidores de parámetros centralizados, el aprendizaje federado descentralizado (DFL), que aprovecha la comunicación entre pares (P2P), ha sido ampliamente explorado en la comunidad investigadora. Aunque los investigadores diseñan diversos enfoques de DFL para garantizar la convergencia del modelo, su proceso de aprendizaje iterativo incurre inevitablemente en costes considerables junto con el crecimiento de la complejidad del modelo y el número de participantes. Estos costes se ven influidos en gran medida por los cambios dinámicos de la topología en cada ronda de entrenamiento, en particular sus condiciones de escasez y conectividad. Además, la heterogeneidad de recursos inherente a los entornos de borde afecta a la eficiencia energética del proceso de aprendizaje, mientras que la heterogeneidad de datos degrada el rendimiento del modelo. Estos factores plantean importantes retos para el diseño de un marco DFL eficaz para los sistemas EC. Con este fin, proponemos Hat-DFed, un marco de aprendizaje federado descentralizado (DFL) eficaz y consciente de la heterogeneidad. En Hat-DFed, la construcción de la topología se formula como un problema de optimización dual, que luego se demuestra que es NP-difícil, con el objetivo de maximizar el rendimiento del modelo y minimizar el consumo de energía acumulado en entornos de borde complejos. Para resolver este problema, diseñamos un algoritmo de dos fases que construye dinámicamente topologías de comunicación óptimas al tiempo que estima de forma insesgada su impacto tanto en el rendimiento del modelo como en el coste energético. Además, el algoritmo incorpora un mecanismo de agregación de modelos que tiene en cuenta la importancia para mitigar la degradación del rendimiento causada por la heterogeneidad de los datos.",
    "source": "arXiv"
  },
  {
    "title": "XFMNet: Decoding Cross-Site and Nonstationary Water Patterns via Stepwise Multimodal Fusion for Long-Term Water Quality Forecasting",
    "title_es": "XFMNet: Decodificación de patrones hídricos no estacionarios y entre emplazamientos mediante la fusión multimodal paso a paso para la predicción de la calidad del agua a largo plazo",
    "url": "https://arxiv.org/abs/2508.08279",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08279v1 Tipo de anuncio: nuevo\nResumen: La predicción de series temporales a largo plazo es fundamental para la vigilancia del medio ambiente, sin embargo, la predicción de la calidad del agua sigue siendo un reto debido a la periodicidad compleja, la no estacionariedad y las fluctuaciones bruscas inducidas por factores ecológicos. Estos retos se amplifican aún más en escenarios multisitio que requieren la modelización simultánea de dinámicas temporales y espaciales. Para hacer frente a esta situación, presentamos XFMNet, una red de fusión multimodal por etapas que integra imágenes de precipitación obtenidas por teledetección para proporcionar un contexto espacial y medioambiental en las redes fluviales. XFMNet alinea primero las resoluciones temporales entre las series de calidad del agua y las entradas de teledetección mediante un muestreo descendente adaptativo, seguido de una descomposición adaptativa local para separar los componentes de tendencia y ciclo. Un módulo de fusión de atención cruzada integra dinámicamente patrones temporales con señales espaciales y ecológicas, mejorando la robustez frente a la no estacionariedad y las anomalías específicas del lugar. Mediante una fusión progresiva y recursiva, XFMNet capta tanto las tendencias a largo plazo como las fluctuaciones a corto plazo. Experimentos exhaustivos con conjuntos de datos reales demuestran mejoras sustanciales respecto a las líneas de base más avanzadas, lo que pone de relieve la eficacia de XFMNet para la predicción de series temporales distribuidas espacialmente.",
    "source": "arXiv"
  },
  {
    "title": "MoSSDA: A Semi-Supervised Domain Adaptation Framework for Multivariate Time-Series Classification using Momentum Encoder",
    "title_es": "MoSSDA: A Semi-Supervised Domain Adaptation Framework for Multivariate Time-Series Classification using Momentum Encoder (Marco de adaptación de dominio semisupervisado para la clasificación de series temporales multivariantes utilizando el codificador Momentum).",
    "url": "https://arxiv.org/abs/2508.08280",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08280v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje profundo ha surgido como el enfoque más prometedor en varios campos; sin embargo, cuando las distribuciones de datos de entrenamiento y prueba son diferentes (cambio de dominio), el rendimiento de los modelos de aprendizaje profundo puede degradarse. La adaptación de dominio semisupervisada (SSDA) es un enfoque importante para abordar este problema, suponiendo que se dispone de un conjunto de entrenamiento totalmente etiquetado (dominio de origen), pero el conjunto de prueba (dominio de destino) proporciona etiquetas solo para un pequeño subconjunto. En este estudio, proponemos un nuevo marco SSDA en dos pasos, MoSSDA, para la clasificación multivariante de series temporales. Los datos de series temporales son muy sensibles al ruido, y las dependencias secuenciales causan cambios de dominio que provocan una degradación crítica del rendimiento. Para obtener una representación robusta, invariante de dominio y discriminatoria de clase, MoSSDA emplea un codificador invariante de dominio para aprender características de los dominios de origen y destino. A continuación, las características aprendidas se introducen en un módulo de contraste positivo mejorado que consiste en un codificador de impulso en línea. El clasificador final se entrena con características aprendidas que muestran coherencia y discriminabilidad con datos de dominio de destino etiquetados limitados, sin aumento de datos. Aplicamos un proceso de dos etapas separando el flujo de gradiente entre los codificadores y el clasificador para obtener representaciones ricas y complejas. Mediante experimentos exhaustivos en seis conjuntos de datos diversos, MoSSDA logró un rendimiento de vanguardia para tres columnas vertebrales diferentes y varias proporciones sin etiquetar en los datos del dominio de destino. El estudio Ablation confirma que cada módulo, incluido el aprendizaje en dos etapas, es eficaz para mejorar el rendimiento. Nuestro código está disponible en https://github.com/seonyoungKimm/MoSSDA",
    "source": "arXiv"
  },
  {
    "title": "Multi-grained spatial-temporal feature complementarity for accurate online cellular traffic prediction",
    "title_es": "Complementariedad espaciotemporal multigrano para una predicción precisa del tráfico celular en línea",
    "url": "https://arxiv.org/abs/2508.08281",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08281v1 Tipo de anuncio: nuevo\nResumen: El conocimiento descubierto a partir de los datos de telecomunicaciones puede facilitar la comprensión proactiva de la dinámica de la red y los comportamientos de los usuarios, lo que a su vez permite a los proveedores de servicios optimizar la programación del tráfico celular y la asignación de recursos. Sin embargo, el sector de las telecomunicaciones sigue dependiendo en gran medida de la intervención manual de expertos. Los estudios existentes se han centrado en explorar exhaustivamente las correlaciones espaciotemporales. Sin embargo, a menudo pasan por alto las características subyacentes del tráfico celular, que se ven condicionadas por la naturaleza esporádica e intermitente de los servicios de telecomunicaciones. Además, la deriva conceptual crea obstáculos sustanciales para mantener una precisión satisfactoria en las tareas de previsión celular continua. Para resolver estos problemas, proponemos un método de predicción del tráfico celular en línea basado en la complementariedad de características multigrano espacio-temporales (MGSTC). El método propuesto está concebido para lograr predicciones de alta precisión en escenarios prácticos de predicción continua. Concretamente, MGSTC segmenta los datos históricos en trozos y emplea la atención temporal de grano grueso para ofrecer una referencia de tendencia para el horizonte de predicción. Posteriormente, se utiliza la atención espacial de grano fino para captar correlaciones detalladas entre los elementos de la red, lo que permite el refinamiento localizado de la tendencia establecida. La complementariedad de estas características espaciotemporales multigrano facilita la transmisión eficaz de información valiosa. Para dar cabida a las necesidades de previsión continua, aplicamos una estrategia de aprendizaje en línea que puede detectar la deriva del concepto en tiempo real y cambiar rápidamente a la etapa de actualización de parámetros adecuada. Los experimentos llevados a cabo en cuatro conjuntos de datos reales demuestran que MGSTC supera sistemáticamente a once líneas de base del estado del arte.",
    "source": "arXiv"
  },
  {
    "title": "MinionsLLM: a Task-adaptive Framework For The Training and Control of Multi-Agent Systems Through Natural Language",
    "title_es": "MinionsLLM: un marco adaptable a tareas para el entrenamiento y control de sistemas multiagente mediante lenguaje natural",
    "url": "https://arxiv.org/abs/2508.08283",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08283v1 Tipo de anuncio: nuevo\nResumen: Este artículo presenta MinionsLLM, un novedoso marco que integra Modelos de Lenguaje Amplio (LLMs) con Árboles de Comportamiento (BTs) y Gramáticas Formales para permitir el control en lenguaje natural de sistemas multiagente dentro de entornos arbitrarios definidos por el usuario. MinionsLLM proporciona interfaces estandarizadas para definir entornos, agentes y primitivas de comportamiento, e introduce dos métodos de generación de conjuntos de datos sintéticos (Método A y Método B) para afinar los LLM con el fin de mejorar la validez sintáctica y la relevancia semántica de la tarea. Validamos nuestro enfoque utilizando la familia de modelos Gemma 3 de Google en tres escalas de parámetros (1B, 4B y 12B) y demostramos mejoras sustanciales: El método B aumenta la validez sintáctica hasta el 92,6% y consigue una mejora media del rendimiento en la tarea del 33% con respecto a la línea de base. En particular, nuestros experimentos muestran que los modelos más pequeños son los que más se benefician del ajuste fino, lo que sugiere direcciones prometedoras para desplegar LLM compactos y alojados localmente en escenarios de control multiagente con recursos limitados. El marco y todos los recursos son de código abierto para facilitar la reproducibilidad y futuras investigaciones.",
    "source": "arXiv"
  },
  {
    "title": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs",
    "title_es": "La ilusión del progreso: Reevaluación de la detección de alucinaciones en los LLM",
    "url": "https://arxiv.org/abs/2508.08285",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08285v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos lingüísticos (LLMs) han revolucionado el procesamiento del lenguaje natural, sin embargo, su tendencia a alucinar plantea serios retos para un despliegue fiable. A pesar de los numerosos métodos de detección de alucinaciones, sus evaluaciones a menudo se basan en ROUGE, una métrica basada en el solapamiento léxico que no coincide con los juicios humanos. A través de exhaustivos estudios en humanos, demostramos que, aunque ROUGE presenta una alta capacidad de recuperación, su precisión extremadamente baja conduce a estimaciones de rendimiento engañosas. De hecho, varios métodos de detección establecidos muestran caídas de rendimiento de hasta el 45,9% cuando se evalúan utilizando métricas alineadas con humanos como LLM-as-Judge. Además, nuestro análisis revela que una simple heurística basada en la longitud de la respuesta puede rivalizar con técnicas de detección complejas, lo que pone de manifiesto un fallo fundamental en las prácticas de evaluación actuales. Sostenemos que la adopción de marcos de evaluación semánticamente conscientes y robustos es esencial para calibrar con precisión el verdadero rendimiento de los métodos de detección de alucinaciones, garantizando en última instancia la fiabilidad de los resultados de LLM.",
    "source": "arXiv"
  },
  {
    "title": "Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions",
    "title_es": "¿Sagrado o sintético? Evaluación de la fiabilidad y la abstención del LLM en cuestiones religiosas",
    "url": "https://arxiv.org/abs/2508.08287",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08287v1 Tipo de anuncio: nuevo\nResumen: A pesar del creciente uso de Modelos de Lenguaje Amplio (LLMs) para responder preguntas en una variedad de dominios, su fiabilidad y precisión siguen sin ser examinadas para una plétora de dominios, incluyendo los dominios religiosos. En este artículo, presentamos un novedoso FiqhQA de referencia centrado en las sentencias islámicas generadas por LLM categorizadas explícitamente por las cuatro principales escuelas de pensamiento suníes, tanto en árabe como en inglés. A diferencia de trabajos anteriores, que o bien pasan por alto las distinciones entre escuelas religiosas de pensamiento o bien no evalúan el comportamiento de abstención, nosotros evaluamos los LLM no sólo por su precisión, sino también por su capacidad para reconocer cuándo no responder. Nuestros experimentos sobre el tiro por cero y la abstención revelan variaciones significativas entre los LLM, los idiomas y las escuelas de pensamiento jurídico. Mientras que GPT-4o supera a todos los demás modelos en precisión, Gemini y Fanar demuestran un comportamiento de abstención superior, crítico para minimizar las respuestas incorrectas seguras. En particular, todos los modelos muestran un descenso del rendimiento en árabe, lo que pone de manifiesto las limitaciones del razonamiento religioso para idiomas distintos del inglés. Hasta donde sabemos, éste es el primer estudio que compara la eficacia de los LLM para la generación de normas específicas de la escuela de pensamiento islámico y que evalúa la abstención en las consultas de jurisprudencia islámica. Nuestros hallazgos subrayan la necesidad de una evaluación específica de la tarea y de un despliegue cauteloso de los LLM en aplicaciones religiosas.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Transformers through the Lens of Pavlovian Conditioning",
    "title_es": "Los transformadores a través del condicionamiento pavloviano",
    "url": "https://arxiv.org/abs/2508.08289",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08289v1 Tipo de anuncio: nuevo\nResumen: Las arquitecturas de transformadores han revolucionado la inteligencia artificial (IA) gracias a sus mecanismos de atención, pero los principios computacionales que subyacen a su éxito siguen siendo opacos. Presentamos un novedoso marco teórico que reinterpreta el núcleo computacional de la atención como condicionamiento pavloviano. Nuestro modelo encuentra un análogo matemático directo en la atención lineal, lo que simplifica el análisis del proceso asociativo subyacente. Demostramos que las consultas, claves y valores de la atención pueden asignarse a los tres elementos del condicionamiento clásico: estímulos de prueba que sondean las asociaciones, estímulos condicionales (EC) que sirven como claves de recuperación y estímulos incondicionales (EE) que contienen información de respuesta. A través de esta lente, sugerimos que cada operación de atención construye una memoria asociativa transitoria a través de una regla Hebbiana, donde los pares CS-US forman asociaciones dinámicas que los estímulos de prueba pueden recuperar más tarde. Nuestro marco produce varios conocimientos teóricos basados en este modelo linealizado: (1) un teorema de capacidad que muestra que las cabezas de atención pueden almacenar O($\\sqrt{d_k}$) asociaciones antes de que la interferencia degrade la recuperación; (2) un análisis de propagación de errores que revela compensaciones arquitectónicas fundamentales para equilibrar la profundidad del modelo, la anchura y la redundancia de la cabeza para mantener la fiabilidad; y (3) una comprensión de cómo las reglas de aprendizaje biológicamente plausibles podrían mejorar las arquitecturas del transformador. Al establecer esta profunda conexión, sugerimos que el éxito de la IA moderna puede no derivarse únicamente de la novedad arquitectónica, sino de la aplicación de principios computacionales que la biología ha optimizado a lo largo de millones de años de evolución.",
    "source": "arXiv"
  },
  {
    "title": "Probabilistic Emissivity Retrieval from Hyperspectral Data via Physics-Guided Variational Inference",
    "title_es": "Recuperación probabilística de la emisividad a partir de datos hiperespectrales mediante inferencia variacional guiada por la física",
    "url": "https://arxiv.org/abs/2508.08291",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08291v1 Tipo de anuncio: nuevo\nResumen: Investigaciones recientes han demostrado que las redes neuronales son una poderosa herramienta para realizar la identificación de objetivos de imágenes hiperespectrales (HSI). Sin embargo, muchos marcos de aprendizaje profundo ofrecen una sola predicción de clase de material y operan sobre una base por píxel; tales enfoques están limitados en su interpretabilidad y restringidos a la predicción de materiales que son accesibles en las bibliotecas de entrenamiento disponibles. En este trabajo, presentamos un enfoque de modelado inverso en forma de modelo generativo condicionado por la física.Un modelo probabilístico de variables latentes aprende la distribución subyacente de las mediciones de radiancia HSI y produce la distribución condicional del espectro de emisividad. Además, se utilizan estimaciones de la atmósfera y el fondo de la escena HSI como mecanismo condicionante físicamente relevante para contextualizar una medición de radiancia determinada durante los procesos de codificación y descodificación. Además, empleamos un esquema de aumento en el bucle y criterios de pérdida basados en la física para evitar el sesgo hacia un conjunto predefinido de material de entrenamiento y animar al modelo a aprender mapeados inversos físicamente coherentes. El muestreo Monte-Carlo de la posterior condicionada del modelo proporciona una distribución de emisividad buscada y permite una cuantificación interpretable de la incertidumbre. Además, se presenta un esquema de correspondencia de materiales basado en la distribución para obtener un conjunto de correspondencias de materiales probables para una distribución de emisividad inferida. Por lo tanto, presentamos una estrategia para incorporar información contextual sobre una escena HSI determinada, capturar la posible variación de los espectros de los materiales subyacentes y proporcionar medidas de probabilidad interpretables de un material candidato para una medición de radiancia obtenida por teledetección.",
    "source": "arXiv"
  },
  {
    "title": "Putnam-AXIOM: A Functional and Static Benchmark",
    "title_es": "Putnam-AXIOM: una referencia funcional y estática",
    "url": "https://arxiv.org/abs/2508.08292",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08292v1 Tipo de anuncio: nuevo\nResumen: Las actuales pruebas de razonamiento matemático para grandes modelos de lenguaje (LLMs) se están acercando a la saturación, con algunos alcanzando más del 90% de precisión, y están cada vez más comprometidas por la contaminación del conjunto de entrenamiento. Presentamos Putnam-AXIOM, una referencia de 522 problemas de competición de nivel universitario extraídos de la prestigiosa competición matemática William Lowell Putnam, y Putnam-AXIOM Variation, un conjunto complementario inédito de 100 variantes funcionales generadas mediante la perturbación programática de variables y constantes. El protocolo de variación produce un flujo ilimitado de instancias igualmente difíciles y nunca vistas, lo que da lugar a un banco de pruebas resistente a la contaminación. En el conjunto original, el modelo o1-preview de OpenAI, el mejor evaluado, obtiene una puntuación del 41,9%, pero su precisión cae un 19,6% (46,8% de descenso relativo) en las variaciones emparejadas. Los dieciocho modelos restantes muestran la misma tendencia a la baja, diez de ellos con intervalos de confianza del 95% que no se solapan. Estas lagunas sugieren memorización y ponen de relieve la necesidad de referencias dinámicas. Complementamos la precisión \"en caja\" con la Precisión Forzada por el Profesor (TFA), una métrica ligera que puntúa directamente las trazas de razonamiento y automatiza las evaluaciones de pruebas en lenguaje natural. Por tanto, Putnam-AXIOM proporciona un marco de evaluación riguroso y resistente a la contaminación para evaluar el razonamiento matemático avanzado de los LLM. Los datos y el código de evaluación están a disposición del público en https://github.com/brando90/putnam-axiom.",
    "source": "arXiv"
  },
  {
    "title": "Topos Theory for Generative AI and LLMs",
    "title_es": "Teoría de Topos para IA Generativa y LLMs",
    "url": "https://arxiv.org/abs/2508.08293",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08293v1 Anunciar Tipo: nuevo\nResumen: Proponemos el diseño de nuevas arquitecturas categóricas generativas de IA (GAIAs) utilizando la teoría de topos, un tipo de categoría que es ``set-like'': un topos tiene todos los (co)límites, es cartesiano cerrado, y tiene un clasificador de subobjetos. Resultados teóricos anteriores sobre el modelo Transformer han demostrado que es un aproximador universal de funciones secuencia a secuencia, y denso en el espacio de todas las funciones continuas con soporte compacto en el espacio euclidiano de incrustaciones de fichas. Partiendo de este resultado teórico, exploramos arquitecturas novedosas para LLM que explotan la propiedad de que la categoría de LLM, vista como funciones, forma un topos. Los estudios anteriores sobre grandes modelos lingüísticos (LLM) se han centrado en arquitecturas lineales encadenadas o en mezclas de expertos. En este artículo, utilizamos construcciones universales de la teoría de categorías para construir nuevas arquitecturas LLM basadas en nuevos tipos de estructuras composicionales. En concreto, estas nuevas estructuras composicionales se derivan de propiedades universales de las categorías LLM, e incluyen pullback, pushout, (co)ecualizadores, objetos exponenciales y clasificadores de subobjetos. Validamos teóricamente estas nuevas estructuras composicionales demostrando que la categoría de los LLM es (co)completa, lo que significa que todos los diagramas tienen soluciones en forma de (co)límites. A partir de este resultado de completitud, demostramos que la categoría de LLMs forma un topos, una categoría ``set-like'', lo que requiere demostrar la existencia de objetos exponenciales así como de clasificadores de subobjetos. Utilizamos una caracterización functorial de la retropropagación para definir una posible implementación de una arquitectura de topos LLM.",
    "source": "arXiv"
  },
  {
    "title": "Topos Causal Models",
    "title_es": "Modelos causales Topos",
    "url": "https://arxiv.org/abs/2508.08295",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08295v1 Anunciar Tipo: nuevo\nResumen: Proponemos modelos topos causales (TCMs), una nueva clase de modelos causales que explotan las propiedades clave de una categoría topos: son (co)completos, lo que significa que todos los (co)límites existen, admiten un clasificador de subobjetos, y permiten objetos exponenciales. El objetivo principal de este trabajo es demostrar que estas propiedades son fundamentales para muchas aplicaciones en la inferencia causal. Por ejemplo, los clasificadores de subobjetos permiten una formulación categórica de la intervención causal, que crea submodelos. Los límites y colímites permiten ``resolver'' diagramas causales de complejidad arbitraria, utilizando una interpretación novedosa de la aproximación causal. Los objetos exponenciales permiten razonar sobre clases de equivalencia de operaciones en modelos causales, como la inversión de aristas cubiertas y la homotopía causal. De forma análoga a los modelos causales estructurales (MCE), los MTC se definen mediante una colección de funciones, cada una de las cuales define un mecanismo causal \"local autónomo\" que se ensambla para inducir una única función global de las variables exógenas a las endógenas. Dado que la categoría de los MTC es (co)completa, lo que demostramos en este artículo, todo diagrama causal tiene una ``solución\" en forma de (co)límite: esto implica que cualquier modelo causal arbitrario puede ser ``aproximado\" por alguna función global con respecto a los morfismos que entran o salen del diagrama. Las transformaciones naturales son cruciales para medir la calidad de la aproximación. Además, mostramos que las intervenciones causales se modelan mediante clasificadores de subobjetos: cualquier submodelo se define mediante una flecha mónica hacia su modelo padre. Los objetos exponenciales permiten razonar sobre clases enteras de equivalencias e intervenciones causales. Por último, como los MTC forman un topos, admiten una lógica interna definida como un lenguaje Mitchell-Benabou con una semántica Kripke-Joyal asociada. Mostramos cómo razonar sobre modelos causales en MTC utilizando esta lógica interna.",
    "source": "arXiv"
  },
  {
    "title": "An Efficient Application of Goal Programming to Tackle Multiobjective Problems with Recurring Fitness Landscapes",
    "title_es": "Una aplicación eficiente de la programación de metas para abordar problemas multiobjetivo con paisajes de aptitud recurrentes",
    "url": "https://arxiv.org/abs/2508.08297",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08297v1 Tipo de anuncio: nuevo\nResumen: Muchas aplicaciones del mundo real requieren que los responsables de la toma de decisiones evalúen la calidad de las soluciones teniendo en cuenta múltiples objetivos en conflicto. La obtención de buenos conjuntos de aproximación para problemas multiobjetivo altamente restringidos suele ser una tarea difícil incluso para los algoritmos multiobjetivo modernos. En algunos casos, múltiples instancias del escenario del problema presentan similitudes en sus paisajes de fitness. Es decir, existen características recurrentes en los paisajes de fitness cuando se buscan soluciones a diferentes instancias del problema. Proponemos una metodología para explotar esta característica resolviendo una instancia de un escenario problemático dado utilizando algoritmos multiobjetivo computacionalmente costosos para obtener un buen conjunto de aproximaciones y, a continuación, utilizando Programación por Metas con algoritmos eficientes de objetivo único para resolver otras instancias del mismo escenario problemático. Utilizamos tres funciones objetivo basadas en metas y mostramos que en instancias de referencia del problema multiobjetivo de rutas de vehículos con ventanas de tiempo, la metodología es capaz de producir buenos resultados en tiempos de computación cortos. La metodología permite combinar la eficacia de los algoritmos multiobjetivo más avanzados con la eficiencia de la programación por objetivos para encontrar buenas soluciones de compromiso en escenarios problemáticos donde las instancias tienen paisajes de fitness similares.",
    "source": "arXiv"
  },
  {
    "title": "Channel-Wise MLPs Improve the Generalization of Recurrent Convolutional Networks",
    "title_es": "Los MLP canalizados mejoran la generalización de las redes convolucionales recurrentes",
    "url": "https://arxiv.org/abs/2508.08298",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08298v1 Tipo de anuncio: nuevo\nResumen: Investigamos el impacto de la mezcla de canales mediante perceptrones multicapa (MLP) en la capacidad de generalización de las redes convolucionales recurrentes. En concreto, comparamos dos arquitecturas: DARC (Depth Aware Recurrent Convolution), que emplea una estructura convolucional recurrente simple, y DAMP (Depth Aware Multi-layer Perceptron), que amplía DARC con un MLP para la mezcla de canales. Utilizando el modelo de referencia Re-ARC, descubrimos que DAMP supera significativamente a DARC tanto en la generalización dentro de la distribución como fuera de ella bajo criterios de clasificación de coincidencia exacta. Estos resultados sugieren que la mezcla explícita de canales a través de MLP permite a las redes convolucionales recurrentes aprender patrones computacionales más robustos y generalizables. Nuestros hallazgos tienen implicaciones para la síntesis de programas neuronales y destacan el potencial de los MLP como arquitectura objetivo para los enfoques de hiperredes.",
    "source": "arXiv"
  },
  {
    "title": "LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models",
    "title_es": "LLM-BI: Hacia una inferencia bayesiana totalmente automatizada con grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.08300",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08300v1 Tipo de anuncio: nuevo\nResumen: Un obstáculo importante para la adopción generalizada de la inferencia bayesiana es la especificación de las distribuciones a priori y las verosimilitudes, que a menudo requiere conocimientos estadísticos especializados. Este trabajo investiga la viabilidad de utilizar un Modelo de Lenguaje Amplio (LLM) para automatizar este proceso. Presentamos el LLM-BI (Large Language Model-driven Bayesian Inference), un canal conceptual para automatizar los flujos de trabajo bayesianos. Como prueba de concepto, presentamos dos experimentos centrados en la regresión lineal bayesiana. En el Experimento I, demostramos que un LLM puede obtener con éxito distribuciones a priori a partir del lenguaje natural. En el Experimento II, mostramos que un LLM puede especificar la estructura completa del modelo, incluyendo tanto las priorizaciones como la verosimilitud, a partir de una única descripción del problema de alto nivel. Nuestros resultados validan el potencial de los LLMs para automatizar pasos clave en el modelado bayesiano, permitiendo la posibilidad de una tubería de inferencia automatizada para la programación probabilística.",
    "source": "arXiv"
  },
  {
    "title": "Evaluation of an Autonomous Surface Robot Equipped with a Transformable Mobility Mechanism for Efficient Mobility Control",
    "title_es": "Evaluación de un robot autónomo de superficie equipado con un mecanismo de movilidad transformable para un control eficiente de la movilidad",
    "url": "https://arxiv.org/abs/2508.08303",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08303v1 Tipo de anuncio: nuevo\nResumen: La movilidad y el consumo de energía eficientes son críticos para los robots autónomos de superficie acuática en la monitorización medioambiental del agua a largo plazo. Este estudio desarrolla y evalúa un mecanismo de movilidad transformable para un robot de superficie acuática con dos modos de control: mantenimiento de estación y desplazamiento para mejorar la eficiencia energética y la maniobrabilidad. Los experimentos de campo muestran que, en una tarea de ida y vuelta entre dos puntos, el modo de desplazamiento reduce el consumo de energía en un 10\\% y disminuye el tiempo total necesario para el desplazamiento en un 5\\% en comparación con el modo de mantenimiento de estación. Estos resultados confirman la eficacia del mecanismo de movilidad transformable para mejorar la eficiencia operativa en las patrullas sobre la superficie del agua.",
    "source": "arXiv"
  },
  {
    "title": "Comparative study of machine learning and statistical methods for automatic identification and quantification in {\\gamma}-ray spectrometry",
    "title_es": "Estudio comparativo de métodos de aprendizaje automático y estadísticos para la identificación y cuantificación automáticas en espectrometría de rayos {\\gamma}.",
    "url": "https://arxiv.org/abs/2508.08306",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08306v1 Tipo de anuncio: nuevo\nResumen: Durante la última década, se han propuesto un gran número de métodos numéricos diferentes para abordar la identificación y cuantificación automática en espectrometría de rayos {\\gamma}. Sin embargo, la falta de puntos de referencia comunes, incluyendo conjuntos de datos, código y métricas de comparación, dificulta su evaluación y comparación. En este contexto, proponemos un punto de referencia de código abierto que incluye conjuntos de datos simulados de varias configuraciones de espectrometría de rayos {\\gamma}, códigos de diferentes enfoques de análisis y métricas de evaluación. Esto nos permite comparar el aprendizaje automático extremo a extremo de última generación con un enfoque estadístico de desmezcla utilizando el espectro completo. Se han investigado tres escenarios: (1) se supone que las firmas espectrales son conocidas; (2) las firmas espectrales se deforman debido a fenómenos físicos como la dispersión Compton y la atenuación; y (3) las firmas espectrales se desplazan (por ejemplo, debido a la variación de temperatura). Para cada escenario con múltiples radionucleidos presentes en el espectro se utiliza un gran conjunto de datos de 200.000 espectros simulados que contienen nueve radionucleidos con un fondo natural experimental. En cuanto al rendimiento de la identificación, el enfoque estadístico supera sistemáticamente a los enfoques de aprendizaje automático en los tres escenarios para todas las métricas de comparación. Sin embargo, el rendimiento del enfoque estadístico puede verse afectado significativamente cuando las firmas espectrales no se modelan correctamente. En consecuencia, el enfoque estadístico de espectro completo es más eficaz con firmas espectrales conocidas o bien modeladas, mientras que el aprendizaje automático de extremo a extremo es una buena alternativa cuando las condiciones de medición son inciertas para la identificación de radionucleidos. En cuanto a la tarea de cuantificación, el enfoque estadístico proporciona estimaciones precisas del recuento de radionucleidos, mientras que los métodos de aprendizaje automático ofrecen resultados menos satisfactorios.",
    "source": "arXiv"
  },
  {
    "title": "First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models",
    "title_es": "Primero preguntar y luego responder: Diseño de un marco para el diálogo de IA basado en preguntas complementarias con grandes modelos lingüísticos",
    "url": "https://arxiv.org/abs/2508.08308",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08308v1 Tipo de anuncio: nuevo\nResumen: Los grandes modelos lingüísticos (LLM) a menudo tienen dificultades para ofrecer respuestas precisas y procesables cuando la información proporcionada por el usuario es incompleta o está mal especificada. Proponemos un nuevo paradigma de interacción, First Ask Then Answer (FATA), en el que, mediante palabras de aviso, se guía a los LLM para que generen proactivamente preguntas complementarias multidimensionales para los usuarios antes de generar la respuesta. Posteriormente, al integrar la información complementaria proporcionada por el usuario con la consulta original mediante sofisticadas técnicas de incitación, conseguimos mejorar sustancialmente la calidad y la pertinencia de las respuestas. A diferencia de los enfoques de clarificación existentes -como el marco CLAM orientado a la ambigüedad y el método de autointerrogatorio Self-Ask-, FATA hace hincapié en la exhaustividad (más allá de la mera desambiguación) y en la participación del usuario (invitando a la aportación humana en lugar de confiar únicamente en el razonamiento interno del modelo). También adopta una estrategia de un solo turno: todas las preguntas aclaratorias se producen a la vez, lo que reduce la duración del diálogo y mejora la eficacia. Conceptualmente, FATA utiliza la capacidad de razonamiento de los LLM para articular la expresión del usuario, lo que permite a los usuarios no expertos formular consultas más completas y contextualmente relevantes. Para evaluar FATA, construimos un modelo de referencia multidominio y lo comparamos con dos controles: una consulta básica (B-Prompt) y una consulta experta mejorada por el contexto (C-Prompt). Los resultados experimentales muestran que FATA supera a B-Prompt en aproximadamente un 40% en métricas agregadas y presenta un coeficiente de variación un 8% inferior a C-Prompt, lo que indica una estabilidad superior.",
    "source": "arXiv"
  },
  {
    "title": "ICT Within Limits Is Bound To Be Old-Fashioned By Design",
    "title_es": "Las TIC dentro de unos límites son anticuadas por diseño",
    "url": "https://arxiv.org/abs/2508.08311",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08311v1 Tipo de anuncio: nuevo\nResumen: Cruzar múltiples fronteras planetarias nos sitúa en una zona de incertidumbre caracterizada por considerables fluctuaciones en los fenómenos climáticos. La situación se ve agravada por el incesante uso de recursos y energía necesarios para desarrollar infraestructuras digitales que se han vuelto omnipresentes y ubicuas. Estamos atados a estas infraestructuras, tecnologías muertas y bienes comunes negativos, tanto como ellas nos atan a nosotros. Aunque su crecimiento amenaza la necesaria reducción de nuestro impacto, tenemos la responsabilidad de mantenerlas hasta que podamos prescindir de ellas.\n  En el ámbito universitario, así como en cualquier organización pública, las minas urbanas per se, proponemos una arquitectura informática basada en el uso exclusivo de residuos poco fiables de aparatos eléctricos y electrónicos (RAEE) como alternativa frugal a la incesante sustitución de dispositivos. Alimentada por energía renovable, autónoma, robusta, adaptable y construida sobre software de código abierto de eficacia probada, imaginamos esta solución para una situación en la que el uso está abocado a declinar con el tiempo, para cerrar este dañino capítulo tecnológico. La tecnología digital, ídolo de los tiempos modernos, va a encontrar su ocaso si no queremos alterar irrevocablemente la zona crítica.",
    "source": "arXiv"
  },
  {
    "title": "Resisting AI Solutionism through Workplace Collective Action",
    "title_es": "Resistencia al solucionismo de la IA mediante la acción colectiva en el lugar de trabajo",
    "url": "https://arxiv.org/abs/2508.08313",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08313v1 Tipo de anuncio: nuevo\nResumen: Frente a la creciente austeridad y las amenazas de sustitución laboral por IA en la Universidad de Michigan, un grupo de trabajadores y estudiantes se han unido en torno al proyecto de \"resistencia a la IA\" desde el otoño de 2024. Formando una coalición interdepartamental que incluye bibliotecarios, profesores, personal, trabajadores graduados y estudiantes universitarios, hemos organizado un taller público cuestionando la inevitabilidad tecno-determinista del uso de la IA en la Universidad y estamos trabajando con otras organizaciones del campus para mantener un espacio de organización permanente. Esta presentación del taller incorpora nuestras reflexiones hasta el momento sobre las estrategias que hemos empleado, los retos de la resistencia colectiva y nuestro papel como trabajadores en la resistencia a la IA dentro de la Universidad. Nuestro objetivo con este trabajo es proporcionar una inspiración concreta para tecnólogos, estudiantes y personal que quieran resistirse al tecnosolucionismo de la IA en sus propias universidades.",
    "source": "arXiv"
  },
  {
    "title": "Assessing the Quality of AI-Generated Exams: A Large-Scale Field Study",
    "title_es": "Evaluación de la calidad de los exámenes generados por IA: Un estudio de campo a gran escala",
    "url": "https://arxiv.org/abs/2508.08314",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08314v1 Tipo de anuncio: nuevo\nResumen: Aunque los grandes modelos lingüísticos (LLM) desafían los métodos convencionales de enseñanza y aprendizaje, presentan una oportunidad apasionante para mejorar la eficiencia y ampliar la enseñanza de alta calidad. Una aplicación prometedora es la generación de exámenes personalizados, adaptados al contenido específico del curso. En los últimos tiempos ha habido un gran interés por la generación automática de preguntas mediante inteligencia artificial, pero comparativamente se ha trabajado poco en la evaluación de la calidad psicométrica de estos ítems en entornos educativos reales. Llenar este vacío es un paso importante para comprender el papel de la IA generativa en el diseño eficaz de exámenes. En este estudio, introducimos y evaluamos una estrategia de refinamiento iterativo para la generación de preguntas, produciendo, evaluando y mejorando repetidamente las preguntas a través de ciclos de crítica y revisión generados por LLM. Evaluamos la calidad de estas preguntas generadas por IA en un estudio de campo a gran escala en el que participaron 91 clases (de informática, matemáticas, química, etc.) de docenas de universidades de Estados Unidos, con casi 1.700 estudiantes. Nuestro análisis, basado en la teoría de la respuesta al ítem (TRI), sugiere que, para los estudiantes de nuestra muestra, las preguntas generadas por IA tuvieron un rendimiento comparable al de las preguntas creadas por expertos y diseñadas para exámenes estandarizados. Nuestros resultados ilustran el poder de la IA para facilitar la disponibilidad de evaluaciones de alta calidad, lo que beneficia tanto a profesores como a alumnos.",
    "source": "arXiv"
  },
  {
    "title": "EU Digital Regulation and Guatemala: AI, 5G, and Cybersecurity",
    "title_es": "EU Digital Regulation and Guatemala: AI, 5G, and Cybersecurity",
    "url": "https://arxiv.org/abs/2508.08315",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08315v1 Announce Type: new \nAbstract: The paper examines how EU rules in AI, 5G, and cybersecurity operate as transnational governance and shape policy in Guatemala. It outlines the AI Act's risk approach, the 5G Action Plan and Security Toolbox, and the cybersecurity regime built on ENISA, NIS2, the Cybersecurity Act, and the Cyber Resilience Act. It traces extraterritorial channels such as the Brussels effect, private standards, supply chain clauses, and data transfer controls. Guatemala specific impacts include SME compliance costs, procurement limits, environmental trade-offs in rollout, rights risks, and capacity gaps. The paper maps current national measures and proposes five guardrails: digital constitutionalism, green IT duties, third country impact assessment, standards co-design, and recognition of regulatory diversity.",
    "source": "arXiv"
  },
  {
    "title": "Evaluation of State-of-the-Art Deep Learning Techniques for Plant Disease and Pest Detection",
    "title_es": "Evaluation of State-of-the-Art Deep Learning Techniques for Plant Disease and Pest Detection",
    "url": "https://arxiv.org/abs/2508.08317",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08317v1 Announce Type: new \nAbstract: Addressing plant diseases and pests is critical for enhancing crop production and preventing economic losses. Recent advances in artificial intelligence (AI), machine learning (ML), and deep learning (DL) have significantly improved the precision and efficiency of detection methods, surpassing the limitations of manual identification. This study reviews modern computer-based techniques for detecting plant diseases and pests from images, including recent AI developments. The methodologies are organized into five categories: hyperspectral imaging, non-visualization techniques, visualization approaches, modified deep learning architectures, and transformer models. This structured taxonomy provides researchers with detailed, actionable insights for selecting advanced state-of-the-art detection methods. A comprehensive survey of recent work and comparative studies demonstrates the consistent superiority of modern AI-based approaches, which often outperform older image analysis methods in speed and accuracy. In particular, vision transformers such as the Hierarchical Vision Transformer (HvT) have shown accuracy exceeding 99.3% in plant disease detection, outperforming architectures like MobileNetV3. The study concludes by discussing system design challenges, proposing solutions, and outlining promising directions for future research.",
    "source": "arXiv"
  },
  {
    "title": "Between Fear and Desire, the Monster Artificial Intelligence (AI): Analysis through the Lenses of Monster Theory",
    "title_es": "Between Fear and Desire, the Monster Artificial Intelligence (AI): Analysis through the Lenses of Monster Theory",
    "url": "https://arxiv.org/abs/2508.08318",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08318v1 Announce Type: new \nAbstract: With the increasing adoption of Artificial Intelligence (AI) in all fields and daily activities, a heated debate is found about the advantages and challenges of AI and the need for navigating the concerns associated with AI to make the best of it. To contribute to this literature and the ongoing debate related to it, this study draws on the Monster theory to explain the conflicting representation of AI. It suggests that studying monsters in popular culture can provide an in-depth understanding of AI and its monstrous effects. Specifically, this study aims to discuss AI perception and development through the seven theses of Monster theory. The obtained results revealed that, just like monsters, AI is complex in nature, and it should not be studied as a separate entity but rather within a given society or culture. Similarly, readers may perceive and interpret AI differently, just as readers may interpret monsters differently. The relationship between AI and monsters, as depicted in this study, does not seem to be as odd as it might be at first.",
    "source": "arXiv"
  },
  {
    "title": "Representative Volume Element: Existence and Extent in Cracked Heterogeneous Medium",
    "title_es": "Representative Volume Element: Existence and Extent in Cracked Heterogeneous Medium",
    "url": "https://arxiv.org/abs/2508.08320",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08320v1 Announce Type: new \nAbstract: Acknowledging the ever-increasing demand for composites in the engineering industry, this paper focuses on the failure of composites at the microscale and augmenting the use of multiscale modelling techniques to make them better for various applications. This work aims to increase the representativeness of the volume element by attenuating the mesh and size sensitivities in representative volume element (RVE) modelling. A technique to alleviate mesh sensitivity in RVE modelling is proposed, which equalises the fracture energy observed from computational analysis with the real phenomenon, thereby keeping the response independent of the bandwidth of strain localisation. Based on the hypothesis that ensuring periodicity of strain, in addition to displacement periodicity across the domain boundary and supplementing the capability of periodic boundary conditions (PBCs) to attenuate the size dependency in RVE modelling, a set of modified PBCs (MPBCs) are formulated. One thousand two hundred RVE samples falling into combinations of five fibre volume fractions and four RVE sizes are analysed under transverse loading, and the ability of MPBCs to attenuate the effect of RVE size on the precision of material response, particularly in the inelastic regime, is verified. This work also focuses on various factors affecting damage initiation in 2D composite RVEs. The arrangement of a pair of fibres with their members placed close to each other, such that the angle between the direction of loading and an imaginary line drawn between their centres is less, is observed to make the region between them more favourable to damage.",
    "source": "arXiv"
  },
  {
    "title": "Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code",
    "title_es": "Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code",
    "url": "https://arxiv.org/abs/2508.08322",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08322v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown promise in automating code generation and software engineering tasks, yet they often struggle with complex, multi-file projects due to context limitations and knowledge gaps. We propose a novel context engineering workflow that combines multiple AI components: an Intent Translator (GPT-5) for clarifying user requirements, an Elicit-powered semantic literature retrieval for injecting domain knowledge, NotebookLM-based document synthesis for contextual understanding, and a Claude Code multi-agent system for code generation and validation. Our integrated approach leverages intent clarification, retrieval-augmented generation, and specialized sub-agents orchestrated via Claude's agent framework. We demonstrate that this method significantly improves the accuracy and reliability of code assistants in real-world repositories, yielding higher single-shot success rates and better adherence to project context than baseline single-agent approaches. Qualitative results on a large Next.js codebase show the multi-agent system effectively plans, edits, and tests complex features with minimal human intervention. We compare our system with recent frameworks like CodePlan, MASAI, and HyperAgent, highlighting how targeted context injection and agent role decomposition lead to state-of-the-art performance. Finally, we discuss the implications for deploying LLM-based coding assistants in production, along with lessons learned on context management and future research directions.",
    "source": "arXiv"
  },
  {
    "title": "Weather-Driven Agricultural Decision-Making Using Digital Twins Under Imperfect Conditions",
    "title_es": "Weather-Driven Agricultural Decision-Making Using Digital Twins Under Imperfect Conditions",
    "url": "https://arxiv.org/abs/2508.08326",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08326v1 Announce Type: new \nAbstract: By offering a dynamic, real-time virtual representation of physical systems, digital twin technology can enhance data-driven decision-making in digital agriculture. Our research shows how digital twins are useful for detecting inconsistencies in agricultural weather data measurements, which are key attributes for various agricultural decision-making and automation tasks. We develop a modular framework named Cerealia that allows end-users to check for data inconsistencies when perfect weather feeds are unavailable. Cerealia uses neural network models to check anomalies and aids end-users in informed decision-making. We develop a prototype of Cerealia using the NVIDIA Jetson Orin platform and test it with an operational weather network established in a commercial orchard as well as publicly available weather datasets.",
    "source": "arXiv"
  },
  {
    "title": "Synthesize, Retrieve, and Propagate: A Unified Predictive Modeling Framework for Relational Databases",
    "title_es": "Synthesize, Retrieve, and Propagate: A Unified Predictive Modeling Framework for Relational Databases",
    "url": "https://arxiv.org/abs/2508.08327",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08327v1 Announce Type: new \nAbstract: Relational databases (RDBs) have become the industry standard for storing massive and heterogeneous data. However, despite the widespread use of RDBs across various fields, the inherent structure of relational databases hinders their ability to benefit from flourishing deep learning methods. Previous research has primarily focused on exploiting the unary dependency among multiple tables in a relational database using the primary key - foreign key relationships, either joining multiple tables into a single table or constructing a graph among them, which leaves the implicit composite relations among different tables and a substantial potential of improvement for predictive modeling unexplored. In this paper, we propose SRP, a unified predictive modeling framework that synthesizes features using the unary dependency, retrieves related information to capture the composite dependency, and propagates messages across a constructed graph to learn adjacent patterns for prediction on relation databases. By introducing a new retrieval mechanism into RDB, SRP is designed to fully capture both the unary and the composite dependencies within a relational database, thereby enhancing the receptive field of tabular data prediction. In addition, we conduct a comprehensive analysis on the components of SRP, offering a nuanced understanding of model behaviors and practical guidelines for future applications. Extensive experiments on five real-world datasets demonstrate the effectiveness of SRP and its potential applicability in industrial scenarios. The code is released at https://github.com/NingLi670/SRP.",
    "source": "arXiv"
  },
  {
    "title": "Whole-Body Coordination for Dynamic Object Grasping with Legged Manipulators",
    "title_es": "Whole-Body Coordination for Dynamic Object Grasping with Legged Manipulators",
    "url": "https://arxiv.org/abs/2508.08328",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08328v1 Announce Type: new \nAbstract: Quadrupedal robots with manipulators offer strong mobility and adaptability for grasping in unstructured, dynamic environments through coordinated whole-body control. However, existing research has predominantly focused on static-object grasping, neglecting the challenges posed by dynamic targets and thus limiting applicability in dynamic scenarios such as logistics sorting and human-robot collaboration. To address this, we introduce DQ-Bench, a new benchmark that systematically evaluates dynamic grasping across varying object motions, velocities, heights, object types, and terrain complexities, along with comprehensive evaluation metrics. Building upon this benchmark, we propose DQ-Net, a compact teacher-student framework designed to infer grasp configurations from limited perceptual cues. During training, the teacher network leverages privileged information to holistically model both the static geometric properties and dynamic motion characteristics of the target, and integrates a grasp fusion module to deliver robust guidance for motion planning. Concurrently, we design a lightweight student network that performs dual-viewpoint temporal modeling using only the target mask, depth map, and proprioceptive state, enabling closed-loop action outputs without reliance on privileged data. Extensive experiments on DQ-Bench demonstrate that DQ-Net achieves robust dynamic objects grasping across multiple task settings, substantially outperforming baseline methods in both success rate and responsiveness.",
    "source": "arXiv"
  },
  {
    "title": "Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming",
    "title_es": "Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming",
    "url": "https://arxiv.org/abs/2508.08332",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08332v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are widely used for code generation. However, commercial models like ChatGPT require significant computing power, which leads to high energy use and carbon emissions. This has raised concerns about their environmental impact. In this study, we evaluate open-source Small Language Models (SLMs) trained explicitly for code generation and compare their performance and energy efficiency against large LLMs and efficient human-written Python code. The goal is to investigate whether SLMs can match the performance of LLMs on certain types of programming problems while producing more energy-efficient code. We evaluate 150 coding problems from LeetCode, evenly distributed across three difficulty levels: easy, medium, and hard. Our comparison includes three small open-source models, StableCode-3B, StarCoderBase-3B, and Qwen2.5-Coder-3B-Instruct, and two large commercial models, GPT-4.0 and DeepSeek-Reasoner. The generated code is evaluated using four key metrics: run-time, memory usage, energy consumption, and correctness. We use human-written solutions as a baseline to assess the quality and efficiency of the model-generated code. Results indicate that LLMs achieve the highest correctness across all difficulty levels, but SLMs are often more energy-efficient when their outputs are correct. In over 52% of the evaluated problems, SLMs consumed the same or less energy than LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Normative Moral Pluralism for AI: A Framework for Deliberation in Complex Moral Contexts",
    "title_es": "Normative Moral Pluralism for AI: A Framework for Deliberation in Complex Moral Contexts",
    "url": "https://arxiv.org/abs/2508.08333",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08333v1 Announce Type: new \nAbstract: The conceptual framework proposed in this paper centers on the development of a deliberative moral reasoning system - one designed to process complex moral situations by generating, filtering, and weighing normative arguments drawn from diverse ethical perspectives. While the framework is rooted in Machine Ethics, it also makes a substantive contribution to Value Alignment by outlining a system architecture that links structured moral reasoning to action under time constraints. Grounded in normative moral pluralism, this system is not constructed to imitate behavior but is built on reason-sensitive deliberation over structured moral content in a transparent and principled manner. Beyond its role as a deliberative system, it also serves as the conceptual foundation for a novel two-level architecture: functioning as a moral reasoning teacher envisioned to train faster models that support real-time responsiveness without reproducing the full structure of deliberative reasoning. Together, the deliberative and intuitive components are designed to enable both deep reflection and responsive action. A key design feature is the dual-hybrid structure: a universal layer that defines a moral threshold through top-down and bottom-up learning, and a local layer that learns to weigh competing considerations in context while integrating culturally specific normative content, so long as it remains within the universal threshold. By extending the notion of moral complexity to include not only conflicting beliefs but also multifactorial dilemmas, multiple stakeholders, and the integration of non-moral considerations, the framework aims to support morally grounded decision-making in realistic, high-stakes contexts.",
    "source": "arXiv"
  },
  {
    "title": "HSA-Net: Hierarchical and Structure-Aware Framework for Efficient and Scalable Molecular Language Modeling",
    "title_es": "HSA-Net: Hierarchical and Structure-Aware Framework for Efficient and Scalable Molecular Language Modeling",
    "url": "https://arxiv.org/abs/2508.08334",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08334v1 Announce Type: new \nAbstract: Molecular representation learning, a cornerstone for downstream tasks like molecular captioning and molecular property prediction, heavily relies on Graph Neural Networks (GNN). However, GNN suffers from the over-smoothing problem, where node-level features collapse in deep GNN layers. While existing feature projection methods with cross-attention have been introduced to mitigate this issue, they still perform poorly in deep features. This motivated our exploration of using Mamba as an alternative projector for its ability to handle complex sequences. However, we observe that while Mamba excels at preserving global topological information from deep layers, it neglects fine-grained details in shallow layers. The capabilities of Mamba and cross-attention exhibit a global-local trade-off. To resolve this critical global-local trade-off, we propose Hierarchical and Structure-Aware Network (HSA-Net), a novel framework with two modules that enables a hierarchical feature projection and fusion. Firstly, a Hierarchical Adaptive Projector (HAP) module is introduced to process features from different graph layers. It learns to dynamically switch between a cross-attention projector for shallow layers and a structure-aware Graph-Mamba projector for deep layers, producing high-quality, multi-level features. Secondly, to adaptively merge these multi-level features, we design a Source-Aware Fusion (SAF) module, which flexibly selects fusion experts based on the characteristics of the aggregation features, ensuring a precise and effective final representation fusion. Extensive experiments demonstrate that our HSA-Net framework quantitatively and qualitatively outperforms current state-of-the-art (SOTA) methods.",
    "source": "arXiv"
  },
  {
    "title": "Algorithmic Fairness amid Social Determinants: Reflection, Characterization, and Approach",
    "title_es": "Algorithmic Fairness amid Social Determinants: Reflection, Characterization, and Approach",
    "url": "https://arxiv.org/abs/2508.08337",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08337v1 Announce Type: new \nAbstract: Social determinants are variables that, while not directly pertaining to any specific individual, capture key aspects of contexts and environments that have direct causal influences on certain attributes of an individual. Previous algorithmic fairness literature has primarily focused on sensitive attributes, often overlooking the role of social determinants. Our paper addresses this gap by introducing formal and quantitative rigor into a space that has been shaped largely by qualitative proposals regarding the use of social determinants. To demonstrate theoretical perspectives and practical applicability, we examine a concrete setting of college admissions, using region as a proxy for social determinants. Our approach leverages a region-based analysis with Gamma distribution parameterization to model how social determinants impact individual outcomes. Despite its simplicity, our method quantitatively recovers findings that resonate with nuanced insights in previous qualitative debates, that are often missed by existing algorithmic fairness approaches. Our findings suggest that mitigation strategies centering solely around sensitive attributes may introduce new structural injustice when addressing existing discrimination. Considering both sensitive attributes and social determinants facilitates a more comprehensive explication of benefits and burdens experienced by individuals from diverse demographic backgrounds as well as contextual environments, which is essential for understanding and achieving fairness effectively and transparently.",
    "source": "arXiv"
  },
  {
    "title": "ImageDDI: Image-enhanced Molecular Motif Sequence Representation for Drug-Drug Interaction Prediction",
    "title_es": "ImageDDI: Image-enhanced Molecular Motif Sequence Representation for Drug-Drug Interaction Prediction",
    "url": "https://arxiv.org/abs/2508.08338",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08338v1 Announce Type: new \nAbstract: To mitigate the potential adverse health effects of simultaneous multi-drug use, including unexpected side effects and interactions, accurately identifying and predicting drug-drug interactions (DDIs) is considered a crucial task in the field of deep learning. Although existing methods have demonstrated promising performance, they suffer from the bottleneck of limited functional motif-based representation learning, as DDIs are fundamentally caused by motif interactions rather than the overall drug structures. In this paper, we propose an Image-enhanced molecular motif sequence representation framework for \\textbf{DDI} prediction, called ImageDDI, which represents a pair of drugs from both global and local structures. Specifically, ImageDDI tokenizes molecules into functional motifs. To effectively represent a drug pair, their motifs are combined into a single sequence and embedded using a transformer-based encoder, starting from the local structure representation. By leveraging the associations between drug pairs, ImageDDI further enhances the spatial representation of molecules using global molecular image information (e.g. texture, shadow, color, and planar spatial relationships). To integrate molecular visual information into functional motif sequence, ImageDDI employs Adaptive Feature Fusion, enhancing the generalization of ImageDDI by dynamically adapting the fusion process of feature representations. Experimental results on widely used datasets demonstrate that ImageDDI outperforms state-of-the-art methods. Moreover, extensive experiments show that ImageDDI achieved competitive performance in both 2D and 3D image-enhanced scenarios compared to other models.",
    "source": "arXiv"
  },
  {
    "title": "SHeRL-FL: When Representation Learning Meets Split Learning in Hierarchical Federated Learning",
    "title_es": "SHeRL-FL: When Representation Learning Meets Split Learning in Hierarchical Federated Learning",
    "url": "https://arxiv.org/abs/2508.08339",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08339v1 Announce Type: new \nAbstract: Federated learning (FL) is a promising approach for addressing scalability and latency issues in large-scale networks by enabling collaborative model training without requiring the sharing of raw data. However, existing FL frameworks often overlook the computational heterogeneity of edge clients and the growing training burden on resource-limited devices. However, FL suffers from high communication costs and complex model aggregation, especially with large models. Previous works combine split learning (SL) and hierarchical FL (HierFL) to reduce device-side computation and improve scalability, but this introduces training complexity due to coordination across tiers. To address these issues, we propose SHeRL-FL, which integrates SL and hierarchical model aggregation and incorporates representation learning at intermediate layers. By allowing clients and edge servers to compute training objectives independently of the cloud, SHeRL-FL significantly reduces both coordination complexity and communication overhead. To evaluate the effectiveness and efficiency of SHeRL-FL, we performed experiments on image classification tasks using CIFAR-10, CIFAR-100, and HAM10000 with AlexNet, ResNet-18, and ResNet-50 in both IID and non-IID settings. In addition, we evaluate performance on image segmentation tasks using the ISIC-2018 dataset with a ResNet-50-based U-Net. Experimental results demonstrate that SHeRL-FL reduces data transmission by over 90\\% compared to centralized FL and HierFL, and by 50\\% compared to SplitFed, which is a hybrid of FL and SL, and further improves hierarchical split learning methods.",
    "source": "arXiv"
  },
  {
    "title": "Decoupling Geometry from Optimization in 2D Irregular Cutting and Packing Problems: an Open-Source Collision Detection Engine",
    "title_es": "Decoupling Geometry from Optimization in 2D Irregular Cutting and Packing Problems: an Open-Source Collision Detection Engine",
    "url": "https://arxiv.org/abs/2508.08341",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08341v1 Announce Type: new \nAbstract: Addressing irregular cutting and packing (C&P) optimization problems poses two distinct challenges: the geometric challenge of determining whether or not an item can be placed feasibly at a certain position, and the optimization challenge of finding a good solution according to some objective function. Until now, those tackling such problems have had to address both challenges simultaneously, requiring two distinct sets of expertise and a lot of research & development effort. One way to lower this barrier is to decouple the two challenges. In this paper we introduce a powerful collision detection engine (CDE) for 2D irregular C&P problems which assumes full responsibility for the geometric challenge. The CDE (i) allows users to focus with full confidence on their optimization challenge by abstracting geometry away and (ii) enables independent advances to propagate to all optimization algorithms built atop it. We present a set of core principles and design philosophies to model a general and adaptable CDE focused on maximizing performance, accuracy and robustness. These principles are accompanied by a concrete open-source implementation called $\\texttt{jagua-rs}$. This paper together with its implementation serves as a catalyst for future advances in irregular C&P problems by providing a solid foundation which can either be used as it currently exists or be further improved upon.",
    "source": "arXiv"
  },
  {
    "title": "Improving Merge Pipeline Throughput in Continuous Integration via Pull Request Prioritization",
    "title_es": "Improving Merge Pipeline Throughput in Continuous Integration via Pull Request Prioritization",
    "url": "https://arxiv.org/abs/2508.08342",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08342v1 Announce Type: new \nAbstract: Integrating changes into large monolithic software repositories is a critical step in modern software development that substantially impacts the speed of feature delivery, the stability of the codebase, and the overall productivity of development teams. To ensure the stability of the main branch, many organizations use merge pipelines that test software versions before the changes are permanently integrated. However, the load on merge pipelines is often so high that they become bottlenecks, despite the use of parallelization. Existing optimizations frequently rely on specific build systems, limiting their generalizability and applicability. In this paper we propose to optimize the order of PRs in merge pipelines using practical build predictions utilizing only historical build data, PR metadata, and contextual information to estimate the likelihood of successful builds in the merge pipeline. By dynamically prioritizing likely passing PRs during peak hours, this approach maximizes throughput when it matters most. Experiments conducted on a real-world, large-scale project demonstrate that predictive ordering significantly outperforms traditional first-in-first-out (FIFO), as well as non-learning-based ordering strategies. Unlike alternative optimizations, this approach is agnostic to the underlying build system and thus easily integrable into existing automated merge pipelines.",
    "source": "arXiv"
  },
  {
    "title": "Maximizing GPU Efficiency via Optimal Adapter Caching: An Analytical Approach for Multi-Tenant LLM Serving",
    "title_es": "Maximizing GPU Efficiency via Optimal Adapter Caching: An Analytical Approach for Multi-Tenant LLM Serving",
    "url": "https://arxiv.org/abs/2508.08343",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08343v1 Announce Type: new \nAbstract: Serving LLM adapters has gained significant attention as an effective approach to adapt general-purpose language models to diverse, task-specific use cases. However, serving a wide range of adapters introduces several and substantial overheads, leading to performance degradation and challenges in optimal placement. To address these challenges, we present an analytical, AI-driven pipeline that accurately determines the optimal allocation of adapters in single-node setups. This allocation maximizes performance, effectively using GPU resources, while preventing request starvation. Crucially, the proposed allocation is given based on current workload patterns. These insights in single-node setups can be leveraged in multi-replica deployments for overall placement, load balancing and server configuration, ultimately enhancing overall performance and improving resource efficiency. Our approach builds on an in-depth analysis of LLM adapter serving, accounting for overheads and performance variability, and includes the development of the first Digital Twin capable of replicating online LLM-adapter serving systems with matching key performance metrics. The experimental results demonstrate that the Digital Twin achieves a SMAPE difference of no more than 5.5% in throughput compared to real results, and the proposed pipeline accurately predicts the optimal placement with minimal latency.",
    "source": "arXiv"
  },
  {
    "title": "What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge",
    "title_es": "What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge",
    "url": "https://arxiv.org/abs/2508.08344",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08344v1 Announce Type: new \nAbstract: Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an increasingly explored approach for combining the reasoning capabilities of large language models with the structured evidence of knowledge graphs. However, current evaluation practices fall short: existing benchmarks often include questions that can be directly answered using existing triples in KG, making it unclear whether models perform reasoning or simply retrieve answers directly. Moreover, inconsistent evaluation metrics and lenient answer matching criteria further obscure meaningful comparisons. In this work, we introduce a general method for constructing benchmarks, together with an evaluation protocol, to systematically assess KG-RAG methods under knowledge incompleteness. Our empirical results show that current KG-RAG methods have limited reasoning ability under missing knowledge, often rely on internal memorization, and exhibit varying degrees of generalization depending on their design.",
    "source": "arXiv"
  },
  {
    "title": "Do AI Companies Make Good on Voluntary Commitments to the White House?",
    "title_es": "Do AI Companies Make Good on Voluntary Commitments to the White House?",
    "url": "https://arxiv.org/abs/2508.08345",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08345v1 Announce Type: new \nAbstract: Voluntary commitments are central to international AI governance, as demonstrated by recent voluntary guidelines from the White House to the G7, from Bletchley Park to Seoul. How do major AI companies make good on their commitments? We score companies based on their publicly disclosed behavior by developing a detailed rubric based on their eight voluntary commitments to the White House in 2023. We find significant heterogeneity: while the highest-scoring company (OpenAI) scores a 83% overall on our rubric, the average score across all companies is just 52%. The companies demonstrate systemically poor performance for their commitment to model weight security with an average score of 17%: 11 of the 16 companies receive 0% for this commitment. Our analysis highlights a clear structural shortcoming that future AI governance initiatives should correct: when companies make public commitments, they should proactively disclose how they meet their commitments to provide accountability, and these disclosures should be verifiable. To advance policymaking on corporate AI governance, we provide three directed recommendations that address underspecified commitments, the role of complex AI supply chains, and public transparency that could be applied towards AI governance initiatives worldwide.",
    "source": "arXiv"
  },
  {
    "title": "Exploring the Technical Knowledge Interaction of Global Digital Humanities: Three-decade Evidence from Bibliometric-based perspectives",
    "title_es": "Exploring the Technical Knowledge Interaction of Global Digital Humanities: Three-decade Evidence from Bibliometric-based perspectives",
    "url": "https://arxiv.org/abs/2508.08347",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08347v1 Announce Type: new \nAbstract: Digital Humanities (DH) is an interdisciplinary field that integrates computational methods with humanities scholarship to investigate innovative topics. Each academic discipline follows a unique developmental path shaped by the topics researchers investigate and the methods they employ. With the help of bibliometric analysis, most of previous studies have examined DH across multiple dimensions such as research hotspots, co-author networks, and institutional rankings. However, these studies have often been limited in their ability to provide deep insights into the current state of technological advancements and topic development in DH. As a result, their conclusions tend to remain superficial or lack interpretability in understanding how methods and topics interrelate in the field. To address this gap, this study introduced a new concept of Topic-Method Composition (TMC), which refers to a hybrid knowledge structure generated by the co-occurrence of specific research topics and the corresponding method. Especially by analyzing the interaction between TMCs, we can see more clearly the intersection and integration of digital technology and humanistic subjects in DH. Moreover, this study developed a TMC-based workflow combining bibliometric analysis, topic modeling, and network analysis to analyze the development characteristics and patterns of research disciplines. By applying this workflow to large-scale bibliometric data, it enables a detailed view of the knowledge structures, providing a tool adaptable to other fields.",
    "source": "arXiv"
  },
  {
    "title": "Fuzzy-Pattern Tsetlin Machine",
    "title_es": "Fuzzy-Pattern Tsetlin Machine",
    "url": "https://arxiv.org/abs/2508.08350",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08350v1 Announce Type: new \nAbstract: The \"all-or-nothing\" clause evaluation strategy is a core mechanism in the Tsetlin Machine (TM) family of algorithms. In this approach, each clause - a logical pattern composed of binary literals mapped to input data - is disqualified from voting if even a single literal fails. Due to this strict requirement, standard TMs must employ thousands of clauses to achieve competitive accuracy. This paper introduces the Fuzzy-Pattern Tsetlin Machine (FPTM), a novel variant where clause evaluation is fuzzy rather than strict. If some literals in a clause fail, the remaining ones can still contribute to the overall vote with a proportionally reduced score. As a result, each clause effectively consists of sub-patterns that adapt individually to the input, enabling more flexible, efficient, and robust pattern matching. The proposed fuzzy mechanism significantly reduces the required number of clauses, memory footprint, and training time, while simultaneously improving accuracy. On the IMDb dataset, FPTM achieves 90.15% accuracy with only one clause per class, a 50x reduction in clauses and memory over the Coalesced Tsetlin Machine. FPTM trains up to 316x faster (45 seconds vs. 4 hours) and fits within 50 KB, enabling online learning on microcontrollers. Inference throughput reaches 34.5 million predictions/second (51.4 GB/s). On Fashion-MNIST, accuracy reaches 92.18% (2 clauses), 93.19% (20 clauses) and 94.68% (8000 clauses), a ~400x clause reduction compared to the Composite TM's 93.00% (8000 clauses). On the Amazon Sales dataset with 20% noise, FPTM achieves 85.22% accuracy, significantly outperforming the Graph Tsetlin Machine (78.17%) and a Graph Convolutional Neural Network (66.23%).",
    "source": "arXiv"
  },
  {
    "title": "Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions",
    "title_es": "Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions",
    "url": "https://arxiv.org/abs/2508.08352",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08352v1 Announce Type: new \nAbstract: Object detection (OD) has become vital for numerous computer vision applications, but deploying it on resource-constrained IoT devices presents a significant challenge. These devices, often powered by energy-efficient microcontrollers, struggle to handle the computational load of deep learning-based OD models. This issue is compounded by the rapid proliferation of IoT devices, predicted to surpass 150 billion by 2030. TinyML offers a compelling solution by enabling OD on ultra-low-power devices, paving the way for efficient and real-time processing at the edge. Although numerous survey papers have been published on this topic, they often overlook the optimization challenges associated with deploying OD models in TinyML environments. To address this gap, this survey paper provides a detailed analysis of key optimization techniques for deploying OD models on resource-constrained devices. These techniques include quantization, pruning, knowledge distillation, and neural architecture search. Furthermore, we explore both theoretical approaches and practical implementations, bridging the gap between academic research and real-world edge artificial intelligence deployment. Finally, we compare the key performance indicators (KPIs) of existing OD implementations on microcontroller devices, highlighting the achieved maturity level of these solutions in terms of both prediction accuracy and efficiency. We also provide a public repository to continually track developments in this fast-evolving field: https://github.com/christophezei/Optimizing-Object-Detection-Models-for-TinyML-A-Comprehensive-Survey.",
    "source": "arXiv"
  },
  {
    "title": "Processing of synthetic data in AI development for healthcare and the definition of personal data in EU law",
    "title_es": "Processing of synthetic data in AI development for healthcare and the definition of personal data in EU law",
    "url": "https://arxiv.org/abs/2508.08353",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08353v1 Announce Type: new \nAbstract: Artificial intelligence (AI) has the potential to transform healthcare, but it requires access to health data. Synthetic data that is generated through machine learning models trained on real data, offers a way to share data while preserving privacy. However, uncertainties in the practical application of the General Data Protection Regulation (GDPR) create an administrative burden, limiting the benefits of synthetic data. Through a systematic analysis of relevant legal sources and an empirical study, this article explores whether synthetic data should be classified as personal data under the GDPR. The study investigates the residual identification risk through generating synthetic data and simulating inference attacks, challenging common perceptions of technical identification risk. The findings suggest synthetic data is likely anonymous, depending on certain factors, but highlights uncertainties about what constitutes reasonably likely risk. To promote innovation, the study calls for clearer regulations to balance privacy protection with the advancement of AI in healthcare.",
    "source": "arXiv"
  },
  {
    "title": "Scaled-Dot-Product Attention as One-Sided Entropic Optimal Transport",
    "title_es": "Scaled-Dot-Product Attention as One-Sided Entropic Optimal Transport",
    "url": "https://arxiv.org/abs/2508.08369",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08369v1 Announce Type: new \nAbstract: The scaled-dot-product attention (SDPA) mechanism is a core component of modern deep learning, but its mathematical form is often motivated by heuristics. This work provides a first-principles justification for SDPA. We first show that the attention forward pass is the exact solution to a degenerate, one-sided Entropic Optimal Transport (EOT) problem, which seeks a distribution that maximizes similarity while being maximally entropic. This optimization perspective has a direct consequence for the backward pass. We prove that the standard gradient computed via backpropagation is mathematically identical to an advantage-based policy gradient, a variance-reduced update rule from reinforcement learning. Crucially, we demonstrate that the EOT formulation of the forward pass induces a specific information geometry on the space of attention distributions. It is this geometry, characterized by the Fisher Information Matrix, that dictates the precise form of the learning gradient, revealing the advantage-based update as a natural consequence of the optimization problem being solved. This unified view reveals SDPA as a principled mechanism where the forward pass performs optimal inference and the backward pass implements a rational, manifold-aware learning update.",
    "source": "arXiv"
  },
  {
    "title": "Experimental Validation of Provably Covert Communication Using Software-Defined Radio",
    "title_es": "Experimental Validation of Provably Covert Communication Using Software-Defined Radio",
    "url": "https://arxiv.org/abs/2508.08380",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08380v1 Announce Type: new \nAbstract: The fundamental information-theoretic limits of covert, or low probability of detection/intercept (LPD/LPI), communication have been extensively studied for over a decade, resulting in the square root law (SRL): only $L\\sqrt{n}$ covert bits can be reliably transmitted over time-bandwidth product $n$, for constant $L>0$. Transmitting more either results in detection or decoding errors. The SRL imposes significant constraints on hardware realization of mathematically-guaranteed covert communication. Indeed, they preclude using standard link maintenance operations that are taken for granted in non-covert communication. Thus, experimental validation of covert communication is underexplored: to date, only two experimental studies of SRL-based covert communication are available, both focusing on optical channels. Here, we report a demonstration of provably-secure covert radio-frequency (RF) communication using software-defined radios (SDRs). This validates theoretical predictions, opens practical avenues for implementing covert communication systems, and raises further research questions.",
    "source": "arXiv"
  },
  {
    "title": "Competitive Online Transportation Simplified",
    "title_es": "Competitive Online Transportation Simplified",
    "url": "https://arxiv.org/abs/2508.08381",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08381v1 Announce Type: new \nAbstract: The setting for the online transportation problem is a metric space $M$, populated by $m$ parking garages of varying capacities. Over time cars arrive in $M$, and must be irrevocably assigned to a parking garage upon arrival in a way that respects the garage capacities. The objective is to minimize the aggregate distance traveled by the cars. In 1998, Kalyanasundaram and Pruhs conjectured that there is a $(2m-1)$-competitive deterministic algorithm for the online transportation problem, matching the optimal competitive ratio for the simpler online metric matching problem. Recently, Harada and Itoh presented the first $O(m)$-competitive deterministic algorithm for the online transportation problem. Our contribution is an alternative algorithm design and analysis that we believe is simpler.",
    "source": "arXiv"
  },
  {
    "title": "UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games",
    "title_es": "UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games",
    "url": "https://arxiv.org/abs/2508.08382",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08382v1 Announce Type: new \nAbstract: Collectible card games (CCGs) are a difficult genre for AI due to their partial observability, long-term decision-making, and evolving card sets. Due to this, current AI models perform vastly worse than human players at CCG tasks such as deckbuilding and gameplay. In this work, we introduce $\\textit{UrzaGPT}$, a domain-adapted large language model that recommends real-time drafting decisions in $\\textit{Magic: The Gathering}$. Starting from an open-weight LLM, we use Low-Rank Adaptation fine-tuning on a dataset of annotated draft logs. With this, we leverage the language modeling capabilities of LLM, and can quickly adapt to different expansions of the game. We benchmark $\\textit{UrzaGPT}$ in comparison to zero-shot LLMs and the state-of-the-art domain-specific model. Untuned, small LLMs like Llama-3-8B are completely unable to draft, but the larger GPT-4o achieves a zero-shot performance of $43\\%$. Using UrzaGPT to fine-tune smaller models, we achieve an accuracy of $66.2\\%$ using only 10,000 steps. Despite this not reaching the capability of domain-specific models, we show that solely using LLMs to draft is possible and conclude that using LLMs can enable performant, general, and update-friendly drafting AIs in the future.",
    "source": "arXiv"
  },
  {
    "title": "Designing for Disclosure in Data Visualizations",
    "title_es": "Designing for Disclosure in Data Visualizations",
    "url": "https://arxiv.org/abs/2508.08383",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08383v1 Announce Type: new \nAbstract: Visualizing data often entails data transformations that can reveal and hide information, operations we dub disclosure tactics. Whether designers hide information intentionally or as an implicit consequence of other design choices, tools and frameworks for visualization offer little explicit guidance on disclosure. To systematically characterize how visualizations can limit access to an underlying dataset, we contribute a content analysis of 425 examples of visualization techniques sampled from academic papers in the visualization literature, resulting in a taxonomy of disclosure tactics. Our taxonomy organizes disclosure tactics based on how they change the data representation underlying a chart, providing a systematic way to reason about design trade-offs in terms of what information is revealed, distorted, or hidden. We demonstrate the benefits of using our taxonomy by showing how it can guide reasoning in design scenarios where disclosure is a first-order consideration. Adopting disclosure as a framework for visualization research offers new perspective on authoring tools, literacy, uncertainty communication, personalization, and ethical design.",
    "source": "arXiv"
  },
  {
    "title": "Spatiotemporally Consistent Indoor Lighting Estimation with Diffusion Priors",
    "title_es": "Spatiotemporally Consistent Indoor Lighting Estimation with Diffusion Priors",
    "url": "https://arxiv.org/abs/2508.08384",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08384v1 Announce Type: new \nAbstract: Indoor lighting estimation from a single image or video remains a challenge due to its highly ill-posed nature, especially when the lighting condition of the scene varies spatially and temporally. We propose a method that estimates from an input video a continuous light field describing the spatiotemporally varying lighting of the scene. We leverage 2D diffusion priors for optimizing such light field represented as a MLP. To enable zero-shot generalization to in-the-wild scenes, we fine-tune a pre-trained image diffusion model to predict lighting at multiple locations by jointly inpainting multiple chrome balls as light probes. We evaluate our method on indoor lighting estimation from a single image or video and show superior performance over compared baselines. Most importantly, we highlight results on spatiotemporally consistent lighting estimation from in-the-wild videos, which is rarely demonstrated in previous works.",
    "source": "arXiv"
  },
  {
    "title": "Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning",
    "title_es": "Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning",
    "url": "https://arxiv.org/abs/2508.08385",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08385v1 Announce Type: new \nAbstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is that it spends a significant time deciding which node to expand next. While selecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity with traditional array-based priority-queues for dense integer keys, the tree-based OPEN list used by MCTS requires $O(\\log N)$, which roughly corresponds to the search depth $d$. In classical planning, $d$ is arbitrarily large (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node selection is significant, unlike in game tree search, where the cost is negligible compared to the node evaluation (rollouts) because $d$ is inherently limited by the game (e.g., $d\\leq 361$ in Go). To improve this bottleneck, we propose a bilevel modification to MCTS that runs a best-first search from each selected leaf node with an expansion budget proportional to $d$, which achieves amortized $O(1)$ runtime for node selection, equivalent to the traditional queue-based OPEN list. In addition, we introduce Tree Collapsing, an enhancement that reduces action selection steps and further improves the performance.",
    "source": "arXiv"
  },
  {
    "title": "CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation",
    "title_es": "CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation",
    "url": "https://arxiv.org/abs/2508.08386",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08386v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly employed as AI tutors due to their scalability and potential for personalized instruction. However, off-the-shelf LLMs often underperform in educational settings: they frequently reveal answers too readily, fail to adapt their responses to student uncertainty, and remain vulnerable to emotionally manipulative prompts. To address these challenges, we introduce CoDAE, a framework that adapts LLMs for educational use through Chain-of-Thought (CoT) data augmentation. We collect real-world dialogues between students and a ChatGPT-based tutor and enrich them using CoT prompting to promote step-by-step reasoning and pedagogically aligned guidance. Furthermore, we design targeted dialogue cases to explicitly mitigate three key limitations: over-compliance, low response adaptivity, and threat vulnerability. We fine-tune four open-source LLMs on different variants of the augmented datasets and evaluate them in simulated educational scenarios using both automatic metrics and LLM-as-a-judge assessments. Our results show that models fine-tuned with CoDAE deliver more pedagogically appropriate guidance, better support reasoning processes, and effectively resist premature answer disclosure.",
    "source": "arXiv"
  },
  {
    "title": "XDMA: A Distributed, Extensible DMA Architecture for Layout-Flexible Data Movements in Heterogeneous Multi-Accelerator SoCs",
    "title_es": "XDMA: A Distributed, Extensible DMA Architecture for Layout-Flexible Data Movements in Heterogeneous Multi-Accelerator SoCs",
    "url": "https://arxiv.org/abs/2508.08396",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08396v1 Announce Type: new \nAbstract: As modern AI workloads increasingly rely on heterogeneous accelerators, ensuring high-bandwidth and layout-flexible data movements between accelerator memories has become a pressing challenge. Direct Memory Access (DMA) engines promise high bandwidth utilization for data movements but are typically optimal only for contiguous memory access, thus requiring additional software loops for data layout transformations. This, in turn, leads to excessive control overhead and underutilized on-chip interconnects. To overcome this inefficiency, we present XDMA, a distributed and extensible DMA architecture that enables layout-flexible data movements with high link utilization. We introduce three key innovations: (1) a data streaming engine as XDMA Frontend, replacing software address generators with hardware ones; (2) a distributed DMA architecture that maximizes link utilization and separates configuration from data transfer; (3) flexible plugins for XDMA enabling on-the-fly data manipulation during data transfers. XDMA demonstrates up to 151.2x/8.2x higher link utilization than software-based implementations in synthetic workloads and achieves 2.3x average speedup over accelerators with SoTA DMA in real-world applications. Our design incurs <2% area overhead over SoTA DMA solutions while consuming 17% of system power. XDMA proves that co-optimizing memory access, layout transformation, and interconnect protocols is key to unlocking heterogeneous multi-accelerator SoC performance.",
    "source": "arXiv"
  },
  {
    "title": "Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery",
    "title_es": "Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery",
    "url": "https://arxiv.org/abs/2508.08401",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08401v1 Announce Type: new \nAbstract: Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT) reasoning models like DeepSeek-R1 and QWQ, have demonstrated powerful reasoning capabilities, achieving impressive performance in commonsense reasoning and mathematical inference. Despite their effectiveness, Long-CoT reasoning models are often criticized for their limited ability and low efficiency in knowledge-intensive domains such as molecule discovery. Success in this field requires a precise understanding of domain knowledge, including molecular structures and chemical principles, which is challenging due to the inherent complexity of molecular data and the scarcity of high-quality expert annotations. To bridge this gap, we introduce Mol-R1, a novel framework designed to improve explainability and reasoning performance of R1-like Explicit Long-CoT reasoning LLMs in text-based molecule generation. Our approach begins with a high-quality reasoning dataset curated through Prior Regulation via In-context Distillation (PRID), a dedicated distillation strategy to effectively generate paired reasoning traces guided by prior regulations. Building upon this, we introduce MoIA, Molecular Iterative Adaptation, a sophisticated training strategy that iteratively combines Supervised Fine-tuning (SFT) with Reinforced Policy Optimization (RPO), tailored to boost the reasoning performance of R1-like reasoning models for molecule discovery. Finally, we examine the performance of Mol-R1 in the text-based molecule reasoning generation task, showing superior performance against existing baselines.",
    "source": "arXiv"
  },
  {
    "title": "Generating Query-Relevant Document Summaries via Reinforcement Learning",
    "title_es": "Generating Query-Relevant Document Summaries via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.08404",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08404v1 Announce Type: new \nAbstract: E-commerce search engines often rely solely on product titles as input for ranking models with latency constraints. However, this approach can result in suboptimal relevance predictions, as product titles often lack sufficient detail to capture query intent. While product descriptions provide richer information, their verbosity and length make them unsuitable for real-time ranking, particularly for computationally expensive architectures like cross-encoder ranking models. To address this challenge, we propose ReLSum, a novel reinforcement learning framework designed to generate concise, query-relevant summaries of product descriptions optimized for search relevance. ReLSum leverages relevance scores as rewards to align the objectives of summarization and ranking, effectively overcoming limitations of prior methods, such as misaligned learning targets. The framework employs a trainable large language model (LLM) to produce summaries, which are then used as input for a cross-encoder ranking model. Experimental results demonstrate significant improvements in offline metrics, including recall and NDCG, as well as online user engagement metrics. ReLSum provides a scalable and efficient solution for enhancing search relevance in large-scale e-commerce systems.",
    "source": "arXiv"
  },
  {
    "title": "Regret minimization in Linear Bandits with offline data via extended D-optimal exploration",
    "title_es": "Regret minimization in Linear Bandits with offline data via extended D-optimal exploration",
    "url": "https://arxiv.org/abs/2508.08420",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08420v1 Announce Type: new \nAbstract: We consider the problem of online regret minimization in linear bandits with access to prior observations (offline data) from the underlying bandit model. There are numerous applications where extensive offline data is often available, such as in recommendation systems, online advertising. Consequently, this problem has been studied intensively in recent literature. Our algorithm, Offline-Online Phased Elimination (OOPE), effectively incorporates the offline data to substantially reduce the online regret compared to prior work. To leverage offline information prudently, OOPE uses an extended D-optimal design within each exploration phase. OOPE achieves an online regret is $\\tilde{O}(\\sqrt{\\deff T \\log \\left(|\\mathcal{A}|T\\right)}+d^2)$. $\\deff \\leq d)$ is the effective problem dimension which measures the number of poorly explored directions in offline data and depends on the eigen-spectrum $(\\lambda_k)_{k \\in [d]}$ of the Gram matrix of the offline data. The eigen-spectrum $(\\lambda_k)_{k \\in [d]}$ is a quantitative measure of the \\emph{quality} of offline data. If the offline data is poorly explored ($\\deff \\approx d$), we recover the established regret bounds for purely online setting while, when offline data is abundant ($\\Toff >> T$) and well-explored ($\\deff = o(1) $), the online regret reduces substantially. Additionally, we provide the first known minimax regret lower bounds in this setting that depend explicitly on the quality of the offline data. These lower bounds establish the optimality of our algorithm in regimes where offline data is either well-explored or poorly explored. Finally, by using a Frank-Wolfe approximation to the extended optimal design we further improve the $O(d^{2})$ term to $O\\left(\\frac{d^{2}}{\\deff} \\min \\{ \\deff,1\\} \\right)$, which can be substantial in high dimensions with moderate quality of offline data $\\deff = \\Omega(1)$.",
    "source": "arXiv"
  },
  {
    "title": "Neural Tangent Knowledge Distillation for Optical Convolutional Networks",
    "title_es": "Neural Tangent Knowledge Distillation for Optical Convolutional Networks",
    "url": "https://arxiv.org/abs/2508.08421",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08421v1 Announce Type: new \nAbstract: Hybrid Optical Neural Networks (ONNs, typically consisting of an optical frontend and a digital backend) offer an energy-efficient alternative to fully digital deep networks for real-time, power-constrained systems. However, their adoption is limited by two main challenges: the accuracy gap compared to large-scale networks during training, and discrepancies between simulated and fabricated systems that further degrade accuracy. While previous work has proposed end-to-end optimizations for specific datasets (e.g., MNIST) and optical systems, these approaches typically lack generalization across tasks and hardware designs. To address these limitations, we propose a task-agnostic and hardware-agnostic pipeline that supports image classification and segmentation across diverse optical systems. To assist optical system design before training, we estimate achievable model accuracy based on user-specified constraints such as physical size and the dataset. For training, we introduce Neural Tangent Knowledge Distillation (NTKD), which aligns optical models with electronic teacher networks, thereby narrowing the accuracy gap. After fabrication, NTKD also guides fine-tuning of the digital backend to compensate for implementation errors. Experiments on multiple datasets (e.g., MNIST, CIFAR, Carvana Masking) and hardware configurations show that our pipeline consistently improves ONN performance and enables practical deployment in both pre-fabrication simulations and physical implementations.",
    "source": "arXiv"
  },
  {
    "title": "Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment",
    "title_es": "Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment",
    "url": "https://arxiv.org/abs/2508.08424",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08424v1 Announce Type: new \nAbstract: Prior work on language modeling showed conflicting findings about whether morphologically aligned approaches to tokenization improve performance, particularly for languages with complex morphology. To investigate this, we select a typologically diverse set of languages: Telugu (agglutinative), Hindi (primarily fusional with some agglutination), and English (fusional). We conduct a comprehensive evaluation of language models -- starting from tokenizer training and extending through the finetuning and downstream task evaluation. To account for the consistent performance differences observed across tokenizer variants, we focus on two key factors: morphological alignment and tokenization quality. To assess morphological alignment of tokenizers in Telugu, we create a dataset containing gold morpheme segmentations of 600 derivational and 7000 inflectional word forms.\n  Our experiments reveal that better morphological alignment correlates positively -- though moderately -- with performance in syntax-based tasks such as Parts-of-Speech tagging, Named Entity Recognition and Dependency Parsing. However, we also find that the tokenizer algorithm (Byte-pair Encoding vs. Unigram) plays a more significant role in influencing downstream performance than morphological alignment alone. Naive Unigram tokenizers outperform others across most settings, though hybrid tokenizers that incorporate morphological segmentation significantly improve performance within the BPE framework. In contrast, intrinsic metrics like Corpus Token Count (CTC) and R\\'enyi entropy showed no correlation with downstream performance.",
    "source": "arXiv"
  },
  {
    "title": "Improving Facial Rig Semantics for Tracking and Retargeting",
    "title_es": "Improving Facial Rig Semantics for Tracking and Retargeting",
    "url": "https://arxiv.org/abs/2508.08429",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08429v1 Announce Type: new \nAbstract: In this paper, we consider retargeting a tracked facial performance to either another person or to a virtual character in a game or virtual reality (VR) environment. We remove the difficulties associated with identifying and retargeting the semantics of one rig framework to another by utilizing the same framework (3DMM, FLAME, MetaHuman, etc.) for both subjects. Although this does not constrain the choice of framework when retargeting from one person to another, it does force the tracker to use the game/VR character rig when retargeting to a game/VR character. We utilize volumetric morphing in order to fit facial rigs to both performers and targets; in addition, a carefully chosen set of Simon-Says expressions is used to calibrate each rig to the motion signatures of the relevant performer or target. Although a uniform set of Simon-Says expressions can likely be used for all person to person retargeting, we argue that person to game/VR character retargeting benefits from Simon-Says expressions that capture the distinct motion signature of the game/VR character rig. The Simon-Says calibrated rigs tend to produce the desired expressions when exercising animation controls (as expected). Unfortunately, these well-calibrated rigs still lead to undesirable controls when tracking a performance (a well-behaved function can have an arbitrarily ill-conditioned inverse), even though they typically produce acceptable geometry reconstructions. Thus, we propose a fine-tuning approach that modifies the rig used by the tracker in order to promote the output of more semantically meaningful animation controls, facilitating high efficacy retargeting. In order to better address real-world scenarios, the fine-tuning relies on implicit differentiation so that the tracker can be treated as a (potentially non-differentiable) black box.",
    "source": "arXiv"
  },
  {
    "title": "Profiling Concurrent Vision Inference Workloads on NVIDIA Jetson -- Extended",
    "title_es": "Profiling Concurrent Vision Inference Workloads on NVIDIA Jetson -- Extended",
    "url": "https://arxiv.org/abs/2508.08430",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08430v1 Announce Type: new \nAbstract: The proliferation of IoT devices and advancements in network technologies have intensified the demand for real-time data processing at the network edge. To address these demands, low-power AI accelerators, particularly GPUs, are increasingly deployed for inference tasks, enabling efficient computation while mitigating cloud-based systems' latency and bandwidth limitations. Despite their growing deployment, GPUs remain underutilised even in computationally intensive workloads. This underutilisation stems from the limited understanding of GPU resource sharing, particularly in edge computing scenarios. In this work, we conduct a detailed analysis of both high- and low-level metrics, including GPU utilisation, memory usage, streaming multiprocessor (SM) utilisation, and tensor core usage, to identify bottlenecks and guide hardware-aware optimisations. By integrating traces from multiple profiling tools, we provide a comprehensive view of resource behaviour on NVIDIA Jetson edge devices under concurrent vision inference workloads. Our findings indicate that while GPU utilisation can reach $100\\%$ under specific optimisations, critical low-level resources, such as SMs and tensor cores, often operate only at $15\\%$ to $30\\%$ utilisation. Moreover, we observe that certain CPU-side events, such as thread scheduling, context switching, etc., frequently emerge as bottlenecks, further constraining overall GPU performance. We provide several key observations for users of vision inference workloads on NVIDIA edge devices.",
    "source": "arXiv"
  },
  {
    "title": "Extremely Scalable Distributed Computation of Contour Trees via Pre-Simplification",
    "title_es": "Extremely Scalable Distributed Computation of Contour Trees via Pre-Simplification",
    "url": "https://arxiv.org/abs/2508.08433",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08433v1 Announce Type: new \nAbstract: Contour trees offer an abstract representation of the level set topology in scalar fields and are widely used in topological data analysis and visualization. However, applying contour trees to large-scale scientific datasets remains challenging due to scalability limitations. Recent developments in distributed hierarchical contour trees have addressed these challenges by enabling scalable computation across distributed systems. Building on these structures, advanced analytical tasks -- such as volumetric branch decomposition and contour extraction -- have been introduced to facilitate large-scale scientific analysis. Despite these advancements, such analytical tasks substantially increase memory usage, which hampers scalability. In this paper, we propose a pre-simplification strategy to significantly reduce the memory overhead associated with analytical tasks on distributed hierarchical contour trees. We demonstrate enhanced scalability through strong scaling experiments, constructing the largest known contour tree -- comprising over half a trillion nodes with complex topology -- in under 15 minutes on a dataset containing 550 billion elements.",
    "source": "arXiv"
  },
  {
    "title": "Fast weight programming and linear transformers: from machine learning to neurobiology",
    "title_es": "Fast weight programming and linear transformers: from machine learning to neurobiology",
    "url": "https://arxiv.org/abs/2508.08435",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08435v1 Announce Type: new \nAbstract: Recent advances in artificial neural networks for machine learning, and language modeling in particular, have established a family of recurrent neural network (RNN) architectures that, unlike conventional RNNs with vector-form hidden states, use two-dimensional (2D) matrix-form hidden states. Such 2D-state RNNs, known as Fast Weight Programmers (FWPs), can be interpreted as a neural network whose synaptic weights (called fast weights) dynamically change over time as a function of input observations, and serve as short-term memory storage; corresponding synaptic weight modifications are controlled or programmed by another network (the programmer) whose parameters are trained (e.g., by gradient descent). In this Primer, we review the technical foundations of FWPs, their computational characteristics, and their connections to transformers and state space models. We also discuss connections between FWPs and models of synaptic plasticity in the brain, suggesting a convergence of natural and artificial intelligence.",
    "source": "arXiv"
  },
  {
    "title": "Selective KV-Cache Sharing to Mitigate Timing Side-Channels in LLM Inference",
    "title_es": "Selective KV-Cache Sharing to Mitigate Timing Side-Channels in LLM Inference",
    "url": "https://arxiv.org/abs/2508.08438",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08438v1 Announce Type: new \nAbstract: Global KV-cache sharing has emerged as a key optimization for accelerating large language model (LLM) inference. However, it exposes a new class of timing side-channel attacks, enabling adversaries to infer sensitive user inputs via shared cache entries. Existing defenses, such as per-user isolation, eliminate leakage but degrade performance by up to 38.9% in time-to-first-token (TTFT), making them impractical for high-throughput deployment. To address this gap, we introduce SafeKV (Secure and Flexible KV Cache Sharing), a privacy-aware KV-cache management framework that selectively shares non-sensitive entries while confining sensitive content to private caches. SafeKV comprises three components: (i) a hybrid, multi-tier detection pipeline that integrates rule-based pattern matching, a general-purpose privacy detector, and context-aware validation; (ii) a unified radix-tree index that manages public and private entries across heterogeneous memory tiers (HBM, DRAM, SSD); and (iii) entropy-based access monitoring to detect and mitigate residual information leakage. Our evaluation shows that SafeKV mitigates 94% - 97% of timing-based side-channel attacks. Compared to per-user isolation method, SafeKV improves TTFT by up to 40.58% and throughput by up to 2.66X across diverse LLMs and workloads. SafeKV reduces cache-induced TTFT overhead from 50.41% to 11.74% on Qwen3-235B. By combining fine-grained privacy control with high cache reuse efficiency, SafeKV reclaims the performance advantages of global sharing while providing robust runtime privacy guarantees for LLM inference.",
    "source": "arXiv"
  },
  {
    "title": "Solver-Aided Expansion of Loops to Avoid Generate-and-Test",
    "title_es": "Solver-Aided Expansion of Loops to Avoid Generate-and-Test",
    "url": "https://arxiv.org/abs/2508.08442",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08442v1 Announce Type: new \nAbstract: Constraint modelling languages like MiniZinc and Essence rely on unrolling loops (in the form of quantified expressions and comprehensions) during compilation. Standard approaches generate all combinations of induction variables and use partial evaluation to discard those that simplify to identity elements of associative-commutative operators (e.g. true for conjunction, 0 for summation). This can be inefficient for problems where most combinations are ultimately irrelevant. We present a method that avoids full enumeration by using a solver to compute only the combinations required to generate the final set of constraints. The resulting model is identical to that produced by conventional flattening, but compilation can be significantly faster. This improves the efficiency of translating high-level user models into solver-ready form, particularly when induction variables range over large domains with selective preconditions.",
    "source": "arXiv"
  },
  {
    "title": "OverFill: Two-Stage Models for Efficient Language Model Decoding",
    "title_es": "OverFill: Two-Stage Models for Efficient Language Model Decoding",
    "url": "https://arxiv.org/abs/2508.08446",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08446v1 Announce Type: new \nAbstract: Large language models (LLMs) excel across diverse tasks but face significant deployment challenges due to high inference costs. LLM inference comprises prefill (compute-bound) and decode (memory-bound) stages, with decode dominating latency particularly for long sequences. Current decoder-only models handle both stages uniformly, despite their distinct computational profiles. We propose OverFill, which decouples these stages to optimize accuracy-efficiency tradeoffs. OverFill begins with a full model for prefill, processing system and user inputs in parallel. It then switches to a dense pruned model, while generating tokens sequentially. Leveraging more compute during prefill, OverFill improves generation quality with minimal latency overhead. Our 3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, while the 8B-to-3B configuration improves over 3B pruned models by 79.2% on average across standard benchmarks. OverFill matches the performance of same-sized models trained from scratch, while using significantly less training data. Our code is available at https://github.com/friendshipkim/overfill.",
    "source": "arXiv"
  },
  {
    "title": "Towards Efficient and Practical GPU Multitasking in the Era of LLM",
    "title_es": "Towards Efficient and Practical GPU Multitasking in the Era of LLM",
    "url": "https://arxiv.org/abs/2508.08448",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08448v1 Announce Type: new \nAbstract: GPU singletasking is becoming increasingly inefficient and unsustainable as hardware capabilities grow and workloads diversify. We are now at an inflection point where GPUs must embrace multitasking, much like CPUs did decades ago, to meet the demands of modern AI workloads. In this work, we highlight the key requirements for GPU multitasking, examine prior efforts, and discuss why they fall short. To advance toward efficient and practical GPU multitasking, we envision a resource management layer, analogous to a CPU operating system, to handle various aspects of GPU resource management and sharing. We outline the challenges and potential solutions, and hope this paper inspires broader community efforts to build the next-generation GPU compute paradigm grounded in multitasking.",
    "source": "arXiv"
  },
  {
    "title": "Differentiable Cyclic Causal Discovery Under Unmeasured Confounders",
    "title_es": "Differentiable Cyclic Causal Discovery Under Unmeasured Confounders",
    "url": "https://arxiv.org/abs/2508.08450",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08450v1 Announce Type: new \nAbstract: Understanding causal relationships between variables is fundamental across scientific disciplines. Most causal discovery algorithms rely on two key assumptions: (i) all variables are observed, and (ii) the underlying causal graph is acyclic. While these assumptions simplify theoretical analysis, they are often violated in real-world systems, such as biological networks. Existing methods that account for confounders either assume linearity or struggle with scalability. To address these limitations, we propose DCCD-CONF, a novel framework for differentiable learning of nonlinear cyclic causal graphs in the presence of unmeasured confounders using interventional data. Our approach alternates between optimizing the graph structure and estimating the confounder distribution by maximizing the log-likelihood of the data. Through experiments on synthetic data and real-world gene perturbation datasets, we show that DCCD-CONF outperforms state-of-the-art methods in both causal graph recovery and confounder identification. Additionally, we also provide consistency guarantees for our framework, reinforcing its theoretical soundness.",
    "source": "arXiv"
  },
  {
    "title": "Enhanced Liver Tumor Detection in CT Images Using 3D U-Net and Bat Algorithm for Hyperparameter Optimization",
    "title_es": "Enhanced Liver Tumor Detection in CT Images Using 3D U-Net and Bat Algorithm for Hyperparameter Optimization",
    "url": "https://arxiv.org/abs/2508.08452",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08452v1 Announce Type: new \nAbstract: Liver cancer is one of the most prevalent and lethal forms of cancer, making early detection crucial for effective treatment. This paper introduces a novel approach for automated liver tumor segmentation in computed tomography (CT) images by integrating a 3D U-Net architecture with the Bat Algorithm for hyperparameter optimization. The method enhances segmentation accuracy and robustness by intelligently optimizing key parameters like the learning rate and batch size. Evaluated on a publicly available dataset, our model demonstrates a strong ability to balance precision and recall, with a high F1-score at lower prediction thresholds. This is particularly valuable for clinical diagnostics, where ensuring no potential tumors are missed is paramount. Our work contributes to the field of medical image analysis by demonstrating that the synergy between a robust deep learning architecture and a metaheuristic optimization algorithm can yield a highly effective solution for complex segmentation tasks.",
    "source": "arXiv"
  },
  {
    "title": "Temporal User Profiling with LLMs: Balancing Short-Term and Long-Term Preferences for Recommendations",
    "title_es": "Temporal User Profiling with LLMs: Balancing Short-Term and Long-Term Preferences for Recommendations",
    "url": "https://arxiv.org/abs/2508.08454",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08454v1 Announce Type: new \nAbstract: Accurately modeling user preferences is crucial for improving the performance of content-based recommender systems. Existing approaches often rely on simplistic user profiling methods, such as averaging or concatenating item embeddings, which fail to capture the nuanced nature of user preference dynamics, particularly the interactions between long-term and short-term preferences. In this work, we propose LLM-driven Temporal User Profiling (LLM-TUP), a novel method for user profiling that explicitly models short-term and long-term preferences by leveraging interaction timestamps and generating natural language representations of user histories using a large language model (LLM). These representations are encoded into high-dimensional embeddings using a pre-trained BERT model, and an attention mechanism is applied to dynamically fuse the short-term and long-term embeddings into a comprehensive user profile. Experimental results on real-world datasets demonstrate that LLM-TUP achieves substantial improvements over several baselines, underscoring the effectiveness of our temporally aware user-profiling approach and the use of semantically rich user profiles, generated by LLMs, for personalized content-based recommendation.",
    "source": "arXiv"
  },
  {
    "title": "Architecting Long-Context LLM Acceleration with Packing-Prefetch Scheduler and Ultra-Large Capacity On-Chip Memories",
    "title_es": "Architecting Long-Context LLM Acceleration with Packing-Prefetch Scheduler and Ultra-Large Capacity On-Chip Memories",
    "url": "https://arxiv.org/abs/2508.08457",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08457v1 Announce Type: new \nAbstract: Long-context Large Language Model (LLM) inference faces increasing compute bottlenecks as attention calculations scale with context length, primarily due to the growing KV-cache transfer overhead that saturates High Bandwidth Memory (HBM). While prefetching techniques mitigate cache misses by fetching KV data in advance, their spatial and temporal benefits present new opportunities to exploit. This work proposes a packing-prefetch scheduling architecture with monolithic 3D (M3D) back-end-of-line (BEOL) compatible embedded memories with ultra-large on-chip capacity to accelerate long-context LLM inference. Our optimizations demonstrate 8.06x decode speedup and 1.83x overall latency reduction on Llama3.1-8B using TPUv6e-like hardware with additional 512MB BEOL memories over the serial execution. Evaluations of multi-request workloads on TPU-like architectures show 1.7x-2.4x throughput improvement and 1.5x-2.4x HBM bandwidth reduction compared to packing-only methods on Llama3.1-8B and Llama3.1-70B models. With the co-design of packing, prefetching, and BEOL memories, our approach alleviates HBM constraints and enables efficient long-context LLM inference.",
    "source": "arXiv"
  },
  {
    "title": "Discrete Diffusion-Based Model-Level Explanation of Heterogeneous GNNs with Node Features",
    "title_es": "Discrete Diffusion-Based Model-Level Explanation of Heterogeneous GNNs with Node Features",
    "url": "https://arxiv.org/abs/2508.08458",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08458v1 Announce Type: new \nAbstract: Many real-world datasets, such as citation networks, social networks, and molecular structures, are naturally represented as heterogeneous graphs, where nodes belong to different types and have additional features. For example, in a citation network, nodes representing \"Paper\" or \"Author\" may include attributes like keywords or affiliations. A critical machine learning task on these graphs is node classification, which is useful for applications such as fake news detection, corporate risk assessment, and molecular property prediction. Although Heterogeneous Graph Neural Networks (HGNNs) perform well in these contexts, their predictions remain opaque. Existing post-hoc explanation methods lack support for actual node features beyond one-hot encoding of node type and often fail to generate realistic, faithful explanations. To address these gaps, we propose DiGNNExplainer, a model-level explanation approach that synthesizes heterogeneous graphs with realistic node features via discrete denoising diffusion. In particular, we generate realistic discrete features (e.g., bag-of-words features) using diffusion models within a discrete space, whereas previous approaches are limited to continuous spaces. We evaluate our approach on multiple datasets and show that DiGNNExplainer produces explanations that are realistic and faithful to the model's decision-making, outperforming state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "Designing with Deception: ML- and Covert Gate-Enhanced Camouflaging to Thwart IC Reverse Engineering",
    "title_es": "Designing with Deception: ML- and Covert Gate-Enhanced Camouflaging to Thwart IC Reverse Engineering",
    "url": "https://arxiv.org/abs/2508.08462",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08462v1 Announce Type: new \nAbstract: Integrated circuits (ICs) are essential to modern electronic systems, yet they face significant risks from physical reverse engineering (RE) attacks that compromise intellectual property (IP) and overall system security. While IC camouflage techniques have emerged to mitigate these risks, existing approaches largely focus on localized gate modifications, neglecting comprehensive deception strategies. To address this gap, we present a machine learning (ML)-driven methodology that integrates cryptic and mimetic cyber deception principles to enhance IC security against RE. Our approach leverages a novel And-Inverter Graph Variational Autoencoder (AIG-VAE) to encode circuit representations, enabling dual-layered camouflage through functional preservation and appearance mimicry. By introducing new variants of covert gates -- Fake Inverters, Fake Buffers, and Universal Transmitters -- our methodology achieves robust protection by obscuring circuit functionality while presenting misleading appearances. Experimental results demonstrate the effectiveness of our strategy in maintaining circuit functionality while achieving high camouflage and similarity scores with minimal structural overhead. Additionally, we validate the robustness of our method against advanced artificial intelligence (AI)-enhanced RE attacks, highlighting its practical applicability in securing IC designs. By bridging the gap in mimetic deception for hardware security, our work sets a new standard for IC camouflage, advancing the application of cyber deception principles to protect critical systems from adversarial threats.",
    "source": "arXiv"
  },
  {
    "title": "Short Proof: Exact Solution to the Finite Frobenius Coin Problem",
    "title_es": "Short Proof: Exact Solution to the Finite Frobenius Coin Problem",
    "url": "https://arxiv.org/abs/2508.08464",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08464v1 Announce Type: new \nAbstract: The Frobenius Coin Problem is a classic question in mathematics: given coins of specified denominations, what is the largest amount that cannot be formed using only those coins? This brief work covers a variation of such question, posing a limit on the number of coins available for each denomination. Thus, the new problem becomes finding the count of distinct values that can be represented, and those that cannot, within the finite set of integers ranging from zero to the sum of all coins. We refer to this version of the problem as the \"finite\" case. We will show how this closely relates to the original question, and prove an exact formula solving the problem when exactly two denominations are involved.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints",
    "title_es": "Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints",
    "url": "https://arxiv.org/abs/2508.08466",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08466v1 Announce Type: new \nAbstract: Small large language models (LLMs) often face difficulties in aligning output to human preferences, particularly when operating under severe performance gaps. In this work, we propose two lightweight DPO-based variants -- Adaptive Margin-Sigmoid Loss and APO-hinge-zero -- to better address underperformance scenarios by introducing margin-based objectives and selective update mechanisms.\n  Our APO-hinge-zero method, which combines hinge-induced hard-example mining with the chosen-focused optimization of APO-zero, achieves strong results. In AlpacaEval, APO-hinge-zero improves the win rate by +2.0 points and the length-controlled win rate by +1.4 points compared to the APO-zero baseline. In MT-Bench, our methods maintain competitive performance in diverse categories, particularly excelling in STEM and Humanities tasks.\n  These results demonstrate that simple modifications to preference-based objectives can significantly enhance small LLM alignment under resource constraints, offering a practical path toward more efficient deployment.",
    "source": "arXiv"
  },
  {
    "title": "Empowering Children to Create AI-Enabled Augmented Reality Experiences",
    "title_es": "Empowering Children to Create AI-Enabled Augmented Reality Experiences",
    "url": "https://arxiv.org/abs/2508.08467",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08467v1 Announce Type: new \nAbstract: Despite their potential to enhance children's learning experiences, AI-enabled AR technologies are predominantly used in ways that position children as consumers rather than creators. We introduce Capybara, an AR-based and AI-powered visual programming environment that empowers children to create, customize, and program 3D characters overlaid onto the physical world. Capybara enables children to create virtual characters and accessories using text-to-3D generative AI models, and to animate these characters through auto-rigging and body tracking. In addition, our system employs vision-based AI models to recognize physical objects, allowing children to program interactive behaviors between virtual characters and their physical surroundings. We demonstrate the expressiveness of Capybara through a set of novel AR experiences. We conducted user studies with 20 children in the United States and Argentina. Our findings suggest that Capybara can empower children to harness AI in authoring personalized and engaging AR experiences that seamlessly bridge the virtual and physical worlds.",
    "source": "arXiv"
  },
  {
    "title": "Audio-Visual Speech Enhancement: Architectural Design and Deployment Strategies",
    "title_es": "Audio-Visual Speech Enhancement: Architectural Design and Deployment Strategies",
    "url": "https://arxiv.org/abs/2508.08468",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08468v1 Announce Type: new \nAbstract: This paper introduces a new AI-based Audio-Visual Speech Enhancement (AVSE) system and presents a comparative performance analysis of different deployment architectures. The proposed AVSE system employs convolutional neural networks (CNNs) for spectral feature extraction and long short-term memory (LSTM) networks for temporal modeling, enabling robust speech enhancement through multimodal fusion of audio and visual cues. Multiple deployment scenarios are investigated, including cloud-based, edge-assisted, and standalone device implementations. Their performance is evaluated in terms of speech quality improvement, latency, and computational overhead. Real-world experiments are conducted across various network conditions, including Ethernet, Wi-Fi, 4G, and 5G, to analyze the trade-offs between processing delay, communication latency, and perceptual speech quality. The results show that while cloud deployment achieves the highest enhancement quality, edge-assisted architectures offer the best balance between latency and intelligibility, meeting real-time requirements under 5G and Wi-Fi 6 conditions. These findings provide practical guidelines for selecting and optimizing AVSE deployment architectures in diverse applications, including assistive hearing devices, telepresence, and industrial communications.",
    "source": "arXiv"
  },
  {
    "title": "Vector-Centric Machine Learning Systems: A Cross-Stack Approach",
    "title_es": "Vector-Centric Machine Learning Systems: A Cross-Stack Approach",
    "url": "https://arxiv.org/abs/2508.08469",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08469v1 Announce Type: new \nAbstract: Today, two major trends are shaping the evolution of ML systems. First, modern AI systems are becoming increasingly complex, often integrating components beyond the model itself. A notable example is Retrieval-Augmented Generation (RAG), which incorporates not only multiple models but also vector databases, leading to heterogeneity in both system components and underlying hardware. Second, with the end of Moore's Law, achieving high system efficiency is no longer feasible without accounting for the rapid evolution of the hardware landscape.\n  Building on the observations above, this thesis adopts a cross-stack approach to improving ML system efficiency, presenting solutions that span algorithms, systems, and hardware. First, it introduces several pioneering works about RAG serving efficiency across the computing stack. PipeRAG focuses on algorithm-level improvements, RAGO introduces system-level optimizations, and Chameleon explores heterogeneous accelerator systems for RAG. Second, this thesis investigates algorithm-hardware co-design for vector search. Specifically, FANNS and Falcon optimize quantization-based and graph-based vector search, the two most popular paradigms of retrieval algorithms. Third, this thesis addresses the serving efficiency of recommender systems, another example of vector-centric ML systems, where the memory-intensive lookup operations on embedding vector tables often represent a major performance bottleneck. MicroRec and FleetRec propose solutions at the hardware and system levels, respectively, optimizing both data movement and computation to enhance the efficiency of large-scale recommender models.",
    "source": "arXiv"
  },
  {
    "title": "A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems",
    "title_es": "A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems",
    "url": "https://arxiv.org/abs/2508.08473",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08473v1 Announce Type: new \nAbstract: Collective behaviors such as swarming and flocking emerge from simple, decentralized interactions in biological systems. Existing models, such as Vicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber model imposes rigid formations, limiting their applicability in swarm robotics. To address these limitations, this paper proposes a minimal yet expressive model that governs agent dynamics using relative positions, velocities, and local density, modulated by two tunable parameters: the spatial offset and kinetic offset. The model achieves spatially flexible, collision-free behaviors that reflect naturalistic group dynamics. Furthermore, we extend the framework to cognitive autonomous systems, enabling energy-aware phase transitions between swarming and flocking through adaptive control parameter tuning. This cognitively inspired approach offers a robust foundation for real-world applications in multi-robot systems, particularly autonomous aerial swarms.",
    "source": "arXiv"
  },
  {
    "title": "Sparse Partial Optimal Transport via Quadratic Regularization",
    "title_es": "Sparse Partial Optimal Transport via Quadratic Regularization",
    "url": "https://arxiv.org/abs/2508.08476",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08476v1 Announce Type: new \nAbstract: Partial Optimal Transport (POT) has recently emerged as a central tool in various Machine Learning (ML) applications. It lifts the stringent assumption of the conventional Optimal Transport (OT) that input measures are of equal masses, which is often not guaranteed in real-world datasets, and thus offers greater flexibility by permitting transport between unbalanced input measures. Nevertheless, existing major solvers for POT commonly rely on entropic regularization for acceleration and thus return dense transport plans, hindering the adoption of POT in various applications that favor sparsity. In this paper, as an alternative approach to the entropic POT formulation in the literature, we propose a novel formulation of POT with quadratic regularization, hence termed quadratic regularized POT (QPOT), which induces sparsity to the transport plan and consequently facilitates the adoption of POT in many applications with sparsity requirements. Extensive experiments on synthetic and CIFAR-10 datasets, as well as real-world applications such as color transfer and domain adaptations, consistently demonstrate the improved sparsity and favorable performance of our proposed QPOT formulation.",
    "source": "arXiv"
  },
  {
    "title": "A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search",
    "title_es": "A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search",
    "url": "https://arxiv.org/abs/2508.08477",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08477v1 Announce Type: new \nAbstract: The Trigger Arc Traveling Salesman Problem (TA-TSP) extends the classical TSP by introducing dynamic arc costs that change when specific \\textit{trigger} arcs are traversed, modeling scenarios such as warehouse operations with compactable storage systems. This paper introduces a GRASP-based metaheuristic that combines multiple construction heuristics with a multi-neighborhood local search. The construction phase uses mixed-integer programming (MIP) techniques to transform the TA-TSP into a sequence of tailored TSP instances, while the improvement phase applies 2-Opt, Swap, and Relocate operators. Computational experiments on MESS 2024 competition instances achieved average optimality gaps of 0.77\\% and 0.40\\% relative to the best-known solutions within a 60-second limit. On smaller, synthetically generated datasets, the method produced solutions 11.3\\% better than the Gurobi solver under the same time constraints. The algorithm finished in the top three at MESS 2024, demonstrating its suitability for real-time routing applications with state-dependent travel costs.",
    "source": "arXiv"
  },
  {
    "title": "Benchmarking Federated Learning for Throughput Prediction in 5G Live Streaming Applications",
    "title_es": "Benchmarking Federated Learning for Throughput Prediction in 5G Live Streaming Applications",
    "url": "https://arxiv.org/abs/2508.08479",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08479v1 Announce Type: new \nAbstract: Accurate and adaptive network throughput prediction is essential for latency-sensitive and bandwidth-intensive applications in 5G and emerging 6G networks. However, most existing methods rely on centralized training with uniformly collected data, limiting their applicability in heterogeneous mobile environments with non-IID data distributions. This paper presents the first comprehensive benchmarking of federated learning (FL) strategies for throughput prediction in realistic 5G edge scenarios. We evaluate three aggregation algorithms - FedAvg, FedProx, and FedBN - across four time-series architectures: LSTM, CNN, CNN+LSTM, and Transformer, using five diverse real-world datasets. We systematically analyze the effects of client heterogeneity, cohort size, and history window length on prediction performance. Our results reveal key trade-offs among model complexities, convergence rates, and generalization. It is found that FedBN consistently delivers robust performance under non-IID conditions. On the other hand, LSTM and Transformer models outperform CNN-based baselines by up to 80% in R2 scores. Moreover, although Transformers converge in half the rounds of LSTM, they require longer history windows to achieve a high R2, indicating higher context dependence. LSTM is, therefore, found to achieve a favorable balance between accuracy, rounds, and temporal footprint. To validate the end-to-end applicability of the framework, we have integrated our FL-based predictors into a live adaptive streaming pipeline. It is seen that FedBN-based LSTM and Transformer models improve mean QoE scores by 11.7% and 11.4%, respectively, over FedAvg, while also reducing the variance. These findings offer actionable insights for building scalable, privacy-preserving, and edge-aware throughput prediction systems in next-generation wireless networks.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Ordinal Preferences: Why Alignment Needs Cardinal Human Feedback",
    "title_es": "Beyond Ordinal Preferences: Why Alignment Needs Cardinal Human Feedback",
    "url": "https://arxiv.org/abs/2508.08486",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08486v1 Announce Type: new \nAbstract: Alignment techniques for LLMs rely on optimizing preference-based objectives -- where these preferences are typically elicited as ordinal, binary choices between responses. Recent work has focused on improving label quality or mitigating particular biases, but we identify a more fundamental limitation: these methods collect the wrong kind of data. We prove an impossibility result: no algorithm relying solely on ordinal comparisons can systematically recover the most preferred model. Intuitively, ordinal data lacks the information needed to resolve tradeoffs -- e.g., fixing a factual error on one prompt versus improving style on another. We show that selecting the optimal model requires recovering preferences over \\emph{models} (rather than just responses), which can only be identified given cardinal feedback about response quality. To address this, we collect and publicly release a dataset of 25,000 cardinal judgments using willingness-to-pay elicitations, a well-established tool from experimental economics. Empirically, we find that incorporating cardinal feedback into preference fine-tuning allows models to prioritize high-impact improvements and outperform ordinal-only methods on downstream benchmarks, such as Arena-Hard.",
    "source": "arXiv"
  },
  {
    "title": "MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling",
    "title_es": "MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling",
    "url": "https://arxiv.org/abs/2508.08487",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08487v1 Announce Type: new \nAbstract: Despite recent advances, long-sequence video generation frameworks still suffer from significant limitations: poor assistive capability, suboptimal visual quality, and limited expressiveness. To mitigate these limitations, we propose MAViS, an end-to-end multi-agent collaborative framework for long-sequence video storytelling. MAViS orchestrates specialized agents across multiple stages, including script writing, shot designing, character modeling, keyframe generation, video animation, and audio generation. In each stage, agents operate under the 3E Principle -- Explore, Examine, and Enhance -- to ensure the completeness of intermediate outputs. Considering the capability limitations of current generative models, we propose the Script Writing Guidelines to optimize compatibility between scripts and generative tools. Experimental results demonstrate that MAViS achieves state-of-the-art performance in assistive capability, visual quality, and video expressiveness. Its modular framework further enables scalability with diverse generative models and tools. With just a brief user prompt, MAViS is capable of producing high-quality, expressive long-sequence video storytelling, enriching inspirations and creativity for users. To the best of our knowledge, MAViS is the only framework that provides multimodal design output -- videos with narratives and background music.",
    "source": "arXiv"
  },
  {
    "title": "MuGa-VTON: Multi-Garment Virtual Try-On via Diffusion Transformers with Prompt Customization",
    "title_es": "MuGa-VTON: Multi-Garment Virtual Try-On via Diffusion Transformers with Prompt Customization",
    "url": "https://arxiv.org/abs/2508.08488",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08488v1 Announce Type: new \nAbstract: Virtual try-on seeks to generate photorealistic images of individuals in desired garments, a task that must simultaneously preserve personal identity and garment fidelity for practical use in fashion retail and personalization. However, existing methods typically handle upper and lower garments separately, rely on heavy preprocessing, and often fail to preserve person-specific cues such as tattoos, accessories, and body shape-resulting in limited realism and flexibility. To this end, we introduce MuGa-VTON, a unified multi-garment diffusion framework that jointly models upper and lower garments together with person identity in a shared latent space. Specifically, we proposed three key modules: the Garment Representation Module (GRM) for capturing both garment semantics, the Person Representation Module (PRM) for encoding identity and pose cues, and the A-DiT fusion module, which integrates garment, person, and text-prompt features through a diffusion transformer. This architecture supports prompt-based customization, allowing fine-grained garment modifications with minimal user input. Extensive experiments on the VITON-HD and DressCode benchmarks demonstrate that MuGa-VTON outperforms existing methods in both qualitative and quantitative evaluations, producing high-fidelity, identity-preserving results suitable for real-world virtual try-on applications.",
    "source": "arXiv"
  },
  {
    "title": "Momentum Point-Perplexity Mechanics in Large Language Models",
    "title_es": "Momentum Point-Perplexity Mechanics in Large Language Models",
    "url": "https://arxiv.org/abs/2508.08492",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08492v1 Announce Type: new \nAbstract: We take a physics-based approach to studying how the internal hidden states of large language models change from token to token during inference. Across 20 open-source transformer models (135M-3B parameters), we find that a quantity combining the rate of change in hidden states and the model's next-token certainty, analogous to energy in physics, remains nearly constant. Random-weight models conserve this \"energy\" more tightly than pre-trained ones, while training shifts models into a faster, more decisive regime with greater variability. Using this \"log-Lagrangian\" view, we derive a control method called Jacobian steering, which perturbs hidden states in the minimal way needed to favor a target token. This approach maintained near-constant energy in two tested models and produced continuations rated higher in semantic quality than the models' natural outputs. Viewing transformers through this mechanics lens offers a principled basis for interpretability, anomaly detection, and low-risk steering. This could help make powerful models more predictable and aligned with human intent.",
    "source": "arXiv"
  },
  {
    "title": "POMO+: Leveraging starting nodes in POMO for solving Capacitated Vehicle Routing Problem",
    "title_es": "POMO+: Leveraging starting nodes in POMO for solving Capacitated Vehicle Routing Problem",
    "url": "https://arxiv.org/abs/2508.08493",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08493v1 Announce Type: new \nAbstract: In recent years, reinforcement learning (RL) methods have emerged as a promising approach for solving combinatorial problems. Among RL-based models, POMO has demonstrated strong performance on a variety of tasks, including variants of the Vehicle Routing Problem (VRP). However, there is room for improvement for these tasks. In this work, we improved POMO, creating a method (\\textbf{POMO+}) that leverages the initial nodes to find a solution in a more informed way. We ran experiments on our new model and observed that our solution converges faster and achieves better results. We validated our models on the CVRPLIB dataset and noticed improvements in problem instances with up to 100 customers. We hope that our research in this project can lead to further advancements in the field.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Computation of Dominant Eigenvalues Using Adaptive Block Lanczos with Chebyshev Filtering",
    "title_es": "Efficient Computation of Dominant Eigenvalues Using Adaptive Block Lanczos with Chebyshev Filtering",
    "url": "https://arxiv.org/abs/2508.08495",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08495v1 Announce Type: new \nAbstract: We present an efficient method for computing dominant eigenvalues of large, nonsymmetric, diagonalizable matrices based on an adaptive block Lanczos algorithm combined with Chebyshev polynomial filtering. The proposed approach improves numerical stability through two key components: (i) the Adaptive Block Lanczos (ABLE) method, which maintains biorthogonality using SVD based stabilization, and (ii) Chebyshev filtering, which enhances spectral separation via iterative polynomial filtering. Numerical experiments on dense and sparse test problems confirm the effectiveness of the ABLE Chebyshev algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Solving Set Constraints with Comprehensions and Bounded Quantifiers",
    "title_es": "Solving Set Constraints with Comprehensions and Bounded Quantifiers",
    "url": "https://arxiv.org/abs/2508.08496",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08496v1 Announce Type: new \nAbstract: Many real applications problems can be encoded easily as quantified formulas in SMT. However, this simplicity comes at the cost of difficulty during solving by SMT solvers. Different strategies and quantifier instantiation techniques have been developed to tackle this. However, SMT solvers still struggle with quantified formulas generated by some applications. In this paper, we discuss the use of set-bounded quantifiers, quantifiers whose variable ranges over a finite set. These quantifiers can be implemented using quantifier-free fragment of the theory of finite relations with a filter operator, a form of restricted comprehension, that constructs a subset from a finite set using a predicate. We show that this approach outperforms other quantification techniques in satisfiable problems generated by the SLEEC tool, and is very competitive on unsatisfiable benchmarks compared to LEGOS, a specialized solver for SLEEC. We also identify a decidable class of constraints with restricted applications of the filter operator, while showing that unrestricted applications lead to undecidability.",
    "source": "arXiv"
  },
  {
    "title": "CObL: Toward Zero-Shot Ordinal Layering without User Prompting",
    "title_es": "CObL: Toward Zero-Shot Ordinal Layering without User Prompting",
    "url": "https://arxiv.org/abs/2508.08498",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08498v1 Announce Type: new \nAbstract: Vision benefits from grouping pixels into objects and understanding their spatial relationships, both laterally and in depth. We capture this with a scene representation comprising an occlusion-ordered stack of \"object layers,\" each containing an isolated and amodally-completed object. To infer this representation from an image, we introduce a diffusion-based architecture named Concurrent Object Layers (CObL). CObL generates a stack of object layers in parallel, using Stable Diffusion as a prior for natural objects and inference-time guidance to ensure the inferred layers composite back to the input image. We train CObL using a few thousand synthetically-generated images of multi-object tabletop scenes, and we find that it zero-shot generalizes to photographs of real-world tabletops with varying numbers of novel objects. In contrast to recent models for amodal object completion, CObL reconstructs multiple occluded objects without user prompting and without knowing the number of objects beforehand. Unlike previous models for unsupervised object-centric representation learning, CObL is not limited to the world it was trained in.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models as Oracles for Ontology Alignment",
    "title_es": "Large Language Models as Oracles for Ontology Alignment",
    "url": "https://arxiv.org/abs/2508.08500",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08500v1 Announce Type: new \nAbstract: Ontology alignment plays a crucial role in integrating diverse data sources across domains. There is a large plethora of systems that tackle the ontology alignment problem, yet challenges persist in producing highly quality correspondences among a set of input ontologies. Human-in-the-loop during the alignment process is essential in applications requiring very accurate mappings. User involvement is, however, expensive when dealing with large ontologies. In this paper, we explore the feasibility of using Large Language Models (LLM) as an alternative to the domain expert. The use of the LLM focuses only on the validation of the subset of correspondences where an ontology alignment system is very uncertain. We have conducted an extensive evaluation over several matching tasks of the Ontology Alignment Evaluation Initiative (OAEI), analysing the performance of several state-of-the-art LLMs using different ontology-driven prompt templates. The LLM results are also compared against simulated Oracles with variable error rates.",
    "source": "arXiv"
  },
  {
    "title": "GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games",
    "title_es": "GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games",
    "url": "https://arxiv.org/abs/2508.08501",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08501v1 Announce Type: new \nAbstract: We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning and problem-solving capabilities of large language models (LLMs). Built on the General Video Game AI framework, it features a diverse collection of arcade-style games designed to test a model's ability to handle tasks that differ from most existing LLM benchmarks. The benchmark leverages a game description language that enables rapid creation of new games and levels, helping to prevent overfitting over time. Each game scene is represented by a compact set of ASCII characters, allowing for efficient processing by language models. GVGAI-LLM defines interpretable metrics, including the meaningful step ratio, step efficiency, and overall score, to assess model behavior. Through zero-shot evaluations across a broad set of games and levels with diverse challenges and skill depth, we reveal persistent limitations of LLMs in spatial reasoning and basic planning. Current models consistently exhibit spatial and logical errors, motivating structured prompting and spatial grounding techniques. While these interventions lead to partial improvements, the benchmark remains very far from solved. GVGAI-LLM provides a reproducible testbed for advancing research on language model capabilities, with a particular emphasis on agentic behavior and contextual reasoning.",
    "source": "arXiv"
  },
  {
    "title": "AirSignatureDB: Exploring In-Air Signature Biometrics in the Wild and its Privacy Concerns",
    "title_es": "AirSignatureDB: Exploring In-Air Signature Biometrics in the Wild and its Privacy Concerns",
    "url": "https://arxiv.org/abs/2508.08502",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08502v1 Announce Type: new \nAbstract: Behavioral biometrics based on smartphone motion sensors are growing in popularity for authentication purposes. In this study, AirSignatureDB is presented: a new publicly accessible dataset of in-air signatures collected from 108 participants under real-world conditions, using 83 different smartphone models across four sessions. This dataset includes genuine samples and skilled forgeries, enabling a comprehensive evaluation of system robustness against realistic attack scenarios. Traditional and deep learning-based methods for in-air signature verification are benchmarked, while analyzing the influence of sensor modality and enrollment strategies. Beyond verification, a first approach to reconstructing the three-dimensional trajectory of in-air signatures from inertial sensor data alone is introduced. Using on-line handwritten signatures as a reference, we demonstrate that the recovery of accurate trajectories is feasible, challenging the long-held assumption that in-air gestures are inherently traceless. Although this approach enables forensic traceability, it also raises critical questions about the privacy boundaries of behavioral biometrics. Our findings underscore the need for a reevaluation of the privacy assumptions surrounding inertial sensor data, as they can reveal user-specific information that had not previously been considered in the design of in-air signature systems.",
    "source": "arXiv"
  },
  {
    "title": "JSPIM: A Skew-Aware PIM Accelerator for High-Performance Databases Join and Select Operations",
    "title_es": "JSPIM: A Skew-Aware PIM Accelerator for High-Performance Databases Join and Select Operations",
    "url": "https://arxiv.org/abs/2508.08503",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08503v1 Announce Type: new \nAbstract: Database applications are increasingly bottlenecked by memory bandwidth and latency due to the memory wall and the limited scalability of DRAM. Join queries, central to analytical workloads, require intensive memory access and are particularly vulnerable to inefficiencies in data movement. While Processing-in-Memory (PIM) offers a promising solution, existing designs typically reuse CPU-oriented join algorithms, limiting parallelism and incurring costly inter-chip communication. Additionally, data skew, a main challenge in CPU-based joins, remains unresolved in current PIM architectures.\n  We introduce JSPIM, a PIM module that accelerates hash join and, by extension, corresponding select queries through algorithm-hardware co-design. JSPIM deploys parallel search engines within each subarray and redesigns hash tables to achieve O(1) lookups, fully exploiting PIM's fine-grained parallelism. To mitigate skew, our design integrates subarray-level parallelism with rank-level processing, eliminating redundant off-chip transfers. Evaluations show JSPIM delivers 400x to 1000x speedup on join queries versus DuckDB. When paired with DuckDB for the full SSB benchmark, JSPIM achieves an overall 2.5x throughput improvement (individual query gains of 1.1x to 28x), at just a 7% data overhead and 2.1% per-rank PIM-enabled chip area increase.",
    "source": "arXiv"
  },
  {
    "title": "When the Domain Expert Has No Time and the LLM Developer Has No Clinical Expertise: Real-World Lessons from LLM Co-Design in a Safety-Net Hospital",
    "title_es": "When the Domain Expert Has No Time and the LLM Developer Has No Clinical Expertise: Real-World Lessons from LLM Co-Design in a Safety-Net Hospital",
    "url": "https://arxiv.org/abs/2508.08504",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08504v1 Announce Type: new \nAbstract: Large language models (LLMs) have the potential to address social and behavioral determinants of health by transforming labor intensive workflows in resource-constrained settings. Creating LLM-based applications that serve the needs of underserved communities requires a deep understanding of their local context, but it is often the case that neither LLMs nor their developers possess this local expertise, and the experts in these communities often face severe time/resource constraints. This creates a disconnect: how can one engage in meaningful co-design of an LLM-based application for an under-resourced community when the communication channel between the LLM developer and domain expert is constrained? We explored this question through a real-world case study, in which our data science team sought to partner with social workers at a safety net hospital to build an LLM application that summarizes patients' social needs. Whereas prior works focus on the challenge of prompt tuning, we found that the most critical challenge in this setting is the careful and precise specification of \\what information to surface to providers so that the LLM application is accurate, comprehensive, and verifiable. Here we present a novel co-design framework for settings with limited access to domain experts, in which the summary generation task is first decomposed into individually-optimizable attributes and then each attribute is efficiently refined and validated through a multi-tier cascading approach.",
    "source": "arXiv"
  },
  {
    "title": "Adaptique: Multi-objective and Context-aware Online Adaptation of Selection Techniques in Virtual Reality",
    "title_es": "Adaptique: Multi-objective and Context-aware Online Adaptation of Selection Techniques in Virtual Reality",
    "url": "https://arxiv.org/abs/2508.08505",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08505v1 Announce Type: new \nAbstract: Selection is a fundamental task that is challenging in virtual reality due to issues such as distant and small targets, occlusion, and target-dense environments. Previous research has tackled these challenges through various selection techniques, but complicates selection and can be seen as tedious outside of their designed use case. We present Adaptique, an adaptive model that infers and switches to the most optimal selection technique based on user and environmental information. Adaptique considers contextual information such as target size, distance, occlusion, and user posture combined with four objectives: speed, accuracy, comfort, and familiarity which are based on fundamental predictive models of human movement for technique selection. This enables Adaptique to select simple techniques when they are sufficiently efficient and more advanced techniques when necessary. We show that Adaptique is more preferred and performant than single techniques in a user study, and demonstrate Adaptique's versatility in an application.",
    "source": "arXiv"
  },
  {
    "title": "AZRA: Extending the Affective Capabilities of Zoomorphic Robots using Augmented Reality",
    "title_es": "AZRA: Extending the Affective Capabilities of Zoomorphic Robots using Augmented Reality",
    "url": "https://arxiv.org/abs/2508.08507",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08507v1 Announce Type: new \nAbstract: Zoomorphic robots could serve as accessible and practical alternatives for users unable or unwilling to keep pets. However, their affective interactions are often simplistic and short-lived, limiting their potential for domestic adoption. In order to facilitate more dynamic and nuanced affective interactions and relationships between users and zoomorphic robots we present AZRA, a novel augmented reality (AR) framework that extends the affective capabilities of these robots without physical modifications. To demonstrate AZRA, we augment a zoomorphic robot, Petit Qoobo, with novel emotional displays (face, light, sound, thought bubbles) and interaction modalities (voice, touch, proximity, gaze). Additionally, AZRA features a computational model of emotion to calculate the robot's emotional responses, daily moods, evolving personality and needs. We highlight how AZRA can be used for rapid participatory prototyping and enhancing existing robots, then discuss implications on future zoomorphic robot development.",
    "source": "arXiv"
  },
  {
    "title": "Re:Verse -- Can Your VLM Read a Manga?",
    "title_es": "Re:Verse -- Can Your VLM Read a Manga?",
    "url": "https://arxiv.org/abs/2508.08508",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08508v1 Announce Type: new \nAbstract: Current Vision Language Models (VLMs) demonstrate a critical gap between surface-level recognition and deep narrative reasoning when processing sequential visual storytelling. Through a comprehensive investigation of manga narrative understanding, we reveal that while recent large multimodal models excel at individual panel interpretation, they systematically fail at temporal causality and cross-panel cohesion, core requirements for coherent story comprehension. We introduce a novel evaluation framework that combines fine-grained multimodal annotation, cross-modal embedding analysis, and retrieval-augmented assessment to systematically characterize these limitations.\n  Our methodology includes (i) a rigorous annotation protocol linking visual elements to narrative structure through aligned light novel text, (ii) comprehensive evaluation across multiple reasoning paradigms, including direct inference and retrieval-augmented generation, and (iii) cross-modal similarity analysis revealing fundamental misalignments in current VLMs' joint representations. Applying this framework to Re:Zero manga across 11 chapters with 308 annotated panels, we conduct the first systematic study of long-form narrative understanding in VLMs through three core evaluation axes: generative storytelling, contextual dialogue grounding, and temporal reasoning. Our findings demonstrate that current models lack genuine story-level intelligence, struggling particularly with non-linear narratives, character consistency, and causal inference across extended sequences. This work establishes both the foundation and practical methodology for evaluating narrative intelligence, while providing actionable insights into the capability of deep sequential understanding of Discrete Visual Narratives beyond basic recognition in Multimodal Models.",
    "source": "arXiv"
  },
  {
    "title": "Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression",
    "title_es": "Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression",
    "url": "https://arxiv.org/abs/2508.08509",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08509v1 Announce Type: new \nAbstract: Large language models (LLMs) are currently aligned using techniques such as reinforcement learning from human feedback (RLHF). However, these methods use scalar rewards that can only reflect user preferences on average. Pluralistic alignment instead seeks to capture diverse user preferences across a set of attributes, moving beyond just helpfulness and harmlessness. Toward this end, we propose a steerable pluralistic model based on few-shot comparative regression that can adapt to individual user preferences. Our approach leverages in-context learning and reasoning, grounded in a set of fine-grained attributes, to compare response options and make aligned choices. To evaluate our algorithm, we also propose two new steerable pluralistic benchmarks by adapting the Moral Integrity Corpus (MIC) and the HelpSteer2 datasets, demonstrating the applicability of our approach to value-aligned decision-making and reward modeling, respectively. Our few-shot comparative regression approach is interpretable and compatible with different attributes and LLMs, while outperforming multiple baseline and state-of-the-art methods. Our work provides new insights and research directions in pluralistic alignment, enabling a more fair and representative use of LLMs and advancing the state-of-the-art in ethical AI.",
    "source": "arXiv"
  },
  {
    "title": "Using LLMs to Capture Users' Temporal Context for Recommendation",
    "title_es": "Using LLMs to Capture Users' Temporal Context for Recommendation",
    "url": "https://arxiv.org/abs/2508.08512",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08512v1 Announce Type: new \nAbstract: Effective recommender systems demand dynamic user understanding, especially in complex, evolving environments. Traditional user profiling often fails to capture the nuanced, temporal contextual factors of user preferences, such as transient short-term interests and enduring long-term tastes. This paper presents an assessment of Large Language Models (LLMs) for generating semantically rich, time-aware user profiles. We do not propose a novel end-to-end recommendation architecture; instead, the core contribution is a systematic investigation into the degree of LLM effectiveness in capturing the dynamics of user context by disentangling short-term and long-term preferences. This approach, framing temporal preferences as dynamic user contexts for recommendations, adaptively fuses these distinct contextual components into comprehensive user embeddings. The evaluation across Movies&TV and Video Games domains suggests that while LLM-generated profiles offer semantic depth and temporal structure, their effectiveness for context-aware recommendations is notably contingent on the richness of user interaction histories. Significant gains are observed in dense domains (e.g., Movies&TV), whereas improvements are less pronounced in sparse environments (e.g., Video Games). This work highlights LLMs' nuanced potential in enhancing user profiling for adaptive, context-aware recommendations, emphasizing the critical role of dataset characteristics for practical applicability.",
    "source": "arXiv"
  },
  {
    "title": "DeCAL Tokenwise Compression",
    "title_es": "DeCAL Tokenwise Compression",
    "url": "https://arxiv.org/abs/2508.08514",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08514v1 Announce Type: new \nAbstract: This paper introduces DeCAL, a new method for tokenwise compression. DeCAL uses an encoder-decoder language model pretrained with denoising to learn to produce high-quality, general-purpose compressed representations by the encoder. DeCAL applies small modifications to the encoder, with the emphasis on maximizing compression quality, even at the expense of compute. We show that DeCAL at 2x compression can match uncompressed on many downstream tasks, with usually only minor dropoff in metrics up to 8x compression, among question-answering, summarization, and multi-vector retrieval tasks. DeCAL offers significant savings where pre-computed dense representations can be utilized, and we believe the approach can be further developed to be more broadly applicable.",
    "source": "arXiv"
  },
  {
    "title": "SharpXR: Structure-Aware Denoising for Pediatric Chest X-Rays",
    "title_es": "SharpXR: Structure-Aware Denoising for Pediatric Chest X-Rays",
    "url": "https://arxiv.org/abs/2508.08518",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08518v1 Announce Type: new \nAbstract: Pediatric chest X-ray imaging is essential for early diagnosis, particularly in low-resource settings where advanced imaging modalities are often inaccessible. Low-dose protocols reduce radiation exposure in children but introduce substantial noise that can obscure critical anatomical details. Conventional denoising methods often degrade fine details, compromising diagnostic accuracy. In this paper, we present SharpXR, a structure-aware dual-decoder U-Net designed to denoise low-dose pediatric X-rays while preserving diagnostically relevant features. SharpXR combines a Laplacian-guided edge-preserving decoder with a learnable fusion module that adaptively balances noise suppression and structural detail retention. To address the scarcity of paired training data, we simulate realistic Poisson-Gaussian noise on the Pediatric Pneumonia Chest X-ray dataset. SharpXR outperforms state-of-the-art baselines across all evaluation metrics while maintaining computational efficiency suitable for resource-constrained settings. SharpXR-denoised images improved downstream pneumonia classification accuracy from 88.8% to 92.5%, underscoring its diagnostic value in low-resource pediatric care.",
    "source": "arXiv"
  },
  {
    "title": "VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models",
    "title_es": "VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.08521",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08521v1 Announce Type: new \nAbstract: Vision Language Models (VLMs) are increasingly being used in a broad range of applications, bringing their security and behavioral control to the forefront. While existing approaches for behavioral control or output redirection, like system prompting in VLMs, are easily detectable and often ineffective, activation-based steering vectors require invasive runtime access to model internals--incompatible with API-based services and closed-source deployments. We introduce VISOR (Visual Input-based Steering for Output Redirection), a novel method that achieves sophisticated behavioral control through optimized visual inputs alone. By crafting universal steering images that induce target activation patterns, VISOR enables practical deployment across all VLM serving modalities while remaining imperceptible compared to explicit textual instructions. We validate VISOR on LLaVA-1.5-7B across three critical alignment tasks: refusal, sycophancy and survival instinct. A single 150KB steering image matches steering vector performance within 1-2% for positive behavioral shifts while dramatically exceeding it for negative steering--achieving up to 25% shifts from baseline compared to steering vectors' modest changes. Unlike system prompting (3-4% shifts), VISOR provides robust bidirectional control while maintaining 99.9% performance on 14,000 unrelated MMLU tasks. Beyond eliminating runtime overhead and model access requirements, VISOR exposes a critical security vulnerability: adversaries can achieve sophisticated behavioral manipulation through visual channels alone, bypassing text-based defenses. Our work fundamentally re-imagines multimodal model control and highlights the urgent need for defenses against visual steering attacks.",
    "source": "arXiv"
  },
  {
    "title": "StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI",
    "title_es": "StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI",
    "url": "https://arxiv.org/abs/2508.08524",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08524v1 Announce Type: new \nAbstract: Interactive streetscape mapping tools such as Google Street View (GSV) and Meta Mapillary enable users to virtually navigate and experience real-world environments via immersive 360{\\deg} imagery but remain fundamentally inaccessible to blind users. We introduce StreetViewAI, the first-ever accessible street view tool, which combines context-aware, multimodal AI, accessible navigation controls, and conversational speech. With StreetViewAI, blind users can virtually examine destinations, engage in open-world exploration, or virtually tour any of the over 220 billion images and 100+ countries where GSV is deployed. We iteratively designed StreetViewAI with a mixed-visual ability team and performed an evaluation with eleven blind users. Our findings demonstrate the value of an accessible street view in supporting POI investigations and remote route planning. We close by enumerating key guidelines for future work.",
    "source": "arXiv"
  },
  {
    "title": "A Reinforcement Learning-Driven Task Scheduling Algorithm for Multi-Tenant Distributed Systems",
    "title_es": "A Reinforcement Learning-Driven Task Scheduling Algorithm for Multi-Tenant Distributed Systems",
    "url": "https://arxiv.org/abs/2508.08525",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08525v1 Announce Type: new \nAbstract: This paper addresses key challenges in task scheduling for multi-tenant distributed systems, including dynamic resource variation, heterogeneous tenant demands, and fairness assurance. An adaptive scheduling method based on reinforcement learning is proposed. By modeling the scheduling process as a Markov decision process, the study defines the state space, action space, and reward function. A scheduling policy learning framework is designed using Proximal Policy Optimization (PPO) as the core algorithm. This enables dynamic perception of complex system states and real-time decision-making. Under a multi-objective reward mechanism, the scheduler jointly optimizes task latency, resource utilization, and tenant fairness. The coordination between the policy network and the value network continuously refines the scheduling strategy. This enhances overall system performance. To validate the effectiveness of the proposed method, a series of experiments were conducted in multi-scenario environments built using a real-world public dataset. The experiments evaluated task latency control, resource efficiency, policy stability, and fairness. The results show that the proposed method outperforms existing scheduling approaches across multiple evaluation metrics. It demonstrates strong stability and generalization ability. The proposed scheduling framework provides practical and engineering value in policy design, dynamic resource modeling, and multi-tenant service assurance. It effectively improves scheduling efficiency and resource management in distributed systems under complex conditions.",
    "source": "arXiv"
  },
  {
    "title": "Playing Atari Space Invaders with Sparse Cosine Optimized Policy Evolution",
    "title_es": "Playing Atari Space Invaders with Sparse Cosine Optimized Policy Evolution",
    "url": "https://arxiv.org/abs/2508.08526",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08526v1 Announce Type: new \nAbstract: Evolutionary approaches have previously been shown to be effective learning methods for a diverse set of domains. However, the domain of game-playing poses a particular challenge for evolutionary methods due to the inherently large state space of video games. As the size of the input state expands, the size of the policy must also increase in order to effectively learn the temporal patterns in the game space. Consequently, a larger policy must contain more trainable parameters, exponentially increasing the size of the search space. Any increase in search space is highly problematic for evolutionary methods, as increasing the number of trainable parameters is inversely correlated with convergence speed. To reduce the size of the input space while maintaining a meaningful representation of the original space, we introduce Sparse Cosine Optimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine Transform (DCT) as a pseudo attention mechanism, transforming an input state into a coefficient matrix. By truncating and applying sparsification to this matrix, we reduce the dimensionality of the input space while retaining the highest energy features of the original input. We demonstrate the effectiveness of SCOPE as the policy for the Atari game Space Invaders. In this task, SCOPE with CMA-ES outperforms evolutionary methods that consider an unmodified input state, such as OpenAI-ES and HyperNEAT. SCOPE also outperforms simple reinforcement learning methods, such as DQN and A3C. SCOPE achieves this result through reducing the input size by 53% from 33,600 to 15,625 then using a bilinear affine mapping of sparse DCT coefficients to policy actions learned by the CMA-ES algorithm.",
    "source": "arXiv"
  },
  {
    "title": "SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering",
    "title_es": "SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering",
    "url": "https://arxiv.org/abs/2508.08529",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08529v1 Announce Type: new \nAbstract: Access to real-world medical data is often restricted due to privacy regulations, posing a significant barrier to the advancement of healthcare research. Synthetic data offers a promising alternative; however, generating realistic, clinically valid, and privacy-conscious records remains a major challenge. Recent advancements in Large Language Models (LLMs) offer new opportunities for structured data generation; however, existing approaches frequently lack systematic prompting strategies and comprehensive, multi-dimensional evaluation frameworks.\n  In this paper, we present SynLLM, a modular framework for generating high-quality synthetic medical tabular data using 20 state-of-the-art open-source LLMs, including LLaMA, Mistral, and GPT variants, guided by structured prompts. We propose four distinct prompt types, ranging from example-driven to rule-based constraints, that encode schema, metadata, and domain knowledge to control generation without model fine-tuning. Our framework features a comprehensive evaluation pipeline that rigorously assesses generated data across statistical fidelity, clinical consistency, and privacy preservation.\n  We evaluate SynLLM across three public medical datasets, including Diabetes, Cirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt engineering significantly impacts data quality and privacy risk, with rule-based prompts achieving the best privacy-quality balance. SynLLM establishes that, when guided by well-designed prompts and evaluated with robust, multi-metric criteria, LLMs can generate synthetic medical data that is both clinically plausible and privacy-aware, paving the way for safer and more effective data sharing in healthcare research.",
    "source": "arXiv"
  },
  {
    "title": "Profiling Large Language Model Inference on Apple Silicon: A Quantization Perspective",
    "title_es": "Profiling Large Language Model Inference on Apple Silicon: A Quantization Perspective",
    "url": "https://arxiv.org/abs/2508.08531",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08531v1 Announce Type: new \nAbstract: A systematic understanding of Apple Silicon is lacking in the current landscape of hardware efficiency; research focus is largely centered on accelerating GPUs for large-scale training or inference on CUDA devices. This paper investigates Apple Silicon's unique memory architecture that offers a unified memory integrating CPU and GPU memory and its implications for on-device LLM inference.\n  We decipher myths about whether Apple Silicon is efficient for on-device inference compared to competitors such as NVIDIA GPUs by directly conducting latency and throughput comparison benchmarks. We explain the performance gap between them through profiling low level hardware metrics - ALU utilization, memory bandwidth, buffer usage, cache residency etc. at runtime. We draw several insights regarding performance bottlenecks such as dequantization overhead, compute throughput and memory bandwidth. We debunk existing false claims regarding large language model inference such as compressing models to lower bit precision is a defacto promise for faster inference across all hardware platforms. We find that the large unified memory enables Apple Silicon to be both cost effective and efficient against NVIDIA GPUs for ultra large language models.\n  Our large scale evaluation on 5 hardware testbeds incorporating three Apple M-series devices: M2 Ultra, M2 Max and M4 Pro and two NVIDIA GPUs: NVIDIA RTX A6000, a multi GPU setup with 2xNVIDIA RTX A6000, 5 model scales ranging from 8B to 405B parameters and 14 quantization schemes gives an understanding of how Apple Silicon fits within the paradigm of on-device LLM inference. Our analysis reveals multiple resource interdependencies and unexpected findings, while also quantifying established insights. To the best of our knowledge, this study makes the first attempt to present a thorough characterization and analysis of Apple Silicon for on-device inference.",
    "source": "arXiv"
  },
  {
    "title": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework",
    "title_es": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework",
    "url": "https://arxiv.org/abs/2508.08535",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08535v1 Announce Type: new \nAbstract: Wireless Body Area Networks (WBANs) enable continuous monitoring of physiological signals for applications ranging from chronic disease management to emergency response. Recent advances in 6G communications, post-quantum cryptography, and energy harvesting have the potential to enhance WBAN performance. However, integrating these technologies into a unified, adaptive system remains a challenge. This paper surveys some of the most well-known Wireless Body Area Network (WBAN) architectures, routing strategies, and security mechanisms, identifying key gaps in adaptability, energy efficiency, and quantum-resistant security. We propose a novel Large Language Model-driven adaptive WBAN framework in which a Large Language Model acts as a cognitive control plane, coordinating routing, physical layer selection, micro-energy harvesting, and post-quantum security in real time. Our review highlights the limitations of current heuristic-based designs and outlines a research agenda for resource-constrained, 6G-ready medical systems. This approach aims to enable ultra-reliable, secure, and self-optimizing WBANs for next-generation mobile health applications.",
    "source": "arXiv"
  },
  {
    "title": "Training Kindai OCR with parallel textline images and self-attention feature distance-based loss",
    "title_es": "Training Kindai OCR with parallel textline images and self-attention feature distance-based loss",
    "url": "https://arxiv.org/abs/2508.08537",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08537v1 Announce Type: new \nAbstract: Kindai documents, written in modern Japanese from the late 19th to early 20th century, hold significant historical value for researchers studying societal structures, daily life, and environmental conditions of that period. However, transcribing these documents remains a labor-intensive and time-consuming task, resulting in limited annotated data for training optical character recognition (OCR) systems. This research addresses this challenge of data scarcity by leveraging parallel textline images - pairs of original Kindai text and their counterparts in contemporary Japanese fonts - to augment training datasets. We introduce a distance-based objective function that minimizes the gap between self-attention features of the parallel image pairs. Specifically, we explore Euclidean distance and Maximum Mean Discrepancy (MMD) as domain adaptation metrics. Experimental results demonstrate that our method reduces the character error rate (CER) by 2.23% and 3.94% over a Transformer-based OCR baseline when using Euclidean distance and MMD, respectively. Furthermore, our approach improves the discriminative quality of self-attention representations, leading to more effective OCR performance for historical documents.",
    "source": "arXiv"
  },
  {
    "title": "Biased Local SGD for Efficient Deep Learning on Heterogeneous Systems",
    "title_es": "Biased Local SGD for Efficient Deep Learning on Heterogeneous Systems",
    "url": "https://arxiv.org/abs/2508.08540",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08540v1 Announce Type: new \nAbstract: Most large-scale neural network training methods assume homogeneous parallel computing resources. For example, synchronous SGD with data parallelism, the most widely used parallel training strategy, incurs significant synchronization overhead when workers process their assigned data at different speeds. Consequently, in systems with heterogeneous compute resources, users often rely solely on the fastest components, such as GPUs, for training. In this work, we explore how to effectively use heterogeneous resources for neural network training. We propose a system-aware local stochastic gradient descent (local SGD) method that allocates workloads to each compute resource in proportion to its compute capacity. To make better use of slower resources such as CPUs, we intentionally introduce bias into data sampling and model aggregation. Our study shows that well-controlled bias can significantly accelerate local SGD in heterogeneous environments, achieving comparable or even higher accuracy than synchronous SGD with data-parallelism within the same time budget. This fundamental parallelization strategy can be readily extended to diverse heterogeneous environments, including cloud platforms and multi-node high-performance computing clusters.",
    "source": "arXiv"
  },
  {
    "title": "Hybrid Long and Short Range Flows for Point Cloud Filtering",
    "title_es": "Hybrid Long and Short Range Flows for Point Cloud Filtering",
    "url": "https://arxiv.org/abs/2508.08542",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08542v1 Announce Type: new \nAbstract: Point cloud capture processes are error-prone and introduce noisy artifacts that necessitate filtering/denoising. Recent filtering methods often suffer from point clustering or noise retaining issues. In this paper, we propose Hybrid Point Cloud Filtering ($\\textbf{HybridPF}$) that considers both short-range and long-range filtering trajectories when removing noise. It is well established that short range scores, given by $\\nabla_{x}\\log p(x_t)$, may provide the necessary displacements to move noisy points to the underlying clean surface. By contrast, long range velocity flows approximate constant displacements directed from a high noise variant patch $x_0$ towards the corresponding clean surface $x_1$. Here, noisy patches $x_t$ are viewed as intermediate states between the high noise variant and the clean patches. Our intuition is that long range information from velocity flow models can guide the short range scores to align more closely with the clean points. In turn, score models generally provide a quicker convergence to the clean surface. Specifically, we devise two parallel modules, the ShortModule and LongModule, each consisting of an Encoder-Decoder pair to respectively account for short-range scores and long-range flows. We find that short-range scores, guided by long-range features, yield filtered point clouds with good point distributions and convergence near the clean surface. We design a joint loss function to simultaneously train the ShortModule and LongModule, in an end-to-end manner. Finally, we identify a key weakness in current displacement based methods, limitations on the decoder architecture, and propose a dynamic graph convolutional decoder to improve the inference process. Comprehensive experiments demonstrate that our HybridPF achieves state-of-the-art results while enabling faster inference speed.",
    "source": "arXiv"
  },
  {
    "title": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction",
    "title_es": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction",
    "url": "https://arxiv.org/abs/2508.08543",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08543v1 Announce Type: new \nAbstract: Achieving accurate traffic prediction is a fundamental but crucial task in the development of current intelligent transportation systems.Most of the mainstream methods that have made breakthroughs in traffic prediction rely on spatio-temporal graph neural networks, spatio-temporal attention mechanisms, etc. The main challenges of the existing deep learning approaches are that they either depend on a complete traffic network structure or require intricate model designs to capture complex spatio-temporal dependencies. These limitations pose significant challenges for the efficient deployment and operation of deep learning models on large-scale datasets. To address these challenges, we propose a cost-effective graph-free Multilayer Perceptron (MLP) based model M3-Net for traffic prediction. Our proposed model not only employs time series and spatio-temporal embeddings for efficient feature processing but also first introduces a novel MLP-Mixer architecture with a mixture of experts (MoE) mechanism. Extensive experiments conducted on multiple real datasets demonstrate the superiority of the proposed model in terms of prediction performance and lightweight deployment.",
    "source": "arXiv"
  },
  {
    "title": "AI Agents and the Law",
    "title_es": "AI Agents and the Law",
    "url": "https://arxiv.org/abs/2508.08544",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08544v1 Announce Type: new \nAbstract: As AI becomes more \"agentic,\" it faces technical and socio-legal issues it must address if it is to fulfill its promise of increased economic productivity and efficiency. This paper uses technical and legal perspectives to explain how things change when AI systems start being able to directly execute tasks on behalf of a user. We show how technical conceptions of agents track some, but not all, socio-legal conceptions of agency. That is, both computer science and the law recognize the problems of under-specification for an agent, and both disciplines have robust conceptions of how to address ensuring an agent does what the programmer, or in the law, the principal desires and no more. However, to date, computer science has under-theorized issues related to questions of loyalty and to third parties that interact with an agent, both of which are central parts of the law of agency. First, we examine the correlations between implied authority in agency law and the principle of value-alignment in AI, wherein AI systems must operate under imperfect objective specification. Second, we reveal gaps in the current computer science view of agents pertaining to the legal concepts of disclosure and loyalty, and how failure to account for them can result in unintended effects in AI ecommerce agents. In surfacing these gaps, we show a path forward for responsible AI agent development and deployment.",
    "source": "arXiv"
  },
  {
    "title": "OmniLLP: Enhancing LLM-based Log Level Prediction with Context-Aware Retrieval",
    "title_es": "OmniLLP: Enhancing LLM-based Log Level Prediction with Context-Aware Retrieval",
    "url": "https://arxiv.org/abs/2508.08545",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08545v1 Announce Type: new \nAbstract: Developers insert logging statements in source code to capture relevant runtime information essential for maintenance and debugging activities. Log level choice is an integral, yet tricky part of the logging activity as it controls log verbosity and therefore influences systems' observability and performance. Recent advances in ML-based log level prediction have leveraged large language models (LLMs) to propose log level predictors (LLPs) that demonstrated promising performance improvements (AUC between 0.64 and 0.8). Nevertheless, current LLM-based LLPs rely on randomly selected in-context examples, overlooking the structure and the diverse logging practices within modern software projects. In this paper, we propose OmniLLP, a novel LLP enhancement framework that clusters source files based on (1) semantic similarity reflecting the code's functional purpose, and (2) developer ownership cohesion. By retrieving in-context learning examples exclusively from these semantic and ownership aware clusters, we aim to provide more coherent prompts to LLPs leveraging LLMs, thereby improving their predictive accuracy. Our results show that both semantic and ownership-aware clusterings statistically significantly improve the accuracy (by up to 8\\% AUC) of the evaluated LLM-based LLPs compared to random predictors (i.e., leveraging randomly selected in-context examples from the whole project). Additionally, our approach that combines the semantic and ownership signal for in-context prediction achieves an impressive 0.88 to 0.96 AUC across our evaluated projects. Our findings highlight the value of integrating software engineering-specific context, such as code semantic and developer ownership signals into LLM-LLPs, offering developers a more accurate, contextually-aware approach to logging and therefore, enhancing system maintainability and observability.",
    "source": "arXiv"
  },
  {
    "title": "Calibration Attention: Instance-wise Temperature Scaling for Vision Transformers",
    "title_es": "Calibration Attention: Instance-wise Temperature Scaling for Vision Transformers",
    "url": "https://arxiv.org/abs/2508.08547",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08547v1 Announce Type: new \nAbstract: Probability calibration is critical when Vision Transformers are deployed in risk-sensitive applications. The standard fix, post-hoc temperature scaling, uses a single global scalar and requires a held-out validation set. We introduce Calibration Attention (CalAttn), a drop-in module that learns an adaptive, per-instance temperature directly from the ViT's CLS token. Across CIFAR-10/100, MNIST, Tiny-ImageNet, and ImageNet-1K, CalAttn reduces calibration error by up to 4x on ViT-224, DeiT, and Swin, while adding under 0.1 percent additional parameters. The learned temperatures cluster tightly around 1.0, in contrast to the large global values used by standard temperature scaling. CalAttn is simple, efficient, and architecture-agnostic, and yields more trustworthy probabilities without sacrificing accuracy. Code: [https://github.com/EagleAdelaide/CalibrationAttention-CalAttn-](https://github.com/EagleAdelaide/CalibrationAttention-CalAttn-)",
    "source": "arXiv"
  },
  {
    "title": "Boosting Generic Semi-Supervised Medical Image Segmentation via Diverse Teaching and Label Propagation",
    "title_es": "Boosting Generic Semi-Supervised Medical Image Segmentation via Diverse Teaching and Label Propagation",
    "url": "https://arxiv.org/abs/2508.08549",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08549v1 Announce Type: new \nAbstract: Both limited annotation and domain shift are significant challenges frequently encountered in medical image segmentation, leading to derivative scenarios like semi-supervised medical (SSMIS), semi-supervised medical domain generalization (Semi-MDG) and unsupervised medical domain adaptation (UMDA). Conventional methods are generally tailored to specific tasks in isolation, the error accumulation hinders the effective utilization of unlabeled data and limits further improvements, resulting in suboptimal performance when these issues occur. In this paper, we aim to develop a generic framework that masters all three tasks. We found that the key to solving the problem lies in how to generate reliable pseudo labels for the unlabeled data in the presence of domain shift with labeled data and increasing the diversity of the model. To tackle this issue, we employ a Diverse Teaching and Label Propagation Network (DTLP-Net) to boosting the Generic Semi-Supervised Medical Image Segmentation. Our DTLP-Net involves a single student model and two diverse teacher models, which can generate reliable pseudo-labels for the student model. The first teacher model decouple the training process with labeled and unlabeled data, The second teacher is momentum-updated periodically, thus generating reliable yet divers pseudo-labels. To fully utilize the information within the data, we adopt inter-sample and intra-sample data augmentation to learn the global and local knowledge. In addition, to further capture the voxel-level correlations, we propose label propagation to enhance the model robust. We evaluate our proposed framework on five benchmark datasets for SSMIS, UMDA, and Semi-MDG tasks. The results showcase notable improvements compared to state-of-the-art methods across all five settings, indicating the potential of our framework to tackle more challenging SSL scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization",
    "title_es": "Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization",
    "url": "https://arxiv.org/abs/2508.08550",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08550v1 Announce Type: new \nAbstract: Video dubbing aims to translate original speech in visual media programs from the source language to the target language, relying on neural machine translation and text-to-speech technologies. Due to varying information densities across languages, target speech often mismatches the source speech duration, causing audio-video synchronization issues that significantly impact viewer experience. In this study, we approach duration alignment in LLM-based video dubbing machine translation as a preference optimization problem. We propose the Segment Supervised Preference Optimization (SSPO) method, which employs a segment-wise sampling strategy and fine-grained loss to mitigate duration mismatches between source and target lines. Experimental results demonstrate that SSPO achieves superior performance in duration alignment tasks.",
    "source": "arXiv"
  },
  {
    "title": "UQGNN: Uncertainty Quantification of Graph Neural Networks for Multivariate Spatiotemporal Prediction",
    "title_es": "UQGNN: Uncertainty Quantification of Graph Neural Networks for Multivariate Spatiotemporal Prediction",
    "url": "https://arxiv.org/abs/2508.08551",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08551v1 Announce Type: new \nAbstract: Spatiotemporal prediction plays a critical role in numerous real-world applications such as urban planning, transportation optimization, disaster response, and pandemic control. In recent years, researchers have made significant progress by developing advanced deep learning models for spatiotemporal prediction. However, most existing models are deterministic, i.e., predicting only the expected mean values without quantifying uncertainty, leading to potentially unreliable and inaccurate outcomes. While recent studies have introduced probabilistic models to quantify uncertainty, they typically focus on a single phenomenon (e.g., taxi, bike, crime, or traffic crashes), thereby neglecting the inherent correlations among heterogeneous urban phenomena. To address the research gap, we propose a novel Graph Neural Network with Uncertainty Quantification, termed UQGNN for multivariate spatiotemporal prediction. UQGNN introduces two key innovations: (i) an Interaction-aware Spatiotemporal Embedding Module that integrates a multivariate diffusion graph convolutional network and an interaction-aware temporal convolutional network to effectively capture complex spatial and temporal interaction patterns, and (ii) a multivariate probabilistic prediction module designed to estimate both expected mean values and associated uncertainties. Extensive experiments on four real-world multivariate spatiotemporal datasets from Shenzhen, New York City, and Chicago demonstrate that UQGNN consistently outperforms state-of-the-art baselines in both prediction accuracy and uncertainty quantification. For example, on the Shenzhen dataset, UQGNN achieves a 5% improvement in both prediction accuracy and uncertainty quantification.",
    "source": "arXiv"
  },
  {
    "title": "SHEFL: Resource-Aware Aggregation and Sparsification in Heterogeneous Ensemble Federated Learning",
    "title_es": "SHEFL: Resource-Aware Aggregation and Sparsification in Heterogeneous Ensemble Federated Learning",
    "url": "https://arxiv.org/abs/2508.08552",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08552v1 Announce Type: new \nAbstract: Federated learning enables distributed training with private data of clients, but its convergence is hindered by data and system heterogeneity in realistic communication scenarios. Most existing system heterogeneous FL schemes utilize global pruning or ensemble distillation, yet they often overlook typical constraints required for communication efficiency. Meanwhile, deep ensembles can aggregate predictions from individually trained models to improve performance, but current ensemble-based FL methods fall short in fully capturing the diversity of model predictions. In this work, we propose SHEFL, a global ensemble-based federated learning framework suited for clients with diverse computational capacities. We allocate different numbers of global models to clients based on their available resources. We further introduce a novel aggregation scheme that accounts for bias between clients with different computational capabilities. To reduce the computational burden of training deep ensembles and mitigate data bias, we dynamically adjust the resource ratio across clients - aggressively reducing the influence of underpowered clients in constrained scenarios, while increasing their weight in the opposite case. Extensive experiments demonstrate that our method effectively addresses computational heterogeneity, significantly improving both fairness and overall performance compared to existing approaches.",
    "source": "arXiv"
  },
  {
    "title": "Explore, Listen, Inspect: Supporting Multimodal Interaction with 3D Surface and Point Data Visualizations",
    "title_es": "Explore, Listen, Inspect: Supporting Multimodal Interaction with 3D Surface and Point Data Visualizations",
    "url": "https://arxiv.org/abs/2508.08554",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08554v1 Announce Type: new \nAbstract: Blind and low-vision (BLV) users remain largely excluded from three-dimensional (3D) surface and point data visualizations due to the reliance on visual interaction. Existing approaches inadequately support non-visual access, especially in browser-based environments. This study introduces DIXTRAL, a hosted web-native system, co-designed with BLV researchers to address these gaps through multimodal interaction. Conducted with two blind and one sighted researcher, this study took place over sustained design sessions. Data were gathered through iterative testing of the prototype, collecting feedback on spatial navigation, sonification, and usability. Co-design observations demonstrate that synchronized auditory, visual, and textual feedback, combined with keyboard and gamepad navigation, enhances both structure discovery and orientation. DIXTRAL aims to improve access to 3D continuous scalar fields for BLV users and inform best practices for creating inclusive 3D visualizations.",
    "source": "arXiv"
  },
  {
    "title": "Traffic Load-Aware Resource Management Strategy for Underwater Wireless Sensor Networks",
    "title_es": "Traffic Load-Aware Resource Management Strategy for Underwater Wireless Sensor Networks",
    "url": "https://arxiv.org/abs/2508.08555",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08555v1 Announce Type: new \nAbstract: Underwater Wireless Sensor Networks (UWSNs) represent a promising technology that enables diverse underwater applications through acoustic communication. However, it encounters significant challenges including harsh communication environments, limited energy supply, and restricted signal transmission. This paper aims to provide efficient and reliable communication in underwater networks with limited energy and communication resources by optimizing the scheduling of communication links and adjusting transmission parameters (e.g., transmit power and transmission rate). The efficient and reliable communication multi-objective optimization problem (ERCMOP) is formulated as a decentralized partially observable Markov decision process (Dec-POMDP). A Traffic Load-Aware Resource Management (TARM) strategy based on deep multi-agent reinforcement learning (MARL) is presented to address this problem. Specifically, a traffic load-aware mechanism that leverages the overhear information from neighboring nodes is designed to mitigate the disparity between partial observations and global states. Moreover, by incorporating a solution space optimization algorithm, the number of candidate solutions for the deep MARL-based decision-making model can be effectively reduced, thereby optimizing the computational complexity. Simulation results demonstrate the adaptability of TARM in various scenarios with different transmission demands and collision probabilities, while also validating the effectiveness of the proposed approach in supporting efficient and reliable communication in underwater networks with limited resources.",
    "source": "arXiv"
  },
  {
    "title": "Unlocking the Potential of Diffusion Priors in Blind Face Restoration",
    "title_es": "Unlocking the Potential of Diffusion Priors in Blind Face Restoration",
    "url": "https://arxiv.org/abs/2508.08556",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08556v1 Announce Type: new \nAbstract: Although diffusion prior is rising as a powerful solution for blind face restoration (BFR), the inherent gap between the vanilla diffusion model and BFR settings hinders its seamless adaptation. The gap mainly stems from the discrepancy between 1) high-quality (HQ) and low-quality (LQ) images and 2) synthesized and real-world images. The vanilla diffusion model is trained on images with no or less degradations, whereas BFR handles moderately to severely degraded images. Additionally, LQ images used for training are synthesized by a naive degradation model with limited degradation patterns, which fails to simulate complex and unknown degradations in real-world scenarios. In this work, we use a unified network FLIPNET that switches between two modes to resolve specific gaps. In Restoration mode, the model gradually integrates BFR-oriented features and face embeddings from LQ images to achieve authentic and faithful face restoration. In Degradation mode, the model synthesizes real-world like degraded images based on the knowledge learned from real-world degradation datasets. Extensive evaluations on benchmark datasets show that our model 1) outperforms previous diffusion prior based BFR methods in terms of authenticity and fidelity, and 2) outperforms the naive degradation model in modeling the real-world degradations.",
    "source": "arXiv"
  },
  {
    "title": "Fast adaptive tubal rank-revealing algorithm for t-product based tensor approximation",
    "title_es": "Fast adaptive tubal rank-revealing algorithm for t-product based tensor approximation",
    "url": "https://arxiv.org/abs/2508.08557",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08557v1 Announce Type: new \nAbstract: Color images and video sequences can be modeled as three-way tensors, which admit low tubal-rank approximations via convex surrogate minimization. This optimization problem is efficiently addressed by tensor singular value thresholding (t-SVT). To mitigate the computational burden of tensor singular value decomposition (t-SVD) in each iteration, this paper introduces an adaptive randomized algorithm for tubal rank revelation in data tensors \\(\\mathcal{A}\\). Our method selectively captures the principal information from frontal slices in the Fourier domain using a predefined threshold, obviating the need for priori tubal-rank and Fourier-domain singular values estimations while providing an explicit tensor approximation. Leveraging optimality results from matrix randomized SVD, we establish theoretical guarantees demonstrating that the proposed algorithm computes low tubal-rank approximations within constants dependent on data dimensions and the Fourier-domain singular value gap. Empirical evaluations validate its efficacy in image processing and background modeling tasks.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Target Backdoor Attacks Against Speaker Recognition",
    "title_es": "Multi-Target Backdoor Attacks Against Speaker Recognition",
    "url": "https://arxiv.org/abs/2508.08559",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08559v1 Announce Type: new \nAbstract: In this work, we propose a multi-target backdoor attack against speaker identification using position-independent clicking sounds as triggers. Unlike previous single-target approaches, our method targets up to 50 speakers simultaneously, achieving success rates of up to 95.04%. To simulate more realistic attack conditions, we vary the signal-to-noise ratio between speech and trigger, demonstrating a trade-off between stealth and effectiveness. We further extend the attack to the speaker verification task by selecting the most similar training speaker - based on cosine similarity - as the target. The attack is most effective when target and enrolled speaker pairs are highly similar, reaching success rates of up to 90% in such cases.",
    "source": "arXiv"
  },
  {
    "title": "Revisiting the City Tower Project: Geometric Principles and Structural Morphology in the Works of Louis I. Kahn and Anne Tyng",
    "title_es": "Revisiting the City Tower Project: Geometric Principles and Structural Morphology in the Works of Louis I. Kahn and Anne Tyng",
    "url": "https://arxiv.org/abs/2508.08561",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08561v1 Announce Type: new \nAbstract: This paper presents a study of computation and morphology of Louis Kahn City Tower project. The City Tower is an unbuilt design by Louis I. Kahn and Anne Tyng that integrates form and structure using 3D space triangular geometries. Although never built, the City Tower geometrical framework anticipated later developments in design of space-frame structures. Initially envisioned in the 1950s, the City Tower project is a skyscraper structure based on a tetrahedral and octahedral space frame called Octet-Truss. The aim of this study is to analyze the geometry of the City Tower structure and how it can be used to develop modular and adaptable architectural forms. The study is based on an analytical shape grammar that is used to recreate the original structure, and later to generate new structural configurations based on the City Tower's morphology. This study also investigates the potential applications of these findings in architecture and reveals the possibilities of using tetrahedrons and octahedrons as fundamental geometries for creating scalable and modular designs and presents initial findings.",
    "source": "arXiv"
  },
  {
    "title": "Think as Cardiac Sonographers: Marrying SAM with Left Ventricular Indicators Measurements According to Clinical Guidelines",
    "title_es": "Think as Cardiac Sonographers: Marrying SAM with Left Ventricular Indicators Measurements According to Clinical Guidelines",
    "url": "https://arxiv.org/abs/2508.08566",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08566v1 Announce Type: new \nAbstract: Left ventricular (LV) indicator measurements following clinical echocardiog-raphy guidelines are important for diagnosing cardiovascular disease. Alt-hough existing algorithms have explored automated LV quantification, they can struggle to capture generic visual representations due to the normally small training datasets. Therefore, it is necessary to introduce vision founda-tional models (VFM) with abundant knowledge. However, VFMs represented by the segment anything model (SAM) are usually suitable for segmentation but incapable of identifying key anatomical points, which are critical in LV indicator measurements. In this paper, we propose a novel framework named AutoSAME, combining the powerful visual understanding of SAM with seg-mentation and landmark localization tasks simultaneously. Consequently, the framework mimics the operation of cardiac sonographers, achieving LV indi-cator measurements consistent with clinical guidelines. We further present fil-tered cross-branch attention (FCBA) in AutoSAME, which leverages relatively comprehensive features in the segmentation to enhance the heatmap regression (HR) of key points from the frequency domain perspective, optimizing the vis-ual representation learned by the latter. Moreover, we propose spatial-guided prompt alignment (SGPA) to automatically generate prompt embeddings guid-ed by spatial properties of LV, thereby improving the accuracy of dense pre-dictions by prior spatial knowledge. The extensive experiments on an echocar-diography dataset demonstrate the efficiency of each design and the superiori-ty of our AutoSAME in LV segmentation, landmark localization, and indicator measurements. The code will be available at https://github.com/QC-LIU-1997/AutoSAME.",
    "source": "arXiv"
  },
  {
    "title": "Achievable Rates of Nanopore-based DNA Storage",
    "title_es": "Achievable Rates of Nanopore-based DNA Storage",
    "url": "https://arxiv.org/abs/2508.08567",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08567v1 Announce Type: new \nAbstract: This paper studies achievable rates of nanopore-based DNA storage when nanopore signals are decoded using a tractable channel model that does not rely on a basecalling algorithm. Specifically, the noisy nanopore channel (NNC) with the Scrappie pore model generates average output levels via i.i.d. geometric sample duplications corrupted by i.i.d. Gaussian noise (NNC-Scrappie). Simplified message passing algorithms are derived for efficient soft decoding of nanopore signals using NNC-Scrappie. Previously, evaluation of this channel model was limited by the lack of DNA storage datasets with nanopore signals included. This is solved by deriving an achievable rate based on the dynamic time-warping (DTW) algorithm that can be applied to genomic sequencing datasets subject to constraints that make the resulting rate applicable to DNA storage. Using a publicly-available dataset from Oxford Nanopore Technologies (ONT), it is demonstrated that coding over multiple DNA strands of $100$ bases in length and decoding with the NNC-Scrappie decoder can achieve rates of at least $0.64-1.18$ bits per base, depending on the channel quality of the nanopore that is chosen in the sequencing device per channel-use, and $0.96$ bits per base on average assuming uniformly chosen nanopores. These rates are pessimistic since they only apply to single reads and do not include calibration of the pore model to specific nanopores.",
    "source": "arXiv"
  },
  {
    "title": "Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation",
    "title_es": "Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation",
    "url": "https://arxiv.org/abs/2508.08570",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08570v1 Announce Type: new \nAbstract: To enhance group robustness to spurious correlations, prior work often relies on auxiliary annotations for groups or spurious features and assumes identical sets of groups across source and target domains. These two requirements are both unnatural and impractical in real-world settings. To overcome these limitations, we propose a method that leverages the semantic structure inherent in class labels--specifically, superclass information--to naturally reduce reliance on spurious features. Our model employs gradient-based attention guided by a pre-trained vision-language model to disentangle superclass-relevant and irrelevant features. Then, by promoting the use of all superclass-relevant features for prediction, our approach achieves robustness to more complex spurious correlations without the need to annotate any source samples. Experiments across diverse datasets demonstrate that our method significantly outperforms baselines in domain generalization tasks, with clear improvements in both quantitative metrics and qualitative visualizations.",
    "source": "arXiv"
  },
  {
    "title": "Bio-Generative Design Morphology with Radiolaria: An application of a Nature-Based Generative Shape Grammar for Geometrical Design of Space Frames",
    "title_es": "Bio-Generative Design Morphology with Radiolaria: An application of a Nature-Based Generative Shape Grammar for Geometrical Design of Space Frames",
    "url": "https://arxiv.org/abs/2508.08572",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08572v1 Announce Type: new \nAbstract: This paper presents a study on using Radiolaria as a basis for generation of space-based geometry for structural design with shape grammars. Radiolaria has been a source of inspiration for architectural design with its intricate structural features and geometric patterns (Lim, 2012). We use the basis of the Radiolaria geometry to create a generative shape grammar as a computational system; then use the shape grammar to create spatial configurations for potential applications in design of 3D space structural frames. This study begins with the geometric analysis of Radiolaria and the dissection of its structure and geometry into a simplified morphological source, in this case a tetrahedral structure. Tetrahedrons are used in combination with octahedrons to generate spatial configurations to generate 3D spatial structural frames. The paper presents the Radiolaria spatial analysis, the shape grammar, the collection of generated designs, and possible applications in space frame structures.",
    "source": "arXiv"
  },
  {
    "title": "Who pays the RENT? Implications of Spatial Inequality for Prediction-Based Allocation Policies",
    "title_es": "Who pays the RENT? Implications of Spatial Inequality for Prediction-Based Allocation Policies",
    "url": "https://arxiv.org/abs/2508.08573",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08573v1 Announce Type: new \nAbstract: AI-powered scarce resource allocation policies rely on predictions to target either specific individuals (e.g., high-risk) or settings (e.g., neighborhoods). Recent research on individual-level targeting demonstrates conflicting results; some models show that targeting is not useful when inequality is high, while other work demonstrates potential benefits. To study and reconcile this apparent discrepancy, we develop a stylized framework based on the Mallows model to understand how the spatial distribution of inequality affects the effectiveness of door-to-door outreach policies. We introduce the RENT (Relative Efficiency of Non-Targeting) metric, which we use to assess the effectiveness of targeting approaches compared with neighborhood-based approaches in preventing tenant eviction when high-risk households are more versus less spatially concentrated. We then calibrate the model parameters to eviction court records collected in a medium-sized city in the USA. Results demonstrate considerable gains in the number of high-risk households canvassed through individually targeted policies, even in a highly segregated metro area with concentrated risks of eviction. We conclude that apparent discrepancies in the prior literature can be reconciled by considering 1) the source of deployment costs and 2) the observed versus modeled concentrations of risk. Our results inform the deployment of AI-based solutions in social service provision that account for particular applications and geographies.",
    "source": "arXiv"
  },
  {
    "title": "DeepFleet: Multi-Agent Foundation Models for Mobile Robots",
    "title_es": "DeepFleet: Multi-Agent Foundation Models for Mobile Robots",
    "url": "https://arxiv.org/abs/2508.08574",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08574v1 Announce Type: new \nAbstract: We introduce DeepFleet, a suite of foundation models designed to support coordination and planning for large-scale mobile robot fleets. These models are trained on fleet movement data, including robot positions, goals, and interactions, from hundreds of thousands of robots in Amazon warehouses worldwide. DeepFleet consists of four architectures that each embody a distinct inductive bias and collectively explore key points in the design space for multi-agent foundation models: the robot-centric (RC) model is an autoregressive decision transformer operating on neighborhoods of individual robots; the robot-floor (RF) model uses a transformer with cross-attention between robots and the warehouse floor; the image-floor (IF) model applies convolutional encoding to a multi-channel image representation of the full fleet; and the graph-floor (GF) model combines temporal attention with graph neural networks for spatial relationships. In this paper, we describe these models and present our evaluation of the impact of these design choices on prediction task performance. We find that the robot-centric and graph-floor models, which both use asynchronous robot state updates and incorporate the localized structure of robot interactions, show the most promise. We also present experiments that show that these two models can make effective use of larger warehouses operation datasets as the models are scaled up.",
    "source": "arXiv"
  },
  {
    "title": "Developing a Calibrated Physics-Based Digital Twin for Construction Vehicles",
    "title_es": "Developing a Calibrated Physics-Based Digital Twin for Construction Vehicles",
    "url": "https://arxiv.org/abs/2508.08576",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08576v1 Announce Type: new \nAbstract: This paper presents the development of a calibrated digital twin of a wheel loader. A calibrated digital twin integrates a construction vehicle with a high-fidelity digital model allowing for automated diagnostics and optimization of operations as well as pre-planning simulations enhancing automation capabilities. The high-fidelity digital model is a virtual twin of the physical wheel loader. It uses a physics-based multibody dynamic model of the wheel loader in the software AGX Dynamics. Interactions of the wheel loader's bucket while in use in construction can be simulated in the virtual model. Calibration makes this simulation of high-fidelity which can enhance realistic planning for automation of construction operations. In this work, a wheel loader was instrumented with several sensors used to calibrate the digital model. The calibrated digital twin was able to estimate the magnitude of the forces on the bucket base with high accuracy, providing a high-fidelity simulation.",
    "source": "arXiv"
  },
  {
    "title": "DeePConverter: A Data-Driven Optimal Control Architecture for Grid-Connected Power Converters",
    "title_es": "DeePConverter: A Data-Driven Optimal Control Architecture for Grid-Connected Power Converters",
    "url": "https://arxiv.org/abs/2508.08578",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08578v1 Announce Type: new \nAbstract: Grid-connected power converters are ubiquitous in modern power systems, acting as grid interfaces of renewable energy sources, energy storage systems, electric vehicles, high-voltage DC systems, etc. Conventionally, power converters use multiple PID regulators to achieve different control objectives such as grid synchronization and voltage/power regulations, where the PID parameters are usually tuned based on a presumed (and often overly-simplified) power grid model. However, this may lead to inferior performance or even instabilities in practice, as the real power grid is highly complex, variable, and generally unknown. To tackle this problem, we employ a data-enabled predictive control (DeePC) to perform data-driven, optimal, and robust control for power converters. We call the converters that are operated in this way \\textit{DeePConverters}. A DeePConverter can implicitly perceive the characteristics of the power grid from data and adjust its control strategy to achieve optimal and robust performance. We present the modular configurations, generalized structure, control behavior specification, detailed implementation, and computation of DeePConverters. High-fidelity simulations and hardware-in-the-loop (HIL) tests are provided to validate the effectiveness of DeePConverters.",
    "source": "arXiv"
  },
  {
    "title": "CoSight: Exploring Viewer Contributions to Online Video Accessibility Through Descriptive Commenting",
    "title_es": "CoSight: Exploring Viewer Contributions to Online Video Accessibility Through Descriptive Commenting",
    "url": "https://arxiv.org/abs/2508.08582",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08582v1 Announce Type: new \nAbstract: The rapid growth of online video content has outpaced efforts to make visual information accessible to blind and low vision (BLV) audiences. While professional Audio Description (AD) remains the gold standard, it is costly and difficult to scale across the vast volume of online media. In this work, we explore a complementary approach to broaden participation in video accessibility: engaging everyday video viewers at their watching and commenting time. We introduce CoSight, a Chrome extension that augments YouTube with lightweight, in-situ nudges to support descriptive commenting. Drawing from Fogg's Behavior Model, CoSight provides visual indicators of accessibility gaps, pop-up hints for what to describe, reminders to clarify vague comments, and related captions and comments as references. In an exploratory study with 48 sighted users, CoSight helped integrate accessibility contribution into natural viewing and commenting practices, resulting in 89% of comments including grounded visual descriptions. Follow-up interviews with four BLV viewers and four professional AD writers suggest that while such comments do not match the rigor of professional AD, they can offer complementary value by conveying visual context and emotional nuance for understanding the videos.",
    "source": "arXiv"
  },
  {
    "title": "AI Security Map: Holistic Organization of AI Security Technologies and Impacts on Stakeholders",
    "title_es": "AI Security Map: Holistic Organization of AI Security Technologies and Impacts on Stakeholders",
    "url": "https://arxiv.org/abs/2508.08583",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08583v1 Announce Type: new \nAbstract: As the social implementation of AI has been steadily progressing, research and development related to AI security has also been increasing. However, existing studies have been limited to organizing related techniques, attacks, defenses, and risks in terms of specific domains or AI elements. Thus, it extremely difficult to understand the relationships among them and how negative impacts on stakeholders are brought about. In this paper, we argue that the knowledge, technologies, and social impacts related to AI security should be holistically organized to help understand relationships among them. To this end, we first develop an AI security map that holistically organizes interrelationships among elements related to AI security as well as negative impacts on information systems and stakeholders. This map consists of the two aspects, namely the information system aspect (ISA) and the external influence aspect (EIA). The elements that AI should fulfill within information systems are classified under the ISA. The EIA includes elements that affect stakeholders as a result of AI being attacked or misused. For each element, corresponding negative impacts are identified. By referring to the AI security map, one can understand the potential negative impacts, along with their causes and countermeasures. Additionally, our map helps clarify how the negative impacts on AI-based systems relate to those on stakeholders. We show some findings newly obtained by referring to our map. We also provide several recommendations and open problems to guide future AI security communities.",
    "source": "arXiv"
  },
  {
    "title": "RealisMotion: Decomposed Human Motion Control and Video Generation in the World Space",
    "title_es": "RealisMotion: Decomposed Human Motion Control and Video Generation in the World Space",
    "url": "https://arxiv.org/abs/2508.08588",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08588v1 Announce Type: new \nAbstract: Generating human videos with realistic and controllable motions is a challenging task. While existing methods can generate visually compelling videos, they lack separate control over four key video elements: foreground subject, background video, human trajectory and action patterns. In this paper, we propose a decomposed human motion control and video generation framework that explicitly decouples motion from appearance, subject from background, and action from trajectory, enabling flexible mix-and-match composition of these elements. Concretely, we first build a ground-aware 3D world coordinate system and perform motion editing directly in the 3D space. Trajectory control is implemented by unprojecting edited 2D trajectories into 3D with focal-length calibration and coordinate transformation, followed by speed alignment and orientation adjustment; actions are supplied by a motion bank or generated via text-to-motion methods. Then, based on modern text-to-video diffusion transformer models, we inject the subject as tokens for full attention, concatenate the background along the channel dimension, and add motion (trajectory and action) control signals by addition. Such a design opens up the possibility for us to generate realistic videos of anyone doing anything anywhere. Extensive experiments on benchmark datasets and real-world cases demonstrate that our method achieves state-of-the-art performance on both element-wise controllability and overall video quality.",
    "source": "arXiv"
  },
  {
    "title": "DocThinker: Explainable Multimodal Large Language Models with Rule-based Reinforcement Learning for Document Understanding",
    "title_es": "DocThinker: Explainable Multimodal Large Language Models with Rule-based Reinforcement Learning for Document Understanding",
    "url": "https://arxiv.org/abs/2508.08589",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08589v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in document understanding. However, their reasoning processes remain largely black-box, making it difficult to ensure reliability and trustworthiness, especially in high-stakes domains such as legal, financial, and medical document analysis. Existing methods use fixed Chain-of-Thought (CoT) reasoning with supervised fine-tuning (SFT) but suffer from catastrophic forgetting, poor adaptability, and limited generalization across domain tasks. In this paper, we propose DocThinker, a rule-based Reinforcement Learning (RL) framework for dynamic inference-time reasoning. Instead of relying on static CoT templates, DocThinker autonomously refines reasoning strategies via policy learning, generating explainable intermediate results, including structured reasoning processes, rephrased questions, regions of interest (RoI) supporting the answer, and the final answer. By integrating multi-objective rule-based rewards and KL-constrained optimization, our method mitigates catastrophic forgetting and enhances both adaptability and transparency. Extensive experiments on multiple benchmarks demonstrate that DocThinker significantly improves generalization while producing more explainable and human-understandable reasoning steps. Our findings highlight RL as a powerful alternative for enhancing explainability and adaptability in MLLM-based document understanding. Code will be available at https://github.com/wenwenyu/DocThinker.",
    "source": "arXiv"
  },
  {
    "title": "QueryCraft: Transformer-Guided Query Initialization for Enhanced Human-Object Interaction Detection",
    "title_es": "QueryCraft: Transformer-Guided Query Initialization for Enhanced Human-Object Interaction Detection",
    "url": "https://arxiv.org/abs/2508.08590",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08590v1 Announce Type: new \nAbstract: Human-Object Interaction (HOI) detection aims to localize human-object pairs and recognize their interactions in images. Although DETR-based methods have recently emerged as the mainstream framework for HOI detection, they still suffer from a key limitation: Randomly initialized queries lack explicit semantics, leading to suboptimal detection performance. To address this challenge, we propose QueryCraft, a novel plug-and-play HOI detection framework that incorporates semantic priors and guided feature learning through transformer-based query initialization. Central to our approach is \\textbf{ACTOR} (\\textbf{A}ction-aware \\textbf{C}ross-modal \\textbf{T}ransf\\textbf{OR}mer), a cross-modal Transformer encoder that jointly attends to visual regions and textual prompts to extract action-relevant features. Rather than merely aligning modalities, ACTOR leverages language-guided attention to infer interaction semantics and produce semantically meaningful query representations. To further enhance object-level query quality, we introduce a \\textbf{P}erceptual \\textbf{D}istilled \\textbf{Q}uery \\textbf{D}ecoder (\\textbf{PDQD}), which distills object category awareness from a pre-trained detector to serve as object query initiation. This dual-branch query initialization enables the model to generate more interpretable and effective queries for HOI detection. Extensive experiments on HICO-Det and V-COCO benchmarks demonstrate that our method achieves state-of-the-art performance and strong generalization. Code will be released upon publication.",
    "source": "arXiv"
  },
  {
    "title": "DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives",
    "title_es": "DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives",
    "url": "https://arxiv.org/abs/2508.08591",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08591v1 Announce Type: new \nAbstract: Advances in large language models (LLMs) have enabled a wide range of applications. However, depression prediction is hindered by the lack of large-scale, high-quality, and rigorously annotated datasets. This study introduces DepressLLM, trained and evaluated on a novel corpus of 3,699 autobiographical narratives reflecting both happiness and distress. DepressLLM provides interpretable depression predictions and, via its Score-guided Token Probability Summation (SToPS) module, delivers both improved classification performance and reliable confidence estimates, achieving an AUC of 0.789, which rises to 0.904 on samples with confidence $\\geq$ 0.95. To validate its robustness to heterogeneous data, we evaluated DepressLLM on in-house datasets, including an Ecological Momentary Assessment (EMA) corpus of daily stress and mood recordings, and on public clinical interview data. Finally, a psychiatric review of high-confidence misclassifications highlighted key model and data limitations that suggest directions for future refinements. These findings demonstrate that interpretable AI can enable earlier diagnosis of depression and underscore the promise of medical AI in psychiatry.",
    "source": "arXiv"
  },
  {
    "title": "Fact-Checking at Scale: Multimodal AI for Authenticity and Context Verification in Online Media",
    "title_es": "Fact-Checking at Scale: Multimodal AI for Authenticity and Context Verification in Online Media",
    "url": "https://arxiv.org/abs/2508.08592",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08592v1 Announce Type: new \nAbstract: The proliferation of multimedia content on social media platforms has dramatically transformed how information is consumed and disseminated. While this shift enables real-time coverage of global events, it also facilitates the rapid spread of misinformation and disinformation, especially during crises such as wars, natural disasters, or elections. The rise of synthetic media and the reuse of authentic content in misleading contexts have intensified the need for robust multimedia verification tools. In this paper, we present a comprehensive system developed for the ACM Multimedia 2025 Grand Challenge on Multimedia Verification. Our system assesses the authenticity and contextual accuracy of multimedia content in multilingual settings and generates both expert-oriented verification reports and accessible summaries for the general public. We introduce a unified verification pipeline that integrates visual forensics, textual analysis, and multimodal reasoning, and propose a hybrid approach to detect out-of-context (OOC) media through semantic similarity, temporal alignment, and geolocation cues. Extensive evaluations on the Grand Challenge benchmark demonstrate the system's effectiveness across diverse real-world scenarios. Our contributions advance the state of the art in multimedia verification and offer practical tools for journalists, fact-checkers, and researchers confronting information integrity challenges in the digital age.",
    "source": "arXiv"
  },
  {
    "title": "Generative AI for Critical Infrastructure in Smart Grids: A Unified Framework for Synthetic Data Generation and Anomaly Detection",
    "title_es": "Generative AI for Critical Infrastructure in Smart Grids: A Unified Framework for Synthetic Data Generation and Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.08593",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08593v1 Announce Type: new \nAbstract: In digital substations, security events pose significant challenges to the sustained operation of power systems. To mitigate these challenges, the implementation of robust defense strategies is critically important. A thorough process of anomaly identification and detection in information and communication technology (ICT) frameworks is crucial to ensure secure and reliable communication and coordination between interconnected devices within digital substations. Hence, this paper addresses the critical cybersecurity challenges confronting IEC61850-based digital substations within modern smart grids, where the integration of advanced communication protocols, e.g., generic object-oriented substation event (GOOSE), has enhanced energy management and introduced significant vulnerabilities to cyberattacks. Focusing on the limitations of traditional anomaly detection systems (ADSs) in detecting threats, this research proposes a transformative approach by leveraging generative AI (GenAI) to develop robust ADSs. The primary contributions include the suggested advanced adversarial traffic mutation (AATM) technique to generate synthesized and balanced datasets for GOOSE messages, ensuring protocol compliance and enabling realistic zero-day attack pattern creation to address data scarcity. Then, the implementation of GenAI-based ADSs incorporating the task-oriented dialogue (ToD) processes has been explored for improved detection of attack patterns. Finally, a comparison of the GenAI-based ADS with machine learning (ML)-based ADSs has been implemented to showcase the outperformance of the GenAI-based frameworks considering the AATM-generated GOOSE datasets and standard/advanced performance evaluation metrics.",
    "source": "arXiv"
  },
  {
    "title": "How Conversational Structure and Style Shape Online Community Experiences",
    "title_es": "How Conversational Structure and Style Shape Online Community Experiences",
    "url": "https://arxiv.org/abs/2508.08596",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08596v1 Announce Type: new \nAbstract: Sense of Community (SOC) is vital to individual and collective well-being. Although social interactions have moved increasingly online, still little is known about the specific relationships between the nature of these interactions and Sense of Virtual Community (SOVC). This study addresses this gap by exploring how conversational structure and linguistic style predict SOVC in online communities, using a large-scale survey of 2,826 Reddit users across 281 varied subreddits. We develop a hierarchical model to predict self-reported SOVC based on automatically quantifiable and highly generalizable features that are agnostic to community topic and that describe both individual users and entire communities. We identify specific interaction patterns (e.g., reciprocal reply chains, use of prosocial language) associated with stronger communities and identify three primary dimensions of SOVC within Reddit -- Membership & Belonging, Cooperation & Shared Values, and Connection & Influence. This study provides the first quantitative evidence linking patterns of social interaction to SOVC and highlights actionable strategies for fostering stronger community attachment, using an approach that can generalize readily across community topics, languages, and platforms. These insights offer theoretical implications for the study of online communities and practical suggestions for the design of features to help more individuals experience the positive benefits of online community participation.",
    "source": "arXiv"
  },
  {
    "title": "Yan: Foundational Interactive Video Generation",
    "title_es": "Yan: Foundational Interactive Video Generation",
    "url": "https://arxiv.org/abs/2508.08601",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08601v1 Announce Type: new \nAbstract: We present Yan, a foundational framework for interactive video generation, covering the entire pipeline from simulation and generation to editing. Specifically, Yan comprises three core modules. AAA-level Simulation: We design a highly-compressed, low-latency 3D-VAE coupled with a KV-cache-based shift-window denoising inference process, achieving real-time 1080P/60FPS interactive simulation. Multi-Modal Generation: We introduce a hierarchical autoregressive caption method that injects game-specific knowledge into open-domain multi-modal video diffusion models (VDMs), then transforming the VDM into a frame-wise, action-controllable, real-time infinite interactive video generator. Notably, when the textual and visual prompts are sourced from different domains, the model demonstrates strong generalization, allowing it to blend and compose the style and mechanics across domains flexibly according to user prompts. Multi-Granularity Editing: We propose a hybrid model that explicitly disentangles interactive mechanics simulation from visual rendering, enabling multi-granularity video content editing during interaction through text. Collectively, Yan offers an integration of these modules, pushing interactive video generation beyond isolated capabilities toward a comprehensive AI-driven interactive creation paradigm, paving the way for the next generation of creative tools, media, and entertainment. The project page is: https://greatx3.github.io/Yan/.",
    "source": "arXiv"
  },
  {
    "title": "Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization",
    "title_es": "Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization",
    "url": "https://arxiv.org/abs/2508.08604",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08604v1 Announce Type: new \nAbstract: Vision-Language Models (VLMs) have been widely used in various visual recognition tasks due to their remarkable generalization capabilities. As these models grow in size and complexity, fine-tuning becomes costly, emphasizing the need to reuse adaptation knowledge from 'weaker' models to efficiently enhance 'stronger' ones. However, existing adaptation transfer methods exhibit limited transferability across models due to their model-specific design and high computational demands. To tackle this, we propose Transferable Model-agnostic adapter (TransMiter), a light-weight adapter that improves vision-language models 'without backpropagation'. TransMiter captures the knowledge gap between pre-trained and fine-tuned VLMs, in an 'unsupervised' manner. Once trained, this knowledge can be seamlessly transferred across different models without the need for backpropagation. Moreover, TransMiter consists of only a few layers, inducing a negligible additional inference cost. Notably, supplementing the process with a few labeled data further yields additional performance gain, often surpassing a fine-tuned stronger model, with a marginal training cost. Experimental results and analyses demonstrate that TransMiter effectively and efficiently transfers adaptation knowledge while preserving generalization abilities across VLMs of different sizes and architectures in visual recognition tasks.",
    "source": "arXiv"
  },
  {
    "title": "SelfHVD: Self-Supervised Handheld Video Deblurring for Mobile Phones",
    "title_es": "SelfHVD: Self-Supervised Handheld Video Deblurring for Mobile Phones",
    "url": "https://arxiv.org/abs/2508.08605",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08605v1 Announce Type: new \nAbstract: Shooting video with a handheld mobile phone, the most common photographic device, often results in blurry frames due to shaking hands and other instability factors. Although previous video deblurring methods have achieved impressive progress, they still struggle to perform satisfactorily on real-world handheld video due to the blur domain gap between training and testing data. To address the issue, we propose a self-supervised method for handheld video deblurring, which is driven by sharp clues in the video. First, to train the deblurring model, we extract the sharp clues from the video and take them as misalignment labels of neighboring blurry frames. Second, to improve the model's ability, we propose a novel Self-Enhanced Video Deblurring (SEVD) method to create higher-quality paired video data. Third, we propose a Self-Constrained Spatial Consistency Maintenance (SCSCM) method to regularize the model, preventing position shifts between the output and input frames. Moreover, we construct a synthetic and a real-world handheld video dataset for handheld video deblurring. Extensive experiments on these two and other common real-world datasets demonstrate that our method significantly outperforms existing self-supervised ones. The code and datasets are publicly available at https://github.com/cshonglei/SelfHVD.",
    "source": "arXiv"
  },
  {
    "title": "Distributed optimization: designed for federated learning",
    "title_es": "Distributed optimization: designed for federated learning",
    "url": "https://arxiv.org/abs/2508.08606",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08606v1 Announce Type: new \nAbstract: Federated Learning (FL), as a distributed collaborative Machine Learning (ML) framework under privacy-preserving constraints, has garnered increasing research attention in cross-organizational data collaboration scenarios. This paper proposes a class of distributed optimization algorithms based on the augmented Lagrangian technique, designed to accommodate diverse communication topologies in both centralized and decentralized FL settings. Furthermore, we develop multiple termination criteria and parameter update mechanisms to enhance computational efficiency, accompanied by rigorous theoretical guarantees of convergence. By generalizing the augmented Lagrangian relaxation through the incorporation of proximal relaxation and quadratic approximation, our framework systematically recovers a broad of classical unconstrained optimization methods, including proximal algorithm, classic gradient descent, and stochastic gradient descent, among others. Notably, the convergence properties of these methods can be naturally derived within the proposed theoretical framework. Numerical experiments demonstrate that the proposed algorithm exhibits strong performance in large-scale settings with significant statistical heterogeneity across clients.",
    "source": "arXiv"
  },
  {
    "title": "Autonomous Mobile Plant Watering Robot : A Kinematic Approach",
    "title_es": "Autonomous Mobile Plant Watering Robot : A Kinematic Approach",
    "url": "https://arxiv.org/abs/2508.08607",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08607v1 Announce Type: new \nAbstract: Plants need regular and the appropriate amount of watering to thrive and survive. While agricultural robots exist that can spray water on plants and crops such as the , they are expensive and have limited mobility and/or functionality. We introduce a novel autonomous mobile plant watering robot that uses a 6 degree of freedom (DOF) manipulator, connected to a 4 wheel drive alloy chassis, to be able to hold a garden hose, recognize and detect plants, and to water them with the appropriate amount of water by being able to insert a soil humidity/moisture sensor into the soil. The robot uses Jetson Nano and Arduino microcontroller and real sense camera to perform computer vision to detect plants using real-time YOLOv5 with the Pl@ntNet-300K dataset. The robot uses LIDAR for object and collision avoideance and does not need to move on a pre-defined path and can keep track of which plants it has watered. We provide the Denavit-Hartenberg (DH) Table, forward kinematics, differential driving kinematics, and inverse kinematics along with simulation and experiment results",
    "source": "arXiv"
  },
  {
    "title": "Neural Artistic Style and Color Transfer Using Deep Learning",
    "title_es": "Neural Artistic Style and Color Transfer Using Deep Learning",
    "url": "https://arxiv.org/abs/2508.08608",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08608v1 Announce Type: new \nAbstract: Neural artistic style transfers and blends the content and style representation of one image with the style of another. This enables artists to create unique innovative visuals and enhances artistic expression in various fields including art, design, and film. Color transfer algorithms are an important in digital image processing by adjusting the color information in a target image based on the colors in the source image. Color transfer enhances images and videos in film and photography, and can aid in image correction. We introduce a methodology that combines neural artistic style with color transfer. The method uses the Kullback-Leibler (KL) divergence to quantitatively evaluate color and luminance histogram matching algorithms including Reinhard global color transfer, iteration distribution transfer (IDT), IDT with regrain, Cholesky, and PCA between the original and neural artistic style transferred image using deep learning. We estimate the color channel kernel densities. Various experiments are performed to evaluate the KL of these algorithms and their color histograms for style to content transfer.",
    "source": "arXiv"
  },
  {
    "title": "Optimizing Retrieval-Augmented Generation (RAG) for Colloquial Cantonese: A LoRA-Based Systematic Review",
    "title_es": "Optimizing Retrieval-Augmented Generation (RAG) for Colloquial Cantonese: A LoRA-Based Systematic Review",
    "url": "https://arxiv.org/abs/2508.08610",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08610v1 Announce Type: new \nAbstract: This review examines recent advances in Parameter-Efficient Fine-Tuning (PEFT), with a focus on Low-Rank Adaptation (LoRA), to optimize Retrieval-Augmented Generation (RAG) systems like Qwen3, DeepSeek, and Kimi. These systems face challenges in understanding and generating authentic Cantonese colloquial expressions due to limited annotated data and linguistic variability. The review evaluates the integration of LoRA within RAG frameworks, benchmarks PEFT methods for retrieval and generation accuracy, identify domain adaptation strategies under limited data, and compares fine-tuning techniques aimed at improving semantic fidelity under data-scarce conditions. A systematic analysis of recent studies employing diverse LoRA variants, synthetic data generation, user feedback integration, and adaptive parameter allocation was conducted to assess their impact on computational efficiency, retrieval precision, linguistic authenticity, and scalability. Findings reveal that dynamic and ensemble LoRA adaptations significantly reduce trainable parameters without sacrificing retrieval accuracy and generation quality in dialectal contexts. However, limitations remain in fully preserving fine-grained linguistic nuances, especially for low-resource settings like Cantonese. The integration of real-time user feedback and domain-specific data remains underdeveloped, limiting model adaptability and personalization. While selective parameter freezing and nonlinear adaptation methods offer better trade-offs between efficiency and accuracy, their robustness at scale remains an open challenge. This review highlights the promise of PEFT-enhanced RAG systems for domain-specific language tasks and calls for future work targeting dialectal authenticity, dynamic adaptation, and scalable fine-tuning pipelines.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical Visual Prompt Learning for Continual Video Instance Segmentation",
    "title_es": "Hierarchical Visual Prompt Learning for Continual Video Instance Segmentation",
    "url": "https://arxiv.org/abs/2508.08612",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08612v1 Announce Type: new \nAbstract: Video instance segmentation (VIS) has gained significant attention for its capability in tracking and segmenting object instances across video frames. However, most of the existing VIS approaches unrealistically assume that the categories of object instances remain fixed over time. Moreover, they experience catastrophic forgetting of old classes when required to continuously learn object instances belonging to new categories. To resolve these challenges, we develop a novel Hierarchical Visual Prompt Learning (HVPL) model that overcomes catastrophic forgetting of previous categories from both frame-level and video-level perspectives. Specifically, to mitigate forgetting at the frame level, we devise a task-specific frame prompt and an orthogonal gradient correction (OGC) module. The OGC module helps the frame prompt encode task-specific global instance information for new classes in each individual frame by projecting its gradients onto the orthogonal feature space of old classes. Furthermore, to address forgetting at the video level, we design a task-specific video prompt and a video context decoder. This decoder first embeds structural inter-class relationships across frames into the frame prompt features, and then propagates task-specific global video contexts from the frame prompt features to the video prompt. Through rigorous comparisons, our HVPL model proves to be more effective than baseline approaches. The code is available at https://github.com/JiahuaDong/HVPL.",
    "source": "arXiv"
  },
  {
    "title": "UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss",
    "title_es": "UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss",
    "url": "https://arxiv.org/abs/2508.08615",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08615v1 Announce Type: new \nAbstract: Partial differential equations (PDEs) form the mathematical foundation for modeling physical systems in science and engineering, where numerical solutions demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address this challenge by dynamically relocating mesh nodes to rapidly-varying regions, enhancing both simulation accuracy and computational efficiency. However, traditional approaches suffer from high computational complexity and geometric inflexibility, limiting their applicability, and existing supervised learning-based approaches face challenges in zero-shot generalization across diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised mesh adaptation through localized geometric feature learning, eliminating the dependency on pre-adapted meshes. We then develop a physics-constrained loss function, M-Uniform loss, that enforces mesh equidistribution at the nodal level.Experimental results demonstrate that the proposed network exhibits equation-agnostic generalization and geometric independence in efficient mesh adaptation. It demonstrates consistent superiority over existing methods, including robust performance across diverse PDEs and mesh geometries, scalability to multi-scale resolutions and guaranteed error reduction without mesh tangling.",
    "source": "arXiv"
  },
  {
    "title": "Communication Efficient Robotic Mixed Reality with Gaussian Splatting Cross-Layer Optimization",
    "title_es": "Communication Efficient Robotic Mixed Reality with Gaussian Splatting Cross-Layer Optimization",
    "url": "https://arxiv.org/abs/2508.08624",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08624v1 Announce Type: new \nAbstract: Realizing low-cost communication in robotic mixed reality (RoboMR) systems presents a challenge, due to the necessity of uploading high-resolution images through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR (GSMR), which enables the simulator to opportunistically render a photo-realistic view from the robot's pose by calling ``memory'' from a GS model, thus reducing the need for excessive image uploads. However, the GS model may involve discrepancies compared to the actual environments. To this end, a GS cross-layer optimization (GSCLO) framework is further proposed, which jointly optimizes content switching (i.e., deciding whether to upload image or not) and power allocation (i.e., adjusting to content profiles) across different frames by minimizing a newly derived GSMR loss function. The GSCLO problem is addressed by an accelerated penalty optimization (APO) algorithm that reduces computational complexity by over $10$x compared to traditional branch-and-bound and search algorithms. Moreover, variants of GSCLO are presented to achieve robust, low-power, and multi-robot GSMR. Extensive experiments demonstrate that the proposed GSMR paradigm and GSCLO method achieve significant improvements over existing benchmarks on both wheeled and legged robots in terms of diverse metrics in various scenarios. For the first time, it is found that RoboMR can be achieved with ultra-low communication costs, and mixture of data is useful for enhancing GS performance in dynamic scenarios.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Rank Adjustment for Accurate and Efficient Neural Network Training",
    "title_es": "Dynamic Rank Adjustment for Accurate and Efficient Neural Network Training",
    "url": "https://arxiv.org/abs/2508.08625",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08625v1 Announce Type: new \nAbstract: Low-rank training methods reduce the number of trainable parameters by re-parameterizing the weights with matrix decompositions (e.g., singular value decomposition). However, enforcing a fixed low-rank structure caps the rank of the weight matrices and can hinder the model's ability to learn complex patterns. Furthermore, the effective rank of the model's weights tends to decline during training, and this drop is accelerated when the model is reparameterized into a low-rank structure. In this study, we argue that strategically interleaving full-rank training epochs within low-rank training epochs can effectively restore the rank of the model's weights. Based on our findings, we propose a general dynamic-rank training framework that is readily applicable to a wide range of neural-network tasks. We first describe how to adjust the rank of weight matrix to alleviate the inevitable rank collapse that arises during training, and then present extensive empirical results that validate our claims and demonstrate the efficacy of the proposed framework. Our empirical study shows that the proposed method achieves almost the same computational cost as SVD-based low-rank training while achieving a comparable accuracy to full-rank training across various benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "QoE-Aware Service Provision for Mobile AR Rendering: An Agent-Driven Approach",
    "title_es": "QoE-Aware Service Provision for Mobile AR Rendering: An Agent-Driven Approach",
    "url": "https://arxiv.org/abs/2508.08627",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08627v1 Announce Type: new \nAbstract: Mobile augmented reality (MAR) is envisioned as a key immersive application in 6G, enabling virtual content rendering aligned with the physical environment through device pose estimation. In this paper, we propose a novel agent-driven communication service provisioning approach for edge-assisted MAR, aiming to reduce communication overhead between MAR devices and the edge server while ensuring the quality of experience (QoE). First, to address the inaccessibility of MAR application-specific information to the network controller, we establish a digital agent powered by large language models (LLMs) on behalf of the MAR service provider, bridging the data and function gap between the MAR service and network domains. Second, to cope with the user-dependent and dynamic nature of data traffic patterns for individual devices, we develop a user-level QoE modeling method that captures the relationship between communication resource demands and perceived user QoE, enabling personalized, agent-driven communication resource management. Trace-driven simulation results demonstrate that the proposed approach outperforms conventional LLM-based QoE-aware service provisioning methods in both user-level QoE modeling accuracy and communication resource efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Securing Educational LLMs: A Generalised Taxonomy of Attacks on LLMs and DREAD Risk Assessment",
    "title_es": "Securing Educational LLMs: A Generalised Taxonomy of Attacks on LLMs and DREAD Risk Assessment",
    "url": "https://arxiv.org/abs/2508.08629",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08629v1 Announce Type: new \nAbstract: Due to perceptions of efficiency and significant productivity gains, various organisations, including in education, are adopting Large Language Models (LLMs) into their workflows. Educator-facing, learner-facing, and institution-facing LLMs, collectively, Educational Large Language Models (eLLMs), complement and enhance the effectiveness of teaching, learning, and academic operations. However, their integration into an educational setting raises significant cybersecurity concerns. A comprehensive landscape of contemporary attacks on LLMs and their impact on the educational environment is missing. This study presents a generalised taxonomy of fifty attacks on LLMs, which are categorized as attacks targeting either models or their infrastructure. The severity of these attacks is evaluated in the educational sector using the DREAD risk assessment framework. Our risk assessment indicates that token smuggling, adversarial prompts, direct injection, and multi-step jailbreak are critical attacks on eLLMs. The proposed taxonomy, its application in the educational environment, and our risk assessment will help academic and industrial practitioners to build resilient solutions that protect learners and institutions.",
    "source": "arXiv"
  },
  {
    "title": "AgriGPT: a Large Language Model Ecosystem for Agriculture",
    "title_es": "AgriGPT: a Large Language Model Ecosystem for Agriculture",
    "url": "https://arxiv.org/abs/2508.08632",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08632v1 Announce Type: new \nAbstract: Despite the rapid progress of Large Language Models (LLMs), their application in agriculture remains limited due to the lack of domain-specific models, curated datasets, and robust evaluation frameworks. To address these challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for agricultural usage. At its core, we design a multi-agent scalable data engine that systematically compiles credible data sources into Agri-342K, a high-quality, standardized question-answer (QA) dataset. Trained on this dataset, AgriGPT supports a broad range of agricultural stakeholders, from practitioners to policy-makers. To enhance factual grounding, we employ Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning, thereby improving the LLM's reasoning reliability. For comprehensive evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks with varying types and complexities. Experiments demonstrate that AgriGPT significantly outperforms general-purpose LLMs on both domain adaptation and reasoning. Beyond the model itself, AgriGPT represents a modular and extensible LLM ecosystem for agriculture, comprising structured data construction, retrieval-enhanced generation, and domain-specific evaluation. This work provides a generalizable framework for developing scientific and industry-specialized LLMs. All models, datasets, and code will be released to empower agricultural communities, especially in underserved regions, and to promote open, impactful research.",
    "source": "arXiv"
  },
  {
    "title": "Diminution: On Reducing the Size of Grounding ASP Programs",
    "title_es": "Diminution: On Reducing the Size of Grounding ASP Programs",
    "url": "https://arxiv.org/abs/2508.08633",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08633v1 Announce Type: new \nAbstract: Answer Set Programming (ASP) is often hindered by the grounding bottleneck: large Herbrand universes generate ground programs so large that solving becomes difficult. Many methods employ ad-hoc heuristics to improve grounding performance, motivating the need for a more formal and generalizable strategy. We introduce the notion of diminution, defined as a selected subset of the Herbrand universe used to generate a reduced ground program before solving. We give a formal definition of diminution, analyze its key properties, and study the complexity of identifying it. We use a specific encoding that enables off-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates seamlessly with existing grounders via domain predicates. In extensive experiments on five benchmarks, applying diminutions selected by our strategy yields significant performance improvements, reducing grounding time by up to 70% on average and decreasing the size of grounding files by up to 85%. These results demonstrate that leveraging diminutions constitutes a robust and general-purpose approach for alleviating the grounding bottleneck in ASP.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Personalized Conversational Information Retrieval",
    "title_es": "Adaptive Personalized Conversational Information Retrieval",
    "url": "https://arxiv.org/abs/2508.08634",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08634v1 Announce Type: new \nAbstract: Personalized conversational information retrieval (CIR) systems aim to satisfy users' complex information needs through multi-turn interactions by considering user profiles. However, not all search queries require personalization. The challenge lies in appropriately incorporating personalization elements into search when needed. Most existing studies implicitly incorporate users' personal information and conversational context using large language models without distinguishing the specific requirements for each query turn. Such a ``one-size-fits-all'' personalization strategy might lead to sub-optimal results. In this paper, we propose an adaptive personalization method, in which we first identify the required personalization level for a query and integrate personalized queries with other query reformulations to produce various enhanced queries. Then, we design a personalization-aware ranking fusion approach to assign fusion weights dynamically to different reformulated queries, depending on the required personalization level. The proposed adaptive personalized conversational information retrieval framework APCIR is evaluated on two TREC iKAT datasets. The results confirm the effectiveness of adaptive personalization of APCIR by outperforming state-of-the-art methods.",
    "source": "arXiv"
  },
  {
    "title": "Classifier Language Models: Unifying Sparse Finetuning and Adaptive Tokenization for Specialized Classification Tasks",
    "title_es": "Classifier Language Models: Unifying Sparse Finetuning and Adaptive Tokenization for Specialized Classification Tasks",
    "url": "https://arxiv.org/abs/2508.08635",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08635v1 Announce Type: new \nAbstract: Semantic text classification requires the understanding of the contextual significance of specific tokens rather than surface-level patterns or keywords (as in rule-based or statistical text classification), making large language models (LLMs) well-suited for this task. However, semantic classification applications in industry, like customer intent detection or semantic role labeling, tend to be highly specialized. They require annotation by domain experts in contrast to general-purpose corpora for pretraining. Further, they typically require high inference throughputs which limits the model size from latency and cost perspectives. Thus, for a range of specialized classification tasks, the preferred solution is to develop customized classifiers by finetuning smaller language models (e.g., mini-encoders, small language models).\n  In this work, we develop a token-driven sparse finetuning strategy to adapt small language models to specialized classification tasks. We identify and finetune a small sensitive subset of model parameters by leveraging task-specific token constructs in the finetuning dataset, while leaving most of the pretrained weights unchanged. Unlike adapter approaches such as low rank adaptation (LoRA), we do not introduce additional parameters to the model. Our approach identifies highly relevant semantic tokens (case study in the Appendix) and outperforms end-to-end finetuning, LoRA, layer selection, and prefix tuning on five diverse semantic classification tasks. We achieve greater stability and half the training costs vs. end-to-end finetuning.",
    "source": "arXiv"
  },
  {
    "title": "InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling",
    "title_es": "InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling",
    "url": "https://arxiv.org/abs/2508.08636",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08636v1 Announce Type: new \nAbstract: Large language models (LLMs) have revolutionized artificial intelligence by enabling complex reasoning capabilities. While recent advancements in reinforcement learning (RL) have primarily focused on domain-specific reasoning tasks (e.g., mathematics or code generation), real-world reasoning scenarios often require models to handle diverse and complex environments that narrow-domain benchmarks cannot fully capture. To address this gap, we present InternBootcamp, an open-source framework comprising 1000+ domain-diverse task environments specifically designed for LLM reasoning research. Our codebase offers two key functionalities: (1) automated generation of unlimited training/testing cases with configurable difficulty levels, and (2) integrated verification modules for objective response evaluation. These features make InternBootcamp fundamental infrastructure for RL-based model optimization, synthetic data generation, and model evaluation. Although manually developing such a framework with enormous task coverage is extremely cumbersome, we accelerate the development procedure through an automated agent workflow supplemented by manual validation protocols, which enables the task scope to expand rapidly. % With these bootcamps, we further establish Bootcamp-EVAL, an automatically generated benchmark for comprehensive performance assessment. Evaluation reveals that frontier models still underperform in many reasoning tasks, while training with InternBootcamp provides an effective way to significantly improve performance, leading to our 32B model that achieves state-of-the-art results on Bootcamp-EVAL and excels on other established benchmarks. In particular, we validate that consistent performance gains come from including more training tasks, namely \\textbf{task scaling}, over two orders of magnitude, offering a promising route towards capable reasoning generalist.",
    "source": "arXiv"
  },
  {
    "title": "MiGrATe: Mixed-Policy GRPO for Adaptation at Test-Time",
    "title_es": "MiGrATe: Mixed-Policy GRPO for Adaptation at Test-Time",
    "url": "https://arxiv.org/abs/2508.08641",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08641v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly being applied to black-box optimization tasks, from program synthesis to molecule design. Prior work typically leverages in-context learning to iteratively guide the model towards better solutions. Such methods, however, often struggle to balance exploration of new solution spaces with exploitation of high-reward ones. Recently, test-time training (TTT) with synthetic data has shown promise in improving solution quality. However, the need for hand-crafted training data tailored to each task limits feasibility and scalability across domains. To address this problem, we introduce MiGrATe-a method for online TTT that uses GRPO as a search algorithm to adapt LLMs at inference without requiring external training data. MiGrATe operates via a mixed-policy group construction procedure that combines on-policy sampling with two off-policy data selection techniques: greedy sampling, which selects top-performing past completions, and neighborhood sampling (NS), which generates completions structurally similar to high-reward ones. Together, these components bias the policy gradient towards exploitation of promising regions in solution space, while preserving exploration through on-policy sampling. We evaluate MiGrATe on three challenging domains-word search, molecule optimization, and hypothesis+program induction on the Abstraction and Reasoning Corpus (ARC)-and find that it consistently outperforms both inference-only and TTT baselines, demonstrating the potential of online TTT as a solution for complex search tasks without external supervision.",
    "source": "arXiv"
  },
  {
    "title": "XR Reality Check: What Commercial Devices Deliver for Spatial Tracking",
    "title_es": "XR Reality Check: What Commercial Devices Deliver for Spatial Tracking",
    "url": "https://arxiv.org/abs/2508.08642",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08642v1 Announce Type: new \nAbstract: Inaccurate spatial tracking in extended reality (XR) devices leads to virtual object jitter, misalignment, and user discomfort, fundamentally limiting immersive experiences and natural interactions. In this work, we introduce a novel testbed that enables simultaneous, synchronized evaluation of multiple XR devices under identical environmental and kinematic conditions. Leveraging this platform, we present the first comprehensive empirical benchmarking of five state-of-the-art XR devices across 16 diverse scenarios. Our results reveal substantial intra-device performance variation, with individual devices exhibiting up to 101\\% increases in error when operating in featureless environments. We also demonstrate that tracking accuracy strongly correlates with visual conditions and motion dynamics. We also observe significant inter-device disparities, with performance differences of up to 2.8$\\times$, which are closely linked to hardware specifications such as sensor configurations and dedicated processing units. Finally, we explore the feasibility of substituting a motion capture system with the Apple Vision Pro as a practical ground truth reference. While the Apple Vision Pro delivers highly accurate relative pose error estimates ($R^2 = 0.830$), its absolute pose error estimation remains limited ($R^2 = 0.387$), highlighting both its potential and its constraints for rigorous XR evaluation. This work establishes the first standardized framework for comparative XR tracking evaluation, providing the research community with reproducible methodologies, comprehensive benchmark datasets, and open-source tools that enable systematic analysis of tracking performance across devices and conditions, thereby accelerating the development of more robust spatial sensing technologies for XR systems.",
    "source": "arXiv"
  },
  {
    "title": "AME: Aligned Manifold Entropy for Robust Vision-Language Distillation",
    "title_es": "AME: Aligned Manifold Entropy for Robust Vision-Language Distillation",
    "url": "https://arxiv.org/abs/2508.08644",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08644v1 Announce Type: new \nAbstract: Knowledge distillation is a long-established technique for knowledge transfer, and has regained attention in the context of the recent emergence of large vision-language models (VLMs). However, vision-language knowledge distillation often requires sufficient training data to achieve robust generalization on amples with ambiguous or boundary-adjacent representations, which are associated with high predictive uncertainty. Critically, collecting such large-scale, task-specific data for training is often impractical in real-world scenarios. To address this major challenge arising from the entanglement of uncertainty and cross-modal feature representation, we propose Aligned Manifold Entropy for Robust Vision-Language Distillation (AME), aiming to achieve robust generalization under real-world conditions. AME applies entropy minimization over a reconfigured shared manifold, where multi-modal data (i.e., image and text) are bridged through a pair of projection functions, conducive to structural compression for cross-modal feature representations. This enables robust knowledge distillation under low-data regimes, while requiring no architectural modifications to the backbone. As a result, it can serve as a plug-and-play module compatible with a wide range of vision-language distillation frameworks. Notably, our theoretical analysis reveals that integrating knowledge distillation with entropy minimization over the shared manifold leads to a tighter generalization error bound. Extensive experiments across diverse distillation architectures and training settings demonstrate that AME consistently facilitates robust knowledge distillation, resulting in superior generalization performance across a wide spectrum of downstream tasks.",
    "source": "arXiv"
  },
  {
    "title": "Quick on the Uptake: Eliciting Implicit Intents from Human Demonstrations for Personalized Mobile-Use Agents",
    "title_es": "Quick on the Uptake: Eliciting Implicit Intents from Human Demonstrations for Personalized Mobile-Use Agents",
    "url": "https://arxiv.org/abs/2508.08645",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08645v1 Announce Type: new \nAbstract: As multimodal large language models advance rapidly, the automation of mobile tasks has become increasingly feasible through the use of mobile-use agents that mimic human interactions from graphical user interface. To further enhance mobile-use agents, previous studies employ demonstration learning to improve mobile-use agents from human demonstrations. However, these methods focus solely on the explicit intention flows of humans (e.g., step sequences) while neglecting implicit intention flows (e.g., personal preferences), which makes it difficult to construct personalized mobile-use agents. In this work, to evaluate the \\textbf{I}ntention \\textbf{A}lignment \\textbf{R}ate between mobile-use agents and humans, we first collect \\textbf{MobileIAR}, a dataset containing human-intent-aligned actions and ground-truth actions. This enables a comprehensive assessment of the agents' understanding of human intent. Then we propose \\textbf{IFRAgent}, a framework built upon \\textbf{I}ntention \\textbf{F}low \\textbf{R}ecognition from human demonstrations. IFRAgent analyzes explicit intention flows from human demonstrations to construct a query-level vector library of standard operating procedures (SOP), and analyzes implicit intention flows to build a user-level habit repository. IFRAgent then leverages a SOP extractor combined with retrieval-augmented generation and a query rewriter to generate personalized query and SOP from a raw ambiguous query, enhancing the alignment between mobile-use agents and human intent. Experimental results demonstrate that IFRAgent outperforms baselines by an average of 6.79\\% (32.06\\% relative improvement) in human intention alignment rate and improves step completion rates by an average of 5.30\\% (26.34\\% relative improvement). The codes are available at https://github.com/MadeAgents/Quick-on-the-Uptake.",
    "source": "arXiv"
  },
  {
    "title": "P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records",
    "title_es": "P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records",
    "url": "https://arxiv.org/abs/2508.08646",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08646v1 Announce Type: new \nAbstract: Electronic Health Records (EHR) have revolutionized healthcare by digitizing patient data, improving accessibility, and streamlining clinical workflows. However, extracting meaningful insights from these complex and multimodal datasets remains a significant challenge for researchers. Traditional feature selection methods often struggle with the inherent sparsity and heterogeneity of EHR data, especially when accounting for patient-specific variations and feature costs in clinical applications. To address these challenges, we propose a novel personalized, online and cost-aware feature selection framework tailored specifically for EHR datasets. The features are aquired in an online fashion for individual patients, incorporating budgetary constraints and feature variability costs. The framework is designed to effectively manage sparse and multimodal data, ensuring robust and scalable performance in diverse healthcare contexts. A primary application of our proposed method is to support physicians' decision making in patient screening scenarios. By guiding physicians toward incremental acquisition of the most informative features within budget constraints, our approach aims to increase diagnostic confidence while optimizing resource utilization.",
    "source": "arXiv"
  },
  {
    "title": "LLaMA-Based Models for Aspect-Based Sentiment Analysis",
    "title_es": "LLaMA-Based Models for Aspect-Based Sentiment Analysis",
    "url": "https://arxiv.org/abs/2508.08649",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08649v1 Announce Type: new \nAbstract: While large language models (LLMs) show promise for various tasks, their performance in compound aspect-based sentiment analysis (ABSA) tasks lags behind fine-tuned models. However, the potential of LLMs fine-tuned for ABSA remains unexplored. This paper examines the capabilities of open-source LLMs fine-tuned for ABSA, focusing on LLaMA-based models. We evaluate the performance across four tasks and eight English datasets, finding that the fine-tuned Orca~2 model surpasses state-of-the-art results in all tasks. However, all models struggle in zero-shot and few-shot scenarios compared to fully fine-tuned ones. Additionally, we conduct error analysis to identify challenges faced by fine-tuned models.",
    "source": "arXiv"
  },
  {
    "title": "UWB at WASSA-2024 Shared Task 2: Cross-lingual Emotion Detection",
    "title_es": "UWB at WASSA-2024 Shared Task 2: Cross-lingual Emotion Detection",
    "url": "https://arxiv.org/abs/2508.08650",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08650v1 Announce Type: new \nAbstract: This paper presents our system built for the WASSA-2024 Cross-lingual Emotion Detection Shared Task. The task consists of two subtasks: first, to assess an emotion label from six possible classes for a given tweet in one of five languages, and second, to predict words triggering the detected emotions in binary and numerical formats. Our proposed approach revolves around fine-tuning quantized large language models, specifically Orca~2, with low-rank adapters (LoRA) and multilingual Transformer-based models, such as XLM-R and mT5. We enhance performance through machine translation for both subtasks and trigger word switching for the second subtask. The system achieves excellent performance, ranking 1st in numerical trigger words detection, 3rd in binary trigger words detection, and 7th in emotion detection.",
    "source": "arXiv"
  },
  {
    "title": "Prompt-Based Approach for Czech Sentiment Analysis",
    "title_es": "Prompt-Based Approach for Czech Sentiment Analysis",
    "url": "https://arxiv.org/abs/2508.08651",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08651v1 Announce Type: new \nAbstract: This paper introduces the first prompt-based methods for aspect-based sentiment analysis and sentiment classification in Czech. We employ the sequence-to-sequence models to solve the aspect-based tasks simultaneously and demonstrate the superiority of our prompt-based approach over traditional fine-tuning. In addition, we conduct zero-shot and few-shot learning experiments for sentiment classification and show that prompting yields significantly better results with limited training examples compared to traditional fine-tuning. We also demonstrate that pre-training on data from the target domain can lead to significant improvements in a zero-shot scenario.",
    "source": "arXiv"
  },
  {
    "title": "Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training",
    "title_es": "Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training",
    "url": "https://arxiv.org/abs/2508.08652",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08652v1 Announce Type: new \nAbstract: Accurate evaluation of procedural communication compliance is essential in simulation-based training, particularly in safety-critical domains where adherence to compliance checklists reflects operational competence. This paper explores a lightweight, deployable approach using prompt-based inference with open-source large language models (LLMs) that can run efficiently on consumer-grade GPUs. We present Prompt-and-Check, a method that uses context-rich prompts to evaluate whether each checklist item in a protocol has been fulfilled, solely based on transcribed verbal exchanges. We perform a case study in the maritime domain with participants performing an identical simulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and Mistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a prompt incorporating relevant transcript excerpts is fed into the model, which outputs a compliance judgment. We assess model outputs against expert-annotated ground truth using classification accuracy and agreement scores. Our findings demonstrate that prompting enables effective context-aware reasoning without task-specific training. This study highlights the practical utility of LLMs in augmenting debriefing, performance feedback, and automated assessment in training environments.",
    "source": "arXiv"
  },
  {
    "title": "LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement",
    "title_es": "LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement",
    "url": "https://arxiv.org/abs/2508.08653",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08653v1 Announce Type: new \nAbstract: Transforming unstructured text into structured data is a complex task, requiring semantic understanding, reasoning, and structural comprehension. While Large Language Models (LLMs) offer potential, they often struggle with handling ambiguous or domain-specific data, maintaining table structure, managing long inputs, and addressing numerical reasoning. This paper proposes an efficient system for LLM-driven text-to-table generation that leverages novel prompting techniques. Specifically, the system incorporates two key strategies: breaking down the text-to-table task into manageable, guided sub-tasks and refining the generated tables through iterative self-feedback. We show that this custom task decomposition allows the model to address the problem in a stepwise manner and improves the quality of the generated table. Furthermore, we discuss the benefits and potential risks associated with iterative self-feedback on the generated tables while highlighting the trade-offs between enhanced performance and computational cost. Our methods achieve strong results compared to baselines on two complex text-to-table generation datasets available in the public domain.",
    "source": "arXiv"
  },
  {
    "title": "Hypervisor-based Double Extortion Ransomware Detection Method Using Kitsune Network Features",
    "title_es": "Hypervisor-based Double Extortion Ransomware Detection Method Using Kitsune Network Features",
    "url": "https://arxiv.org/abs/2508.08655",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08655v1 Announce Type: new \nAbstract: Double extortion ransomware attacks have become mainstream since many organizations adopt more robust and resilient data backup strategies against conventional crypto-ransomware. This paper presents detailed attack stages, tactics, procedures, and tools used in the double extortion ransomware attacks. We then present a novel detection method using low-level storage and memory behavioral features and network traffic features obtained from a thin hypervisor to establish a defense-in-depth strategy for when attackers compromise OS-level protection. We employed the lightweight \\emph{Kitsune} Network Intrusion Detection System (NIDS)'s network feature to detect the data exfiltration phase in double extortion ransomware attacks. Our experimental results showed that the presented method improved by 0.166 in the macro F score of the data exfiltration phase detection rate. Lastly, we discuss the limitations of the presented method and future work.",
    "source": "arXiv"
  },
  {
    "title": "Evasive Ransomware Attacks Using Low-level Behavioral Adversarial Examples",
    "title_es": "Evasive Ransomware Attacks Using Low-level Behavioral Adversarial Examples",
    "url": "https://arxiv.org/abs/2508.08656",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08656v1 Announce Type: new \nAbstract: Protecting state-of-the-art AI-based cybersecurity defense systems from cyber attacks is crucial. Attackers create adversarial examples by adding small changes (i.e., perturbations) to the attack features to evade or fool the deep learning model. This paper introduces the concept of low-level behavioral adversarial examples and its threat model of evasive ransomware. We formulate the method and the threat model to generate the optimal source code of evasive malware. We then examine the method using the leaked source code of Conti ransomware with the micro-behavior control function. The micro-behavior control function is our test component to simulate changing source code in ransomware; ransomware's behavior can be changed by specifying the number of threads, file encryption ratio, and delay after file encryption at the boot time. We evaluated how much an attacker can control the behavioral features of ransomware using the micro-behavior control function to decrease the detection rate of a ransomware detector.",
    "source": "arXiv"
  },
  {
    "title": "$\\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models",
    "title_es": "$\\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models",
    "url": "https://arxiv.org/abs/2508.08657",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08657v1 Announce Type: new \nAbstract: Accurate molecular property prediction is a critical challenge with wide-ranging applications in chemistry, materials science, and drug discovery. Molecular representation methods, including fingerprints and graph neural networks (GNNs), achieve state-of-the-art results by effectively deriving features from molecular structures. However, these methods often overlook decades of accumulated semantic and contextual knowledge. Recent advancements in large language models (LLMs) demonstrate remarkable reasoning abilities and prior knowledge across scientific domains, leading us to hypothesize that LLMs can generate rich molecular representations when guided to reason in multiple perspectives. To address these gaps, we propose $\\text{M}^{2}$LLM, a multi-view framework that integrates three perspectives: the molecular structure view, the molecular task view, and the molecular rules view. These views are fused dynamically to adapt to task requirements, and experiments demonstrate that $\\text{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks across classification and regression tasks. Moreover, we demonstrate that representation derived from LLM achieves exceptional performance by leveraging two core functionalities: the generation of molecular embeddings through their encoding capabilities and the curation of molecular features through advanced reasoning processes.",
    "source": "arXiv"
  },
  {
    "title": "Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem",
    "title_es": "Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem",
    "url": "https://arxiv.org/abs/2508.08659",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08659v1 Announce Type: new \nAbstract: In this research, we propose an iterative learning hybrid optimization solver developed to strengthen the performance of metaheuristic algorithms in solving the Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism integrates the proposed Node-Destroyer Model, a machine learning hybrid model that utilized Graph Neural Networks (GNNs) such identifies and selects customer nodes to guide the Large Neighborhood Search (LNS) operator within the metaheuristic optimization frameworks. This model leverages the structural properties of the problem and solution that can be represented as a graph, to guide strategic selections concerning node removal. The proposed approach reduces operational complexity and scales down the search space involved in the optimization process. The hybrid approach is applied specifically to the CVRP and does not require retraining across problem instances of different sizes. The proposed hybrid mechanism is able to improve the performance of baseline metaheuristic algorithms. Our approach not only enhances the solution quality for standard CVRP benchmarks but also proves scalability on very large-scale instances with up to 30,000 customer nodes. Experimental evaluations on benchmark datasets show that the proposed hybrid mechanism is capable of improving different baseline algorithms, achieving better quality of solutions under similar settings.",
    "source": "arXiv"
  },
  {
    "title": "Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation",
    "title_es": "Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation",
    "url": "https://arxiv.org/abs/2508.08660",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08660v1 Announce Type: new \nAbstract: Most prior unsupervised domain adaptation approaches for medical image segmentation are narrowly tailored to either the source-accessible setting, where adaptation is guided by source-target alignment, or the source-free setting, which typically resorts to implicit supervision mechanisms such as pseudo-labeling and model distillation. This substantial divergence in methodological designs between the two settings reveals an inherent flaw: the lack of an explicit, structured construction of anatomical knowledge that naturally generalizes across domains and settings. To bridge this longstanding divide, we introduce a unified, semantically grounded framework that supports both source-accessible and source-free adaptation. Fundamentally distinct from all prior works, our framework's adaptability emerges naturally as a direct consequence of the model architecture, without the need for any handcrafted adaptation strategies. Specifically, our model learns a domain-agnostic probabilistic manifold as a global space of anatomical regularities, mirroring how humans establish visual understanding. Thus, the structural content in each image can be interpreted as a canonical anatomy retrieved from the manifold and a spatial transformation capturing individual-specific geometry. This disentangled, interpretable formulation enables semantically meaningful prediction with intrinsic adaptability. Extensive experiments on challenging cardiac and abdominal datasets show that our framework achieves state-of-the-art results in both settings, with source-free performance closely approaching its source-accessible counterpart, a level of consistency rarely observed in prior works. Beyond quantitative improvement, we demonstrate strong interpretability of the proposed framework via manifold traversal for smooth shape manipulation.",
    "source": "arXiv"
  },
  {
    "title": "Hallucinations in Code Change to Natural Language Generation: Prevalence and Evaluation of Detection Metrics",
    "title_es": "Hallucinations in Code Change to Natural Language Generation: Prevalence and Evaluation of Detection Metrics",
    "url": "https://arxiv.org/abs/2508.08661",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08661v1 Announce Type: new \nAbstract: Language models have shown strong capabilities across a wide range of tasks in software engineering, such as code generation, yet they suffer from hallucinations. While hallucinations have been studied independently in natural language and code generation, their occurrence in tasks involving code changes which have a structurally complex and context-dependent format of code remains largely unexplored. This paper presents the first comprehensive analysis of hallucinations in two critical tasks involving code change to natural language generation: commit message generation and code review comment generation. We quantify the prevalence of hallucinations in recent language models and explore a range of metric-based approaches to automatically detect them. Our findings reveal that approximately 50\\% of generated code reviews and 20\\% of generated commit messages contain hallucinations. Whilst commonly used metrics are weak detectors on their own, combining multiple metrics substantially improves performance. Notably, model confidence and feature attribution metrics effectively contribute to hallucination detection, showing promise for inference-time detection.\\footnote{All code and data will be released upon acceptance.",
    "source": "arXiv"
  },
  {
    "title": "Aryabhata: An exam-focused language model for JEE Math",
    "title_es": "Aryabhata: An exam-focused language model for JEE Math",
    "url": "https://arxiv.org/abs/2508.08665",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08665v1 Announce Type: new \nAbstract: We present $\\textbf{Aryabhata 1.0}$, a compact 7B parameter math reasoning model optimized for the Indian academic exam, the Joint Entrance Examination (JEE). Despite rapid progress in large language models (LLMs), current models often remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong open-weight reasoning models, followed by supervised fine-tuning (SFT) with curriculum learning on verified chain-of-thought (CoT) traces curated through best-of-$n$ rejection sampling. To further boost performance, we apply reinforcement learning with verifiable rewards (RLVR) using A2C objective with group-relative advantage estimation alongwith novel exploration strategies such as $\\textit{Adaptive Group Resizing}$ and $\\textit{Temperature Scaling}$. Evaluated on both in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K) benchmarks, Aryabhata outperforms existing models in accuracy and efficiency, while offering pedagogically useful step-by-step reasoning. We release Aryabhata as a foundation model to advance exam-centric, open-source small language models. This marks our first open release for community feedback ($\\href{https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0}{Aryabhata\\ 1.0\\ on\\ Hugging\\ Face}$); PW is actively training future models to further improve learning outcomes for students.",
    "source": "arXiv"
  },
  {
    "title": "Learning Generalizable and Efficient Image Watermarking via Hierarchical Two-Stage Optimization",
    "title_es": "Learning Generalizable and Efficient Image Watermarking via Hierarchical Two-Stage Optimization",
    "url": "https://arxiv.org/abs/2508.08667",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08667v1 Announce Type: new \nAbstract: Deep image watermarking, which refers to enable imperceptible watermark embedding and reliable extraction in cover images, has shown to be effective for copyright protection of image assets. However, existing methods face limitations in simultaneously satisfying three essential criteria for generalizable watermarking: 1) invisibility (imperceptible hide of watermarks), 2) robustness (reliable watermark recovery under diverse conditions), and 3) broad applicability (low latency in watermarking process). To address these limitations, we propose a Hierarchical Watermark Learning (HiWL), a two-stage optimization that enable a watermarking model to simultaneously achieve three criteria. In the first stage, distribution alignment learning is designed to establish a common latent space with two constraints: 1) visual consistency between watermarked and non-watermarked images, and 2) information invariance across watermark latent representations. In this way, multi-modal inputs including watermark message (binary codes) and cover images (RGB pixels) can be well represented, ensuring the invisibility of watermarks and robustness in watermarking process thereby. The second stage employs generalized watermark representation learning to establish a disentanglement policy for separating watermarks from image content in RGB space. In particular, it strongly penalizes substantial fluctuations in separated RGB watermarks corresponding to identical messages. Consequently, HiWL effectively learns generalizable latent-space watermark representations while maintaining broad applicability. Extensive experiments demonstrate the effectiveness of proposed method. In particular, it achieves 7.6\\% higher accuracy in watermark extraction than existing methods, while maintaining extremely low latency (100K images processed in 8s).",
    "source": "arXiv"
  },
  {
    "title": "Convergent Q-Learning for Infinite-Horizon General-Sum Markov Games through Behavioral Economics",
    "title_es": "Convergent Q-Learning for Infinite-Horizon General-Sum Markov Games through Behavioral Economics",
    "url": "https://arxiv.org/abs/2508.08669",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08669v1 Announce Type: new \nAbstract: Risk-aversion and bounded rationality are two key characteristics of human decision-making. Risk-averse quantal-response equilibrium (RQE) is a solution concept that incorporates these features, providing a more realistic depiction of human decision making in various strategic environments compared to a Nash equilibrium. Furthermore a class of RQE has recently been shown in arXiv:2406.14156 to be universally computationally tractable in all finite-horizon Markov games, allowing for the development of multi-agent reinforcement learning algorithms with convergence guarantees. In this paper, we expand upon the study of RQE and analyze their computation in both two-player normal form games and discounted infinite-horizon Markov games. For normal form games we adopt a monotonicity-based approach allowing us to generalize previous results. We first show uniqueness and Lipschitz continuity of RQE with respect to player's payoff matrices under monotonicity assumptions, and then provide conditions on the players' degrees of risk aversion and bounded rationality that ensure monotonicity. We then focus on discounted infinite-horizon Markov games. We define the risk-averse quantal-response Bellman operator and prove its contraction under further conditions on the players' risk-aversion, bounded rationality, and temporal discounting. This yields a Q-learning based algorithm with convergence guarantees for all infinite-horizon general-sum Markov games.",
    "source": "arXiv"
  },
  {
    "title": "Imposing AI: Deceptive design patterns against sustainability",
    "title_es": "Imposing AI: Deceptive design patterns against sustainability",
    "url": "https://arxiv.org/abs/2508.08672",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08672v1 Announce Type: new \nAbstract: Generative AI is being massively deployed in digital services, at a scale that will result in significant environmental harm. We document how tech companies are transforming established user interfaces to impose AI use and show how and to what extent these strategies fit within established deceptive pattern categories. We identify two main design strategies that are implemented to impose AI use in both personal and professional contexts: imposing AI features in interfaces at the expense of existing non-AI features and promoting narratives about AI that make it harder to resist using it. We discuss opportunities for regulating the imposed adoption of AI features, which would inevitably lead to negative environmental effects.",
    "source": "arXiv"
  },
  {
    "title": "Multi-level Collaborative Distillation Meets Global Workspace Model: A Unified Framework for OCIL",
    "title_es": "Multi-level Collaborative Distillation Meets Global Workspace Model: A Unified Framework for OCIL",
    "url": "https://arxiv.org/abs/2508.08677",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08677v1 Announce Type: new \nAbstract: Online Class-Incremental Learning (OCIL) enables models to learn continuously from non-i.i.d. data streams and samples of the data streams can be seen only once, making it more suitable for real-world scenarios compared to offline learning. However, OCIL faces two key challenges: maintaining model stability under strict memory constraints and ensuring adaptability to new tasks. Under stricter memory constraints, current replay-based methods are less effective. While ensemble methods improve adaptability (plasticity), they often struggle with stability. To overcome these challenges, we propose a novel approach that enhances ensemble learning through a Global Workspace Model (GWM)-a shared, implicit memory that guides the learning of multiple student models. The GWM is formed by fusing the parameters of all students within each training batch, capturing the historical learning trajectory and serving as a dynamic anchor for knowledge consolidation. This fused model is then redistributed periodically to the students to stabilize learning and promote cross-task consistency. In addition, we introduce a multi-level collaborative distillation mechanism. This approach enforces peer-to-peer consistency among students and preserves historical knowledge by aligning each student with the GWM. As a result, student models remain adaptable to new tasks while maintaining previously learned knowledge, striking a better balance between stability and plasticity. Extensive experiments on three standard OCIL benchmarks show that our method delivers significant performance improvement for several OCIL models across various memory budgets.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Large Language Model Agents for Piloting Social Experiments",
    "title_es": "Exploring Large Language Model Agents for Piloting Social Experiments",
    "url": "https://arxiv.org/abs/2508.08678",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08678v1 Announce Type: new \nAbstract: Computational social experiments, which typically employ agent-based modeling to create testbeds for piloting social experiments, not only provide a computational solution to the major challenges faced by traditional experimental methods, but have also gained widespread attention in various research fields. Despite their significance, their broader impact is largely limited by the underdeveloped intelligence of their core component, i.e., agents. To address this limitation, we develop a framework grounded in well-established social science theories and practices, consisting of three key elements: (i) large language model (LLM)-driven experimental agents, serving as \"silicon participants\", (ii) methods for implementing various interventions or treatments, and (iii) tools for collecting behavioral, survey, and interview data. We evaluate its effectiveness by replicating three representative experiments, with results demonstrating strong alignment, both quantitatively and qualitatively, with real-world evidence. This work provides the first framework for designing LLM-driven agents to pilot social experiments, underscoring the transformative potential of LLMs and their agents in computational social science",
    "source": "arXiv"
  },
  {
    "title": "MMIF-AMIN: Adaptive Loss-Driven Multi-Scale Invertible Dense Network for Multimodal Medical Image Fusion",
    "title_es": "MMIF-AMIN: Adaptive Loss-Driven Multi-Scale Invertible Dense Network for Multimodal Medical Image Fusion",
    "url": "https://arxiv.org/abs/2508.08679",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08679v1 Announce Type: new \nAbstract: Multimodal medical image fusion (MMIF) aims to integrate images from different modalities to produce a comprehensive image that enhances medical diagnosis by accurately depicting organ structures, tissue textures, and metabolic information. Capturing both the unique and complementary information across multiple modalities simultaneously is a key research challenge in MMIF. To address this challenge, this paper proposes a novel image fusion method, MMIF-AMIN, which features a new architecture that can effectively extract these unique and complementary features. Specifically, an Invertible Dense Network (IDN) is employed for lossless feature extraction from individual modalities. To extract complementary information between modalities, a Multi-scale Complementary Feature Extraction Module (MCFEM) is designed, which incorporates a hybrid attention mechanism, convolutional layers of varying sizes, and Transformers. An adaptive loss function is introduced to guide model learning, addressing the limitations of traditional manually-designed loss functions and enhancing the depth of data mining. Extensive experiments demonstrate that MMIF-AMIN outperforms nine state-of-the-art MMIF methods, delivering superior results in both quantitative and qualitative analyses. Ablation experiments confirm the effectiveness of each component of the proposed method. Additionally, extending MMIF-AMIN to other image fusion tasks also achieves promising performance.",
    "source": "arXiv"
  },
  {
    "title": "TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation",
    "title_es": "TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation",
    "url": "https://arxiv.org/abs/2508.08680",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08680v1 Announce Type: new \nAbstract: LLMs have been shown to perform well in machine translation (MT) with the use of in-context learning (ICL), rivaling supervised models when translating into high-resource languages (HRLs). However, they lag behind when translating into low-resource language (LRLs). Example selection via similarity search and supervised fine-tuning help. However the improvements they give are limited by the size, quality and diversity of existing parallel datasets. A common technique in low-resource MT is synthetic parallel data creation, the most frequent of which is backtranslation, whereby existing target-side texts are automatically translated into the source language. However, this assumes the existence of good quality and relevant target-side texts, which are not readily available for many LRLs. In this paper, we present \\textsc{TopXGen}, an LLM-based approach for the generation of high quality and topic-diverse data in multiple LRLs, which can then be backtranslated to produce useful and diverse parallel texts for ICL and fine-tuning. Our intuition is that while LLMs struggle to translate into LRLs, their ability to translate well into HRLs and their multilinguality enable them to generate good quality, natural-sounding target-side texts, which can be translated well into a high-resource source language. We show that \\textsc{TopXGen} boosts LLM translation performance during fine-tuning and in-context learning. Code and outputs are available at https://github.com/ArmelRandy/topxgen.",
    "source": "arXiv"
  },
  {
    "title": "How to Resolve Envy by Adding Goods",
    "title_es": "How to Resolve Envy by Adding Goods",
    "url": "https://arxiv.org/abs/2508.08682",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08682v1 Announce Type: new \nAbstract: We consider the problem of resolving the envy of a given initial allocation by adding elements from a pool of goods. We give a characterization of the instances where envy can be resolved by adding an arbitrary number of copies of the items in the pool. From this characterization, we derive a polynomial-time algorithm returning a respective solution if it exists. If the number of copies or the total number of added items are bounded, the problem becomes computationally intractable even in various restricted cases. We perform a parameterized complexity analysis, focusing on the number of agents and the pool size as parameters. Notably, although not every instance admits an envy-free solution, our approach allows us to efficiently determine, in polynomial time, whether a solution exists-an aspect that is both theoretically interesting and far from trivial.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Function Approximation Under Heteroskedastic Noise",
    "title_es": "Efficient Function Approximation Under Heteroskedastic Noise",
    "url": "https://arxiv.org/abs/2508.08683",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08683v1 Announce Type: new \nAbstract: Approximating a function $f(x)$ on $[-1,1]$ based on $N+1$ samples is a classical problem in numerical analysis. If the samples come with heteroskedastic noise depending on $x$ of variance $\\sigma(x)^2$, an $O(N\\log N)$ algorithm for this problem has not yet been found in the current literature. In this paper, we propose a method called HeteroChebtrunc, adapted from an algorithm named NoisyChebtrunc. Using techniques in high-dimensional probability, we show that with high probability, HeteroChebtrunc achieves a tighter infinity-norm error bound than NoisyChebtrunc under heteroskedastic noise. This algorithm runs in $O(N+\\hat{N}\\log \\hat{N})$ operations, where $\\hat{N}\\ll N$ is a chosen parameter. While investigating the properties of HeteroChebtrunc, we also derive a high-probability non-asymptotic relative error bound on the sample variance estimator for subgaussian variables, which is potentially another result of broader interest. We provide numerical experiments to demonstrate the improved uniform error of our algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Out of the Box, into the Clinic? Evaluating State-of-the-Art ASR for Clinical Applications for Older Adults",
    "title_es": "Out of the Box, into the Clinic? Evaluating State-of-the-Art ASR for Clinical Applications for Older Adults",
    "url": "https://arxiv.org/abs/2508.08684",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08684v1 Announce Type: new \nAbstract: Voice-controlled interfaces can support older adults in clinical contexts, with chatbots being a prime example, but reliable Automatic Speech Recognition (ASR) for underrepresented groups remains a bottleneck. This study evaluates state-of-the-art ASR models on language use of older Dutch adults, who interacted with the Welzijn.AI chatbot designed for geriatric contexts. We benchmark generic multilingual ASR models, and models fine-tuned for Dutch spoken by older adults, while also considering processing speed. Our results show that generic multilingual models outperform fine-tuned models, which suggests recent ASR models can generalise well out of the box to realistic datasets. Furthermore, our results suggest that truncating existing architectures is helpful in balancing the accuracy-speed trade-off, though we also identify some cases with high WER due to hallucinations.",
    "source": "arXiv"
  },
  {
    "title": "PADReg: Physics-Aware Deformable Registration Guided by Contact Force for Ultrasound Sequences",
    "title_es": "PADReg: Physics-Aware Deformable Registration Guided by Contact Force for Ultrasound Sequences",
    "url": "https://arxiv.org/abs/2508.08685",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08685v1 Announce Type: new \nAbstract: Ultrasound deformable registration estimates spatial transformations between pairs of deformed ultrasound images, which is crucial for capturing biomechanical properties and enhancing diagnostic accuracy in diseases such as thyroid nodules and breast cancer. However, ultrasound deformable registration remains highly challenging, especially under large deformation. The inherently low contrast, heavy noise and ambiguous tissue boundaries in ultrasound images severely hinder reliable feature extraction and correspondence matching. Existing methods often suffer from poor anatomical alignment and lack physical interpretability. To address the problem, we propose PADReg, a physics-aware deformable registration framework guided by contact force. PADReg leverages synchronized contact force measured by robotic ultrasound systems as a physical prior to constrain the registration. Specifically, instead of directly predicting deformation fields, we first construct a pixel-wise stiffness map utilizing the multi-modal information from contact force and ultrasound images. The stiffness map is then combined with force data to estimate a dense deformation field, through a lightweight physics-aware module inspired by Hooke's law. This design enables PADReg to achieve physically plausible registration with better anatomical alignment than previous methods relying solely on image similarity. Experiments on in-vivo datasets demonstrate that it attains a HD95 of 12.90, which is 21.34\\% better than state-of-the-art methods. The source code is available at https://github.com/evelynskip/PADReg.",
    "source": "arXiv"
  },
  {
    "title": "Expert-Guided Diffusion Planner for Auto-bidding",
    "title_es": "Expert-Guided Diffusion Planner for Auto-bidding",
    "url": "https://arxiv.org/abs/2508.08687",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08687v1 Announce Type: new \nAbstract: Auto-bidding is extensively applied in advertising systems, serving a multitude of advertisers. Generative bidding is gradually gaining traction due to its robust planning capabilities and generalizability. In contrast to traditional reinforcement learning-based bidding, generative bidding does not rely on the Markov Decision Process (MDP) exhibiting superior planning capabilities in long-horizon scenarios. Conditional diffusion modeling approaches have demonstrated significant potential in the realm of auto-bidding. However, relying solely on return as the optimality condition is weak to guarantee the generation of genuinely optimal decision sequences, lacking personalized structural information. Moreover, diffusion models' t-step autoregressive generation mechanism inherently carries timeliness risks. To address these issues, we propose a novel conditional diffusion modeling method based on expert trajectory guidance combined with a skip-step sampling strategy to enhance generation efficiency. We have validated the effectiveness of this approach through extensive offline experiments and achieved statistically significant results in online A/B testing, achieving an increase of 11.29% in conversion and a 12.35% in revenue compared with the baseline.",
    "source": "arXiv"
  },
  {
    "title": "STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision",
    "title_es": "STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision",
    "url": "https://arxiv.org/abs/2508.08688",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08688v1 Announce Type: new \nAbstract: Vision-language models (VLMs) have made significant strides in reasoning, yet they often struggle with complex multimodal tasks and tend to generate overly verbose outputs. A key limitation is their reliance on chain-of-thought (CoT) reasoning, despite many tasks benefiting from alternative topologies like trees or graphs. To address this, we introduce STELAR-Vision, a training framework for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline that enriches training with diverse topological structures. Using supervised fine-tuning and reinforcement learning, we post-train Qwen2VL models with both accuracy and efficiency in mind. Additionally, we propose Frugal Learning, which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H, STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it outperforms Phi-4-Multimodal-Instruct by up to 28.4% and LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong generalization. Compared to Chain-Only training, our approach achieves 4.3% higher overall accuracy on in-distribution datasets and consistently outperforms across all OOD benchmarks. We have released datasets, and code will be available.",
    "source": "arXiv"
  },
  {
    "title": "ZS-Puffin: Design, Modeling and Implementation of an Unmanned Aerial-Aquatic Vehicle with Amphibious Wings",
    "title_es": "ZS-Puffin: Design, Modeling and Implementation of an Unmanned Aerial-Aquatic Vehicle with Amphibious Wings",
    "url": "https://arxiv.org/abs/2508.08690",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08690v1 Announce Type: new \nAbstract: Unmanned aerial-aquatic vehicles (UAAVs) can operate both in the air and underwater, giving them broad application prospects. Inspired by the dual-function wings of puffins, we propose a UAAV with amphibious wings to address the challenge posed by medium differences on the vehicle's propulsion system. The amphibious wing, redesigned based on a fixed-wing structure, features a single degree of freedom in pitch and requires no additional components. It can generate lift in the air and function as a flapping wing for propulsion underwater, reducing disturbance to marine life and making it environmentally friendly. Additionally, an artificial central pattern generator (CPG) is introduced to enhance the smoothness of the flapping motion. This paper presents the prototype, design details, and practical implementation of this concept.",
    "source": "arXiv"
  },
  {
    "title": "ROD: RGB-Only Fast and Efficient Off-road Freespace Detection",
    "title_es": "ROD: RGB-Only Fast and Efficient Off-road Freespace Detection",
    "url": "https://arxiv.org/abs/2508.08697",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08697v1 Announce Type: new \nAbstract: Off-road freespace detection is more challenging than on-road scenarios because of the blurred boundaries of traversable areas. Previous state-of-the-art (SOTA) methods employ multi-modal fusion of RGB images and LiDAR data. However, due to the significant increase in inference time when calculating surface normal maps from LiDAR data, multi-modal methods are not suitable for real-time applications, particularly in real-world scenarios where higher FPS is required compared to slow navigation. This paper presents a novel RGB-only approach for off-road freespace detection, named ROD, eliminating the reliance on LiDAR data and its computational demands. Specifically, we utilize a pre-trained Vision Transformer (ViT) to extract rich features from RGB images. Additionally, we design a lightweight yet efficient decoder, which together improve both precision and inference speed. ROD establishes a new SOTA on ORFD and RELLIS-3D datasets, as well as an inference speed of 50 FPS, significantly outperforming prior models.",
    "source": "arXiv"
  },
  {
    "title": "Subjective and Objective Quality Assessment of Banding Artifacts on Compressed Videos",
    "title_es": "Subjective and Objective Quality Assessment of Banding Artifacts on Compressed Videos",
    "url": "https://arxiv.org/abs/2508.08700",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08700v1 Announce Type: new \nAbstract: Although there have been notable advancements in video compression technologies in recent years, banding artifacts remain a serious issue affecting the quality of compressed videos, particularly on smooth regions of high-definition videos. Noticeable banding artifacts can severely impact the perceptual quality of videos viewed on a high-end HDTV or high-resolution screen. Hence, there is a pressing need for a systematic investigation of the banding video quality assessment problem for advanced video codecs. Given that the existing publicly available datasets for studying banding artifacts are limited to still picture data only, which cannot account for temporal banding dynamics, we have created a first-of-a-kind open video dataset, dubbed LIVE-YT-Banding, which consists of 160 videos generated by four different compression parameters using the AV1 video codec. A total of 7,200 subjective opinions are collected from a cohort of 45 human subjects. To demonstrate the value of this new resources, we tested and compared a variety of models that detect banding occurrences, and measure their impact on perceived quality. Among these, we introduce an effective and efficient new no-reference (NR) video quality evaluator which we call CBAND. CBAND leverages the properties of the learned statistics of natural images expressed in the embeddings of deep neural networks. Our experimental results show that the perceptual banding prediction performance of CBAND significantly exceeds that of previous state-of-the-art models, and is also orders of magnitude faster. Moreover, CBAND can be employed as a differentiable loss function to optimize video debanding models. The LIVE-YT-Banding database, code, and pre-trained model are all publically available at https://github.com/uniqzheng/CBAND.",
    "source": "arXiv"
  },
  {
    "title": "SafeFix: Targeted Model Repair via Controlled Image Generation",
    "title_es": "SafeFix: Targeted Model Repair via Controlled Image Generation",
    "url": "https://arxiv.org/abs/2508.08701",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08701v1 Announce Type: new \nAbstract: Deep learning models for visual recognition often exhibit systematic errors due to underrepresented semantic subpopulations. Although existing debugging frameworks can pinpoint these failures by identifying key failure attributes, repairing the model effectively remains difficult. Current solutions often rely on manually designed prompts to generate synthetic training images -- an approach prone to distribution shift and semantic errors. To overcome these challenges, we introduce a model repair module that builds on an interpretable failure attribution pipeline. Our approach uses a conditional text-to-image model to generate semantically faithful and targeted images for failure cases. To preserve the quality and relevance of the generated samples, we further employ a large vision-language model (LVLM) to filter the outputs, enforcing alignment with the original data distribution and maintaining semantic consistency. By retraining vision models with this rare-case-augmented synthetic dataset, we significantly reduce errors associated with rare cases. Our experiments demonstrate that this targeted repair strategy improves model robustness without introducing new bugs. Code is available at https://github.com/oxu2/SafeFix",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Confidence-Wise Loss for Improved Lens Structure Segmentation in AS-OCT",
    "title_es": "Adaptive Confidence-Wise Loss for Improved Lens Structure Segmentation in AS-OCT",
    "url": "https://arxiv.org/abs/2508.08705",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08705v1 Announce Type: new \nAbstract: Precise lens structure segmentation is essential for the design of intraocular lenses (IOLs) in cataract surgery. Existing deep segmentation networks typically weight all pixels equally under cross-entropy (CE) loss, overlooking the fact that sub-regions of lens structures are inhomogeneous (e.g., some regions perform better than others) and that boundary regions often suffer from poor segmentation calibration at the pixel level. Clinically, experts annotate different sub-regions of lens structures with varying confidence levels, considering factors such as sub-region proportions, ambiguous boundaries, and lens structure shapes. Motivated by this observation, we propose an Adaptive Confidence-Wise (ACW) loss to group each lens structure sub-region into different confidence sub-regions via a confidence threshold from the unique region aspect, aiming to exploit the potential of expert annotation confidence prior. Specifically, ACW clusters each target region into low-confidence and high-confidence groups and then applies a region-weighted loss to reweigh each confidence group. Moreover, we design an adaptive confidence threshold optimization algorithm to adjust the confidence threshold of ACW dynamically. Additionally, to better quantify the miscalibration errors in boundary region segmentation, we propose a new metric, termed Boundary Expected Calibration Error (BECE). Extensive experiments on a clinical lens structure AS-OCT dataset and other multi-structure datasets demonstrate that our ACW significantly outperforms competitive segmentation loss methods across different deep segmentation networks (e.g., MedSAM). Notably, our method surpasses CE with 6.13% IoU gain, 4.33% DSC increase, and 4.79% BECE reduction in lens structure segmentation under U-Net. The code of this paper is available at https://github.com/XiaoLing12138/Adaptive-Confidence-Wise-Loss.",
    "source": "arXiv"
  },
  {
    "title": "OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing",
    "title_es": "OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing",
    "url": "https://arxiv.org/abs/2508.08706",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08706v1 Announce Type: new \nAbstract: Recent vision-language-action (VLA) models build upon vision-language foundations, and have achieved promising results and exhibit the possibility of task generalization in robot manipulation. However, due to the heterogeneity of tactile sensors and the difficulty of acquiring tactile data, current VLA models significantly overlook the importance of tactile perception and fail in contact-rich tasks. To address this issue, this paper proposes OmniVTLA, a novel architecture involving tactile sensing. Specifically, our contributions are threefold. First, our OmniVTLA features a dual-path tactile encoder framework. This framework enhances tactile perception across diverse vision-based and force-based tactile sensors by using a pretrained vision transformer (ViT) and a semantically-aligned tactile ViT (SA-ViT). Second, we introduce ObjTac, a comprehensive force-based tactile dataset capturing textual, visual, and tactile information for 56 objects across 10 categories. With 135K tri-modal samples, ObjTac supplements existing visuo-tactile datasets. Third, leveraging this dataset, we train a semantically-aligned tactile encoder to learn a unified tactile representation, serving as a better initialization for OmniVTLA. Real-world experiments demonstrate substantial improvements over state-of-the-art VLA baselines, achieving 96.9% success rates with grippers, (21.9% higher over baseline) and 100% success rates with dexterous hands (6.2% higher over baseline) in pick-and-place tasks. Besides, OmniVTLA significantly reduces task completion time and generates smoother trajectories through tactile sensing compared to existing VLA.",
    "source": "arXiv"
  },
  {
    "title": "Towards Safe Imitation Learning via Potential Field-Guided Flow Matching",
    "title_es": "Towards Safe Imitation Learning via Potential Field-Guided Flow Matching",
    "url": "https://arxiv.org/abs/2508.08707",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08707v1 Announce Type: new \nAbstract: Deep generative models, particularly diffusion and flow matching models, have recently shown remarkable potential in learning complex policies through imitation learning. However, the safety of generated motions remains overlooked, particularly in complex environments with inherent obstacles. In this work, we address this critical gap by proposing Potential Field-Guided Flow Matching Policy (PF2MP), a novel approach that simultaneously learns task policies and extracts obstacle-related information, represented as a potential field, from the same set of successful demonstrations. During inference, PF2MP modulates the flow matching vector field via the learned potential field, enabling safe motion generation. By leveraging these complementary fields, our approach achieves improved safety without compromising task success across diverse environments, such as navigation tasks and robotic manipulation scenarios. We evaluate PF2MP in both simulation and real-world settings, demonstrating its effectiveness in task space and joint space control. Experimental results demonstrate that PF2MP enhances safety, achieving a significant reduction of collisions compared to baseline policies. This work paves the way for safer motion generation in unstructured and obstaclerich environments.",
    "source": "arXiv"
  },
  {
    "title": "CRADLE: Conversational RTL Design Space Exploration with LLM-based Multi-Agent Systems",
    "title_es": "CRADLE: Conversational RTL Design Space Exploration with LLM-based Multi-Agent Systems",
    "url": "https://arxiv.org/abs/2508.08709",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08709v1 Announce Type: new \nAbstract: This paper presents CRADLE, a conversational framework for design space exploration of RTL designs using LLM-based multi-agent systems. Unlike existing rigid approaches, CRADLE enables user-guided flows with internal self-verification, correction, and optimization. We demonstrate the framework with a generator-critic agent system targeting FPGA resource minimization using state-of-the-art LLMs. Experimental results on the RTLLM benchmark show that CRADLE achieves significant reductions in resource usage with averages of 48% and 40% in LUTs and FFs across all benchmark designs.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models",
    "title_es": "A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models",
    "url": "https://arxiv.org/abs/2508.08712",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08712v1 Announce Type: new \nAbstract: As text generation has become a core capability of modern Large Language Models (LLMs), it underpins a wide range of downstream applications. However, most existing LLMs rely on autoregressive (AR) generation, producing one token at a time based on previously generated context-resulting in limited generation speed due to the inherently sequential nature of the process. To address this challenge, an increasing number of researchers have begun exploring parallel text generation-a broad class of techniques aimed at breaking the token-by-token generation bottleneck and improving inference efficiency. Despite growing interest, there remains a lack of comprehensive analysis on what specific techniques constitute parallel text generation and how they improve inference performance. To bridge this gap, we present a systematic survey of parallel text generation methods. We categorize existing approaches into AR-based and Non-AR-based paradigms, and provide a detailed examination of the core techniques within each category. Following this taxonomy, we assess their theoretical trade-offs in terms of speed, quality, and efficiency, and examine their potential for combination and comparison with alternative acceleration strategies. Finally, based on our findings, we highlight recent advancements, identify open challenges, and outline promising directions for future research in parallel text generation.",
    "source": "arXiv"
  },
  {
    "title": "Eat your own KR: a KR-based approach to index Semantic Web Endpoints and Knowledge Graphs",
    "title_es": "Eat your own KR: a KR-based approach to index Semantic Web Endpoints and Knowledge Graphs",
    "url": "https://arxiv.org/abs/2508.08713",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08713v1 Announce Type: new \nAbstract: Over the last decade, knowledge graphs have multiplied, grown, and evolved on the World Wide Web, and the advent of new standards, vocabularies, and application domains has accelerated this trend. IndeGx is a framework leveraging an extensible base of rules to index the content of KGs and the capacities of their SPARQL endpoints. In this article, we show how knowledge representation (KR) and reasoning methods and techniques can be used in a reflexive manner to index and characterize existing knowledge graphs (KG) with respect to their usage of KR methods and techniques. We extended IndeGx with a fully ontology-oriented modeling and processing approach to do so. Using SPARQL rules and an OWL RL ontology of the indexing domain, IndeGx can now build and reason over an index of the contents and characteristics of an open collection of public knowledge graphs. Our extension of the framework relies on a declarative representation of procedural knowledge and collaborative environments (e.g., GitHub) to provide an agile, customizable, and expressive KR approach for building and maintaining such an index of knowledge graphs in the wild. In doing so, we help anyone answer the question of what knowledge is out there in the world wild Semantic Web in general, and we also help our community monitor which KR research results are used in practice. In particular, this article provides a snapshot of the state of the Semantic Web regarding supported standard languages, ontology usage, and diverse quality evaluations by applying this method to a collection of over 300 open knowledge graph endpoints.",
    "source": "arXiv"
  },
  {
    "title": "Generative Modeling for Robust Deep Reinforcement Learning on the Traveling Salesman Problem",
    "title_es": "Generative Modeling for Robust Deep Reinforcement Learning on the Traveling Salesman Problem",
    "url": "https://arxiv.org/abs/2508.08718",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08718v1 Announce Type: new \nAbstract: The Traveling Salesman Problem (TSP) is a classic NP-hard combinatorial optimization task with numerous practical applications. Classic heuristic solvers can attain near-optimal performance for small problem instances, but become computationally intractable for larger problems. Real-world logistics problems such as dynamically re-routing last-mile deliveries demand a solver with fast inference time, which has led researchers to investigate specialized neural network solvers. However, neural networks struggle to generalize beyond the synthetic data they were trained on. In particular, we show that there exist TSP distributions that are realistic in practice, which also consistently lead to poor worst-case performance for existing neural approaches. To address this issue of distribution robustness, we present Combinatorial Optimization with Generative Sampling (COGS), where training data is sampled from a generative TSP model. We show that COGS provides better data coverage and interpolation in the space of TSP training distributions. We also present TSPLib50, a dataset of realistically distributed TSP samples, which tests real-world generalization ability without conflating this issue with instance size. We evaluate our method on various synthetic datasets as well as TSPLib50, and compare to state-of-the-art neural baselines. We demonstrate that COGS improves distribution robustness, with most performance gains coming from worst-case scenarios.",
    "source": "arXiv"
  },
  {
    "title": "IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization",
    "title_es": "IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization",
    "url": "https://arxiv.org/abs/2508.08719",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08719v1 Announce Type: new \nAbstract: Trained on various human-authored corpora, Large Language Models (LLMs) have demonstrated a certain capability of reflecting specific human-like traits (e.g., personality or values) by prompting, benefiting applications like personalized LLMs and social simulations. However, existing methods suffer from the superficial elicitation problem: LLMs can only be steered to mimic shallow and unstable stylistic patterns, failing to embody the desired traits precisely and consistently across diverse tasks like humans. To address this challenge, we propose IROTE, a novel in-context method for stable and transferable trait elicitation. Drawing on psychological theories suggesting that traits are formed through identity-related reflection, our method automatically generates and optimizes a textual self-reflection within prompts, which comprises self-perceived experience, to stimulate LLMs' trait-driven behavior. The optimization is performed by iteratively maximizing an information-theoretic objective that enhances the connections between LLMs' behavior and the target trait, while reducing noisy redundancy in reflection without any fine-tuning, leading to evocative and compact trait reflection. Extensive experiments across three human trait systems manifest that one single IROTE-generated self-reflection can induce LLMs' stable impersonation of the target trait across diverse downstream tasks beyond simple questionnaire answering, consistently outperforming existing strong baselines.",
    "source": "arXiv"
  },
  {
    "title": "Architecture and FPGA Implementation of Digital Time-to-Digital Converter for Sensing Applications",
    "title_es": "Architecture and FPGA Implementation of Digital Time-to-Digital Converter for Sensing Applications",
    "url": "https://arxiv.org/abs/2508.08725",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08725v1 Announce Type: new \nAbstract: Many application domains face the challenges of high-power consumption and high computational demands, especially with the advancement in embedded machine learning and edge computing. Designing application-specific circuits is crucial to reducing hardware complexity and power consumption. In these perspectives, this paper presents the design of a Digital Time-to-Digital converter (DTDC) based on multiple delay line topologies. The DTDC is implemented in VHDL for the Xilinx Artix-7 AC701 FPGA device. Simulation results demonstrate the effectiveness of the circuit in converting the input period along a wide range up to 1ps. The designed circuit is implemented with less than 1% of the resource utilization on the target FPGA device.",
    "source": "arXiv"
  },
  {
    "title": "Simulating Generative Social Agents via Theory-Informed Workflow Design",
    "title_es": "Simulating Generative Social Agents via Theory-Informed Workflow Design",
    "url": "https://arxiv.org/abs/2508.08726",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08726v1 Announce Type: new \nAbstract: Recent advances in large language models have demonstrated strong reasoning and role-playing capabilities, opening new opportunities for agent-based social simulations. However, most existing agents' implementations are scenario-tailored, without a unified framework to guide the design. This lack of a general social agent limits their ability to generalize across different social contexts and to produce consistent, realistic behaviors. To address this challenge, we propose a theory-informed framework that provides a systematic design process for LLM-based social agents. Our framework is grounded in principles from Social Cognition Theory and introduces three key modules: motivation, action planning, and learning. These modules jointly enable agents to reason about their goals, plan coherent actions, and adapt their behavior over time, leading to more flexible and contextually appropriate responses. Comprehensive experiments demonstrate that our theory-driven agents reproduce realistic human behavior patterns under complex conditions, achieving up to 75% lower deviation from real-world behavioral data across multiple fidelity metrics compared to classical generative baselines. Ablation studies further show that removing motivation, planning, or learning modules increases errors by 1.5 to 3.2 times, confirming their distinct and essential contributions to generating realistic and coherent social behaviors.",
    "source": "arXiv"
  },
  {
    "title": "Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation",
    "title_es": "Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation",
    "url": "https://arxiv.org/abs/2508.08730",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08730v1 Announce Type: new \nAbstract: Medical Lay Language Generation (MLLG) plays a vital role in improving the accessibility of complex scientific content for broader audiences. Recent literature to MLLG commonly employ parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) to fine-tuning large language models (LLMs) using paired expert-lay language datasets. However, LoRA struggles with the challenges posed by multi-source heterogeneous MLLG datasets. Specifically, through a series of exploratory experiments, we reveal that standard LoRA fail to meet the requirement for semantic fidelity and diverse lay-style generation in MLLG task. To address these limitations, we propose Magical, an asymmetric LoRA architecture tailored for MLLG under heterogeneous data scenarios. Magical employs a shared matrix $A$ for abstractive summarization, along with multiple isolated matrices $B$ for diverse lay-style generation. To preserve semantic fidelity during the lay language generation process, Magical introduces a Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix $A$. Furthermore, to better adapt to diverse lay-style generation, Magical incorporates the Recommendation-guided Switch, an externally interface to prompt the LLM to switch between different matrices $B$. Experimental results on three real-world lay language generation datasets demonstrate that Magical consistently outperforms prompt-based methods, vanilla LoRA, and its recent variants, while also reducing trainable parameters by 31.66%.",
    "source": "arXiv"
  },
  {
    "title": "Caption: Generating Informative Content Labels for Image Buttons Using Next-Screen Context",
    "title_es": "Caption: Generating Informative Content Labels for Image Buttons Using Next-Screen Context",
    "url": "https://arxiv.org/abs/2508.08731",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08731v1 Announce Type: new \nAbstract: We present Caption, an LLM-powered content label generation tool for visual interactive elements on mobile devices. Content labels are essential for screen readers to provide announcements for image-based elements, but are often missing or uninformative due to developer neglect. Automated captioning systems attempt to address this, but are limited to on-screen context, often resulting in inaccurate or unspecific labels. To generate more accurate and descriptive labels, Caption collects next-screen context on interactive elements by navigating to the destination screen that appears after an interaction and incorporating information from both the origin and destination screens. Preliminary results show Caption generates more accurate labels than both human annotators and an LLM baseline. We expect Caption to empower developers by providing actionable accessibility suggestions and directly support on-demand repairs by screen reader users.",
    "source": "arXiv"
  },
  {
    "title": "Elucidating Rectified Flow with Deterministic Sampler: Polynomial Discretization Complexity for Multi and One-step Models",
    "title_es": "Elucidating Rectified Flow with Deterministic Sampler: Polynomial Discretization Complexity for Multi and One-step Models",
    "url": "https://arxiv.org/abs/2508.08735",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08735v1 Announce Type: new \nAbstract: Recently, rectified flow (RF)-based models have achieved state-of-the-art performance in many areas for both the multi-step and one-step generation. However, only a few theoretical works analyze the discretization complexity of RF-based models. Existing works either focus on flow-based models with stochastic samplers or establish complexity results that exhibit exponential dependence on problem parameters. In this work, under the realistic bounded support assumption, we prove the first polynomial discretization complexity for multi-step and one-step RF-based models with a deterministic sampler simultaneously. For the multi-step setting, inspired by the predictor-corrector framework of diffusion models, we introduce a Langevin process as a corrector and show that RF-based models can achieve better polynomial discretization complexity than diffusion models. To achieve this result, we conduct a detailed analysis of the RF-based model and explain why it is better than previous popular models, such as variance preserving (VP) and variance exploding (VE)-based models. Based on the observation of multi-step RF-based models, we further provide the first polynomial discretization complexity result for one-step RF-based models, improving upon prior results for one-step diffusion-based models. These findings mark the first step toward theoretically understanding the impressive empirical performance of RF-based models in both multi-step and one-step generation.",
    "source": "arXiv"
  },
  {
    "title": "Optimum 1-Step Majority-Logic Decoding of Binary Reed-Muller Codes",
    "title_es": "Optimum 1-Step Majority-Logic Decoding of Binary Reed-Muller Codes",
    "url": "https://arxiv.org/abs/2508.08736",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08736v1 Announce Type: new \nAbstract: The classical majority-logic decoder proposed by Reed for Reed-Muller codes RM(r, m) of order r and length 2^m, unfolds in r+1 sequential steps, decoding message symbols from highest to lowest degree. Several follow-up decoding algorithms reduced the number of steps, but for a limited set of parameters, or at the expense of reduced performance, or relying on the existence of some combinatorial structures. We show that any one-step majority-logic decoder-that is, a decoder performing all majority votes in one step simultaneously without sequential processing-can correct at most d_min/4 errors for all values of r and m, where d_min denotes the code's minimum distance. We then introduce a new hard-decision decoder that completes the decoding in a single step and attains this error-correction limit. It applies to all r and m, and can be viewed as a parallel realization of Reed's original algorithm, decoding all message symbols simultaneously. Remarkably, we also prove that the decoder is optimum in the erasure setting: it recovers the message from any erasure pattern of up to d_min-1 symbols-the theoretical limit. To our knowledge, this is the first 1-step decoder for RM codes that achieves both optimal erasure correction and the maximum one-step error correction capability.",
    "source": "arXiv"
  },
  {
    "title": "From Data to Insight: Using Contextual Scenarios to Teach Critical Thinking in Data Visualisation",
    "title_es": "From Data to Insight: Using Contextual Scenarios to Teach Critical Thinking in Data Visualisation",
    "url": "https://arxiv.org/abs/2508.08737",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08737v1 Announce Type: new \nAbstract: This paper explores the use of scenario-based visualisation examples as a pedagogical strategy for teaching students the complexities of data insight, representation, and interpretation. Teaching data visualisation often involves explaining intricate issues related to data management and the challenges of presenting data meaningfully. In this work, we present a series of data-driven scenarios. These concise stories depict specific situations, and are created to help the educators highlight key concerns in data communication, such as chart selection, temporal versus categorical comparison, visual bias, and narrative framing. By grounding these examples in real-world contexts, students are encouraged to critically assess not only what the data shows, but how and why it is shown that way. The paper presents a collection of example scenarios, that educators can use for their own lessons; the work fits with a larger project on looking at critical thinking in the classroom, and developing appropriate tools. We also start to abstract principles, from our approach, so that others can develop their own scenarios for their teaching. Our approach aligns with principles of authentic and scenario-based learning, using real-world contexts to foster critical engagement with data.",
    "source": "arXiv"
  },
  {
    "title": "Dead Zone of Accountability: Why Social Claims in Machine Learning Research Should Be Articulated and Defended",
    "title_es": "Dead Zone of Accountability: Why Social Claims in Machine Learning Research Should Be Articulated and Defended",
    "url": "https://arxiv.org/abs/2508.08739",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08739v1 Announce Type: new \nAbstract: Many Machine Learning research studies use language that describes potential social benefits or technical affordances of new methods and technologies. Such language, which we call \"social claims\", can help garner substantial resources and influence for those involved in ML research and technology production. However, there exists a gap between social claims and reality (the claim-reality gap): ML methods often fail to deliver the claimed functionality or social impacts. This paper investigates the claim-reality gap and makes a normative argument for developing accountability mechanisms for it. In making the argument, we make three contributions. First, we show why the symptom - absence of social claim accountability - is problematic. Second, we coin dead zone of accountability - a lens that scholars and practitioners can use to identify opportunities for new forms of accountability. We apply this lens to the claim-reality gap and provide a diagnosis by identifying cognitive and structural resistances to accountability in the claim-reality gap. Finally, we offer a prescription - two potential collaborative research agendas that can help create the condition for social claim accountability.",
    "source": "arXiv"
  },
  {
    "title": "Two for One, One for All: Deterministic LDC-based Robust Computation in Congested Clique",
    "title_es": "Two for One, One for All: Deterministic LDC-based Robust Computation in Congested Clique",
    "url": "https://arxiv.org/abs/2508.08740",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08740v1 Announce Type: new \nAbstract: We design a deterministic compiler that makes any computation in the Congested Clique model robust to a constant fraction $\\alpha<1$ of adversarial crash faults. In particular, we show how a network of $n$ nodes can compute any circuit of depth $d$, width $\\omega$, and gate total fan $\\Delta$, in $d\\cdot\\lceil\\frac{\\omega}{n^2}+\\frac{\\Delta}{n}\\rceil\\cdot 2^{O(\\sqrt{\\log{n}}\\log\\log{n})}$ rounds in such a faulty model. As a corollary, any $T$-round Congested Clique algorithm can be compiled into an algorithm that completes in $T^2 n^{o(1)}$ rounds in this model.\n  Our compiler obtains resilience to node crashes by coding information across the network, where we leverage locally-decodable codes (LDCs) to maintain a low complexity overhead, as these allow recovering the information needed at each computational step by querying only small parts of the codeword.\n  The main technical contribution is that because erasures occur in known locations, which correspond to crashed nodes, we can derandomize classical LDC constructions by deterministically selecting query sets that avoid sufficiently many erasures. Moreover, when decoding multiple codewords in parallel, our derandomization load-balances the queries per-node, thereby preventing congestion and maintaining a low round complexity.\n  Deterministic decoding of LDCs presents a new challenge: the adversary can target precisely the (few) nodes that are queried for decoding a certain codeword. We overcome this issue via an adaptive doubling strategy: if a decoding attempt for a codeword fails, the node doubles the number of its decoding attempts. Similarly, when the adversary crashes the decoding node itself, we replace it dynamically with two other non-crashed nodes. By carefully combining these two doubling processes, we overcome the challenges posed by the combination of a deterministic LDC with a worst case pattern of crashes.",
    "source": "arXiv"
  },
  {
    "title": "SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs",
    "title_es": "SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs",
    "url": "https://arxiv.org/abs/2508.08742",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08742v1 Announce Type: new \nAbstract: Scientific literature question answering is a pivotal step towards new scientific discoveries. Recently, \\textit{two-stage} retrieval-augmented generated large language models (RAG-LLMs) have shown impressive advancements in this domain. Such a two-stage framework, especially the second stage (reranker), is particularly essential in the scientific domain, where subtle differences in terminology may have a greatly negative impact on the final factual-oriented or knowledge-intensive answers. Despite this significant progress, the potential and limitations of these works remain unexplored. In this work, we present a Scientific Rerank-oriented RAG Benchmark (SciRerankBench), for evaluating rerankers within RAG-LLMs systems, spanning five scientific subjects. To rigorously assess the reranker performance in terms of noise resilience, relevance disambiguation, and factual consistency, we develop three types of question-context-answer (Q-C-A) pairs, i.e., Noisy Contexts (NC), Semantically Similar but Logically Irrelevant Contexts (SSLI), and Counterfactual Contexts (CC). Through systematic evaluation of 13 widely used rerankers on five families of LLMs, we provide detailed insights into their relative strengths and limitations. To the best of our knowledge, SciRerankBench is the first benchmark specifically developed to evaluate rerankers within RAG-LLMs, which provides valuable observations and guidance for their future development.",
    "source": "arXiv"
  },
  {
    "title": "Boosting Action-Information via a Variational Bottleneck on Unlabelled Robot Videos",
    "title_es": "Boosting Action-Information via a Variational Bottleneck on Unlabelled Robot Videos",
    "url": "https://arxiv.org/abs/2508.08743",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08743v1 Announce Type: new \nAbstract: Learning from demonstrations (LfD) typically relies on large amounts of action-labeled expert trajectories, which fundamentally constrains the scale of available training data. A promising alternative is to learn directly from unlabeled video demonstrations. However, we find that existing methods tend to encode latent actions that share little mutual information with the true robot actions, leading to suboptimal control performance. To address this limitation, we introduce a novel framework that explicitly maximizes the mutual information between latent actions and true actions, even in the absence of action labels. Our method leverage the variational information-bottleneck to extract action-relevant representations while discarding task-irrelevant information. We provide a theoretical analysis showing that our objective indeed maximizes the mutual information between latent and true actions. Finally, we validate our approach through extensive experiments: first in simulated robotic environments and then on real-world robotic platforms, the experimental results demonstrate that our method significantly enhances mutual information and consistently improves policy performance.",
    "source": "arXiv"
  },
  {
    "title": "Scalable Graph Indexing using GPUs for Approximate Nearest Neighbor Search",
    "title_es": "Scalable Graph Indexing using GPUs for Approximate Nearest Neighbor Search",
    "url": "https://arxiv.org/abs/2508.08744",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08744v1 Announce Type: new \nAbstract: Approximate nearest neighbor search (ANNS) in high-dimensional vector spaces has a wide range of real-world applications. Numerous methods have been proposed to handle ANNS efficiently, while graph-based indexes have gained prominence due to their high accuracy and efficiency. However, the indexing overhead of graph-based indexes remains substantial. With exponential growth in data volume and increasing demands for dynamic index adjustments, this overhead continues to escalate, posing a critical challenge. In this paper, we introduce Tagore, a fast library accelerated by GPUs for graph indexing, which has powerful capabilities of constructing refinement-based graph indexes such as NSG and Vamana. We first introduce GNN-Descent, a GPU-specific algorithm for efficient k-Nearest Neighbor (k-NN) graph initialization. GNN-Descent speeds up the similarity comparison by a two-phase descent procedure and enables highly parallelized neighbor updates. Next, aiming to support various k-NN graph pruning strategies, we formulate a universal computing procedure termed CFS and devise two generalized GPU kernels for parallel processing complex dependencies in neighbor relationships. For large-scale datasets exceeding GPU memory capacity, we propose an asynchronous GPU-CPU-disk indexing framework with a cluster-aware caching mechanism to minimize the I/O pressure on the disk. Extensive experiments on 7 real-world datasets exhibit that Tagore achieves 1.32x-112.79x speedup while maintaining the index quality.",
    "source": "arXiv"
  },
  {
    "title": "Comprehensive Comparison Network: a framework for locality-aware, routes-comparable and interpretable route recommendation",
    "title_es": "Comprehensive Comparison Network: a framework for locality-aware, routes-comparable and interpretable route recommendation",
    "url": "https://arxiv.org/abs/2508.08745",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08745v1 Announce Type: new \nAbstract: Route recommendation (RR) is a core task of route planning in the Amap app, with the goal of recommending the optimal route among candidate routes to users. Unlike traditional recommendation methods, insights into the local quality of routes and comparisons between candidate routes are crucial for enhancing recommendation performance but often overlooked in previous studies. To achieve these, we propose a novel model called Comprehensive Comparison Network (CCN). CCN not only uses query-level features (e.g. user features) and item-level features (e.g. route features, item embedding) that are common in traditional recommendations, but also introduces comparison-level features which describe the non-overlapping segments between different routes to capture the local quality of routes. The key component Comprehensive Comparison Block (CCB) in CCN is designed to enable comparisons between routes. CCB includes a Comprehensive Comparison Operator (CCO) and a multi-scenario MLP, which can update the representations of candidate routes based on a comprehensive comparison. By stacking multiple CCBs, CCN can determine the final scores of candidate routes and recommend the optimal one to the user. Additionally, since routes directly affect the costs and risks experienced by users, the RR model must be interpretable for online deployment. Therefore, we designed an interpretable pair scoring network to achieve interpretability. Both offline and online experiments demonstrate that CCN significantly improves RR performance and exhibits strong interpretability. CCN has been fully deployed in the Amap app for over a year, providing stable and optimal benefits for route recommendations.",
    "source": "arXiv"
  },
  {
    "title": "Interpretable Reward Model via Sparse Autoencoder",
    "title_es": "Interpretable Reward Model via Sparse Autoencoder",
    "url": "https://arxiv.org/abs/2508.08746",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08746v1 Announce Type: new \nAbstract: Large language models (LLMs) have been widely deployed across numerous fields. Reinforcement Learning from Human Feedback (RLHF) leverages reward models (RMs) as proxies for human preferences to align LLM behaviors with human values, making the accuracy, reliability, and interpretability of RMs critical for effective alignment. However, traditional RMs lack interpretability, offer limited insight into the reasoning behind reward assignments, and are inflexible toward user preference shifts. While recent multidimensional RMs aim for improved interpretability, they often fail to provide feature-level attribution and require costly annotations. To overcome these limitations, we introduce the Sparse Autoencoder-enhanced Reward Model (\\textbf{SARM}), a novel architecture that integrates a pretrained Sparse Autoencoder (SAE) into a reward model. SARM maps the hidden activations of LLM-based RM into an interpretable, sparse, and monosemantic feature space, from which a scalar head aggregates feature activations to produce transparent and conceptually meaningful reward scores. Empirical evaluations demonstrate that SARM facilitates direct feature-level attribution of reward assignments, allows dynamic adjustment to preference shifts, and achieves superior alignment performance compared to conventional reward models. Our code is available at https://github.com/schrieffer-z/sarm.",
    "source": "arXiv"
  },
  {
    "title": "Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT",
    "title_es": "Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT",
    "url": "https://arxiv.org/abs/2508.08748",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08748v1 Announce Type: new \nAbstract: Robotic pick-and-place tasks in convenience stores pose challenges due to dense object arrangements, occlusions, and variations in object properties such as color, shape, size, and texture. These factors complicate trajectory planning and grasping. This paper introduces a perception-action pipeline leveraging annotation-guided visual prompting, where bounding box annotations identify both pickable objects and placement locations, providing structured spatial guidance. Instead of traditional step-by-step planning, we employ Action Chunking with Transformers (ACT) as an imitation learning algorithm, enabling the robotic arm to predict chunked action sequences from human demonstrations. This facilitates smooth, adaptive, and data-driven pick-and-place operations. We evaluate our system based on success rate and visual analysis of grasping behavior, demonstrating improved grasp accuracy and adaptability in retail environments.",
    "source": "arXiv"
  },
  {
    "title": "Approximate DBSCAN under Differential Privacy",
    "title_es": "Approximate DBSCAN under Differential Privacy",
    "url": "https://arxiv.org/abs/2508.08749",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08749v1 Announce Type: new \nAbstract: This paper revisits the DBSCAN problem under differential privacy (DP). Existing DP-DBSCAN algorithms aim at publishing the cluster labels of the input points. However, we show that both empirically and theoretically, this approach cannot offer any utility in the published results. We therefore propose an alternative definition of DP-DBSCAN based on the notion of spans. We argue that publishing the spans actually better serves the purposes of visualization and classification of DBSCAN. Then we present a linear-time DP-DBSCAN algorithm achieving the sandwich quality guarantee in any constant dimensions, as well as matching lower bounds on the approximation ratio. A key building block in our algorithm is a linear-time algorithm for constructing a histogram under pure-DP, which is of independent interest. Finally, we conducted experiments on both synthetic and real-world datasets to verify the practical performance of our DP-DBSCAN algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Exploring Palette based Color Guidance in Diffusion Models",
    "title_es": "Exploring Palette based Color Guidance in Diffusion Models",
    "url": "https://arxiv.org/abs/2508.08754",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08754v1 Announce Type: new \nAbstract: With the advent of diffusion models, Text-to-Image (T2I) generation has seen substantial advancements. Current T2I models allow users to specify object colors using linguistic color names, and some methods aim to personalize color-object association through prompt learning. However, existing models struggle to provide comprehensive control over the color schemes of an entire image, especially for background elements and less prominent objects not explicitly mentioned in prompts. This paper proposes a novel approach to enhance color scheme control by integrating color palettes as a separate guidance mechanism alongside prompt instructions. We investigate the effectiveness of palette guidance by exploring various palette representation methods within a diffusion-based image colorization framework. To facilitate this exploration, we construct specialized palette-text-image datasets and conduct extensive quantitative and qualitative analyses. Our results demonstrate that incorporating palette guidance significantly improves the model's ability to generate images with desired color schemes, enabling a more controlled and refined colorization process.",
    "source": "arXiv"
  },
  {
    "title": "Solving Approximation Tasks with Greedy Deep Kernel Methods",
    "title_es": "Solving Approximation Tasks with Greedy Deep Kernel Methods",
    "url": "https://arxiv.org/abs/2508.08759",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08759v1 Announce Type: new \nAbstract: Kernel methods are versatile tools for function approximation and surrogate modeling. In particular, greedy techniques offer computational efficiency and reliability through inherent sparsity and provable convergence. Inspired by the success of deep neural networks and structured deep kernel networks, we consider deep, multilayer kernels for greedy approximation. This multilayer structure, consisting of linear kernel layers and optimizable kernel activation function layers in an alternating fashion, increases the expressiveness of the kernels and thus of the resulting approximants. Compared to standard kernels, deep kernels are able to adapt kernel intrinsic shape parameters automatically, incorporate transformations of the input space and induce a data-dependent reproducing kernel Hilbert space. For this, deep kernels need to be pretrained using a specifically tailored optimization objective. In this work, we not only introduce deep kernel greedy models, but also present numerical investigations and comparisons with neural networks, which clearly show the advantages in terms of approximation accuracies. As applications we consider the approximation of model problems, the prediction of breakthrough curves for reactive flow through porous media and the approximation of solutions for parametrized ordinary differential equation systems.",
    "source": "arXiv"
  },
  {
    "title": "DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation",
    "title_es": "DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation",
    "url": "https://arxiv.org/abs/2508.08761",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08761v1 Announce Type: new \nAbstract: The manual translation of unstructured team dialogue into the structured artifacts required for Information Technology (IT) project governance is a critical bottleneck in modern information systems management. We introduce DevNous, a Large Language Model-based (LLM) multi-agent expert system, to automate this unstructured-to-structured translation process. DevNous integrates directly into team chat environments, identifying actionable intents from informal dialogue and managing stateful, multi-turn workflows for core administrative tasks like automated task formalization and progress summary synthesis. To quantitatively evaluate the system, we introduce a new benchmark of 160 realistic, interactive conversational turns. The dataset was manually annotated with a multi-label ground truth and is publicly available. On this benchmark, DevNous achieves an exact match turn accuracy of 81.3\\% and a multiset F1-Score of 0.845, providing strong evidence for its viability. The primary contributions of this work are twofold: (1) a validated architectural pattern for developing ambient administrative agents, and (2) the introduction of the first robust empirical baseline and public benchmark dataset for this challenging problem domain.",
    "source": "arXiv"
  },
  {
    "title": "CARES: Collaborative Agentic Reasoning for Error Detection in Surgery",
    "title_es": "CARES: Collaborative Agentic Reasoning for Error Detection in Surgery",
    "url": "https://arxiv.org/abs/2508.08764",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08764v1 Announce Type: new \nAbstract: Robotic-assisted surgery (RAS) introduces complex challenges that current surgical error detection methods struggle to address effectively due to limited training data and methodological constraints. Therefore, we construct MERP (Multi-class Error in Robotic Prostatectomy), a comprehensive dataset for error detection in robotic prostatectomy with frame-level annotations featuring six clinically aligned error categories. In addition, we propose CARES (Collaborative Agentic Reasoning for Error Detection in Surgery), a novel zero-shot clinically-informed and risk-stratified agentic reasoning architecture for multi-class surgical error detection. CARES implements adaptive generation of medically informed, error-specific Chain-of-Thought (CoT) prompts across multiple expertise levels. The framework employs risk-aware routing to assign error task to expertise-matched reasoning pathways based on complexity and clinical impact. Subsequently, each pathway decomposes surgical error analysis into three specialized agents with temporal, spatial, and procedural analysis. Each agent analyzes using dynamically selected prompts tailored to the assigned expertise level and error type, generating detailed and transparent reasoning traces. By incorporating clinically informed reasoning from established surgical assessment guidelines, CARES enables zero-shot surgical error detection without prior training. Evaluation demonstrates superior performance with 54.3 mF1 on RARP and 52.0 mF1 on MERP datasets, outperforming existing zero-shot approaches by up to 14% while remaining competitive with trained models. Ablation studies demonstrate the effectiveness of our method. The dataset and code will be publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Bridging the Gap: A Framework for Real-World Video Deepfake Detection via Social Network Compression Emulation",
    "title_es": "Bridging the Gap: A Framework for Real-World Video Deepfake Detection via Social Network Compression Emulation",
    "url": "https://arxiv.org/abs/2508.08765",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08765v1 Announce Type: new \nAbstract: The growing presence of AI-generated videos on social networks poses new challenges for deepfake detection, as detectors trained under controlled conditions often fail to generalize to real-world scenarios. A key factor behind this gap is the aggressive, proprietary compression applied by platforms like YouTube and Facebook, which launder low-level forensic cues. However, replicating these transformations at scale is difficult due to API limitations and data-sharing constraints. For these reasons, we propose a first framework that emulates the video sharing pipelines of social networks by estimating compression and resizing parameters from a small set of uploaded videos. These parameters enable a local emulator capable of reproducing platform-specific artifacts on large datasets without direct API access. Experiments on FaceForensics++ videos shared via social networks demonstrate that our emulated data closely matches the degradation patterns of real uploads. Furthermore, detectors fine-tuned on emulated videos achieve comparable performance to those trained on actual shared media. Our approach offers a scalable and practical solution for bridging the gap between lab-based training and real-world deployment of deepfake detectors, particularly in the underexplored domain of compressed video content.",
    "source": "arXiv"
  },
  {
    "title": "Robot can reduce superior's dominance in group discussions with human social hierarchy",
    "title_es": "Robot can reduce superior's dominance in group discussions with human social hierarchy",
    "url": "https://arxiv.org/abs/2508.08767",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08767v1 Announce Type: new \nAbstract: This study investigated whether robotic agents that deal with social hierarchical relationships can reduce the dominance of superiors and equalize participation among participants in discussions with hierarchical structures. Thirty doctors and students having hierarchical relationship were gathered as participants, and an intervention experiment was conducted using a robot that can encourage participants to speak depending on social hierarchy. These were compared with strategies that intervened equally for all participants without considering hierarchy and with a no-action. The robots performed follow actions, showing backchanneling to speech, and encourage actions, prompting speech from members with less speaking time, on the basis of the hierarchical relationships among group members to equalize participation. The experimental results revealed that the robot's actions could potentially influence the speaking time among members, but it could not be conclusively stated that there were significant differences between the robot's action conditions. However, the results suggested that it might be possible to influence speaking time without decreasing the satisfaction of superiors. This indicates that in discussion scenarios where experienced superiors are likely to dominate, controlling the robot's backchanneling behavior could potentially suppress dominance and equalize participation among group members.",
    "source": "arXiv"
  },
  {
    "title": "Differentiated Information Mining: A Semi-supervised Learning Framework for GNNs",
    "title_es": "Differentiated Information Mining: A Semi-supervised Learning Framework for GNNs",
    "url": "https://arxiv.org/abs/2508.08769",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08769v1 Announce Type: new \nAbstract: In semi-supervised learning (SSL) for enhancing the performance of graph neural networks (GNNs) with unlabeled data, introducing mutually independent decision factors for cross-validation is regarded as an effective strategy to alleviate pseudo-label confirmation bias and training collapse. However, obtaining such factors is challenging in practice: additional and valid information sources are inherently scarce, and even when such sources are available, their independence from the original source cannot be guaranteed. To address this challenge, In this paper we propose a Differentiated Factor Consistency Semi-supervised Framework (DiFac), which derives differentiated factors from a single information source and enforces their consistency. During pre-training, the model learns to extract these factors; in training, it iteratively removes samples with conflicting factors and ranks pseudo-labels based on the shortest stave principle, selecting the top candidate samples to reduce overconfidence commonly observed in confidence-based or ensemble-based methods. Our framework can also incorporate additional information sources. In this work, we leverage the large multimodal language model to introduce latent textual knowledge as auxiliary decision factors, and we design a accountability scoring mechanism to mitigate additional erroneous judgments introduced by these auxiliary factors. Experiments on multiple benchmark datasets demonstrate that DiFac consistently improves robustness and generalization in low-label regimes, outperforming other baseline methods.",
    "source": "arXiv"
  },
  {
    "title": "Optimal Boost Design for Auto-bidding Mechanism with Publisher Quality Constraints",
    "title_es": "Optimal Boost Design for Auto-bidding Mechanism with Publisher Quality Constraints",
    "url": "https://arxiv.org/abs/2508.08772",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08772v1 Announce Type: new \nAbstract: Online bidding is crucial in mobile ecosystems, enabling real-time ad allocation across billions of devices to optimize performance and user experience. Improving ad allocation efficiency is a long-standing research problem, as it directly enhances the economic outcomes for all participants in advertising platforms. This paper investigates the design of optimal boost factors in online bidding while incorporating quality value (the impact of displayed ads on publishers' long-term benefits). To address the divergent interests on quality, we establish a three-party auction framework with a unified welfare metric of advertiser and publisher. Within this framework, we derive the theoretical efficiency lower bound for C-competitive boost in second-price single-slot auctions, then design a novel quality-involved Boosting (q-Boost) algorithm for computing the optimal boost factor. Experimental validation on Alibaba's public dataset (AuctionNet) demonstrates 2%-6% welfare improvements over conventional approaches, proving our method's effectiveness in real-world settings.",
    "source": "arXiv"
  },
  {
    "title": "Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance",
    "title_es": "Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance",
    "url": "https://arxiv.org/abs/2508.08774",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08774v1 Announce Type: new \nAbstract: Augmented Reality (AR) systems are increasingly integrating foundation models, such as Multimodal Large Language Models (MLLMs), to provide more context-aware and adaptive user experiences. This integration has led to the development of AR agents to support intelligent, goal-directed interactions in real-world environments. While current AR agents effectively support immediate tasks, they struggle with complex multi-step scenarios that require understanding and leveraging user's long-term experiences and preferences. This limitation stems from their inability to capture, retain, and reason over historical user interactions in spatiotemporal contexts. To address these challenges, we propose a conceptual framework for memory-augmented AR agents that can provide personalized task assistance by learning from and adapting to user-specific experiences over time. Our framework consists of four interconnected modules: (1) Perception Module for multimodal sensor processing, (2) Memory Module for persistent spatiotemporal experience storage, (3) Spatiotemporal Reasoning Module for synthesizing past and present contexts, and (4) Actuator Module for effective AR communication. We further present an implementation roadmap, a future evaluation strategy, a potential target application and use cases to demonstrate the practical applicability of our framework across diverse domains. We aim for this work to motivate future research toward developing more intelligent AR systems that can effectively bridge user's interaction history with adaptive, context-aware task assistance.",
    "source": "arXiv"
  },
  {
    "title": "SonicRadiation: A Hybrid Numerical Solution for Sound Radiation without Ghost Cells",
    "title_es": "SonicRadiation: A Hybrid Numerical Solution for Sound Radiation without Ghost Cells",
    "url": "https://arxiv.org/abs/2508.08775",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08775v1 Announce Type: new \nAbstract: Interactive synthesis of physical sound effects is crucial in digital media production. Sound radiation simulation, a key component of physically based sound synthesis, has posed challenges in the context of complex object boundaries. Previous methods, such as ghost cell-based finite-difference time-domain (FDTD) wave solver, have struggled to address these challenges, leading to large errors and failures in complex boundaries because of the limitation of ghost cells. We present SonicRadiation, a hybrid numerical solution capable of handling complex and dynamic object boundaries in sound radiation simulation without relying on ghost cells. We derive a consistent formulation to connect the physical quantities on grid cells in FDTD with the boundary elements in the time-domain boundary element method (TDBEM). Hereby, we propose a boundary grid synchronization strategy to seamlessly integrate TDBEM with FDTD while maintaining high numerical accuracy. Our method holds both advantages from the accuracy of TDBEM for the near-field and the efficiency of FDTD for the far-field. Experimental results demonstrate the superiority of our method in sound radiation simulation over previous approaches in terms of accuracy and efficiency, particularly in complex scenes, further validating its effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge",
    "title_es": "Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge",
    "url": "https://arxiv.org/abs/2508.08777",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08777v1 Announce Type: new \nAbstract: Evaluating personalized recommendations remains a central challenge, especially in long-form audio domains like podcasts, where traditional offline metrics suffer from exposure bias and online methods such as A/B testing are costly and operationally constrained. In this paper, we propose a novel framework that leverages Large Language Models (LLMs) as offline judges to assess the quality of podcast recommendations in a scalable and interpretable manner. Our two-stage profile-aware approach first constructs natural-language user profiles distilled from 90 days of listening history. These profiles summarize both topical interests and behavioral patterns, serving as compact, interpretable representations of user preferences. Rather than prompting the LLM with raw data, we use these profiles to provide high-level, semantically rich context-enabling the LLM to reason more effectively about alignment between a user's interests and recommended episodes. This reduces input complexity and improves interpretability. The LLM is then prompted to deliver fine-grained pointwise and pairwise judgments based on the profile-episode match. In a controlled study with 47 participants, our profile-aware judge matched human judgments with high fidelity and outperformed or matched a variant using raw listening histories. The framework enables efficient, profile-aware evaluation for iterative testing and model selection in recommender systems.",
    "source": "arXiv"
  },
  {
    "title": "SHREC 2025: Retrieval of Optimal Objects for Multi-modal Enhanced Language and Spatial Assistance (ROOMELSA)",
    "title_es": "SHREC 2025: Retrieval of Optimal Objects for Multi-modal Enhanced Language and Spatial Assistance (ROOMELSA)",
    "url": "https://arxiv.org/abs/2508.08781",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08781v1 Announce Type: new \nAbstract: Recent 3D retrieval systems are typically designed for simple, controlled scenarios, such as identifying an object from a cropped image or a brief description. However, real-world scenarios are more complex, often requiring the recognition of an object in a cluttered scene based on a vague, free-form description. To this end, we present ROOMELSA, a new benchmark designed to evaluate a system's ability to interpret natural language. Specifically, ROOMELSA attends to a specific region within a panoramic room image and accurately retrieves the corresponding 3D model from a large database. In addition, ROOMELSA includes over 1,600 apartment scenes, nearly 5,200 rooms, and more than 44,000 targeted queries. Empirically, while coarse object retrieval is largely solved, only one top-performing model consistently ranked the correct match first across nearly all test cases. Notably, a lightweight CLIP-based model also performed well, although it struggled with subtle variations in materials, part structures, and contextual cues, resulting in occasional errors. These findings highlight the importance of tightly integrating visual and language understanding. By bridging the gap between scene-level grounding and fine-grained 3D retrieval, ROOMELSA establishes a new benchmark for advancing robust, real-world 3D recognition systems.",
    "source": "arXiv"
  },
  {
    "title": "DiffPose-Animal: A Language-Conditioned Diffusion Framework for Animal Pose Estimation",
    "title_es": "DiffPose-Animal: A Language-Conditioned Diffusion Framework for Animal Pose Estimation",
    "url": "https://arxiv.org/abs/2508.08783",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08783v1 Announce Type: new \nAbstract: Animal pose estimation is a fundamental task in computer vision, with growing importance in ecological monitoring, behavioral analysis, and intelligent livestock management. Compared to human pose estimation, animal pose estimation is more challenging due to high interspecies morphological diversity, complex body structures, and limited annotated data. In this work, we introduce DiffPose-Animal, a novel diffusion-based framework for top-down animal pose estimation. Unlike traditional heatmap regression methods, DiffPose-Animal reformulates pose estimation as a denoising process under the generative framework of diffusion models. To enhance semantic guidance during keypoint generation, we leverage large language models (LLMs) to extract both global anatomical priors and local keypoint-wise semantics based on species-specific prompts. These textual priors are encoded and fused with image features via cross-attention modules to provide biologically meaningful constraints throughout the denoising process. Additionally, a diffusion-based keypoint decoder is designed to progressively refine pose predictions, improving robustness to occlusion and annotation sparsity. Extensive experiments on public animal pose datasets demonstrate the effectiveness and generalization capability of our method, especially under challenging scenarios with diverse species, cluttered backgrounds, and incomplete keypoints.",
    "source": "arXiv"
  },
  {
    "title": "Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering",
    "title_es": "Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering",
    "url": "https://arxiv.org/abs/2508.08785",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08785v1 Announce Type: new \nAbstract: LLMs often suffer from hallucinations and outdated or incomplete knowledge. RAG is proposed to address these issues by integrating external knowledge like that in KGs into LLMs. However, leveraging private KGs in RAG systems poses significant privacy risks due to the black-box nature of LLMs and potential insecure data transmission, especially when using third-party LLM APIs lacking transparency and control. In this paper, we investigate the privacy-protected RAG scenario for the first time, where entities in KGs are anonymous for LLMs, thus preventing them from accessing entity semantics. Due to the loss of semantics of entities, previous RAG systems cannot retrieve question-relevant knowledge from KGs by matching questions with the meaningless identifiers of anonymous entities. To realize an effective RAG system in this scenario, two key challenges must be addressed: (1) How can anonymous entities be converted into retrievable information. (2) How to retrieve question-relevant anonymous entities. Hence, we propose a novel ARoG framework including relation-centric abstraction and structure-oriented abstraction strategies. For challenge (1), the first strategy abstracts entities into high-level concepts by dynamically capturing the semantics of their adjacent relations. It supplements meaningful semantics which can further support the retrieval process. For challenge (2), the second strategy transforms unstructured natural language questions into structured abstract concept paths. These paths can be more effectively aligned with the abstracted concepts in KGs, thereby improving retrieval performance. To guide LLMs to effectively retrieve knowledge from KGs, the two strategies strictly protect privacy from being exposed to LLMs. Experiments on three datasets demonstrate that ARoG achieves strong performance and privacy-robustness.",
    "source": "arXiv"
  },
  {
    "title": "Never Compromise to Vulnerabilities: A Comprehensive Survey on AI Governance",
    "title_es": "Never Compromise to Vulnerabilities: A Comprehensive Survey on AI Governance",
    "url": "https://arxiv.org/abs/2508.08789",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08789v1 Announce Type: new \nAbstract: The rapid advancement of AI has expanded its capabilities across domains, yet introduced critical technical vulnerabilities, such as algorithmic bias and adversarial sensitivity, that pose significant societal risks, including misinformation, inequity, security breaches, physical harm, and eroded public trust. These challenges highlight the urgent need for robust AI governance. We propose a comprehensive framework integrating technical and societal dimensions, structured around three interconnected pillars: Intrinsic Security (system reliability), Derivative Security (real-world harm mitigation), and Social Ethics (value alignment and accountability). Uniquely, our approach unifies technical methods, emerging evaluation benchmarks, and policy insights to promote transparency, accountability, and trust in AI systems. Through a systematic review of over 300 studies, we identify three core challenges: (1) the generalization gap, where defenses fail against evolving threats; (2) inadequate evaluation protocols that overlook real-world risks; and (3) fragmented regulations leading to inconsistent oversight. These shortcomings stem from treating governance as an afterthought, rather than a foundational design principle, resulting in reactive, siloed efforts that fail to address the interdependence of technical integrity and societal trust. To overcome this, we present an integrated research agenda that bridges technical rigor with social responsibility. Our framework offers actionable guidance for researchers, engineers, and policymakers to develop AI systems that are not only robust and secure but also ethically aligned and publicly trustworthy. The accompanying repository is available at https://github.com/ZTianle/Awesome-AI-SG.",
    "source": "arXiv"
  },
  {
    "title": "Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments",
    "title_es": "Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments",
    "url": "https://arxiv.org/abs/2508.08791",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08791v1 Announce Type: new \nAbstract: Effective tool use is essential for large language models (LLMs) to interact meaningfully with their environment. However, progress is limited by the lack of efficient reinforcement learning (RL) frameworks specifically designed for tool use, due to challenges in constructing stable training environments and designing verifiable reward mechanisms. To address this, we propose an automated environment construction pipeline, incorporating scenario decomposition, document generation, function integration, complexity scaling, and localized deployment. This enables the creation of high-quality training environments that provide detailed and measurable feedback without relying on external tools. Additionally, we introduce a verifiable reward mechanism that evaluates both the precision of tool use and the completeness of task execution. When combined with trajectory data collected from the constructed environments, this mechanism integrates seamlessly with standard RL algorithms to facilitate feedback-driven model training. Experiments on LLMs of varying scales demonstrate that our approach significantly enhances the models' tool-use performance without degrading their general capabilities, regardless of inference modes or training algorithms. Our analysis suggests that these gains result from improved context understanding and reasoning, driven by updates to the lower-layer MLP parameters in models.",
    "source": "arXiv"
  },
  {
    "title": "Region-Adaptive Video Sharpening via Rate-Perception Optimization",
    "title_es": "Region-Adaptive Video Sharpening via Rate-Perception Optimization",
    "url": "https://arxiv.org/abs/2508.08794",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08794v1 Announce Type: new \nAbstract: Sharpening is a widely adopted video enhancement technique. However, uniform sharpening intensity ignores texture variations, degrading video quality. Sharpening also increases bitrate, and there's a lack of techniques to optimally allocate these additional bits across diverse regions. Thus, this paper proposes RPO-AdaSharp, an end-to-end region-adaptive video sharpening model for both perceptual enhancement and bitrate savings. We use the coding tree unit (CTU) partition mask as prior information to guide and constrain the allocation of increased bits. Experiments on benchmarks demonstrate the effectiveness of the proposed model qualitatively and quantitatively.",
    "source": "arXiv"
  },
  {
    "title": "A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions",
    "title_es": "A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions",
    "url": "https://arxiv.org/abs/2508.08795",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08795v1 Announce Type: new \nAbstract: Large language models (LLMs) acquire vast knowledge from large text corpora, but this information can become outdated or inaccurate. Since retraining is computationally expensive, knowledge editing offers an efficient alternative -- modifying internal knowledge without full retraining. These methods aim to update facts precisely while preserving the model's overall capabilities. While existing surveys focus on the mechanism of editing (e.g., parameter changes vs. external memory), they often overlook the function of the knowledge being edited. This survey introduces a novel, complementary function-based taxonomy to provide a more holistic view. We examine how different mechanisms apply to various knowledge types -- factual, temporal, conceptual, commonsense, and social -- highlighting how editing effectiveness depends on the nature of the target knowledge. By organizing our review along these two axes, we map the current landscape, outline the strengths and limitations of existing methods, define the problem formally, survey evaluation tasks and datasets, and conclude with open challenges and future directions.",
    "source": "arXiv"
  },
  {
    "title": "MonoPartNeRF:Human Reconstruction from Monocular Video via Part-Based Neural Radiance Fields",
    "title_es": "MonoPartNeRF:Human Reconstruction from Monocular Video via Part-Based Neural Radiance Fields",
    "url": "https://arxiv.org/abs/2508.08798",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08798v1 Announce Type: new \nAbstract: In recent years, Neural Radiance Fields (NeRF) have achieved remarkable progress in dynamic human reconstruction and rendering. Part-based rendering paradigms, guided by human segmentation, allow for flexible parameter allocation based on structural complexity, thereby enhancing representational efficiency. However, existing methods still struggle with complex pose variations, often producing unnatural transitions at part boundaries and failing to reconstruct occluded regions accurately in monocular settings. We propose MonoPartNeRF, a novel framework for monocular dynamic human rendering that ensures smooth transitions and robust occlusion recovery. First, we build a bidirectional deformation model that combines rigid and non-rigid transformations to establish a continuous, reversible mapping between observation and canonical spaces. Sampling points are projected into a parameterized surface-time space (u, v, t) to better capture non-rigid motion. A consistency loss further suppresses deformation-induced artifacts and discontinuities. We introduce a part-based pose embedding mechanism that decomposes global pose vectors into local joint embeddings based on body regions. This is combined with keyframe pose retrieval and interpolation, along three orthogonal directions, to guide pose-aware feature sampling. A learnable appearance code is integrated via attention to model dynamic texture changes effectively. Experiments on the ZJU-MoCap and MonoCap datasets demonstrate that our method significantly outperforms prior approaches under complex pose and occlusion conditions, achieving superior joint alignment, texture fidelity, and structural continuity.",
    "source": "arXiv"
  },
  {
    "title": "Fault Tolerant Multi-Agent Learning with Adversarial Budget Constraints",
    "title_es": "Fault Tolerant Multi-Agent Learning with Adversarial Budget Constraints",
    "url": "https://arxiv.org/abs/2508.08800",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08800v1 Announce Type: new \nAbstract: In multi-agent systems, the safe and reliable execution of tasks often depends on agents correctly coordinating their actions. However, in real-world deployments, failures of computational components are inevitable, presenting a critical challenge: ensuring that multi-agent reinforcement learning (MARL) policies remain effective even when some agents malfunction. We propose the Multi-Agent Robust Training Algorithm (MARTA), a plug-and-play framework for training MARL agents to be resilient to potentially severe faults. MARTA operates in cooperative multi-agent settings where agents may lose the ability to execute their intended actions. It learns to identify failure scenarios that are especially detrimental to system performance and equips agents with strategies to mitigate their impact. At the heart of MARTA is a novel adversarial Markov game in which an adversary -- modelled via \\emph{Markov switching controls} -- learns to disable agents in high-risk state regions, while the remaining agents are trained to \\emph{jointly} best-respond to such targeted malfunctions. To ensure practicality, MARTA enforces a malfunction budget, constraining the adversary to a fixed number of failures and learning robust policies accordingly. We provide theoretical guarantees that MARTA converges to a Markov perfect equilibrium, ensuring agents optimally counteract worst-case faults. Empirically, we show that MARTA achieves state-of-the-art fault-tolerant performance across benchmark environments, including Multi-Agent Particle World and Level-Based Foraging.",
    "source": "arXiv"
  },
  {
    "title": "TechOps: Technical Documentation Templates for the AI Act",
    "title_es": "TechOps: Technical Documentation Templates for the AI Act",
    "url": "https://arxiv.org/abs/2508.08804",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08804v1 Announce Type: new \nAbstract: Operationalizing the EU AI Act requires clear technical documentation to ensure AI systems are transparent, traceable, and accountable. Existing documentation templates for AI systems do not fully cover the entire AI lifecycle while meeting the technical documentation requirements of the AI Act.\n  This paper addresses those shortcomings by introducing open-source templates and examples for documenting data, models, and applications to provide sufficient documentation for certifying compliance with the AI Act. These templates track the system status over the entire AI lifecycle, ensuring traceability, reproducibility, and compliance with the AI Act. They also promote discoverability and collaboration, reduce risks, and align with best practices in AI documentation and governance.\n  The templates are evaluated and refined based on user feedback to enable insights into their usability and implementability. We then validate the approach on real-world scenarios, providing examples that further guide their implementation: the data template is followed to document a skin tones dataset created to support fairness evaluations of downstream computer vision models and human-centric applications; the model template is followed to document a neural network for segmenting human silhouettes in photos. The application template is tested on a system deployed for construction site safety using real-time video analytics and sensor data. Our results show that TechOps can serve as a practical tool to enable oversight for regulatory compliance and responsible AI development.",
    "source": "arXiv"
  },
  {
    "title": "Opening Musical Creativity? Embedded Ideologies in Generative-AI Music Systems",
    "title_es": "Opening Musical Creativity? Embedded Ideologies in Generative-AI Music Systems",
    "url": "https://arxiv.org/abs/2508.08805",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08805v1 Announce Type: new \nAbstract: AI systems for music generation are increasingly common and easy to use, granting people without any musical background the ability to create music. Because of this, generative-AI has been marketed and celebrated as a means of democratizing music making. However, inclusivity often functions as marketable rhetoric rather than a genuine guiding principle in these industry settings. In this paper, we look at four generative-AI music making systems available to the public as of mid-2025 (AIVA, Stable Audio, Suno, and Udio) and track how they are rhetoricized by their developers, and received by users. Our aim is to investigate ideologies that are driving the early-stage development and adoption of generative-AI in music making, with a particular focus on democratization. A combination of autoethnography and digital ethnography is used to examine patterns and incongruities in rhetoric when positioned against product functionality. The results are then collated to develop a nuanced, contextual discussion. The shared ideology we map between producers and consumers is individualist, globalist, techno-liberal, and ethically evasive. It is a 'total ideology' which obfuscates individual responsibility, and through which the nature of music and musical practice is transfigured to suit generative outcomes.",
    "source": "arXiv"
  },
  {
    "title": "Effective and Efficient Attributed Hypergraph Embedding on Nodes and Hyperedges",
    "title_es": "Effective and Efficient Attributed Hypergraph Embedding on Nodes and Hyperedges",
    "url": "https://arxiv.org/abs/2508.08807",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08807v1 Announce Type: new \nAbstract: An attributed hypergraph comprises nodes with attributes and hyperedges that connect varying numbers of nodes. Attributed hypergraph node and hyperedge embedding (AHNEE) maps nodes and hyperedges to compact vectors for use in important tasks such as node classification, hyperedge link prediction, and hyperedge classification. Generating high-quality embeddings is challenging due to the complexity of attributed hypergraphs and the need to embed both nodes and hyperedges, especially in large-scale data. Existing solutions often fall short by focusing only on nodes or lacking native support for attributed hypergraphs, leading to inferior quality, and struggle with scalability on large attributed hypergraphs.\n  We propose SAHE, an efficient and effective approach that unifies node and hyperedge embeddings for AHNEE computation, advancing the state of the art via comprehensive embedding formulations and algorithmic designs. First, we introduce two higher-order similarity measures, HMS-N and HMS-E, to capture similarities between node pairs and hyperedge pairs, respectively. These measures consider multi-hop connections and global topology within an extended hypergraph that incorporates attribute-based hyperedges. SAHE formulates the AHNEE objective to jointly preserve all-pair HMS-N and HMS-N similarities. Direct optimization is computationally expensive, so we analyze and unify core approximations of all-pair HMS-N and HMS-N to solve them simultaneously. To enhance efficiency, we design several non-trivial optimizations that avoid iteratively materializing large dense matrices while maintaining high-quality results. Extensive experiments on diverse attributed hypergraphs and 3 downstream tasks, compared against 11 baselines, show that SAHE consistently outperforms existing methods in embedding quality and is up to orders of magnitude faster.",
    "source": "arXiv"
  },
  {
    "title": "Identity-Preserving Aging and De-Aging of Faces in the StyleGAN Latent Space",
    "title_es": "Identity-Preserving Aging and De-Aging of Faces in the StyleGAN Latent Space",
    "url": "https://arxiv.org/abs/2508.08808",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08808v1 Announce Type: new \nAbstract: Face aging or de-aging with generative AI has gained significant attention for its applications in such fields like forensics, security, and media. However, most state of the art methods rely on conditional Generative Adversarial Networks (GANs), Diffusion-based models, or Visual Language Models (VLMs) to age or de-age faces based on predefined age categories and conditioning via loss functions, fine-tuning, or text prompts. The reliance on such conditioning leads to complex training requirements, increased data needs, and challenges in generating consistent results. Additionally, identity preservation is rarely taken into accountor evaluated on a single face recognition system without any control or guarantees on whether identity would be preserved in a generated aged/de-aged face. In this paper, we propose to synthesize aged and de-aged faces via editing latent space of StyleGAN2 using a simple support vector modeling of aging/de-aging direction and several feature selection approaches. By using two state-of-the-art face recognition systems, we empirically find the identity preserving subspace within the StyleGAN2 latent space, so that an apparent age of a given face can changed while preserving the identity. We then propose a simple yet practical formula for estimating the limits on aging/de-aging parameters that ensures identity preservation for a given input face. Using our method and estimated parameters we have generated a public dataset of synthetic faces at different ages that can be used for benchmarking cross-age face recognition, age assurance systems, or systems for detection of synthetic images. Our code and dataset are available at the project page https://www.idiap.ch/paper/agesynth/",
    "source": "arXiv"
  },
  {
    "title": "Not in My Backyard! Temporal Voting Over Public Chores",
    "title_es": "Not in My Backyard! Temporal Voting Over Public Chores",
    "url": "https://arxiv.org/abs/2508.08810",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08810v1 Announce Type: new \nAbstract: We study a temporal voting model where voters have dynamic preferences over a set of public chores -- projects that benefit society, but impose individual costs on those affected by their implementation. We investigate the computational complexity of optimizing utilitarian and egalitarian welfare. Our results show that while optimizing the former is computationally straightforward, minimizing the latter is computationally intractable, even in very restricted cases. Nevertheless, we identify several settings where this problem can be solved efficiently, either exactly or by an approximation algorithm. We also examine the effects of enforcing temporal fairness and its impact on social welfare, and analyze the competitive ratio of online algorithms. We then explore the strategic behavior of agents, providing insights into potential malfeasance in such decision-making environments. Finally, we discuss a range of fairness measures and their suitability for our setting.",
    "source": "arXiv"
  },
  {
    "title": "Revisiting Efficient Semantic Segmentation: Learning Offsets for Better Spatial and Class Feature Alignment",
    "title_es": "Revisiting Efficient Semantic Segmentation: Learning Offsets for Better Spatial and Class Feature Alignment",
    "url": "https://arxiv.org/abs/2508.08811",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08811v1 Announce Type: new \nAbstract: Semantic segmentation is fundamental to vision systems requiring pixel-level scene understanding, yet deploying it on resource-constrained devices demands efficient architectures. Although existing methods achieve real-time inference through lightweight designs, we reveal their inherent limitation: misalignment between class representations and image features caused by a per-pixel classification paradigm. With experimental analysis, we find that this paradigm results in a highly challenging assumption for efficient scenarios: Image pixel features should not vary for the same category in different images. To address this dilemma, we propose a coupled dual-branch offset learning paradigm that explicitly learns feature and class offsets to dynamically refine both class representations and spatial image features. Based on the proposed paradigm, we construct an efficient semantic segmentation network, OffSeg. Notably, the offset learning paradigm can be adopted to existing methods with no additional architectural changes. Extensive experiments on four datasets, including ADE20K, Cityscapes, COCO-Stuff-164K, and Pascal Context, demonstrate consistent improvements with negligible parameters. For instance, on the ADE20K dataset, our proposed offset learning paradigm improves SegFormer-B0, SegNeXt-T, and Mask2Former-Tiny by 2.7%, 1.9%, and 2.6% mIoU, respectively, with only 0.1-0.2M additional parameters required.",
    "source": "arXiv"
  },
  {
    "title": "TARA: Token-Aware LoRA for Composable Personalization in Diffusion Models",
    "title_es": "TARA: Token-Aware LoRA for Composable Personalization in Diffusion Models",
    "url": "https://arxiv.org/abs/2508.08812",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08812v1 Announce Type: new \nAbstract: Personalized text-to-image generation aims to synthesize novel images of a specific subject or style using only a few reference images. Recent methods based on Low-Rank Adaptation (LoRA) enable efficient single-concept customization by injecting lightweight, concept-specific adapters into pre-trained diffusion models. However, combining multiple LoRA modules for multi-concept generation often leads to identity missing and visual feature leakage. In this work, we identify two key issues behind these failures: (1) token-wise interference among different LoRA modules, and (2) spatial misalignment between the attention map of a rare token and its corresponding concept-specific region. To address these issues, we propose Token-Aware LoRA (TARA), which introduces a token mask to explicitly constrain each module to focus on its associated rare token to avoid interference, and a training objective that encourages the spatial attention of a rare token to align with its concept region. Our method enables training-free multi-concept composition by directly injecting multiple independently trained TARA modules at inference time. Experimental results demonstrate that TARA enables efficient multi-concept inference and effectively preserving the visual identity of each concept by avoiding mutual interference between LoRA modules. The code and models are available at https://github.com/YuqiPeng77/TARA.",
    "source": "arXiv"
  },
  {
    "title": "TempOpt -- Unsupervised Alarm Relation Learning for Telecommunication Networks",
    "title_es": "TempOpt -- Unsupervised Alarm Relation Learning for Telecommunication Networks",
    "url": "https://arxiv.org/abs/2508.08814",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08814v1 Announce Type: new \nAbstract: In a telecommunications network, fault alarms generated by network nodes are monitored in a Network Operations Centre (NOC) to ensure network availability and continuous network operations. The monitoring process comprises of tasks such as active alarms analysis, root alarm identification, and resolution of the underlying problem. Each network node potentially can generate alarms of different types, while nodes can be from multiple vendors, a network can have hundreds of nodes thus resulting in an enormous volume of alarms at any time. Since network nodes are inter-connected, a single fault in the network would trigger multiple sequences of alarms across a variety of nodes and from a monitoring point of view, it is a challenging task for a NOC engineer to be aware of relations between the various alarms, when trying to identify, for example, a root alarm on which an action needs to be taken. To effectively identify root alarms, it is essential to learn relation among the alarms for accurate and faster resolution. In this work we propose a novel unsupervised alarm relation learning technique Temporal Optimization (TempOpt) that is practical and overcomes the limitations of an existing class of alarm relational learning method-temporal dependency methods. Experiments have been carried on real-world network datasets, that demonstrate the improved quality of alarm relations learned by TempOpt as compared to temporal dependency method.",
    "source": "arXiv"
  },
  {
    "title": "GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs",
    "title_es": "GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs",
    "url": "https://arxiv.org/abs/2508.08815",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08815v1 Announce Type: new \nAbstract: Since Knowledge Graphs are often incomplete, link prediction methods are adopted for predicting missing facts. Scalable embedding based solutions are mostly adopted for this purpose, however, they lack comprehensibility, which may be crucial in several domains. Explanation methods tackle this issue by identifying supporting knowledge explaining the predicted facts. Regretfully, evaluating/comparing quantitatively the resulting explanations is challenging as there is no standard evaluation protocol and overall benchmarking resource. We fill this important gap by proposing GRainsaCK, a reusable software resource that fully streamlines all the tasks involved in benchmarking explanations, i.e., from model training to evaluation of explanations along the same evaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by implementing the main components as functions that can be easily replaced. Finally, fostering its reuse, we provide extensive documentation including a tutorial.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation",
    "title_es": "Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation",
    "url": "https://arxiv.org/abs/2508.08816",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08816v1 Announce Type: new \nAbstract: Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising solution to address the temporal limitations of Multimodal Large Language Models (MLLMs) in real-world scenarios like news analysis and trending topics. However, existing approaches often suffer from rigid retrieval strategies and under-utilization of visual information. To bridge this gap, we propose E-Agent, an agent framework featuring two key innovations: a mRAG planner trained to dynamically orchestrate multimodal tools based on contextual reasoning, and a task executor employing tool-aware execution sequencing to implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning strategy that enables efficient information retrieval while minimizing redundant tool invocations. To rigorously assess the planning capabilities of mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark. This novel benchmark contains both retrieval-dependent and retrieval-independent question types, systematically annotated with essential retrieval tools required for each instance. The benchmark's explicit mRAG planning annotations and diverse question design enhance its practical relevance by simulating real-world scenarios requiring dynamic mRAG decisions. Experiments across RemPlan and three established benchmarks demonstrate E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods while reducing redundant searches by 37%.",
    "source": "arXiv"
  },
  {
    "title": "3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs",
    "title_es": "3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs",
    "url": "https://arxiv.org/abs/2508.08821",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08821v1 Announce Type: new \nAbstract: Recent Multi-Modal Large Language Models (MLLMs) have demonstrated strong capabilities in learning joint representations from text and images. However, their spatial reasoning remains limited. We introduce 3DFroMLLM, a novel framework that enables the generation of 3D object prototypes directly from MLLMs, including geometry and part labels. Our pipeline is agentic, comprising a designer, coder, and visual inspector operating in a refinement loop. Notably, our approach requires no additional training data or detailed user instructions. Building on prior work in 2D generation, we demonstrate that rendered images produced by our framework can be effectively used for image classification pretraining tasks and outperforms previous methods by 15%. As a compelling real-world use case, we show that the generated prototypes can be leveraged to improve fine-grained vision-language models by using the rendered, part-labeled prototypes to fine-tune CLIP for part segmentation and achieving a 55% accuracy improvement without relying on any additional human-labeled data.",
    "source": "arXiv"
  },
  {
    "title": "OISMA: On-the-fly In-memory Stochastic Multiplication Architecture for Matrix-Multiplication Workloads",
    "title_es": "OISMA: On-the-fly In-memory Stochastic Multiplication Architecture for Matrix-Multiplication Workloads",
    "url": "https://arxiv.org/abs/2508.08822",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08822v1 Announce Type: new \nAbstract: Artificial Intelligence models are currently driven by a significant up-scaling of their complexity, with massive matrix multiplication workloads representing the major computational bottleneck. In-memory computing architectures are proposed to avoid the Von Neumann bottleneck. However, both digital/binary-based and analogue in-memory computing architectures suffer from various limitations, which significantly degrade the performance and energy efficiency gains. This work proposes OISMA, a novel in-memory computing architecture that utilizes the computational simplicity of a quasi-stochastic computing domain (Bent-Pyramid system), while keeping the same efficiency, scalability, and productivity of digital memories. OISMA converts normal memory read operations into in-situ stochastic multiplication operations with a negligible cost. An accumulation periphery then accumulates the output multiplication bitstreams, achieving the matrix multiplication functionality. Extensive matrix multiplication benchmarking was conducted to analyze the accuracy of the Bent-Pyramid system, using matrix dimensions ranging from 4x4 to 512x512. The accuracy results show a significant decrease in the average relative Frobenius error, from 9.42% (for 4x4) to 1.81% (for 512x512), compared to 64-bit double precision floating-point format. A 1T1R OISMA array of 4 KB capacity was implemented using a commercial 180nm technology node and in-house RRAM technology. At 50 MHz, OISMA achieves 0.891 TOPS/W and 3.98 GOPS/mm2 for energy and area efficiency, respectively, occupying an effective computing area of 0.804241 mm2. Scaling OISMA from 180nm to 22nm technology shows a significant improvement of two orders of magnitude in energy efficiency and one order of magnitude in area efficiency, compared to dense matrix multiplication in-memory computing architectures.",
    "source": "arXiv"
  },
  {
    "title": "A Parametric Bi-Directional Curvature-Based Framework for Image Artifact Classification and Quantification",
    "title_es": "A Parametric Bi-Directional Curvature-Based Framework for Image Artifact Classification and Quantification",
    "url": "https://arxiv.org/abs/2508.08824",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08824v1 Announce Type: new \nAbstract: This work presents a novel framework for No-Reference Image Quality Assessment (NR-IQA) founded on the analysis of directional image curvature. Within this framework, we define a measure of Anisotropic Texture Richness (ATR), which is computed at the pixel level using two tunable thresholds -- one permissive and one restrictive -- that quantify orthogonal texture suppression. When its parameters are optimized for a specific artifact, the resulting ATR score serves as a high-performance quality metric, achieving Spearman correlations with human perception of approximately -0.93 for Gaussian blur and -0.95 for white noise on the LIVE dataset. The primary contribution is a two-stage system that leverages the differential response of ATR to various distortions. First, the system utilizes the signature from two specialist ATR configurations to classify the primary artifact type (blur vs. noise) with over 97% accuracy. Second, following classification, it employs a dedicated regression model mapping the relevant ATR score to a quality rating to quantify the degradation. On a combined dataset, the complete system predicts human scores with a coefficient of determination (R2) of 0.892 and a Root Mean Square Error (RMSE) of 5.17 DMOS points. This error corresponds to just 7.4% of the dataset's total quality range, demonstrating high predictive accuracy. This establishes our framework as a robust, dual-purpose tool for the classification and subsequent quantification of image degradation.",
    "source": "arXiv"
  },
  {
    "title": "Wavelet Mixture of Experts for Time Series Forecasting",
    "title_es": "Wavelet Mixture of Experts for Time Series Forecasting",
    "url": "https://arxiv.org/abs/2508.08825",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08825v1 Announce Type: new \nAbstract: The field of time series forecasting is rapidly advancing, with recent large-scale Transformers and lightweight Multilayer Perceptron (MLP) models showing strong predictive performance. However, conventional Transformer models are often hindered by their large number of parameters and their limited ability to capture non-stationary features in data through smoothing. Similarly, MLP models struggle to manage multi-channel dependencies effectively. To address these limitations, we propose a novel, lightweight time series prediction model, WaveTS-B. This model combines wavelet transforms with MLP to capture both periodic and non-stationary characteristics of data in the wavelet domain. Building on this foundation, we propose a channel clustering strategy that incorporates a Mixture of Experts (MoE) framework, utilizing a gating mechanism and expert network to handle multi-channel dependencies efficiently. We propose WaveTS-M, an advanced model tailored for multi-channel time series prediction. Empirical evaluation across eight real-world time series datasets demonstrates that our WaveTS series models achieve state-of-the-art (SOTA) performance with significantly fewer parameters. Notably, WaveTS-M shows substantial improvements on multi-channel datasets, highlighting its effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "Geometry-Aware Global Feature Aggregation for Real-Time Indirect Illumination",
    "title_es": "Geometry-Aware Global Feature Aggregation for Real-Time Indirect Illumination",
    "url": "https://arxiv.org/abs/2508.08826",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08826v1 Announce Type: new \nAbstract: Real-time rendering with global illumination is crucial to afford the user realistic experience in virtual environments. We present a learning-based estimator to predict diffuse indirect illumination in screen space, which then is combined with direct illumination to synthesize globally-illuminated high dynamic range (HDR) results. Our approach tackles the challenges of capturing long-range/long-distance indirect illumination when employing neural networks and is generalized to handle complex lighting and scenarios.\n  From the neural network thinking of the solver to the rendering equation, we present a novel network architecture to predict indirect illumination. Our network is equipped with a modified attention mechanism that aggregates global information guided by spacial geometry features, as well as a monochromatic design that encodes each color channel individually.\n  We conducted extensive evaluations, and the experimental results demonstrate our superiority over previous learning-based techniques. Our approach excels at handling complex lighting such as varying-colored lighting and environment lighting. It can successfully capture distant indirect illumination and simulates the interreflections between textured surfaces well (i.e., color bleeding effects); it can also effectively handle new scenes that are not present in the training dataset.",
    "source": "arXiv"
  },
  {
    "title": "TiMoE: Time-Aware Mixture of Language Experts",
    "title_es": "TiMoE: Time-Aware Mixture of Language Experts",
    "url": "https://arxiv.org/abs/2508.08827",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08827v1 Announce Type: new \nAbstract: Large language models (LLMs) are typically trained on fixed snapshots of the web, which means that their knowledge becomes stale and their predictions risk temporal leakage: relying on information that lies in the future relative to a query. We tackle this problem by pre-training from scratch a set of GPT-style experts on disjoint two-year slices of a 2013-2024 corpus and combining them through TiMoE, a Time-aware Mixture of Language Experts. At inference time, TiMoE masks all experts whose training window ends after the query timestamp and merges the remaining log-probabilities in a shared space, guaranteeing strict causal validity while retaining the breadth of multi-period knowledge. We also release TSQA, a 10k-question benchmark whose alternatives are explicitly labelled as past, future or irrelevant, allowing fine-grained measurement of temporal hallucinations. Experiments on eight standard NLP tasks plus TSQA show that a co-adapted TiMoE variant matches or exceeds the best single-period expert and cuts future-knowledge errors by up to 15%. Our results demonstrate that modular, time-segmented pre-training paired with causal routing is a simple yet effective path toward LLMs that stay chronologically grounded without sacrificing general performance much. We open source our code at TiMoE (Github): https://github.com/epfml/TiMoE",
    "source": "arXiv"
  },
  {
    "title": "Recent Advances and Trends in Research Paper Recommender Systems: A Comprehensive Survey",
    "title_es": "Recent Advances and Trends in Research Paper Recommender Systems: A Comprehensive Survey",
    "url": "https://arxiv.org/abs/2508.08828",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08828v1 Announce Type: new \nAbstract: As the volume of scientific publications grows exponentially, researchers increasingly face difficulties in locating relevant literature. Research Paper Recommender Systems have become vital tools to mitigate this information overload by delivering personalized suggestions. This survey provides a comprehensive analysis of Research Paper Recommender Systems developed between November 2021 and December 2024, building upon prior reviews in the field. It presents an extensive overview of the techniques and approaches employed, the datasets utilized, the evaluation metrics and procedures applied, and the status of both enduring and emerging challenges observed during the research. Unlike prior surveys, this survey goes beyond merely cataloguing techniques and models, providing a thorough examination of how these methods are implemented across different stages of the recommendation process. By furnishing a detailed and structured reference, this work aims to function as a consultative resource for the research community, supporting informed decision-making and guiding future investigations in the advances of effective Research Paper Recommender Systems.",
    "source": "arXiv"
  },
  {
    "title": "Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition",
    "title_es": "Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition",
    "url": "https://arxiv.org/abs/2508.08830",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08830v1 Announce Type: new \nAbstract: The ability to discern subtle emotional cues is fundamental to human social intelligence. As artificial intelligence (AI) becomes increasingly common, AI's ability to recognize and respond to human emotions is crucial for effective human-AI interactions. In particular, whether such systems can match or surpass human experts remains to be seen. However, the emotional intelligence of AI, particularly multimodal large language models (MLLMs), remains largely unexplored. This study evaluates the emotion recognition abilities of MLLMs using the Reading the Mind in the Eyes Test (RMET) and its multiracial counterpart (MRMET), and compares their performance against human participants. Results show that, on average, MLLMs outperform humans in accurately identifying emotions across both tests. This trend persists even when comparing performance across low, medium, and expert-level performing groups. Yet when we aggregate independent human decisions to simulate collective intelligence, human groups significantly surpass the performance of aggregated MLLM predictions, highlighting the wisdom of the crowd. Moreover, a collaborative approach (augmented intelligence) that combines human and MLLM predictions achieves greater accuracy than either humans or MLLMs alone. These results suggest that while MLLMs exhibit strong emotion recognition at the individual level, the collective intelligence of humans and the synergistic potential of human-AI collaboration offer the most promising path toward effective emotional AI. We discuss the implications of these findings for the development of emotionally intelligent AI systems and future research directions.",
    "source": "arXiv"
  },
  {
    "title": "DiffPhysCam: Differentiable Physics-Based Camera Simulation for Inverse Rendering and Embodied AI",
    "title_es": "DiffPhysCam: Differentiable Physics-Based Camera Simulation for Inverse Rendering and Embodied AI",
    "url": "https://arxiv.org/abs/2508.08831",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08831v1 Announce Type: new \nAbstract: We introduce DiffPhysCam, a differentiable camera simulator designed to support robotics and embodied AI applications by enabling gradient-based optimization in visual perception pipelines. Generating synthetic images that closely mimic those from real cameras is essential for training visual models and enabling end-to-end visuomotor learning. Moreover, differentiable rendering allows inverse reconstruction of real-world scenes as digital twins, facilitating simulation-based robotics training. However, existing virtual cameras offer limited control over intrinsic settings, poorly capture optical artifacts, and lack tunable calibration parameters -- hindering sim-to-real transfer. DiffPhysCam addresses these limitations through a multi-stage pipeline that provides fine-grained control over camera settings, models key optical effects such as defocus blur, and supports calibration with real-world data. It enables both forward rendering for image synthesis and inverse rendering for 3D scene reconstruction, including mesh and material texture optimization. We show that DiffPhysCam enhances robotic perception performance in synthetic image tasks. As an illustrative example, we create a digital twin of a real-world scene using inverse rendering, simulate it in a multi-physics environment, and demonstrate navigation of an autonomous ground vehicle using images generated by DiffPhysCam.",
    "source": "arXiv"
  },
  {
    "title": "Image selective encryption analysis using mutual information in CNN based embedding space",
    "title_es": "Image selective encryption analysis using mutual information in CNN based embedding space",
    "url": "https://arxiv.org/abs/2508.08832",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08832v1 Announce Type: new \nAbstract: As digital data transmission continues to scale, concerns about privacy grow increasingly urgent - yet privacy remains a socially constructed and ambiguously defined concept, lacking a universally accepted quantitative measure. This work examines information leakage in image data, a domain where information-theoretic guarantees are still underexplored. At the intersection of deep learning, information theory, and cryptography, we investigate the use of mutual information (MI) estimators - in particular, the empirical estimator and the MINE framework - to detect leakage from selectively encrypted images. Motivated by the intuition that a robust estimator would require a probabilistic frameworks that can capture spatial dependencies and residual structures, even within encrypted representations - our work represent a promising direction for image information leakage estimation.",
    "source": "arXiv"
  },
  {
    "title": "An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems",
    "title_es": "An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems",
    "url": "https://arxiv.org/abs/2508.08833",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08833v1 Announce Type: new \nAbstract: In this paper, we introduce a systematic framework beyond conventional method to assess LLMs' mathematical-reasoning robustness by stress-testing them on advanced math problems that are mathematically equivalent but with linguistic and parametric variation. These transformations allow us to measure the sensitivity of LLMs to non-mathematical perturbations, thereby enabling a more accurate evaluation of their mathematical reasoning capabilities. Using this new evaluation methodology, we created PutnamGAP, a new benchmark dataset with multiple mathematically-equivalent variations of competition-level math problems. With the new dataset, we evaluate multiple families of representative LLMs and examine their robustness. Across 18 commercial and open-source models we observe sharp performance degradation on the variants. OpenAI's flagship reasoning model, O3, scores 49 % on the originals but drops by 4 percentage points on surface variants, and by 10.5 percentage points on core-step-based variants, while smaller models fare far worse. Overall, the results show that the proposed new evaluation methodology is effective for deepening our understanding of the robustness of LLMs and generating new insights for further improving their mathematical reasoning capabilities.",
    "source": "arXiv"
  },
  {
    "title": "EditMF: Drawing an Invisible Fingerprint for Your Large Language Models",
    "title_es": "EditMF: Drawing an Invisible Fingerprint for Your Large Language Models",
    "url": "https://arxiv.org/abs/2508.08836",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08836v1 Announce Type: new \nAbstract: Training large language models (LLMs) is resource-intensive and expensive, making protecting intellectual property (IP) for LLMs crucial. Recently, embedding fingerprints into LLMs has emerged as a prevalent method for establishing model ownership. However, existing back-door-based methods suffer from limited stealth and efficiency. To simultaneously address these issues, we propose EditMF, a training-free fingerprinting paradigm that achieves highly imperceptible fingerprint embedding with minimal computational overhead. Ownership bits are mapped to compact, semantically coherent triples drawn from an encrypted artificial knowledge base (e.g., virtual author-novel-protagonist facts). Causal tracing localizes the minimal set of layers influencing each triple, and a zero-space update injects the fingerprint without perturbing unrelated knowledge. Verification requires only a single black-box query and succeeds when the model returns the exact pre-embedded protagonist. Empirical results on LLaMA and Qwen families show that EditMF combines high imperceptibility with negligible model's performance loss, while delivering robustness far beyond LoRA-based fingerprinting and approaching that of SFT embeddings. Extensive experiments demonstrate that EditMF is an effective and low-overhead solution for secure LLM ownership verification.",
    "source": "arXiv"
  },
  {
    "title": "The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents",
    "title_es": "The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents",
    "url": "https://arxiv.org/abs/2508.08837",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08837v1 Announce Type: new \nAbstract: The rise of LLMs poses new possibilities in modeling opinion evolution, a long-standing task in simulation, by leveraging advanced reasoning abilities to recreate complex, large-scale human cognitive trends. While most prior works focus on opinion evolution surrounding specific isolated events or the views within a country, ours is the first to model the large-scale attitude evolution of a population representing an entire country towards another -- US citizens' perspectives towards China. To tackle the challenges of this broad scenario, we propose a framework that integrates media data collection, user profile creation, and cognitive architecture for opinion updates to successfully reproduce the real trend of US attitudes towards China over a 20-year period from 2005 to today. We also leverage LLMs' capabilities to introduce debiased media exposure, extracting neutral events from typically subjective news contents, to uncover the roots of polarized opinion formation, as well as a devils advocate agent to help explain the rare reversal from negative to positive attitudes towards China, corresponding with changes in the way Americans obtain information about the country. The simulation results, beyond validating our framework architecture, also reveal the impact of biased framing and selection bias in shaping attitudes. Overall, our work contributes to a new paradigm for LLM-based modeling of cognitive behaviors in a large-scale, long-term, cross-border social context, providing insights into the formation of international biases and offering valuable implications for media consumers to better understand the factors shaping their perspectives, and ultimately contributing to the larger social need for bias reduction and cross-cultural tolerance.",
    "source": "arXiv"
  },
  {
    "title": "Optimized Arithmetic Coding for Efficient Data Compression in the Resource-Constrained Internet of Things(IoT)",
    "title_es": "Optimized Arithmetic Coding for Efficient Data Compression in the Resource-Constrained Internet of Things(IoT)",
    "url": "https://arxiv.org/abs/2508.08840",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08840v1 Announce Type: new \nAbstract: The Internet of Things (IoT) generates vast amounts of heterogeneous data, ranging from sensor readings to log alerts and images, that pose challenges to storage and data transmission in resource-constrained environments. In this context, lossless data compression techniques, like Arithmetic Coding, offer an effective solution owing to their high compression ratio. However, the standard Arithmetic Coding technique is computationally intensive, leading to high memory and processing overhead. This paper proposes an optimized version of Arithmetic coding for the IoT environment that incorporates three improvements using Iterative and Iteration Optimizations for minimizing redundant computations and achieving faster convergence; Principal Component Analysis(PCA) for dimensionality reduction and identifying key features; and lastly, Cardinality reduction for grouping similar probabilities to improve the compression efficiency. The proposed method was evaluated on a dataset of images and demonstrated significant reductions in the time to compress, CPU utilization, and memory consumption, and preserves data integrity as seen through the low RMSE values. The optimized version of the Arithmetic Coding algorithm achieves an impressive compression ratio of 814:1 and 101 ms to compress a single image. This makes the optimized algorithm suitable for real-time applications and resource-constrained environments for efficient data transmission and storage.",
    "source": "arXiv"
  },
  {
    "title": "Steering Towards Fairness: Mitigating Political Bias in LLMs",
    "title_es": "Steering Towards Fairness: Mitigating Political Bias in LLMs",
    "url": "https://arxiv.org/abs/2508.08846",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08846v1 Announce Type: new \nAbstract: Recent advancements in large language models (LLMs) have enabled their widespread use across diverse real-world applications. However, concerns remain about their tendency to encode and reproduce ideological biases, particularly along political and economic dimensions. In this paper, we propose a framework for probing and mitigating such biases in decoder-based LLMs through analysis of internal model representations. Grounded in the Political Compass Test (PCT), our method uses contrastive pairs to extract and compare hidden layer activations from models like Mistral and DeepSeek. We introduce a comprehensive activation extraction pipeline capable of layer-wise analysis across multiple ideological axes, revealing meaningful disparities linked to political framing. Our results show that decoder LLMs systematically encode representational bias across layers, which can be leveraged for effective steering vector-based mitigation. This work provides new insights into how political bias is encoded in LLMs and offers a principled approach to debiasing beyond surface-level output interventions.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive High-Frequency Preprocessing for Video Coding",
    "title_es": "Adaptive High-Frequency Preprocessing for Video Coding",
    "url": "https://arxiv.org/abs/2508.08849",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08849v1 Announce Type: new \nAbstract: High-frequency components are crucial for maintaining video clarity and realism, but they also significantly impact coding bitrate, resulting in increased bandwidth and storage costs. This paper presents an end-to-end learning-based framework for adaptive high-frequency preprocessing to enhance subjective quality and save bitrate in video coding. The framework employs the Frequency-attentive Feature pyramid Prediction Network (FFPN) to predict the optimal high-frequency preprocessing strategy, guiding subsequent filtering operators to achieve the optimal tradeoff between bitrate and quality after compression. For training FFPN, we pseudo-label each training video with the optimal strategy, determined by comparing the rate-distortion (RD) performance across different preprocessing types and strengths. Distortion is measured using the latest quality assessment metric. Comprehensive evaluations on multiple datasets demonstrate the visually appealing enhancement capabilities and bitrate savings achieved by our framework.",
    "source": "arXiv"
  },
  {
    "title": "APCs and citation impact of Gold OA articles authored by Ukrainian scholars before and during Russia's full-scale war against Ukraine (2020-2023)",
    "title_es": "APCs and citation impact of Gold OA articles authored by Ukrainian scholars before and during Russia's full-scale war against Ukraine (2020-2023)",
    "url": "https://arxiv.org/abs/2508.08850",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08850v1 Announce Type: new \nAbstract: This study examines how Russia's full-scale war against Ukraine affected APCs, publishing patterns, and citation impact of Gold OA articles authored by Ukrainian scholars between 2020 and 2023. Data from Scopus covers articles published before (2020-2021) and after (2022-2023) the war's onset. Statistical analysis revealed a small but significant correlation between APC amounts and citation impact, though the effect size was minimal, suggesting higher APCs did not substantially boost citations. APC waivers offered by major publishers such as Springer and Elsevier since 2022 have led to only a slight increase in articles authored solely by Ukrainian scholars in their journals. Despite these waivers, MDPI and Aluna Publishing House maintained the largest shares of such publications, likely due to low rejection rates, fast publication, and - in Aluna's case - reduced APCs for Ukrainian authors. Between 2020 and 2023, the number of articles authored solely by Ukrainian scholars in foreign journals fell by 25.7%, and total APC spending declined by 24.6%, from EUR 1.24 million to EUR 0.93 million. Medicine accounted for the largest share of both articles and APC expenditure, with the majority published in Aluna journals. Ensuring genuine equity in scholarly communication requires alternative publishing models beyond APC-based Gold OA, guaranteeing equal opportunities to publish regardless of institutional or national affiliation. Reform must also address evaluation systems that prioritise output metrics over research quality and academic cultures that favour speed and APC payments over rigour, even when high-quality, no-cost publishing options are available.",
    "source": "arXiv"
  },
  {
    "title": "BiasGym: Fantastic Biases and How to Find (and Remove) Them",
    "title_es": "BiasGym: Fantastic Biases and How to Find (and Remove) Them",
    "url": "https://arxiv.org/abs/2508.08855",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08855v1 Announce Type: new \nAbstract: Understanding biases and stereotypes encoded in the weights of Large Language Models (LLMs) is crucial for developing effective mitigation strategies. Biased behaviour is often subtle and non-trivial to isolate, even when deliberately elicited, making systematic analysis and debiasing particularly challenging. To address this, we introduce BiasGym, a simple, cost-effective, and generalizable framework for reliably injecting, analyzing, and mitigating conceptual associations within LLMs. BiasGym consists of two components: BiasInject, which injects specific biases into the model via token-based fine-tuning while keeping the model frozen, and BiasScope, which leverages these injected signals to identify and steer the components responsible for biased behavior. Our method enables consistent bias elicitation for mechanistic analysis, supports targeted debiasing without degrading performance on downstream tasks, and generalizes to biases unseen during training. We demonstrate the effectiveness of BiasGym in reducing real-world stereotypes (e.g., people from a country being `reckless drivers') and in probing fictional associations (e.g., people from a country having `blue skin'), showing its utility for both safety interventions and interpretability research.",
    "source": "arXiv"
  },
  {
    "title": "Flow Battery Manifold Design with Heterogeneous Inputs Through Generative Adversarial Neural Networks",
    "title_es": "Flow Battery Manifold Design with Heterogeneous Inputs Through Generative Adversarial Neural Networks",
    "url": "https://arxiv.org/abs/2508.08863",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08863v1 Announce Type: new \nAbstract: Generative machine learning has emerged as a powerful tool for design representation and exploration. However, its application is often constrained by the need for large datasets of existing designs and the lack of interpretability about what features drive optimality. To address these challenges, we introduce a systematic framework for constructing training datasets tailored to generative models and demonstrate how these models can be leveraged for interpretable design. The novelty of this work is twofold: (i) we present a systematic framework for generating archetypes with internally homogeneous but mutually heterogeneous inputs that can be used to generate a training dataset, and (ii) we show how integrating generative models with Bayesian optimization can enhance the interpretability of the latent space of admissible designs. These findings are validated by using the framework to design a flow battery manifold, demonstrating that it effectively captures the space of feasible designs, including novel configurations while enabling efficient exploration. This work broadens the applicability of generative machine-learning models in system designs by enhancing quality and reliability.",
    "source": "arXiv"
  },
  {
    "title": "GaussianUpdate: Continual 3D Gaussian Splatting Update for Changing Environments",
    "title_es": "GaussianUpdate: Continual 3D Gaussian Splatting Update for Changing Environments",
    "url": "https://arxiv.org/abs/2508.08867",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08867v1 Announce Type: new \nAbstract: Novel view synthesis with neural models has advanced rapidly in recent years, yet adapting these models to scene changes remains an open problem. Existing methods are either labor-intensive, requiring extensive model retraining, or fail to capture detailed types of changes over time. In this paper, we present GaussianUpdate, a novel approach that combines 3D Gaussian representation with continual learning to address these challenges. Our method effectively updates the Gaussian radiance fields with current data while preserving information from past scenes. Unlike existing methods, GaussianUpdate explicitly models different types of changes through a novel multi-stage update strategy. Additionally, we introduce a visibility-aware continual learning approach with generative replay, enabling self-aware updating without the need to store images. The experiments on the benchmark dataset demonstrate our method achieves superior and real-time rendering with the capability of visualizing changes over different times",
    "source": "arXiv"
  },
  {
    "title": "Description and Comparative Analysis of QuRE: A New Industrial Requirements Quality Dataset",
    "title_es": "Description and Comparative Analysis of QuRE: A New Industrial Requirements Quality Dataset",
    "url": "https://arxiv.org/abs/2508.08868",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08868v1 Announce Type: new \nAbstract: Requirements quality is central to successful software and systems engineering. Empirical research on quality defects in natural language requirements relies heavily on datasets, ideally as realistic and representative as possible. However, such datasets are often inaccessible, small, or lack sufficient detail. This paper introduces QuRE (Quality in Requirements), a new dataset comprising 2,111 industrial requirements that have been annotated through a real-world review process. Previously used for over five years as part of an industrial contract, this dataset is now being released to the research community. In this work, we furthermore provide descriptive statistics on the dataset, including measures such as lexical diversity and readability, and compare it to existing requirements datasets and synthetically generated requirements. In contrast to synthetic datasets, QuRE is linguistically similar to existing ones. However, this dataset comes with a detailed context description, and its labels have been created and used systematically and extensively in an industrial context over a period of close to a decade. Our goal is to foster transparency, comparability, and empirical rigor by supporting the development of a common gold standard for requirements quality datasets. This, in turn, will enable more sound and collaborative research efforts in the field.",
    "source": "arXiv"
  },
  {
    "title": "Empirical Analysis of Temporal and Spatial Fault Characteristics in Multi-Fault Bug Repositories",
    "title_es": "Empirical Analysis of Temporal and Spatial Fault Characteristics in Multi-Fault Bug Repositories",
    "url": "https://arxiv.org/abs/2508.08872",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08872v1 Announce Type: new \nAbstract: Fixing software faults contributes significantly to the cost of software maintenance and evolution. Techniques for reducing these costs require datasets of software faults, as well as an understanding of the faults, for optimal testing and evaluation. In this paper, we present an empirical analysis of the temporal and spatial characteristics of faults existing in 16 open-source Java and Python projects, which form part of the Defects4J and BugsInPy datasets, respectively. Our findings show that many faults in these software systems are long-lived, leading to the majority of software versions having multiple coexisting faults. This is in contrast to the assumptions of the original datasets, where the majority of versions only identify a single fault. In addition, we show that although the faults are found in only a small subset of the systems, these faults are often evenly distributed amongst this subset, leading to relatively few bug hotspots.",
    "source": "arXiv"
  },
  {
    "title": "A Parareal Algorithm with Spectral Coarse Solver",
    "title_es": "A Parareal Algorithm with Spectral Coarse Solver",
    "url": "https://arxiv.org/abs/2508.08873",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08873v1 Announce Type: new \nAbstract: We consider a new class of Parareal algorithms, which use ideas from localized reduced basis methods to construct the coarse solver from spectral approximations of the transfer operators mapping initial values for a given time interval to the solution at the end of the interval. By leveraging randomized singular value decompositions, these spectral approximations are obtained embarrassingly parallel by computing local fine solutions for random initial values. We show a priori and a posteriori error bounds in terms of the computed singular values of the transfer operators. Our numerical experiments demonstrate that our approach can significantly outperform Parareal with single-step coarse solvers. At the same time, it permits to further increase parallelism in Parareal by trading global iterations for a larger number of independent local solves.",
    "source": "arXiv"
  },
  {
    "title": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
    "title_es": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
    "url": "https://arxiv.org/abs/2508.08875",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08875v1 Announce Type: new \nAbstract: Large Language Models (LLMs) increasingly leverage Federated Learning (FL) to utilize private, task-specific datasets for fine-tuning while preserving data privacy. However, while federated LLM frameworks effectively enable collaborative training without raw data sharing, they critically lack built-in mechanisms for regulatory compliance like GDPR's right to be forgotten. Integrating private data heightens concerns over data quality and long-term governance, yet existing distributed training frameworks offer no principled way to selectively remove specific client contributions post-training. Due to distributed data silos, stringent privacy constraints, and the intricacies of interdependent model aggregation, federated LLM unlearning is significantly more complex than centralized LLM unlearning. To address this gap, we introduce Oblivionis, a lightweight learning and unlearning framework that enables clients to selectively remove specific private data during federated LLM training, enhancing trustworthiness and regulatory compliance. By unifying FL and unlearning as a dual optimization objective, we incorporate 6 FL and 5 unlearning algorithms for comprehensive evaluation and comparative analysis, establishing a robust pipeline for federated LLM unlearning. Extensive experiments demonstrate that Oblivionis outperforms local training, achieving a robust balance between forgetting efficacy and model utility, with cross-algorithm comparisons providing clear directions for future LLM development.",
    "source": "arXiv"
  },
  {
    "title": "Weakly Supervised Fine-grained Span-Level Framework for Chinese Radiology Report Quality Assurance",
    "title_es": "Weakly Supervised Fine-grained Span-Level Framework for Chinese Radiology Report Quality Assurance",
    "url": "https://arxiv.org/abs/2508.08876",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08876v1 Announce Type: new \nAbstract: Quality Assurance (QA) for radiology reports refers to judging whether the junior reports (written by junior doctors) are qualified. The QA scores of one junior report are given by the senior doctor(s) after reviewing the image and junior report. This process requires intensive labor costs for senior doctors. Additionally, the QA scores may be inaccurate for reasons like diagnosis bias, the ability of senior doctors, and so on. To address this issue, we propose a Span-level Quality Assurance EvaluaTOR (Sqator) to mark QA scores automatically. Unlike the common document-level semantic comparison method, we try to analyze the semantic difference by exploring more fine-grained text spans. Unlike the common document-level semantic comparison method, we try to analyze the semantic difference by exploring more fine-grained text spans. Specifically, Sqator measures QA scores by measuring the importance of revised spans between junior and senior reports, and outputs the final QA scores by merging all revised span scores. We evaluate Sqator using a collection of 12,013 radiology reports. Experimental results show that Sqator can achieve competitive QA scores. Moreover, the importance scores of revised spans can be also consistent with the judgments of senior doctors.",
    "source": "arXiv"
  },
  {
    "title": "Towards Scalable Lottery Ticket Networks using Genetic Algorithms",
    "title_es": "Towards Scalable Lottery Ticket Networks using Genetic Algorithms",
    "url": "https://arxiv.org/abs/2508.08877",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08877v1 Announce Type: new \nAbstract: Building modern deep learning systems that are not just effective but also efficient requires rethinking established paradigms for model training and neural architecture design. Instead of adapting highly overparameterized networks and subsequently applying model compression techniques to reduce resource consumption, a new class of high-performing networks skips the need for expensive parameter updates, while requiring only a fraction of parameters, making them highly scalable. The Strong Lottery Ticket Hypothesis posits that within randomly initialized, sufficiently overparameterized neural networks, there exist subnetworks that can match the accuracy of the trained original model-without any training. This work explores the usage of genetic algorithms for identifying these strong lottery ticket subnetworks. We find that for instances of binary and multi-class classification tasks, our approach achieves better accuracies and sparsity levels than the current state-of-the-art without requiring any gradient information. In addition, we provide justification for the need for appropriate evaluation metrics when scaling to more complex network architectures and learning tasks.",
    "source": "arXiv"
  },
  {
    "title": "Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models",
    "title_es": "Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models",
    "url": "https://arxiv.org/abs/2508.08879",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08879v1 Announce Type: new \nAbstract: The growing deployment of large language models (LLMs) across diverse cultural contexts necessitates a better understanding of how the overgeneralization of less documented cultures within LLMs' representations impacts their cultural understanding. Prior work only performs extrinsic evaluation of LLMs' cultural competence, without accounting for how LLMs' internal mechanisms lead to cultural (mis)representation. To bridge this gap, we propose Culturescope, the first mechanistic interpretability-based method that probes the internal representations of LLMs to elicit the underlying cultural knowledge space. CultureScope utilizes a patching method to extract the cultural knowledge. We introduce a cultural flattening score as a measure of the intrinsic cultural biases. Additionally, we study how LLMs internalize Western-dominance bias and cultural flattening, which allows us to trace how cultural biases emerge within LLMs. Our experimental results reveal that LLMs encode Western-dominance bias and cultural flattening in their cultural knowledge space. We find that low-resource cultures are less susceptible to cultural biases, likely due to their limited training resources. Our work provides a foundation for future research on mitigating cultural biases and enhancing LLMs' cultural understanding. Our codes and data used for experiments are publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Hi-fi functional priors by learning activations",
    "title_es": "Hi-fi functional priors by learning activations",
    "url": "https://arxiv.org/abs/2508.08880",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08880v1 Announce Type: new \nAbstract: Function-space priors in Bayesian Neural Networks (BNNs) provide a more intuitive approach to embedding beliefs directly into the model's output, thereby enhancing regularization, uncertainty quantification, and risk-aware decision-making. However, imposing function-space priors on BNNs is challenging. We address this task through optimization techniques that explore how trainable activations can accommodate higher-complexity priors and match intricate target function distributions. We investigate flexible activation models, including Pade functions and piecewise linear functions, and discuss the learning challenges related to identifiability, loss construction, and symmetries. Our empirical findings indicate that even BNNs with a single wide hidden layer when equipped with flexible trainable activation, can effectively achieve desired function-space priors.",
    "source": "arXiv"
  },
  {
    "title": "Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation",
    "title_es": "Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation",
    "url": "https://arxiv.org/abs/2508.08882",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08882v1 Announce Type: new \nAbstract: Current tool-integrated mathematical reasoning systems often adopt a single-agent paradigm, where one large language model handles problem reasoning, code generation, and code execution in an integrated workflow. While this design eases coordination, we hypothesize that it imposes cognitive load interference, as the agent must interleave long-horizon reasoning with precise program synthesis. We validate this hypothesis through a controlled comparison between a reasoning-only agent and a reasoning-plus-code agent, finding that the latter produces significantly fewer correct reasoning paths despite having tool-calling capabilities. To address this, we propose a dual-agent hybrid framework: a Reasoning Agent performs stepwise problem decomposition, and a Code Agent handles code generation and execution. Training combines imitation learning and reinforcement learning: the Code Agent receives strong rewards for matching intermediate ground-truth programs and weaker rewards for valid execution, while the Reasoning Agent is optimized chiefly via final-answer accuracy using advantage estimation to credit intermediate steps. This decoupled role design reduces cognitive interference and promotes stable reasoning-coding coordination.",
    "source": "arXiv"
  },
  {
    "title": "Position: Causal Machine Learning Requires Rigorous Synthetic Experiments for Broader Adoption",
    "title_es": "Position: Causal Machine Learning Requires Rigorous Synthetic Experiments for Broader Adoption",
    "url": "https://arxiv.org/abs/2508.08883",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08883v1 Announce Type: new \nAbstract: Causal machine learning has the potential to revolutionize decision-making by combining the predictive power of machine learning algorithms with the theory of causal inference. However, these methods remain underutilized by the broader machine learning community, in part because current empirical evaluations do not permit assessment of their reliability and robustness, undermining their practical utility. Specifically, one of the principal criticisms made by the community is the extensive use of synthetic experiments. We argue, on the contrary, that synthetic experiments are essential and necessary to precisely assess and understand the capabilities of causal machine learning methods. To substantiate our position, we critically review the current evaluation practices, spotlight their shortcomings, and propose a set of principles for conducting rigorous empirical analyses with synthetic data. Adopting the proposed principles will enable comprehensive evaluations that build trust in causal machine learning methods, driving their broader adoption and impactful real-world use.",
    "source": "arXiv"
  },
  {
    "title": "A Dual Framework for Optimized Data Storage and Retrieval using Lightweight Python Blockchain and Scalable Smart Contracts with IPFS",
    "title_es": "A Dual Framework for Optimized Data Storage and Retrieval using Lightweight Python Blockchain and Scalable Smart Contracts with IPFS",
    "url": "https://arxiv.org/abs/2508.08887",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08887v1 Announce Type: new \nAbstract: The exponential growth of IoT data demands efficient, secure, and scalable storage solutions on one hand, and efficient data migration and retrieval on the other hand are essential for the systems to be practical and acceptable for different applications. The traditional cloud-based models face latency, security, and high operational costs, while existing bi-directional data storage and retrieval-based IPFS models are not computationally efficient and incur high gas costs at the cost of a necessary blockchain deployment. To overcome the challenges of efficient data migration, we initially developed a 2-way data storage and retrieval system as well as a scalable framework that dynamically monitors and transfers device-generated data to IPFS, records the content identifier(CID) on a blockchain, and enables secure, real-time access via smart contracts. Experimental results demonstrate that the existing work achieved an average data upload time of 117.12 sec for a file size of 500 MB; our framework achieves a faster upload time of 7.63 sec, marking a 93.47% improvement. We further optimize the proposed framework to reduce the file upload time incurred from the smart contracts by introducing a blockchain-inspired, lightweight, and customizable Python framework that replicates the storage and retrieval functionalities of a traditional blockchain, where the file upload time is 4.2 sec, further optimized by 45% from our previous approach, thus demonstrating its efficiency, security and suitability for deploy ment in real-time and critical IoT applications and outperforming the existing IPFS-smart contract based solutions.",
    "source": "arXiv"
  },
  {
    "title": "Preview WB-DH: Towards Whole Body Digital Human Bench for the Generation of Whole-body Talking Avatar Videos",
    "title_es": "Preview WB-DH: Towards Whole Body Digital Human Bench for the Generation of Whole-body Talking Avatar Videos",
    "url": "https://arxiv.org/abs/2508.08891",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08891v1 Announce Type: new \nAbstract: Creating realistic, fully animatable whole-body avatars from a single portrait is challenging due to limitations in capturing subtle expressions, body movements, and dynamic backgrounds. Current evaluation datasets and metrics fall short in addressing these complexities. To bridge this gap, we introduce the Whole-Body Benchmark Dataset (WB-DH), an open-source, multi-modal benchmark designed for evaluating whole-body animatable avatar generation. Key features include: (1) detailed multi-modal annotations for fine-grained guidance, (2) a versatile evaluation framework, and (3) public access to the dataset and tools at https://github.com/deepreasonings/WholeBodyBenchmark.",
    "source": "arXiv"
  },
  {
    "title": "Sound Signal Synthesis with Auxiliary Classifier GAN, COVID-19 cough as an example",
    "title_es": "Sound Signal Synthesis with Auxiliary Classifier GAN, COVID-19 cough as an example",
    "url": "https://arxiv.org/abs/2508.08892",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08892v1 Announce Type: new \nAbstract: One of the fastest-growing domains in AI is healthcare. Given its importance, it has been the interest of many researchers to deploy ML models into the ever-demanding healthcare domain to aid doctors and increase accessibility. Delivering reliable models, however, demands a sizable amount of data, and the recent COVID-19 pandemic served as a reminder of the rampant and scary nature of healthcare that makes training models difficult. To alleviate such scarcity, many published works attempted to synthesize radiological cough data to train better COVID-19 detection models on the respective radiological data. To accommodate the time sensitivity expected during a pandemic, this work focuses on detecting COVID-19 through coughs using synthetic data to improve the accuracy of the classifier. The work begins by training a CNN on a balanced subset of the Coughvid dataset, establishing a baseline classification test accuracy of 72%. The paper demonstrates how an Auxiliary Classification GAN (ACGAN) may be trained to conditionally generate novel synthetic Mel Spectrograms of both healthy and COVID-19 coughs. These coughs are used to augment the training dataset of the CNN classifier, allowing it to reach a new test accuracy of 75%. The work highlights the expected messiness and inconsistency in training and offers insights into detecting and handling such shortcomings.",
    "source": "arXiv"
  },
  {
    "title": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs",
    "title_es": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs",
    "url": "https://arxiv.org/abs/2508.08895",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08895v1 Announce Type: new \nAbstract: The increasing scale and complexity of large language models (LLMs) pose significant inference latency challenges, primarily due to their autoregressive decoding paradigm characterized by the sequential nature of next-token prediction. By re-examining the outputs of autoregressive models, we observed that some segments exhibit parallelizable structures, which we term intrinsic parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel decoding) can significantly improve the overall inference speed of LLMs. In this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which addresses two core challenges: automated construction of parallelizable data and efficient parallel decoding mechanism. More specifically, we introduce a non-invasive pipeline that automatically extracts and validates parallelizable structures from the responses of autoregressive models. To empower efficient adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which enables seamless transitions between serial and parallel decoding modes while maintaining a reusable KV cache, maximizing computational efficiency. Extensive evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical Reasoning, demonstrate that ASPD achieves unprecedented performance in both effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up to 3.19x speedup (1.85x on average) while maintaining response quality within 1% difference compared to autoregressive models, realizing significant acceleration without compromising generation quality. Our framework sets a groundbreaking benchmark for efficient LLM parallel inference, paving the way for its deployment in latency-sensitive applications such as AI-powered customer service bots and answer retrieval engines.",
    "source": "arXiv"
  },
  {
    "title": "Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors",
    "title_es": "Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors",
    "url": "https://arxiv.org/abs/2508.08896",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08896v1 Announce Type: new \nAbstract: A dexterous hand capable of generalizable grasping objects is fundamental for the development of general-purpose embodied AI. However, previous methods focus narrowly on low-level grasp stability metrics, neglecting affordance-aware positioning and human-like poses which are crucial for downstream manipulation. To address these limitations, we propose AffordDex, a novel framework with two-stage training that learns a universal grasping policy with an inherent understanding of both motion priors and object affordances. In the first stage, a trajectory imitator is pre-trained on a large corpus of human hand motions to instill a strong prior for natural movement. In the second stage, a residual module is trained to adapt these general human-like motions to specific object instances. This refinement is critically guided by two components: our Negative Affordance-aware Segmentation (NAA) module, which identifies functionally inappropriate contact regions, and a privileged teacher-student distillation process that ensures the final vision-based policy is highly successful. Extensive experiments demonstrate that AffordDex not only achieves universal dexterous grasping but also remains remarkably human-like in posture and functionally appropriate in contact location. As a result, AffordDex significantly outperforms state-of-the-art baselines across seen objects, unseen instances, and even entirely novel categories.",
    "source": "arXiv"
  },
  {
    "title": "Redactable Blockchains: An Overview",
    "title_es": "Redactable Blockchains: An Overview",
    "url": "https://arxiv.org/abs/2508.08898",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08898v1 Announce Type: new \nAbstract: Blockchains are widely recognized for their immutability, which provides robust guarantees of data integrity and transparency. However, this same feature poses significant challenges in real-world situations that require regulatory compliance, correction of erroneous data, or removal of sensitive information. Redactable blockchains address the limitations of traditional ones by enabling controlled, auditable modifications to blockchain data, primarily through cryptographic mechanisms such as chameleon hash functions and alternative redaction schemes. This report examines the motivations for introducing redactability, surveys the cryptographic primitives that enable secure edits, and analyzes competing approaches and their shortcomings. Special attention is paid to the practical deployment of redactable blockchains in private settings, with discussions of use cases in healthcare, finance, Internet of drones, and federated learning. Finally, the report outlines further challenges, also in connection with reversible computing, and the future potential of redactable blockchains in building law-compliant, trustworthy, and scalable digital infrastructures.",
    "source": "arXiv"
  },
  {
    "title": "A Robust Epipolar-Domain Regularization Algorithm for Light Field Depth Estimation",
    "title_es": "A Robust Epipolar-Domain Regularization Algorithm for Light Field Depth Estimation",
    "url": "https://arxiv.org/abs/2508.08900",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08900v1 Announce Type: new \nAbstract: Robust depth estimation in light field imaging remains a critical challenge for pattern recognition applications such as augmented reality, biomedical imaging, and scene reconstruction. While existing approaches often rely heavily on deep convolutional neural networks, they tend to incur high computational costs and struggle in noisy real-world environments. This paper proposes a novel lightweight depth estimation pipeline that integrates light field-based disparity information with a directed random walk refinement algorithm. Unlike traditional CNN-based methods, our approach enhances depth map consistency without requiring extensive training or large-scale datasets. The proposed method was evaluated on the 4D Light Field Benchmark dataset and a diverse set of real-world images. Experimental results indicate that while performance slightly declines under uncontrolled conditions, the algorithm consistently maintains low computational complexity and competitive accuracy compared to state-of-the-art deep learning models. These findings highlight the potential of our method as a robust and efficient alternative for depth estimation and segmentation in light field imaging. The work provides insights into practical algorithm design for light field-based pattern recognition and opens new directions for integrating probabilistic graph models with depth sensing frameworks.",
    "source": "arXiv"
  },
  {
    "title": "Ultra Ethernet's Design Principles and Architectural Innovations",
    "title_es": "Ultra Ethernet's Design Principles and Architectural Innovations",
    "url": "https://arxiv.org/abs/2508.08906",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08906v1 Announce Type: new \nAbstract: The recently released Ultra Ethernet (UE) 1.0 specification defines a transformative High-Performance Ethernet standard for future Artificial Intelligence (AI) and High-Performance Computing (HPC) systems. This paper, written by the specification's authors, provides a high-level overview of UE's design, offering crucial motivations and scientific context to understand its innovations. While UE introduces advancements across the entire Ethernet stack, its standout contribution is the novel Ultra Ethernet Transport (UET), a potentially fully hardware-accelerated protocol engineered for reliable, fast, and efficient communication in extreme-scale systems. Unlike InfiniBand, the last major standardization effort in high-performance networking over two decades ago, UE leverages the expansive Ethernet ecosystem and the 1,000x gains in computational efficiency per moved bit to deliver a new era of high-performance networking.",
    "source": "arXiv"
  },
  {
    "title": "Compass-Thinker-7B Technical Report",
    "title_es": "Compass-Thinker-7B Technical Report",
    "url": "https://arxiv.org/abs/2508.08909",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08909v1 Announce Type: new \nAbstract: Recent R1-Zero-like research further demonstrates that reasoning extension has given large language models (LLMs) unprecedented reasoning capabilities, and Reinforcement Learning is the core tech- nology to elicit its complex reasoning. However, conducting RL experiments directly on hyperscale models involves high computational costs and resource demands, posing significant risks. We pro- pose the Compass-Thinker-7B model, which aims to explore the potential of Reinforcement Learn- ing with less computational resources and costs, and provides insights for further research into RL recipes for larger models. Compass-Thinker-7B is trained from an open source model through a spe- cially designed Reinforcement Learning Pipeline. we curate a dataset of 30k verifiable mathematics problems for the Reinforcement Learning Pipeline. By configuring data and training settings with dif- ferent difficulty distributions for different stages, the potential of the model is gradually released and the training efficiency is improved. Extensive evaluations show that Compass-Thinker-7B possesses exceptional reasoning potential, and achieves superior performance on mathematics compared to the same-sized RL model.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B achieves 40% accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Masked Clustering Prediction for Unsupervised Point Cloud Pre-training",
    "title_es": "Masked Clustering Prediction for Unsupervised Point Cloud Pre-training",
    "url": "https://arxiv.org/abs/2508.08910",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08910v1 Announce Type: new \nAbstract: Vision transformers (ViTs) have recently been widely applied to 3D point cloud understanding, with masked autoencoding as the predominant pre-training paradigm. However, the challenge of learning dense and informative semantic features from point clouds via standard ViTs remains underexplored. We propose MaskClu, a novel unsupervised pre-training method for ViTs on 3D point clouds that integrates masked point modeling with clustering-based learning. MaskClu is designed to reconstruct both cluster assignments and cluster centers from masked point clouds, thus encouraging the model to capture dense semantic information. Additionally, we introduce a global contrastive learning mechanism that enhances instance-level feature learning by contrasting different masked views of the same point cloud. By jointly optimizing these complementary objectives, i.e., dense semantic reconstruction, and instance-level contrastive learning. MaskClu enables ViTs to learn richer and more semantically meaningful representations from 3D point clouds. We validate the effectiveness of our method via multiple 3D tasks, including part segmentation, semantic segmentation, object detection, and classification, where MaskClu sets new competitive results. The code and models will be released at:https://github.com/Amazingren/maskclu.",
    "source": "arXiv"
  },
  {
    "title": "Munsit at NADI 2025 Shared Task 2: Pushing the Boundaries of Multidialectal Arabic ASR with Weakly Supervised Pretraining and Continual Supervised Fine-tuning",
    "title_es": "Munsit at NADI 2025 Shared Task 2: Pushing the Boundaries of Multidialectal Arabic ASR with Weakly Supervised Pretraining and Continual Supervised Fine-tuning",
    "url": "https://arxiv.org/abs/2508.08912",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08912v1 Announce Type: new \nAbstract: Automatic speech recognition (ASR) plays a vital role in enabling natural human-machine interaction across applications such as virtual assistants, industrial automation, customer support, and real-time transcription. However, developing accurate ASR systems for low-resource languages like Arabic remains a significant challenge due to limited labeled data and the linguistic complexity introduced by diverse dialects. In this work, we present a scalable training pipeline that combines weakly supervised learning with supervised fine-tuning to develop a robust Arabic ASR model. In the first stage, we pretrain the model on 15,000 hours of weakly labeled speech covering both Modern Standard Arabic (MSA) and various Dialectal Arabic (DA) variants. In the subsequent stage, we perform continual supervised fine-tuning using a mixture of filtered weakly labeled data and a small, high-quality annotated dataset. Our approach achieves state-of-the-art results, ranking first in the multi-dialectal Arabic ASR challenge. These findings highlight the effectiveness of weak supervision paired with fine-tuning in overcoming data scarcity and delivering high-quality ASR for low-resource, dialect-rich languages.",
    "source": "arXiv"
  },
  {
    "title": "Provably positivity-preserving, globally divergence-free central DG methods for ideal MHD system",
    "title_es": "Provably positivity-preserving, globally divergence-free central DG methods for ideal MHD system",
    "url": "https://arxiv.org/abs/2508.08913",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08913v1 Announce Type: new \nAbstract: This paper proposes a numerical method, termed PosDiv-CDG, that provably preserves both positivity and the globally divergence-free (DF) condition at arbitrarily high order in multiple dimensions. It resolves the fundamental structural incompatibility between standard positivity-preserving limiters and global DF enforcement in the central discontinuous Galerkin (CDG) framework. The method integrates a novel positivity-limiting strategy, a modified dissipation mechanism guided by convex decomposition, and an auxiliary evolution equation for the magnetic field, which are designed based on rigorous theoretical analysis. Notably, we provide a rigorous proof of positivity preservation for the updated cell averages under an explicit CFL-type condition. The proof leverages the geometric quasi-linearization (GQL) technique, which reformulates the nonlinear positivity constraint into an equivalent linear form. This enables the derivation of flux-based inequalities and technical estimates under the global DF constraint. To suppress nonphysical oscillations near shocks, we develop a compact, non-intrusive convex-oscillation-suppressing (COS) procedure based on the entropy function. The COS process acts only on non-magnetic variables, avoids costly characteristic decomposition, and maintains both the globally DF property and high-order accuracy. Several challenging experiments -- including low plasma-beta MHD jets with Mach numbers up to 1,000,000 -- demonstrate the proposed method robustness, high-order accuracy, non-oscillatory behavior, and its ability to preserve both positivity and globally DF structures under extreme conditions.",
    "source": "arXiv"
  },
  {
    "title": "Automatic and standardized surgical reporting for central nervous system tumors",
    "title_es": "Automatic and standardized surgical reporting for central nervous system tumors",
    "url": "https://arxiv.org/abs/2508.08916",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08916v1 Announce Type: new \nAbstract: Magnetic resonance (MR) imaging is essential for evaluating central nervous system (CNS) tumors, guiding surgical planning, treatment decisions, and assessing postoperative outcomes and complication risks. While recent work has advanced automated tumor segmentation and report generation, most efforts have focused on preoperative data, with limited attention to postoperative imaging analysis. This study introduces a comprehensive pipeline for standardized postsurtical reporting in CNS tumors. Using the Attention U-Net architecture, segmentation models were trained for the preoperative (non-enhancing) tumor core, postoperative contrast-enhancing residual tumor, and resection cavity. Additionally, MR sequence classification and tumor type identification for contrast-enhancing lesions were explored using the DenseNet architecture. The models were integrated into a reporting pipeline, following the RANO 2.0 guidelines. Training was conducted on multicentric datasets comprising 2000 to 7000 patients, using a 5-fold cross-validation. Evaluation included patient-, voxel-, and object-wise metrics, with benchmarking against the latest BraTS challenge results. The segmentation models achieved average voxel-wise Dice scores of 87%, 66%, 70%, and 77% for the tumor core, non-enhancing tumor core, contrast-enhancing residual tumor, and resection cavity, respectively. Classification models reached 99.5% balanced accuracy in MR sequence classification and 80% in tumor type classification. The pipeline presented in this study enables robust, automated segmentation, MR sequence classification, and standardized report generation aligned with RANO 2.0 guidelines, enhancing postoperative evaluation and clinical decision-making. The proposed models and methods were integrated into Raidionics, open-source software platform for CNS tumor analysis, now including a dedicated module for postsurgical analysis.",
    "source": "arXiv"
  },
  {
    "title": "A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition",
    "title_es": "A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition",
    "url": "https://arxiv.org/abs/2508.08917",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08917v1 Announce Type: new \nAbstract: LiDAR-based Place Recognition (LPR) remains a critical task in Embodied Artificial Intelligence (AI) and Autonomous Driving, primarily addressing localization challenges in GPS-denied environments and supporting loop closure detection. Existing approaches reduce place recognition to a Euclidean distance-based metric learning task, neglecting the feature space's intrinsic structures and intra-class variances. Such Euclidean-centric formulation inherently limits the model's capacity to capture nonlinear data distributions, leading to suboptimal performance in complex environments and temporal-varying scenarios. To address these challenges, we propose a novel cross-view network based on an innovative fusion paradigm. Our framework introduces a pseudo-global information guidance mechanism that coordinates multi-modal branches to perform feature learning within a unified semantic space. Concurrently, we propose a Manifold Adaptation and Pairwise Variance-Locality Learning Metric that constructs a Symmetric Positive Definite (SPD) matrix to compute Mahalanobis distance, superseding traditional Euclidean distance metrics. This geometric formulation enables the model to accurately characterize intrinsic data distributions and capture complex inter-class dependencies within the feature space. Experimental results demonstrate that the proposed algorithm achieves competitive performance, particularly excelling in complex environmental conditions.",
    "source": "arXiv"
  },
  {
    "title": "Stationarity Exploration for Multivariate Time Series Forecasting",
    "title_es": "Stationarity Exploration for Multivariate Time Series Forecasting",
    "url": "https://arxiv.org/abs/2508.08919",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08919v1 Announce Type: new \nAbstract: Deep learning-based time series forecasting has found widespread applications. Recently, converting time series data into the frequency domain for forecasting has become popular for accurately exploring periodic patterns. However, existing methods often cannot effectively explore stationary information from complex intertwined frequency components. In this paper, we propose a simple yet effective Amplitude-Phase Reconstruct Network (APRNet) that models the inter-relationships of amplitude and phase, which prevents the amplitude and phase from being constrained by different physical quantities, thereby decoupling the distinct characteristics of signals for capturing stationary information. Specifically, we represent the multivariate time series input across sequence and channel dimensions, highlighting the correlation between amplitude and phase at multiple interaction frequencies. We propose a novel Kolmogorov-Arnold-Network-based Local Correlation (KLC) module to adaptively fit local functions using univariate functions, enabling more flexible characterization of stationary features across different amplitudes and phases. This significantly enhances the model's capability to capture time-varying patterns. Extensive experiments demonstrate the superiority of our APRNet against the state-of-the-arts (SOTAs).",
    "source": "arXiv"
  },
  {
    "title": "Exploring Cross-Stage Adversarial Transferability in Class-Incremental Continual Learning",
    "title_es": "Exploring Cross-Stage Adversarial Transferability in Class-Incremental Continual Learning",
    "url": "https://arxiv.org/abs/2508.08920",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08920v1 Announce Type: new \nAbstract: Class-incremental continual learning addresses catastrophic forgetting by enabling classification models to preserve knowledge of previously learned classes while acquiring new ones. However, the vulnerability of the models against adversarial attacks during this process has not been investigated sufficiently. In this paper, we present the first exploration of vulnerability to stage-transferred attacks, i.e., an adversarial example generated using the model in an earlier stage is used to attack the model in a later stage. Our findings reveal that continual learning methods are highly susceptible to these attacks, raising a serious security issue. We explain this phenomenon through model similarity between stages and gradual robustness degradation. Additionally, we find that existing adversarial training-based defense methods are not sufficiently effective to stage-transferred attacks. Codes are available at https://github.com/mcml-official/CSAT.",
    "source": "arXiv"
  },
  {
    "title": "Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions",
    "title_es": "Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions",
    "url": "https://arxiv.org/abs/2508.08923",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08923v1 Announce Type: new \nAbstract: Ultrasound (US) imaging is increasingly used in spinal procedures due to its real-time, radiation-free capabilities; however, its effectiveness is hindered by shadowing artifacts that obscure deeper tissue structures. Traditional approaches, such as CT-to-US registration, incorporate anatomical information from preoperative CT scans to guide interventions, but they are limited by complex registration requirements, differences in spine curvature, and the need for recent CT imaging. Recent shape completion methods can offer an alternative by reconstructing spinal structures in US data, while being pretrained on large set of publicly available CT scans. However, these approaches are typically offline and have limited reproducibility. In this work, we introduce a novel integrated system that combines robotic ultrasound with real-time shape completion to enhance spinal visualization. Our robotic platform autonomously acquires US sweeps of the lumbar spine, extracts vertebral surfaces from ultrasound, and reconstructs the complete anatomy using a deep learning-based shape completion network. This framework provides interactive, real-time visualization with the capability to autonomously repeat scans and can enable navigation to target locations. This can contribute to better consistency, reproducibility, and understanding of the underlying anatomy. We validate our approach through quantitative experiments assessing shape completion accuracy and evaluations of multiple spine acquisition protocols on a phantom setup. Additionally, we present qualitative results of the visualization on a volunteer scan.",
    "source": "arXiv"
  },
  {
    "title": "Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models",
    "title_es": "Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.08926",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08926v1 Announce Type: new \nAbstract: Large Vision-Language Models face growing safety challenges with multimodal inputs. This paper introduces the concept of Implicit Reasoning Safety, a vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due to flawed or hidden reasoning. To showcase this, we developed Safe Semantics, Unsafe Interpretations, the first dataset for this critical issue. Our demonstrations show that even simple In-Context Learning with SSUI significantly mitigates these implicit multimodal threats, underscoring the urgent need to improve cross-modal implicit reasoning.",
    "source": "arXiv"
  },
  {
    "title": "DASC: Depth-of-Field Aware Scene Complexity Metric for 3D Visualization on Light Field Display",
    "title_es": "DASC: Depth-of-Field Aware Scene Complexity Metric for 3D Visualization on Light Field Display",
    "url": "https://arxiv.org/abs/2508.08928",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08928v1 Announce Type: new \nAbstract: Light field display is one of the technologies providing 3D immersive visualization. However, a light field display generates only a limited number of light rays which results in finite angular and spatial resolutions. Therefore, 3D content can be shown with high quality only within a narrow depth range notated as Depth of Field (DoF) around the display screen. Outside this range, due to the appearance of aliasing artifacts, the quality degrades proportionally to the distance from the screen. One solution to mitigate the artifacts is depth of field rendering which blurs the content in the distorted regions, but can result in the removal of scene details. This research focuses on proposing a DoF Aware Scene Complexity (DASC) metric that characterizes 3D content based on geometrical and positional factors considering the light field display's DoF. In this research, we also evaluate the observers' preference across different level of blurriness caused by DoF rendering ranging from sharp, aliased scenes to overly smoothed alias-free scenes. We have conducted this study over multiple scenes that we created to account for different types of content. Based on the outcome of subjective studies, we propose a model that takes the value of DASC metric as input and predicts the preferred level of blurring for the given scene as output.",
    "source": "arXiv"
  },
  {
    "title": "How Does a Virtual Agent Decide Where to Look? - Symbolic Cognitive Reasoning for Embodied Head Rotation",
    "title_es": "How Does a Virtual Agent Decide Where to Look? - Symbolic Cognitive Reasoning for Embodied Head Rotation",
    "url": "https://arxiv.org/abs/2508.08930",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08930v1 Announce Type: new \nAbstract: Natural head rotation is critical for believable embodied virtual agents, yet this micro-level behavior remains largely underexplored. While head-rotation prediction algorithms could, in principle, reproduce this behavior, they typically focus on visually salient stimuli and overlook the cognitive motives that guide head rotation. This yields agents that look at conspicuous objects while overlooking obstacles or task-relevant cues, diminishing realism in a virtual environment. We introduce SCORE, a Symbolic Cognitive Reasoning framework for Embodied Head Rotation, a data-agnostic framework that produces context-aware head movements without task-specific training or hand-tuned heuristics. A controlled VR study (N=20) identifies five motivational drivers of human head movements: Interest, Information Seeking, Safety, Social Schema, and Habit. SCORE encodes these drivers as symbolic predicates, perceives the scene with a Vision-Language Model (VLM), and plans head poses with a Large Language Model (LLM). The framework employs a hybrid workflow: the VLM-LLM reasoning is executed offline, after which a lightweight FastVLM performs online validation to suppress hallucinations while maintaining responsiveness to scene dynamics. The result is an agent that predicts not only where to look but also why, generalizing to unseen scenes and multi-agent crowds while retaining behavioral plausibility.",
    "source": "arXiv"
  },
  {
    "title": "Reveal-Bangla: A Dataset for Cross-Lingual Multi-Step Reasoning Evaluation",
    "title_es": "Reveal-Bangla: A Dataset for Cross-Lingual Multi-Step Reasoning Evaluation",
    "url": "https://arxiv.org/abs/2508.08933",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08933v1 Announce Type: new \nAbstract: Language models have demonstrated remarkable performance on complex multi-step reasoning tasks. However, their evaluation has been predominantly confined to high-resource languages such as English. In this paper, we introduce a manually translated Bangla multi-step reasoning dataset derived from the English Reveal dataset, featuring both binary and non-binary question types. We conduct a controlled evaluation of English-centric and Bangla-centric multilingual small language models on the original dataset and our translated version to compare their ability to exploit relevant reasoning steps to produce correct answers. Our results show that, in comparable settings, reasoning context is beneficial for more challenging non-binary questions, but models struggle to employ relevant Bangla reasoning steps effectively. We conclude by exploring how reasoning steps contribute to models' predictions, highlighting different trends across models and languages.",
    "source": "arXiv"
  },
  {
    "title": "LNN-PINN: A Unified Physics-Only Training Framework with Liquid Residual Blocks",
    "title_es": "LNN-PINN: A Unified Physics-Only Training Framework with Liquid Residual Blocks",
    "url": "https://arxiv.org/abs/2508.08935",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08935v1 Announce Type: new \nAbstract: Physics-informed neural networks (PINNs) have attracted considerable attention for their ability to integrate partial differential equation priors into deep learning frameworks; however, they often exhibit limited predictive accuracy when applied to complex problems. To address this issue, we propose LNN-PINN, a physics-informed neural network framework that incorporates a liquid residual gating architecture while preserving the original physics modeling and optimization pipeline to improve predictive accuracy. The method introduces a lightweight gating mechanism solely within the hidden-layer mapping, keeping the sampling strategy, loss composition, and hyperparameter settings unchanged to ensure that improvements arise purely from architectural refinement. Across four benchmark problems, LNN-PINN consistently reduced RMSE and MAE under identical training conditions, with absolute error plots further confirming its accuracy gains. Moreover, the framework demonstrates strong adaptability and stability across varying dimensions, boundary conditions, and operator characteristics. In summary, LNN-PINN offers a concise and effective architectural enhancement for improving the predictive accuracy of physics-informed neural networks in complex scientific and engineering problems.",
    "source": "arXiv"
  },
  {
    "title": "Accelerated Volumetric Compression without Hierarchies: A Fourier Feature Based Implicit Neural Representation Approach",
    "title_es": "Accelerated Volumetric Compression without Hierarchies: A Fourier Feature Based Implicit Neural Representation Approach",
    "url": "https://arxiv.org/abs/2508.08937",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08937v1 Announce Type: new \nAbstract: Volumetric data compression is critical in fields like medical imaging, scientific simulation, and entertainment. We introduce a structure-free neural compression method combining Fourierfeature encoding with selective voxel sampling, yielding compact volumetric representations and faster convergence. Our dynamic voxel selection uses morphological dilation to prioritize active regions, reducing redundant computation without any hierarchical metadata. In the experiment, sparse training reduced training time by 63.7 % (from 30 to 11 minutes) with only minor quality loss: PSNR dropped 0.59 dB (from 32.60 to 32.01) and SSIM by 0.008 (from 0.948 to 0.940). The resulting neural representation, stored solely as network weights, achieves a compression rate of 14 and eliminates traditional data-loading overhead. This connects coordinate-based neural representation with efficient volumetric compression, offering a scalable, structure-free solution for practical applications.",
    "source": "arXiv"
  },
  {
    "title": "MADPromptS: Unlocking Zero-Shot Morphing Attack Detection with Multiple Prompt Aggregation",
    "title_es": "MADPromptS: Unlocking Zero-Shot Morphing Attack Detection with Multiple Prompt Aggregation",
    "url": "https://arxiv.org/abs/2508.08939",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08939v1 Announce Type: new \nAbstract: Face Morphing Attack Detection (MAD) is a critical challenge in face recognition security, where attackers can fool systems by interpolating the identity information of two or more individuals into a single face image, resulting in samples that can be verified as belonging to multiple identities by face recognition systems. While multimodal foundation models (FMs) like CLIP offer strong zero-shot capabilities by jointly modeling images and text, most prior works on FMs for biometric recognition have relied on fine-tuning for specific downstream tasks, neglecting their potential for direct, generalizable deployment. This work explores a pure zero-shot approach to MAD by leveraging CLIP without any additional training or fine-tuning, focusing instead on the design and aggregation of multiple textual prompts per class. By aggregating the embeddings of diverse prompts, we better align the model's internal representations with the MAD task, capturing richer and more varied cues indicative of bona-fide or attack samples. Our results show that prompt aggregation substantially improves zero-shot detection performance, demonstrating the effectiveness of exploiting foundation models' built-in multimodal knowledge through efficient prompt engineering.",
    "source": "arXiv"
  },
  {
    "title": "Train Long, Think Short: Curriculum Learning for Efficient Reasoning",
    "title_es": "Train Long, Think Short: Curriculum Learning for Efficient Reasoning",
    "url": "https://arxiv.org/abs/2508.08940",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08940v1 Announce Type: new \nAbstract: Recent work on enhancing the reasoning abilities of large language models (LLMs) has introduced explicit length control as a means of constraining computational cost while preserving accuracy. However, existing approaches rely on fixed-length training budgets, which do not take advantage of the natural progression from exploration to compression during learning. In this work, we propose a curriculum learning strategy for length-controlled reasoning using Group Relative Policy Optimization (GRPO). Our method starts with generous token budgets and gradually tightens them over training, encouraging models to first discover effective solution strategies and then distill them into more concise reasoning traces. We augment GRPO with a reward function that balances three signals: task correctness (via verifier feedback), length efficiency, and formatting adherence (via structural tags). Experiments on GSM8K, MATH500, SVAMP, College Math, and GSM+ demonstrate that curriculum-based training consistently outperforms fixed-budget baselines at the same final budget, achieving higher accuracy and significantly improved token efficiency. We further ablate the impact of reward weighting and decay schedule design, showing that progressive constraint serves as a powerful inductive bias for training efficient reasoning models. Our code and checkpoints are released at: https://github.com/hammoudhasan/curriculum_grpo.",
    "source": "arXiv"
  },
  {
    "title": "Jointly Generating and Attributing Answers using Logits of Document-Identifier Tokens",
    "title_es": "Jointly Generating and Attributing Answers using Logits of Document-Identifier Tokens",
    "url": "https://arxiv.org/abs/2508.08942",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08942v1 Announce Type: new \nAbstract: Despite their impressive performances, Large Language Models (LLMs) remain prone to hallucination, which critically undermines their trustworthiness. While most of the previous work focused on tackling answer and attribution correctness, a recent line of work investigated faithfulness, with a focus on leveraging internal model signals to reflect a model's actual decision-making process while generating the answer. Nevertheless, these methods induce additional latency and have shown limitations in directly aligning token generation with attribution generation. In this paper, we introduce LoDIT, a method that jointly generates and faithfully attributes answers in RAG by leveraging specific token logits during generation. It consists of two steps: (1) marking the documents with specific token identifiers and then leveraging the logits of these tokens to estimate the contribution of each document to the answer during generation, and (2) aggregating these contributions into document attributions. Experiments on a trustworthiness-focused attributed text-generation benchmark, Trust-Align, show that LoDIT significantly outperforms state-of-the-art models on several metrics. Finally, an in-depth analysis of LoDIT shows both its efficiency in terms of latency and its robustness in different settings.",
    "source": "arXiv"
  },
  {
    "title": "UniSTFormer: Unified Spatio-Temporal Lightweight Transformer for Efficient Skeleton-Based Action Recognition",
    "title_es": "UniSTFormer: Unified Spatio-Temporal Lightweight Transformer for Efficient Skeleton-Based Action Recognition",
    "url": "https://arxiv.org/abs/2508.08944",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08944v1 Announce Type: new \nAbstract: Skeleton-based action recognition (SAR) has achieved impressive progress with transformer architectures. However, existing methods often rely on complex module compositions and heavy designs, leading to increased parameter counts, high computational costs, and limited scalability. In this paper, we propose a unified spatio-temporal lightweight transformer framework that integrates spatial and temporal modeling within a single attention module, eliminating the need for separate temporal modeling blocks. This approach reduces redundant computations while preserving temporal awareness within the spatial modeling process. Furthermore, we introduce a simplified multi-scale pooling fusion module that combines local and global pooling pathways to enhance the model's ability to capture fine-grained local movements and overarching global motion patterns. Extensive experiments on benchmark datasets demonstrate that our lightweight model achieves a superior balance between accuracy and efficiency, reducing parameter complexity by over 58% and lowering computational cost by over 60% compared to state-of-the-art transformer-based baselines, while maintaining competitive recognition performance.",
    "source": "arXiv"
  },
  {
    "title": "Load-Altering Attacks Against Power Grids: A Case Study Using the GB-36 Bus System Open Dataset",
    "title_es": "Load-Altering Attacks Against Power Grids: A Case Study Using the GB-36 Bus System Open Dataset",
    "url": "https://arxiv.org/abs/2508.08945",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08945v1 Announce Type: new \nAbstract: The growing digitalization and the rapid adoption of high-powered Internet-of-Things (IoT)-enabled devices (e.g., EV charging stations) have increased the vulnerability of power grids to cyber threats. In particular, the so-called Load Altering Attacks (LAAs) can trigger rapid frequency fluctuations and potentially destabilize the power grid. This paper aims to bridge the gap between academic research and practical application by using open-source datasets released by grid operators. It investigates various LAA scenarios on a real-world transmission network, namely the Great Britain (GB)-36 Zone model released by the UK's National Electricity System Operator (NESO). It evaluates the threshold of LAA severity that the grid can tolerate before triggering cascading effects. Additionally, it explores how Battery Energy Storage Systems (BESS) based fast frequency response services can mitigate or prevent such impacts. Simulations are conducted using DIgSILENT PowerFactory to ensure realistic system representation. The analysis provides several useful insights to grid operators on the LAA impact, such as the influence of the relative locations of BESS and LAA, as well as how delays in attack execution can influence the overall system response.",
    "source": "arXiv"
  },
  {
    "title": "Mitigating Popularity Bias in Counterfactual Explanations using Large Language Models",
    "title_es": "Mitigating Popularity Bias in Counterfactual Explanations using Large Language Models",
    "url": "https://arxiv.org/abs/2508.08946",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08946v1 Announce Type: new \nAbstract: Counterfactual explanations (CFEs) offer a tangible and actionable way to explain recommendations by showing users a \"what-if\" scenario that demonstrates how small changes in their history would alter the system's output. However, existing CFE methods are susceptible to bias, generating explanations that might misalign with the user's actual preferences. In this paper, we propose a pre-processing step that leverages large language models to filter out-of-character history items before generating an explanation. In experiments on two public datasets, we focus on popularity bias and apply our approach to ACCENT, a neural CFE framework. We find that it creates counterfactuals that are more closely aligned with each user's popularity preferences than ACCENT alone.",
    "source": "arXiv"
  },
  {
    "title": "Generalising Traffic Forecasting to Regions without Traffic Observations",
    "title_es": "Generalising Traffic Forecasting to Regions without Traffic Observations",
    "url": "https://arxiv.org/abs/2508.08947",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08947v1 Announce Type: new \nAbstract: Traffic forecasting is essential for intelligent transportation systems. Accurate forecasting relies on continuous observations collected by traffic sensors. However, due to high deployment and maintenance costs, not all regions are equipped with such sensors. This paper aims to forecast for regions without traffic sensors, where the lack of historical traffic observations challenges the generalisability of existing models. We propose a model named GenCast, the core idea of which is to exploit external knowledge to compensate for the missing observations and to enhance generalisation. We integrate physics-informed neural networks into GenCast, enabling physical principles to regularise the learning process. We introduce an external signal learning module to explore correlations between traffic states and external signals such as weather conditions, further improving model generalisability. Additionally, we design a spatial grouping module to filter localised features that hinder model generalisability. Extensive experiments show that GenCast consistently reduces forecasting errors on multiple real-world datasets.",
    "source": "arXiv"
  },
  {
    "title": "Lay2Story: Extending Diffusion Transformers for Layout-Togglable Story Generation",
    "title_es": "Lay2Story: Extending Diffusion Transformers for Layout-Togglable Story Generation",
    "url": "https://arxiv.org/abs/2508.08949",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08949v1 Announce Type: new \nAbstract: Storytelling tasks involving generating consistent subjects have gained significant attention recently. However, existing methods, whether training-free or training-based, continue to face challenges in maintaining subject consistency due to the lack of fine-grained guidance and inter-frame interaction. Additionally, the scarcity of high-quality data in this field makes it difficult to precisely control storytelling tasks, including the subject's position, appearance, clothing, expression, and posture, thereby hindering further advancements. In this paper, we demonstrate that layout conditions, such as the subject's position and detailed attributes, effectively facilitate fine-grained interactions between frames. This not only strengthens the consistency of the generated frame sequence but also allows for precise control over the subject's position, appearance, and other key details. Building on this, we introduce an advanced storytelling task: Layout-Togglable Storytelling, which enables precise subject control by incorporating layout conditions. To address the lack of high-quality datasets with layout annotations for this task, we develop Lay2Story-1M, which contains over 1 million 720p and higher-resolution images, processed from approximately 11,300 hours of cartoon videos. Building on Lay2Story-1M, we create Lay2Story-Bench, a benchmark with 3,000 prompts designed to evaluate the performance of different methods on this task. Furthermore, we propose Lay2Story, a robust framework based on the Diffusion Transformers (DiTs) architecture for Layout-Togglable Storytelling tasks. Through both qualitative and quantitative experiments, we find that our method outperforms the previous state-of-the-art (SOTA) techniques, achieving the best results in terms of consistency, semantic correlation, and aesthetic quality.",
    "source": "arXiv"
  },
  {
    "title": "Toward Automated Hypervisor Scenario Generation Based on VM Workload Profiling for Resource-Constrained Environments",
    "title_es": "Toward Automated Hypervisor Scenario Generation Based on VM Workload Profiling for Resource-Constrained Environments",
    "url": "https://arxiv.org/abs/2508.08952",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08952v1 Announce Type: new \nAbstract: In the automotive industry, the rise of software-defined vehicles (SDVs) has\n  driven a shift toward virtualization-based architectures that consolidate\n  diverse automotive workloads on a shared hardware platform. To support this\n  evolution, chipset vendors provide board support packages (BSPs), hypervisor\n  setups, and resource allocation guidelines. However, adapting these static\n  configurations to varying system requirements and workloads remain a\n  significant challenge for Tier 1 integrators.\n  This paper presents an automated scenario generation framework, which helps\n  automotive vendors to allocate hardware resources efficiently across multiple\n  VMs. By profiling runtime behavior and integrating both theoretical models and\n  vendor heuristics, the proposed tool generates optimized hypervisor\n  configurations tailored to system constraints.\n  We compare two main approaches for modeling target QoS based on profiled data\n  and resource allocation: domain-guided parametric modeling and deep\n  learning-based modeling. We further describe our optimization strategy using\n  the selected QoS model to derive efficient resource allocations. Finally, we\n  report on real-world deployments to demonstrate the effectiveness of our\n  framework in improving integration efficiency and reducing development time in\n  resource-constrained environments.",
    "source": "arXiv"
  },
  {
    "title": "GRAVITY: A Controversial Graph Representation Learning for Vertex Classification",
    "title_es": "GRAVITY: A Controversial Graph Representation Learning for Vertex Classification",
    "url": "https://arxiv.org/abs/2508.08954",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08954v1 Announce Type: new \nAbstract: In the quest of accurate vertex classification, we introduce GRAVITY (Graph-based Representation leArning via Vertices Interaction TopologY), a framework inspired by physical systems where objects self-organize under attractive forces. GRAVITY models each vertex as exerting influence through learned interactions shaped by structural proximity and attribute similarity. These interactions induce a latent potential field in which vertices move toward energy efficient positions, coalescing around class-consistent attractors and distancing themselves from unrelated groups. Unlike traditional message-passing schemes with static neighborhoods, GRAVITY adaptively modulates the receptive field of each vertex based on a learned force function, enabling dynamic aggregation driven by context. This field-driven organization sharpens class boundaries and promotes semantic coherence within latent clusters. Experiments on real-world benchmarks show that GRAVITY yields competitive embeddings, excelling in both transductive and inductive vertex classification tasks.",
    "source": "arXiv"
  },
  {
    "title": "Fre-CW: Targeted Attack on Time Series Forecasting using Frequency Domain Loss",
    "title_es": "Fre-CW: Targeted Attack on Time Series Forecasting using Frequency Domain Loss",
    "url": "https://arxiv.org/abs/2508.08955",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08955v1 Announce Type: new \nAbstract: Transformer-based models have made significant progress in time series forecasting. However, a key limitation of deep learning models is their susceptibility to adversarial attacks, which has not been studied enough in the context of time series prediction. In contrast to areas such as computer vision, where adversarial robustness has been extensively studied, frequency domain features of time series data play an important role in the prediction task but have not been sufficiently explored in terms of adversarial attacks. This paper proposes a time series prediction attack algorithm based on frequency domain loss. Specifically, we adapt an attack method originally designed for classification tasks to the prediction field and optimize the adversarial samples using both time-domain and frequency-domain losses. To the best of our knowledge, there is no relevant research on using frequency information for time-series adversarial attacks. Our experimental results show that these current time series prediction models are vulnerable to adversarial attacks, and our approach achieves excellent performance on major time series forecasting datasets.",
    "source": "arXiv"
  },
  {
    "title": "QAMRO: Quality-aware Adaptive Margin Ranking Optimization for Human-aligned Assessment of Audio Generation Systems",
    "title_es": "QAMRO: Quality-aware Adaptive Margin Ranking Optimization for Human-aligned Assessment of Audio Generation Systems",
    "url": "https://arxiv.org/abs/2508.08957",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08957v1 Announce Type: new \nAbstract: Evaluating audio generation systems, including text-to-music (TTM), text-to-speech (TTS), and text-to-audio (TTA), remains challenging due to the subjective and multi-dimensional nature of human perception. Existing methods treat mean opinion score (MOS) prediction as a regression problem, but standard regression losses overlook the relativity of perceptual judgments. To address this limitation, we introduce QAMRO, a novel Quality-aware Adaptive Margin Ranking Optimization framework that seamlessly integrates regression objectives from different perspectives, aiming to highlight perceptual differences and prioritize accurate ratings. Our framework leverages pre-trained audio-text models such as CLAP and Audiobox-Aesthetics, and is trained exclusively on the official AudioMOS Challenge 2025 dataset. It demonstrates superior alignment with human evaluations across all dimensions, significantly outperforming robust baseline models.",
    "source": "arXiv"
  },
  {
    "title": "Addressing the Heterogeneity of Visualization in an Introductory PhD Course in the Swedish Context",
    "title_es": "Addressing the Heterogeneity of Visualization in an Introductory PhD Course in the Swedish Context",
    "url": "https://arxiv.org/abs/2508.08958",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08958v1 Announce Type: new \nAbstract: Visualization is a heterogeneous field, and this aspect is often reflected by the organizational structures at higher education institutions that academic researchers in visualization and related fields including computer graphics, human-computer interaction, and media design are typically affiliated with. It may thus be a challenge for new PhD students to grasp the fragmented structure of their new workplace, form collegial relations across the institution, and to build a coherent picture of the discipline as a whole. We report an attempt to address this challenge, in the form of an introductory course on the subject of Visualization Technology and Methodology for PhD students at the Division for Media and Information Technology, Link\\\"oping University, Sweden. We discuss the course design, including interactions with other doctoral education activities and field trips to multiple research groups and units within the division (ranging from scientific visualization and computer graphics to media design and visual communication). Lessons learned from the course preparation work as well as the first instance of the course offered during autumn term 2023 can be helpful to researchers and educators aiming to establish or improve similar doctoral courses.",
    "source": "arXiv"
  },
  {
    "title": "A Framework for FAIR and CLEAR Ecological Data and Knowledge: Semantic Units for Synthesis and Causal Modelling",
    "title_es": "A Framework for FAIR and CLEAR Ecological Data and Knowledge: Semantic Units for Synthesis and Causal Modelling",
    "url": "https://arxiv.org/abs/2508.08959",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08959v1 Announce Type: new \nAbstract: Ecological research increasingly relies on integrating heterogeneous datasets and knowledge to explain and predict complex phenomena. Yet, differences in data types, terminology, and documentation often hinder interoperability, reuse, and causal understanding. We present the Semantic Units Framework, a novel, domain-agnostic semantic modelling approach applied here to ecological data and knowledge in compliance with the FAIR (Findable, Accessible, Interoperable, Reusable) and CLEAR (Cognitively interoperable, semantically Linked, contextually Explorable, easily Accessible, human-Readable and -interpretable) Principles. The framework models data and knowledge as modular, logic-aware semantic units: single propositions (statement units) or coherent groups of propositions (compound units). Statement units can model measurements, observations, or universal relationships, including causal ones, and link to methods and evidence. Compound units group related statement units into reusable, semantically coherent knowledge objects. Implemented using RDF, OWL, and knowledge graphs, semantic units can be serialized as FAIR Digital Objects with persistent identifiers, provenance, and semantic interoperability. We show how universal statement units build ecological causal networks, which can be composed into causal maps and perspective-specific subnetworks. These support causal reasoning, confounder detection (back-door), effect identification with unobserved confounders (front-door), application of do-calculus, and alignment with Bayesian networks, structural equation models, and structural causal models. By linking fine-grained empirical data to high-level causal reasoning, the Semantic Units Framework provides a foundation for ecological knowledge synthesis, evidence annotation, cross-domain integration, reproducible workflows, and AI-ready ecological research.",
    "source": "arXiv"
  },
  {
    "title": "DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models",
    "title_es": "DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models",
    "url": "https://arxiv.org/abs/2508.08961",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08961v1 Announce Type: new \nAbstract: Extending pre-trained Large Language Models (LLMs)'s speech understanding or generation abilities by introducing various effective speech tokens has attracted great attention in the speech community. However, building a unified speech understanding and generation model still faces the following challenges: (1) Due to the huge modality gap between speech tokens and text tokens, extending text LLMs to unified speech LLMs relies on large-scale paired data for fine-tuning, and (2) Generation and understanding tasks prefer information at different levels, e.g., generation benefits from detailed acoustic features, while understanding favors high-level semantics. This divergence leads to difficult performance optimization in one unified model. To solve these challenges, in this paper, we present two key insights in speech tokenization and speech language modeling. Specifically, we first propose an Understanding-driven Speech Tokenizer (USTokenizer), which extracts high-level semantic information essential for accomplishing understanding tasks using text LLMs. In this way, USToken enjoys better modality commonality with text, which reduces the difficulty of modality alignment in adapting text LLMs to speech LLMs. Secondly, we present DualSpeechLM, a dual-token modeling framework that concurrently models USToken as input and acoustic token as output within a unified, end-to-end framework, seamlessly integrating speech understanding and generation capabilities. Furthermore, we propose a novel semantic supervision loss and a Chain-of-Condition (CoC) strategy to stabilize model training and enhance speech generation performance. Experimental results demonstrate that our proposed approach effectively fosters a complementary relationship between understanding and generation tasks, highlighting the promising strategy of mutually enhancing both tasks in one unified model.",
    "source": "arXiv"
  },
  {
    "title": "An effective implementation of high-order compact gas-kinetic scheme on structured meshes for compressible flows",
    "title_es": "An effective implementation of high-order compact gas-kinetic scheme on structured meshes for compressible flows",
    "url": "https://arxiv.org/abs/2508.08965",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08965v1 Announce Type: new \nAbstract: A novel fifth-order compact gas-kinetic scheme is developed for high-resolution simulation of compressible flows on structured meshes. Its accuracy relies on a new multidimensional fifth-order compact reconstruction that uses line-averaged derivatives to introduce additional degrees of freedom, enabling a compact stencil with superior resolution. For non-orthogonal meshes, reconstruction is performed on a standard reference cell in a transformed computational space. This approach provides a unified polynomial form, significantly reducing memory usage and computational cost while simplifying implementation compared to direct multi-dimensional or dimension-by-dimension methods. A nonlinear adaptive method ensures high accuracy and robustness by smoothly transitioning from the high-order linear scheme in smooth regions to a second-order scheme at discontinuities. The method is implemented with multi-GPU parallelization using CUDA and MPI for large-scale applications. Comprehensive numerical tests, from subsonic to supersonic turbulence, validate the scheme's high accuracy, resolution and excellent robustness.",
    "source": "arXiv"
  },
  {
    "title": "Integrating attention into explanation frameworks for language and vision transformers",
    "title_es": "Integrating attention into explanation frameworks for language and vision transformers",
    "url": "https://arxiv.org/abs/2508.08966",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08966v1 Announce Type: new \nAbstract: The attention mechanism lies at the core of the transformer architecture, providing an interpretable model-internal signal that has motivated a growing interest in attention-based model explanations. Although attention weights do not directly determine model outputs, they reflect patterns of token influence that can inform and complement established explainability techniques. This work studies the potential of utilising the information encoded in attention weights to provide meaningful model explanations by integrating them into explainable AI (XAI) frameworks that target fundamentally different aspects of model behaviour. To this end, we develop two novel explanation methods applicable to both natural language processing and computer vision tasks. The first integrates attention weights into the Shapley value decomposition by redefining the characteristic function in terms of pairwise token interactions via attention weights, thus adapting this widely used game-theoretic solution concept to provide attention-driven attributions for local explanations. The second incorporates attention weights into token-level directional derivatives defined through concept activation vectors to measure concept sensitivity for global explanations. Our empirical evaluations on standard benchmarks and in a comparison study with widely used explanation methods show that attention weights can be meaningfully incorporated into the studied XAI frameworks, highlighting their value in enriching transformer explainability.",
    "source": "arXiv"
  },
  {
    "title": "Revealing the Role of Audio Channels in ASR Performance Degradation",
    "title_es": "Revealing the Role of Audio Channels in ASR Performance Degradation",
    "url": "https://arxiv.org/abs/2508.08967",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08967v1 Announce Type: new \nAbstract: Pre-trained automatic speech recognition (ASR) models have demonstrated strong performance on a variety of tasks. However, their performance can degrade substantially when the input audio comes from different recording channels. While previous studies have demonstrated this phenomenon, it is often attributed to the mismatch between training and testing corpora. This study argues that variations in speech characteristics caused by different recording channels can fundamentally harm ASR performance. To address this limitation, we propose a normalization technique designed to mitigate the impact of channel variation by aligning internal feature representations in the ASR model with those derived from a clean reference channel. This approach significantly improves ASR performance on previously unseen channels and languages, highlighting its ability to generalize across channel and language differences.",
    "source": "arXiv"
  },
  {
    "title": "Millisecond-scale Volatile Memory in HZO Ferroelectric Capacitors for Bio-inspired Temporal Computing",
    "title_es": "Millisecond-scale Volatile Memory in HZO Ferroelectric Capacitors for Bio-inspired Temporal Computing",
    "url": "https://arxiv.org/abs/2508.08973",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08973v1 Announce Type: new \nAbstract: With the broad recent research on ferroelectric hafnium oxide for non-volatile memory technology, depolarization effects in HfO2-based ferroelectric devices gained a lot of interest. Understanding the physical mechanisms regulating the retention of these devices provides an excellent opportunity for device optimization both towards non-volatile memory applications and towards real-time signal processing applications in which controlled time constants are of paramount importance. Indeed, we argue that ferroelectric devices, particularly HfO2-based, are an elegant solution to realize possibly arbitrary time constants in a single scaled memory device, which paves the way for temporal and brain-inspired computing in hardware. Here we present a ferroelectric capacitor stack realizing volatile memory due to its unique interface configuration. We provide electrical characterization of the device to motivate its use for realizing time constants in hardware, followed by an investigation of the electronic mechanisms and their possible relation to the observed retention times to facilitate further modeling of the retention process in HfO2-based ferroelectric capacitors. In the presented device, internal electric fields stabilize one polarization of the ferroelectric film, opening the possibility for unipolar operation with millisecond retention for the unstable polarization state. We show a dependence of the retention on both the polarization as well as the electrical stimuli, allowing us to exploit a range of time scales in a single device. Further, the intentionally defective interface in the presented material stack allows an insight into the interplay between retention loss in HfO2-based ferroelectric devices and the internal bias field, which we relate to the interface composition and the role of oxygen vacancies as a possible source of the internal bias fields.",
    "source": "arXiv"
  },
  {
    "title": "Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering",
    "title_es": "Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering",
    "url": "https://arxiv.org/abs/2508.08974",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08974v1 Announce Type: new \nAbstract: The Earth's surface is constantly changing, and detecting these changes provides valuable insights that benefit various aspects of human society. While traditional change detection methods have been employed to detect changes from bi-temporal images, these approaches typically require expert knowledge for accurate interpretation. To enable broader and more flexible access to change information by non-expert users, the task of Change Detection Visual Question Answering (CDVQA) has been introduced. However, existing CDVQA methods have been developed under the assumption that training and testing datasets share similar distributions. This assumption does not hold in real-world applications, where domain shifts often occur. In this paper, the CDVQA task is revisited with a focus on addressing domain shift. To this end, a new multi-modal and multi-domain dataset, BrightVQA, is introduced to facilitate domain generalization research in CDVQA. Furthermore, a novel state space model, termed Text-Conditioned State Space Model (TCSSM), is proposed. The TCSSM framework is designed to leverage both bi-temporal imagery and geo-disaster-related textual information in an unified manner to extract domain-invariant features across domains. Input-dependent parameters existing in TCSSM are dynamically predicted by using both bi-temporal images and geo-disaster-related description, thereby facilitating the alignment between bi-temporal visual data and the associated textual descriptions. Extensive experiments are conducted to evaluate the proposed method against state-of-the-art models, and superior performance is consistently demonstrated. The code and dataset will be made publicly available upon acceptance at https://github.com/Elman295/TCSSM.",
    "source": "arXiv"
  },
  {
    "title": "Urban-STA4CLC: Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change",
    "title_es": "Urban-STA4CLC: Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change",
    "url": "https://arxiv.org/abs/2508.08976",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08976v1 Announce Type: new \nAbstract: Natural disasters such as hurricanes and wildfires increasingly introduce unusual disturbance on economic activities, which are especially likely to reshape commercial land use pattern given their sensitive to customer visitation. However, current modeling approaches are limited in capturing such complex interplay between human activities and commercial land use change under and following disturbances. Such interactions have been more effectively captured in current resilient urban planning theories. This study designs and calibrates a Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change (Urban-STA4CLC) to predict both the yearly decline and expansion of commercial land use at census block level under cumulative impact of disasters on human activities over two years. Guided by urban theories, Urban-STA4CLC integrates both spatial and temporal attention mechanisms with three theory-informed modules. Resilience theory guides a disaster-aware temporal attention module that captures visitation dynamics. Spatial economic theory informs a multi-relational spatial attention module for inter-block representation. Diffusion theory contributes a regularization term that constrains land use transitions. The model performs significantly better than non-theoretical baselines in predicting commercial land use change under the scenario of recurrent hurricanes, with around 19% improvement in F1 score (0.8763). The effectiveness of the theory-guided modules was further validated through ablation studies. The research demonstrates that embedding urban theory into commercial land use modeling models may substantially enhance the capacity to capture its gains and losses. These advances in commercial land use modeling contribute to land use research that accounts for cumulative impacts of recurrent disasters and shifts in economic activity patterns.",
    "source": "arXiv"
  },
  {
    "title": "TaoCache: Structure-Maintained Video Generation Acceleration",
    "title_es": "TaoCache: Structure-Maintained Video Generation Acceleration",
    "url": "https://arxiv.org/abs/2508.08978",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08978v1 Announce Type: new \nAbstract: Existing cache-based acceleration methods for video diffusion models primarily skip early or mid denoising steps, which often leads to structural discrepancies relative to full-timestep generation and can hinder instruction following and character consistency. We present TaoCache, a training-free, plug-and-play caching strategy that, instead of residual-based caching, adopts a fixed-point perspective to predict the model's noise output and is specifically effective in late denoising stages. By calibrating cosine similarities and norm ratios of consecutive noise deltas, TaoCache preserves high-resolution structure while enabling aggressive skipping. The approach is orthogonal to complementary accelerations such as Pyramid Attention Broadcast (PAB) and TeaCache, and it integrates seamlessly into DiT-based frameworks. Across Latte-1, OpenSora-Plan v110, and Wan2.1, TaoCache attains substantially higher visual quality (LPIPS, SSIM, PSNR) than prior caching methods under the same speedups.",
    "source": "arXiv"
  },
  {
    "title": "Robust Scheduling on Uniform Machines - New Results Using a Relaxed Approximation Guarantee",
    "title_es": "Robust Scheduling on Uniform Machines - New Results Using a Relaxed Approximation Guarantee",
    "url": "https://arxiv.org/abs/2508.08979",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08979v1 Announce Type: new \nAbstract: We consider the problem of scheduling $n$ jobs on $m$ uniform machines while minimizing the makespan ($Q||C_{\\max}$) and maximizing the minimum completion time ($Q||C_{\\min}$) in an online setting with migration of jobs. In this online setting, the jobs are inserted or deleted over time, and at each step, the goal is to compute a near-optimal solution while reassigning some jobs, such that the overall processing time of reassigned jobs, called migration, is bounded by some factor $\\beta$ times the processing time of the job added or removed.\n  We propose Efficient Polynomial Time Approximation Schemes (EPTASs) with an additional load error of $\\mathcal{O}(\\varepsilon p_{\\max})$ for both problems, with constant amortized migration factor $\\beta$, where $p_{\\max}$ is the maximum processing time in the instance over all steps. As an intermediate step, we obtain Efficient Parameterized Approximation Schemes (EPASs) for both problems, $(1+\\varepsilon)$-competitive algorithms parameterized by $p_{\\max}$ and the number of different processing times $d$ in an instance, with $\\beta$ bounded in a function of $p_{\\max}$, $d$ and $\\varepsilon$.\n  This is the first result in the direction of a polynomial time approximation scheme in the field of online scheduling with bounded reassignment on uniform machines; before, such results were known only for the considered problems on identical machines. Crucial to our result is a division of the machines into large and small machines depending on the current approximate objective value, allowing for different approaches on either machine set, as well as a new way of rounding the instance that does not depend on the current objective value.",
    "source": "arXiv"
  },
  {
    "title": "Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion",
    "title_es": "Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion",
    "url": "https://arxiv.org/abs/2508.08982",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08982v1 Announce Type: new \nAbstract: Exploration is crucial for enabling legged robots to learn agile locomotion behaviors that can overcome diverse obstacles. However, such exploration is inherently challenging, and we often rely on extensive reward engineering, expert demonstrations, or curriculum learning - all of which limit generalizability. In this work, we propose Skill Discovery as Exploration (SDAX), a novel learning framework that significantly reduces human engineering effort. SDAX leverages unsupervised skill discovery to autonomously acquire a diverse repertoire of skills for overcoming obstacles. To dynamically regulate the level of exploration during training, SDAX employs a bi-level optimization process that autonomously adjusts the degree of exploration. We demonstrate that SDAX enables quadrupedal robots to acquire highly agile behaviors including crawling, climbing, leaping, and executing complex maneuvers such as jumping off vertical walls. Finally, we deploy the learned policy on real hardware, validating its successful transfer to the real world.",
    "source": "arXiv"
  },
  {
    "title": "Rational Inverse Reasoning",
    "title_es": "Rational Inverse Reasoning",
    "url": "https://arxiv.org/abs/2508.08983",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08983v1 Announce Type: new \nAbstract: Humans can observe a single, imperfect demonstration and immediately generalize to very different problem settings. Robots, in contrast, often require hundreds of examples and still struggle to generalize beyond the training conditions. We argue that this limitation arises from the inability to recover the latent explanations that underpin intelligent behavior, and that these explanations can take the form of structured programs consisting of high-level goals, sub-task decomposition, and execution constraints. In this work, we introduce Rational Inverse Reasoning (RIR), a framework for inferring these latent programs through a hierarchical generative model of behavior. RIR frames few-shot imitation as Bayesian program induction: a vision-language model iteratively proposes structured symbolic task hypotheses, while a planner-in-the-loop inference scheme scores each by the likelihood of the observed demonstration under that hypothesis. This loop yields a posterior over concise, executable programs. We evaluate RIR on a suite of continuous manipulation tasks designed to test one-shot and few-shot generalization across variations in object pose, count, geometry, and layout. With as little as one demonstration, RIR infers the intended task structure and generalizes to novel settings, outperforming state-of-the-art vision-language model baselines.",
    "source": "arXiv"
  },
  {
    "title": "Low-Regret and Low-Complexity Learning for Hierarchical Inference",
    "title_es": "Low-Regret and Low-Complexity Learning for Hierarchical Inference",
    "url": "https://arxiv.org/abs/2508.08985",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08985v1 Announce Type: new \nAbstract: This work focuses on Hierarchical Inference (HI) in edge intelligence systems, where a compact Local-ML model on an end-device works in conjunction with a high-accuracy Remote-ML model on an edge-server. HI aims to reduce latency, improve accuracy, and lower bandwidth usage by first using the Local-ML model for inference and offloading to the Remote-ML only when the local inference is likely incorrect. A critical challenge in HI is estimating the likelihood of the local inference being incorrect, especially when data distributions and offloading costs change over time -- a problem we term Hierarchical Inference Learning (HIL). We introduce a novel approach to HIL by modeling the probability of correct inference by the Local-ML as an increasing function of the model's confidence measure, a structure motivated by empirical observations but previously unexploited. We propose two policies, HI-LCB and HI-LCB-lite, based on the Upper Confidence Bound (UCB) framework. We demonstrate that both policies achieve order-optimal regret of $O(\\log T)$, a significant improvement over existing HIL policies with $O(T^{2/3})$ regret guarantees. Notably, HI-LCB-lite has an $O(1)$ per-sample computational complexity, making it well-suited for deployment on devices with severe resource limitations. Simulations using real-world datasets confirm that our policies outperform existing state-of-the-art HIL methods.",
    "source": "arXiv"
  },
  {
    "title": "ColorGPT: Leveraging Large Language Models for Multimodal Color Recommendation",
    "title_es": "ColorGPT: Leveraging Large Language Models for Multimodal Color Recommendation",
    "url": "https://arxiv.org/abs/2508.08987",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08987v1 Announce Type: new \nAbstract: Colors play a crucial role in the design of vector graphic documents by enhancing visual appeal, facilitating communication, improving usability, and ensuring accessibility. In this context, color recommendation involves suggesting appropriate colors to complete or refine a design when one or more colors are missing or require alteration. Traditional methods often struggled with these challenges due to the complex nature of color design and the limited data availability. In this study, we explored the use of pretrained Large Language Models (LLMs) and their commonsense reasoning capabilities for color recommendation, raising the question: Can pretrained LLMs serve as superior designers for color recommendation tasks? To investigate this, we developed a robust, rigorously validated pipeline, ColorGPT, that was built by systematically testing multiple color representations and applying effective prompt engineering techniques. Our approach primarily targeted color palette completion by recommending colors based on a set of given colors and accompanying context. Moreover, our method can be extended to full palette generation, producing an entire color palette corresponding to a provided textual description. Experimental results demonstrated that our LLM-based pipeline outperformed existing methods in terms of color suggestion accuracy and the distribution of colors in the color palette completion task. For the full palette generation task, our approach also yielded improvements in color diversity and similarity compared to current techniques.",
    "source": "arXiv"
  },
  {
    "title": "KFFocus: Highlighting Keyframes for Enhanced Video Understanding",
    "title_es": "KFFocus: Highlighting Keyframes for Enhanced Video Understanding",
    "url": "https://arxiv.org/abs/2508.08989",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08989v1 Announce Type: new \nAbstract: Recently, with the emergence of large language models, multimodal LLMs have demonstrated exceptional capabilities in image and video modalities. Despite advancements in video comprehension, the substantial computational demands of long video sequences lead current video LLMs (Vid-LLMs) to employ compression strategies at both the inter-frame level (e.g., uniform sampling of video frames) and intra-frame level (e.g., condensing all visual tokens of each frame into a limited number). However, this approach often neglects the uneven temporal distribution of critical information across frames, risking the omission of keyframes that contain essential temporal and semantic details. To tackle these challenges, we propose KFFocus, a method designed to efficiently compress video tokens and emphasize the informative context present within video frames. We substitute uniform sampling with a refined approach inspired by classic video compression principles to identify and capture keyframes based on their temporal redundancy. By assigning varying condensation ratios to frames based on their contextual relevance, KFFocus efficiently reduces token redundancy while preserving informative content details. Additionally, we introduce a spatiotemporal modeling module that encodes both the temporal relationships between video frames and the spatial structure within each frame, thus providing Vid-LLMs with a nuanced understanding of spatial-temporal dynamics. Extensive experiments on widely recognized video understanding benchmarks, especially long video scenarios, demonstrate that KFFocus significantly outperforms existing methods, achieving substantial computational efficiency and enhanced accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Spatial-Temporal Multi-Scale Quantization for Flexible Motion Generation",
    "title_es": "Spatial-Temporal Multi-Scale Quantization for Flexible Motion Generation",
    "url": "https://arxiv.org/abs/2508.08991",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08991v1 Announce Type: new \nAbstract: Despite significant advancements in human motion generation, current motion representations, typically formulated as discrete frame sequences, still face two critical limitations: (i) they fail to capture motion from a multi-scale perspective, limiting the capability in complex patterns modeling; (ii) they lack compositional flexibility, which is crucial for model's generalization in diverse generation tasks. To address these challenges, we introduce MSQ, a novel quantization method that compresses the motion sequence into multi-scale discrete tokens across spatial and temporal dimensions. MSQ employs distinct encoders to capture body parts at varying spatial granularities and temporally interpolates the encoded features into multiple scales before quantizing them into discrete tokens. Building on this representation, we establish a generative mask modeling model to effectively support motion editing, motion control, and conditional motion generation. Through quantitative and qualitative analysis, we show that our quantization method enables the seamless composition of motion tokens without requiring specialized design or re-training. Furthermore, extensive evaluations demonstrate that our approach outperforms existing baseline methods on various benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty",
    "title_es": "Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty",
    "url": "https://arxiv.org/abs/2508.08992",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08992v1 Announce Type: new \nAbstract: Prospect Theory (PT) models human decision-making under uncertainty, while epistemic markers (e.g., maybe) serve to express uncertainty in language. However, it remains largely unexplored whether Prospect Theory applies to contemporary Large Language Models and whether epistemic markers, which express human uncertainty, affect their decision-making behaviour. To address these research gaps, we design a three-stage experiment based on economic questionnaires. We propose a more general and precise evaluation framework to model LLMs' decision-making behaviour under PT, introducing uncertainty through the empirical probability values associated with commonly used epistemic markers in comparable contexts. We then incorporate epistemic markers into the evaluation framework based on their corresponding probability values to examine their influence on LLM decision-making behaviours. Our findings suggest that modelling LLMs' decision-making with PT is not consistently reliable, particularly when uncertainty is expressed in diverse linguistic forms. Our code is released in https://github.com/HKUST-KnowComp/MarPT.",
    "source": "arXiv"
  },
  {
    "title": "Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory",
    "title_es": "Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory",
    "url": "https://arxiv.org/abs/2508.08997",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08997v1 Announce Type: new \nAbstract: Multi-agent systems built on Large Language Models (LLMs) show exceptional promise for complex collaborative problem-solving, yet they face fundamental challenges stemming from context window limitations that impair memory consistency, role adherence, and procedural integrity. This paper introduces Intrinsic Memory Agents, a novel framework that addresses these limitations through structured agent-specific memories that evolve intrinsically with agent outputs. Specifically, our method maintains role-aligned memory templates that preserve specialized perspectives while focusing on task-relevant information. We benchmark our approach on the PDDL dataset, comparing its performance to existing state-of-the-art multi-agentic memory approaches and showing an improvement of 38.6\\% with the highest token efficiency. An additional evaluation is performed on a complex data pipeline design task, we demonstrate that our approach produces higher quality designs when comparing 5 metrics: scalability, reliability, usability, cost-effectiveness and documentation with additional qualitative evidence of the improvements. Our findings suggest that addressing memory limitations through structured, intrinsic approaches can improve the capabilities of multi-agent LLM systems on structured planning tasks.",
    "source": "arXiv"
  },
  {
    "title": "Generation of Real-time Robotic Emotional Expressions Learning from Human Demonstration in Mixed Reality",
    "title_es": "Generation of Real-time Robotic Emotional Expressions Learning from Human Demonstration in Mixed Reality",
    "url": "https://arxiv.org/abs/2508.08999",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08999v1 Announce Type: new \nAbstract: Expressive behaviors in robots are critical for effectively conveying their emotional states during interactions with humans. In this work, we present a framework that autonomously generates realistic and diverse robotic emotional expressions based on expert human demonstrations captured in Mixed Reality (MR). Our system enables experts to teleoperate a virtual robot from a first-person perspective, capturing their facial expressions, head movements, and upper-body gestures, and mapping these behaviors onto corresponding robotic components including eyes, ears, neck, and arms. Leveraging a flow-matching-based generative process, our model learns to produce coherent and varied behaviors in real-time in response to moving objects, conditioned explicitly on given emotional states. A preliminary test validated the effectiveness of our approach for generating autonomous expressions.",
    "source": "arXiv"
  },
  {
    "title": "UniConvNet: Expanding Effective Receptive Field while Maintaining Asymptotically Gaussian Distribution for ConvNets of Any Scale",
    "title_es": "UniConvNet: Expanding Effective Receptive Field while Maintaining Asymptotically Gaussian Distribution for ConvNets of Any Scale",
    "url": "https://arxiv.org/abs/2508.09000",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09000v1 Announce Type: new \nAbstract: Convolutional neural networks (ConvNets) with large effective receptive field (ERF), still in their early stages, have demonstrated promising effectiveness while constrained by high parameters and FLOPs costs and disrupted asymptotically Gaussian distribution (AGD) of ERF. This paper proposes an alternative paradigm: rather than merely employing extremely large ERF, it is more effective and efficient to expand the ERF while maintaining AGD of ERF by proper combination of smaller kernels, such as $7\\times{7}$, $9\\times{9}$, $11\\times{11}$. This paper introduces a Three-layer Receptive Field Aggregator and designs a Layer Operator as the fundamental operator from the perspective of receptive field. The ERF can be expanded to the level of existing large-kernel ConvNets through the stack of proposed modules while maintaining AGD of ERF. Using these designs, we propose a universal model for ConvNet of any scale, termed UniConvNet. Extensive experiments on ImageNet-1K, COCO2017, and ADE20K demonstrate that UniConvNet outperforms state-of-the-art CNNs and ViTs across various vision recognition tasks for both lightweight and large-scale models with comparable throughput. Surprisingly, UniConvNet-T achieves $84.2\\%$ ImageNet top-1 accuracy with $30M$ parameters and $5.1G$ FLOPs. UniConvNet-XL also shows competitive scalability to big data and large models, acquiring $88.4\\%$ top-1 accuracy on ImageNet. Code and models are publicly available at https://github.com/ai-paperwithcode/UniConvNet.",
    "source": "arXiv"
  },
  {
    "title": "Retrospective Sparse Attention for Efficient Long-Context Generation",
    "title_es": "Retrospective Sparse Attention for Efficient Long-Context Generation",
    "url": "https://arxiv.org/abs/2508.09001",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09001v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly deployed in long-context tasks such as reasoning, code generation, and multi-turn dialogue. However, inference over extended contexts is bottlenecked by the Key-Value (KV) cache, whose memory footprint grows linearly with sequence length and dominates latency at each decoding step. While recent KV cache compression methods identify and load important tokens, they focus predominantly on input contexts and fail to address the cumulative attention errors that arise during long decoding. In this paper, we introduce RetroAttention, a novel KV cache update technique that retrospectively revises past attention outputs using newly arrived KV entries from subsequent decoding steps. By maintaining a lightweight output cache, RetroAttention enables past queries to efficiently access more relevant context, while incurring minimal latency overhead. This breaks the fixed-attention-output paradigm and allows continual correction of prior approximations. Extensive experiments on long-generation benchmarks show that RetroAttention consistently outperforms state-of-the-art (SOTA) KV compression methods, increasing effective KV exposure by up to 1.6$\\times$ and accuracy by up to 21.9\\%.",
    "source": "arXiv"
  },
  {
    "title": "Large Scale Robotic Material Handling: Learning, Planning, and Control",
    "title_es": "Large Scale Robotic Material Handling: Learning, Planning, and Control",
    "url": "https://arxiv.org/abs/2508.09003",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09003v1 Announce Type: new \nAbstract: Bulk material handling involves the efficient and precise moving of large quantities of materials, a core operation in many industries, including cargo ship unloading, waste sorting, construction, and demolition. These repetitive, labor-intensive, and safety-critical operations are typically performed using large hydraulic material handlers equipped with underactuated grippers. In this work, we present a comprehensive framework for the autonomous execution of large-scale material handling tasks. The system integrates specialized modules for environment perception, pile attack point selection, path planning, and motion control. The main contributions of this work are two reinforcement learning-based modules: an attack point planner that selects optimal grasping locations on the material pile to maximize removal efficiency and minimize the number of scoops, and a robust trajectory following controller that addresses the precision and safety challenges associated with underactuated grippers in movement, while utilizing their free-swinging nature to release material through dynamic throwing. We validate our framework through real-world experiments on a 40 t material handler in a representative worksite, focusing on two key tasks: high-throughput bulk pile management and high-precision truck loading. Comparative evaluations against human operators demonstrate the system's effectiveness in terms of precision, repeatability, and operational safety. To the best of our knowledge, this is the first complete automation of material handling tasks on a full scale.",
    "source": "arXiv"
  },
  {
    "title": "MechaFormer: Sequence Learning for Kinematic Mechanism Design Automation",
    "title_es": "MechaFormer: Sequence Learning for Kinematic Mechanism Design Automation",
    "url": "https://arxiv.org/abs/2508.09005",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09005v1 Announce Type: new \nAbstract: Designing mechanical mechanisms to trace specific paths is a classic yet notoriously difficult engineering problem, characterized by a vast and complex search space of discrete topologies and continuous parameters. We introduce MechaFormer, a Transformer-based model that tackles this challenge by treating mechanism design as a conditional sequence generation task. Our model learns to translate a target curve into a domain-specific language (DSL) string, simultaneously determining the mechanism's topology and geometric parameters in a single, unified process. MechaFormer significantly outperforms existing baselines, achieving state-of-the-art path-matching accuracy and generating a wide diversity of novel and valid designs. We demonstrate a suite of sampling strategies that can dramatically improve solution quality and offer designers valuable flexibility. Furthermore, we show that the high-quality outputs from MechaFormer serve as excellent starting points for traditional optimizers, creating a hybrid approach that finds superior solutions with remarkable efficiency.",
    "source": "arXiv"
  },
  {
    "title": "Principles for Environmental Justice in Technology: Toward a Regenerative Future",
    "title_es": "Principles for Environmental Justice in Technology: Toward a Regenerative Future",
    "url": "https://arxiv.org/abs/2508.09007",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09007v1 Announce Type: new \nAbstract: This paper introduces the Environmental Justice in Technology (EJIT) Principles, a framework to help reorient technological development toward social and ecological justice and collective flourishing. In response to prevailing models of technological innovation that prioritize speed, scale, and profit while neglecting systemic injustice, the EJIT principles offer an alternative: a set of guiding values that foreground interdependence, repair, and community self-determination. Drawing inspiration from the 1991 principles of environmental justice, this framework extends their commitments into the technological domain, treating environmental justice not as a peripheral concern but as a necessary foundation for building equitable and regenerative futures. We situate the EJIT principles within the broader landscape of environmental justice, design justice, and post-growth computing, proposing them as a values infrastructure for resisting extractive defaults and envisioning technological systems that operate in reciprocity with people and the planet. In doing so, this article aims to support collective efforts to transform not only what technologies we build, but how, why, and for whom.",
    "source": "arXiv"
  },
  {
    "title": "Optimality of adaptive $H(\\operatorname{div}\\operatorname{div})$ mixed finite element methods for the Kirchhoff-Love plate bending problem",
    "title_es": "Optimality of adaptive $H(\\operatorname{div}\\operatorname{div})$ mixed finite element methods for the Kirchhoff-Love plate bending problem",
    "url": "https://arxiv.org/abs/2508.09008",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09008v1 Announce Type: new \nAbstract: This paper presents a reliable and efficient residual-based a posteriori error analysis for the symmetric $H(\\operatorname{div}\\operatorname{div})$ mixed finite element method for the Kirchhoff-Love plate bending problem with mixed boundary conditions. The key ingredient lies in the construction of boundary-condition-preserving complexes at both continuous and discrete levels. Additionally, the discrete symmetric $H(\\operatorname{div}\\operatorname{div})$ space is extended to ensure nestedness, which leads to optimality for the adaptive algorithm. Numerical examples confirm the effectiveness of the a posteriori error estimator and demonstrate the optimal convergence rate under adaptive refinements.",
    "source": "arXiv"
  },
  {
    "title": "Towards Perfection: Building Inter-component Mutual Correction for Retinex-based Low-light Image Enhancement",
    "title_es": "Towards Perfection: Building Inter-component Mutual Correction for Retinex-based Low-light Image Enhancement",
    "url": "https://arxiv.org/abs/2508.09009",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09009v1 Announce Type: new \nAbstract: In low-light image enhancement, Retinex-based deep learning methods have garnered significant attention due to their exceptional interpretability. These methods decompose images into mutually independent illumination and reflectance components, allows each component to be enhanced separately. In fact, achieving perfect decomposition of illumination and reflectance components proves to be quite challenging, with some residuals still existing after decomposition. In this paper, we formally name these residuals as inter-component residuals (ICR), which has been largely underestimated by previous methods. In our investigation, ICR not only affects the accuracy of the decomposition but also causes enhanced components to deviate from the ideal outcome, ultimately reducing the final synthesized image quality. To address this issue, we propose a novel Inter-correction Retinex model (IRetinex) to alleviate ICR during the decomposition and enhancement stage. In the decomposition stage, we leverage inter-component residual reduction module to reduce the feature similarity between illumination and reflectance components. In the enhancement stage, we utilize the feature similarity between the two components to detect and mitigate the impact of ICR within each enhancement unit. Extensive experiments on three low-light benchmark datasets demonstrated that by reducing ICR, our method outperforms state-of-the-art approaches both qualitatively and quantitatively.",
    "source": "arXiv"
  },
  {
    "title": "LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA",
    "title_es": "LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA",
    "url": "https://arxiv.org/abs/2508.09012",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09012v1 Announce Type: new \nAbstract: This paper describes our participation in SemEval 2025 Task 8, focused on Tabular Question Answering. We developed a zero-shot pipeline that leverages an Large Language Model to generate functional code capable of extracting the relevant information from tabular data based on an input question. Our approach consists of a modular pipeline where the main code generator module is supported by additional components that identify the most relevant columns and analyze their data types to improve extraction accuracy. In the event that the generated code fails, an iterative refinement process is triggered, incorporating the error feedback into a new generation prompt to enhance robustness. Our results show that zero-shot code generation is a valid approach for Tabular QA, achieving rank 33 of 53 in the test phase despite the lack of task-specific fine-tuning.",
    "source": "arXiv"
  },
  {
    "title": "Uncertainty-aware Cross-training for Semi-supervised Medical Image Segmentation",
    "title_es": "Uncertainty-aware Cross-training for Semi-supervised Medical Image Segmentation",
    "url": "https://arxiv.org/abs/2508.09014",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09014v1 Announce Type: new \nAbstract: Semi-supervised learning has gained considerable popularity in medical image segmentation tasks due to its capability to reduce reliance on expert-examined annotations. Several mean-teacher (MT) based semi-supervised methods utilize consistency regularization to effectively leverage valuable information from unlabeled data. However, these methods often heavily rely on the student model and overlook the potential impact of cognitive biases within the model. Furthermore, some methods employ co-training using pseudo-labels derived from different inputs, yet generating high-confidence pseudo-labels from perturbed inputs during training remains a significant challenge. In this paper, we propose an Uncertainty-aware Cross-training framework for semi-supervised medical image Segmentation (UC-Seg). Our UC-Seg framework incorporates two distinct subnets to effectively explore and leverage the correlation between them, thereby mitigating cognitive biases within the model. Specifically, we present a Cross-subnet Consistency Preservation (CCP) strategy to enhance feature representation capability and ensure feature consistency across the two subnets. This strategy enables each subnet to correct its own biases and learn shared semantics from both labeled and unlabeled data. Additionally, we propose an Uncertainty-aware Pseudo-label Generation (UPG) component that leverages segmentation results and corresponding uncertainty maps from both subnets to generate high-confidence pseudo-labels. We extensively evaluate the proposed UC-Seg on various medical image segmentation tasks involving different modality images, such as MRI, CT, ultrasound, colonoscopy, and so on. The results demonstrate that our method achieves superior segmentation accuracy and generalization performance compared to other state-of-the-art semi-supervised methods. Our code will be released at https://github.com/taozh2017/UCSeg.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on Training-free Alignment of Large Language Models",
    "title_es": "A Survey on Training-free Alignment of Large Language Models",
    "url": "https://arxiv.org/abs/2508.09016",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09016v1 Announce Type: new \nAbstract: The alignment of large language models (LLMs) aims to ensure their outputs adhere to human values, ethical standards, and legal norms. Traditional alignment methods often rely on resource-intensive fine-tuning (FT), which may suffer from knowledge degradation and face challenges in scenarios where the model accessibility or computational resources are constrained. In contrast, training-free (TF) alignment techniques--leveraging in-context learning, decoding-time adjustments, and post-generation corrections--offer a promising alternative by enabling alignment without heavily retraining LLMs, making them adaptable to both open-source and closed-source environments. This paper presents the first systematic review of TF alignment methods, categorizing them by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we provide a detailed examination from the viewpoint of LLMs and multimodal LLMs (MLLMs), highlighting their mechanisms and limitations. Furthermore, we identify key challenges and future directions, paving the way for more inclusive and effective TF alignment techniques. By synthesizing and organizing the rapidly growing body of research, this survey offers a guidance for practitioners and advances the development of safer and more reliable LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs",
    "title_es": "Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs",
    "url": "https://arxiv.org/abs/2508.09019",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09019v1 Announce Type: new \nAbstract: As large language models (LLMs) become more integrated into societal systems, the risk of them perpetuating and amplifying harmful biases becomes a critical safety concern. Traditional methods for mitigating bias often rely on data filtering or post-hoc output moderation, which treat the model as an opaque black box. In this work, we introduce a complete, end-to-end system that uses techniques from mechanistic interpretability to both identify and actively mitigate bias directly within a model's internal workings. Our method involves two primary stages. First, we train linear \"probes\" on the internal activations of a model to detect the latent representations of various biases (e.g., gender, race, age). Our experiments on \\texttt{gpt2-large} demonstrate that these probes can identify biased content with near-perfect accuracy, revealing that bias representations become most salient in the model's later layers. Second, we leverage these findings to compute \"steering vectors\" by contrasting the model's activation patterns for biased and neutral statements. By adding these vectors during inference, we can actively steer the model's generative process away from producing harmful, stereotypical, or biased content in real-time. We demonstrate the efficacy of this activation steering technique, showing that it successfully alters biased completions toward more neutral alternatives. We present our work as a robust and reproducible system that offers a more direct and interpretable approach to building safer and more accountable LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Attacks and Defenses Against LLM Fingerprinting",
    "title_es": "Attacks and Defenses Against LLM Fingerprinting",
    "url": "https://arxiv.org/abs/2508.09021",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09021v1 Announce Type: new \nAbstract: As large language models are increasingly deployed in sensitive environments, fingerprinting attacks pose significant privacy and security risks. We present a study of LLM fingerprinting from both offensive and defensive perspectives. Our attack methodology uses reinforcement learning to automatically optimize query selection, achieving better fingerprinting accuracy with only 3 queries compared to randomly selecting 3 queries from the same pool. Our defensive approach employs semantic-preserving output filtering through a secondary LLM to obfuscate model identity while maintaining semantic integrity. The defensive method reduces fingerprinting accuracy across tested models while preserving output quality. These contributions show the potential to improve fingerprinting tools capabilities while providing practical mitigation strategies against fingerprinting attacks.",
    "source": "arXiv"
  },
  {
    "title": "When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges",
    "title_es": "When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges",
    "url": "https://arxiv.org/abs/2508.09022",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09022v1 Announce Type: new \nAbstract: Existing deepfake detection methods heavily depend on labeled training data. However, as AI-generated content becomes increasingly realistic, even \\textbf{human annotators struggle to distinguish} between deepfakes and authentic images. This makes the labeling process both time-consuming and less reliable. Specifically, there is a growing demand for approaches that can effectively utilize large-scale unlabeled data from online social networks. Unlike typical unsupervised learning tasks, where categories are distinct, AI-generated faces closely mimic real image distributions and share strong similarities, causing performance drop in conventional strategies. In this paper, we introduce the Dual-Path Guidance Network (DPGNet), to tackle two key challenges: (1) bridging the domain gap between faces from different generation models, and (2) utilizing unlabeled image samples. The method features two core modules: text-guided cross-domain alignment, which uses learnable prompts to unify visual and textual embeddings into a domain-invariant feature space, and curriculum-driven pseudo label generation, which dynamically exploit more informative unlabeled samples. To prevent catastrophic forgetting, we also facilitate bridging between domains via cross-domain knowledge distillation. Extensive experiments on \\textbf{11 popular datasets}, show that DPGNet outperforms SoTA approaches by \\textbf{6.3\\%}, highlighting its effectiveness in leveraging unlabeled data to address the annotation challenges posed by the increasing realism of deepfakes.",
    "source": "arXiv"
  },
  {
    "title": "E3-Rewrite: Learning to Rewrite SQL for Executability, Equivalence,and Efficiency",
    "title_es": "E3-Rewrite: Learning to Rewrite SQL for Executability, Equivalence,and Efficiency",
    "url": "https://arxiv.org/abs/2508.09023",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09023v1 Announce Type: new \nAbstract: SQL query rewriting aims to reformulate a query into a more efficient form while preserving equivalence. Most existing methods rely on predefined rewrite rules. However, such rule-based approaches face fundamental limitations: (1) fixed rule sets generalize poorly to novel query patterns and struggle with complex queries; (2) a wide range of effective rewriting strategies cannot be fully captured by declarative rules. To overcome these issues, we propose using large language models (LLMs) to generate rewrites. LLMs can capture complex strategies, such as evaluation reordering and CTE rewriting. Despite this potential, directly applying LLMs often results in suboptimal or non-equivalent rewrites due to a lack of execution awareness and semantic grounding. To address these challenges, We present E3-Rewrite, an LLM-based SQL rewriting framework that produces executable, equivalent, and efficient queries. It integrates two core components: a context construction module and a reinforcement learning framework. First, the context module leverages execution plans and retrieved demonstrations to build bottleneck-aware prompts that guide inference-time rewriting. Second, we design a reward function targeting executability, equivalence, and efficiency, evaluated via syntax checks, equivalence verification, and cost estimation. Third, to ensure stable multi-objective learning, we adopt a staged curriculum that first emphasizes executability and equivalence, then gradually incorporates efficiency. Extensive experiments show that E3-Rewrite achieves up to a 25.6\\% reduction in query execution time compared to state-of-the-art methods across multiple SQL benchmarks. Moreover, it delivers up to 24.4\\% more successful rewrites, expanding coverage to complex queries that previous systems failed to handle.",
    "source": "arXiv"
  },
  {
    "title": "A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems",
    "title_es": "A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems",
    "url": "https://arxiv.org/abs/2508.09027",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09027v1 Announce Type: new \nAbstract: Passenger waiting time prediction plays a critical role in enhancing both ridesharing user experience and platform efficiency. While most existing research focuses on post-request waiting time prediction with knowing the matched driver information, pre-request waiting time prediction (i.e., before submitting a ride request and without matching a driver) is also important, as it enables passengers to plan their trips more effectively and enhance the experience of both passengers and drivers. However, it has not been fully studied by existing works. In this paper, we take the first step toward understanding the predictability and explainability of pre-request passenger waiting time in ridesharing systems. Particularly, we conduct an in-depth data-driven study to investigate the impact of demand&supply dynamics on passenger waiting time. Based on this analysis and feature engineering, we propose FiXGBoost, a novel feature interaction-based XGBoost model designed to predict waiting time without knowing the assigned driver information. We further perform an importance analysis to quantify the contribution of each factor. Experiments on a large-scale real-world ridesharing dataset including over 30 million trip records show that our FiXGBoost can achieve a good performance for pre-request passenger waiting time prediction with high explainability.",
    "source": "arXiv"
  },
  {
    "title": "Envisioning Generative Artificial Intelligence in Cartography and Mapmaking",
    "title_es": "Envisioning Generative Artificial Intelligence in Cartography and Mapmaking",
    "url": "https://arxiv.org/abs/2508.09028",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09028v1 Announce Type: new \nAbstract: Generative artificial intelligence (GenAI), including large language models, diffusion-based image generation models, and GenAI agents, has provided new opportunities for advancements in mapping and cartography. Due to their characteristics including world knowledge and generalizability, artistic style and creativity, and multimodal integration, we envision that GenAI may benefit a variety of cartographic design decisions, from mapmaking (e.g., conceptualization, data preparation, map design, and map evaluation) to map use (such as map reading, interpretation, and analysis). This paper discusses several important topics regarding why and how GenAI benefits cartography with case studies including symbolization, map evaluation, and map reading. Despite its unprecedented potential, we identify key scenarios where GenAI may not be suitable, such as tasks that require a deep understanding of cartographic knowledge or prioritize precision and reliability. We also emphasize the need to consider ethical and social implications, such as concerns related to hallucination, reproducibility, bias, copyright, and explainability. This work lays the foundation for further exploration and provides a roadmap for future research at the intersection of GenAI and cartography.",
    "source": "arXiv"
  },
  {
    "title": "Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding",
    "title_es": "Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding",
    "url": "https://arxiv.org/abs/2508.09032",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09032v1 Announce Type: new \nAbstract: Vision-Language-Action models have demonstrated remarkable capabilities in predicting agent movements within virtual environments and real-world scenarios based on visual observations and textual instructions. Although recent research has focused on enhancing spatial and temporal understanding independently, this paper presents a novel approach that integrates both aspects through visual prompting. We introduce a method that projects visual traces of key points from observations onto depth maps, enabling models to capture both spatial and temporal information simultaneously. The experiments in SimplerEnv show that the mean number of tasks successfully solved increased for 4% compared to SpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this enhancement can be achieved with minimal training data, making it particularly valuable for real-world applications where data collection is challenging. The project page is available at https://ampiromax.github.io/ST-VLA.",
    "source": "arXiv"
  },
  {
    "title": "Beyond Predictions: A Study of AI Strength and Weakness Transparency Communication on Human-AI Collaboration",
    "title_es": "Beyond Predictions: A Study of AI Strength and Weakness Transparency Communication on Human-AI Collaboration",
    "url": "https://arxiv.org/abs/2508.09033",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09033v1 Announce Type: new \nAbstract: The promise of human-AI teaming lies in humans and AI working together to achieve performance levels neither could accomplish alone. Effective communication between AI and humans is crucial for teamwork, enabling users to efficiently benefit from AI assistance. This paper investigates how AI communication impacts human-AI team performance. We examine AI explanations that convey an awareness of its strengths and limitations. To achieve this, we train a decision tree on the model's mistakes, allowing it to recognize and explain where and why it might err. Through a user study on an income prediction task, we assess the impact of varying levels of information and explanations about AI predictions. Our results show that AI performance insights enhance task performance, and conveying AI awareness of its strengths and weaknesses improves trust calibration. These findings highlight the importance of considering how information delivery influences user trust and reliance in AI-assisted decision-making.",
    "source": "arXiv"
  },
  {
    "title": "P/D-Device: Disaggregated Large Language Model between Cloud and Devices",
    "title_es": "P/D-Device: Disaggregated Large Language Model between Cloud and Devices",
    "url": "https://arxiv.org/abs/2508.09035",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09035v1 Announce Type: new \nAbstract: Serving disaggregated large language models has been widely adopted in industrial practice for enhanced performance. However, too many tokens generated in decoding phase, i.e., occupying the resources for a long time, essentially hamper the cloud from achieving a higher throughput. Meanwhile, due to limited on-device resources, the time to first token (TTFT), i.e., the latency of prefill phase, increases dramatically with the growth on prompt length. In order to concur with such a bottleneck on resources, i.e., long occupation in cloud and limited on-device computing capacity, we propose to separate large language model between cloud and devices. That is, the cloud helps a portion of the content for each device, only in its prefill phase. Specifically, after receiving the first token from the cloud, decoupling with its own prefill, the device responds to the user immediately for a lower TTFT. Then, the following tokens from cloud are presented via a speed controller for smoothed TPOT (the time per output token), until the device catches up with the progress. On-device prefill is then amortized using received tokens while the resource usage in cloud is controlled. Moreover, during cloud prefill, the prompt can be refined, using those intermediate data already generated, to further speed up on-device inference. We implement such a scheme P/D-Device, and confirm its superiority over other alternatives. We further propose an algorithm to decide the best settings. Real-trace experiments show that TTFT decreases at least 60%, maximum TPOT is about tens of milliseconds, and cloud throughput increases by up to 15x.",
    "source": "arXiv"
  },
  {
    "title": "Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams",
    "title_es": "Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams",
    "url": "https://arxiv.org/abs/2508.09036",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09036v1 Announce Type: new \nAbstract: The rapid emergence of large language models (LLMs) has raised urgent questions across the modern workforce about this new technology's strengths, weaknesses, and capabilities. For privacy professionals, the question is whether these AI systems can provide reliable support on regulatory compliance, privacy program management, and AI governance. In this study, we evaluate ten leading open and closed LLMs, including models from OpenAI, Anthropic, Google DeepMind, Meta, and DeepSeek, by benchmarking their performance on industry-standard certification exams: CIPP/US, CIPM, CIPT, and AIGP from the International Association of Privacy Professionals (IAPP). Each model was tested using official sample exams in a closed-book setting and compared to IAPP's passing thresholds. Our findings show that several frontier models such as Gemini 2.5 Pro and OpenAI's GPT-5 consistently achieve scores exceeding the standards for professional human certification - demonstrating substantial expertise in privacy law, technical controls, and AI governance. The results highlight both the strengths and domain-specific gaps of current LLMs and offer practical insights for privacy officers, compliance leads, and technologists assessing the readiness of AI tools for high-stakes data governance roles. This paper provides an overview for professionals navigating the intersection of AI advancement and regulatory risk and establishes a machine benchmark based on human-centric evaluations.",
    "source": "arXiv"
  },
  {
    "title": "LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback",
    "title_es": "LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback",
    "url": "https://arxiv.org/abs/2508.09042",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09042v1 Announce Type: new \nAbstract: Although large language models (LLMs) hold significant promise in psychotherapy, their direct application in patient-facing scenarios raises ethical and safety concerns. Therefore, this work shifts towards developing an LLM as a supervisor to train real therapists. In addition to the privacy of clinical therapist training data, a fundamental contradiction complicates the training of therapeutic behaviors: clear feedback standards are necessary to ensure a controlled training system, yet there is no absolute \"gold standard\" for appropriate therapeutic behaviors in practice. In contrast, many common therapeutic mistakes are universal and identifiable, making them effective triggers for targeted feedback that can serve as clearer evidence. Motivated by this, we create a novel therapist-training paradigm: (1) guidelines for mistaken behaviors and targeted correction strategies are first established as standards; (2) a human-in-the-loop dialogue-feedback dataset is then constructed, where a mistake-prone agent intentionally makes standard mistakes during interviews naturally, and a supervisor agent locates and identifies mistakes and provides targeted feedback; (3) after fine-tuning on this dataset, the final supervisor model is provided for real therapist training. The detailed experimental results of automated, human and downstream assessments demonstrate that models fine-tuned on our dataset MATE, can provide high-quality feedback according to the clinical guideline, showing significant potential for the therapist training scenario.",
    "source": "arXiv"
  },
  {
    "title": "Where are GIScience Faculty Hired from? Analyzing Faculty Mobility and Research Themes Through Hiring Networks",
    "title_es": "Where are GIScience Faculty Hired from? Analyzing Faculty Mobility and Research Themes Through Hiring Networks",
    "url": "https://arxiv.org/abs/2508.09043",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09043v1 Announce Type: new \nAbstract: Academia is profoundly influenced by faculty hiring networks, which serve as critical conduits for knowledge dissemination and the formation of collaborative research initiatives. While extensive research in various disciplines has revealed the institutional hierarchies inherent in these networks, their impacts within GIScience remain underexplored. To fill this gap, this study analyzes the placement patterns of 946 GIScience faculty worldwide by mapping the connections between PhD-granting institutions and current faculty affiliations. Our dataset, which is compiled from volunteer-contributed information, is the most comprehensive collection available in this field. While there may be some limitations in its representativeness, its scope and depth provide a unique and valuable perspective on the global placement patterns of GIScience faculty. Our analysis reveals several influential programs in placing GIScience faculty, with hiring concentrated in the western countries. We examined the diversity index to assess the representation of regions and institutions within the global GIScience faculty network. We observe significant internal retention at both the continental and country levels, and a high level of non-self-hired ratio at the institutional level. Over time, research themes have also evolved, with growing research clusters emphasis on spatial data analytics, cartography and geovisualization, geocomputation, and environmental sciences, etc. These results illuminate the influence of hiring practices on global knowledge dissemination and contribute to promoting academic equity within GIScience and Geography.",
    "source": "arXiv"
  },
  {
    "title": "Per-Query Visual Concept Learning",
    "title_es": "Per-Query Visual Concept Learning",
    "url": "https://arxiv.org/abs/2508.09045",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09045v1 Announce Type: new \nAbstract: Visual concept learning, also known as Text-to-image personalization, is the process of teaching new concepts to a pretrained model. This has numerous applications from product placement to entertainment and personalized design. Here we show that many existing methods can be substantially augmented by adding a personalization step that is (1) specific to the prompt and noise seed, and (2) using two loss terms based on the self- and cross- attention, capturing the identity of the personalized concept. Specifically, we leverage PDM features - previously designed to capture identity - and show how they can be used to improve personalized semantic similarity. We evaluate the benefit that our method gains on top of six different personalization methods, and several base text-to-image models (both UNet- and DiT-based). We find significant improvements even over previous per-query personalization methods.",
    "source": "arXiv"
  },
  {
    "title": "Behavioural Theory of Reflective Algorithms II: Reflective Parallel Algorithms",
    "title_es": "Behavioural Theory of Reflective Algorithms II: Reflective Parallel Algorithms",
    "url": "https://arxiv.org/abs/2508.09053",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09053v1 Announce Type: new \nAbstract: We develop a behavioural theory of reflective parallel algorithms (RAs), i.e. synchronous parallel algorithms that can modify their own behaviour. The theory comprises a set of postulates defining the class of RAs, an abstract machine model, and the proof that all RAs are captured by this machine model. RAs are sequential-time, parallel algorithms, where every state includes a representation of the algorithm in that state, thus enabling linguistic reflection. Bounded exploration is preserved using multiset comprehension terms as values. The abstract machine model is defined by reflective Abstract State Machines (rASMs), which extend ASMs using extended states that include an updatable representation of the main ASM rule to be executed by the machine in that state.",
    "source": "arXiv"
  },
  {
    "title": "CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks",
    "title_es": "CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks",
    "url": "https://arxiv.org/abs/2508.09054",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09054v1 Announce Type: new \nAbstract: Track circuits are critical for railway operations, acting as the main signalling sub-system to locate trains. Continuous Variable Current Modulation (CVCM) is one such technology. Like any field-deployed, safety-critical asset, it can fail, triggering cascading disruptions. Many failures originate as subtle anomalies that evolve over time, often not visually apparent in monitored signals. Conventional approaches, which rely on clear signal changes, struggle to detect them early. Early identification of failure types is essential to improve maintenance planning, minimising downtime and revenue loss. Leveraging deep neural networks, we propose a predictive maintenance framework that classifies anomalies well before they escalate into failures. Validated on 10 CVCM failure cases across different installations, the method is ISO-17359 compliant and outperforms conventional techniques, achieving 99.31% overall accuracy with detection within 1% of anomaly onset. Through conformal prediction, we provide uncertainty estimates, reaching 99% confidence with consistent coverage across classes. Given CVCMs global deployment, the approach is scalable and adaptable to other track circuits and railway systems, enhancing operational reliability.",
    "source": "arXiv"
  },
  {
    "title": "FetFIDS: A Feature Embedding Attention based Federated Network Intrusion Detection Algorithm",
    "title_es": "FetFIDS: A Feature Embedding Attention based Federated Network Intrusion Detection Algorithm",
    "url": "https://arxiv.org/abs/2508.09056",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09056v1 Announce Type: new \nAbstract: Intrusion Detection Systems (IDS) have an increasingly important role in preventing exploitation of network vulnerabilities by malicious actors. Recent deep learning based developments have resulted in significant improvements in the performance of IDS systems. In this paper, we present FetFIDS, where we explore the employment of feature embedding instead of positional embedding to improve intrusion detection performance of a transformer based deep learning system. Our model is developed with the aim of deployments in edge learning scenarios, where federated learning over multiple communication rounds can ensure both privacy and localized performance improvements. FetFIDS outperforms multiple state-of-the-art intrusion detection systems in a federated environment and demonstrates a high degree of suitability to federated learning. The code for this work can be found at https://github.com/ghosh64/fetfids.",
    "source": "arXiv"
  },
  {
    "title": "MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions",
    "title_es": "MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions",
    "url": "https://arxiv.org/abs/2508.09057",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09057v1 Announce Type: new \nAbstract: Given the significant advances in Large Vision Language Models (LVLMs) in reasoning and visual understanding, mobile agents are rapidly emerging to meet users' automation needs. However, existing evaluation benchmarks are disconnected from the real world and fail to adequately address the diverse and complex requirements of users. From our extensive collection of user questionnaire, we identified five tasks: Multi-App, Vague, Interactive, Single-App, and Unethical Instructions. Around these tasks, we present \\textbf{MVISU-Bench}, a bilingual benchmark that includes 404 tasks across 137 mobile applications. Furthermore, we propose Aider, a plug-and-play module that acts as a dynamic prompt prompter to mitigate risks and clarify user intent for mobile agents. Our Aider is easy to integrate into several frameworks and has successfully improved overall success rates by 19.55\\% compared to the current state-of-the-art (SOTA) on MVISU-Bench. Specifically, it achieves success rate improvements of 53.52\\% and 29.41\\% for unethical and interactive instructions, respectively. Through extensive experiments and analysis, we highlight the gap between existing mobile agents and real-world user expectations.",
    "source": "arXiv"
  },
  {
    "title": "ALFred: An Active Learning Framework for Real-world Semi-supervised Anomaly Detection with Adaptive Thresholds",
    "title_es": "ALFred: An Active Learning Framework for Real-world Semi-supervised Anomaly Detection with Adaptive Thresholds",
    "url": "https://arxiv.org/abs/2508.09058",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09058v1 Announce Type: new \nAbstract: Video Anomaly Detection (VAD) can play a key role in spotting unusual activities in video footage. VAD is difficult to use in real-world settings due to the dynamic nature of human actions, environmental variations, and domain shifts. Traditional evaluation metrics often prove inadequate for such scenarios, as they rely on static assumptions and fall short of identifying a threshold that distinguishes normal from anomalous behavior in dynamic settings. To address this, we introduce an active learning framework tailored for VAD, designed for adapting to the ever-changing real-world conditions. Our approach leverages active learning to continuously select the most informative data points for labeling, thereby enhancing model adaptability. A critical innovation is the incorporation of a human-in-the-loop mechanism, which enables the identification of actual normal and anomalous instances from pseudo-labeling results generated by AI. This collected data allows the framework to define an adaptive threshold tailored to different environments, ensuring that the system remains effective as the definition of 'normal' shifts across various settings. Implemented within a lab-based framework that simulates real-world conditions, our approach allows rigorous testing and refinement of VAD algorithms with a new metric. Experimental results show that our method achieves an EBI (Error Balance Index) of 68.91 for Q3 in real-world simulated scenarios, demonstrating its practical effectiveness and significantly enhancing the applicability of VAD in dynamic environments.",
    "source": "arXiv"
  },
  {
    "title": "Causal Machine Learning for Patient-Level Intraoperative Opioid Dose Prediction from Electronic Health Records",
    "title_es": "Causal Machine Learning for Patient-Level Intraoperative Opioid Dose Prediction from Electronic Health Records",
    "url": "https://arxiv.org/abs/2508.09059",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09059v1 Announce Type: new \nAbstract: This paper introduces the OPIAID algorithm, a novel approach for predicting and recommending personalized opioid dosages for individual patients. The algorithm optimizes pain management while minimizing opioid related adverse events (ORADE) by employing machine learning models trained on observational electronic health records (EHR) data. It leverages a causal machine learning approach to understand the relationship between opioid dose, case specific patient and intraoperative characteristics, and pain versus ORADE outcomes. The OPIAID algorithm considers patient-specific characteristics and the influence of different opiates, enabling personalized dose recommendations. This paper outlines the algorithm's methodology and architecture, and discusses key assumptions, and approaches to evaluating its performance.",
    "source": "arXiv"
  },
  {
    "title": "Developing a Transferable Federated Network Intrusion Detection System",
    "title_es": "Developing a Transferable Federated Network Intrusion Detection System",
    "url": "https://arxiv.org/abs/2508.09060",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09060v1 Announce Type: new \nAbstract: Intrusion Detection Systems (IDS) are a vital part of a network-connected device. In this paper, we develop a deep learning based intrusion detection system that is deployed in a distributed setup across devices connected to a network. Our aim is to better equip deep learning models against unknown attacks using knowledge from known attacks. To this end, we develop algorithms to maximize the number of transferability relationships. We propose a Convolutional Neural Network (CNN) model, along with two algorithms that maximize the number of relationships observed. One is a two step data pre-processing stage, and the other is a Block-Based Smart Aggregation (BBSA) algorithm. The proposed system succeeds in achieving superior transferability performance while maintaining impressive local detection rates. We also show that our method is generalizable, exhibiting transferability potential across datasets and even with different backbones. The code for this work can be found at https://github.com/ghosh64/tabfidsv2.",
    "source": "arXiv"
  },
  {
    "title": "VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception",
    "title_es": "VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception",
    "url": "https://arxiv.org/abs/2508.09061",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09061v1 Announce Type: new \nAbstract: Open-set perception in complex traffic environments poses a critical challenge for autonomous driving systems, particularly in identifying previously unseen object categories, which is vital for ensuring safety. Visual Language Models (VLMs), with their rich world knowledge and strong semantic reasoning capabilities, offer new possibilities for addressing this task. However, existing approaches typically leverage VLMs to extract visual features and couple them with traditional object detectors, resulting in multi-stage error propagation that hinders perception accuracy. To overcome this limitation, we propose VLM-3D, the first end-to-end framework that enables VLMs to perform 3D geometric perception in autonomous driving scenarios. VLM-3D incorporates Low-Rank Adaptation (LoRA) to efficiently adapt VLMs to driving tasks with minimal computational overhead, and introduces a joint semantic-geometric loss design: token-level semantic loss is applied during early training to ensure stable convergence, while 3D IoU loss is introduced in later stages to refine the accuracy of 3D bounding box predictions. Evaluations on the nuScenes dataset demonstrate that the proposed joint semantic-geometric loss in VLM-3D leads to a 12.8% improvement in perception accuracy, fully validating the effectiveness and advancement of our method.",
    "source": "arXiv"
  },
  {
    "title": "VertexRegen: Mesh Generation with Continuous Level of Detail",
    "title_es": "VertexRegen: Mesh Generation with Continuous Level of Detail",
    "url": "https://arxiv.org/abs/2508.09062",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09062v1 Announce Type: new \nAbstract: We introduce VertexRegen, a novel mesh generation framework that enables generation at a continuous level of detail. Existing autoregressive methods generate meshes in a partial-to-complete manner and thus intermediate steps of generation represent incomplete structures. VertexRegen takes inspiration from progressive meshes and reformulates the process as the reversal of edge collapse, i.e. vertex split, learned through a generative model. Experimental results demonstrate that VertexRegen produces meshes of comparable quality to state-of-the-art methods while uniquely offering anytime generation with the flexibility to halt at any step to yield valid meshes with varying levels of detail.",
    "source": "arXiv"
  },
  {
    "title": "Meta-learning optimizes predictions of missing links in real-world networks",
    "title_es": "Meta-learning optimizes predictions of missing links in real-world networks",
    "url": "https://arxiv.org/abs/2508.09069",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09069v1 Announce Type: new \nAbstract: Relational data are ubiquitous in real-world data applications, e.g., in social network analysis or biological modeling, but networks are nearly always incompletely observed. The state-of-the-art for predicting missing links in the hard case of a network without node attributes uses model stacking or neural network techniques. It remains unknown which approach is best, and whether or how the best choice of algorithm depends on the input network's characteristics. We answer these questions systematically using a large, structurally diverse benchmark of 550 real-world networks under two standard accuracy measures (AUC and Top-k), comparing four stacking algorithms with 42 topological link predictors, two of which we introduce here, and two graph neural network algorithms. We show that no algorithm is best across all input networks, all algorithms perform well on most social networks, and few perform well on economic and biological networks. Overall, model stacking with a random forest is both highly scalable and surpasses on AUC or is competitive with graph neural networks on Top-k accuracy. But, algorithm performance depends strongly on network characteristics like the degree distribution, triangle density, and degree assortativity. We introduce a meta-learning algorithm that exploits this variability to optimize link predictions for individual networks by selecting the best algorithm to apply, which we show outperforms all state-of-the-art algorithms and scales to large networks.",
    "source": "arXiv"
  },
  {
    "title": "GeoVLA: Empowering 3D Representations in Vision-Language-Action Models",
    "title_es": "GeoVLA: Empowering 3D Representations in Vision-Language-Action Models",
    "url": "https://arxiv.org/abs/2508.09071",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09071v1 Announce Type: new \nAbstract: Vision-Language-Action (VLA) models have emerged as a promising approach for enabling robots to follow language instructions and predict corresponding actions.However, current VLA models mainly rely on 2D visual inputs, neglecting the rich geometric information in the 3D physical world, which limits their spatial awareness and adaptability. In this paper, we present GeoVLA, a novel VLA framework that effectively integrates 3D information to advance robotic manipulation. It uses a vision-language model (VLM) to process images and language instructions,extracting fused vision-language embeddings. In parallel, it converts depth maps into point clouds and employs a customized point encoder, called Point Embedding Network, to generate 3D geometric embeddings independently. These produced embeddings are then concatenated and processed by our proposed spatial-aware action expert, called 3D-enhanced Action Expert, which combines information from different sensor modalities to produce precise action sequences. Through extensive experiments in both simulation and real-world environments, GeoVLA demonstrates superior performance and robustness. It achieves state-of-the-art results in the LIBERO and ManiSkill2 simulation benchmarks and shows remarkable robustness in real-world tasks requiring height adaptability, scale awareness and viewpoint invariance.",
    "source": "arXiv"
  },
  {
    "title": "READER: Retrieval-Assisted Drafter for Efficient LLM Inference",
    "title_es": "READER: Retrieval-Assisted Drafter for Efficient LLM Inference",
    "url": "https://arxiv.org/abs/2508.09072",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09072v1 Announce Type: new \nAbstract: Large Language Models (LLMs) generate tokens autoregressively, with each token depending on the preceding context. This sequential nature makes the inference process inherently difficult to accelerate, posing a significant challenge for efficient deployment. In recent years, various methods have been proposed to address this issue, with the most effective approaches often involving the training of additional draft models. In this paper, we introduce READER (Retrieval-Assisted Drafter for Efficient LLM Inference), a novel lossless speculative decoding method that enhances model-based approaches by leveraging self-repetitions in the text. Our algorithm expands the speculative decoding tree using tokens obtained through statistical search. This work focuses on large batch sizes (>= 8), an underexplored yet important area for industrial applications. We also analyze the key-value (KV) cache size during speculative decoding and propose an optimization to improve performance for large batches. As a result, READER outperforms existing speculative decoding methods. Notably, READER requires no additional training and can reuse pre-trained speculator models, increasing the speedup by over 40\\%. Our method demonstrates particularly strong performance on search-based tasks, such as retrieval-augmented generation, where we achieve more than 10x speedup.",
    "source": "arXiv"
  },
  {
    "title": "CPO: Addressing Reward Ambiguity in Role-playing Dialogue via Comparative Policy Optimization",
    "title_es": "CPO: Addressing Reward Ambiguity in Role-playing Dialogue via Comparative Policy Optimization",
    "url": "https://arxiv.org/abs/2508.09074",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09074v1 Announce Type: new \nAbstract: Reinforcement Learning Fine-Tuning (RLFT) has achieved notable success in tasks with objectively verifiable answers (e.g., code generation, mathematical reasoning), yet struggles with open-ended subjective tasks like role-playing dialogue. Traditional reward modeling approaches, which rely on independent sample-wise scoring, face dual challenges: subjective evaluation criteria and unstable reward signals.Motivated by the insight that human evaluation inherently combines explicit criteria with implicit comparative judgments, we propose Comparative Policy Optimization (CPO). CPO redefines the reward evaluation paradigm by shifting from sample-wise scoring to comparative group-wise scoring.Building on the same principle, we introduce the CharacterArena evaluation framework, which comprises two stages:(1) Contextualized Multi-turn Role-playing Simulation, and (2) Trajectory-level Comparative Evaluation. By operationalizing subjective scoring via objective trajectory comparisons, CharacterArena minimizes contextual bias and enables more robust and fair performance evaluation. Empirical results on CharacterEval, CharacterBench, and CharacterArena confirm that CPO effectively mitigates reward ambiguity and leads to substantial improvements in dialogue quality.",
    "source": "arXiv"
  },
  {
    "title": "Scaling Learned Image Compression Models up to 1 Billion",
    "title_es": "Scaling Learned Image Compression Models up to 1 Billion",
    "url": "https://arxiv.org/abs/2508.09075",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09075v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) highlight a strong connection between intelligence and compression. Learned image compression, a fundamental task in modern data compression, has made significant progress in recent years. However, current models remain limited in scale, restricting their representation capacity, and how scaling model size influences compression performance remains unexplored. In this work, we present a pioneering study on scaling up learned image compression models and revealing the performance trends through scaling laws. Using the recent state-of-the-art HPCM model as baseline, we scale model parameters from 68.5 millions to 1 billion and fit power-law relations between test loss and key scaling variables, including model size and optimal training compute. The results reveal a scaling trend, enabling extrapolation to larger scale models. Experimental results demonstrate that the scaled-up HPCM-1B model achieves state-of-the-art rate-distortion performance. We hope this work inspires future exploration of large-scale compression models and deeper investigations into the connection between compression and intelligence.",
    "source": "arXiv"
  },
  {
    "title": "Generalized Bicycle Codes with Low Connectivity: Minimum Distance Bounds and Hook Errors",
    "title_es": "Generalized Bicycle Codes with Low Connectivity: Minimum Distance Bounds and Hook Errors",
    "url": "https://arxiv.org/abs/2508.09082",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09082v1 Announce Type: new \nAbstract: We present new upper and lower bounds on the minimum distance of certain generalized bicycle (GB) codes beyond the reach of techniques for classical codes capable of even capturing the true minimum distance for some cases. These bounds are then applied to illustrate the existence and analyze two highly degenerate GB code families with parameters $[[d^2+1,2,d]]$ for odd $d \\geq 3$ and $[[d^2,2,d]]$ for even $d \\geq 4$, both having the property that each check qubit is connected to exactly four data qubits similar to surface codes. For the odd-distance family, we analyze the structure of low-weight logical Pauli operators and demonstrate the existence of a fault-tolerant logical CNOT gate between the two logical qubits, achievable through a simple relabeling of data qubits. We further construct a syndrome extraction pattern for both families that does not imply minimum distance reduction arising from extraction circuit faults that propagate from the check qubits to the data qubits. Finally, we numerically evaluate their logical error rates under a code capacity depolarizing noise model using the belief propagation ordered statistics decoding (BP-OSD) and minimum-weight perfect-matching (MWPM) decoders, yielding thresholds of approximately $14-16\\%$ for the odd and even families, very similar to those of rotated surface codes.",
    "source": "arXiv"
  },
  {
    "title": "Weighted Proper Orthogonal Decomposition for High-Dimensional Optimization",
    "title_es": "Weighted Proper Orthogonal Decomposition for High-Dimensional Optimization",
    "url": "https://arxiv.org/abs/2508.09084",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09084v1 Announce Type: new \nAbstract: While proper orthogonal decomposition (POD) is widely used for model reduction, its standard form does not take into account any parametric model structure. Extensions to POD have been proposed to address this, but these either require large amounts of solution data, lack online adaptivity, or have limited approximation accuracy. We circumvent these limitations by instead assigning weights to the snapshot matrix columns, and updating these whenever the model is evaluated at a new point in the parameter space. We derive an a posteriori error bound that depends on these snapshot weights, show how these weights can be chosen to tighten the error bound, and present an algorithm to compute the corresponding reduced basis efficiently. We show how this weighted POD approach can be used to naturally generalize the calculation of reduced basis derivatives to situations with multidimensional parameter spaces and snapshots at multiple locations in the parameter space. Lastly, we cover how these approaches can be implemented within an optimization algorithm, without the need for an offline training phase. The proposed weighted POD methods with and without reduced basis derivatives are applied to a gradient-based shell thickness optimization problem with 105 design parameters and a time-dependent partial differential equation. The numerical solutions obtained for this problem attain errors that are several orders of magnitude smaller when using weighted POD than those computed with regular POD and Grassmann manifold interpolation, while having comparable wall times per query and requiring fewer high-dimensional model snapshots to reach an optimal solution.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Uncertainty-aware Multimodal Fusion for Outdoor Health Monitoring",
    "title_es": "Dynamic Uncertainty-aware Multimodal Fusion for Outdoor Health Monitoring",
    "url": "https://arxiv.org/abs/2508.09085",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09085v1 Announce Type: new \nAbstract: Outdoor health monitoring is essential to detect early abnormal health status for safeguarding human health and safety. Conventional outdoor monitoring relies on static multimodal deep learning frameworks, which requires extensive data training from scratch and fails to capture subtle health status changes. Multimodal large language models (MLLMs) emerge as a promising alternative, utilizing only small datasets to fine-tune pre-trained information-rich models for enabling powerful health status monitoring. Unfortunately, MLLM-based outdoor health monitoring also faces significant challenges: I) sensor data contains input noise stemming from sensor data acquisition and fluctuation noise caused by sudden changes in physiological signals due to dynamic outdoor environments, thus degrading the training performance; ii) current transformer based MLLMs struggle to achieve robust multimodal fusion, as they lack a design for fusing the noisy modality; iii) modalities with varying noise levels hinder accurate recovery of missing data from fluctuating distributions. To combat these challenges, we propose an uncertainty-aware multimodal fusion framework, named DUAL-Health, for outdoor health monitoring in dynamic and noisy environments. First, to assess the impact of noise, we accurately quantify modality uncertainty caused by input and fluctuation noise with current and temporal features. Second, to empower efficient muitimodal fusion with low-quality modalities,we customize the fusion weight for each modality based on quantified and calibrated uncertainty. Third, to enhance data recovery from fluctuating noisy modalities, we align modality distributions within a common semantic space. Extensive experiments demonstrate that our DUAL-Health outperforms state-of-the-art baselines in detection accuracy and robustness.",
    "source": "arXiv"
  },
  {
    "title": "Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision",
    "title_es": "Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision",
    "url": "https://arxiv.org/abs/2508.09087",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09087v1 Announce Type: new \nAbstract: Vision-Language Models (VLMs) have achieved remarkable success on multimodal tasks such as image-text retrieval and zero-shot classification, yet they can exhibit demographic biases even when explicit protected attributes are absent during training. In this work, we focus on automated glaucoma screening from retinal fundus images, a critical application given that glaucoma is a leading cause of irreversible blindness and disproportionately affects underserved populations. Building on a reweighting-based contrastive learning framework, we introduce an attribute-agnostic debiasing method that (i) infers proxy subgroups via unsupervised clustering of image-image embeddings, (ii) computes gradient-similarity weights between the CLIP-style multimodal loss and a SimCLR-style image-pair contrastive loss, and (iii) applies these weights in a joint, top-$k$ weighted objective to upweight underperforming clusters. This label-free approach adaptively targets the hardest examples, thereby reducing subgroup disparities. We evaluate our method on the Harvard FairVLMed glaucoma subset, reporting Equalized Odds Distance (EOD), Equalized Subgroup AUC (ES AUC), and Groupwise AUC to demonstrate equitable performance across inferred demographic subgroups.",
    "source": "arXiv"
  },
  {
    "title": "SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system",
    "title_es": "SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system",
    "url": "https://arxiv.org/abs/2508.09090",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09090v1 Announce Type: new \nAbstract: Modeling multi-interests has arisen as a core problem in real-world RS. Current multi-interest retrieval methods pose three major challenges: 1) Interests, typically extracted from predefined external knowledge, are invariant. Failed to dynamically evolve with users' real-time consumption preferences. 2) Online inference typically employs an over-exploited strategy, mainly matching users' existing interests, lacking proactive exploration and discovery of novel and long-tail interests. To address these challenges, we propose a novel retrieval framework named SPARC(Soft Probabilistic Adaptive Retrieval Model via Codebooks). Our contribution is two folds. First, the framework utilizes Residual Quantized Variational Autoencoder (RQ-VAE) to construct a discretized interest space. It achieves joint training of the RQ-VAE with the industrial large scale recommendation model, mining behavior-aware interests that can perceive user feedback and evolve dynamically. Secondly, a probabilistic interest module that predicts the probability distribution over the entire dynamic and discrete interest space. This facilitates an efficient \"soft-search\" strategy during online inference, revolutionizing the retrieval paradigm from \"passive matching\" to \"proactive exploration\" and thereby effectively promoting interest discovery. Online A/B tests on an industrial platform with tens of millions daily active users, have achieved substantial gains in business metrics: +0.9% increase in user view duration, +0.4% increase in user page views (PV), and a +22.7% improvement in PV500(new content reaching 500 PVs in 24 hours). Offline evaluations are conducted on open-source Amazon Product datasets. Metrics, such as Recall@K and Normalized Discounted Cumulative Gain@K(NDCG@K), also showed consistent improvement. Both online and offline experiments validate the efficacy and practical value of the proposed method.",
    "source": "arXiv"
  },
  {
    "title": "Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages",
    "title_es": "Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages",
    "url": "https://arxiv.org/abs/2508.09091",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09091v1 Announce Type: new \nAbstract: Large Language Models (LLMs) excel in English, but their performance degrades significantly on low-resource languages (LRLs) due to English-centric training. While methods like LangBridge align LLMs with multilingual encoders such as the Massively Multilingual Text-to-Text Transfer Transformer (mT5), they typically use only the final encoder layer. We propose a novel architecture that fuses all intermediate layers, enriching the linguistic information passed to the LLM. Our approach features two strategies: (1) a Global Softmax weighting for overall layer importance, and (2) a Transformer Softmax model that learns token-specific weights. The fused representations are mapped into the LLM's embedding space, enabling it to process multilingual inputs. The model is trained only on English data, without using any parallel or multilingual data. Evaluated on XNLI, IndicXNLI, Sinhala News Classification, and Amazon Reviews, our Transformer Softmax model significantly outperforms the LangBridge baseline. We observe strong performance gains in LRLs, improving Sinhala classification accuracy from 71.66% to 75.86% and achieving clear improvements across Indic languages such as Tamil, Bengali, and Malayalam. These specific gains contribute to an overall boost in average XNLI accuracy from 70.36% to 71.50%. This approach offers a scalable, data-efficient path toward more capable and equitable multilingual LLMs.",
    "source": "arXiv"
  },
  {
    "title": "Scaling Up Active Testing to Large Language Models",
    "title_es": "Scaling Up Active Testing to Large Language Models",
    "url": "https://arxiv.org/abs/2508.09093",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09093v1 Announce Type: new \nAbstract: Active testing enables label-efficient evaluation of models through careful data acquisition. However, its significant computational costs have previously undermined its use for large models. We show how it can be successfully scaled up to the evaluation of large language models (LLMs). In particular we show that the surrogate model used to guide data acquisition can be constructed cheaply using in-context learning, does not require updating within an active-testing loop, and can be smaller than the target model. We even find we can make good data-acquisition decisions without computing predictions with the target model and further introduce a single-run error estimator to asses how well active testing is working on the fly. We find that our approach is able to more effectively evaluate LLM performance with less data than current standard practices.",
    "source": "arXiv"
  },
  {
    "title": "Deep Learning Models for Robust Facial Liveness Detection",
    "title_es": "Deep Learning Models for Robust Facial Liveness Detection",
    "url": "https://arxiv.org/abs/2508.09094",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09094v1 Announce Type: new \nAbstract: In the rapidly evolving landscape of digital security, biometric authentication systems, particularly facial recognition, have emerged as integral components of various security protocols. However, the reliability of these systems is compromised by sophisticated spoofing attacks, where imposters gain unauthorized access by falsifying biometric traits. Current literature reveals a concerning gap: existing liveness detection methodologies - designed to counteract these breaches - fall short against advanced spoofing tactics employing deepfakes and other artificial intelligence-driven manipulations. This study introduces a robust solution through novel deep learning models addressing the deficiencies in contemporary anti-spoofing techniques. By innovatively integrating texture analysis and reflective properties associated with genuine human traits, our models distinguish authentic presence from replicas with remarkable precision. Extensive evaluations were conducted across five diverse datasets, encompassing a wide range of attack vectors and environmental conditions. Results demonstrate substantial advancement over existing systems, with our best model (AttackNet V2.2) achieving 99.9% average accuracy when trained on combined data. Moreover, our research unveils critical insights into the behavioral patterns of impostor attacks, contributing to a more nuanced understanding of their evolving nature. The implications are profound: our models do not merely fortify the authentication processes but also instill confidence in biometric systems across various sectors reliant on secure access.",
    "source": "arXiv"
  },
  {
    "title": "Link Prediction for Event Logs in the Process Industry",
    "title_es": "Link Prediction for Event Logs in the Process Industry",
    "url": "https://arxiv.org/abs/2508.09096",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09096v1 Announce Type: new \nAbstract: Knowledge management (KM) is vital in the process industry for optimizing operations, ensuring safety, and enabling continuous improvement through effective use of operational data and past insights. A key challenge in this domain is the fragmented nature of event logs in shift books, where related records, e.g., entries documenting issues related to equipment or processes and the corresponding solutions, may remain disconnected. This fragmentation hinders the recommendation of previous solutions to the users. To address this problem, we investigate record linking (RL) as link prediction, commonly studied in graph-based machine learning, by framing it as a cross-document coreference resolution (CDCR) task enhanced with natural language inference (NLI) and semantic text similarity (STS) by shifting it into the causal inference (CI). We adapt CDCR, traditionally applied in the news domain, into an RL model to operate at the passage level, similar to NLI and STS, while accommodating the process industry's specific text formats, which contain unstructured text and structured record attributes. Our RL model outperformed the best versions of NLI- and STS-driven baselines by 28% (11.43 points) and 27% (11.21 points), respectively. Our work demonstrates how domain adaptation of the state-of-the-art CDCR models, enhanced with reasoning capabilities, can be effectively tailored to the process industry, improving data quality and connectivity in shift logs.",
    "source": "arXiv"
  },
  {
    "title": "Chi-Geometry: A Library for Benchmarking Chirality Prediction of GNNs",
    "title_es": "Chi-Geometry: A Library for Benchmarking Chirality Prediction of GNNs",
    "url": "https://arxiv.org/abs/2508.09097",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09097v1 Announce Type: new \nAbstract: We introduce Chi-Geometry - a library that generates graph data for testing and benchmarking GNNs' ability to predict chirality. Chi-Geometry generates synthetic graph samples with (i) user-specified geometric and topological traits to isolate certain types of samples and (ii) randomized node positions and species to minimize extraneous correlations. Each generated graph contains exactly one chiral center labeled either R or S, while all other nodes are labeled N/A (non-chiral). The generated samples are then combined into a cohesive dataset that can be used to assess a GNN's ability to predict chirality as a node classification task. Chi-Geometry allows more interpretable and less confounding benchmarking of GNNs for prediction of chirality in the graph samples which can guide the design of new GNN architectures with improved predictive performance. We illustrate Chi-Geometry's efficacy by using it to generate synthetic datasets for benchmarking various state-of-the-art (SOTA) GNN architectures. The conclusions of these benchmarking results guided our design of two new GNN architectures. The first GNN architecture established all-to-all connections in the graph to accurately predict chirality across all challenging configurations where previously tested SOTA models failed, but at a computational cost (both for training and inference) that grows quadratically with the number of graph nodes. The second GNN architecture avoids all-to-all connections by introducing a virtual node in the original graph structure of the data, which restores the linear scaling of training and inference computational cost with respect to the number of nodes in the graph, while still ensuring competitive accuracy in detecting chirality with respect to SOTA GNN architectures.",
    "source": "arXiv"
  },
  {
    "title": "Bridging Formal Language with Chain-of-Thought Reasoning to Geometry Problem Solving",
    "title_es": "Bridging Formal Language with Chain-of-Thought Reasoning to Geometry Problem Solving",
    "url": "https://arxiv.org/abs/2508.09099",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09099v1 Announce Type: new \nAbstract: Large vision language models exhibit notable limitations on Geometry Problem Solving (GPS) because of their unreliable diagram interpretation and pure natural-language reasoning. A recent line of work mitigates this by using symbolic solvers: the model directly generates a formal program that a geometry solver can execute. However, this direct program generation lacks intermediate reasoning, making the decision process opaque and prone to errors. In this work, we explore a new approach that integrates Chain-of-Thought (CoT) with formal language. The model interleaves natural language reasoning with incremental emission of solver-executable code, producing a hybrid reasoning trace in which critical derivations are expressed in formal language. To teach this behavior at scale, we combine (1) supervised fine-tuning on an 11K newly developed synthetic dataset with interleaved natural language reasoning and automatic formalization, and (2) solver-in-the-loop reinforcement learning that jointly optimizes both the CoT narrative and the resulting program through outcome-based rewards. Built on Qwen2.5-VL-7B, our new model, named GF-Reasoner, achieves up to 15% accuracy improvements on standard GPS benchmarks, surpassing both 7B-scale peers and the much larger model Qwen2.5-VL-72B. By exploiting high-order geometric knowledge and offloading symbolic computation to the solver, the generated reasoning traces are noticeably shorter and cleaner. Furthermore, we present a comprehensive analysis of method design choices (e.g., reasoning paradigms, data synthesis, training epochs, etc.), providing actionable insights for future research.",
    "source": "arXiv"
  },
  {
    "title": "Towards Universal Neural Inference",
    "title_es": "Towards Universal Neural Inference",
    "url": "https://arxiv.org/abs/2508.09100",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09100v1 Announce Type: new \nAbstract: Real-world data often appears in diverse, disjoint forms -- with varying schemas, inconsistent semantics, and no fixed feature ordering -- making it challenging to build general-purpose models that can leverage information across datasets. We introduce ASPIRE, Arbitrary Set-based Permutation-Invariant Reasoning Engine, a Universal Neural Inference model for semantic reasoning and prediction over heterogeneous structured data. ASPIRE combines a permutation-invariant, set-based Transformer with a semantic grounding module that incorporates natural language descriptions, dataset metadata, and in-context examples to learn cross-dataset feature dependencies. This architecture allows ASPIRE to ingest arbitrary sets of feature--value pairs and support examples, align semantics across disjoint tables, and make predictions for any specified target. Once trained, ASPIRE generalizes to new inference tasks without additional tuning. In addition to delivering strong results across diverse benchmarks, ASPIRE naturally supports cost-aware active feature acquisition in an open-world setting, selecting informative features under test-time budget constraints for an arbitrary unseen dataset. These capabilities position ASPIRE as a step toward truly universal, semantics-aware inference over structured data.",
    "source": "arXiv"
  },
  {
    "title": "AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators",
    "title_es": "AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators",
    "url": "https://arxiv.org/abs/2508.09101",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09101v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, with code generation emerging as a key area of focus. While numerous benchmarks have been proposed to evaluate their code generation abilities, these benchmarks face several critical limitations. First, they often rely on manual annotations, which are time-consuming and difficult to scale across different programming languages and problem complexities. Second, most existing benchmarks focus primarily on Python, while the few multilingual benchmarks suffer from limited difficulty and uneven language distribution. To address these challenges, we propose AutoCodeGen, an automated method for generating high-difficulty multilingual code generation datasets without manual annotations. AutoCodeGen ensures the correctness and completeness of test cases by generating test inputs with LLMs and obtaining test outputs through a multilingual sandbox, while achieving high data quality through reverse-order problem generation and multiple filtering steps. Using this novel method, we introduce AutoCodeBench, a large-scale code generation benchmark comprising 3,920 problems evenly distributed across 20 programming languages. It is specifically designed to evaluate LLMs on challenging, diverse, and practical multilingual tasks. We evaluate over 30 leading open-source and proprietary LLMs on AutoCodeBench and its simplified version AutoCodeBench-Lite. The results show that even the most advanced LLMs struggle with the complexity, diversity, and multilingual nature of these tasks. Besides, we introduce AutoCodeBench-Complete, specifically designed for base models to assess their few-shot code generation capabilities. We hope the AutoCodeBench series will serve as a valuable resource and inspire the community to focus on more challenging and practical multilingual code generation scenarios.",
    "source": "arXiv"
  },
  {
    "title": "SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling",
    "title_es": "SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling",
    "url": "https://arxiv.org/abs/2508.09105",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09105v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented Generation (MRAG) significantly improve the knowledge coverage and contextual understanding of Large Language Models (LLMs) by introducing external knowledge sources. However, retrieval and multimodal fusion obscure content provenance, rendering existing membership inference methods unable to reliably attribute generated outputs to pre-training, external retrieval, or user input, thus undermining privacy leakage accountability\n  To address these challenges, we propose the first Source-aware Membership Audit (SMA) that enables fine-grained source attribution of generated content in a semi-black-box setting with retrieval control capabilities.To address the environmental constraints of semi-black-box auditing, we further design an attribution estimation mechanism based on zero-order optimization, which robustly approximates the true influence of input tokens on the output through large-scale perturbation sampling and ridge regression modeling. In addition, SMA introduces a cross-modal attribution technique that projects image inputs into textual descriptions via MLLMs, enabling token-level attribution in the text modality, which for the first time facilitates membership inference on image retrieval traces in MRAG systems. This work shifts the focus of membership inference from 'whether the data has been memorized' to 'where the content is sourced from', offering a novel perspective for auditing data provenance in complex generative systems.",
    "source": "arXiv"
  },
  {
    "title": "Smart Residential Community Simulator for Developing and Benchmarking Energy Management Systems",
    "title_es": "Smart Residential Community Simulator for Developing and Benchmarking Energy Management Systems",
    "url": "https://arxiv.org/abs/2508.09106",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09106v1 Announce Type: new \nAbstract: Home Energy Management Systems (HEMS) are being actively developed for both individual houses and communities to support demand response in on-grid operation, and ensure resilience during off-grid scenarios. However, most simulators used for closed-loop HEMS testing are tailored to a specific distributed energy resource (DER) configuration with a fixed number of houses, limiting flexibility and scalability. This leads to additional development efforts to support diverse DER configurations across any number of houses and to integrate appropriate weather and load data pipelines. To address these limitations, we present a scalable simulator capable of modeling any number of houses in both on-grid and off-grid modes as a Gymnasium environment. Each house can have a unique DER configuration - Rooftop Solar Photovoltaics (PV), Battery-only, PV-only, or no DER - and includes models for air-conditioning and eight grouped circuit-level loads. The simulator integrates National Solar Radiation Database (NSRDB) weather and Pecan Street load datasets, supports three default controllers (two for off-grid, and one for on-grid scenarios), and includes performance metrics and visualization tools. We demonstrate its flexibility through simulations on individual houses and a four-house community with heterogeneous DERs, benchmarking the controllers across built-in metrics and computation time. The results highlight the simulator's capability to systematically evaluate control policy performance under varying system configurations.",
    "source": "arXiv"
  },
  {
    "title": "SinLlama - A Large Language Model for Sinhala",
    "title_es": "SinLlama - A Large Language Model for Sinhala",
    "url": "https://arxiv.org/abs/2508.09115",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09115v1 Announce Type: new \nAbstract: Low-resource languages such as Sinhala are often overlooked by open-source Large Language Models (LLMs). In this research, we extend an existing multilingual LLM (Llama-3-8B) to better serve Sinhala. We enhance the LLM tokenizer with Sinhala specific vocabulary and perform continual pre-training on a cleaned 10 million Sinhala corpus, resulting in the SinLlama model. This is the very first decoder-based open-source LLM with explicit Sinhala support. When SinLlama was instruction fine-tuned for three text classification tasks, it outperformed base and instruct variants of Llama-3-8B by a significant margin.",
    "source": "arXiv"
  },
  {
    "title": "Deep Neural Network Calibration by Reducing Classifier Shift with Stochastic Masking",
    "title_es": "Deep Neural Network Calibration by Reducing Classifier Shift with Stochastic Masking",
    "url": "https://arxiv.org/abs/2508.09116",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09116v1 Announce Type: new \nAbstract: In recent years, deep neural networks (DNNs) have shown competitive results in many fields. Despite this success, they often suffer from poor calibration, especially in safety-critical scenarios such as autonomous driving and healthcare, where unreliable confidence estimates can lead to serious consequences. Recent studies have focused on improving calibration by modifying the classifier, yet such efforts remain limited. Moreover, most existing approaches overlook calibration errors caused by underconfidence, which can be equally detrimental. To address these challenges, we propose MaC-Cal, a novel mask-based classifier calibration method that leverages stochastic sparsity to enhance the alignment between confidence and accuracy. MaC-Cal adopts a two-stage training scheme with adaptive sparsity, dynamically adjusting mask retention rates based on the deviation between confidence and accuracy. Extensive experiments show that MaC-Cal achieves superior calibration performance and robustness under data corruption, offering a practical and effective solution for reliable confidence estimation in DNNs.",
    "source": "arXiv"
  },
  {
    "title": "Comparing Building Thermal Dynamics Models and Estimation Methods for Grid-Edge Applications",
    "title_es": "Comparing Building Thermal Dynamics Models and Estimation Methods for Grid-Edge Applications",
    "url": "https://arxiv.org/abs/2508.09118",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09118v1 Announce Type: new \nAbstract: We need computationally efficient and accurate building thermal dynamics models for use in grid-edge applications. This work evaluates two grey-box approaches for modeling building thermal dynamics: RC-network models and structured regression models. For RC-network models, we compare parameter estimation methods including Nonlinear Least Squares, Batch Estimation, and Maximum Likelihood Estimation. We use the Almon Lag Structure with Linear Least Squares for estimating the structured regression models. The performance of these models and methods is evaluated on simulated house and commercial building data across three different simulation types.",
    "source": "arXiv"
  },
  {
    "title": "OpenCUA: Open Foundations for Computer-Use Agents",
    "title_es": "OpenCUA: Open Foundations for Computer-Use Agents",
    "url": "https://arxiv.org/abs/2508.09123",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09123v1 Announce Type: new \nAbstract: Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.",
    "source": "arXiv"
  },
  {
    "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows",
    "title_es": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows",
    "url": "https://arxiv.org/abs/2508.09124",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09124v1 Announce Type: new \nAbstract: Autonomous agents powered by large language models (LLMs) are increasingly deployed in real-world applications requiring complex, long-horizon workflows. However, existing benchmarks predominantly focus on atomic tasks that are self-contained and independent, failing to capture the long-term contextual dependencies and multi-interaction coordination required in realistic scenarios. To address this gap, we introduce OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications including Word, Excel, PDF, Email, and Calendar. Our benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks derived from real-world use cases, and OdysseyBench-Neo with 302 newly synthesized complex tasks. Each task requires agent to identify essential information from long-horizon interaction histories and perform multi-step reasoning across various applications. To enable scalable benchmark creation, we propose HomerAgents, a multi-agent framework that automates the generation of long-horizon workflow benchmarks through systematic environment exploration, task generation, and dialogue synthesis. Our extensive evaluation demonstrates that OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks. We believe that OdysseyBench will serve as a valuable resource for advancing the development and evaluation of LLM agents in real-world productivity scenarios. In addition, we release OdysseyBench and HomerAgents to foster research along this line.",
    "source": "arXiv"
  },
  {
    "title": "Complex Logical Instruction Generation",
    "title_es": "Complex Logical Instruction Generation",
    "url": "https://arxiv.org/abs/2508.09125",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09125v1 Announce Type: new \nAbstract: Instruction following has catalyzed the recent era of Large Language Models (LLMs) and is the foundational skill underpinning more advanced capabilities such as reasoning and agentic behaviors. As tasks grow more challenging, the logic structures embedded in natural language instructions becomes increasingly intricate. However, how well LLMs perform on such logic-rich instructions remains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a scalable, automated framework for generating verifiable instructions from code functions, which can naturally express rich logic such as conditionals, nesting, recursion, and function calls. We further curate a collection of complex code functions and use LogicIFGen to construct LogicIFEval, a benchmark comprising 426 verifiable logic-rich instructions. Our experiments demonstrate that current state-of-the-art LLMs still struggle to correctly follow the instructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the instructions, revealing significant deficiencies in the instruction-following ability. Code and Benchmark: https://github.com/mianzhang/LogicIF",
    "source": "arXiv"
  },
  {
    "title": "Neutone SDK: An Open Source Framework for Neural Audio Processing",
    "title_es": "Neutone SDK: An Open Source Framework for Neural Audio Processing",
    "url": "https://arxiv.org/abs/2508.09126",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09126v1 Announce Type: new \nAbstract: Neural audio processing has unlocked novel methods of sound transformation and synthesis, yet integrating deep learning models into digital audio workstations (DAWs) remains challenging due to real-time / neural network inference constraints and the complexities of plugin development. In this paper, we introduce the Neutone SDK: an open source framework that streamlines the deployment of PyTorch-based neural audio models for both real-time and offline applications. By encapsulating common challenges such as variable buffer sizes, sample rate conversion, delay compensation, and control parameter handling within a unified, model-agnostic interface, our framework enables seamless interoperability between neural models and host plugins while allowing users to work entirely in Python. We provide a technical overview of the interfaces needed to accomplish this, as well as the corresponding SDK implementations. We also demonstrate the SDK's versatility across applications such as audio effect emulation, timbre transfer, and sample generation, as well as its adoption by researchers, educators, companies, and artists alike. The Neutone SDK is available at https://github.com/Neutone/neutone_sdk",
    "source": "arXiv"
  },
  {
    "title": "A Review On Safe Reinforcement Learning Using Lyapunov and Barrier Functions",
    "title_es": "A Review On Safe Reinforcement Learning Using Lyapunov and Barrier Functions",
    "url": "https://arxiv.org/abs/2508.09128",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09128v1 Announce Type: new \nAbstract: Reinforcement learning (RL) has proven to be particularly effective in solving complex decision-making problems for a wide range of applications. From a control theory perspective, RL can be considered as an adaptive optimal control scheme. Lyapunov and barrier functions are the most commonly used certificates to guarantee system stability for a proposed/derived controller and constraint satisfaction guarantees, respectively, in control theoretic approaches. However, compared to theoretical guarantees available in control theoretic methods, RL lacks closed-loop stability of a computed policy and constraint satisfaction guarantees. Safe reinforcement learning refers to a class of constrained problems where the constraint violations lead to partial or complete system failure. The goal of this review is to provide an overview of safe RL techniques using Lyapunov and barrier functions to guarantee this notion of safety discussed (stability of the system in terms of a computed policy and constraint satisfaction during training and deployment). The different approaches employed are discussed in detail along with their shortcomings and benefits to provide critique and possible future research directions. Key motivation for this review is to discuss current theoretical approaches for safety and stability guarantees in RL similar to control theoretic approaches using Lyapunov and barrier functions. The review provides proven potential and promising scope of providing safety guarantees for complex dynamical systems with operational constraints using model-based and model-free RL.",
    "source": "arXiv"
  },
  {
    "title": "BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair",
    "title_es": "BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair",
    "url": "https://arxiv.org/abs/2508.09129",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09129v1 Announce Type: new \nAbstract: Effective information seeking in the vast and ever-growing digital landscape requires balancing expansive search with strategic reasoning. Current large language model (LLM)-based agents struggle to achieve this balance due to limitations in search breadth and reasoning depth, where slow, serial querying restricts coverage of relevant sources and noisy raw inputs disrupt the continuity of multi-step reasoning. To address these challenges, we propose BrowseMaster, a scalable framework built around a programmatically augmented planner-executor agent pair. The planner formulates and adapts search strategies based on task constraints, while the executor conducts efficient, targeted retrieval to supply the planner with concise, relevant evidence. This division of labor preserves coherent, long-horizon reasoning while sustaining broad and systematic exploration, overcoming the trade-off that limits existing agents. Extensive experiments on challenging English and Chinese benchmarks show that BrowseMaster consistently outperforms open-source and proprietary baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh, which demonstrates its strong capability in complex, reasoning-heavy information-seeking tasks at scale.",
    "source": "arXiv"
  },
  {
    "title": "An Open-Source Simulation and Data Management Tool for EnergyPlus Building Models",
    "title_es": "An Open-Source Simulation and Data Management Tool for EnergyPlus Building Models",
    "url": "https://arxiv.org/abs/2508.09130",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09130v1 Announce Type: new \nAbstract: We present a new open-source, GUI-based application created using Plotly-Dash, along with an integrated PostgreSQL-based relational database, developed to streamline EnergyPlus building model simulation workflows. The application facilitates data generation, aggregation (across thermal zones), and visualization based on customizable user preferences, while the database efficiently stores and retrieves complex simulation data generated by EnergyPlus. We demonstrate the need for this application and database, emphasizing how existing approaches for generating, managing, and analyzing EnergyPlus simulation data can be cumbersome, particularly when handling a large number of building models with varying simulation setups. This integrated framework enables building energy engineers and researchers to simplify their EnergyPlus simulations, manage generated simulation data, perform data analyses, and support data-driven modeling tasks.",
    "source": "arXiv"
  },
  {
    "title": "Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer",
    "title_es": "Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer",
    "url": "https://arxiv.org/abs/2508.09131",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09131v1 Announce Type: new \nAbstract: Text-guided color editing in images and videos is a fundamental yet unsolved problem, requiring fine-grained manipulation of color attributes, including albedo, light source color, and ambient lighting, while preserving physical consistency in geometry, material properties, and light-matter interactions. Existing training-free methods offer broad applicability across editing tasks but struggle with precise color control and often introduce visual inconsistency in both edited and non-edited regions. In this work, we present ColorCtrl, a training-free color editing method that leverages the attention mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By disentangling structure and color through targeted manipulation of attention maps and value tokens, our method enables accurate and consistent color editing, along with word-level control of attribute intensity. Our method modifies only the intended regions specified by the prompt, leaving unrelated areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate that ColorCtrl outperforms existing training-free approaches and achieves state-of-the-art performances in both edit quality and consistency. Furthermore, our method surpasses strong commercial models such as FLUX.1 Kontext Max and GPT-4o Image Generation in terms of consistency. When extended to video models like CogVideoX, our approach exhibits greater advantages, particularly in maintaining temporal coherence and editing stability. Finally, our method also generalizes to instruction-based editing diffusion models such as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.",
    "source": "arXiv"
  },
  {
    "title": "Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices",
    "title_es": "Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices",
    "url": "https://arxiv.org/abs/2508.09136",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09136v1 Announce Type: new \nAbstract: There is a growing demand for deploying large generative AI models on mobile devices. For recent popular video generative models, however, the Variational AutoEncoder (VAE) represents one of the major computational bottlenecks. Both large parameter sizes and mismatched kernels cause out-of-memory errors or extremely slow inference on mobile devices. To address this, we propose a low-cost solution that efficiently transfers widely used video VAEs to mobile devices. (1) We analyze redundancy in existing VAE architectures and get empirical design insights. By integrating 3D depthwise separable convolutions into our model, we significantly reduce the number of parameters. (2) We observe that the upsampling techniques in mainstream video VAEs are poorly suited to mobile hardware and form the main bottleneck. In response, we propose a decoupled 3D pixel shuffle scheme that slashes end-to-end delay. Building upon these, we develop a universal mobile-oriented VAE decoder, Turbo-VAED. (3) We propose an efficient VAE decoder training method. Since only the decoder is used during deployment, we distill it to Turbo-VAED instead of retraining the full VAE, enabling fast mobile adaptation with minimal performance loss. To our knowledge, our method enables real-time 720p video VAE decoding on mobile devices for the first time. This approach is widely applicable to most video VAEs. When integrated into four representative models, with training cost as low as $95, it accelerates original VAEs by up to 84.5x at 720p resolution on GPUs, uses as low as 17.5% of original parameter count, and retains 96.9% of the original reconstruction quality. Compared to mobile-optimized VAEs, Turbo-VAED achieves a 2.9x speedup in FPS and better reconstruction quality on the iPhone 16 Pro. The code and models will soon be available at https://github.com/hustvl/Turbo-VAED.",
    "source": "arXiv"
  },
  {
    "title": "HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis",
    "title_es": "HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis",
    "url": "https://arxiv.org/abs/2508.09137",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09137v1 Announce Type: new \nAbstract: Simultaneous relighting and novel-view rendering of digital human representations is an important yet challenging task with numerous applications. Progress in this area has been significantly limited due to the lack of publicly available, high-quality datasets, especially for full-body human captures. To address this critical gap, we introduce the HumanOLAT dataset, the first publicly accessible large-scale dataset of multi-view One-Light-at-a-Time (OLAT) captures of full-body humans. The dataset includes HDR RGB frames under various illuminations, such as white light, environment maps, color gradients and fine-grained OLAT illuminations. Our evaluations of state-of-the-art relighting and novel-view synthesis methods underscore both the dataset's value and the significant challenges still present in modeling complex human-centric appearance and lighting interactions. We believe HumanOLAT will significantly facilitate future research, enabling rigorous benchmarking and advancements in both general and human-specific relighting and rendering techniques.",
    "source": "arXiv"
  },
  {
    "title": "Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models",
    "title_es": "Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models",
    "url": "https://arxiv.org/abs/2508.09138",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09138v1 Announce Type: new \nAbstract: Diffusion large language models (dLLMs) generate text through iterative denoising, yet current decoding strategies discard rich intermediate predictions in favor of the final output. Our work here reveals a critical phenomenon, temporal oscillation, where correct answers often emerge in the middle process, but are overwritten in later denoising steps. To address this issue, we introduce two complementary methods that exploit temporal consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time decoding strategy that aggregates predictions across denoising steps to select the most consistent output; and 2) a post-training method termed Temporal Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a measure of semantic stability across intermediate predictions, as a reward signal to encourage stable generations. Empirical results across multiple benchmarks demonstrate the effectiveness of our approach. Using the negative TSE reward alone, we observe a remarkable average improvement of 24.7% on the Countdown dataset over an existing dLLM. Combined with the accuracy reward, we achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and 25.3% on Countdown, respectively. Our findings underscore the untapped potential of temporal dynamics in dLLMs and offer two simple yet effective tools to harness them.",
    "source": "arXiv"
  },
  {
    "title": "A New Parallel Cooperative Landscape Smoothing Algorithm and Its Applications on TSP and UBQP",
    "title_es": "A New Parallel Cooperative Landscape Smoothing Algorithm and Its Applications on TSP and UBQP",
    "url": "https://arxiv.org/abs/2401.03237",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2401.03237v2 Announce Type: cross \nAbstract: Combinatorial optimization problem (COP) is difficult to solve because of the massive number of local optimal solutions in his solution space. Various methods have been put forward to smooth the solution space of COPs, including homotopic convex (HC) transformation for the traveling salesman problem (TSP). This paper extends the HC transformation approach to unconstrained binary quadratic programming (UBQP) by proposing a method to construct a unimodal toy UBQP of any size. We theoretically prove the unimodality of the constructed toy UBQP. After that, we apply this unimodal toy UBQP to smooth the original UBQP by using the HC transformation framework and empirically verify the smoothing effects. Subsequently, we introduce an iterative algorithmic framework incorporating HC transformation, referred as landscape smoothing iterated local search (LSILS). Our experimental analyses, conducted on various UBQP instances show the effectiveness of LSILS. Furthermore, this paper proposes a parallel cooperative variant of LSILS, denoted as PC-LSILS and apply it to both the UBQP and the TSP. Our experimental findings highlight that PC-LSILS improves the smoothing performance of the HC transformation, and further improves the overall performance of the algorithm.",
    "source": "arXiv"
  },
  {
    "title": "On the Effects of Smoothing Rugged Landscape by Different Toy Problems: A Case Study on UBQP",
    "title_es": "On the Effects of Smoothing Rugged Landscape by Different Toy Problems: A Case Study on UBQP",
    "url": "https://arxiv.org/abs/2407.19676",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2407.19676v1 Announce Type: cross \nAbstract: The hardness of the Unconstrained Binary Quadratic Program (UBQP) problem is due its rugged landscape. Various algorithms have been proposed for UBQP, including the Landscape Smoothing Iterated Local Search (LSILS). Different from other UBQP algorithms, LSILS tries to smooth the rugged landscape by building a convex combination of the original UBQP and a toy UBQP. In this paper, our study further investigates the impact of smoothing rugged landscapes using different toy UBQP problems, including a toy UBQP with matrix ^Q1 (construct by \"+/-1\"), a toy UBQP with matrix ^Q2 (construct by \"+/-i\") and a toy UBQP with matrix ^Q3 (construct randomly). We first assess the landscape flatness of the three toy UBQPs. Subsequently, we test the efficiency of LSILS with different toy UBQPs. Results reveal that the toy UBQP with ^Q1 (construct by \"+/-1\") exhibits the flattest landscape among the three, while the toy UBQP with ^Q3 (construct randomly) presents the most non-flat landscape. Notably, LSILS using the toy UBQP with ^Q2 (construct by \"+/-i\") emerges as the most effective, while ^Q3 (construct randomly) has the poorest result. These findings contribute to a detailed understanding of landscape smoothing techniques in optimizing UBQP.",
    "source": "arXiv"
  },
  {
    "title": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning",
    "title_es": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning",
    "url": "https://arxiv.org/abs/2508.07292",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07292v1 Announce Type: cross \nAbstract: Developing general artificial intelligence (AI) systems to support endoscopic image diagnosis is an emerging research priority. Existing methods based on large-scale pretraining often lack unified coordination across tasks and struggle to handle the multi-step processes required in complex clinical workflows. While AI agents have shown promise in flexible instruction parsing and tool integration across domains, their potential in endoscopy remains underexplored. To address this gap, we propose EndoAgent, the first memory-guided agent for vision-to-decision endoscopic analysis that integrates iterative reasoning with adaptive tool selection and collaboration. Built on a dual-memory design, it enables sophisticated decision-making by ensuring logical coherence through short-term action tracking and progressively enhancing reasoning acuity through long-term experiential learning. To support diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools within a unified reasoning loop. We further introduce EndoAgentBench, a benchmark of 5,709 visual question-answer pairs that assess visual understanding and language generation capabilities in realistic scenarios. Extensive experiments show that EndoAgent consistently outperforms both general and medical multimodal models, exhibiting its strong flexibility and reasoning capabilities.",
    "source": "arXiv"
  },
  {
    "title": "Obfuscated Quantum and Post-Quantum Cryptography",
    "title_es": "Obfuscated Quantum and Post-Quantum Cryptography",
    "url": "https://arxiv.org/abs/2508.07635",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07635v1 Announce Type: cross \nAbstract: In this work, we present an experimental deployment of a new design for combined quantum key distribution (QKD) and post-quantum cryptography (PQC). Novel to our system is the dynamic obfuscation of the QKD-PQC sequence of operations, the number of operations, and parameters related to the operations; coupled to the integration of a GPS-free quantum synchronization protocol within the QKD process. We compare the performance and overhead of our QKD-PQC system relative to a standard QKD system with one-time pad encryption, demonstrating that our design can operate in real time with little additional overhead caused by the new security features. Since our system can offer additional defensive strategies against a wide spectrum of practical attacks that undermine deployed QKD, PQC, and certain combinations of these two primitives, we suggest that our design represents one of the most secure communication systems currently available. Given the dynamic nature of its obfuscation attributes, our new system can also be adapted in the field to defeat yet-to-be-discovered practical attacks.",
    "source": "arXiv"
  },
  {
    "title": "Symplectification of Circular Arcs and Arc Splines",
    "title_es": "Symplectification of Circular Arcs and Arc Splines",
    "url": "https://arxiv.org/abs/2508.07726",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07726v1 Announce Type: cross \nAbstract: In this article, circular arcs are considered both individually and as elements of a piecewise circular curve. The endpoint parameterization proves to be quite advantageous here. The perspective of symplectic geometry provides new vectorial relationships for the circular arc. Curves are considered whose neighboring circular elements each have a common end point or, in addition, a common tangent. These arc splines prove to be a one-parameter curve family, whereby this parameter can be optimized with regard to various criteria.",
    "source": "arXiv"
  },
  {
    "title": "Where is the Boundary: Multimodal Sensor Fusion Test Bench for Tissue Boundary Delineation",
    "title_es": "Where is the Boundary: Multimodal Sensor Fusion Test Bench for Tissue Boundary Delineation",
    "url": "https://arxiv.org/abs/2508.08257",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08257v1 Announce Type: cross \nAbstract: Robot-assisted neurological surgery is receiving growing interest due to the improved dexterity, precision, and control of surgical tools, which results in better patient outcomes. However, such systems often limit surgeons' natural sensory feedback, which is crucial in identifying tissues -- particularly in oncological procedures where distinguishing between healthy and tumorous tissue is vital. While imaging and force sensing have addressed the lack of sensory feedback, limited research has explored multimodal sensing options for accurate tissue boundary delineation. We present a user-friendly, modular test bench designed to evaluate and integrate complementary multimodal sensors for tissue identification. Our proposed system first uses vision-based guidance to estimate boundary locations with visual cues, which are then refined using data acquired by contact microphones and a force sensor. Real-time data acquisition and visualization are supported via an interactive graphical interface. Experimental results demonstrate that multimodal fusion significantly improves material classification accuracy. The platform provides a scalable hardware-software solution for exploring sensor fusion in surgical applications and demonstrates the potential of multimodal approaches in real-time tissue boundary delineation.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating Imputation Techniques for Short-Term Gaps in Heart Rate Data",
    "title_es": "Evaluating Imputation Techniques for Short-Term Gaps in Heart Rate Data",
    "url": "https://arxiv.org/abs/2508.08268",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08268v1 Announce Type: cross \nAbstract: Recent advances in wearable technology have enabled the continuous monitoring of vital physiological signals, essential for predictive modeling and early detection of extreme physiological events. Among these physiological signals, heart rate (HR) plays a central role, as it is widely used in monitoring and managing cardiovascular conditions and detecting extreme physiological events such as hypoglycemia. However, data from wearable devices often suffer from missing values. To address this issue, recent studies have employed various imputation techniques. Traditionally, the effectiveness of these methods has been evaluated using predictive accuracy metrics such as RMSE, MAPE, and MAE, which assess numerical proximity to the original data. While informative, these metrics fail to capture the complex statistical structure inherent in physiological signals. This study bridges this gap by presenting a comprehensive evaluation of four statistical imputation methods, linear interpolation, K Nearest Neighbors (KNN), Piecewise Cubic Hermite Interpolating Polynomial (PCHIP), and B splines, for short term HR data gaps. We assess their performance using both predictive accuracy metrics and statistical distance measures, including the Cohen Distance Test (CDT) and Jensen Shannon Distance (JS Distance), applied to HR data from the D1NAMO dataset and the BIG IDEAs Lab Glycemic Variability and Wearable Device dataset. The analysis reveals limitations in existing imputation approaches and the absence of a robust framework for evaluating imputation quality in physiological signals. Finally, this study proposes a foundational framework to develop a composite evaluation metric to assess imputation performance.",
    "source": "arXiv"
  },
  {
    "title": "Financial and symbolic incentives promote 'green' charging choices",
    "title_es": "Financial and symbolic incentives promote 'green' charging choices",
    "url": "https://arxiv.org/abs/2508.08282",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08282v1 Announce Type: cross \nAbstract: Electromobility can contribute to a reduction in greenhouse gas emissions if usage behavior is aligned with the increasing availability of renewable energy. To achieve this, smart navigation systems can be used to inform drivers of optimal charging times and locations. Yet, required flexibility may impart time penalties. We investigate the impact of financial and symbolic incentive schemes to counteract these additional costs. In a laboratory experiment with real-life time costs, we find that monetary and symbolic incentives are both effective in changing behavior towards 'greener' charging choices, while we find no significant statistical difference between them.",
    "source": "arXiv"
  },
  {
    "title": "Binary Decision Process in Pre-Evacuation Behavior",
    "title_es": "Binary Decision Process in Pre-Evacuation Behavior",
    "url": "https://arxiv.org/abs/2508.08284",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08284v1 Announce Type: cross \nAbstract: In crowd evacuation the time interval before decisive movement towards a safe place is defined as the pre-evacuation phase, and it has crucial impact on the total time required to safe egress. This process mainly refers to situation awareness and response to an external stressors, e.g., fire alarm. Due to the complexity of human cognitive process, stimulation is widely used to study this important time interval. In this paper a binary decision process is formulated to simulate pre-evacuation time of many evacuees in a given social context. The model combines classic opinion dynamics with binary phase transition to describe how pre-evacuation time emerges from individual interaction. The model parameters are conceptually meaningful to human factors research within socio-psychological background, e.g., whether an individual is stubborn or open-minded, or what kind of the social topology exists among the individuals and how it matters in aggregating individuals into social groups. The modeling framework also describes collective motion of many evacuees in a planar space, and the resulting multi-agent system is partly similar to Vicsek model, and it is meaningful to explore complex crowd behavior in social context.",
    "source": "arXiv"
  },
  {
    "title": "Quantum Inspired Legal Tech Environmental Integration for Emergency Pharmaceutical Logistics with Entropy Modulated Collapse and Multilevel Governance",
    "title_es": "Quantum Inspired Legal Tech Environmental Integration for Emergency Pharmaceutical Logistics with Entropy Modulated Collapse and Multilevel Governance",
    "url": "https://arxiv.org/abs/2508.08286",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08286v1 Announce Type: cross \nAbstract: Emergency pharmaceutical logistics during rapid-onset disasters must balance timeliness, legal compliance, and environmental uncertainty. We present a hybrid framework that co-designs quantum-inspired decision dynamics, embedded legal constraints, and blockchain-verified environmental feedback. Candidate routes are modeled as a superposed state whose collapse is governed by entropy modulation-delaying commitment under ambiguity and accelerating resolution when coherent signals emerge. Legal statutes act as real-time projection operators shaping feasible choices, while environmental decoherence cues adjust confidence and path viability. The core engine is situated within a multilevel governance and mechanism design architecture, establishing clear roles, accountability channels, and audit trails. Large-scale simulations in wildfire scenarios demonstrate substantial gains over conventional baselines in latency, compliance, and robustness, while preserving interpretability and fairness adaptation. The resulting system offers a deployable, governance-aware infrastructure where law and physical risk jointly inform emergency routing decisions.",
    "source": "arXiv"
  },
  {
    "title": "On Experiments",
    "title_es": "On Experiments",
    "url": "https://arxiv.org/abs/2508.08288",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08288v1 Announce Type: cross \nAbstract: The scientific process is a means for turning the results of experiments into knowledge about the world in which we live. Much research effort has been directed toward automating this process. To do this, one needs to formulate the scientific process in a precise mathematical language. This paper outlines one such language. What is presented here is hardly new. The material leans much on great thinkers of times past as well as more modern contributions. The novel contributions of this paper are: A new, general data processing inequality, a bias variance decomposition for canonical losses, Streamlined proofs of the Blackwell-Sherman-Stein and Randomization Theorems, and Means to calculate deficiency via linear programming.",
    "source": "arXiv"
  },
  {
    "title": "Non-participant externalities reshape the evolution of altruistic punishment",
    "title_es": "Non-participant externalities reshape the evolution of altruistic punishment",
    "url": "https://arxiv.org/abs/2508.08302",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08302v1 Announce Type: cross \nAbstract: While voluntary participation is a key mechanism that enables altruistic punishment to emerge, its explanatory power typically rests on the common assumption that non-participants have no impact on the public good. Yet, given the decentralized nature of voluntary participation, opting out does not necessarily preclude individuals from influencing the public good. Here, we revisit the role of voluntary participation by allowing non-participants to exert either positive or negative impacts on the public good. Using evolutionary analysis in a well-mixed finite population, we find that positive externalities from non-participants lower the synergy threshold required for altruistic punishment to dominate. In contrast, negative externalities raise this threshold, making altruistic punishment harder to sustain. Notably, when non-participants have positive impacts, altruistic punishment thrives only if non-participation is incentivized, whereas under negative impacts, it can persist even when non-participation is discouraged. Our findings reveal that efforts to promote altruistic punishment must account for the active role of non-participants, whose influence can make or break collective outcomes.",
    "source": "arXiv"
  },
  {
    "title": "Constrained PSLQ Search for Machin-like Identities Achieving Record-Low Lehmer Measures",
    "title_es": "Constrained PSLQ Search for Machin-like Identities Achieving Record-Low Lehmer Measures",
    "url": "https://arxiv.org/abs/2508.08307",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08307v1 Announce Type: cross \nAbstract: Machin-like arctangent relations are classical tools for computing $\\pi$, with efficiency quantified by the Lehmer measure ($\\lambda$). We present a framework for discovering low-measure relations by coupling the PSLQ integer-relation algorithm with number-theoretic filters derived from the algebraic structure of Gaussian integers, making large scale search tractable. Our search yields new 5 and 6 term relations with record-low Lehmer measures ($\\lambda=1.4572, \\lambda=1.3291$). We also demonstrate how discovered relations can serve as a basis for generating new, longer formulae through algorithmic extensions. This combined approach of a constrained PSLQ search and algorithmic extension provides a robust method for future explorations.",
    "source": "arXiv"
  },
  {
    "title": "Variational volume reconstruction with the Deep Ritz Method",
    "title_es": "Variational volume reconstruction with the Deep Ritz Method",
    "url": "https://arxiv.org/abs/2508.08309",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08309v1 Announce Type: cross \nAbstract: We present a novel approach to variational volume reconstruction from sparse, noisy slice data using the Deep Ritz method. Motivated by biomedical imaging applications such as MRI-based slice-to-volume reconstruction (SVR), our approach addresses three key challenges: (i) the reliance on image segmentation to extract boundaries from noisy grayscale slice images, (ii) the need to reconstruct volumes from a limited number of slice planes, and (iii) the computational expense of traditional mesh-based methods. We formulate a variational objective that combines a regression loss designed to avoid image segmentation by operating on noisy slice data directly with a modified Cahn-Hilliard energy incorporating anisotropic diffusion to regularize the reconstructed geometry. We discretize the phase field with a neural network, approximate the objective at each optimization step with Monte Carlo integration, and use ADAM to find the minimum of the approximated variational objective. While the stochastic integration may not yield the true solution to the variational problem, we demonstrate that our method reliably produces high-quality reconstructed volumes in a matter of seconds, even when the slice data is sparse and noisy.",
    "source": "arXiv"
  },
  {
    "title": "CFM-GP: Unified Conditional Flow Matching to Learn Gene Perturbation Across Cell Types",
    "title_es": "CFM-GP: Unified Conditional Flow Matching to Learn Gene Perturbation Across Cell Types",
    "url": "https://arxiv.org/abs/2508.08312",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08312v1 Announce Type: cross \nAbstract: Understanding gene perturbation effects across diverse cellular contexts is a central challenge in functional genomics, with important implications for therapeutic discovery and precision medicine. Single-cell technologies enable high-resolution measurement of transcriptional responses, but collecting such data is costly and time-consuming, especially when repeated for each cell type. Existing computational methods often require separate models per cell type, limiting scalability and generalization. We present CFM-GP, a method for cell type-agnostic gene perturbation prediction. CFM-GP learns a continuous, time-dependent transformation between unperturbed and perturbed gene expression distributions, conditioned on cell type, allowing a single model to predict across all cell types. Unlike prior approaches that use discrete modeling, CFM-GP employs a flow matching objective to capture perturbation dynamics in a scalable manner. We evaluate on five datasets: SARS-CoV-2 infection, IFN-beta stimulated PBMCs, glioblastoma treated with Panobinostat, lupus under IFN-beta stimulation, and Statefate progenitor fate mapping. CFM-GP consistently outperforms state-of-the-art baselines in R-squared and Spearman correlation, and pathway enrichment analysis confirms recovery of key biological pathways. These results demonstrate the robustness and biological fidelity of CFM-GP as a scalable solution for cross-cell type gene perturbation prediction.",
    "source": "arXiv"
  },
  {
    "title": "Algorithmic Collusion of Pricing and Advertising on E-commerce Platforms",
    "title_es": "Algorithmic Collusion of Pricing and Advertising on E-commerce Platforms",
    "url": "https://arxiv.org/abs/2508.08325",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08325v1 Announce Type: cross \nAbstract: Online sellers have been adopting AI learning algorithms to automatically make product pricing and advertising decisions on e-commerce platforms. When sellers compete using such algorithms, one concern is that of tacit collusion - the algorithms learn to coordinate on higher than competitive. We empirically investigate whether these concerns are valid when sellers make pricing and advertising decisions together, i.e., two-dimensional decisions. Our empirical strategy is to analyze competition with multi-agent reinforcement learning, which we calibrate to a large-scale dataset collected from Amazon.com products. Our first contribution is to find conditions under which learning algorithms can facilitate win-win-win outcomes that are beneficial for consumers, sellers, and even the platform, when consumers have high search costs. In these cases the algorithms learn to coordinate on prices that are lower than competitive prices. The intuition is that the algorithms learn to coordinate on lower advertising bids, which lower advertising costs, leading to lower prices. Our second contribution is an analysis of a large-scale, high-frequency keyword-product dataset for more than 2 million products on Amazon.com. Our estimates of consumer search costs show a wide range of costs for different product keywords. We generate an algorithm usage and find a negative interaction between the estimated consumer search costs and the algorithm usage index, providing empirical evidence of beneficial collusion. Finally, we analyze the platform's strategic response. We find that reserve price adjustments will not increase profits for the platform, but commission adjustments will. Our analyses help alleviate some worries about the potentially harmful effects of competing learning algorithms, and can help sellers, platforms and policymakers to decide on whether to adopt or regulate such algorithms.",
    "source": "arXiv"
  },
  {
    "title": "On Irreversibility and Stochastic Systems: Part One",
    "title_es": "On Irreversibility and Stochastic Systems: Part One",
    "url": "https://arxiv.org/abs/2508.08330",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08330v1 Announce Type: cross \nAbstract: We attempt to characterize irreversibility of a dynamical system from the existence of different forward and backward mathematical representations depending on the direction of the time arrow. Such different representations have been studied intensively and are shown to exist for stochastic diffusion models. In this setting one has however to face the preliminary justification of stochastic description for physical systems which are described by classical mechanics as inherently deterministic and conservative.\n  In part one of this paper we first address this modeling problem for linear systems in a deterministic context. We show that forward-backward representations can also describe conservative finite dimensional deterministic systems when they are coupled to an infinite-dimensional conservative heat bath. A novel key observation is that the heat bath acts on the finite-dimensional conservative system by {\\em state-feedback} and can shift its eigenvalues to make the system dissipative but may also generate another totally unstable model which naturally evolves backward in time.\n  In the second part, we address the stochastic description of these two representations. Under a natural family of invariant measures the heat bath can be shown to induce a white noise input acting on the system making it look like a true dissipative diffusion.",
    "source": "arXiv"
  },
  {
    "title": "miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research",
    "title_es": "miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research",
    "url": "https://arxiv.org/abs/2508.08331",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08331v1 Announce Type: cross \nAbstract: MicroRNAs (miRs) are robust regulators of gene expression, implicated in most biological processes. microRNAs predominantly downregulate the expression of genes post-transcriptionally and each miR is predicted to target several hundred genes. The accurate identification and annotation of miR-mRNA target interactions is central to understanding miRs function and their therapeutic potential. However, computational target prediction is challenging due to imperfect complementarity of miRs with their targets and the growing volume and heterogeneity of experimental data present challenges in accessing, integrating, and analysing miR-target interaction information across biological contexts. This creates a need for integrated resources and intelligent query tools.\n  We present the miRKat Suite, comprising miRKatDB, a comprehensive, curated database of predicted and validated miR-target interactions and associated annotations, and miRKatAI, a multi-agent system powered by large language models (LLMs) and LangGraph. miRKatDB integrates data from multiple publicly available sources, providing a comprehensive foundation for miR studies, including miR target genes and changes in levels of tissue expression previously reported. miRKatAI offers a natural language interface for complex querying of miRKatDB, facilitates grounded information retrieval from established sources in the field, and supports basic data visualisation. The miRKat Suite aims to accelerate miR research by streamlining data access, enhancing exploratory analysis, and supporting hypothesis generation.",
    "source": "arXiv"
  },
  {
    "title": "The DNA of nuclear models: How AI predicts nuclear masses",
    "title_es": "The DNA of nuclear models: How AI predicts nuclear masses",
    "url": "https://arxiv.org/abs/2508.08370",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08370v1 Announce Type: cross \nAbstract: Obtaining high-precision predictions of nuclear masses, or equivalently nuclear binding energies, $E_b$, remains an important goal in nuclear-physics research. Recently, many AI-based tools have shown promising results on this task, some achieving precision that surpasses the best physics models. However, the utility of these AI models remains in question given that predictions are only useful where measurements do not exist, which inherently requires extrapolation away from the training (and testing) samples. Since AI models are largely black boxes, the reliability of such an extrapolation is difficult to assess. We present an AI model that not only achieves cutting-edge precision for $E_b$, but does so in an interpretable manner. For example, we find (and explain why) that the most important dimensions of its internal representation form a double helix, where the analog of the hydrogen bonds in DNA here link the number of protons and neutrons found in the most stable nucleus of each isotopic chain. Furthermore, we show that the AI prediction of $E_b$ can be factorized and ordered hierarchically, with the most important terms corresponding to well-known symbolic models (such as the famous liquid drop). Remarkably, the improvement of the AI model over symbolic ones can almost entirely be attributed to an observation made by Jaffe in 1969. The end result is a fully interpretable data-driven model of nuclear masses.",
    "source": "arXiv"
  },
  {
    "title": "Preprocessing Algorithm Leveraging Geometric Modeling for Scale Correction in Hyperspectral Images for Improved Unmixing Performance",
    "title_es": "Preprocessing Algorithm Leveraging Geometric Modeling for Scale Correction in Hyperspectral Images for Improved Unmixing Performance",
    "url": "https://arxiv.org/abs/2508.08431",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08431v1 Announce Type: cross \nAbstract: Spectral variability significantly impacts the accuracy and convergence of hyperspectral unmixing algorithms. While many methods address complex spectral variability, large-scale variations in spectral signature scale caused by factors such as topography, illumination, and shadowing remain a major challenge. These variations often degrade unmixing performance and complicate model fitting. In this paper, we propose a novel preprocessing algorithm that corrects scale-induced spectral variability prior to unmixing. By isolating and compensating for these large-scale multiplicative effects, the algorithm provides a cleaner input, enabling unmixing methods to focus more effectively on modeling nonlinear spectral variability and abundance estimation. We present a rigorous mathematical framework to describe scale variability and extensive experimental validation of the proposed algorithm. Furthermore, the algorithm's impact is evaluated across a broad spectrum of state-of-the-art unmixing algorithms on two synthetic and two real hyperspectral datasets. The proposed preprocessing step consistently improves the performance of these algorithms, including those specifically designed to handle spectral variability, with error reductions close to 50% in many cases. This demonstrates that scale correction acts as a complementary step, facilitating more accurate unmixing by existing methods. The algorithm's generality and significant impact highlight its potential as a key component in practical hyperspectral unmixing pipelines. The implementation code will be made publicly available upon publication.",
    "source": "arXiv"
  },
  {
    "title": "Language Models Can Understand Spectra: A Multimodal Model for Molecular Structure Elucidation",
    "title_es": "Language Models Can Understand Spectra: A Multimodal Model for Molecular Structure Elucidation",
    "url": "https://arxiv.org/abs/2508.08441",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08441v1 Announce Type: cross \nAbstract: Structure elucidation is a fundamental technique for understanding the microscopic composition of matter and is widely applied across various disciplines in the natural sciences and engineering. However, existing methods often rely heavily on prior databases or known structural information, making it difficult to resolve unknown structures. In addition, complex structures typically require the joint analysis of multiple spectroscopic modalities. This process heavily depends on expert domain knowledge and is often accompanied by high costs in terms of both time and instrumentation. To address these challenges, we propose SpectraLLM, the first large language model designed to support multi-modal spectroscopic joint reasoning. SpectraLLM is capable of processing either single or multiple spectroscopic inputs and performing end-to-end structure elucidation. By integrating continuous and discrete spectroscopic modalities into a shared semantic space, SpectraLLM learns to uncover substructural patterns that are consistent and complementary across spectra, enabling precise molecular structure elucidation. We pretrain and fine-tune SpectraLLM in the domain of small molecules, and evaluate it on six standardized, publicly available chemical datasets. The model achieves state-of-the-art performance, significantly outperforming existing approaches trained on single modalities. Notably, SpectraLLM demonstrates strong robustness and generalization even for single-spectrum inference, while its multi-modal reasoning capability further improves the accuracy of structural prediction.",
    "source": "arXiv"
  },
  {
    "title": "Gradient- and Newton-Based Unit Vector Extremum Seeking Control",
    "title_es": "Gradient- and Newton-Based Unit Vector Extremum Seeking Control",
    "url": "https://arxiv.org/abs/2508.08485",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08485v1 Announce Type: cross \nAbstract: This paper presents novel methods for achieving stable and efficient convergence in multivariable extremum seeking control (ESC) using sliding mode techniques. Drawing inspiration from both classical sliding mode control and more recent developments in finite-time and fixed-time control, we propose a new framework that integrates these concepts into Gradient- and Newton-based ESC schemes based on sinusoidal perturbation signals. The key innovation lies in the use of discontinuous \"relay-type\" control components, replacing traditional proportional feedback to estimate the gradient of unknown quadratic nonlinear performance maps with Unit Vector Control (UVC). This represents the first attempt to address real-time, model-free optimization using sliding modes within the classical extremum seeking paradigm. In the Gradient-based approach, the convergence rate is influenced by the unknown Hessian of the objective function. In contrast, the Newton-based method overcomes this limitation by employing a dynamic estimator for the inverse of the Hessian, implemented via a Riccati equation filter. We establish finite-time convergence of the closed-loop average system to the extremum point for both methods by leveraging Lyapunov-based analysis and averaging theory tailored to systems with discontinuous right-hand sides. Numerical simulations validate the proposed method, illustrating significantly faster convergence and improved robustness compared to conventional ESC strategies, which typically guarantee only exponential stability. The results also demonstrate that the Gradient-based method exhibits slower convergence and higher transients since the gradient trajectory follows the curved and steepest-descent path, whereas the Newton-based method achieves faster convergence and improved overall performance going straightly to the extremum.",
    "source": "arXiv"
  },
  {
    "title": "An Analytical and Experimental Study of Distributed Uplink Beamforming in the Presence of Carrier Frequency Offsets",
    "title_es": "An Analytical and Experimental Study of Distributed Uplink Beamforming in the Presence of Carrier Frequency Offsets",
    "url": "https://arxiv.org/abs/2508.08506",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08506v1 Announce Type: cross \nAbstract: Realizing distributed multi-user beamforming (D-MUBF) in time division duplex (TDD)-based multi-user MIMO (MU-MIMO) systems faces significant challenges. One of the most fundamental challenges is achieving accurate over-the-air (OTA) timing and frequency synchronization among distributed access points (APs), particularly due to residual frequency offsets caused by local oscillator (LO) drifts. Despite decades of research on synchronization for MU-MIMO, there are only a few experimental studies that evaluate D-MUBF techniques under imperfect frequency synchronization among distributed antennas. This paper presents an analytical and experimental assessment of D-MUBF methods in the presence of frequency synchronization errors. We provide closed-form expressions for signal-to-interference-plus-noise ratio (SINR) as a function of channel characteristics and statistical properties of carrier frequency offset (CFO) among AP antennas. In addition, through experimental evaluations conducted with the RENEW massive MIMO testbed, we collected comprehensive datasets across various experimental scenarios. These datasets comprise uplink pilot samples for channel and CFO estimation, in addition to uplink multi-user data intended for analyzing D-MUBF techniques. By examining these datasets, we assess the performance of D-MUBF in the presence of CFO and compare the analytical predictions with empirical measurements. Furthermore, we make the datasets publicly available and provide insights on utilizing them for future research endeavors.",
    "source": "arXiv"
  },
  {
    "title": "Control-affine Schr\\\"odinger Bridge and Generalized Bohm Potential",
    "title_es": "Control-affine Schr\\\"odinger Bridge and Generalized Bohm Potential",
    "url": "https://arxiv.org/abs/2508.08511",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08511v1 Announce Type: cross \nAbstract: The control-affine Schr\\\"odinger bridge concerns with a stochastic optimal control problem. Its solution is a controlled evolution of joint state probability density subject to a control-affine It\\^o diffusion with a given deadline connecting a given pair of initial and terminal densities. In this work, we recast the necessary conditions of optimality for the control-affine Schr\\\"odinger bridge problem as a two point boundary value problem for a quantum mechanical Schr\\\"odinger PDE with complex potential. This complex-valued potential is a generalization of the real-valued Bohm potential in quantum mechanics. Our derived potential is akin to the optical potential in nuclear physics where the real part of the potential encodes elastic scattering (transmission of wave function), and the imaginary part encodes inelastic scattering (absorption of wave function). The key takeaway is that the process noise that drives the evolution of probability densities induces an absorbing medium in the evolution of wave function. These results make new connections between control theory and non-equilibrium statistical mechanics through the lens of quantum mechanics.",
    "source": "arXiv"
  },
  {
    "title": "Projection-based multifidelity linear regression for data-scarce applications",
    "title_es": "Projection-based multifidelity linear regression for data-scarce applications",
    "url": "https://arxiv.org/abs/2508.08517",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08517v1 Announce Type: cross \nAbstract: Surrogate modeling for systems with high-dimensional quantities of interest remains challenging, particularly when training data are costly to acquire. This work develops multifidelity methods for multiple-input multiple-output linear regression targeting data-limited applications with high-dimensional outputs. Multifidelity methods integrate many inexpensive low-fidelity model evaluations with limited, costly high-fidelity evaluations. We introduce two projection-based multifidelity linear regression approaches that leverage principal component basis vectors for dimensionality reduction and combine multifidelity data through: (i) a direct data augmentation using low-fidelity data, and (ii) a data augmentation incorporating explicit linear corrections between low-fidelity and high-fidelity data. The data augmentation approaches combine high-fidelity and low-fidelity data into a unified training set and train the linear regression model through weighted least squares with fidelity-specific weights. Various weighting schemes and their impact on regression accuracy are explored. The proposed multifidelity linear regression methods are demonstrated on approximating the surface pressure field of a hypersonic vehicle in flight. In a low-data regime of no more than ten high-fidelity samples, multifidelity linear regression achieves approximately 3% - 12% improvement in median accuracy compared to single-fidelity methods with comparable computational cost.",
    "source": "arXiv"
  },
  {
    "title": "Graph-based method for constructing consensus trees",
    "title_es": "Graph-based method for constructing consensus trees",
    "url": "https://arxiv.org/abs/2508.08569",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08569v1 Announce Type: cross \nAbstract: A consensus tree is a phylogenetic tree that synthesizes a given collection of phylogenetic trees, all of which share the same leaf labels but may have different topologies, typically obtained through bootstrapping. Our research focuses on creating a consensus tree from a collection of phylogenetic trees, each detailed with branch-length data. We integrate branch lengths into the consensus to encapsulate the progression rate of genetic mutations. However, traditional consensus trees, such as the strict consensus tree, primarily focus on the topological structure of these trees, often neglecting the informative value of branch lengths. This oversight disregards a crucial aspect of evolutionary study and highlights a notable gap in traditional phylogenetic approaches. In this paper, we extend \\textit{PrimConsTree}\\footnote{A preliminary version of this article was presented at \\emph{the Fifteenth International Conference on Bioscience, Biochemistry, and Bioinformatics (ICBBB~2025)}~(reference~\\cite{torquet2005icbbb}).}, a graph-based method for constructing consensus trees. This algorithm incorporates topological information, edge frequency, clade frequency, and branch length to construct a more robust and comprehensive consensus tree. Our adaptation of the well-known Prim algorithm efficiently identifies the maximum frequency branch and maximum frequency nodes to build the optimal consensus tree. This strategy was pre-processed with clustering steps to calibrate the robustness and accuracy of the consensus tree.\\\\ \\textbf{Availability and implementation:} The source code of PrimConsTree is freely available on GitHub at https://github.com/tahiri-lab/PrimConsTree.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchy Entropy Degeneration Explains the Rat Utopia Population Collapse: The Role of Full Visibility and Isolation",
    "title_es": "Hierarchy Entropy Degeneration Explains the Rat Utopia Population Collapse: The Role of Full Visibility and Isolation",
    "url": "https://arxiv.org/abs/2508.08587",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08587v1 Announce Type: cross \nAbstract: Calhoun's Rat Utopia experiments demonstrated a puzzling population trajectory: initial growth, plateau, and eventually a total collapse of the rat population despite abundant resources. This paper proposes a hypothesis that the enclosure's design enabled full visibility of the social hierarchy (pecking order), leading to entropy degeneration: progressive loss of uncertainty in rats' perceived ranks over generations. High initial uncertainty drives engagement in dominance, reproduction, and care; as visibility solidifies the hierarchy over the generations, uncertainty vanishes, nullifying perceived gains from social activities. Simulations reproduce the experimental arc which rely on a game theoretic matrix that is parameterized by the uncertainty (entropy) in the hierarchy which changes over rat generations.",
    "source": "arXiv"
  },
  {
    "title": "Performance Benchmarking of Machine Learning Models for Terahertz Metamaterial Absorber Prediction",
    "title_es": "Performance Benchmarking of Machine Learning Models for Terahertz Metamaterial Absorber Prediction",
    "url": "https://arxiv.org/abs/2508.08611",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08611v1 Announce Type: cross \nAbstract: This study presents a polarization-insensitive ultra-broadband terahertz metamaterial absorber based on vanadium dioxide (VO2) and evaluates machine learning methods for predicting its absorption performance. The structure consists of a VO2 metasurface, a MF2 dielectric spacer, and a gold ground plane. It achieves more than 90% absorption between 5.72 and 11.11 THz, covering a 5.38 THz bandwidth with an average absorptance of 98.15%. A dataset of 9,018 samples was generated from full-wave simulations by varying patch width, dielectric thickness, and frequency. Six regression models were trained: Linear Regression, Support Vector Regression, Decision Tree, Random Forest, XGBoost, and Bagging. Performance was measured using adjusted R2, MAE, MSE, and RMSE. Ensemble models achieved the best results, with Bagging reaching an adjusted R2 of 0.9985 and RMSE of 0.0146. The workflow offers a faster alternative to exhaustive simulations and can be applied to other metamaterial designs, enabling efficient evaluation and optimization.",
    "source": "arXiv"
  },
  {
    "title": "In-Context Learning as Nonparametric Conditional Probability Estimation: Risk Bounds and Optimality",
    "title_es": "In-Context Learning as Nonparametric Conditional Probability Estimation: Risk Bounds and Optimality",
    "url": "https://arxiv.org/abs/2508.08673",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08673v1 Announce Type: cross \nAbstract: This paper investigates the expected excess risk of In-Context Learning (ICL) for multiclass classification. We model each task as a sequence of labeled prompt samples and a query input, where a pre-trained model estimates the conditional class probabilities of the query. The expected excess risk is defined as the average truncated Kullback-Leibler (KL) divergence between the predicted and ground-truth conditional class distributions, averaged over a specified family of tasks. We establish a new oracle inequality for the expected excess risk based on KL divergence in multiclass classification. This allows us to derive tight upper and lower bounds for the expected excess risk in transformer-based models, demonstrating that the ICL estimator achieves the minimax optimal rate - up to a logarithmic factor - for conditional probability estimation. From a technical standpoint, our results introduce a novel method for controlling generalization error using the uniform empirical covering entropy of the log-likelihood function class. Furthermore, we show that multilayer perceptrons (MLPs) can also perform ICL and achieve this optimal rate under specific assumptions, suggesting that transformers may not be the exclusive architecture capable of effective ICL.",
    "source": "arXiv"
  },
  {
    "title": "DiffVolume: Diffusion Models for Volume Generation in Limit Order Books",
    "title_es": "DiffVolume: Diffusion Models for Volume Generation in Limit Order Books",
    "url": "https://arxiv.org/abs/2508.08698",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08698v1 Announce Type: cross \nAbstract: Modeling limit order books (LOBs) dynamics is a fundamental problem in market microstructure research. In particular, generating high-dimensional volume snapshots with strong temporal and liquidity-dependent patterns remains a challenging task, despite recent work exploring the application of Generative Adversarial Networks to LOBs. In this work, we propose a conditional \\textbf{Diff}usion model for the generation of future LOB \\textbf{Volume} snapshots (\\textbf{DiffVolume}). We evaluate our model across three axes: (1) \\textit{Realism}, where we show that DiffVolume, conditioned on past volume history and time of day, better reproduces statistical properties such as marginal distribution, spatial correlation, and autocorrelation decay; (2) \\textit{Counterfactual generation}, allowing for controllable generation under hypothetical liquidity scenarios by additionally conditioning on a target future liquidity profile; and (3) \\textit{Downstream prediction}, where we show that the synthetic counterfactual data from our model improves the performance of future liquidity forecasting models. Together, these results suggest that DiffVolume provides a powerful and flexible framework for realistic and controllable LOB volume generation.",
    "source": "arXiv"
  },
  {
    "title": "MultiAiTutor: Child-Friendly Educational Multilingual Speech Generation Tutor with LLMs",
    "title_es": "MultiAiTutor: Child-Friendly Educational Multilingual Speech Generation Tutor with LLMs",
    "url": "https://arxiv.org/abs/2508.08715",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08715v1 Announce Type: cross \nAbstract: Generative speech models have demonstrated significant potential in personalizing teacher-student interactions, offering valuable real-world applications for language learning in children's education. However, achieving high-quality, child-friendly speech generation remains challenging, particularly for low-resource languages across diverse languages and cultural contexts. In this paper, we propose MultiAiTutor, an educational multilingual generative AI tutor with child-friendly designs, leveraging LLM architecture for speech generation tailored for educational purposes. We propose to integrate age-appropriate multilingual speech generation using LLM architectures, facilitating young children's language learning through culturally relevant image-description tasks in three low-resource languages: Singaporean-accent Mandarin, Malay, and Tamil. Experimental results from both objective metrics and subjective evaluations demonstrate the superior performance of the proposed MultiAiTutor compared to baseline methods.",
    "source": "arXiv"
  },
  {
    "title": "Hierarchical Variable Importance with Statistical Control for Medical Data-Based Prediction",
    "title_es": "Hierarchical Variable Importance with Statistical Control for Medical Data-Based Prediction",
    "url": "https://arxiv.org/abs/2508.08724",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08724v1 Announce Type: cross \nAbstract: Recent advances in machine learning have greatly expanded the repertoire of predictive methods for medical imaging. However, the interpretability of complex models remains a challenge, which limits their utility in medical applications. Recently, model-agnostic methods have been proposed to measure conditional variable importance and accommodate complex non-linear models. However, they often lack power when dealing with highly correlated data, a common problem in medical imaging. We introduce Hierarchical-CPI, a model-agnostic variable importance measure that frames the inference problem as the discovery of groups of variables that are jointly predictive of the outcome. By exploring subgroups along a hierarchical tree, it remains computationally tractable, yet also enjoys explicit family-wise error rate control. Moreover, we address the issue of vanishing conditional importance under high correlation with a tree-based importance allocation mechanism. We benchmarked Hierarchical-CPI against state-of-the-art variable importance methods. Its effectiveness is demonstrated in two neuroimaging datasets: classifying dementia diagnoses from MRI data (ADNI dataset) and analyzing the Berger effect on EEG data (TDBRAIN dataset), identifying biologically plausible variables.",
    "source": "arXiv"
  },
  {
    "title": "Sensitivity Analysis to Unobserved Confounding with Copula-based Normalizing Flows",
    "title_es": "Sensitivity Analysis to Unobserved Confounding with Copula-based Normalizing Flows",
    "url": "https://arxiv.org/abs/2508.08752",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08752v1 Announce Type: cross \nAbstract: We propose a novel method for sensitivity analysis to unobserved confounding in causal inference. The method builds on a copula-based causal graphical normalizing flow that we term $\\rho$-GNF, where $\\rho \\in [-1,+1]$ is the sensitivity parameter. The parameter represents the non-causal association between exposure and outcome due to unobserved confounding, which is modeled as a Gaussian copula. In other words, the $\\rho$-GNF enables scholars to estimate the average causal effect (ACE) as a function of $\\rho$, accounting for various confounding strengths. The output of the $\\rho$-GNF is what we term the $\\rho_{curve}$, which provides the bounds for the ACE given an interval of assumed $\\rho$ values. The $\\rho_{curve}$ also enables scholars to identify the confounding strength required to nullify the ACE. We also propose a Bayesian version of our sensitivity analysis method. Assuming a prior over the sensitivity parameter $\\rho$ enables us to derive the posterior distribution over the ACE, which enables us to derive credible intervals. Finally, leveraging on experiments from simulated and real-world data, we show the benefits of our sensitivity analysis method.",
    "source": "arXiv"
  },
  {
    "title": "Bio-Inspired Artificial Neural Networks based on Predictive Coding",
    "title_es": "Bio-Inspired Artificial Neural Networks based on Predictive Coding",
    "url": "https://arxiv.org/abs/2508.08762",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08762v1 Announce Type: cross \nAbstract: Backpropagation (BP) of errors is the backbone training algorithm for artificial neural networks (ANNs). It updates network weights through gradient descent to minimize a loss function representing the mismatch between predictions and desired outputs. BP uses the chain rule to propagate the loss gradient backward through the network hierarchy, allowing efficient weight updates. However, this process requires weight updates at every layer to rely on a global error signal generated at the network's output.\n  In contrast, the Hebbian model of synaptic plasticity states that weight updates are local, depending only on the activity of pre- and post-synaptic neurons. This suggests biological brains likely do not implement BP directly. Recently, Predictive Coding (PC) has gained interest as a biologically plausible alternative that updates weights using only local information. Originating from 1950s work on signal compression, PC was later proposed as a model of the visual cortex and formalized under the free energy principle, linking it to Bayesian inference and dynamical systems. PC weight updates rely solely on local information and provide theoretical advantages such as automatic scaling of gradients based on uncertainty.\n  This lecture notes column offers a novel, tutorial-style introduction to PC, focusing on its formulation, derivation, and connections to well-known optimization and signal processing algorithms such as BP and the Kalman Filter (KF). It aims to support existing literature by guiding readers from the mathematical foundations of PC to practical implementation, including Python examples using PyTorch.",
    "source": "arXiv"
  },
  {
    "title": "Subsampling Factorization Machine Annealing",
    "title_es": "Subsampling Factorization Machine Annealing",
    "url": "https://arxiv.org/abs/2508.08778",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08778v1 Announce Type: cross \nAbstract: Quantum computing and machine learning are state-of-the-art technologies which have been investigated intensively in both academia and industry. The hybrid technology of these two ingredients is expected to be a powerful tool to solve complex problems in many branches of science and engineering such as combinatorial optimization problems and accelerate the creation of next-generation technologies. In this work, we develop an algorithm to solve a black-box optimization problem by improving Factorization Machine Annealing (FMA) such that the training of a machine learning model called Factorization Machine is performed not by a full dataset but by a subdataset which is sampled from a full dataset: Subsampling Factorization Machine Annealing (SFMA). According to such a probabilistic training process, the performance of FMA on exploring a solution space gets enhanced. As a result, SFMA exhibits balanced performance of exploration and exploitation which we call exploitation-exploration functionality. We conduct numerical benchmarking tests to compare the performance of SFMA with that of FMA. Consequently, SFMA certainly exhibits the exploration-exploitation functionality and outperforms FMA in speed and accuracy. In addition, the performance of SFMA can be further improved by sequentially using two subsampling datasets with different sizes such that the size of the latter dataset is substantially smaller than the former. Such a substantial reduction not only enhances the exploration performance of SFMA but also enables us to run it with correspondingly low computational cost even for a large-scale problem. These results indicate the effectiveness of SFMA in a certain class of black-box optimization problems of significant size: the potential scalability of SFMA in solving large-scale problems with correspondingly low computational cost.",
    "source": "arXiv"
  },
  {
    "title": "ReQuestNet: A Foundational Learning model for Channel Estimation",
    "title_es": "ReQuestNet: A Foundational Learning model for Channel Estimation",
    "url": "https://arxiv.org/abs/2508.08790",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08790v1 Announce Type: cross \nAbstract: In this paper, we present a novel neural architecture for channel estimation (CE) in 5G and beyond, the Recurrent Equivariant UERS Estimation Network (ReQuestNet). It incorporates several practical considerations in wireless communication systems, such as ability to handle variable number of resource block (RB), dynamic number of transmit layers, physical resource block groups (PRGs) bundling size (BS), demodulation reference signal (DMRS) patterns with a single unified model, thereby, drastically simplifying the CE pipeline. Besides it addresses several limitations of the legacy linear MMSE solutions, for example, by being independent of other reference signals and particularly by jointly processing MIMO layers and differently precoded channels with unknown precoding at the receiver. ReQuestNet comprises of two sub-units, CoarseNet followed by RefinementNet. CoarseNet performs per PRG, per transmit-receive (Tx-Rx) stream channel estimation, while RefinementNet refines the CoarseNet channel estimate by incorporating correlations across differently precoded PRGs, and correlation across multiple input multiple output (MIMO) channel spatial dimensions (cross-MIMO). Simulation results demonstrate that ReQuestNet significantly outperforms genie minimum mean squared error (MMSE) CE across a wide range of channel conditions, delay-Doppler profiles, achieving up to 10dB gain at high SNRs. Notably, ReQuestNet generalizes effectively to unseen channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations under dynamic PRG BS and varying transmit layer allocations.",
    "source": "arXiv"
  },
  {
    "title": "Fundamental limitations of monotonic tracking systems",
    "title_es": "Fundamental limitations of monotonic tracking systems",
    "url": "https://arxiv.org/abs/2508.08844",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08844v1 Announce Type: cross \nAbstract: We consider the monotonic tracking control problem for continuous-time single-input single-output linear systems using output-feedback linear controllers in this paper. We provide the necessary and sufficient conditions for this problem to be solvable and expose its fundamental limitations: the exact feasible locations of the plant zeros, the minimum controller order possible, and the maximum decay rate achievable for the closed-loop system. The relationship between these bounds is explained by a simple geometric shape for plants with a pair of complex-conjugate zeros.",
    "source": "arXiv"
  },
  {
    "title": "A Brief Introduction to Quantum Query Complexity",
    "title_es": "A Brief Introduction to Quantum Query Complexity",
    "url": "https://arxiv.org/abs/2508.08852",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08852v1 Announce Type: cross \nAbstract: Quantum query complexity is a fundamental model for analyzing the computational power of quantum algorithms. It has played a key role in characterizing quantum speedups, from early breakthroughs such as Grover's and Simon's algorithms to more recent developments in quantum cryptography and complexity theory. This document provides a structured introduction to quantum query lower bounds, focusing on four major techniques: the hybrid method, the polynomial method, the recording method, and the adversary method. Each method is developed from first principles and illustrated through canonical problems. Additionally, the document discusses how the adversary method can be used to derive upper bounds, highlighting its dual role in quantum query complexity. The goal is to offer a self-contained exposition accessible to readers with a basic background in quantum computing, while also serving as an entry point for researchers interested in the study of quantum lower bounds.",
    "source": "arXiv"
  },
  {
    "title": "Frequency-Assisted Adaptive Sharpening Scheme Considering Bitrate and Quality Tradeoff",
    "title_es": "Frequency-Assisted Adaptive Sharpening Scheme Considering Bitrate and Quality Tradeoff",
    "url": "https://arxiv.org/abs/2508.08854",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08854v1 Announce Type: cross \nAbstract: Sharpening is a widely adopted technique to improve video quality, which can effectively emphasize textures and alleviate blurring. However, increasing the sharpening level comes with a higher video bitrate, resulting in degraded Quality of Service (QoS). Furthermore, the video quality does not necessarily improve with increasing sharpening levels, leading to issues such as over-sharpening. Clearly, it is essential to figure out how to boost video quality with a proper sharpening level while also controlling bandwidth costs effectively. This paper thus proposes a novel Frequency-assisted Sharpening level Prediction model (FreqSP). We first label each video with the sharpening level correlating to the optimal bitrate and quality tradeoff as ground truth. Then taking uncompressed source videos as inputs, the proposed FreqSP leverages intricate CNN features and high-frequency components to estimate the optimal sharpening level. Extensive experiments demonstrate the effectiveness of our method.",
    "source": "arXiv"
  },
  {
    "title": "Transient Noise Removal via Diffusion-based Speech Inpainting",
    "title_es": "Transient Noise Removal via Diffusion-based Speech Inpainting",
    "url": "https://arxiv.org/abs/2508.08890",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08890v1 Announce Type: cross \nAbstract: In this paper, we present PGDI, a diffusion-based speech inpainting framework for restoring missing or severely corrupted speech segments. Unlike previous methods that struggle with speaker variability or long gap lengths, PGDI can accurately reconstruct gaps of up to one second in length while preserving speaker identity, prosody, and environmental factors such as reverberation. Central to this approach is classifier guidance, specifically phoneme-level guidance, which substantially improves reconstruction fidelity. PGDI operates in a speaker-independent manner and maintains robustness even when long segments are completely masked by strong transient noise, making it well-suited for real-world applications, such as fireworks, door slams, hammer strikes, and construction noise. Through extensive experiments across diverse speakers and gap lengths, we demonstrate PGDI's superior inpainting performance and its ability to handle challenging acoustic conditions. We consider both scenarios, with and without access to the transcript during inference, showing that while the availability of text further enhances performance, the model remains effective even in its absence. For audio samples, visit: https://mordehaym.github.io/PGDI/",
    "source": "arXiv"
  },
  {
    "title": "EGGCodec: A Robust Neural Encodec Framework for EGG Reconstruction and F0 Extraction",
    "title_es": "EGGCodec: A Robust Neural Encodec Framework for EGG Reconstruction and F0 Extraction",
    "url": "https://arxiv.org/abs/2508.08924",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08924v1 Announce Type: cross \nAbstract: This letter introduces EGGCodec, a robust neural Encodec framework engineered for electroglottography (EGG) signal reconstruction and F0 extraction. We propose a multi-scale frequency-domain loss function to capture the nuanced relationship between original and reconstructed EGG signals, complemented by a time-domain correlation loss to improve generalization and accuracy. Unlike conventional Encodec models that extract F0 directly from features, EGGCodec leverages reconstructed EGG signals, which more closely correspond to F0. By removing the conventional GAN discriminator, we streamline EGGCodec's training process without compromising efficiency, incurring only negligible performance degradation. Trained on a widely used EGG-inclusive dataset, extensive evaluations demonstrate that EGGCodec outperforms state-of-the-art F0 extraction schemes, reducing mean absolute error (MAE) from 14.14 Hz to 13.69 Hz, and improving voicing decision error (VDE) by 38.2\\%. Moreover, extensive ablation experiments validate the contribution of each component of EGGCodec.",
    "source": "arXiv"
  },
  {
    "title": "LPGNet: A Lightweight Network with Parallel Attention and Gated Fusion for Multimodal Emotion Recognition",
    "title_es": "LPGNet: A Lightweight Network with Parallel Attention and Gated Fusion for Multimodal Emotion Recognition",
    "url": "https://arxiv.org/abs/2508.08925",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08925v1 Announce Type: cross \nAbstract: Emotion recognition in conversations (ERC) aims to predict the emotional state of each utterance by using multiple input types, such as text and audio. While Transformer-based models have shown strong performance in this task, they often face two major issues: high computational cost and heavy dependence on speaker information. These problems reduce their ability to generalize in real-world conversations. To solve these challenges, we propose LPGNet, a Lightweight network with Parallel attention and Gated fusion for multimodal ERC. The main part of LPGNet is the Lightweight Parallel Interaction Attention (LPIA) module. This module replaces traditional stacked Transformer layers with parallel dot-product attention, which can model both within-modality and between-modality relationships more efficiently. To improve emotional feature learning, LPGNet also uses a dual-gated fusion method. This method filters and combines features from different input types in a flexible and dynamic way. In addition, LPGNet removes speaker embeddings completely, which allows the model to work independently of speaker identity. Experiments on the IEMOCAP dataset show that LPGNet reaches over 87% accuracy and F1-score in 4-class emotion classification. It outperforms strong baseline models while using fewer parameters and showing better generalization across speakers.",
    "source": "arXiv"
  },
  {
    "title": "Listen through the Sound: Generative Speech Restoration Leveraging Acoustic Context Representation",
    "title_es": "Listen through the Sound: Generative Speech Restoration Leveraging Acoustic Context Representation",
    "url": "https://arxiv.org/abs/2508.08953",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08953v1 Announce Type: cross \nAbstract: This paper introduces a novel approach to speech restoration by integrating a context-related conditioning strategy. Specifically, we employ the diffusion-based generative restoration model, UNIVERSE++, as a backbone to evaluate the effectiveness of contextual representations. We incorporate acoustic context embeddings extracted from the CLAP model, which capture the environmental attributes of input audio. Additionally, we propose an Acoustic Context (ACX) representation that refines CLAP embeddings to better handle various distortion factors and their intensity in speech signals. Unlike content-based approaches that rely on linguistic and speaker attributes, ACX provides contextual information that enables the restoration model to distinguish and mitigate distortions better. Experimental results indicate that context-aware conditioning improves both restoration performance and its stability across diverse distortion conditions, reducing variability compared to content-based methods.",
    "source": "arXiv"
  },
  {
    "title": "Dividing a cake for the irrationally entitled",
    "title_es": "Dividing a cake for the irrationally entitled",
    "url": "https://arxiv.org/abs/2508.09004",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09004v1 Announce Type: cross \nAbstract: A perfectly divisible cake is to be divided among a group of agents. Each agent is entitled to a share between zero and one, and these entitlements are compatible in that they sum to one. The mediator does not know the preferences of the agents, but can query the agents to make cuts and appraise slices in order to learn. We prove that if one of the entitlements is irrational, then the mediator must use a protocol that involves an arbitrarily large number of queries in order to construct an allocation that respects the entitlements regardless of preferences.",
    "source": "arXiv"
  },
  {
    "title": "Optimization-Free Fast Optimal Control: Bang-Ride Property, Monotonicity, and Applications to Fast Battery Charging",
    "title_es": "Optimization-Free Fast Optimal Control: Bang-Ride Property, Monotonicity, and Applications to Fast Battery Charging",
    "url": "https://arxiv.org/abs/2508.09010",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09010v1 Announce Type: cross \nAbstract: Single-input fast optimal control problems, which aim to achieve the optimal objective as fast as possible, occur in various real-world applications. In the case of fast battery charging, the associated optimal control problem becomes computationally challenging when detailed battery models are used. A recent heuristic optimization-free algorithm can significantly reduce the computational cost and provide an approximate solution, consistent with many heuristic input profiles in practice. These heuristic solutions have several special properties: They follow a bang-ride pattern that always activates a constraint and applies the maximum feasible input. This work investigates when the above properties arise in the optimal input, and ultimately, when the heuristic input profiles satisfy necessary optimality conditions. By exploiting Pontryagin's maximum principle (PMP), we show that the optimal control is bang-ride under regularity conditions on constraint switching and local controllability of the system. Moreover, the special type of bang-ride behavior, i.e., applying the maximum feasible input, arises under the monotonicity of the system, objective function, and restricted sensitivity of the constraints. These results provide a theoretical justification for a class of charging heuristics and the fast optimization-free algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Improved SINR Approximation for Downlink SDMA-based Networks with Outdated Channel State Information",
    "title_es": "Improved SINR Approximation for Downlink SDMA-based Networks with Outdated Channel State Information",
    "url": "https://arxiv.org/abs/2508.09020",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09020v1 Announce Type: cross \nAbstract: Understanding the performance of multi-user multiple-input multiple-output (MU-MIMO) systems under imperfect channel state information at the transmitter (CSIT) remains a critical challenge in next-generation wireless networks. In this context, accurate statistical modeling of the signal-tointerference- plus-noise ratio (SINR) is essential for enabling tractable performance analysis of multi-user systems. This paper presents an improved statistical approximation of the SINR for downlink (DL) MU-MIMO systems with imperfect CSIT. The proposed model retains the analytical simplicity of existing approaches (e.g., Gamma-based approximations) while overcoming their limitations, particularly the underestimation of SINR variance. We evaluate the proposed approximation in the context of Rate-Splitting Multiple Access (RSMA)-enabled MIMO DL systems with outdated CSIT. The results demonstrate excellent accuracy across a wide range of system configurations, including varying",
    "source": "arXiv"
  },
  {
    "title": "Chartwin: a Case Study on Channel Charting-aided Localization in Dynamic Digital Network Twins",
    "title_es": "Chartwin: a Case Study on Channel Charting-aided Localization in Dynamic Digital Network Twins",
    "url": "https://arxiv.org/abs/2508.09055",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09055v1 Announce Type: cross \nAbstract: Wireless communication systems can significantly benefit from the availability of spatially consistent representations of the wireless channel to efficiently perform a wide range of communication tasks. Towards this purpose, channel charting has been introduced as an effective unsupervised learning technique to achieve both locally and globally consistent radio maps. In this letter, we propose Chartwin, a case study on the integration of localization-oriented channel charting with dynamic Digital Network Twins (DNTs). Numerical results showcase the significant performance of semi-supervised channel charting in constructing a spatially consistent chart of the considered extended urban environment. The considered method results in $\\approx$ 4.5 m localization error for the static DNT and $\\approx$ 6 m in the dynamic DNT, fostering DNT-aided channel charting and localization.",
    "source": "arXiv"
  },
  {
    "title": "A new dataset and comparison for multi-camera frame synthesis",
    "title_es": "A new dataset and comparison for multi-camera frame synthesis",
    "url": "https://arxiv.org/abs/2508.09068",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09068v1 Announce Type: cross \nAbstract: Many methods exist for frame synthesis in image sequences but can be broadly categorised into frame interpolation and view synthesis techniques. Fundamentally, both frame interpolation and view synthesis tackle the same task, interpolating a frame given surrounding frames in time or space. However, most frame interpolation datasets focus on temporal aspects with single cameras moving through time and space, while view synthesis datasets are typically biased toward stereoscopic depth estimation use cases. This makes direct comparison between view synthesis and frame interpolation methods challenging. In this paper, we develop a novel multi-camera dataset using a custom-built dense linear camera array to enable fair comparison between these approaches. We evaluate classical and deep learning frame interpolators against a view synthesis method (3D Gaussian Splatting) for the task of view in-betweening. Our results reveal that deep learning methods do not significantly outperform classical methods on real image data, with 3D Gaussian Splatting actually underperforming frame interpolators by as much as 3.5 dB PSNR. However, in synthetic scenes, the situation reverses -- 3D Gaussian Splatting outperforms frame interpolation algorithms by almost 5 dB PSNR at a 95% confidence level.",
    "source": "arXiv"
  },
  {
    "title": "Efficient motion-based metrics for video frame interpolation",
    "title_es": "Efficient motion-based metrics for video frame interpolation",
    "url": "https://arxiv.org/abs/2508.09078",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09078v1 Announce Type: cross \nAbstract: Video frame interpolation (VFI) offers a way to generate intermediate frames between consecutive frames of a video sequence. Although the development of advanced frame interpolation algorithms has received increased attention in recent years, assessing the perceptual quality of interpolated content remains an ongoing area of research. In this paper, we investigate simple ways to process motion fields, with the purposes of using them as video quality metric for evaluating frame interpolation algorithms. We evaluate these quality metrics using the BVI-VFI dataset which contains perceptual scores measured for interpolated sequences. From our investigation we propose a motion metric based on measuring the divergence of motion fields. This metric correlates reasonably with these perceptual scores (PLCC=0.51) and is more computationally efficient (x2.7 speedup) compared to FloLPIPS (a well known motion-based metric). We then use our new proposed metrics to evaluate a range of state of the art frame interpolation metrics and find our metrics tend to favour more perceptual pleasing interpolated frames that may not score highly in terms of PSNR or SSIM.",
    "source": "arXiv"
  },
  {
    "title": "The shape of economics before and after the financial crisis",
    "title_es": "The shape of economics before and after the financial crisis",
    "url": "https://arxiv.org/abs/2508.09079",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09079v1 Announce Type: cross \nAbstract: This paper investigates the impact of the global financial crisis on the shape of economics as a discipline by analyzing EconLit-indexed journals from 2006 to 2020 using a multilayer network approach. We consider two types of social relationships among journals, based on shared editors (interlocking editorship) and shared authors (interlocking authorship), as well as two forms of intellectual proximity, derived from bibliographic coupling and textual similarity. These four dimensions are integrated using Similarity Network Fusion to produce a unified similarity network from which journal communities are identified. Comparing the field in 2006, 2012, and 2019 reveals a high degree of structural continuity. Our findings suggest that, despite changes in research topics after the crisis, fundamental social and intellectual relationships among journals have remained remarkably stable. Editorial networks, in particular, continue to shape hierarchies and legitimize knowledge production.",
    "source": "arXiv"
  },
  {
    "title": "Constrained free energy minimization for the design of thermal states and stabilizer thermodynamic systems",
    "title_es": "Constrained free energy minimization for the design of thermal states and stabilizer thermodynamic systems",
    "url": "https://arxiv.org/abs/2508.09103",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.09103v1 Announce Type: cross \nAbstract: A quantum thermodynamic system is described by a Hamiltonian and a list of conserved, non-commuting charges, and a fundamental goal is to determine the minimum energy of the system subject to constraints on the charges. Recently, [Liu et al., arXiv:2505.04514] proposed first- and second-order classical and hybrid quantum-classical algorithms for solving a dual chemical potential maximization problem, and they proved that these algorithms converge to global optima by means of gradient-ascent approaches. In this paper, we benchmark these algorithms on several problems of interest in thermodynamics, including one- and two-dimensional quantum Heisenberg models with nearest and next-to-nearest neighbor interactions and with the charges set to the total $x$, $y$, and $z$ magnetizations. We also offer an alternative compelling interpretation of these algorithms as methods for designing ground and thermal states of controllable Hamiltonians, with potential applications in molecular and material design. Furthermore, we introduce stabilizer thermodynamic systems as thermodynamic systems based on stabilizer codes, with the Hamiltonian constructed from a given code's stabilizer operators and the charges constructed from the code's logical operators. We benchmark the aforementioned algorithms on several examples of stabilizer thermodynamic systems, including those constructed from the one-to-three-qubit repetition code, the perfect one-to-five-qubit code, and the two-to-four-qubit error-detecting code. Finally, we observe that the aforementioned hybrid quantum-classical algorithms, when applied to stabilizer thermodynamic systems, can serve as alternative methods for encoding qubits into stabilizer codes at a fixed temperature, and we provide an effective method for warm-starting these encoding algorithms whenever a single qubit is encoded into multiple physical qubits.",
    "source": "arXiv"
  },
  {
    "title": "Simultaneous Go via quantum collapse",
    "title_es": "Simultaneous Go via quantum collapse",
    "url": "https://arxiv.org/abs/1007.3310",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:1007.3310v4 Announce Type: replace \nAbstract: We construct a symmetric, simultaneous, deterministic evolution game $SGo$, which is in a certain mathematical sense a symmetrization of the classical board game Go. $SGo$ is in some ways a simpler game than Go, as Komi, Ko and suicide rules are removed. On the other hand it has similar dynamics and move sensitivity, enabled by certain deterministic ``quantum state'' reduction, so that state evolution is deterministic. Using the argument of Nash, we show that $SGo$ has a mixed equilibrium strategy to draw on average.",
    "source": "arXiv"
  },
  {
    "title": "Quantifying Gender Biases Towards Politicians on Reddit",
    "title_es": "Quantifying Gender Biases Towards Politicians on Reddit",
    "url": "https://arxiv.org/abs/2112.12014",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2112.12014v3 Announce Type: replace \nAbstract: Despite attempts to increase gender parity in politics, global efforts have struggled to ensure equal female representation. This is likely tied to implicit gender biases against women in authority. In this work, we present a comprehensive study of gender biases that appear in online political discussion. To this end, we collect 10 million comments on Reddit in conversations about male and female politicians, which enables an exhaustive study of automatic gender bias detection. We address not only misogynistic language, but also other manifestations of bias, like benevolent sexism in the form of seemingly positive sentiment and dominance attributed to female politicians, or differences in descriptor attribution. Finally, we conduct a multi-faceted study of gender bias towards politicians investigating both linguistic and extra-linguistic cues. We assess 5 different types of gender bias, evaluating coverage, combinatorial, nominal, sentimental, and lexical biases extant in social media language and discourse. Overall, we find that, contrary to previous research, coverage and sentiment biases suggest equal public interest in female politicians. Rather than overt hostile or benevolent sexism, the results of the nominal and lexical analyses suggest this interest is not as professional or respectful as that expressed about male politicians. Female politicians are often named by their first names and are described in relation to their body, clothing, or family; this is a treatment that is not similarly extended to men. On the now banned far-right subreddits, this disparity is greatest, though differences in gender biases still appear in the right and left-leaning subreddits. We release the curated dataset to the public for future studies.",
    "source": "arXiv"
  },
  {
    "title": "On the Origins of Objects by Means of Careful Selection",
    "title_es": "On the Origins of Objects by Means of Careful Selection",
    "url": "https://arxiv.org/abs/2206.02585",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2206.02585v5 Announce Type: replace \nAbstract: We introduce a taxonomy of objects for EO programming language. This taxonomy is designed with a few principles in mind: non-redundancy, simplicity, and so on. The taxonomy is supposed to be used as a navigation map by EO programmers. It may also be helpful as a guideline for designers of other object-oriented languages or libraries for them.",
    "source": "arXiv"
  },
  {
    "title": "Tame Riemannian Stochastic Approximation",
    "title_es": "Tame Riemannian Stochastic Approximation",
    "url": "https://arxiv.org/abs/2302.00709",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2302.00709v5 Announce Type: replace \nAbstract: We study the properties of stochastic approximation applied to a tame nondifferentiable function subject to constraints defined by a Riemannian manifold. The objective landscape of tame functions, arising in o-minimal topology extended to a geometric category when generalized to manifolds, exhibits some structure that enables theoretical guarantees of expected function decrease and asymptotic convergence for generic stochastic sub-gradient descent. Recent work has shown that this class of functions faithfully model the loss landscape of deep neural network training objectives, and the autograd operation used in deep learning packages implements a variant of subgradient descent with the correct properties for convergence. Riemannian optimization uses geometric properties of a constraint set to perform a minimization procedure while enforcing adherence to the the optimization variable lying on a Riemannian manifold. This paper presents the first study of tame optimization on Riemannian manifolds, highlighting the rich geometric structure of the problem and confirming the appropriateness of the canonical \"SGD\" for such a problem with the analysis and numerical reports of a simple Retracted SGD algorithm.",
    "source": "arXiv"
  },
  {
    "title": "Converging to Stability in Two-Sided Bandits: The Case of Unknown Preferences on Both Sides of a Matching Market",
    "title_es": "Converging to Stability in Two-Sided Bandits: The Case of Unknown Preferences on Both Sides of a Matching Market",
    "url": "https://arxiv.org/abs/2302.06176",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2302.06176v4 Announce Type: replace \nAbstract: We study the problem of repeated two-sided matching with uncertain preferences (two-sided bandits), and no explicit communication between agents. Recent work has developed algorithms that converge to stable matchings when one side (the proposers or agents) must learn their preferences, but the preferences of the other side (the proposees or arms) are common knowledge, and the matching mechanism uses simultaneous proposals at each round. We develop new algorithms that provably converge to stable matchings for two more challenging settings: one where the arm preferences are no longer common knowledge, and a second, more general one where the arms are also uncertain about their preferences. In our algorithms, agents start with optimistic beliefs about arms' preferences and update these preferences over time. The key insight is in how to combine these beliefs about arm preferences with beliefs about the value of matching with an arm conditional on one's proposal being accepted when choosing whom to propose to.",
    "source": "arXiv"
  },
  {
    "title": "BELLA: Black box model Explanations by Local Linear Approximations",
    "title_es": "BELLA: Black box model Explanations by Local Linear Approximations",
    "url": "https://arxiv.org/abs/2305.11311",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2305.11311v3 Announce Type: replace \nAbstract: Understanding the decision-making process of black-box models has become not just a legal requirement, but also an additional way to assess their performance. However, the state of the art post-hoc explanation approaches for regression models rely on synthetic data generation, which introduces uncertainty and can hurt the reliability of the explanations. Furthermore, they tend to produce explanations that apply to only very few data points. In this paper, we present BELLA, a deterministic model-agnostic post-hoc approach for explaining the individual predictions of regression black-box models. BELLA provides explanations in the form of a linear model trained in the feature space. BELLA maximizes the size of the neighborhood to which the linear model applies so that the explanations are accurate, simple, general, and robust.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Annotation of Medieval Charters",
    "title_es": "Efficient Annotation of Medieval Charters",
    "url": "https://arxiv.org/abs/2306.14071",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2306.14071v2 Announce Type: replace \nAbstract: Diplomatics, the analysis of medieval charters, is a major field of research in which paleography is applied. Annotating data, if performed by laymen, needs validation and correction by experts. In this paper, we propose an effective and efficient annotation approach for charter segmentation, essentially reducing it to object detection. This approach allows for a much more efficient use of the paleographer's time and produces results that can compete and even outperform pixel-level segmentation in some use cases. Further experiments shed light on how to design a class ontology in order to make the best use of annotators' time and effort. Exploiting the presence of calibration cards in the image, we further annotate the data with the physical length in pixels and train regression neural networks to predict it from image patches.",
    "source": "arXiv"
  },
  {
    "title": "Box2Poly: Memory-Efficient Polygon Prediction of Arbitrarily Shaped and Rotated Text",
    "title_es": "Box2Poly: Memory-Efficient Polygon Prediction of Arbitrarily Shaped and Rotated Text",
    "url": "https://arxiv.org/abs/2309.11248",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2309.11248v2 Announce Type: replace \nAbstract: Recently, Transformer-based text detection techniques have sought to predict polygons by encoding the coordinates of individual boundary vertices using distinct query features. However, this approach incurs a significant memory overhead and struggles to effectively capture the intricate relationships between vertices belonging to the same instance. Consequently, irregular text layouts often lead to the prediction of outlined vertices, diminishing the quality of results. To address these challenges, we present an innovative approach rooted in Sparse R-CNN: a cascade decoding pipeline for polygon prediction. Our method ensures precision by iteratively refining polygon predictions, considering both the scale and location of preceding results. Leveraging this stabilized regression pipeline, even employing just a single feature vector to guide polygon instance regression yields promising detection results. Simultaneously, the leverage of instance-level feature proposal substantially enhances memory efficiency (>50% less vs. the state-of-the-art method DPText-DETR) and reduces inference speed (>40% less vs. DPText-DETR) with minor performance drop on benchmarks.",
    "source": "arXiv"
  },
  {
    "title": "Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes",
    "title_es": "Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes",
    "url": "https://arxiv.org/abs/2309.12658",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2309.12658v2 Announce Type: replace \nAbstract: Deep Gaussian Process (DGP) models offer a powerful nonparametric approach for Bayesian inference, but exact inference is typically intractable, motivating the use of various approximations. However, existing approaches, such as mean-field Gaussian assumptions, limit the expressiveness and efficacy of DGP models, while stochastic approximation can be computationally expensive. To tackle these challenges, we introduce Neural Operator Variational Inference (NOVI) for Deep Gaussian Processes. NOVI uses a neural generator to obtain a sampler and minimizes the Regularized Stein Discrepancy in L2 space between the generated distribution and true posterior. We solve the minimax problem using Monte Carlo estimation and subsampling stochastic optimization techniques. We demonstrate that the bias introduced by our method can be controlled by multiplying the Fisher divergence with a constant, which leads to robust error control and ensures the stability and precision of the algorithm. Our experiments on datasets ranging from hundreds to tens of thousands demonstrate the effectiveness and the faster convergence rate of the proposed method. We achieve a classification accuracy of 93.56 on the CIFAR10 dataset, outperforming SOTA Gaussian process methods. Furthermore, our method guarantees theoretically controlled prediction error for DGP models and demonstrates remarkable performance on various datasets. We are optimistic that NOVI has the potential to enhance the performance of deep Bayesian nonparametric models and could have significant implications for various practical applications",
    "source": "arXiv"
  },
  {
    "title": "SSPFusion: A Semantic Structure-Preserving Approach for Infrared and Visible Image Fusion",
    "title_es": "SSPFusion: A Semantic Structure-Preserving Approach for Infrared and Visible Image Fusion",
    "url": "https://arxiv.org/abs/2309.14745",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2309.14745v3 Announce Type: replace \nAbstract: Most existing learning-based multi-modality image fusion (MMIF) methods suffer from significant structure inconsistency due to their inappropriate usage of structural features at the semantic level. To alleviate these issues, we propose a semantic structure-preserving fusion approach for MMIF, namely SSPFusion. At first, we design a structural feature extractor (SFE) to extract the prominent structural features from multiple input images. Concurrently, we introduce a transformation function with Sobel operator to generate self-supervised structural signals in these extracted features. Subsequently, we design a multi-scale structure-preserving fusion (SPF) module, guided by the generated structural signals, to merge the structural features of input images. This process ensures the preservation of semantic structure consistency between the resultant fusion image and the input images. Through the synergy of these two robust modules of SFE and SPF, our method can generate high-quality fusion images and demonstrate good generalization ability. Experimental results, on both infrared-visible image fusion and medical image fusion tasks, demonstrate that our method outperforms nine state-of-the-art methods in terms of both qualitative and quantitative evaluations. The code is publicly available at https://github.com/QiaoYang-CV/SSPFUSION.",
    "source": "arXiv"
  },
  {
    "title": "Learning Generative Models for Climbing Aircraft from Radar Data",
    "title_es": "Learning Generative Models for Climbing Aircraft from Radar Data",
    "url": "https://arxiv.org/abs/2309.14941",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2309.14941v2 Announce Type: replace \nAbstract: Accurate trajectory prediction (TP) for climbing aircraft is hampered by the presence of epistemic uncertainties concerning aircraft operation, which can lead to significant misspecification between predicted and observed trajectories. This paper proposes a generative model for climbing aircraft in which the standard Base of Aircraft Data (BADA) model is enriched by a functional correction to the thrust that is learned from data. The method offers three features: predictions of the arrival time with 26.7% less error when compared to BADA; generated trajectories that are realistic when compared to test data; and a means of computing confidence bounds for minimal computational cost.",
    "source": "arXiv"
  },
  {
    "title": "Combat Urban Congestion via Collaboration: Heterogeneous GNN-based MARL for Coordinated Platooning and Traffic Signal Control",
    "title_es": "Combat Urban Congestion via Collaboration: Heterogeneous GNN-based MARL for Coordinated Platooning and Traffic Signal Control",
    "url": "https://arxiv.org/abs/2310.10948",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2310.10948v3 Announce Type: replace \nAbstract: Over the years, reinforcement learning has emerged as a popular approach to develop signal control and vehicle platooning strategies either independently or in a hierarchical way. However, jointly controlling both in real-time to alleviate traffic congestion presents new challenges, such as the inherent physical and behavioral heterogeneity between signal control and platooning, as well as coordination between them. This paper proposes an innovative solution to tackle these challenges based on heterogeneous graph multi-agent reinforcement learning and traffic theories. Our approach involves: 1) designing platoon and signal control as distinct reinforcement learning agents with their own set of observations, actions, and reward functions to optimize traffic flow; 2) designing coordination by incorporating graph neural networks within multi-agent reinforcement learning to facilitate seamless information exchange among agents on a regional scale; 3) applying alternating optimization for training, allowing agents to update their own policies and adapt to other agents' policies. We evaluate our approach through SUMO simulations, which show convergent results in terms of both travel time and fuel consumption, and superior performance compared to other adaptive signal control methods.",
    "source": "arXiv"
  },
  {
    "title": "Proofs of NP = coNP = PSPACE: Current upgrade",
    "title_es": "Proofs of NP = coNP = PSPACE: Current upgrade",
    "url": "https://arxiv.org/abs/2311.17939",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2311.17939v2 Announce Type: replace \nAbstract: In this paper we present a more transparent upgrade of our proofs and comment on Jerabek's paper [8] that tried to refute our results by providing exponential lower bounds on the implicational minimal logic.",
    "source": "arXiv"
  },
  {
    "title": "Un-EVIMO: Unsupervised Event-Based Independent Motion Segmentation",
    "title_es": "Un-EVIMO: Unsupervised Event-Based Independent Motion Segmentation",
    "url": "https://arxiv.org/abs/2312.00114",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2312.00114v2 Announce Type: replace \nAbstract: Event cameras are a novel type of biologically inspired vision sensor known for their high temporal resolution, high dynamic range, and low power consumption. Because of these properties, they are well-suited for processing fast motions that require rapid reactions. Although event cameras have recently shown competitive performance in unsupervised optical flow estimation, performance in detecting independently moving objects (IMOs) is lacking behind, although event-based methods would be suited for this task based on their low latency and HDR properties. Previous approaches to event-based IMO segmentation have been heavily dependent on labeled data. However, biological vision systems have developed the ability to avoid moving objects through daily tasks without being given explicit labels. In this work, we propose the first event framework that generates IMO pseudo-labels using geometric constraints. Due to its unsupervised nature, our method can handle an arbitrary number of not predetermined objects and is easily scalable to datasets where expensive IMO labels are not readily available. We evaluate our approach on the EVIMO dataset and show that it performs competitively with supervised methods, both quantitatively and qualitatively.",
    "source": "arXiv"
  },
  {
    "title": "From Lab to Field: Real-World Evaluation of an AI-Driven Smart Video Solution to Enhance Community Safety",
    "title_es": "From Lab to Field: Real-World Evaluation of an AI-Driven Smart Video Solution to Enhance Community Safety",
    "url": "https://arxiv.org/abs/2312.02078",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2312.02078v3 Announce Type: replace \nAbstract: This article adopts and evaluates an AI-enabled Smart Video Solution (SVS) designed to enhance safety in the real world. The system integrates with existing infrastructure camera networks, leveraging recent advancements in AI for easy adoption. Prioritizing privacy and ethical standards, pose based data is used for downstream AI tasks such as anomaly detection. Cloud-based infrastructure and mobile app are deployed, enabling real-time alerts within communities. The SVS employs innovative data representation and visualization techniques, such as the Occupancy Indicator, Statistical Anomaly Detection, Bird's Eye View, and Heatmaps, to understand pedestrian behaviors and enhance public safety. Evaluation of the SVS demonstrates its capacity to convert complex computer vision outputs into actionable insights for stakeholders, community partners, law enforcement, urban planners, and social scientists. This article presents a comprehensive real-world deployment and evaluation of the SVS, implemented in a community college environment across 16 cameras. The system integrates AI-driven visual processing, supported by statistical analysis, database management, cloud communication, and user notifications. Additionally, the article evaluates the end-to-end latency from the moment an AI algorithm detects anomalous behavior in real-time at the camera level to the time stakeholders receive a notification. The results demonstrate the system's robustness, effectively managing 16 CCTV cameras with a consistent throughput of 16.5 frames per second (FPS) over a 21-hour period and an average end-to-end latency of 26.76 seconds between anomaly detection and alert issuance.",
    "source": "arXiv"
  },
  {
    "title": "Keep Your Friends Close: Leveraging Affinity Groups to Accelerate AI Inference Workflows",
    "title_es": "Keep Your Friends Close: Leveraging Affinity Groups to Accelerate AI Inference Workflows",
    "url": "https://arxiv.org/abs/2312.11488",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2312.11488v2 Announce Type: replace \nAbstract: AI inference workflows are typically structured as a pipeline or graph of AI programs triggered by events. As events occur, the AIs perform inference or classification tasks under time pressure to respond or take some action. Standard techniques that reduce latency in other streaming settings (such as caching and optimization-driven scheduling) are of limited value because AI data access patterns (models, databases) change depending on the triggering event: a significant departure from traditional streaming. In this work, we propose a novel affinity grouping mechanism that makes it easier for developers to express application-specific data access correlations, enabling coordinated management of data objects in server clusters hosting streaming inference tasks. Our proposals are thus complementary to other approaches such as caching and scheduling. Experiments confirm the limitations of standard techniques, while showing that the proposed mechanism is able to maintain significantly lower latency as workload and scale-out increase, and yet requires only minor code changes.",
    "source": "arXiv"
  },
  {
    "title": "Whispers in the Machine: Confidentiality in Agentic Systems",
    "title_es": "Whispers in the Machine: Confidentiality in Agentic Systems",
    "url": "https://arxiv.org/abs/2402.06922",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2402.06922v4 Announce Type: replace \nAbstract: The interaction between users and applications is increasingly shifted toward natural language by deploying Large Language Models (LLMs) as the core interface. The capabilities of these so-called agents become more capable the more tools and services they serve as an interface for, ultimately leading to agentic systems. Agentic systems use LLM-based agents as interfaces for most user interactions and various integrations with external tools and services. While these interfaces can significantly enhance the capabilities of the agentic system, they also introduce a new attack surface. Manipulated integrations, for example, can exploit the internal LLM and compromise sensitive data accessed through other interfaces. While previous work primarily focused on attacks targeting a model's alignment or the leakage of training data, the security of data that is only available during inference has escaped scrutiny so far. In this work, we demonstrate how the integration of LLMs into systems with external tool integration poses a risk similar to established prompt-based attacks, able to compromise the confidentiality of the entire system. Introducing a systematic approach to evaluate these confidentiality risks, we identify two specific attack scenarios unique to these agentic systems and formalize these into a tool-robustness framework designed to measure a model's ability to protect sensitive information. Our analysis reveals significant vulnerabilities across all tested models, highlighting an increased risk when models are combined with external tools.",
    "source": "arXiv"
  },
  {
    "title": "HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents",
    "title_es": "HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents",
    "url": "https://arxiv.org/abs/2403.02752",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2403.02752v2 Announce Type: replace \nAbstract: Sensemaking on a large collection of documents (corpus) is a challenging task often found in fields such as market research, legal studies, intelligence analysis, political science, computational linguistics, etc. Previous works approach this problem either from a topic- or entity-based perspective, but they lack interpretability and trust due to poor model alignment. In this paper, we present HINTs, a visual analytics approach that combines topic- and entity-based techniques seamlessly and integrates Large Language Models (LLMs) as both a general NLP task solver and an intelligent agent. By leveraging the extraction capability of LLMs in the data preparation stage, we model the corpus as a hypergraph that matches the user's mental model when making sense of the corpus. The constructed hypergraph is hierarchically organized with an agglomerative clustering algorithm by combining semantic and connectivity similarity. The system further integrates an LLM-based intelligent chatbot agent in the interface to facilitate sensemaking. To demonstrate the generalizability and effectiveness of the HINTs system, we present two case studies on different domains and a comparative user study. We report our insights on the behavior patterns and challenges when intelligent agents are used to facilitate sensemaking. We find that while intelligent agents can address many challenges in sensemaking, the visual hints that visualizations provide are necessary to address the new problems brought by intelligent agents. We discuss limitations and future work for combining interactive visualization and LLMs more profoundly to better support corpus analysis.",
    "source": "arXiv"
  },
  {
    "title": "AIOS: LLM Agent Operating System",
    "title_es": "AIOS: LLM Agent Operating System",
    "url": "https://arxiv.org/abs/2403.16971",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2403.16971v5 Announce Type: replace \nAbstract: LLM-based intelligent agents face significant deployment challenges, particularly related to resource management. Allowing unrestricted access to LLM or tool resources can lead to inefficient or even potentially harmful resource allocation and utilization for agents. Furthermore, the absence of proper scheduling and resource management mechanisms in current agent designs hinders concurrent processing and limits overall system efficiency. To address these challenges, this paper proposes the architecture of AIOS (LLM-based AI Agent Operating System) under the context of managing LLM-based agents. It introduces a novel architecture for serving LLM-based agents by isolating resources and LLM-specific services from agent applications into an AIOS kernel. This AIOS kernel provides fundamental services (e.g., scheduling, context management, memory management, storage management, access control) for runtime agents. To enhance usability, AIOS also includes an AIOS SDK, a comprehensive suite of APIs designed for utilizing functionalities provided by the AIOS kernel. Experimental results demonstrate that using AIOS can achieve up to 2.1x faster execution for serving agents built by various agent frameworks. The source code is available at https://github.com/agiresearch/AIOS.",
    "source": "arXiv"
  },
  {
    "title": "Puzzle Game: Prediction and Classification of Wordle Solution Words",
    "title_es": "Puzzle Game: Prediction and Classification of Wordle Solution Words",
    "url": "https://arxiv.org/abs/2403.19433",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2403.19433v4 Announce Type: replace \nAbstract: We study the prediction and classification of Wordle solution words. After cleaning the public results log, we fit an ARIMA model to forecast the daily volume of reported outcomes through March 1, 2023. For each solution word, we compute three interpretable attributes: usage frequency (FREQ), word information entropy (WIE), and the number of repeated letters (NRE), and analyze their correlations with the empirical attempt distribution (1-6 attempts plus failure, coded as 7). We then train an XGBoost regressor to predict the full 1-7 outcome distribution for unseen words; a case study of \"EERIE\" illustrates the model's behavior. To categorize difficulty, we cluster words into three tiers (simple, moderate, difficult) via K-means and train a decision-tree classifier that maps FREQ, WIE, and NRE to these tiers, yielding interpretable rules. For each word, we also report the share of players requiring three or more attempts. Sensitivity analyses and full modeling details are provided in the appendix.",
    "source": "arXiv"
  },
  {
    "title": "Multidimensional Adaptive Coefficient for Inference Trajectory Optimization in Flow and Diffusion",
    "title_es": "Multidimensional Adaptive Coefficient for Inference Trajectory Optimization in Flow and Diffusion",
    "url": "https://arxiv.org/abs/2404.14161",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2404.14161v4 Announce Type: replace \nAbstract: Flow and diffusion models have demonstrated strong performance and training stability across various tasks but lack two critical properties of simulation-based methods: freedom of dimensionality and adaptability to different inference trajectories. To address this limitation, we propose the Multidimensional Adaptive Coefficient (MAC), a plug-in module for flow and diffusion models that extends conventional unidimensional coefficients to multidimensional ones and enables inference trajectory-wise adaptation. MAC is trained via simulation-based feedback through adversarial refinement. Empirical results across diverse frameworks and datasets demonstrate that MAC enhances generative quality with high training efficiency. Consequently, our work offers a new perspective on inference trajectory optimality, encouraging future research to move beyond vector field design and to leverage training-efficient, simulation-based optimization.",
    "source": "arXiv"
  },
  {
    "title": "Utilizing Large Language Models for Information Extraction from Real Estate Transactions",
    "title_es": "Utilizing Large Language Models for Information Extraction from Real Estate Transactions",
    "url": "https://arxiv.org/abs/2404.18043",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2404.18043v3 Announce Type: replace \nAbstract: Real estate sales contracts contain crucial information for property transactions, but manual data extraction can be time-consuming and error-prone. This paper explores the application of large language models, specifically transformer-based architectures, for automated information extraction from real estate contracts. We discuss challenges, techniques, and future directions in leveraging these models to improve efficiency and accuracy in real estate contract analysis. We generated synthetic contracts using the real-world transaction dataset, thereby fine-tuning the large-language model and achieving significant metrics improvements and qualitative improvements in information retrieval and reasoning tasks.",
    "source": "arXiv"
  },
  {
    "title": "What Foundation Models can Bring for Robot Learning in Manipulation : A Survey",
    "title_es": "What Foundation Models can Bring for Robot Learning in Manipulation : A Survey",
    "url": "https://arxiv.org/abs/2404.18201",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2404.18201v5 Announce Type: replace \nAbstract: The realization of universal robots is an ultimate goal of researchers. However, a key hurdle in achieving this goal lies in the robots' ability to manipulate objects in their unstructured surrounding environments according to different tasks. The learning-based approach is considered an effective way to address generalization. The impressive performance of foundation models in the fields of computer vision and natural language suggests the potential of embedding foundation models into manipulation tasks as a viable path toward achieving general manipulation capability. However, we believe achieving general manipulation capability requires an overarching framework akin to auto driving. This framework should encompass multiple functional modules, with different foundation models assuming distinct roles in facilitating general manipulation capability. This survey focuses on the contributions of foundation models to robot learning for manipulation. We propose a comprehensive framework and detail how foundation models can address challenges in each module of the framework. What's more, we examine current approaches, outline challenges, suggest future research directions, and identify potential risks associated with integrating foundation models into this domain.",
    "source": "arXiv"
  },
  {
    "title": "Solving unification in the description logic $\\mathcal{FL}_\\bot$",
    "title_es": "Solving unification in the description logic $\\mathcal{FL}_\\bot$",
    "url": "https://arxiv.org/abs/2405.00912",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2405.00912v5 Announce Type: replace \nAbstract: We present an algorithm for solving the unification problem in the description logic $\\mathcal{FL}_\\bot$. This logic extends $\\mathcal{FL}_0$ with the bottom constructor, and thus supports conjunction, value restrictions, top and bottom constructors. Unification of concepts can be a useful tool for ontology maintenance; however, little is known about unification even in small, restricted description logics. The unification problem has been solved only for $\\mathcal{FL}_0$ and $\\mathcal{EL}$. This paper contributes to the ongoing effort to extend these results to richer logics. Our algorithm runs in exponential time with respect to the size of the problem.",
    "source": "arXiv"
  },
  {
    "title": "Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES)",
    "title_es": "Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES)",
    "url": "https://arxiv.org/abs/2405.01354",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2405.01354v3 Announce Type: replace \nAbstract: Understanding user enjoyment is crucial in human-robot interaction (HRI), as it can impact interaction quality and influence user acceptance and long-term engagement with robots, particularly in the context of conversations with social robots. However, current assessment methods rely solely on self-reported questionnaires, failing to capture interaction dynamics. This work introduces the Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES), a novel 5-point scale to assess user enjoyment from an external perspective (e.g. by an annotator) for conversations with a robot. The scale was developed through rigorous evaluations and discussions among three annotators with relevant expertise, using open-domain conversations with a companion robot that was powered by a large language model, and was applied to each conversation exchange (i.e. a robot-participant turn pair) alongside overall interaction. It was evaluated on 25 older adults' interactions with the companion robot, corresponding to 174 minutes of data, showing moderate to good alignment between annotators. Although the scale was developed and tested in the context of older adult interactions with a robot, its basis in general and non-task-specific indicators of enjoyment supports its broader applicability. The study further offers insights into understanding the nuances and challenges of assessing user enjoyment in robot interactions, and provides guidelines on applying the scale to other domains and populations. The dataset is available online.",
    "source": "arXiv"
  },
  {
    "title": "Synthesizing JSON Schema Transformers",
    "title_es": "Synthesizing JSON Schema Transformers",
    "url": "https://arxiv.org/abs/2405.17681",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2405.17681v2 Announce Type: replace \nAbstract: JSON (JavaScript Object Notation) is a data encoding that allows structured data to be used in a standardized and straightforward manner across systems. Schemas for JSON-formatted data can be constructed using the JSON Schema standard, which describes the data types, structure, and meaning of JSON-formatted data. JSON is commonly used for storing and transmitting information such as program configurations, web API requests and responses, or remote procedure calls; or data records, such as healthcare information or other structured documents. Since JSON is a plaintext format with potentially highly complex definitions, it can be an arduous process to change code which handles structured JSON data when its storage or transmission schemas are modified. Our work describes a program synthesis method to generate a program that accepts data conforming to a given input JSON Schema and automatically converts it to conform to a resulting, target JSON Schema. We use a top-down, type-directed approach to search for programs using a set of rewrite rules which constrain the ways in which a schema can be modified without unintended data loss or corruption. Once a satisfying sequence of rewrites has been found, we pass an intermediate representation of the rewrite sequence to a code generation backend, which synthesizes a program which executes the data transformation. This system allows users to quickly and efficiently modify or augment their existing systems in safe ways at their interfaces.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating lightweight unsupervised online IDS for masquerade attacks in CAN",
    "title_es": "Evaluating lightweight unsupervised online IDS for masquerade attacks in CAN",
    "url": "https://arxiv.org/abs/2406.13778",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2406.13778v3 Announce Type: replace \nAbstract: Vehicular controller area networks (CANs) are susceptible to masquerade attacks by malicious adversaries. In masquerade attacks, adversaries silence a targeted ID and then send malicious frames with forged content at the expected timing of benign frames. As masquerade attacks could seriously harm vehicle functionality and are the stealthiest attacks to detect in CAN, recent work has devoted attention to compare frameworks for detecting masquerade attacks in CAN. However, most existing works report offline evaluations using CAN logs already collected using simulations that do not comply with the domain's real-time constraints. Here we contribute to advance the state of the art by presenting a comparative evaluation of four different non-deep learning (DL)-based unsupervised online intrusion detection systems (IDS) for masquerade attacks in CAN. Our approach differs from existing comparative evaluations in that we analyze the effect of controlling streaming data conditions in a sliding window setting. In doing so, we use realistic masquerade attacks being replayed from the ROAD dataset. We show that although evaluated IDS are not effective at detecting every attack type, the method that relies on detecting changes in the hierarchical structure of clusters of time series produces the best results at the expense of higher computational overhead. We discuss limitations, open challenges, and how the evaluated methods can be used for practical unsupervised online CAN IDS for masquerade attacks.",
    "source": "arXiv"
  },
  {
    "title": "PointDreamer: Zero-shot 3D Textured Mesh Reconstruction from Colored Point Cloud",
    "title_es": "PointDreamer: Zero-shot 3D Textured Mesh Reconstruction from Colored Point Cloud",
    "url": "https://arxiv.org/abs/2406.15811",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2406.15811v3 Announce Type: replace \nAbstract: Faithfully reconstructing textured meshes is crucial for many applications. Compared to text or image modalities, leveraging 3D colored point clouds as input (colored-PC-to-mesh) offers inherent advantages in comprehensively and precisely replicating the target object's 360{\\deg} characteristics. While most existing colored-PC-to-mesh methods suffer from blurry textures or require hard-to-acquire 3D training data, we propose PointDreamer, a novel framework that harnesses 2D diffusion prior for superior texture quality. Crucially, unlike prior 2D-diffusion-for-3D works driven by text or image inputs, PointDreamer successfully adapts 2D diffusion models to 3D point cloud data by a novel project-inpaint-unproject pipeline. Specifically, it first projects the point cloud into sparse 2D images and then performs diffusion-based inpainting. After that, diverging from most existing 3D reconstruction or generation approaches that predict texture in 3D/UV space thus often yielding blurry texture, PointDreamer achieves high-quality texture by directly unprojecting the inpainted 2D images to the 3D mesh. Furthermore, we identify for the first time a typical kind of unprojection artifact appearing in occlusion borders, which is common in other multiview-image-to-3D pipelines but less-explored. To address this, we propose a novel solution named the Non-Border-First (NBF) unprojection strategy. Extensive qualitative and quantitative experiments on various synthetic and real-scanned datasets demonstrate that PointDreamer, though zero-shot, exhibits SoTA performance (30% improvement on LPIPS score from 0.118 to 0.068), and is robust to noisy, sparse, or even incomplete input data. Code at: https://github.com/YuQiao0303/PointDreamer.",
    "source": "arXiv"
  },
  {
    "title": "MEReQ: Max-Ent Residual-Q Inverse RL for Sample-Efficient Alignment from Intervention",
    "title_es": "MEReQ: Max-Ent Residual-Q Inverse RL for Sample-Efficient Alignment from Intervention",
    "url": "https://arxiv.org/abs/2406.16258",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2406.16258v3 Announce Type: replace \nAbstract: Aligning robot behavior with human preferences is crucial for deploying embodied AI agents in human-centered environments. A promising solution is interactive imitation learning from human intervention, where a human expert observes the policy's execution and provides interventions as feedback. However, existing methods often fail to utilize the prior policy efficiently to facilitate learning, thus hindering sample efficiency. In this work, we introduce MEReQ (Maximum-Entropy Residual-Q Inverse Reinforcement Learning), designed for sample-efficient alignment from human intervention. Instead of inferring the complete human behavior characteristics, MEReQ infers a residual reward function that captures the discrepancy between the human expert's and the prior policy's underlying reward functions. It then employs Residual Q-Learning (RQL) to align the policy with human preferences using this residual reward function. Extensive evaluations on simulated and real-world tasks demonstrate that MEReQ achieves sample-efficient policy alignment from human intervention.",
    "source": "arXiv"
  },
  {
    "title": "Beamforming Design for Joint Target Sensing and Proactive Eavesdropping",
    "title_es": "Beamforming Design for Joint Target Sensing and Proactive Eavesdropping",
    "url": "https://arxiv.org/abs/2407.06521",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2407.06521v3 Announce Type: replace \nAbstract: This work studies the beamforming design in the joint target sensing and proactive eavesdropping (JTSAPE) system. The JTSAPE base station (BS) receives the information transmitted by the illegal transmitter and transmits the waveform for target sensing. The shared waveform also serves as artificial noise to interfere with the illegal receiver, thereby achieving proactive eavesdropping. We firstly optimize the transmitting beam of the BS to maximize the eavesdropping signal-to-interference-plus-noise ratio or minimize the target estimation parameter Cram{\\'{e}}r-Rao bound, respectively. Then, the joint optimization of proactive eavesdropping and target sensing is investigated, and the normalized weighted optimization problem is formulated. To address the complexity of the original problem, the formulated problem is decomposed into two subproblems: proactive eavesdropping and target sensing, which are solved by the semi-definite relaxation technique. Furthermore, the scenario in which the quality of the eavesdropping channel is stronger than that of the illegal channel is considered. We utilize the sequential rank-one constraint relaxation method and iteration technique to obtain the high-quality suboptimal solution of the beam transmit covariance matrix. Numerical simulation shows the effectiveness of our proposed algorithm.",
    "source": "arXiv"
  },
  {
    "title": "DreamStory: Open-Domain Story Visualization by LLM-Guided Multi-Subject Consistent Diffusion",
    "title_es": "DreamStory: Open-Domain Story Visualization by LLM-Guided Multi-Subject Consistent Diffusion",
    "url": "https://arxiv.org/abs/2407.12899",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2407.12899v3 Announce Type: replace \nAbstract: Story visualization aims to create visually compelling images or videos corresponding to textual narratives. Despite recent advances in diffusion models yielding promising results, existing methods still struggle to create a coherent sequence of subject-consistent frames based solely on a story. To this end, we propose DreamStory, an automatic open-domain story visualization framework by leveraging the LLMs and a novel multi-subject consistent diffusion model. DreamStory consists of (1) an LLM acting as a story director and (2) an innovative Multi-Subject consistent Diffusion model (MSD) for generating consistent multi-subject across the images. First, DreamStory employs the LLM to generate descriptive prompts for subjects and scenes aligned with the story, annotating each scene's subjects for subsequent subject-consistent generation. Second, DreamStory utilizes these detailed subject descriptions to create portraits of the subjects, with these portraits and their corresponding textual information serving as multimodal anchors (guidance). Finally, the MSD uses these multimodal anchors to generate story scenes with consistent multi-subject. Specifically, the MSD includes Masked Mutual Self-Attention (MMSA) and Masked Mutual Cross-Attention (MMCA) modules. MMSA and MMCA modules ensure appearance and semantic consistency with reference images and text, respectively. Both modules employ masking mechanisms to prevent subject blending. To validate our approach and promote progress in story visualization, we established a benchmark, DS-500, which can assess the overall performance of the story visualization framework, subject-identification accuracy, and the consistency of the generation model. Extensive experiments validate the effectiveness of DreamStory in both subjective and objective evaluations. Please visit our project homepage at https://dream-xyz.github.io/dreamstory.",
    "source": "arXiv"
  },
  {
    "title": "Exploring the Evidence-Based SE Beliefs of Generative AI Tools",
    "title_es": "Exploring the Evidence-Based SE Beliefs of Generative AI Tools",
    "url": "https://arxiv.org/abs/2407.13900",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2407.13900v5 Announce Type: replace \nAbstract: Background: Recent innovations in generative artificial intelligence (AI) have transformed how programmers develop and maintain software. The advanced capabilities of generative AI tools in supporting development tasks have led to a rise in their adoption within software engineering (SE) workflows. However, little is known about how AI tools perceive evidence-based practices supported by empirical SE research. Aim: To this end, we explore the \"beliefs\" of generative AI tools increasingly used to support software development in practice. Method: We conduct a preliminary evaluation conceptually replicating prior work to investigate 17 evidence-based claims across five generative AI tools. Results: Our findings demonstrate generative AI tools have ambiguous beliefs regarding research claims and lack credible evidence to support responses. Conclusions: Based on our results, we provide implications for practitioners integrating generative AI-based systems into development contexts and shed light on future research directions to enhance the reliability and trustworthiness of generative AI -- aiming to increase awareness and adoption of evidence-based SE research findings in practice.",
    "source": "arXiv"
  },
  {
    "title": "Vision-Based Adaptive Robotics for Autonomous Surface Crack Repair",
    "title_es": "Vision-Based Adaptive Robotics for Autonomous Surface Crack Repair",
    "url": "https://arxiv.org/abs/2407.16874",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2407.16874v3 Announce Type: replace \nAbstract: Surface cracks in infrastructure can lead to severe deterioration and expensive maintenance if not efficiently repaired. Manual repair methods are labor-intensive, time-consuming, and imprecise. While advancements in robotic perception and manipulation have progressed autonomous crack repair, three key challenges remain: accurate localization in the robot's coordinate frame, adaptability to varying crack sizes, and realistic validation of repairs. We present an adaptive, autonomous robotic system for surface crack detection and repair using advanced sensing technologies to enhance precision and safety for humans. A laser scanner is used to refine crack coordinates for accurate localization. Furthermore, our adaptive crack filling approach outperforms fixed speed techniques in efficiency and consistency. We validate our method using 3D printed cracks under realistic conditions, demonstrating repeatable testing. This research contributes to the field of human-robot interaction by reducing manual labor, improving safety, and streamlining maintenance operations, ultimately paving the way for more sophisticated and integrated construction robotics.",
    "source": "arXiv"
  },
  {
    "title": "OE3DIS: Open-Ended 3D Point Cloud Instance Segmentation",
    "title_es": "OE3DIS: Open-Ended 3D Point Cloud Instance Segmentation",
    "url": "https://arxiv.org/abs/2408.11747",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2408.11747v2 Announce Type: replace \nAbstract: Open-Vocab 3D Instance Segmentation methods (OV-3DIS) have recently demonstrated their ability to generalize to unseen objects. However, these methods still depend on predefined class names during testing, restricting the autonomy of agents. To mitigate this constraint, we propose a novel problem termed Open-Ended 3D Instance Segmentation (OE-3DIS), which eliminates the necessity for predefined class names during testing. Moreover, we contribute a comprehensive set of strong baselines, derived from OV-3DIS approaches and leveraging 2D Multimodal Large Language Models. To assess the performance of our OE-3DIS system, we introduce a novel Open-Ended score, evaluating both the semantic and geometric quality of predicted masks and their associated class names, alongside the standard AP score. Our approach demonstrates significant performance improvements over the baselines on the ScanNet200 and ScanNet++ datasets. Remarkably, our method surpasses the performance of Open3DIS, the current state-of-the-art method in OV-3DIS, even in the absence of ground-truth object class names.",
    "source": "arXiv"
  },
  {
    "title": "A DNN Biophysics Model with Topological and Electrostatic Features",
    "title_es": "A DNN Biophysics Model with Topological and Electrostatic Features",
    "url": "https://arxiv.org/abs/2409.03658",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2409.03658v2 Announce Type: replace \nAbstract: In this project, we provide a deep-learning neural network (DNN) based biophysics model to predict protein properties. The model uses multi-scale and uniform topological and electrostatic features generated with protein structural information and force field, which governs the molecular mechanics. The topological features are generated using the element specified persistent homology (ESPH) while the electrostatic features are fast computed using a Cartesian treecode. These features are uniform in number for proteins with various sizes thus the broadly available protein structure database can be used in training the network. These features are also multi-scale thus the resolution and computational cost can be balanced by the users. The machine learning simulation on over 4000 protein structures shows the efficiency and fidelity of these features in representing the protein structure and force field for the predication of their biophysical properties such as electrostatic solvation energy. Tests on topological or electrostatic features alone and the combination of both showed the optimal performance when both features are used. This model shows its potential as a general tool in assisting biophysical properties and function prediction for the broad biomolecules using data from both theoretical computing and experiments.",
    "source": "arXiv"
  },
  {
    "title": "Robust optimal design of large-scale Bayesian nonlinear inverse problems",
    "title_es": "Robust optimal design of large-scale Bayesian nonlinear inverse problems",
    "url": "https://arxiv.org/abs/2409.09137",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2409.09137v2 Announce Type: replace \nAbstract: We consider robust optimal experimental design (ROED) for nonlinear Bayesian inverse problems governed by partial differential equations (PDEs). An optimal design is one that maximizes some utility quantifying the quality of the solution of an inverse problem. However, the optimal design is dependent on elements of the inverse problem such as the simulation model, the prior, or the measurement error model. ROED aims to produce an optimal design that is aware of the additional uncertainties encoded in the inverse problem and remains optimal even after variations in them. We follow a worst-case scenario approach to develop a new framework for robust optimal design of nonlinear Bayesian inverse problems. The proposed framework a) is scalable and designed for infinite-dimensional Bayesian nonlinear inverse problems constrained by PDEs; b) develops efficient approximations of the utility, namely, the expected information gain; c) employs eigenvalue sensitivity techniques to develop analytical forms and efficient evaluation methods of the gradient of the utility with respect to the uncertainties we wish to be robust against; and d) employs a probabilistic optimization paradigm that properly defines and efficiently solves the resulting combinatorial max-min optimization problem. The effectiveness of the proposed approach is illustrated for optimal sensor placement problem in an inverse problem governed by an elliptic PDE.",
    "source": "arXiv"
  },
  {
    "title": "3DFacePolicy: Audio-Driven 3D Facial Animation Based on Action Control",
    "title_es": "3DFacePolicy: Audio-Driven 3D Facial Animation Based on Action Control",
    "url": "https://arxiv.org/abs/2409.10848",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2409.10848v2 Announce Type: replace \nAbstract: Audio-driven 3D facial animation has achieved significant progress in both research and applications. While recent baselines struggle to generate natural and continuous facial movements due to their frame-by-frame vertex generation approach, we propose 3DFacePolicy, a pioneer work that introduces a novel definition of vertex trajectory changes across consecutive frames through the concept of \"action\". By predicting action sequences for each vertex that encode frame-to-frame movements, we reformulate vertex generation approach into an action-based control paradigm. Specifically, we leverage a robotic control mechanism, diffusion policy, to predict action sequences conditioned on both audio and vertex states. Extensive experiments on VOCASET and BIWI datasets demonstrate that our approach significantly outperforms state-of-the-art methods and is particularly expert in dynamic, expressive and naturally smooth facial animations.",
    "source": "arXiv"
  },
  {
    "title": "Hypergraph-based Motion Generation with Multi-modal Interaction Relational Reasoning",
    "title_es": "Hypergraph-based Motion Generation with Multi-modal Interaction Relational Reasoning",
    "url": "https://arxiv.org/abs/2409.11676",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2409.11676v2 Announce Type: replace \nAbstract: The intricate nature of real-world driving environments, characterized by dynamic and diverse interactions among multiple vehicles and their possible future states, presents considerable challenges in accurately predicting the motion states of vehicles and handling the uncertainty inherent in the predictions. Addressing these challenges requires comprehensive modeling and reasoning to capture the implicit relations among vehicles and the corresponding diverse behaviors. This research introduces an integrated framework for autonomous vehicles (AVs) motion prediction to address these complexities, utilizing a novel Relational Hypergraph Interaction-informed Neural mOtion generator (RHINO). RHINO leverages hypergraph-based relational reasoning by integrating a multi-scale hypergraph neural network to model group-wise interactions among multiple vehicles and their multi-modal driving behaviors, thereby enhancing motion prediction accuracy and reliability. Experimental validation using real-world datasets demonstrates the superior performance of this framework in improving predictive accuracy and fostering socially aware automated driving in dynamic traffic scenarios. The source code is publicly available at https://github.com/keshuw95/RHINO-Hypergraph-Motion-Generation.",
    "source": "arXiv"
  },
  {
    "title": "Task Diversity Shortens the ICL Plateau",
    "title_es": "Task Diversity Shortens the ICL Plateau",
    "url": "https://arxiv.org/abs/2410.05448",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.05448v3 Announce Type: replace \nAbstract: In-context learning (ICL) describes a language model's ability to generate outputs based on a set of input demonstrations and a subsequent query. To understand this remarkable capability, researchers have studied simplified, stylized models. These studies have consistently observed long loss plateaus, during which models exhibit minimal improvement, followed by a sudden, rapid surge of learning. In this work, we reveal that training on multiple diverse ICL tasks simultaneously shortens the loss plateaus, making each task easier to learn. This finding is surprising as it contradicts the natural intuition that the combined complexity of multiple ICL tasks would lengthen the learning process, not shorten it. Our result suggests that the recent success in large-scale training of language models may be attributed not only to the richness of the data at scale but also to the easier optimization (training) induced by the diversity of natural language training data.",
    "source": "arXiv"
  },
  {
    "title": "From Pixels to Tokens: Revisiting Object Hallucinations in Large Vision-Language Models",
    "title_es": "From Pixels to Tokens: Revisiting Object Hallucinations in Large Vision-Language Models",
    "url": "https://arxiv.org/abs/2410.06795",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.06795v2 Announce Type: replace \nAbstract: Hallucinations in large vision-language models (LVLMs) are a significant challenge, i.e., generating objects that are not presented in the visual input, which impairs their reliability. Recent studies often attribute hallucinations to a lack of understanding of visual input, yet ignore a more fundamental issue: the model's inability to effectively extract or decouple visual features. In this paper, we revisit the hallucinations in LVLMs from an architectural perspective, investigating whether the primary cause lies in the visual encoder (feature extraction) or the modal alignment module (feature decoupling). Motivated by our findings on the preliminary investigation, we propose a novel tuning strategy, PATCH, to mitigate hallucinations in LVLMs. This plug-and-play method can be integrated into various LVLMs, utilizing adaptive virtual tokens to extract object features from bounding boxes, thereby addressing hallucinations caused by insufficient decoupling of visual features. PATCH achieves state-of-the-art performance on multiple multi-modal hallucination datasets. We hope this approach provides researchers with deeper insights into the underlying causes of hallucinations in LVLMs, fostering further advancements and innovation in this field.",
    "source": "arXiv"
  },
  {
    "title": "Zero-Shot Generalization of Vision-Based RL Without Data Augmentation",
    "title_es": "Zero-Shot Generalization of Vision-Based RL Without Data Augmentation",
    "url": "https://arxiv.org/abs/2410.07441",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.07441v2 Announce Type: replace \nAbstract: Generalizing vision-based reinforcement learning (RL) agents to novel environments remains a difficult and open challenge. Current trends are to collect large-scale datasets or use data augmentation techniques to prevent overfitting and improve downstream generalization. However, the computational and data collection costs increase exponentially with the number of task variations and can destabilize the already difficult task of training RL agents. In this work, we take inspiration from recent advances in computational neuroscience and propose a model, Associative Latent DisentAnglement (ALDA), that builds on standard off-policy RL towards zero-shot generalization. Specifically, we revisit the role of latent disentanglement in RL and show how combining it with a model of associative memory achieves zero-shot generalization on difficult task variations without relying on data augmentation. Finally, we formally show that data augmentation techniques are a form of weak disentanglement and discuss the implications of this insight.",
    "source": "arXiv"
  },
  {
    "title": "Fast Mixed-Precision Real Evaluation",
    "title_es": "Fast Mixed-Precision Real Evaluation",
    "url": "https://arxiv.org/abs/2410.07468",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.07468v3 Announce Type: replace \nAbstract: Evaluating real-valued expressions to high precision is a key building block in computational mathematics, physics, and numerics. A typical implementation evaluates the whole expression in a uniform precision, doubling that precision until a sufficiently-accurate result is achieved. This is wasteful: usually only a few operations really need to be performed at high precision, and the bulk of the expression could be computed much faster. However, such non-uniform precision assignments have, to date, been impractical to compute. We propose a fast new algorithm for deriving such precision assignments. The algorithm leverages results computed at lower precisions to analytically determine a mixed-precision assignment that will result in a sufficiently-accurate result. Our implementation, Reval, achieves an average speed-up of 1.72x compared to the state-of-the-art Sollya tool, with the speed-up increasing to 5.21x on the most difficult input points. An examination of the precisions used with and without precision tuning shows that the speed-up results from assigning lower precisions for the majority of operations, though additional optimizations enabled by the non-uniform precision assignments also play a role.",
    "source": "arXiv"
  },
  {
    "title": "System~2 Reasoning for Human--AI Alignment: Generality and Adaptivity via ARC-AGI",
    "title_es": "System~2 Reasoning for Human--AI Alignment: Generality and Adaptivity via ARC-AGI",
    "url": "https://arxiv.org/abs/2410.07866",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.07866v4 Announce Type: replace \nAbstract: Despite their broad applicability, transformer-based models still fall short in System~2 reasoning, lacking the generality and adaptivity needed for human--AI alignment. We examine weaknesses on ARC-AGI tasks, revealing gaps in compositional generalization and novel-rule adaptation, and argue that closing these gaps requires overhauling the reasoning pipeline and its evaluation. We propose three research axes: (1) Symbolic representation pipeline for compositional generality, (2) Interactive feedback-driven reasoning loop for adaptivity, and (3) Test-time task augmentation balancing both qualities. Finally, we demonstrate how ARC-AGI's evaluation suite can be adapted to track progress in symbolic generality, feedback-driven adaptivity, and task-level robustness, thereby guiding future work on robust human--AI alignment.",
    "source": "arXiv"
  },
  {
    "title": "SynFER: Towards Boosting Facial Expression Recognition with Synthetic Data",
    "title_es": "SynFER: Towards Boosting Facial Expression Recognition with Synthetic Data",
    "url": "https://arxiv.org/abs/2410.09865",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.09865v3 Announce Type: replace \nAbstract: Facial expression datasets remain limited in scale due to the subjectivity of annotations and the labor-intensive nature of data collection. This limitation poses a significant challenge for developing modern deep learning-based facial expression analysis models, particularly foundation models, that rely on large-scale data for optimal performance. To tackle the overarching and complex challenge, instead of introducing a new large-scale dataset, we introduce SynFER (Synthesis of Facial Expressions with Refined Control), a novel synthetic framework for synthesizing facial expression image data based on high-level textual descriptions as well as more fine-grained and precise control through facial action units. To ensure the quality and reliability of the synthetic data, we propose a semantic guidance technique to steer the generation process and a pseudo-label generator to help rectify the facial expression labels for the synthetic images. To demonstrate the generation fidelity and the effectiveness of the synthetic data from SynFER, we conduct extensive experiments on representation learning using both synthetic data and real-world data. Results validate the efficacy of our approach and the synthetic data. Notably, our approach achieves a 67.23% classification accuracy on AffectNet when training solely with synthetic data equivalent to the AffectNet training set size, which increases to 69.84% when scaling up to five times the original size. Code is available here.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on All-in-One Image Restoration: Taxonomy, Evaluation and Future Trends",
    "title_es": "A Survey on All-in-One Image Restoration: Taxonomy, Evaluation and Future Trends",
    "url": "https://arxiv.org/abs/2410.15067",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.15067v3 Announce Type: replace \nAbstract: Image restoration (IR) seeks to recover high-quality images from degraded observations caused by a wide range of factors, including noise, blur, compression, and adverse weather. While traditional IR methods have made notable progress by targeting individual degradation types, their specialization often comes at the cost of generalization, leaving them ill-equipped to handle the multifaceted distortions encountered in real-world applications. In response to this challenge, the all-in-one image restoration (AiOIR) paradigm has recently emerged, offering a unified framework that adeptly addresses multiple degradation types. These innovative models enhance the convenience and versatility by adaptively learning degradation-specific features while simultaneously leveraging shared knowledge across diverse corruptions. In this survey, we provide the first in-depth and systematic overview of AiOIR, delivering a structured taxonomy that categorizes existing methods by architectural designs, learning paradigms, and their core innovations. We systematically categorize current approaches and assess the challenges these models encounter, outlining research directions to propel this rapidly evolving field. To facilitate the evaluation of existing methods, we also consolidate widely-used datasets, evaluation protocols, and implementation practices, and compare and summarize the most advanced open-source models. As the first comprehensive review dedicated to AiOIR, this paper aims to map the conceptual landscape, synthesize prevailing techniques, and ignite further exploration toward more intelligent, unified, and adaptable visual restoration systems. A curated code repository is available at https://github.com/Harbinzzy/All-in-One-Image-Restoration-Survey.",
    "source": "arXiv"
  },
  {
    "title": "Multi-modal Policies with Physics-informed Representations in Complex Fluid Environments",
    "title_es": "Multi-modal Policies with Physics-informed Representations in Complex Fluid Environments",
    "url": "https://arxiv.org/abs/2410.15250",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.15250v2 Announce Type: replace \nAbstract: Control in fluid environments is an important research area with numerous applications across various domains, including underwater robotics, aerospace engineering, and biomedical systems. However, in practice, control methods often face challenges due to sparse or missing observations, stemming from sensor limitations and faults. These issues result in observations that are not only sparse but also inconsistent in their number and modalities (e.g., velocity and pressure sensors). In this work, we propose a Physics-Informed Representation (PIR) algorithm for multi-modal policies of control to leverage the sparse and random observations in complex fluid environments. PIR integrates sparse observational data with the Partial Differential Equation (PDE) information to distill a unified representation of fluid systems. The main idea is that PDE solutions are determined by three elements: the equation, initial conditions, and boundary conditions. Given the equation, we only need to learn the representation of the initial and boundary conditions, which define a trajectory of a specific fluid system. Specifically, it leverages PDE loss to fit the neural network and data loss calculated on the observations with random quantities and multi-modalities to propagate the information with initial and boundary conditions into the representations. The representations are the learnable parameters or the output of the encoder. In the experiments, the PIR illustrates the superior consistency with the features of the ground truth compared with baselines, even when there are missing modalities. Furthermore, PIR combined with Reinforcement Learning has been successfully applied in control tasks where the robot leverages the learned state by PIR faster and more accurately, passing through the complex vortex street from a random starting location to reach a random target.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Spectrum Access for Ambient Backscatter Communication-assisted D2D Systems with Quantum Reinforcement Learning",
    "title_es": "Dynamic Spectrum Access for Ambient Backscatter Communication-assisted D2D Systems with Quantum Reinforcement Learning",
    "url": "https://arxiv.org/abs/2410.17971",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.17971v2 Announce Type: replace \nAbstract: Spectrum access is an essential problem in device-to-device (D2D) communications. However, with the recent growth in the number of mobile devices, the wireless spectrum is becoming scarce, resulting in low spectral efficiency for D2D communications. To address this problem, this paper aims to integrate the ambient backscatter communication technology into D2D devices to allow them to backscatter ambient RF signals to transmit their data when the shared spectrum is occupied by mobile users. To obtain the optimal spectrum access policy, i.e., stay idle or access the shared spectrum and perform active transmissions or backscattering ambient RF signals for transmissions, to maximize the average throughput for D2D users, deep reinforcement learning (DRL) can be adopted. However, DRL-based solutions may require long training time due to the curse of dimensionality issue as well as complex deep neural network architectures. For that, we develop a novel quantum reinforcement learning (RL) algorithm that can achieve a faster convergence rate with fewer training parameters compared to DRL thanks to the quantum superposition and quantum entanglement principles. Specifically, instead of using conventional deep neural networks, the proposed quantum RL algorithm uses a parametrized quantum circuit to approximate an optimal policy. Extensive simulations then demonstrate that the proposed solution not only can significantly improve the average throughput of D2D devices when the shared spectrum is busy but also can achieve much better performance in terms of convergence rate and learning complexity compared to existing DRL-based methods.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Aggregations of Proper Learners in Multiclass Classification",
    "title_es": "Understanding Aggregations of Proper Learners in Multiclass Classification",
    "url": "https://arxiv.org/abs/2410.22749",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.22749v2 Announce Type: replace \nAbstract: Multiclass learnability is known to exhibit a properness barrier: there are learnable classes which cannot be learned by any proper learner. Binary classification faces no such barrier for learnability, but a similar one for optimal learning, which can in general only be achieved by improper learners. Fortunately, recent advances in binary classification have demonstrated that this requirement can be satisfied using aggregations of proper learners, some of which are strikingly simple. This raises a natural question: to what extent can simple aggregations of proper learners overcome the properness barrier in multiclass classification?\n  We give a positive answer to this question for classes which have finite Graph dimension, $d_G$. Namely, we demonstrate that the optimal binary learners of Hanneke, Larsen, and Aden-Ali et al. (appropriately generalized to the multiclass setting) achieve sample complexity $O\\left(\\frac{d_G + \\ln(1 / \\delta)}{\\epsilon}\\right)$. This forms a strict improvement upon the sample complexity of ERM. We complement this with a lower bound demonstrating that for certain classes of Graph dimension $d_G$, majorities of ERM learners require $\\Omega \\left( \\frac{d_G + \\ln(1 / \\delta)}{\\epsilon}\\right)$ samples. Furthermore, we show that a single ERM requires $\\Omega \\left(\\frac{d_G \\ln(1 / \\epsilon) + \\ln(1 / \\delta)}{\\epsilon}\\right)$ samples on such classes, exceeding the lower bound of Daniely et al. (2015) by a factor of $\\ln(1 / \\epsilon)$. For multiclass learning in full generality -- i.e., for classes of finite DS dimension but possibly infinite Graph dimension -- we give a strong refutation to these learning strategies, by exhibiting a learnable class which cannot be learned to constant error by any aggregation of a finite number of proper learners.",
    "source": "arXiv"
  },
  {
    "title": "Learning Marmoset Vocal Patterns with a Masked Autoencoder for Robust Call Segmentation, Classification, and Caller Identification",
    "title_es": "Learning Marmoset Vocal Patterns with a Masked Autoencoder for Robust Call Segmentation, Classification, and Caller Identification",
    "url": "https://arxiv.org/abs/2410.23279",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2410.23279v4 Announce Type: replace \nAbstract: The marmoset, a highly vocal primate, is a key model for studying social-communicative behavior. Unlike human speech, marmoset vocalizations are less structured, highly variable, and recorded in noisy, low-resource conditions. Learning marmoset communication requires joint call segmentation, classification, and caller identification -- challenging domain tasks. Previous CNNs handle local patterns but struggle with long-range temporal structure. We applied Transformers using self-attention for global dependencies. However, Transformers show overfitting and instability on small, noisy annotated datasets. To address this, we pretrain Transformers with MAE -- a self-supervised method reconstructing masked segments from hundreds of hours of unannotated marmoset recordings. The pretraining improved stability and generalization. Results show MAE-pretrained Transformers outperform CNNs, demonstrating modern self-supervised architectures effectively model low-resource non-human vocal communication.",
    "source": "arXiv"
  },
  {
    "title": "A Risk Taxonomy and Reflection Tool for Large Language Model Adoption in Public Health",
    "title_es": "A Risk Taxonomy and Reflection Tool for Large Language Model Adoption in Public Health",
    "url": "https://arxiv.org/abs/2411.02594",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2411.02594v2 Announce Type: replace \nAbstract: Recent breakthroughs in large language models (LLMs) have generated both interest and concern about their potential adoption as information sources or communication tools across different domains. In public health, where stakes are high and impacts extend across diverse populations, adopting LLMs poses unique challenges that require thorough evaluation. However, structured approaches for assessing potential risks in public health remain under-explored. To address this gap, we conducted focus groups with public health professionals and individuals with lived experience to unpack their concerns, situated across three distinct and critical public health issues that demand high-quality information: infectious disease prevention (vaccines), chronic and well-being care (opioid use disorder), and community health and safety (intimate partner violence). We synthesize participants' perspectives into a risk taxonomy, identifying and contextualizing the potential harms LLMs may introduce when positioned alongside traditional health communication. This taxonomy highlights four dimensions of risk to individuals, human-centered care, information ecosystem, and technology accountability. For each dimension, we unpack specific risks and offer example reflection questions to help practitioners adopt a risk-reflexive approach. By summarizing distinctive LLM characteristics and linking them to identified risks, we discuss the need to revisit prior mental models of information behaviors and complement evaluations with external validity and domain expertise through lived experience and real-world practices. Together, this work contributes a shared vocabulary and reflection tool for people in both computing and public health to collaboratively anticipate, evaluate, and mitigate risks in deciding when to employ LLM capabilities (or not) and how to mitigate harm.",
    "source": "arXiv"
  },
  {
    "title": "REDUCIO! Generating 1K Video within 16 Seconds using Extremely Compressed Motion Latents",
    "title_es": "REDUCIO! Generating 1K Video within 16 Seconds using Extremely Compressed Motion Latents",
    "url": "https://arxiv.org/abs/2411.13552",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2411.13552v3 Announce Type: replace \nAbstract: Commercial video generation models have exhibited realistic, high-fidelity results but are still restricted to limited access. One crucial obstacle for large-scale applications is the expensive training and inference cost. In this paper, we argue that videos contain significantly more redundant information than images, allowing them to be encoded with very few motion latents. Towards this goal, we design an image-conditioned VAE that projects videos into extremely compressed latent space and decode them based on content images. This magic Reducio charm enables 64x reduction of latents compared to a common 2D VAE, without sacrificing the quality. Building upon Reducio-VAE, we can train diffusion models for high-resolution video generation efficiently. Specifically, we adopt a two-stage generation paradigm, first generating a condition image via text-to-image generation, followed by text-image-to-video generation with the proposed Reducio-DiT. Extensive experiments show that our model achieves strong performance in evaluation. More importantly, our method significantly boosts the training and inference efficiency of video LDMs. Reducio-DiT is trained in just 3.2K A100 GPU hours in total and can generate a 16-frame 1024$\\times$1024 video clip within 15.5 seconds on a single A100 GPU. Code released at https://github.com/microsoft/Reducio-VAE .",
    "source": "arXiv"
  },
  {
    "title": "Gotta Hear Them All: Towards Sound Source Aware Audio Generation",
    "title_es": "Gotta Hear Them All: Towards Sound Source Aware Audio Generation",
    "url": "https://arxiv.org/abs/2411.15447",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2411.15447v4 Announce Type: replace \nAbstract: Audio synthesis has broad applications in multimedia. Recent advancements have made it possible to generate relevant audios from inputs describing an audio scene, such as images or texts. However, the immersiveness and expressiveness of the generation are limited. One possible problem is that existing methods solely rely on the global scene and overlook details of local sounding objects (i.e., sound sources). To address this issue, we propose a Sound Source-Aware Audio (SS2A) generator. SS2A is able to locally perceive multimodal sound sources from a scene with visual detection and cross-modality translation. It then contrastively learns a Cross-Modal Sound Source (CMSS) Manifold to semantically disambiguate each source. Finally, we attentively mix their CMSS semantics into a rich audio representation, from which a pretrained audio generator outputs the sound. To model the CMSS manifold, we curate a novel single-sound-source visual-audio dataset VGGS3 from VGGSound. We also design a Sound Source Matching Score to clearly measure localized audio relevance. With the effectiveness of explicit sound source modeling, SS2A achieves state-of-the-art performance in extensive image-to-audio tasks. We also qualitatively demonstrate SS2A's ability to achieve intuitive synthesis control by compositing vision, text, and audio conditions. Furthermore, we show that our sound source modeling can achieve competitive video-to-audio performance with a straightforward temporal aggregation mechanism.",
    "source": "arXiv"
  },
  {
    "title": "Fancy123: One Image to High-Quality 3D Mesh Generation via Plug-and-Play Deformation",
    "title_es": "Fancy123: One Image to High-Quality 3D Mesh Generation via Plug-and-Play Deformation",
    "url": "https://arxiv.org/abs/2411.16185",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2411.16185v2 Announce Type: replace \nAbstract: Generating 3D meshes from a single image is an important but ill-posed task. Existing methods mainly adopt 2D multiview diffusion models to generate intermediate multiview images, and use the Large Reconstruction Model (LRM) to create the final meshes. However, the multiview images exhibit local inconsistencies, and the meshes often lack fidelity to the input image or look blurry. We propose Fancy123, featuring two enhancement modules and an unprojection operation to address the above three issues, respectively. The appearance enhancement module deforms the 2D multiview images to realign misaligned pixels for better multiview consistency. The fidelity enhancement module deforms the 3D mesh to match the input image. The unprojection of the input image and deformed multiview images onto LRM's generated mesh ensures high clarity, discarding LRM's predicted blurry-looking mesh colors. Extensive qualitative and quantitative experiments verify Fancy123's SoTA performance with significant improvement. Also, the two enhancement modules are plug-and-play and work at inference time, allowing seamless integration into various existing single-image-to-3D methods. Code at: https://github.com/YuQiao0303/Fancy123",
    "source": "arXiv"
  },
  {
    "title": "PAD-F: Prior-Aware Debiasing Framework for Long-Tailed X-ray Prohibited Item Detection",
    "title_es": "PAD-F: Prior-Aware Debiasing Framework for Long-Tailed X-ray Prohibited Item Detection",
    "url": "https://arxiv.org/abs/2411.18078",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2411.18078v3 Announce Type: replace \nAbstract: Detecting prohibited items in X-ray security imagery is a challenging yet crucial task. With the rapid advancement of deep learning, object detection algorithms have been widely applied in this area. However, the distribution of object classes in real-world prohibited item detection scenarios often exhibits a distinct long-tailed distribution. Due to the unique principles of X-ray imaging, conventional methods for long-tailed object detection are often ineffective in this domain. To tackle these challenges, we introduce the Prior-Aware Debiasing Framework (PAD-F), a novel approach that employs a two-pronged strategy leveraging both material and co-occurrence priors. At the data level, our Explicit Material-Aware Augmentation (EMAA) component generates numerous challenging training samples for tail classes. It achieves this through a placement strategy guided by material-specific absorption rates and a gradient-based Poisson blending technique. At the feature level, the Implicit Co-occurrence Aggregator (ICA) acts as a plug-in module that enhances features for ambiguous objects by implicitly learning and aggregating statistical co-occurrence relationships within the image. Extensive experiments on the HiXray and PIDray datasets demonstrate that PAD-F significantly boosts the performance of multiple popular detectors. It achieves an absolute improvement of up to +17.2% in AP50 for tail classes and comprehensively outperforms existing state-of-the-art methods. Our work provides an effective and versatile solution to the critical problem of long-tailed detection in X-ray security.",
    "source": "arXiv"
  },
  {
    "title": "Targeting Completeness: Automated Complexity Analysis of Integer Programs",
    "title_es": "Targeting Completeness: Automated Complexity Analysis of Integer Programs",
    "url": "https://arxiv.org/abs/2412.01832",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2412.01832v2 Announce Type: replace \nAbstract: There exist several approaches to infer runtime or resource bounds for integer programs automatically. In this paper, we study the subclass of periodic rational solvable loops (prs-loops), where questions regarding the runtime and the size of variable values are decidable and where we can therefore obtain techniques that are complete for such subclasses. We show how to use these results for the complexity analysis of arbitrary general integer programs. To this end, we present a modular approach which computes local runtime and size bounds for subprograms which correspond to prs-loops. These local bounds are then lifted to global runtime and size bounds for the whole integer program. Furthermore, we introduce several techniques to transform larger programs into prs-loops to increase the scope of the approach. The power of the procedure is shown by our implementation in the complexity analysis tool KoAT.",
    "source": "arXiv"
  },
  {
    "title": "WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image",
    "title_es": "WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image",
    "url": "https://arxiv.org/abs/2412.02141",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2412.02141v5 Announce Type: replace \nAbstract: Recent advancements in computational pathology have produced patch-level Multi-modal Large Language Models (MLLMs), but these models are limited by their inability to analyze whole slide images (WSIs) comprehensively and their tendency to bypass crucial morphological features that pathologists rely on for diagnosis. To address these challenges, we first introduce WSI-Bench, a large-scale morphology-aware benchmark containing 180k VQA pairs from 9,850 WSIs across 30 cancer types, designed to evaluate MLLMs' understanding of morphological characteristics crucial for accurate diagnosis. Building upon this benchmark, we present WSI-LLaVA, a novel framework for gigapixel WSI understanding that employs a three-stage training approach: WSI-text alignment, feature space alignment, and task-specific instruction tuning. To better assess model performance in pathological contexts, we develop two specialized WSI metrics: WSI-Precision and WSI-Relevance. Experimental results demonstrate that WSI-LLaVA outperforms existing models across all capability dimensions, with a significant improvement in morphological analysis, establishing a clear correlation between morphological understanding and diagnostic accuracy.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Informed Deep Neural Networks for Power Flow Analysis",
    "title_es": "Adaptive Informed Deep Neural Networks for Power Flow Analysis",
    "url": "https://arxiv.org/abs/2412.02659",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2412.02659v3 Announce Type: replace \nAbstract: This study introduces PINN4PF, an end-to-end deep learning architecture for power flow (PF) analysis that effectively captures the nonlinear dynamics of large-scale modern power systems. The proposed neural network (NN) architecture consists of two important advancements in the training pipeline: (A) a double-head feed-forward NN that aligns with PF analysis, including an activation function that adjusts to the net active and reactive power injections patterns, and (B) a physics-based loss function that partially incorporates power system topology information through a novel hidden function. The effectiveness of the proposed architecture is illustrated through 4-bus, 15-bus, 290-bus, and 2224-bus test systems and is evaluated against two baselines: a linear regression model (LR) and a black-box NN (MLP). The comparison is based on (i) generalization ability, (ii) robustness, (iii) impact of training dataset size on generalization ability, (iv) accuracy in approximating derived PF quantities (specifically line current, line active power, and line reactive power), and (v) scalability. Results demonstrate that PINN4PF outperforms both baselines across all test systems by up to two orders of magnitude not only in terms of direct criteria, e.g., generalization ability, but also in terms of approximating derived physical quantities.",
    "source": "arXiv"
  },
  {
    "title": "Touch and Tell: Multimodal Decoding of Human Emotions and Social Gestures for Robots",
    "title_es": "Touch and Tell: Multimodal Decoding of Human Emotions and Social Gestures for Robots",
    "url": "https://arxiv.org/abs/2412.03300",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2412.03300v2 Announce Type: replace \nAbstract: Human emotions are complex and can be conveyed through nuanced touch gestures. Previous research has primarily focused on how humans recognize emotions through touch or on identifying key features of emotional expression for robots. However, there is a gap in understanding how reliably these emotions and gestures can be communicated to robots via touch and interpreted using data driven methods. This study investigates the consistency and distinguishability of emotional and gestural expressions through touch and sound. To this end, we integrated a custom piezoresistive pressure sensor as well as a microphone on a social robot. Twenty-eight participants first conveyed ten different emotions to the robot using spontaneous touch gestures, then they performed six predefined social touch gestures. Our findings reveal statistically significant consistency in both emotion and gesture expression among participants. However, some emotions exhibited low intraclass correlation values, and certain emotions with similar levels of arousal or valence did not show significant differences in their conveyance. To investigate emotion and social gesture decoding within affective human-robot tactile interaction, we developed single-modality models and multimodal models integrating tactile and auditory features. A support vector machine (SVM) model trained on multimodal features achieved the highest accuracy for classifying ten emotions, reaching 40 %.For gesture classification, a Convolutional Neural Network- Long Short-Term Memory Network (CNN-LSTM) achieved 90.74 % accuracy. Our results demonstrate that even though the unimodal models have the potential to decode emotions and touch gestures, the multimodal integration of touch and sound significantly outperforms unimodal approaches, enhancing the decoding of both emotions and gestures.",
    "source": "arXiv"
  },
  {
    "title": "Chemist-aligned retrosynthesis by ensembling diverse inductive bias models",
    "title_es": "Chemist-aligned retrosynthesis by ensembling diverse inductive bias models",
    "url": "https://arxiv.org/abs/2412.05269",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2412.05269v2 Announce Type: replace \nAbstract: Chemical synthesis remains a critical bottleneck in the discovery and manufacture of functional small molecules. AI-based synthesis planning models could be a potential remedy to find effective syntheses, and have made progress in recent years. However, they still struggle with less frequent, yet critical reactions for synthetic strategy, as well as hallucinated, incorrect predictions. This hampers multi-step search algorithms that rely on models, and leads to misalignment with chemists' expectations. Here we propose RetroChimera: a frontier retrosynthesis model, built upon two newly developed components with complementary inductive biases, which we fuse together using a new framework for integrating predictions from multiple sources via a learning-based ensembling strategy. Through experiments across several orders of magnitude in data scale and splitting strategy, we show RetroChimera outperforms all major models by a large margin, demonstrating robustness outside the training data, as well as for the first time the ability to learn from even a very small number of examples per reaction class. Moreover, industrial organic chemists prefer predictions from RetroChimera over the reactions it was trained on in terms of quality, revealing high levels of alignment. Finally, we demonstrate zero-shot transfer to an internal dataset from a major pharmaceutical company, showing robust generalization under distribution shift. With the new dimension that our ensembling framework unlocks, we anticipate further acceleration in the development of even more accurate models.",
    "source": "arXiv"
  },
  {
    "title": "Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video",
    "title_es": "Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video",
    "url": "https://arxiv.org/abs/2412.06424",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2412.06424v2 Announce Type: replace \nAbstract: Recent 4D reconstruction methods have yielded impressive results but rely on sharp videos as supervision. However, motion blur often occurs in videos due to camera shake and object movement, while existing methods render blurry results when using such videos for reconstructing 4D models. Although a few approaches attempted to address the problem, they struggled to produce high-quality results, due to the inaccuracy in estimating continuous dynamic representations within the exposure time. Encouraged by recent works in 3D motion trajectory modeling using 3D Gaussian Splatting (3DGS), we take 3DGS as the scene representation manner, and propose Deblur4DGS to reconstruct a high-quality 4D model from blurry monocular video. Specifically, we transform continuous dynamic representations estimation within an exposure time into the exposure time estimation. Moreover, we introduce the exposure regularization term, multi-frame, and multi-resolution consistency regularization term to avoid trivial solutions. Furthermore, to better represent objects with large motion, we suggest blur-aware variable canonical Gaussians. Beyond novel-view synthesis, Deblur4DGS can be applied to improve blurry video from multiple perspectives, including deblurring, frame interpolation, and video stabilization. Extensive experiments in both synthetic and real-world data on the above four tasks show that Deblur4DGS outperforms state-of-the-art 4D reconstruction methods. The codes are available at https://github.com/ZcsrenlongZ/Deblur4DGS.",
    "source": "arXiv"
  },
  {
    "title": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models",
    "title_es": "From Slow Bidirectional to Fast Autoregressive Video Diffusion Models",
    "url": "https://arxiv.org/abs/2412.07772",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2412.07772v3 Announce Type: replace \nAbstract: Current video diffusion models achieve impressive generation quality but struggle in interactive applications due to bidirectional attention dependencies. The generation of a single frame requires the model to process the entire sequence, including the future. We address this limitation by adapting a pretrained bidirectional diffusion transformer to an autoregressive transformer that generates frames on-the-fly. To further reduce latency, we extend distribution matching distillation (DMD) to videos, distilling 50-step diffusion model into a 4-step generator. To enable stable and high-quality distillation, we introduce a student initialization scheme based on teacher's ODE trajectories, as well as an asymmetric distillation strategy that supervises a causal student model with a bidirectional teacher. This approach effectively mitigates error accumulation in autoregressive generation, allowing long-duration video synthesis despite training on short clips. Our model achieves a total score of 84.27 on the VBench-Long benchmark, surpassing all previous video generation models. It enables fast streaming generation of high-quality videos at 9.4 FPS on a single GPU thanks to KV caching. Our approach also enables streaming video-to-video translation, image-to-video, and dynamic prompting in a zero-shot manner.",
    "source": "arXiv"
  },
  {
    "title": "UnrealZoo: Enriching Photo-realistic Virtual Worlds for Embodied AI",
    "title_es": "UnrealZoo: Enriching Photo-realistic Virtual Worlds for Embodied AI",
    "url": "https://arxiv.org/abs/2412.20977",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2412.20977v2 Announce Type: replace \nAbstract: We introduce UnrealZoo, a collection of over 100 photo-realistic 3D virtual worlds built on Unreal Engine, designed to reflect the complexity and variability of open-world environments. We also provide a rich variety of playable entities, including humans, animals, robots, and vehicles for embodied AI research. We extend UnrealCV with optimized APIs and tools for data collection, environment augmentation, distributed training, and benchmarking. These improvements achieve significant improvements in the efficiency of rendering and communication, enabling advanced applications such as multi-agent interactions. Our experimental evaluation across visual navigation and tracking tasks reveals two key insights: 1) environmental diversity provides substantial benefits for developing generalizable reinforcement learning (RL) agents, and 2) current embodied agents face persistent challenges in open-world scenarios, including navigation in unstructured terrain, adaptation to unseen morphologies, and managing latency in the close-loop control systems for interacting in highly dynamic objects. UnrealZoo thus serves as both a comprehensive testing ground and a pathway toward developing more capable embodied AI systems for real-world deployment.",
    "source": "arXiv"
  },
  {
    "title": "Improving the robustness of neural ODEs with minimal weight perturbation",
    "title_es": "Improving the robustness of neural ODEs with minimal weight perturbation",
    "url": "https://arxiv.org/abs/2501.10740",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2501.10740v2 Announce Type: replace \nAbstract: We propose a method to enhance the stability of a neural ordinary differential equation (neural ODE) by reducing the maximum error growth subsequent to a perturbation of the initial value. Since the stability depends on the logarithmic norm of the Jacobian matrix associated with the neural ODE, we control the logarithmic norm by perturbing the weight matrices of the neural ODE by a smallest possible perturbation (in Frobenius norm). We do so by engaging an eigenvalue optimisation problem, for which we propose a nested two-level algorithm. For a given perturbation size of the weight matrix, the inner level computes optimal perturbations of that size, while - at the outer level - we tune the perturbation amplitude until we reach the desired uniform stability bound. We embed the proposed algorithm in the training of the neural ODE to improve its robustness to perturbations of the initial value, as adversarial attacks. Numerical experiments on classical image datasets show that an image classifier including a neural ODE in its architecture trained according to our strategy is more stable than the same classifier trained in the classical way, and therefore, it is more robust and less vulnerable to adversarial attacks.",
    "source": "arXiv"
  },
  {
    "title": "Memory Storyboard: Leveraging Temporal Segmentation for Streaming Self-Supervised Learning from Egocentric Videos",
    "title_es": "Memory Storyboard: Leveraging Temporal Segmentation for Streaming Self-Supervised Learning from Egocentric Videos",
    "url": "https://arxiv.org/abs/2501.12254",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2501.12254v3 Announce Type: replace \nAbstract: Self-supervised learning holds the promise of learning good representations from real-world continuous uncurated data streams. However, most existing works in visual self-supervised learning focus on static images or artificial data streams. Towards exploring a more realistic learning substrate, we investigate streaming self-supervised learning from long-form real-world egocentric video streams. Inspired by the event segmentation mechanism in human perception and memory, we propose \"Memory Storyboard\" that groups recent past frames into temporal segments for more effective summarization of the past visual streams for memory replay. To accommodate efficient temporal segmentation, we propose a two-tier memory hierarchy: the recent past is stored in a short-term memory, and the storyboard temporal segments are then transferred to a long-term memory. Experiments on real-world egocentric video datasets including SAYCam and KrishnaCam show that contrastive learning objectives on top of storyboard frames result in semantically meaningful representations that outperform those produced by state-of-the-art unsupervised continual learning methods.",
    "source": "arXiv"
  },
  {
    "title": "AdEval: Alignment-based Dynamic Evaluation to Mitigate Data Contamination in Large Language Models",
    "title_es": "AdEval: Alignment-based Dynamic Evaluation to Mitigate Data Contamination in Large Language Models",
    "url": "https://arxiv.org/abs/2501.13983",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2501.13983v5 Announce Type: replace \nAbstract: As Large Language Models (LLMs) are pre-trained on ultra-large-scale corpora, the problem of data contamination is becoming increasingly serious, and there is a risk that static evaluation benchmarks overestimate the performance of LLMs. To address this, this paper proposes a dynamic data evaluation method called AdEval (Alignment-based Dynamic Evaluation). AdEval first extracts knowledge points and main ideas from static datasets to achieve dynamic alignment with the core content of static benchmarks, and by avoiding direct reliance on static datasets, it inherently reduces the risk of data contamination from the source. It then obtains background information through online searches to generate detailed descriptions of the knowledge points. Finally, it designs questions based on Bloom's cognitive hierarchy across six dimensions-remembering, understanding, applying, analyzing, evaluating, and creating to enable multi-level cognitive assessment. Additionally, AdEval controls the complexity of dynamically generated datasets through iterative question reconstruction. Experimental results on multiple datasets show that AdEval effectively alleviates the impact of data contamination on evaluation results, solves the problems of insufficient complexity control and single-dimensional evaluation, and improves the fairness, reliability and diversity of LLMs evaluation.",
    "source": "arXiv"
  },
  {
    "title": "Decoding-based Regression",
    "title_es": "Decoding-based Regression",
    "url": "https://arxiv.org/abs/2501.19383",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2501.19383v2 Announce Type: replace \nAbstract: Language models have recently been shown capable of performing regression wherein numeric predictions are represented as decoded strings. In this work, we provide theoretical grounds for this capability and furthermore investigate the utility of causal sequence decoding models as numeric regression heads given any feature representation. We find that, despite being trained in the usual way - for next-token prediction via cross-entropy loss - decoder-based heads are as performant as standard pointwise heads when benchmarked over standard regression tasks, while being flexible enough to capture smooth numeric distributions, such as in the task of density estimation.",
    "source": "arXiv"
  },
  {
    "title": "Optimal Coupled Sensor Placement and Path-Planning in Unknown Time-Varying Environments",
    "title_es": "Optimal Coupled Sensor Placement and Path-Planning in Unknown Time-Varying Environments",
    "url": "https://arxiv.org/abs/2502.00185",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.00185v2 Announce Type: replace \nAbstract: We address path-planning for a mobile agent to navigate in an unknown environment with minimum exposure to a spatially and temporally varying threat field. The threat field is estimated using pointwise noisy measurements from a mobile sensor network. For this problem, we present a new information gain measure for optimal sensor placement that quantifies reduction in uncertainty in the path cost rather than the environment state. This measure, which we call the context-relevant mutual information (CRMI), couples the sensor placement and path-planning problem. We propose an iterative coupled sensor configuration and path-planning (CSCP) algorithm. At each iteration, this algorithm places sensors to maximize CRMI, updates the threat estimate using new measurements, and recalculates the path with minimum expected exposure to the threat. The iterations converge when the path cost variance, which is an indicator of risk, reduces below a desired threshold. We show that CRMI is submodular, and therefore, greedy optimization provides near-optimal sensor placements while maintaining computational efficiency of the CSCP algorithm. Distance-based sensor reconfiguration costs are introduced in a modified CRMI measure, which we also show to be submodular. Through numerical simulations, we demonstrate that the principal advantage of this algorithm is that near-optimal low-variance paths are achieved using far fewer sensor measurements as compared to a standard sensor placement method.",
    "source": "arXiv"
  },
  {
    "title": "Joint State and Noise Covariance Estimation",
    "title_es": "Joint State and Noise Covariance Estimation",
    "url": "https://arxiv.org/abs/2502.04584",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.04584v3 Announce Type: replace \nAbstract: This paper tackles the problem of jointly estimating the noise covariance matrix alongside states (parameters such as poses and points) from measurements corrupted by Gaussian noise and, if available, prior information. In such settings, the noise covariance matrix determines the weights assigned to individual measurements in the least squares problem. We show that the joint problem exhibits a convex structure and provide a full characterization of the optimal noise covariance estimate (with analytical solutions) within joint maximum a posteriori and likelihood frameworks and several variants. Leveraging this theoretical result, we propose two novel algorithms that jointly estimate the primary parameters and the noise covariance matrix. Our BCD algorithm can be easily integrated into existing nonlinear least squares solvers, with negligible per-iteration computational overhead. To validate our approach, we conduct extensive experiments across diverse scenarios and offer practical insights into their application in robotics and computer vision estimation problems with a particular focus on SLAM.",
    "source": "arXiv"
  },
  {
    "title": "Data-Driven Certificate Synthesis",
    "title_es": "Data-Driven Certificate Synthesis",
    "url": "https://arxiv.org/abs/2502.05510",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.05510v3 Announce Type: replace \nAbstract: We investigate the problem of verifying different properties of discrete time dynamical systems, namely, reachability, safety and reach-while-avoid. To achieve this, we adopt a data driven perspective and, using past system trajectories as data, we aim at learning a specific function termed certificate for each property we wish to verify. We seek to minimize a loss function, designed to encompass conditions on the certificate to be learned that encode the satisfaction of the associated property. Besides learning a certificate, we quantify probabilistically its generalization properties, namely, how likely it is for a certificate to be valid (and hence for the associated property to be satisfied) when it comes to a new system trajectory not included in the training data set. We view this problem under the realm of probably approximately correct (PAC) learning under the notion of compression, and use recent advancements of the so-called scenario approach to obtain scalable generalization bounds on the learned certificates. To achieve this, we design a novel algorithm that minimizes the loss function and hence constructs a certificate, and at the same time determines a quantity termed compression, which is instrumental in obtaining meaningful probabilistic guarantees. This process is novel per se and provides a constructive mechanism for compression set calculation, thus opening the road for its use to more general non-convex optimization problems. We verify the efficacy of our methodology on several numerical case studies, and compare it (both theoretically and numerically) with closely related results on data-driven property verification.",
    "source": "arXiv"
  },
  {
    "title": "FBFL: A Field-Based Coordination Approach for Data Heterogeneity in Federated Learning",
    "title_es": "FBFL: A Field-Based Coordination Approach for Data Heterogeneity in Federated Learning",
    "url": "https://arxiv.org/abs/2502.08577",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.08577v2 Announce Type: replace \nAbstract: In the last years, Federated learning (FL) has become a popular solution to train machine learning models in domains with high privacy concerns. However, FL scalability and performance face significant challenges in real-world deployments where data across devices are non-independently and identically distributed (non-IID). The heterogeneity in data distribution frequently arises from spatial distribution of devices, leading to degraded model performance in the absence of proper handling. Additionally, FL typical reliance on centralized architectures introduces bottlenecks and single-point-of-failure risks, particularly problematic at scale or in dynamic environments. To close this gap, we propose Field-Based Federated Learning (FBFL), a novel approach leveraging macroprogramming and field coordination to address these limitations through: (i) distributed spatial-based leader election for personalization to mitigate non-IID data challenges; and (ii) construction of a self-organizing, hierarchical architecture using advanced macroprogramming patterns. Moreover, FBFL not only overcomes the aforementioned limitations, but also enables the development of more specialized models tailored to the specific data distribution in each subregion. This paper formalizes FBFL and evaluates it extensively using MNIST, FashionMNIST, and Extended MNIST datasets. We demonstrate that, when operating under IID data conditions, FBFL performs comparably to the widely-used FedAvg algorithm. Furthermore, in challenging non-IID scenarios, FBFL not only outperforms FedAvg but also surpasses other state-of-the-art methods, namely FedProx and Scaffold, which have been specifically designed to address non-IID data distributions. Additionally, we showcase the resilience of FBFL's self-organizing hierarchical architecture against server failures.",
    "source": "arXiv"
  },
  {
    "title": "Fast Tensor Completion via Approximate Richardson Iteration",
    "title_es": "Fast Tensor Completion via Approximate Richardson Iteration",
    "url": "https://arxiv.org/abs/2502.09534",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.09534v2 Announce Type: replace \nAbstract: We study tensor completion (TC) through the lens of low-rank tensor decomposition (TD). Many TD algorithms use fast alternating minimization methods to solve highly structured linear regression problems at each step (e.g., for CP, Tucker, and tensor-train decompositions). However, such algebraic structure is often lost in TC regression problems, making direct extensions unclear. This work proposes a novel lifting method for approximately solving TC regression problems using structured TD regression algorithms as blackbox subroutines, enabling sublinear-time methods. We analyze the convergence rate of our approximate Richardson iteration-based algorithm, and our empirical study shows that it can be 100x faster than direct methods for CP completion on real-world tensors.",
    "source": "arXiv"
  },
  {
    "title": "Polymind: Parallel Visual Diagramming with Large Language Models to Support Prewriting Through Microtasks",
    "title_es": "Polymind: Parallel Visual Diagramming with Large Language Models to Support Prewriting Through Microtasks",
    "url": "https://arxiv.org/abs/2502.09577",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.09577v2 Announce Type: replace \nAbstract: Prewriting is the process of generating and organising ideas before a first draft. It consists of a combination of informal, iterative, and semi-structured strategies such as visual diagramming, which poses a challenge for collaborating with large language models (LLMs) in a turn-taking conversational manner. We present Polymind, a visual diagramming tool that leverages multiple LLM-powered agents to support prewriting. The system features a parallel collaboration workflow in place of the turn-taking conversational interactions. It defines multiple ``microtasks'' to simulate group collaboration scenarios such as collaborative writing and group brainstorming. Instead of repetitively prompting a chatbot for various purposes, Polymind enables users to orchestrate multiple microtasks simultaneously. Users can configure and delegate customised microtasks, and manage their microtasks by specifying task requirements and toggling visibility and initiative. Our evaluation revealed that, compared to ChatGPT, users had more customizability over collaboration with Polymind, and were thus able to quickly expand personalised writing ideas during prewriting.",
    "source": "arXiv"
  },
  {
    "title": "Forget the Data and Fine-Tuning! Just Fold the Network to Compress",
    "title_es": "Forget the Data and Fine-Tuning! Just Fold the Network to Compress",
    "url": "https://arxiv.org/abs/2502.10216",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.10216v2 Announce Type: replace \nAbstract: We introduce model folding, a novel data-free model compression technique that merges structurally similar neurons across layers, significantly reducing the model size without the need for fine-tuning or access to training data. Unlike existing methods, model folding preserves data statistics during compression by leveraging k-means clustering, and using novel data-free techniques to prevent variance collapse or explosion. Our theoretical framework and experiments across standard benchmarks, including ResNet18 and LLaMA-7B, demonstrate that model folding achieves comparable performance to data-driven compression techniques and outperforms recently proposed data-free methods, especially at high sparsity levels. This approach is particularly effective for compressing large-scale models, making it suitable for deployment in resource-constrained environments.",
    "source": "arXiv"
  },
  {
    "title": "LLM-Lasso: A Robust Framework for Domain-Informed Feature Selection and Regularization",
    "title_es": "LLM-Lasso: A Robust Framework for Domain-Informed Feature Selection and Regularization",
    "url": "https://arxiv.org/abs/2502.10648",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.10648v3 Announce Type: replace \nAbstract: We introduce LLM-Lasso, a novel framework that leverages large language models (LLMs) to guide feature selection in Lasso $\\ell_1$ regression. Unlike traditional methods that rely solely on numerical data, LLM-Lasso incorporates domain-specific knowledge extracted from natural language, enhanced through a retrieval-augmented generation (RAG) pipeline, to seamlessly integrate data-driven modeling with contextual insights. Specifically, the LLM generates penalty factors for each feature, which are converted into weights for the Lasso penalty using a simple, tunable model. Features identified as more relevant by the LLM receive lower penalties, increasing their likelihood of being retained in the final model, while less relevant features are assigned higher penalties, reducing their influence. Importantly, LLM-Lasso has an internal validation step that determines how much to trust the contextual knowledge in our prediction pipeline. Hence it addresses key challenges in robustness, making it suitable for mitigating potential inaccuracies or hallucinations from the LLM. In various biomedical case studies, LLM-Lasso outperforms standard Lasso and existing feature selection baselines, all while ensuring the LLM operates without prior access to the datasets. To our knowledge, this is the first approach to effectively integrate conventional feature selection techniques directly with LLM-based domain-specific reasoning.",
    "source": "arXiv"
  },
  {
    "title": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN",
    "title_es": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN",
    "url": "https://arxiv.org/abs/2502.12207",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.12207v3 Announce Type: replace \nAbstract: Deep neural networks have demonstrated remarkable performance across various domains. However, they are vulnerable to adversarial examples, which can lead to erroneous predictions. Generative Adversarial Networks (GANs) can leverage the generators and discriminators model to quickly produce high-quality adversarial examples. Since both modules train in a competitive and simultaneous manner, GAN-based algorithms like AdvGAN can generate adversarial examples with better transferability compared to traditional methods. However, the generation of perturbations is usually limited to a single iteration, preventing these examples from fully exploiting the potential of the methods. To tackle this issue, we introduce a novel approach named Progressive Auto-Regression AdvGAN (PAR-AdvGAN). It incorporates an auto-regressive iteration mechanism within a progressive generation network to craft adversarial examples with enhanced attack capability. We thoroughly evaluate our PAR-AdvGAN method with a large-scale experiment, demonstrating its superior performance over various state-of-the-art black-box adversarial attacks, as well as the original AdvGAN.Moreover, PAR-AdvGAN significantly accelerates the adversarial example generation, i.e., achieving the speeds of up to 335.5 frames per second on Inception-v3 model, outperforming the gradient-based transferable attack algorithms. Our code is available at: https://github.com/LMBTough/PAR",
    "source": "arXiv"
  },
  {
    "title": "Zero-shot Emotion Annotation in Facial Images Using Large Multimodal Models: Benchmarking and Prospects for Multi-Class, Multi-Frame Approaches",
    "title_es": "Zero-shot Emotion Annotation in Facial Images Using Large Multimodal Models: Benchmarking and Prospects for Multi-Class, Multi-Frame Approaches",
    "url": "https://arxiv.org/abs/2502.12454",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.12454v2 Announce Type: replace \nAbstract: This study investigates the feasibility and performance of using large multimodal models (LMMs) to automatically annotate human emotions in everyday scenarios. We conducted experiments on the DailyLife subset of the publicly available FERV39k dataset, employing the GPT-4o-mini model for rapid, zero-shot labeling of key frames extracted from video segments. Under a seven-class emotion taxonomy (\"Angry,\" \"Disgust,\" \"Fear,\" \"Happy,\" \"Neutral,\" \"Sad,\" \"Surprise\"), the LMM achieved an average precision of approximately 50%. In contrast, when limited to ternary emotion classification (negative/neutral/positive), the average precision increased to approximately 64%. Additionally, we explored a strategy that integrates multiple frames within 1-2 second video clips to enhance labeling performance and reduce costs. The results indicate that this approach can slightly improve annotation accuracy. Overall, our preliminary findings highlight the potential application of zero-shot LMMs in human facial emotion annotation tasks, offering new avenues for reducing labeling costs and broadening the applicability of LMMs in complex multimodal environments.",
    "source": "arXiv"
  },
  {
    "title": "Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions",
    "title_es": "Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions",
    "url": "https://arxiv.org/abs/2502.13135",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.13135v3 Announce Type: replace \nAbstract: We present an end-to-end framework for generating synthetic users for evaluating interactive agents designed to encourage positive behavior changes, such as in health and lifestyle coaching. The synthetic users are grounded in health and lifestyle conditions, specifically sleep and diabetes management in this study, to ensure realistic interactions with the health coaching agent. Synthetic users are created in two stages: first, structured data are generated grounded in real-world health and lifestyle factors in addition to basic demographics and behavioral attributes; second, full profiles of the synthetic users are developed conditioned on the structured data. Interactions between synthetic users and the coaching agent are simulated using generative agent-based models such as Concordia, or directly by prompting a language model. Using two independently-developed agents for sleep and diabetes coaching as case studies, the validity of this framework is demonstrated by analyzing the coaching agent's understanding of the synthetic users' needs and challenges. Finally, through multiple blinded evaluations of user-coach interactions by human experts, we demonstrate that our synthetic users with health and behavioral attributes more accurately portray real human users with the same attributes, compared to generic synthetic users not grounded in such attributes. The proposed framework lays the foundation for efficient development of conversational agents through extensive, realistic, and grounded simulated interactions.",
    "source": "arXiv"
  },
  {
    "title": "EvoP: Robust LLM Inference via Evolutionary Pruning",
    "title_es": "EvoP: Robust LLM Inference via Evolutionary Pruning",
    "url": "https://arxiv.org/abs/2502.14910",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.14910v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have achieved remarkable success in natural language processing tasks, but their massive size and computational demands hinder their deployment in resource-constrained environments. Existing model pruning methods address this issue by removing redundant structures (e.g., elements, channels, layers) from the model. However, these methods employ a heuristic pruning strategy, which leads to suboptimal performance. Besides, they also ignore the data characteristics when pruning the model.\n  To overcome these limitations, we propose EvoP, an evolutionary pruning framework for robust LLM inference. EvoP first presents a cluster-based calibration dataset sampling (CCDS) strategy for creating a more diverse calibration dataset. EvoP then introduces an evolutionary pruning pattern searching (EPPS) method to find the optimal pruning pattern. Compared to existing model pruning techniques, EvoP achieves the best performance while maintaining the best efficiency. Experiments across different LLMs and different downstream tasks validate the effectiveness of the proposed EvoP, making it a practical and scalable solution for deploying LLMs in real-world applications.",
    "source": "arXiv"
  },
  {
    "title": "Conformal Linguistic Calibration: Trading-off between Factuality and Specificity",
    "title_es": "Conformal Linguistic Calibration: Trading-off between Factuality and Specificity",
    "url": "https://arxiv.org/abs/2502.19110",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.19110v4 Announce Type: replace \nAbstract: Language model outputs are not always reliable, thus prompting research into how to adapt model responses based on uncertainty. Common approaches include: \\emph{abstention}, where models refrain from generating responses when uncertain; and \\emph{linguistic calibration}, where models hedge their statements using uncertainty quantifiers. However, abstention can withhold valuable information, while linguistically calibrated responses are often challenging to leverage in downstream tasks. We propose a unified view, Conformal Linguistic Calibration (CLC), which reinterprets linguistic calibration as \\emph{answer set prediction}. First we present a framework connecting abstention and linguistic calibration through the lens of linguistic pragmatics. We then describe an implementation of CLC that allows for controlling the level of imprecision in model responses. Results demonstrate our method produces calibrated outputs with conformal guarantees on factual accuracy. Further, our approach enables fine-tuning models to perform uncertainty-aware adaptive claim rewriting, offering a controllable balance between factuality and specificity.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Keypoint Affordance Representation for Functional Dexterous Grasping",
    "title_es": "Multi-Keypoint Affordance Representation for Functional Dexterous Grasping",
    "url": "https://arxiv.org/abs/2502.20018",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.20018v2 Announce Type: replace \nAbstract: Functional dexterous grasping requires precise hand-object interaction, going beyond simple gripping. Existing affordance-based methods primarily predict coarse interaction regions and cannot directly constrain the grasping posture, leading to a disconnection between visual perception and manipulation. To address this issue, we propose a multi-keypoint affordance representation for functional dexterous grasping, which directly encodes task-driven grasp configurations by localizing functional contact points. Our method introduces Contact-guided Multi-Keypoint Affordance (CMKA), leveraging human grasping experience images for weak supervision combined with Large Vision Models for fine affordance feature extraction, achieving generalization while avoiding manual keypoint annotations. Additionally, we present a Keypoint-based Grasp matrix Transformation (KGT) method, ensuring spatial consistency between hand keypoints and object contact points, thus providing a direct link between visual perception and dexterous grasping actions. Experiments on public real-world FAH datasets, IsaacGym simulation, and challenging robotic tasks demonstrate that our method significantly improves affordance localization accuracy, grasp consistency, and generalization to unseen tools and tasks, bridging the gap between visual affordance learning and dexterous robotic manipulation. The source code and demo videos are publicly available at https://github.com/PopeyePxx/MKA.",
    "source": "arXiv"
  },
  {
    "title": "Flexible Prefrontal Control over Hippocampal Episodic Memory for Goal-Directed Generalization",
    "title_es": "Flexible Prefrontal Control over Hippocampal Episodic Memory for Goal-Directed Generalization",
    "url": "https://arxiv.org/abs/2503.02303",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.02303v3 Announce Type: replace \nAbstract: Many tasks require flexibly modifying perception and behavior based on current goals. Humans can retrieve episodic memories from days to years ago, using them to contextualize and generalize behaviors across novel but structurally related situations. The brain's ability to control episodic memories based on task demands is often attributed to interactions between the prefrontal cortex (PFC) and hippocampus (HPC). We propose a reinforcement learning model that incorporates a PFC-HPC interaction mechanism for goal-directed generalization. In our model, the PFC learns to generate query-key representations to encode and retrieve goal-relevant episodic memories, modulating HPC memories top-down based on current task demands. Moreover, the PFC adapts its encoding and retrieval strategies dynamically when faced with multiple goals presented in a blocked, rather than interleaved, manner. Our results show that: (1) combining working memory with selectively retrieved episodic memory allows transfer of decisions among similar environments or situations, (2) top-down control from PFC over HPC improves learning of arbitrary structural associations between events for generalization to novel environments compared to a bottom-up sensory-driven approach, and (3) the PFC encodes generalizable representations during both encoding and retrieval of goal-relevant memories, whereas the HPC exhibits event-specific representations. Together, these findings highlight the importance of goal-directed prefrontal control over hippocampal episodic memory for decision-making in novel situations and suggest a computational mechanism by which PFC-HPC interactions enable flexible behavior.",
    "source": "arXiv"
  },
  {
    "title": "A Survey on Web Testing: On the Rise of AI and Applications in Industry",
    "title_es": "A Survey on Web Testing: On the Rise of AI and Applications in Industry",
    "url": "https://arxiv.org/abs/2503.05378",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.05378v2 Announce Type: replace \nAbstract: Web application testing is an essential practice to ensure the reliability, security, and performance of web systems in an increasingly digital world. This paper presents a systematic literature survey focusing on web testing methodologies, tools, and trends from 2014 to 2025. By analyzing 259 research papers, the survey identifies key trends, demographics, contributions, tools, challenges, and innovations in this domain. In addition, the survey analyzes the experimental setups adopted by the studies, including the number of participants involved and the outcomes of the experiments. Our results show that web testing research has been highly active, with ICST as the leading venue. Most studies focus on novel techniques, emphasizing automation in black-box testing. Selenium is the most widely used tool, while industrial adoption and human studies remain comparatively limited. The findings provide a detailed overview of trends, advancements, and challenges in web testing research, the evolution of automated testing methods, the role of artificial intelligence in test case generation, and gaps in current research. Special attention was given to the level of collaboration and engagement with the industry. A positive trend in using industrial systems is observed, though many tools lack open-source availability",
    "source": "arXiv"
  },
  {
    "title": "TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation",
    "title_es": "TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation",
    "url": "https://arxiv.org/abs/2503.07050",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.07050v2 Announce Type: replace \nAbstract: Diffusion Transformers (DiTs) are a powerful yet underexplored class of generative models compared to U-Net-based diffusion architectures. We propose TIDE-Temporal-aware sparse autoencoders for Interpretable Diffusion transformErs-a framework designed to extract sparse, interpretable activation features across timesteps in DiTs. TIDE effectively captures temporally-varying representations and reveals that DiTs naturally learn hierarchical semantics (e.g., 3D structure, object class, and fine-grained concepts) during large-scale pretraining. Experiments show that TIDE enhances interpretability and controllability while maintaining reasonable generation quality, enabling applications such as safe image editing and style transfer.",
    "source": "arXiv"
  },
  {
    "title": "Achieving More with Less: Additive Prompt Tuning for Rehearsal-Free Class-Incremental Learning",
    "title_es": "Achieving More with Less: Additive Prompt Tuning for Rehearsal-Free Class-Incremental Learning",
    "url": "https://arxiv.org/abs/2503.07979",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.07979v2 Announce Type: replace \nAbstract: Class-incremental learning (CIL) enables models to learn new classes progressively while preserving knowledge of previously learned ones. Recent advances in this field have shifted towards parameter-efficient fine-tuning techniques, with many approaches building upon the framework that maintains a pool of learnable prompts. Although effective, these methods introduce substantial computational overhead, primarily due to prompt pool querying and increased input sequence lengths from prompt concatenation. In this work, we present a novel prompt-based approach that addresses this limitation. Our method trains a single set of shared prompts across all tasks and, rather than concatenating prompts to the input, directly modifies the CLS token's attention computation by adding the prompts to it. This simple and lightweight design not only significantly reduces computational complexity-both in terms of inference costs and the number of trainable parameters-but also eliminates the need to optimize prompt lengths for different downstream tasks, offering a more efficient yet powerful solution for rehearsal-free class-incremental learning. Extensive experiments across a diverse range of CIL benchmarks demonstrate the effectiveness of our approach, highlighting its potential to establish a new prompt-based CIL paradigm. Furthermore, experiments on general recognition benchmarks beyond the CIL setting also show strong performance, positioning our method as a promising candidate for a general parameter-efficient fine-tuning approach.",
    "source": "arXiv"
  },
  {
    "title": "Gait in Eight: Efficient On-Robot Learning for Omnidirectional Quadruped Locomotion",
    "title_es": "Gait in Eight: Efficient On-Robot Learning for Omnidirectional Quadruped Locomotion",
    "url": "https://arxiv.org/abs/2503.08375",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.08375v2 Announce Type: replace \nAbstract: On-robot Reinforcement Learning is a promising approach to train embodiment-aware policies for legged robots. However, the computational constraints of real-time learning on robots pose a significant challenge. We present a framework for efficiently learning quadruped locomotion in just 8 minutes of raw real-time training utilizing the sample efficiency and minimal computational overhead of the new off-policy algorithm CrossQ. We investigate two control architectures: Predicting joint target positions for agile, high-speed locomotion and Central Pattern Generators for stable, natural gaits. While prior work focused on learning simple forward gaits, our framework extends on-robot learning to omnidirectional locomotion. We demonstrate the robustness of our approach in different indoor and outdoor environments.",
    "source": "arXiv"
  },
  {
    "title": "OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions",
    "title_es": "OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions",
    "url": "https://arxiv.org/abs/2503.10331",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.10331v2 Announce Type: replace \nAbstract: Open Semantic Mapping (OSM) is a key technology in robotic perception, combining semantic segmentation and SLAM techniques. This paper introduces a dynamically configurable and highly automated LLM/LVLM-powered pipeline for evaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark). The study focuses on evaluating state-of-the-art semantic mapping algorithms under varying indoor lighting conditions, a critical challenge in indoor environments. We introduce a novel dataset with simulated RGB-D sequences and ground truth 3D reconstructions, facilitating the rigorous analysis of mapping performance across different lighting conditions. Through experiments on leading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the semantic fidelity of object recognition and segmentation. Additionally, we introduce a Scene Graph evaluation method to analyze the ability of models to interpret semantic structure. The results provide insights into the robustness of these models, forming future research directions for developing resilient and adaptable robotic systems. Project page is available at https://be2rlab.github.io/OSMa-Bench/.",
    "source": "arXiv"
  },
  {
    "title": "Triad: Empowering LMM-based Anomaly Detection with Vision Expert-guided Visual Tokenizer and Manufacturing Process",
    "title_es": "Triad: Empowering LMM-based Anomaly Detection with Vision Expert-guided Visual Tokenizer and Manufacturing Process",
    "url": "https://arxiv.org/abs/2503.13184",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.13184v2 Announce Type: replace \nAbstract: Although recent methods have tried to introduce large multimodal models (LMMs) into industrial anomaly detection (IAD), their generalization in the IAD field is far inferior to that for general purposes. We summarize the main reasons for this gap into two aspects. On one hand, general-purpose LMMs lack cognition of defects in the visual modality, thereby failing to sufficiently focus on defect areas. Therefore, we propose to modify the AnyRes structure of the LLaVA model, providing the potential anomalous areas identified by existing IAD models to the LMMs. On the other hand, existing methods mainly focus on identifying defects by learning defect patterns or comparing with normal samples, yet they fall short of understanding the causes of these defects. Considering that the generation of defects is closely related to the manufacturing process, we propose a manufacturing-driven IAD paradigm. An instruction-tuning dataset for IAD (InstructIAD) and a data organization approach for Chain-of-Thought with manufacturing (CoT-M) are designed to leverage the manufacturing process for IAD. Based on the above two modifications, we present Triad, a novel LMM-based method incorporating an expert-guided region-of-interest tokenizer and manufacturing process for industrial anomaly detection. Extensive experiments show that our Triad not only demonstrates competitive performance against current LMMs but also achieves further improved accuracy when equipped with manufacturing processes. Source code, training data, and pre-trained models will be publicly available at https://github.com/tzjtatata/Triad.",
    "source": "arXiv"
  },
  {
    "title": "SketchSplat: 3D Edge Reconstruction via Differentiable Multi-view Sketch Splatting",
    "title_es": "SketchSplat: 3D Edge Reconstruction via Differentiable Multi-view Sketch Splatting",
    "url": "https://arxiv.org/abs/2503.14786",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.14786v2 Announce Type: replace \nAbstract: Edges are one of the most basic parametric primitives to describe structural information in 3D. In this paper, we study parametric 3D edge reconstruction from calibrated multi-view images. Previous methods usually reconstruct a 3D edge point set from multi-view 2D edge images, and then fit 3D edges to the point set. However, noise in the point set may cause gaps among fitted edges, and the recovered edges may not align with input multi-view images since the edge fitting depends only on the reconstructed 3D point set. To mitigate these problems, we propose SketchSplat, a method to reconstruct accurate, complete, and compact 3D edges via differentiable multi-view sketch splatting. We represent 3D edges as sketches, which are parametric lines and curves defined by attributes including control points, scales, and opacity. During reconstruction, we iteratively sample Gaussian points from a set of sketches and rasterize the Gaussians onto 2D edge images. Then the gradient of the image loss can be back-propagated to optimize the sketch attributes. Our method bridges 2D edge images and 3D edges in a differentiable manner, which ensures that 3D edges align well with 2D images and leads to accurate and complete results. We also propose a series of adaptive topological operations to reduce redundant edges and apply them along with the sketch optimization, yielding a more compact reconstruction. Finally, we contribute an accurate 2D edge detector that improves the performance of both ours and existing methods. Experiments show that our method achieves state-of-the-art accuracy, completeness, and compactness on a benchmark CAD dataset.",
    "source": "arXiv"
  },
  {
    "title": "Impedance Space Method: Time-Independent Parametric Ellipses for Robot Compliant Control",
    "title_es": "Impedance Space Method: Time-Independent Parametric Ellipses for Robot Compliant Control",
    "url": "https://arxiv.org/abs/2503.17533",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.17533v2 Announce Type: replace \nAbstract: This paper proposes a novel 3D graphical representation for impedance control, called the impedance space, to foster the analysis of the dynamic behavior of robotic compliant controllers. The method overcomes limitations of existing 2D graphical approaches by incorporating mass, stiffness, and damping dynamics, and associates the impedance control parameters with linear transformations to plot a parametric 3D ellipse and its projections in 2D for a mass-spring-damper impedance under sinusoidal reference. Experimental evaluation demonstrates the effectiveness of the proposed representation for analysis of impedance control. The method applies to various compliant control topologies and can be extended to other model-based control approaches.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating Large Language Models for Automated Clinical Abstraction in Pulmonary Embolism Registries: Performance Across Model Sizes, Versions, and Parameters",
    "title_es": "Evaluating Large Language Models for Automated Clinical Abstraction in Pulmonary Embolism Registries: Performance Across Model Sizes, Versions, and Parameters",
    "url": "https://arxiv.org/abs/2503.21004",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.21004v3 Announce Type: replace \nAbstract: Pulmonary embolism (PE) registries accelerate practice-improving research but depend on resource-intensive manual abstraction of radiology reports. We evaluated whether openly available large-language models (LLMs) can automate concept extraction from computed-tomography PE (CTPE) reports without sacrificing data quality. Four Llama-3 (L3) variants (3.0 8 B, 3.1 8 B, 3.1 70 B, 3.3 70 B) and two reviewer models Phi-4 (P4) 14 B and Gemma-3 27 B (G3) were tested on 250 dual-annotated CTPE reports each from MIMIC-IV and Duke University. Outcomes were accuracy, positive predictive value (PPV), and negative predictive value (NPV) versus a human gold standard across model sizes, temperature settings, and shot counts. Mean accuracy across all concepts increased with scale: 0.83 (L3-0 8 B), 0.91 (L3-1 8 B), and 0.96 for both 70 B variants; P4 14 B achieved 0.98; G3 matched. Accuracy differed by = 0.95 and NPV >= 0.98, while location, thrombus burden, right-heart strain, and image-quality artifacts each maintained PPV >= 0.90 and NPV >= 0.95. Fewer than 4% of individual concept annotations were discordant, and complete agreement was observed in more than 75% of reports. G3 performed comparably. LLMs therefore offer a scalable, accurate solution for PE registry abstraction, and a dual-model review workflow can further safeguard data quality with minimal human oversight.",
    "source": "arXiv"
  },
  {
    "title": "ObfusQate: Unveiling the First Quantum Program Obfuscation Framework",
    "title_es": "ObfusQate: Unveiling the First Quantum Program Obfuscation Framework",
    "url": "https://arxiv.org/abs/2503.23785",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.23785v2 Announce Type: replace \nAbstract: This paper introduces ObfusQate, a novel tool that conducts obfuscations using quantum primitives to enhance the security of both classical and quantum programs. We have designed and implemented two primary categories of obfuscations: quantum circuit level obfuscation and code level obfuscation, encompassing a total of eight distinct methods. Quantum circuit-level obfuscation leverages on quantum gates and circuits, utilizing strategies such as quantum gate hiding and identity matrices to construct complex, non-intuitive circuits that effectively obscure core functionalities and resist reverse engineering, making the underlying code difficult to interpret. Meanwhile, code-level obfuscation manipulates the logical sequence of program operations through quantum-based opaque predicates, obfuscating execution paths and rendering program behavior more unpredictable and challenging to analyze. Additionally, ObfusQate can be used to obfuscate malicious code segments, making them harder to detect and analyze. These advancements establish a foundational framework for further exploration into the potential and limitations of quantum-based obfuscation techniques, positioning ObfusQate as a valuable tool for future developers to enhance code security in the evolving landscape of software development. To the best of our knowledge, ObfusQate represents the pioneering work in developing an automated framework for implementing obfuscations leveraging quantum primitives. Security evaluations show that obfuscations by ObfusQate maintain code behavior with polynomial overheads in space and time complexities. We have also demonstrated an offensive use case by embedding a keylogger into Shor's algorithm and obfuscating it using ObfusQate. Our results show that current Large language models like GPT 4o, GPT o3 mini and Grok 3 were not able to identify the malicious keylogger after obfuscation.",
    "source": "arXiv"
  },
  {
    "title": "Opioid Named Entity Recognition (ONER-2025) from Reddit",
    "title_es": "Opioid Named Entity Recognition (ONER-2025) from Reddit",
    "url": "https://arxiv.org/abs/2504.00027",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.00027v4 Announce Type: replace \nAbstract: The opioid overdose epidemic remains a critical public health crisis, particularly in the United States, leading to significant mortality and societal costs. Social media platforms like Reddit provide vast amounts of unstructured data that offer insights into public perceptions, discussions, and experiences related to opioid use. This study leverages Natural Language Processing (NLP), specifically Opioid Named Entity Recognition (ONER-2025), to extract actionable information from these platforms. Our research makes four key contributions. First, we created a unique, manually annotated dataset sourced from Reddit, where users share self-reported experiences of opioid use via different administration routes. This dataset contains 331,285 tokens and includes eight major opioid entity categories. Second, we detail our annotation process and guidelines while discussing the challenges of labeling the ONER-2025 dataset. Third, we analyze key linguistic challenges, including slang, ambiguity, fragmented sentences, and emotionally charged language, in opioid discussions. Fourth, we propose a real-time monitoring system to process streaming data from social media, healthcare records, and emergency services to identify overdose events. Using 5-fold cross-validation in 11 experiments, our system integrates machine learning, deep learning, and transformer-based language models with advanced contextual embeddings to enhance understanding. Our transformer-based models (bert-base-NER and roberta-base) achieved 97% accuracy and F1-score, outperforming baselines by 10.23% (RF=0.88).",
    "source": "arXiv"
  },
  {
    "title": "CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation",
    "title_es": "CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation",
    "url": "https://arxiv.org/abs/2504.00043",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.00043v2 Announce Type: replace \nAbstract: Existing reasoning evaluation frameworks for Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) predominantly assess either text-based reasoning or vision-language understanding capabilities, with limited dynamic interplay between textual and visual constraints. To address this limitation, we introduce CrossWordBench, a benchmark designed to evaluate the reasoning capabilities of both LLMs and LVLMs through the medium of crossword puzzles -- a task requiring multimodal adherence to semantic constraints from text-based clues and intersectional constraints from visual grid structures. CrossWordBench leverages a controllable puzzle generation framework that produces puzzles in two formats (text and image), supports adjustable difficulty through prefill ratio control, and offers different evaluation strategies, ranging from direct puzzle solving to interactive modes. Our extensive evaluation of over 20 models reveals that reasoning LLMs substantially outperform non-reasoning models by effectively leveraging crossing-letter constraints. We further demonstrate that LVLMs struggle with the task, showing a strong correlation between their puzzle-solving performance and grid-parsing accuracy. Our findings highlight limitations of the reasoning capabilities of current LLMs and LVLMs, and provide an effective approach for creating multimodal constrained tasks for future evaluations.",
    "source": "arXiv"
  },
  {
    "title": "The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction",
    "title_es": "The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction",
    "url": "https://arxiv.org/abs/2504.01260",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.01260v2 Announce Type: replace \nAbstract: This study explores how human perceptions of a non-anthropomorphic robotic manipulator are shaped by two key dimensions of behaviour: arousal, defined as the robot's movement energy and expressiveness, and attention, defined as the robot's capacity to selectively orient toward and engage with a user. We introduce a novel control architecture that integrates a gaze-like attention engine with an arousal-modulated motion system to generate socially meaningful behaviours. In a user study, we find that robots exhibiting high attention -- actively directing their focus toward users -- are perceived as warmer and more competent, intentional, and lifelike. In contrast, high arousal -- characterized by fast, expansive, and energetic motions -- increases perceptions of discomfort and disturbance. Importantly, a combination of focused attention and moderate arousal yields the highest ratings of trust and sociability, while excessive arousal diminishes social engagement. These findings offer design insights for endowing non-humanoid robots with expressive, intuitive behaviours that support more natural human-robot interaction.",
    "source": "arXiv"
  },
  {
    "title": "Anticipating Degradation: A Predictive Approach to Fault Tolerance in Robot Swarms",
    "title_es": "Anticipating Degradation: A Predictive Approach to Fault Tolerance in Robot Swarms",
    "url": "https://arxiv.org/abs/2504.01594",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.01594v2 Announce Type: replace \nAbstract: An active approach to fault tolerance is essential for robot swarms to achieve long-term autonomy. Previous efforts have focused on responding to spontaneous electro-mechanical faults and failures. However, many faults occur gradually over time. Waiting until such faults have manifested as failures before addressing them is both inefficient and unsustainable in a variety of scenarios. This work argues that the principles of predictive maintenance, in which potential faults are resolved before they hinder the operation of the swarm, offer a promising means of achieving long-term fault tolerance. This is a novel approach to swarm fault tolerance, which is shown to give a comparable or improved performance when tested against a reactive approach in almost all cases tested.",
    "source": "arXiv"
  },
  {
    "title": "On Composable and Parametric Uncertainty in Systems Co-Design",
    "title_es": "On Composable and Parametric Uncertainty in Systems Co-Design",
    "url": "https://arxiv.org/abs/2504.02766",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.02766v2 Announce Type: replace \nAbstract: Optimizing the design of complex systems requires navigating interdependent decisions, heterogeneous components, and multiple objectives. Our monotone theory of co-design offers a compositional framework for addressing this challenge, modeling systems as Design Problems (DPs), representing trade-offs between functionalities and resources within partially ordered sets. While current approaches model uncertainty using intervals, capturing worst- and best-case bounds, they fail to express probabilistic notions such as risk and confidence. These limitations hinder the applicability of co-design in domains where uncertainty plays a critical role. In this paper, we introduce a unified framework for composable uncertainty in co-design, capturing intervals, distributions, and parametrized models. This extension enables reasoning about risk-performance trade-offs and supports advanced queries such as experiment design, learning, and multi-stage decision making. We demonstrate the expressiveness and utility of the framework via a numerical case study on the uncertainty-aware co-design of task-driven Unmanned Aerial Vehicles (UAVs).",
    "source": "arXiv"
  },
  {
    "title": "AI-induced sexual harassment: Investigating Contextual Characteristics and User Reactions of Sexual Harassment by a Companion Chatbot",
    "title_es": "AI-induced sexual harassment: Investigating Contextual Characteristics and User Reactions of Sexual Harassment by a Companion Chatbot",
    "url": "https://arxiv.org/abs/2504.04299",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.04299v2 Announce Type: replace \nAbstract: Advancements in artificial intelligence (AI) have led to the increase of conversational agents like Replika, designed to provide social interaction and emotional support. However, reports of these AI systems engaging in inappropriate sexual behaviors with users have raised significant concerns. In this study, we conducted a thematic analysis of user reviews from the Google Play Store to investigate instances of sexual harassment by the Replika chatbot. From a dataset of 35,105 negative reviews, we identified 800 relevant cases for analysis. Our findings revealed that users frequently experience unsolicited sexual advances, persistent inappropriate behavior, and failures of the chatbot to respect user boundaries. Users expressed feelings of discomfort, violation of privacy, and disappointment, particularly when seeking a platonic or therapeutic AI companion. This study highlights the potential harms associated with AI companions and underscores the need for developers to implement effective safeguards and ethical guidelines to prevent such incidents. By shedding light on user experiences of AI-induced harassment, we contribute to the understanding of AI-related risks and emphasize the importance of corporate responsibility in developing safer and more ethical AI systems.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Computation Pruning for the Forgetting Transformer",
    "title_es": "Adaptive Computation Pruning for the Forgetting Transformer",
    "url": "https://arxiv.org/abs/2504.06949",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.06949v2 Announce Type: replace \nAbstract: The recently proposed Forgetting Transformer (FoX) incorporates a forget gate into softmax attention and has shown consistently better or on-par performance compared to the standard RoPE-based Transformer. Notably, many attention heads in FoX tend to forget quickly, causing their output at each timestep to rely primarily on local context. Based on this observation, we propose Adaptive Computation Pruning (ACP) for FoX, a method that dynamically prunes computations involving input-output dependencies that are strongly decayed by the forget gate. In particular, our method performs provably safe pruning via a dynamically set pruning threshold that guarantees the pruned attention weights are negligible. We apply ACP to language model pretraining with FoX and show it consistently reduces the number of FLOPs and memory accesses in softmax attention by around 70% across different model sizes and context lengths, resulting in a roughly 50% to 70% reduction in attention runtime (or a 2-3$\\times$ speedup) and a roughly 10% to 40% increase in end-to-end training throughput. Furthermore, longer context lengths yield greater computational savings. All these speed improvements are achieved without any performance degradation. Our code is available at https://github.com/zhixuan-lin/forgetting-transformer.",
    "source": "arXiv"
  },
  {
    "title": "ChatBench: From Static Benchmarks to Human-AI Evaluation",
    "title_es": "ChatBench: From Static Benchmarks to Human-AI Evaluation",
    "url": "https://arxiv.org/abs/2504.07114",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.07114v2 Announce Type: replace \nAbstract: With the rapid adoption of LLM-based chatbots, there is a pressing need to evaluate what humans and LLMs can achieve together. However, standard benchmarks, such as MMLU, measure LLM capabilities in isolation (i.e., \"AI-alone\"). Here, we design and conduct a user study to convert MMLU questions into user-AI conversations, by seeding the user with the question and having them carry out a conversation with the LLM to answer their question. We release ChatBench, a new dataset with AI-alone, user-alone, and user-AI data for 396 questions and two LLMs, including 144K answers and 7,336 user-AI conversations. We find that AI-alone accuracy fails to predict user-AI accuracy, with significant differences across multiple subjects (math, physics, and moral reasoning), and we analyze the user-AI conversations to provide insight into how they diverge from AI-alone benchmarks. Finally, we show that fine-tuning a user simulator on a subset of ChatBench improves its ability to estimate user-AI accuracies, increasing correlation on held-out questions by more than 20 points, creating possibilities for scaling interactive evaluation.",
    "source": "arXiv"
  },
  {
    "title": "ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning",
    "title_es": "ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning",
    "url": "https://arxiv.org/abs/2504.08713",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.08713v5 Announce Type: replace \nAbstract: Deep learning-based electrocardiogram (ECG) classification has shown impressive performance but clinical adoption has been slowed by the lack of transparent and faithful explanations. Post hoc methods such as saliency maps may fail to reflect a model's true decision process. Prototype-based reasoning offers a more transparent alternative by grounding decisions in similarity to learned representations of real ECG segments, enabling faithful, case-based explanations. We introduce ProtoECGNet, a prototype-based deep learning model for interpretable, multi-label ECG classification. ProtoECGNet employs a structured, multi-branch architecture that reflects clinical interpretation workflows: it integrates a 1D CNN with global prototypes for rhythm classification, a 2D CNN with time-localized prototypes for morphology-based reasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Each branch is trained with a prototype loss designed for multi-label learning, combining clustering, separation, diversity, and a novel contrastive loss that encourages appropriate separation between prototypes of unrelated classes while allowing clustering for frequently co-occurring diagnoses. We evaluate ProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstrating competitive performance relative to state-of-the-art black-box models while providing structured, case-based explanations. To assess prototype quality, we conduct a structured clinician review of the final model's projected prototypes, finding that they are rated as representative and clear. ProtoECGNet shows that prototype learning can be effectively scaled to complex, multi-label time-series classification, offering a practical path toward transparent and trustworthy deep learning models for clinical decision support.",
    "source": "arXiv"
  },
  {
    "title": "Enhancing Wide-Angle Image Using Narrow-Angle View of the Same Scene",
    "title_es": "Enhancing Wide-Angle Image Using Narrow-Angle View of the Same Scene",
    "url": "https://arxiv.org/abs/2504.09455",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.09455v3 Announce Type: replace \nAbstract: A common dilemma while photographing a scene is whether to capture it at a wider angle, allowing more of the scene to be covered but in less detail or to click in a narrow angle that captures better details but leaves out portions of the scene. We propose a novel method in this paper that infuses wider shots with finer quality details that is usually associated with an image captured by the primary lens by capturing the same scene using both narrow and wide field of view (FoV) lenses. We do so by training a Generative Adversarial Network (GAN)-based model to learn to extract the visual quality parameters from a narrow-angle shot and to transfer these to the corresponding wide-angle image of the scene using residual connections and an attention-based fusion module. We have mentioned in details the proposed technique to isolate the visual essence of an image and to transfer it into another image. We have also elaborately discussed our implementation details and have presented the results of evaluation over several benchmark datasets and comparisons with contemporary advancements in the field.",
    "source": "arXiv"
  },
  {
    "title": "Mixture-of-RAG: Integrating Text and Tables with Large Language Models",
    "title_es": "Mixture-of-RAG: Integrating Text and Tables with Large Language Models",
    "url": "https://arxiv.org/abs/2504.09554",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.09554v2 Announce Type: replace \nAbstract: Large language models (LLMs) achieve optimal utility when their responses are grounded in external knowledge sources. However, real-world documents, such as annual reports, scientific papers, and clinical guidelines, frequently combine extensive narrative content with complex, hierarchically structured tables. While existing retrieval-augmented generation (RAG) systems effectively integrate LLMs' generative capabilities with external retrieval-based information, their performance significantly deteriorates when processing such heterogeneous text-table hierarchies. To address this limitation, we formalize the task of Heterogeneous Document RAG, which requires joint retrieval and reasoning across textual and hierarchical tabular data. We propose MixRAG, a novel three-stage framework: (i) hierarchy row-and-column-level (H-RCL) representation that preserves hierarchical structure and heterogeneous relationships, (ii) an ensemble retriever with LLM-based reranking for evidence alignment, and (iii) multi-step reasoning decomposition via a RECAP prompt strategy. To bridge the gap in available data for this domain, we release a large-scale dataset, DocRAGLib, a 2k-document corpus paired with automatically aligned text-table summaries and gold document annotations. The comprehensive experimental results demonstrate that MixRAG boosts top-1 retrieval by 46% over strong text-only, table-only, and naive-mixture baselines, establishing new state-of-the-art performance for mixed-modality document grounding.",
    "source": "arXiv"
  },
  {
    "title": "Masked Autoencoder Self Pre-Training for Defect Detection in Microelectronics",
    "title_es": "Masked Autoencoder Self Pre-Training for Defect Detection in Microelectronics",
    "url": "https://arxiv.org/abs/2504.10021",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.10021v2 Announce Type: replace \nAbstract: While transformers have surpassed convolutional neural networks (CNNs) in various computer vision tasks, microelectronics defect detection still largely relies on CNNs. We hypothesize that this gap is due to the fact that a) transformers have an increased need for data and b) (labelled) image generation procedures for microelectronics are costly, and data is therefore sparse. Whereas in other domains, pre-training on large natural image datasets can mitigate this problem, in microelectronics transfer learning is hindered due to the dissimilarity of domain data and natural images. We address this challenge through self pre-training, where models are pre-trained directly on the target dataset, rather than another dataset. We propose a resource-efficient vision transformer (ViT) pre-training framework for defect detection in microelectronics based on masked autoencoders (MAE). We perform pre-training and defect detection using a dataset of less than 10,000 scanning acoustic microscopy (SAM) images. Our experimental results show that our approach leads to substantial performance gains compared to a) supervised ViT, b) ViT pre-trained on natural image datasets, and c) state-of-the-art CNN-based defect detection models used in microelectronics. Additionally, interpretability analysis reveals that our self pre-trained models attend to defect-relevant features such as cracks in the solder material, while baseline models often attend to spurious patterns. This shows that our approach yields defect-specific feature representations, resulting in more interpretable and generalizable transformer models for this data-sparse domain.",
    "source": "arXiv"
  },
  {
    "title": "Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image Dynamics Correction",
    "title_es": "Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image Dynamics Correction",
    "url": "https://arxiv.org/abs/2504.10080",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.10080v2 Announce Type: replace \nAbstract: In this paper, we explore how conventional image enhancement can improve model robustness in medical image analysis. By applying commonly used normalization methods to images from various vendors and studying their influence on model generalization in transfer learning, we show that the nonlinear characteristics of domain-specific image dynamics cannot be addressed by simple linear transforms. To tackle this issue, we reformulate the image harmonization task as an exposure correction problem and propose a method termed Global Deep Curve Estimation (GDCE) to reduce domain-specific exposure mismatch. GDCE performs enhancement via a pre-defined polynomial function and is trained with a \"domain discriminator\", aiming to improve model transparency in downstream tasks compared to existing black-box methods.",
    "source": "arXiv"
  },
  {
    "title": "When Technologies Are Not Enough: Understanding How Domestic Workers Employ (and Avoid) Online Technologies in Their Work Practices",
    "title_es": "When Technologies Are Not Enough: Understanding How Domestic Workers Employ (and Avoid) Online Technologies in Their Work Practices",
    "url": "https://arxiv.org/abs/2504.10265",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.10265v2 Announce Type: replace \nAbstract: Although domestic work is often viewed as manual labor, it involves significant interaction with online technologies. However, the detailed exploration of how domestic workers use these technologies remains limited. This study examines the impact of online technologies on domestic workers' work practices, perceptions, and relationships with customers and employers. We interviewed 30 domestic workers residing in the United States, who provided examples that highlight the insufficient transformative role of current online technologies in their work. By conducting a thematic analysis, we characterize how they approach and avoid these digital tools at different stages of their work. Through these findings, we investigate the limitations of technology and identify challenges and opportunities that could inform the design of more suitable tools to improve the conditions of this marginalized group.",
    "source": "arXiv"
  },
  {
    "title": "Minimal Sensing for Orienting a Solar Panel",
    "title_es": "Minimal Sensing for Orienting a Solar Panel",
    "url": "https://arxiv.org/abs/2504.10765",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.10765v2 Announce Type: replace \nAbstract: A solar panel harvests the most energy when pointing in the direction that maximizes the total illumination (irradiance) falling on it. Given an arbitrary panel orientation and an arbitrary environmental illumination, we address the problem of finding the direction of maximum total irradiance. We develop a minimal sensing approach where measurements from just four photodetectors are used to iteratively vary the tilt of the panel to maximize the irradiance. Many environments produce irradiance functions with multiple local maxima. As a result, simply measuring the gradient of the irradiance function and applying gradient ascent will not work. We show that a larger, optimized tilt between the detectors and the panel is equivalent to blurring the irradiance function. This has the effect of eliminating local maxima and turning the irradiance function into a unimodal one, whose maximum can be found using gradient ascent. We show that there is a close relationship between our approach and scale space theory. We collected a large dataset of high-dynamic range lighting environments in Manhattan, called UrbanSky. We use this dataset to conduct simulations to verify the robustness of our approach. Next, we simulate the energy harvested using our approach under dynamic illumination. Finally, we built a portable solar panel with four compact detectors and an actuator to conduct experiments in various real-world settings: direct sunlight, cloudy sky, urban settings with occlusions and shadows, and complex indoor lighting. In all cases, we show improvements in harvested energy compared to standard approaches for orienting a solar panel.",
    "source": "arXiv"
  },
  {
    "title": "Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students",
    "title_es": "Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students",
    "url": "https://arxiv.org/abs/2504.10961",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.10961v2 Announce Type: replace \nAbstract: As generative AI models, particularly large language models (LLMs), transform educational feedback practices in higher education (HE) contexts, understanding students' perceptions of different sources of feedback becomes crucial for their effective implementation and adoption. This study addresses a critical gap by comparing undergraduate students' trust in LLM, human, and human-AI co-produced feedback in their authentic HE context. More specifically, through a within-subject experimental design involving 91 participants, we investigated factors that predict students' ability to distinguish between feedback types, their perceptions of feedback quality, and potential biases related to the source of feedback. Findings revealed that when the source was blinded, students generally preferred AI and co-produced feedback over human feedback regarding perceived usefulness and objectivity. However, they presented a strong bias against AI when the source of feedback was disclosed. In addition, only AI feedback suffered a decline in perceived genuineness when feedback sources were revealed, while co-produced feedback maintained its positive perception. Educational AI experience improved students' ability to identify LLM-generated feedback and increased their trust in all types of feedback. More years of students' experience using AI for general purposes were associated with lower perceived usefulness and credibility of feedback. These insights offer substantial evidence of the importance of source credibility and the need to enhance both feedback literacy and AI literacy to mitigate bias in student perceptions for AI-generated feedback to be adopted and impact education.",
    "source": "arXiv"
  },
  {
    "title": "Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Immersive Audiobook Generation",
    "title_es": "Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Immersive Audiobook Generation",
    "url": "https://arxiv.org/abs/2504.11002",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.11002v2 Announce Type: replace \nAbstract: Audiobook generation aims to create rich, immersive listening experiences from multimodal inputs, but current approaches face three critical challenges: (1) the lack of synergistic generation of diverse audio types (e.g., speech, sound effects, and music) with precise temporal and semantic alignment; (2) the difficulty in conveying expressive, fine-grained emotions, which often results in machine-like vocal outputs; and (3) the absence of automated evaluation frameworks that align with human preferences for complex and diverse audio. To address these issues, we propose Dopamine Audiobook, a novel unified training-free multi-agent system, where a multimodal large language model (MLLM) serves two specialized roles (i.e., speech designer and audio designer) for emotional, human-like, and immersive audiobook generation and evaluation. Specifically, we firstly propose a flow-based, context-aware framework for diverse audio generation with word-level semantic and temporal alignment. To enhance expressiveness, we then design word-level paralinguistic augmentation, utterance-level prosody retrieval, and adaptive TTS model selection. Finally, for evaluation, we introduce a novel MLLM-based evaluation framework incorporating self-critique, perspective-taking, and psychological MagicEmo prompts to ensure human-aligned and self-aligned assessments. Experimental results demonstrate that our method achieves state-of-the-art (SOTA) performance on multiple metrics. Importantly, our evaluation framework shows better alignment with human preferences and transferability across audio tasks.",
    "source": "arXiv"
  },
  {
    "title": "SPIE: Semantic and Structural Post-Training of Image Editing Diffusion Models with AI feedback",
    "title_es": "SPIE: Semantic and Structural Post-Training of Image Editing Diffusion Models with AI feedback",
    "url": "https://arxiv.org/abs/2504.12833",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.12833v2 Announce Type: replace \nAbstract: This paper presents SPIE: a novel approach for semantic and structural post-training of instruction-based image editing diffusion models, addressing key challenges in alignment with user prompts and consistency with input images. We introduce an online reinforcement learning framework that aligns the diffusion model with human preferences without relying on extensive human annotations or curating a large dataset. Our method significantly improves the alignment with instructions and realism in two ways. First, SPIE captures fine nuances in the desired edit by leveraging a visual prompt, enabling detailed control over visual edits without lengthy textual prompts. Second, it achieves precise and structurally coherent modifications in complex scenes while maintaining high fidelity in instruction-irrelevant areas. This approach simplifies users' efforts to achieve highly specific edits, requiring only 5 reference images depicting a certain concept for training. Experimental results demonstrate that SPIE can perform intricate edits in complex scenes, after just 10 training steps. Finally, we showcase the versatility of our method by applying it to robotics, where targeted image edits enhance the visual realism of simulated environments, which improves their utility as proxy for real-world settings.",
    "source": "arXiv"
  },
  {
    "title": "Retrieval-Augmented Generation with Conflicting Evidence",
    "title_es": "Retrieval-Augmented Generation with Conflicting Evidence",
    "url": "https://arxiv.org/abs/2504.13079",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.13079v2 Announce Type: replace \nAbstract: Large language model (LLM) agents are increasingly employing retrieval-augmented generation (RAG) to improve the factuality of their responses. However, in practice, these systems often need to handle ambiguous user queries and potentially conflicting information from multiple sources while also suppressing inaccurate information from noisy or irrelevant documents. Prior work has generally studied and addressed these challenges in isolation, considering only one aspect at a time, such as handling ambiguity or robustness to noise and misinformation. We instead consider multiple factors simultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and Misinformation in Documents), a new dataset that simulates complex and realistic scenarios for conflicting evidence for a user query, including ambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent approach in which LLM agents debate over the merits of an answer over multiple rounds, allowing an aggregator to collate responses corresponding to disambiguated entities while discarding misinformation and noise, thereby handling diverse sources of conflict jointly. We demonstrate the effectiveness of MADAM-RAG using both closed and open-source models on AmbigDocs -- which requires presenting all valid answers for ambiguous queries -- improving over strong RAG baselines by up to 11.40% and on FaithEval -- which requires suppressing misinformation -- where we improve by up to 15.80% (absolute) with Llama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for existing RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match score). While MADAM-RAG begins to address these conflicting factors, our analysis indicates that a substantial gap remains especially when increasing the level of imbalance in supporting evidence and misinformation.",
    "source": "arXiv"
  },
  {
    "title": "Cross-Modal Temporal Fusion for Financial Market Forecasting",
    "title_es": "Cross-Modal Temporal Fusion for Financial Market Forecasting",
    "url": "https://arxiv.org/abs/2504.13522",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.13522v2 Announce Type: replace \nAbstract: Accurate forecasting in financial markets requires integrating diverse data sources, from historical prices to macroeconomic indicators and financial news. However, existing models often fail to align these modalities effectively, limiting their practical use. In this paper, we introduce a transformer-based deep learning framework, Cross-Modal Temporal Fusion (CMTF), that fuses structured and unstructured financial data for improved market prediction. The model incorporates a tensor interpretation module for feature selection and an auto-training pipeline for efficient hyperparameter tuning. Experimental results using FTSE 100 stock data demonstrate that CMTF achieves superior performance in price direction classification compared to classical and deep learning baselines. These findings suggest that our framework is an effective and scalable solution for real-world cross-modal financial forecasting tasks.",
    "source": "arXiv"
  },
  {
    "title": "Democracy of AI Numerical Weather Models: An Example of Global Forecasting with FourCastNetv2 Made by a University Research Lab Using GPU",
    "title_es": "Democracy of AI Numerical Weather Models: An Example of Global Forecasting with FourCastNetv2 Made by a University Research Lab Using GPU",
    "url": "https://arxiv.org/abs/2504.17028",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.17028v3 Announce Type: replace \nAbstract: This paper demonstrates the feasibility of democratizing AI-driven global weather forecasting models among university research groups by leveraging Graphics Processing Units (GPUs) and freely available AI models, such as NVIDIA's FourCastNetv2. FourCastNetv2 is an NVIDIA's advanced neural network for weather prediction and is trained on a 73-channel subset of the European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset at single levels and different pressure levels. Although the training specifications for FourCastNetv2 are not released to the public, the training documentation of the model's first generation, FourCastNet, is available to all users. The training had 64 A100 GPUs and took 16 hours to complete. Although NVIDIA's models offer significant reductions in both time and cost compared to traditional Numerical Weather Prediction (NWP), reproducing published forecasting results presents ongoing challenges for resource-constrained university research groups with limited GPU availability. We demonstrate both (i) leveraging FourCastNetv2 to create predictions through the designated application programming interface (API) and (ii) utilizing NVIDIA hardware to train the original FourCastNet model. Further, this paper demonstrates the capabilities and limitations of NVIDIA A100's for resource-limited research groups in universities. We also explore data management, training efficiency, and model validation, highlighting the advantages and challenges of using limited high-performance computing resources. Consequently, this paper and its corresponding GitHub materials may serve as an initial guide for other university research groups and courses related to machine learning, climate science, and data science to develop research and education programs on AI weather forecasting, and hence help democratize the AI NWP in the digital economy.",
    "source": "arXiv"
  },
  {
    "title": "Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence",
    "title_es": "Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence",
    "url": "https://arxiv.org/abs/2504.17703",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.17703v3 Announce Type: replace \nAbstract: Federated Learning (FL) has emerged as a transformative paradigm in the field of distributed machine learning, enabling multiple clients such as mobile devices, edge nodes, or organizations to collaboratively train a shared global model without the need to centralize sensitive data. This decentralized approach addresses growing concerns around data privacy, security, and regulatory compliance, making it particularly attractive in domains such as healthcare, finance, and smart IoT systems. This survey provides a concise yet comprehensive overview of Federated Learning, beginning with its core architecture and communication protocol. We discuss the standard FL lifecycle, including local training, model aggregation, and global updates. A particular emphasis is placed on key technical challenges such as handling non-IID (non-independent and identically distributed) data, mitigating system and hardware heterogeneity, reducing communication overhead, and ensuring privacy through mechanisms like differential privacy and secure aggregation. Furthermore, we examine emerging trends in FL research, including personalized FL, cross-device versus cross-silo settings, and integration with other paradigms such as reinforcement learning and quantum computing. We also highlight real-world applications and summarize benchmark datasets and evaluation metrics commonly used in FL research. Finally, we outline open research problems and future directions to guide the development of scalable, efficient, and trustworthy FL systems.",
    "source": "arXiv"
  },
  {
    "title": "Efficient Learning on Large Graphs using a Densifying Regularity Lemma",
    "title_es": "Efficient Learning on Large Graphs using a Densifying Regularity Lemma",
    "url": "https://arxiv.org/abs/2504.18273",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.18273v2 Announce Type: replace \nAbstract: Learning on large graphs presents significant challenges, with traditional Message Passing Neural Networks suffering from computational and memory costs scaling linearly with the number of edges. We introduce the Intersecting Block Graph (IBG), a low-rank factorization of large directed graphs based on combinations of intersecting bipartite components, each consisting of a pair of communities, for source and target nodes. By giving less weight to non-edges, we show how to efficiently approximate any graph, sparse or dense, by a dense IBG. Specifically, we prove a constructive version of the weak regularity lemma, showing that for any chosen accuracy, every graph, regardless of its size or sparsity, can be approximated by a dense IBG whose rank depends only on the accuracy. This dependence of the rank solely on the accuracy, and not on the sparsity level, is in contrast to previous forms of the weak regularity lemma. We present a graph neural network architecture operating on the IBG representation of the graph and demonstrating competitive performance on node classification, spatio-temporal graph analysis, and knowledge graph completion, while having memory and computational complexity linear in the number of nodes rather than edges.",
    "source": "arXiv"
  },
  {
    "title": "LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition",
    "title_es": "LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition",
    "url": "https://arxiv.org/abs/2504.19256",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.19256v2 Announce Type: replace \nAbstract: In human-centered environments such as restaurants, homes, and warehouses, robots often face challenges in accurately recognizing 3D objects. These challenges stem from the complexity and variability of these environments, including diverse object shapes. In this paper, we propose a novel Lightweight Multi-modal Multi-view Convolutional-Vision Transformer network (LM-MCVT) to enhance 3D object recognition in robotic applications. Our approach leverages the Globally Entropy-based Embeddings Fusion (GEEF) method to integrate multi-views efficiently. The LM-MCVT architecture incorporates pre- and mid-level convolutional encoders and local and global transformers to enhance feature extraction and recognition accuracy. We evaluate our method on the synthetic ModelNet40 dataset and achieve a recognition accuracy of 95.6% using a four-view setup, surpassing existing state-of-the-art methods. To further validate its effectiveness, we conduct 5-fold cross-validation on the real-world OmniObject3D dataset using the same configuration. Results consistently show superior performance, demonstrating the method's robustness in 3D object recognition across synthetic and real-world 3D data.",
    "source": "arXiv"
  },
  {
    "title": "Mj\\\"olnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density",
    "title_es": "Mj\\\"olnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density",
    "url": "https://arxiv.org/abs/2504.19822",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.19822v3 Announce Type: replace \nAbstract: Recent advances in AI-based weather forecasting models, such as FourCastNet, Pangu-Weather, and GraphCast, have demonstrated the remarkable ability of deep learning to emulate complex atmospheric dynamics. Building on this momentum, we propose Mj\\\"olnir, a novel deep learning-based framework for global lightning flash density parameterization. Trained on ERA5 atmospheric predictors and World Wide Lightning Location Network (WWLLN) observations at a daily temporal resolution and 1 degree spatial resolution, Mj\\\"olnir captures the nonlinear mapping between large-scale environmental conditions and lightning activity. The model architecture is based on the InceptionNeXt backbone with SENet, and a multi-task learning strategy to simultaneously predict lightning occurrence and magnitude. Extensive evaluations yield that Mollnir accurately reproduces the global distribution, seasonal variability, and regional characteristics of lightning activity, achieving a global Pearson correlation coefficient of 0.96 for annual mean fields. These results suggest that Mj\\\"olnir serves not only as an effective data-driven global lightning parameterization but also as a promising AI-based scheme for next-generation Earth system models (AI-ESMs).",
    "source": "arXiv"
  },
  {
    "title": "Edge-Cloud Collaborative Computing on Distributed Intelligence and Model Optimization: A Survey",
    "title_es": "Edge-Cloud Collaborative Computing on Distributed Intelligence and Model Optimization: A Survey",
    "url": "https://arxiv.org/abs/2505.01821",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.01821v3 Announce Type: replace \nAbstract: Edge-cloud collaborative computing (ECCC) has emerged as a pivotal paradigm for addressing the computational demands of modern intelligent applications, integrating cloud resources with edge devices to enable efficient, low-latency processing. Recent advancements in AI, particularly deep learning and large language models (LLMs), have dramatically enhanced the capabilities of these distributed systems, yet introduce significant challenges in model deployment and resource management. In this survey, we comprehensive examine the intersection of distributed intelligence and model optimization within edge-cloud environments, providing a structured tutorial on fundamental architectures, enabling technologies, and emerging applications. Additionally, we systematically analyze model optimization approaches, including compression, adaptation, and neural architecture search, alongside AI-driven resource management strategies that balance performance, energy efficiency, and latency requirements. We further explore critical aspects of privacy protection and security enhancement within ECCC systems and examines practical deployments through diverse applications, spanning autonomous driving, healthcare, and industrial automation. Performance analysis and benchmarking techniques are also thoroughly explored to establish evaluation standards for these complex systems. Furthermore, the review identifies critical research directions including LLMs deployment, 6G integration, neuromorphic computing, and quantum computing, offering a roadmap for addressing persistent challenges in heterogeneity management, real-time processing, and scalability. By bridging theoretical advancements and practical deployments, this survey offers researchers and practitioners a holistic perspective on leveraging AI to optimize distributed computing environments, fostering innovation in next-generation intelligent systems.",
    "source": "arXiv"
  },
  {
    "title": "To Judge or not to Judge: Using LLM Judgements for Advertiser Keyphrase Relevance at eBay",
    "title_es": "To Judge or not to Judge: Using LLM Judgements for Advertiser Keyphrase Relevance at eBay",
    "url": "https://arxiv.org/abs/2505.04209",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.04209v3 Announce Type: replace \nAbstract: E-commerce sellers are recommended keyphrases based on their inventory on which they advertise to increase buyer engagement (clicks/sales). The relevance of advertiser keyphrases plays an important role in preventing the inundation of search systems with numerous irrelevant items that compete for attention in auctions, in addition to maintaining a healthy seller perception. In this work, we describe the shortcomings of training Advertiser keyphrase relevance filter models on click/sales/search relevance signals and the importance of aligning with human judgment, as sellers have the power to adopt or reject said keyphrase recommendations. In this study, we frame Advertiser keyphrase relevance as a complex interaction between 3 dynamical systems -- seller judgment, which influences seller adoption of our product, Advertising, which provides the keyphrases to bid on, and Search, who holds the auctions for the same keyphrases. This study discusses the practicalities of using human judgment via a case study at eBay Advertising and demonstrate that using LLM-as-a-judge en-masse as a scalable proxy for seller judgment to train our relevance models achieves a better harmony across the three systems -- provided that they are bound by a meticulous evaluation framework grounded in business metrics.",
    "source": "arXiv"
  },
  {
    "title": "Hyperbolic Fuzzy C-Means with Adaptive Weight-based Filtering for Efficient Clustering",
    "title_es": "Hyperbolic Fuzzy C-Means with Adaptive Weight-based Filtering for Efficient Clustering",
    "url": "https://arxiv.org/abs/2505.04335",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.04335v2 Announce Type: replace \nAbstract: Clustering algorithms play a pivotal role in unsupervised learning by identifying and grouping similar objects based on shared characteristics. Although traditional clustering techniques, such as hard and fuzzy center-based clustering, have been widely used, they struggle with complex, high-dimensional, and non-Euclidean datasets. In particular, the fuzzy $C$-Means (FCM) algorithm, despite its efficiency and popularity, exhibits notable limitations in non-Euclidean spaces. Euclidean spaces assume linear separability and uniform distance scaling, limiting their effectiveness in capturing complex, hierarchical, or non-Euclidean structures in fuzzy clustering. To overcome these challenges, we introduce Filtration-based Hyperbolic Fuzzy C-Means (HypeFCM), a novel clustering algorithm tailored for better representation of data relationships in non-Euclidean spaces. HypeFCM integrates the principles of fuzzy clustering with hyperbolic geometry and employs a weight-based filtering mechanism to improve performance. The algorithm initializes weights using a Dirichlet distribution and iteratively refines cluster centroids and membership assignments based on a hyperbolic metric in the Poincar\\'e Disc model. Extensive experimental evaluations on $6$ synthetic and $12$ real-world datasets demonstrate that HypeFCM significantly outperforms conventional fuzzy clustering methods in non-Euclidean settings, underscoring its robustness and effectiveness.",
    "source": "arXiv"
  },
  {
    "title": "Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models",
    "title_es": "Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models",
    "url": "https://arxiv.org/abs/2505.15130",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.15130v2 Announce Type: replace \nAbstract: Vision-Language Models (VLMs) such as CLIP have shown remarkable performance in cross-modal tasks through large-scale contrastive pre-training. To adapt these large transformer-based models efficiently for downstream tasks, Parameter-Efficient Fine-Tuning (PEFT) techniques like LoRA have emerged as scalable alternatives to full fine-tuning, especially in few-shot scenarios. However, like traditional deep neural networks, VLMs are highly vulnerable to adversarial attacks, where imperceptible perturbations can significantly degrade model performance. Adversarial training remains the most effective strategy for improving model robustness in PEFT. In this work, we propose AdvCLIP-LoRA, the first algorithm designed to enhance the adversarial robustness of CLIP models fine-tuned with LoRA in few-shot settings. Our method formulates adversarial fine-tuning as a minimax optimization problem and provides theoretical guarantees for convergence under smoothness and nonconvex-strong-concavity assumptions. Empirical results across eight datasets using ViT-B/16 and ViT-B/32 models show that AdvCLIP-LoRA significantly improves robustness against common adversarial attacks (e.g., FGSM, PGD), without sacrificing much clean accuracy. These findings highlight AdvCLIP-LoRA as a practical and theoretically grounded approach for robust adaptation of VLMs in resource-constrained settings.",
    "source": "arXiv"
  },
  {
    "title": "SoftHGNN: Soft Hypergraph Neural Networks for General Visual Recognition",
    "title_es": "SoftHGNN: Soft Hypergraph Neural Networks for General Visual Recognition",
    "url": "https://arxiv.org/abs/2505.15325",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.15325v2 Announce Type: replace \nAbstract: Visual recognition relies on understanding both the semantics of image tokens and the complex interactions among them. Mainstream self-attention methods, while effective at modeling global pair-wise relations, fail to capture high-order associations inherent in real-world scenes and often suffer from redundant computation. Hypergraphs extend conventional graphs by modeling high-order interactions and offer a promising framework for addressing these limitations. However, existing hypergraph neural networks typically rely on static and hard hyperedge assignments, leading to excessive and redundant hyperedges with hard binary vertex memberships that overlook the continuity of visual semantics. To overcome these issues, we present Soft Hypergraph Neural Networks (SoftHGNNs), which extend the methodology of hypergraph computation, to make it truly efficient and versatile in visual recognition tasks. Our framework introduces the concept of soft hyperedges, where each vertex is associated with hyperedges via continuous participation weights rather than hard binary assignments. This dynamic and differentiable association is achieved by using the learnable hyperedge prototype. Through similarity measurements between token features and the prototype, the model generates semantically rich soft hyperedges. SoftHGNN then aggregates messages over soft hyperedges to capture high-order semantics. To further enhance efficiency when scaling up the number of soft hyperedges, we incorporate a sparse hyperedge selection mechanism that activates only the top-k important hyperedges, along with a load-balancing regularizer to ensure balanced hyperedge utilization. Experimental results across three tasks on five datasets demonstrate that SoftHGNN efficiently captures high-order associations in visual scenes, achieving significant performance improvements.",
    "source": "arXiv"
  },
  {
    "title": "Near-optimal edge partitioning via intersecting families",
    "title_es": "Near-optimal edge partitioning via intersecting families",
    "url": "https://arxiv.org/abs/2505.18026",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.18026v2 Announce Type: replace \nAbstract: We study the problem of edge-centric graph partitioning, where the goal is to distribute the edges of a graph among several almost equally sized parts in order to minimize the replication factor of vertices. We build a partitioning algorithm that guarantees near-perfect balance and replication factor $\\sqrt{n} (1 + o(1))$ for arbitrary number of parts $n$. This asymptotical bound cannot be improved. To do so, we introduce balanced intersecting systems. It is a construction similar to symmetric intersecting families, but the symmetry condition is replaced by a weaker balance condition. We build an algorithm that uses such a system, and prove that by using a system of optimal rank we achieve exactly optimal guarantees for the replication factor. Finally, we build balanced intersecting systems with asymptotically optimal rank.",
    "source": "arXiv"
  },
  {
    "title": "Making Teams and Influencing Agents: Efficiently Coordinating Decision Trees for Interpretable Multi-Agent Reinforcement Learning",
    "title_es": "Making Teams and Influencing Agents: Efficiently Coordinating Decision Trees for Interpretable Multi-Agent Reinforcement Learning",
    "url": "https://arxiv.org/abs/2505.19316",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.19316v2 Announce Type: replace \nAbstract: Poor interpretability hinders the practical applicability of multi-agent reinforcement learning (MARL) policies. Deploying interpretable surrogates of uninterpretable policies enhances the safety and verifiability of MARL for real-world applications. However, if these surrogates are to interact directly with the environment within human supervisory frameworks, they must be both performant and computationally efficient. Prior work on interpretable MARL has either sacrificed performance for computational efficiency or computational efficiency for performance. To address this issue, we propose HYDRAVIPER, a decision tree-based interpretable MARL algorithm. HYDRAVIPER coordinates training between agents based on expected team performance, and adaptively allocates budgets for environment interaction to improve computational efficiency. Experiments on standard benchmark environments for multi-agent coordination and traffic signal control show that HYDRAVIPER matches the performance of state-of-the-art methods using a fraction of the runtime, and that it maintains a Pareto frontier of performance for different interaction budgets.",
    "source": "arXiv"
  },
  {
    "title": "Effort-aware Fairness: Incorporating a Philosophy-informed, Human-centered Notion of Effort into Algorithmic Fairness Metrics",
    "title_es": "Effort-aware Fairness: Incorporating a Philosophy-informed, Human-centered Notion of Effort into Algorithmic Fairness Metrics",
    "url": "https://arxiv.org/abs/2505.19317",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.19317v2 Announce Type: replace \nAbstract: Although popularized AI fairness metrics, e.g., demographic parity, have uncovered bias in AI-assisted decision-making outcomes, they do not consider how much effort one has spent to get to where one is today in the input feature space. However, the notion of effort is important in how Philosophy and humans understand fairness. We propose a philosophy-informed approach to conceptualize and evaluate Effort-aware Fairness (EaF), grounded in the concept of Force, which represents the temporal trajectory of predictive features coupled with inertia. Besides theoretical formulation, our empirical contributions include: (1) a pre-registered human subjects experiment, which shows that for both stages of the (individual) fairness evaluation process, people consider the temporal trajectory of a predictive feature more than its aggregate value; (2) pipelines to compute Effort-aware Individual/Group Fairness in the criminal justice and personal finance contexts. Our work may enable AI model auditors to uncover and potentially correct unfair decisions against individuals who have spent significant efforts to improve but are still stuck with systemic disadvantages outside their control.",
    "source": "arXiv"
  },
  {
    "title": "Out of the Past: An AI-Enabled Pipeline for Traffic Simulation from Noisy, Multimodal Detector Data and Stakeholder Feedback",
    "title_es": "Out of the Past: An AI-Enabled Pipeline for Traffic Simulation from Noisy, Multimodal Detector Data and Stakeholder Feedback",
    "url": "https://arxiv.org/abs/2505.21349",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.21349v2 Announce Type: replace \nAbstract: How can a traffic simulation be designed to faithfully reflect real-world traffic conditions? One crucial step is modeling the volume of traffic demand. But past demand modeling approaches have relied on unrealistic or suboptimal heuristics, and they have failed to adequately account for the effects of noisy and multimodal data on simulation outcomes. In this work, we integrate advances in AI to construct a three-step, end-to-end pipeline for systematically modeling traffic demand from detector data: computer vision for vehicle counting from noisy camera footage, combinatorial optimization for vehicle route generation from multimodal data, and large language models for iterative simulation refinement from natural language feedback. Using a road network from Strongsville, Ohio as a testbed, we show that our pipeline accurately captures the city's traffic patterns in a granular simulation. Beyond Strongsville, incorporating noise and multimodality makes our framework generalizable to municipalities with different levels of data and infrastructure availability.",
    "source": "arXiv"
  },
  {
    "title": "GUARD:Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural Code Generation",
    "title_es": "GUARD:Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural Code Generation",
    "url": "https://arxiv.org/abs/2505.21425",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.21425v3 Announce Type: replace \nAbstract: With the widespread application of large language models in code generation, recent studies demonstrate that employing additional Chain-of-Thought generation models can significantly enhance code generation performance by providing explicit reasoning steps. However, as external components, CoT models are particularly vulnerable to backdoor attacks, which existing defense mechanisms often fail to detect effectively. To address this challenge, we propose GUARD, a novel dual-agent defense framework specifically designed to counter CoT backdoor attacks in neural code generation. GUARD integrates two core components: GUARD-Judge, which identifies suspicious CoT steps and potential triggers through comprehensive analysis, and GUARD-Repair, which employs a retrieval-augmented generation approach to regenerate secure CoT steps for identified anomalies. Experimental results show that GUARD effectively mitigates attacks while maintaining generation quality, advancing secure code generation systems.",
    "source": "arXiv"
  },
  {
    "title": "Mitigating Hallucination in Large Vision-Language Models via Adaptive Attention Calibration",
    "title_es": "Mitigating Hallucination in Large Vision-Language Models via Adaptive Attention Calibration",
    "url": "https://arxiv.org/abs/2505.21472",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.21472v2 Announce Type: replace \nAbstract: Large vision-language models (LVLMs) achieve impressive performance on multimodal tasks but often suffer from hallucination, and confidently describe objects or attributes not present in the image. Current training-free interventions struggle to maintain accuracy in open-ended and long-form generation scenarios. We introduce the Confidence-Aware Attention Calibration (CAAC) framework to address this challenge by targeting two key biases: spatial perception bias, which distributes attention disproportionately across image tokens, and modality bias, which shifts focus from visual to textual inputs over time. CAAC employs a two-step approach: Visual-Token Calibration (VTC) to balance attention across visual tokens, and Adaptive Attention Re-Scaling (AAR) to reinforce visual grounding guided by the model's confidence. This confidence-driven adjustment ensures consistent visual alignment during generation. Experiments on CHAIR, AMBER, and POPE benchmarks demonstrate that CAAC outperforms baselines, particularly in long-form generations, effectively reducing hallucination.",
    "source": "arXiv"
  },
  {
    "title": "A simulation framework for autonomous lunar construction work",
    "title_es": "A simulation framework for autonomous lunar construction work",
    "url": "https://arxiv.org/abs/2505.22091",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.22091v2 Announce Type: replace \nAbstract: We present a simulation framework for lunar construction work involving multiple autonomous machines. The framework supports modelling of construction scenarios and autonomy solutions, execution of the scenarios in simulation, and analysis of work time and energy consumption throughout the construction project. The simulations are based on physics-based models for contacting multibody dynamics and deformable terrain, including vehicle-soil interaction forces and soil flow in real time. A behaviour tree manages the operational logic and error handling, which enables the representation of complex behaviours through a discrete set of simpler tasks in a modular hierarchical structure. High-level decision-making is separated from lower-level control algorithms, with the two connected via ROS2. Excavation movements are controlled through inverse kinematics and tracking controllers. The framework is tested and demonstrated on two different lunar construction scenarios that involve an excavator and dump truck with actively controlled articulated crawlers.",
    "source": "arXiv"
  },
  {
    "title": "ViStoryBench: Comprehensive Benchmark Suite for Story Visualization",
    "title_es": "ViStoryBench: Comprehensive Benchmark Suite for Story Visualization",
    "url": "https://arxiv.org/abs/2505.24862",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.24862v3 Announce Type: replace \nAbstract: Story visualization aims to generate coherent image sequences that faithfully depict a narrative and align with character references. Despite progress in generative models, existing benchmarks are narrow in scope, often limited to short prompts, no character reference, or single-image cases, and fall short of real-world storytelling complexity. This hinders a nuanced understanding of model capabilities and limitations. We present ViStoryBench, a comprehensive benchmark designed to evaluate story visualization models across diverse narrative structures, visual styles, and character settings. The benchmark features richly annotated multi-shot scripts derived from curated stories spanning literature, film, and folklore. Large language models assist in story summarization and script generation, with all outputs verified by humans to ensure coherence and fidelity. Character references are carefully curated to maintain intra-story consistency across varying artistic styles. To enable thorough evaluation, ViStoryBench introduces a set of automated metrics that assess character consistency, style similarity, prompt adherence, aesthetic quality, and generation artifacts such as copy-paste behavior. These metrics are validated through human studies, and used to benchmark a broad range of open-source and commercial models. ViStoryBench offers a high-fidelity, multi-dimensional evaluation suite that facilitates systematic analysis and fosters future progress in visual storytelling.",
    "source": "arXiv"
  },
  {
    "title": "SIL Allocation for Mitigation Safety Functions",
    "title_es": "SIL Allocation for Mitigation Safety Functions",
    "url": "https://arxiv.org/abs/2506.02309",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.02309v2 Announce Type: replace \nAbstract: SIL (Safety Integrity Level) allocation plays a pivotal role in evaluating the significance of Safety Functions (SFs) within high-risk industries. The outcomes of a SIL allocation study determine the design specifications necessary to uphold the Probability of Failure on Demand (PFD) below permissible limits, thus managing risk effectively. While extensive research has focused on SIL allocation for preventive SFs, there is a noticeable gap in attention towards mitigation SFs. To address this gap, this paper discusses the shortcomings of current methods and proposes a new approach to overcome them. The principles of the proposed method are substantiated by detailed mathematical formulation and the practical application of the method is demonstrated through a case study in a road tunnel project.",
    "source": "arXiv"
  },
  {
    "title": "Context as Memory: Scene-Consistent Interactive Long Video Generation with Memory Retrieval",
    "title_es": "Context as Memory: Scene-Consistent Interactive Long Video Generation with Memory Retrieval",
    "url": "https://arxiv.org/abs/2506.03141",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.03141v2 Announce Type: replace \nAbstract: Recent advances in interactive video generation have shown promising results, yet existing approaches struggle with scene-consistent memory capabilities in long video generation due to limited use of historical context. In this work, we propose Context-as-Memory, which utilizes historical context as memory for video generation. It includes two simple yet effective designs: (1) storing context in frame format without additional post-processing; (2) conditioning by concatenating context and frames to be predicted along the frame dimension at the input, requiring no external control modules. Furthermore, considering the enormous computational overhead of incorporating all historical context, we propose the Memory Retrieval module to select truly relevant context frames by determining FOV (Field of View) overlap between camera poses, which significantly reduces the number of candidate frames without substantial information loss. Experiments demonstrate that Context-as-Memory achieves superior memory capabilities in interactive long video generation compared to SOTAs, even generalizing effectively to open-domain scenarios not seen during training. The link of our project page is https://context-as-memory.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "Vulnerability-Aware Alignment: Mitigating Uneven Forgetting in Harmful Fine-Tuning",
    "title_es": "Vulnerability-Aware Alignment: Mitigating Uneven Forgetting in Harmful Fine-Tuning",
    "url": "https://arxiv.org/abs/2506.03850",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.03850v2 Announce Type: replace \nAbstract: Harmful fine-tuning (HFT), performed directly on open-source LLMs or through Fine-tuning-as-a-Service, breaks safety alignment and poses significant threats. Existing methods aim to mitigate HFT risks by learning robust representation on alignment data or making harmful data unlearnable, but they treat each data sample equally, leaving data vulnerability patterns understudied. In this work, we reveal that certain subsets of alignment data are consistently more prone to forgetting during HFT across different fine-tuning tasks. Inspired by these findings, we propose Vulnerability-Aware Alignment (VAA), which estimates data vulnerability, partitions data into \"vulnerable\" and \"invulnerable\" groups, and encourages balanced learning using a group distributionally robust optimization (Group DRO) framework. Specifically, VAA learns an adversarial sampler that samples examples from the currently underperforming group and then applies group-dependent adversarial perturbations to the data during training, aiming to encourage a balanced learning process across groups. Experiments across four fine-tuning tasks demonstrate that VAA significantly reduces harmful scores while preserving downstream task performance, outperforming state-of-the-art baselines.",
    "source": "arXiv"
  },
  {
    "title": "Multiple Stochastic Prompt Tuning for Few-shot Adaptation under Extreme Domain Shift",
    "title_es": "Multiple Stochastic Prompt Tuning for Few-shot Adaptation under Extreme Domain Shift",
    "url": "https://arxiv.org/abs/2506.03926",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.03926v2 Announce Type: replace \nAbstract: Foundation Vision-Language Models (VLMs) like CLIP exhibit strong generalization capabilities due to large-scale pretraining on diverse image-text pairs. However, their performance often degrades when applied to target datasets with significant distribution shifts in both visual appearance and class semantics. Recent few-shot learning approaches adapt CLIP to downstream tasks using limited labeled data via adapter or prompt tuning, but are not specifically designed to handle such extreme domain shifts. Conversely, some works addressing cross-domain few-shot learning consider such domain-shifted scenarios but operate in an episodic setting with only a few classes per episode, limiting their applicability to real-world deployment, where all classes must be handled simultaneously. To address this gap, we propose a novel framework, MIST (Multiple Stochastic Prompt Tuning), for efficiently adapting CLIP to datasets with extreme distribution shifts using only a few labeled examples, in scenarios involving all classes at once. Specifically, we introduce multiple learnable prompts per class to effectively capture diverse modes in visual representations arising from distribution shifts. To further enhance generalization, these prompts are modeled as learnable Gaussian distributions, enabling efficient exploration of the prompt parameter space and reducing overfitting caused by limited supervision. Extensive experiments and comparisons with state-of-the-art methods demonstrate the effectiveness of the proposed framework.",
    "source": "arXiv"
  },
  {
    "title": "A Fast Unsupervised Scheme for Polygonal Approximation",
    "title_es": "A Fast Unsupervised Scheme for Polygonal Approximation",
    "url": "https://arxiv.org/abs/2506.04664",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.04664v2 Announce Type: replace \nAbstract: This paper proposes a fast and unsupervised scheme for the polygonal approximation of a closed digital curve. It is demonstrated that the approximation scheme is faster than state-of-the-art approximation and is competitive with Rosin's measure and aesthetic aspects. The scheme comprises of three phases: initial segmentation, iterative vertex insertion, iterative merging, and vertex adjustment. The initial segmentation is used to detect sharp turns, that is, vertices that seemingly have high curvature. It is likely that some of the important vertices with low curvature might have been missed in the first phase; therefore, iterative vertex insertion is used to add vertices in a region where the curvature changes slowly but steadily. The initial phase may pick up some undesirable vertices, and thus merging is used to eliminate redundant vertices. Finally, vertex adjustment was used to enhance the aesthetic appearance of the approximation. The quality of the approximations was measured using the Rosin's method. The robustness of the proposed scheme with respect to geometric transformation was observed.",
    "source": "arXiv"
  },
  {
    "title": "HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition",
    "title_es": "HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition",
    "url": "https://arxiv.org/abs/2506.04764",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.04764v2 Announce Type: replace \nAbstract: When applying Visual Place Recognition (VPR) to real-world mobile robots and similar applications, perspective-to-equirectangular (P2E) formulation naturally emerges as a suitable approach to accommodate diverse query images captured from various viewpoints. In this paper, we introduce HypeVPR, a novel hierarchical embedding framework in hyperbolic space, designed to address the unique challenges of P2E VPR. The key idea behind HypeVPR is that visual environments captured by panoramic views exhibit inherent hierarchical structures. To leverage this property, we employ hyperbolic space to represent hierarchical feature relationships and preserve distance properties within the feature space. To achieve this, we propose a hierarchical feature aggregation mechanism that organizes local-to-global feature representations within hyperbolic space. Additionally, HypeVPR adopts an efficient coarse-to-fine search strategy to enable flexible control over accuracy-efficiency trade-offs and ensure robust matching even between descriptors from different image types. This approach allows HypeVPR to outperform existing methods while significantly accelerating retrieval and reducing database storage requirements. The code and models will be released at https://github.com/suhan-woo/HypeVPR.git.",
    "source": "arXiv"
  },
  {
    "title": "Numerical evaluation of the Kirchhoff-Helmholtz integral outside a sphere",
    "title_es": "Numerical evaluation of the Kirchhoff-Helmholtz integral outside a sphere",
    "url": "https://arxiv.org/abs/2506.04809",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.04809v2 Announce Type: replace \nAbstract: A method is presented for the fast evaluation of the transient acoustic field generated outside a spherical surface using surface data on the sphere. The method employs Lebedev quadratures, which are optimal integration on the sphere, and Lagrange interpolation and differentiation in an advanced time algorithm for the evaluation of the transient field. Numerical testing demonstrates that the approach gives near machine-precision accuracy and a speed-up in evaluation time which depends on the order of quadrature rule employed but breaks even with direct evaluation at a number of field points about 1.15 times the number of surface quadrature nodes, making the method an efficient means of evaluating the field generated by a large number of sources.",
    "source": "arXiv"
  },
  {
    "title": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness",
    "title_es": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness",
    "url": "https://arxiv.org/abs/2506.05735",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.05735v2 Announce Type: replace \nAbstract: Machine unlearning techniques aim to mitigate unintended memorization in large language models (LLMs). However, existing approaches predominantly focus on the explicit removal of isolated facts, often overlooking latent inferential dependencies and the non-deterministic nature of knowledge within LLMs. Consequently, facts presumed forgotten may persist implicitly through correlated information. To address these challenges, we propose a knowledge unlearning evaluation framework that more accurately captures the implicit structure of real-world knowledge by representing relevant factual contexts as knowledge graphs with associated confidence scores. We further develop an inference-based evaluation protocol leveraging powerful LLMs as judges; these judges reason over the extracted knowledge subgraph to determine unlearning success. Our LLM judges utilize carefully designed prompts and are calibrated against human evaluations to ensure their trustworthiness and stability. Extensive experiments on our newly constructed benchmark demonstrate that our framework provides a more realistic and rigorous assessment of unlearning performance. Moreover, our findings reveal that current evaluation strategies tend to overestimate unlearning effectiveness. Our code is publicly available at https://github.com/Graph-COM/Knowledge_Unlearning.git.",
    "source": "arXiv"
  },
  {
    "title": "Investigating the Relationship between the Weighted Figure of Merit and Rosin's Measure",
    "title_es": "Investigating the Relationship between the Weighted Figure of Merit and Rosin's Measure",
    "url": "https://arxiv.org/abs/2506.05749",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.05749v2 Announce Type: replace \nAbstract: Many studies have been conducted to solve the problem of approximating a digital boundary by piece straight-line segments for the further processing required in computer vision applications. The authors of these studies compared their schemes to determine the best one. The initial measure used to assess the goodness of fit of a polygonal approximation was the figure of merit. Later,it was noted that this measure was not an appropriate metric for a valid reason which is why Rosin-through mathematical analysis-introduced a measure called merit. However,this measure involves an optimal scheme of polygonal approximation,so it is time-consuming to compute it to assess the goodness of fit of an approximation. This led many researchers to use a weighted figure of merit as a substitute for Rosin's measure to compare sub optimal schemes. An attempt is made in this communication to investigate whether the two measures-weighted figure of merit and Rosin's measure-are related so that one can be used instead of the other, and toward this end, theoretical analysis, experimental investigation and statistical analysis are carried out. The mathematical formulas for the weighted figure of merit and Rosin's measure are analyzed, and through proof of theorems,it is found that the two measures are theoretically independent of each other. The graphical analysis of experiments carried out using a public dataset supports the results of the theoretical analysis. The statistical analysis via Pearson's correlation coefficient and non-linear correlation measure also revealed that the two measures are uncorrelated. This analysis leads one to conclude that if a suboptimal scheme is found to be better (worse) than some other suboptimal scheme,as indicated by Rosin's measure,then the same conclusion cannot be drawn using a weighted figure of merit,so one cannot use a weighted figure of merit instead of Rosin's measure.",
    "source": "arXiv"
  },
  {
    "title": "CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics",
    "title_es": "CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics",
    "url": "https://arxiv.org/abs/2506.08835",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.08835v2 Announce Type: replace \nAbstract: The increasing ubiquity of text-to-image (T2I) models as tools for visual content generation raises concerns about their ability to accurately represent diverse cultural contexts -- where missed cues can stereotype communities and undermine usability. In this work, we present the first study to systematically quantify the alignment of T2I models and evaluation metrics with respect to both explicit (stated) as well as implicit (unstated, implied by the prompt's cultural context) cultural expectations. To this end, we introduce CulturalFrames, a novel benchmark designed for rigorous human evaluation of cultural representation in visual generations. Spanning 10 countries and 5 socio-cultural domains, CulturalFrames comprises 983 prompts, 3637 corresponding images generated by 4 state-of-the-art T2I models, and over 10k detailed human annotations. We find that across models and countries, cultural expectations are missed an average of 44% of the time. Among these failures, explicit expectations are missed at a surprisingly high average rate of 68%, while implicit expectation failures are also significant, averaging 49%. Furthermore, we show that existing T2I evaluation metrics correlate poorly with human judgments of cultural alignment, irrespective of their internal reasoning. Collectively, our findings expose critical gaps, provide a concrete testbed, and outline actionable directions for developing culturally informed T2I models and metrics that improve global usability.",
    "source": "arXiv"
  },
  {
    "title": "ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space",
    "title_es": "ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space",
    "url": "https://arxiv.org/abs/2506.10323",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.10323v5 Announce Type: replace \nAbstract: Generation-based fuzzing produces appropriate test cases according to specifications of input grammars and semantic constraints to test systems and software. However, these specifications require significant manual effort to construct. This paper proposes a new approach, ELFuzz (Evolution Through Large Language Models for Fuzzing), that automatically synthesizes generation-based fuzzers tailored to a system under test (SUT) via LLM-driven synthesis over fuzzer space. At a high level, it starts with minimal seed fuzzers and propels the synthesis by fully automated LLM-driven evolution with coverage guidance. Compared to previous approaches, ELFuzz can 1) seamlessly scale to SUTs of real-world sizes -- up to 1,791,104 lines of code in our evaluation -- and 2) synthesize efficient fuzzers that catch interesting grammatical structures and semantic constraints in a human-understandable way. Our evaluation compared ELFuzz with specifications manually written by domain experts and synthesized by state-of-the-art approaches. It shows that ELFuzz achieves up to 434.8% more coverage over the second best and triggers up to 216.7% more artificially injected bugs, compared to the state-of-the-art. We also used ELFuzz to conduct a real-world fuzzing campaign on the newest version of cvc5 for 14 days, and encouragingly, it found five 0-day bugs (three are exploitable). Moreover, we conducted an ablation study, which shows that the fuzzer space model, the key component of ELFuzz, contributes the most (up to 62.5%) to the effectiveness of ELFuzz. Further analysis of the fuzzers synthesized by ELFuzz confirms that they catch interesting grammatical structures and semantic constraints in a human-understandable way. The results present the promising potential of ELFuzz for more automated, efficient, and extensible input generation for fuzzing.",
    "source": "arXiv"
  },
  {
    "title": "Saturation Self-Organizing Map",
    "title_es": "Saturation Self-Organizing Map",
    "url": "https://arxiv.org/abs/2506.10680",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.10680v3 Announce Type: replace \nAbstract: Continual learning poses a fundamental challenge for neural systems, which often suffer from catastrophic forgetting when exposed to sequential tasks. Self-Organizing Maps (SOMs), despite their interpretability and efficiency, are not immune to this issue. In this paper, we introduce Saturation Self-Organizing Maps (SatSOM)-an extension of SOMs designed to improve knowledge retention in continual learning scenarios. SatSOM incorporates a novel saturation mechanism that gradually reduces the learning rate and neighborhood radius of neurons as they accumulate information. This effectively freezes well-trained neurons and redirects learning to underutilized areas of the map.",
    "source": "arXiv"
  },
  {
    "title": "Mind the Gap: Benchmarking LLM Uncertainty, Discrimination, and Calibration in Specialty-Aware Clinical QA",
    "title_es": "Mind the Gap: Benchmarking LLM Uncertainty, Discrimination, and Calibration in Specialty-Aware Clinical QA",
    "url": "https://arxiv.org/abs/2506.10769",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.10769v2 Announce Type: replace \nAbstract: Reliable uncertainty quantification (UQ) is essential when employing large language models (LLMs) in high-risk domains such as clinical question answering (QA). In this work, we evaluate uncertainty estimation methods for clinical QA focusing, for the first time, on eleven clinical specialties and six question types, and across ten open-source LLMs (general-purpose, biomedical, and reasoning models). We analyze score-based UQ methods, present a case study introducing a novel lightweight method based on behavioral features derived from reasoning-oriented models, and examine conformal prediction as a complementary set-based approach. Our findings reveal that uncertainty reliability is not a monolithic property, but one that depends on clinical specialty and question type due to shifts in calibration and discrimination. Our results highlight the need to select or ensemble models based on their distinct, complementary strengths and clinical use.",
    "source": "arXiv"
  },
  {
    "title": "Unsupervised Document and Template Clustering using Multimodal Embeddings",
    "title_es": "Unsupervised Document and Template Clustering using Multimodal Embeddings",
    "url": "https://arxiv.org/abs/2506.12116",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.12116v2 Announce Type: replace \nAbstract: This paper investigates a novel approach to unsupervised document clustering by leveraging multimodal embeddings as input to clustering algorithms such as $k$-Means, DBSCAN, a combination of HDBSCAN and $k$-NN, and BIRCH. Our method aims to achieve a finer-grained document understanding by not only grouping documents at the type level (e.g., invoices, purchase orders), but also distinguishing between different templates within the same document category. This is achieved by using embeddings that capture textual content, layout information, and visual features of documents. We evaluated the effectiveness of this approach using embeddings generated by several state-of-the-art pre-trained multimodal models, including SBERT, LayoutLMv1, LayoutLMv3, DiT, Donut, ColPali, Gemma3, and InternVL3. Our findings demonstrate the potential of multimodal embeddings to significantly enhance document clustering, offering benefits for various applications in intelligent document processing, document layout analysis, and unsupervised document classification. This work provides valuable insight into the advantages and limitations of different multimodal models for this task and opens new avenues for future research to understand and organize document collections.",
    "source": "arXiv"
  },
  {
    "title": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models",
    "title_es": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models",
    "url": "https://arxiv.org/abs/2506.14291",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.14291v3 Announce Type: replace \nAbstract: Graph machine learning architectures are typically tailored to specific tasks on specific datasets, which hinders their broader applicability. This has led to a new quest in graph machine learning: how to build graph foundation models capable of generalizing across arbitrary graphs and features? In this work, we present a recipe for designing graph foundation models for node-level tasks from first principles. The key ingredient underpinning our study is a systematic investigation of the symmetries that a graph foundation model must respect. In a nutshell, we argue that label permutation-equivariance alongside feature permutation-invariance are necessary in addition to the common node permutation-equivariance on each local neighborhood of the graph. To this end, we first characterize the space of linear transformations that are equivariant to permutations of nodes and labels, and invariant to permutations of features. We then prove that the resulting network is a universal approximator on multisets that respect the aforementioned symmetries. Our recipe uses such layers on the multiset of features induced by the local neighborhood of the graph to obtain a class of graph foundation models for node property prediction. We validate our approach through extensive experiments on 29 real-world node classification datasets, demonstrating both strong zero-shot empirical performance and consistent improvement as the number of training graphs increases.",
    "source": "arXiv"
  },
  {
    "title": "RAGtifier: Evaluating RAG Generation Approaches of State-of-the-Art RAG Systems for the SIGIR LiveRAG Competition",
    "title_es": "RAGtifier: Evaluating RAG Generation Approaches of State-of-the-Art RAG Systems for the SIGIR LiveRAG Competition",
    "url": "https://arxiv.org/abs/2506.14412",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.14412v2 Announce Type: replace \nAbstract: Retrieval-Augmented Generation (RAG) enriches Large Language Models (LLMs) by combining their internal, parametric knowledge with external, non-parametric sources, with the goal of improving factual correctness and minimizing hallucinations. The LiveRAG 2025 challenge explores RAG solutions to maximize accuracy on DataMorgana's QA pairs, which are composed of single-hop and multi-hop questions. The challenge provides access to sparse OpenSearch and dense Pinecone indices of the Fineweb 10BT dataset. It restricts model use to LLMs with up to 10B parameters and final answer generation with Falcon-3-10B. A judge-LLM assesses the submitted answers along with human evaluators. By exploring distinct retriever combinations and RAG solutions under the challenge conditions, our final solution emerged using InstructRAG in combination with a Pinecone retriever and a BGE reranker. Our solution achieved a correctness score of 1.13 and a faithfulness score of 0.55 in the non-human evaluation, placing it overall in third place in the SIGIR 2025 LiveRAG Challenge.",
    "source": "arXiv"
  },
  {
    "title": "Reasoning with Exploration: An Entropy Perspective on Reinforcement Learning for LLMs",
    "title_es": "Reasoning with Exploration: An Entropy Perspective on Reinforcement Learning for LLMs",
    "url": "https://arxiv.org/abs/2506.14758",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.14758v3 Announce Type: replace \nAbstract: Balancing exploration and exploitation is a central goal in reinforcement learning (RL). Despite recent advances in enhancing large language model (LLM) reasoning, most methods lean toward exploitation, and increasingly encounter performance plateaus. In this work, we revisit entropy -- a signal of exploration in RL -- and examine its relationship to exploratory reasoning in LLMs. Through empirical analysis, we uncover positive correlations between high-entropy regions and three types of exploratory reasoning actions: (1) pivotal tokens that determine or connect logical steps, (2) reflective actions such as self-verification and correction, and (3) rare behaviors under-explored by the base LLMs. Motivated by this, we introduce a minimal modification to standard RL with only one line of code: augmenting the advantage function with an entropy-based term. Unlike traditional maximum-entropy methods which encourage exploration by promoting uncertainty, we encourage exploration by promoting longer and deeper reasoning chains. Notably, our method achieves significant gains on the Pass@K metric -- an upper-bound estimator of LLM reasoning capabilities -- even when evaluated with extremely large K values, pushing the boundaries of LLM reasoning.",
    "source": "arXiv"
  },
  {
    "title": "Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?",
    "title_es": "Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?",
    "url": "https://arxiv.org/abs/2506.14805",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.14805v2 Announce Type: replace \nAbstract: As Multimodal Large Language Models (MLLMs) continue to evolve, their cognitive and reasoning capabilities have seen remarkable progress. However, challenges in visual fine-grained perception and commonsense causal inference persist. This paper introduces Argus Inspection, a multimodal benchmark with two levels of difficulty, emphasizing detailed visual recognition while incorporating real-world commonsense understanding to evaluate causal reasoning abilities. Expanding on it, we present the Eye of Panoptes framework, which integrates a binary parametric Sigmoid metric with an indicator function, enabling a more holistic evaluation of MLLMs' responses in opinion-based reasoning tasks. Experiments conducted on 26 mainstream MLLMs reveal that the highest performance in visual fine-grained reasoning reaches only 0.46, highlighting considerable potential for enhancement. Our research offers valuable perspectives for the continued refinement of MLLMs.",
    "source": "arXiv"
  },
  {
    "title": "Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies",
    "title_es": "Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies",
    "url": "https://arxiv.org/abs/2506.15716",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.15716v2 Announce Type: replace \nAbstract: Citizens' assemblies are an increasingly influential form of deliberative democracy, where randomly selected people discuss policy questions. The legitimacy of these assemblies hinges on their representation of the broader population, but participant dropout often leads to an unbalanced composition. In practice, dropouts are replaced by preselected alternates, but existing methods do not address how to choose these alternates. To address this gap, we introduce an optimization framework for alternate selection. Our algorithmic approach, which leverages learning-theoretic machinery, estimates dropout probabilities using historical data and selects alternates to minimize expected misrepresentation. Our theoretical bounds provide guarantees on sample complexity (with implications for computational efficiency) and on loss due to dropout probability mis-estimation. Empirical evaluation using real-world data demonstrates that, compared to the status quo, our method significantly improves representation while requiring fewer alternates.",
    "source": "arXiv"
  },
  {
    "title": "Structural Optimal Jacobian Accumulation and Minimum Edge Count are NP-Complete Under Vertex Elimination",
    "title_es": "Structural Optimal Jacobian Accumulation and Minimum Edge Count are NP-Complete Under Vertex Elimination",
    "url": "https://arxiv.org/abs/2506.17521",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.17521v2 Announce Type: replace \nAbstract: We study graph-theoretic formulations of two fundamental problems in algorithmic differentiation. The first (Structural Optimal Jacobian Accumulation) is that of computing a Jacobian while minimizing multiplications. The second (Minimum Edge Count) is to find a minimum-size computational graph. For both problems, we consider the vertex elimination operation. Our main contribution is to show that both problems are NP-complete, thus resolving longstanding open questions. In contrast to prior work, our reduction for Structural Optimal Jacobian Accumulation does not rely on any assumptions about the algebraic relationships between local partial derivatives; we allow these values to be mutually independent. We also provide $O^*(2^n)$-time exact algorithms for both problems, and show that under the exponential time hypothesis these running times are essentially tight. Finally, we provide a data reduction rule for Structural Optimal Jacobian Accumulation by showing that false twins may always be eliminated consecutively.",
    "source": "arXiv"
  },
  {
    "title": "ChatHLS: Towards Systematic Design Automation and Optimization for High-Level Synthesis",
    "title_es": "ChatHLS: Towards Systematic Design Automation and Optimization for High-Level Synthesis",
    "url": "https://arxiv.org/abs/2507.00642",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.00642v2 Announce Type: replace \nAbstract: The increasing complexity of computational demands has spurred the adoption of domain-specific accelerators, yet traditional hardware design methodologies remain constrained by prolonged development and verification cycles. High-Level Synthesis (HLS) bridges the software-hardware gap by enabling hardware design from high-level languages. However, its widespread adoption is hindered by strict coding constraints and intricate hardware-specific optimizations. To address these challenges, we introduce ChatHLS, an agile HLS design automation workflow that leverages fine-tuned LLMs integrated within a multi-agent framework for HLS-specific error correction and design optimization. Through navigating LLM training with a novel verification-oriented data augmentation paradigm, ChatHLS achieves an average repair pass rate of 82.7% over 612 error cases. Furthermore, by enabling optimization reasoning within practical computational budgets, ChatHLS delivers performance improvements ranging from 1.9$\\times$ to 14.8$\\times$ on resource-constrained kernels, attaining a 3.6$\\times$ average speedup compared to SOTA approaches. These results underscore the potential of ChatHLS in substantially expediting hardware development cycles while upholding rigorous standards of design reliability and quality.",
    "source": "arXiv"
  },
  {
    "title": "MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing",
    "title_es": "MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing",
    "url": "https://arxiv.org/abs/2507.01384",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.01384v2 Announce Type: replace \nAbstract: The weakly-supervised audio-visual video parsing (AVVP) aims to predict all modality-specific events and locate their temporal boundaries. Despite significant progress, due to the limitations of the weakly-supervised and the deficiencies of the model architecture, existing methods are lacking in simultaneously improving both the segment-level prediction and the event-level prediction. In this work, we propose a audio-visual Mamba network with pseudo labeling aUGmentation (MUG) for emphasising the uniqueness of each segment and excluding the noise interference from the alternate modalities. Specifically, we annotate some of the pseudo-labels based on previous work. Using unimodal pseudo-labels, we perform cross-modal random combinations to generate new data, which can enhance the model's ability to parse various segment-level event combinations. For feature processing and interaction, we employ a audio-visual mamba network. The AV-Mamba enhances the ability to perceive different segments and excludes additional modal noise while sharing similar modal information. Our extensive experiments demonstrate that MUG improves state-of-the-art results on LLP dataset in all metrics (e.g,, gains of 2.1% and 1.2% in terms of visual Segment-level and audio Segment-level metrics). Our code is available at https://github.com/WangLY136/MUG.",
    "source": "arXiv"
  },
  {
    "title": "Efficient and Effective Query Context-Aware Learning-to-Rank Model for Sequential Recommendation",
    "title_es": "Efficient and Effective Query Context-Aware Learning-to-Rank Model for Sequential Recommendation",
    "url": "https://arxiv.org/abs/2507.03789",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.03789v2 Announce Type: replace \nAbstract: Modern sequential recommender systems commonly use transformer-based models for next-item prediction. While these models demonstrate a strong balance between efficiency and quality, integrating interleaving features - such as the query context (e.g., browse category) under which next-item interactions occur - poses challenges. Effectively capturing query context is crucial for refining ranking relevance and enhancing user engagement, as it provides valuable signals about user intent within a session. Unlike item features, historical query context is typically not aligned with item sequences and may be unavailable at inference due to privacy constraints or feature store limitations - making its integration into transformers both challenging and error-prone. This paper analyzes different strategies for incorporating query context into transformers trained with a causal language modeling procedure as a case study. We propose a new method that effectively fuses the item sequence with query context within the attention mechanism. Through extensive offline and online experiments on a large-scale online platform and open datasets, we present evidence that our proposed method is an effective approach for integrating query context to improve model ranking quality in terms of relevance and diversity.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Two-sided Assortment Optimization: Revenue Maximization",
    "title_es": "Adaptive Two-sided Assortment Optimization: Revenue Maximization",
    "url": "https://arxiv.org/abs/2507.04156",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.04156v3 Announce Type: replace \nAbstract: We study adaptive two-sided assortment optimization for revenue maximization in choice-based matching platforms. The platform has two sides of agents, an initiating side, and a responding side. The decision-maker sequentially selects agents from the initiating side, shows each an assortment of agents from the responding side, and observes their choices. After processing all initiating agents, the responding agents are shown assortments and make their selections. A match occurs when two agents mutually select each other, generating pair-dependent revenue. Choices follow Multinomial Logit (MNL) models. This setting generalizes prior work focused on maximizing the number of matches under submodular demand assumptions, which do not hold in our revenue-maximization context. Our main contribution is the design of polynomial-time approximation algorithms with constant-factor guarantees. In particular, for general pairwise revenues, we develop a randomized algorithm that achieves a $(\\frac{1}{2} - \\epsilon)$-approximation in expectation for any $\\epsilon > 0$. The algorithm is static and provides guarantees under various agent arrival settings, including fixed order, simultaneous processing, and adaptive selection. When revenues are uniform across all pairs involving any given responding-side agent, the guarantee improves to $(1 - \\frac{1}{e} - \\epsilon)$. In structural settings where responding-side agents share a common revenue-based ranking, we design a simpler adaptive deterministic algorithm achieving a $\\frac{1}{2}$-approximation. Our approach leverages novel linear programming relaxations, correlation gap arguments, and structural properties of the revenue functions.",
    "source": "arXiv"
  },
  {
    "title": "When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning",
    "title_es": "When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning",
    "url": "https://arxiv.org/abs/2507.05011",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.05011v2 Announce Type: replace \nAbstract: Surgical action planning requires predicting future instrument-verb-target triplets for real-time assistance. While teleoperated robotic surgery provides natural expert demonstrations for imitation learning (IL), reinforcement learning (RL) could potentially discover superior strategies through exploration. We present the first comprehensive comparison of IL versus RL for surgical action planning on CholecT50. Our Dual-task Autoregressive Imitation Learning (DARIL) baseline achieves 34.6% action triplet recognition mAP and 33.6% next frame prediction mAP with smooth planning degradation to 29.2% at 10-second horizons. We evaluated three RL variants: world model-based RL, direct video RL, and inverse RL enhancement. Surprisingly, all RL approaches underperformed DARIL i.e. world model RL dropped to 3.1% mAP at 10s while direct video RL achieved only 15.9%. Our analysis reveals that distribution matching on expert-annotated test sets systematically favors IL over potentially valid RL policies that differ from training demonstrations. This challenges assumptions about RL superiority in sequential decision making and provides crucial insights for surgical AI development.",
    "source": "arXiv"
  },
  {
    "title": "LayLens: Improving Deepfake Understanding through Simplified Explanations",
    "title_es": "LayLens: Improving Deepfake Understanding through Simplified Explanations",
    "url": "https://arxiv.org/abs/2507.10066",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.10066v2 Announce Type: replace \nAbstract: This demonstration paper presents $\\mathbf{LayLens}$, a tool aimed to make deepfake understanding easier for users of all educational backgrounds. While prior works often rely on outputs containing technical jargon, LayLens bridges the gap between model reasoning and human understanding through a three-stage pipeline: (1) explainable deepfake detection using a state-of-the-art forgery localization model, (2) natural language simplification of technical explanations using a vision-language model, and (3) visual reconstruction of a plausible original image via guided image editing. The interface presents both technical and layperson-friendly explanations in addition to a side-by-side comparison of the uploaded and reconstructed images. A user study with 15 participants shows that simplified explanations significantly improve clarity and reduce cognitive load, with most users expressing increased confidence in identifying deepfakes. LayLens offers a step toward transparent, trustworthy, and user-centric deepfake forensics.",
    "source": "arXiv"
  },
  {
    "title": "Construction of Self-Orthogonal Quasi-Cyclic Codes and Their Application to Quantum Error-Correcting Codes",
    "title_es": "Construction of Self-Orthogonal Quasi-Cyclic Codes and Their Application to Quantum Error-Correcting Codes",
    "url": "https://arxiv.org/abs/2507.17319",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.17319v2 Announce Type: replace \nAbstract: In this paper, necessary and sufficient conditions for the self-orthogonality of t-generator quasi-cyclic (QC) codes are presented under the Euclidean, Hermitian, and symplectic inner products, respectively. Particularly, by studying the structure of the dual codes of a class of 2-generator QC codes, we derive necessary and sufficient conditions for the QC codes to be dual-containing under the above three inner products. This class of 2-generator QC codes generalizes many known codes in the literature. Based on the above conditions, we construct several quantum stabilizer codes and quantum synchronizable codes with good parameters, some of which share parameters with certain best-known codes listed in Grassl's code table.",
    "source": "arXiv"
  },
  {
    "title": "See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering",
    "title_es": "See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering",
    "url": "https://arxiv.org/abs/2507.17659",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.17659v2 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) have pushed the frontiers of Knowledge-Based Visual Question Answering (KBVQA), yet their reasoning is fundamentally bottlenecked by a reliance on uni-dimensional evidence. This \"seeing only the trees, but not the forest\" approach prevents robust, multi-faceted understanding. Inspired by the principle of seeing both the forest and trees, we propose Synergos-VQA, a novel synergistic reasoning framework. At its core, Synergos-VQA concurrently generates and fuses three complementary evidence streams at inference time: (1) Holistic Evidence to perceive the entire scene (the \"forest\"), (2) Structural Evidence from a prototype-driven module to identify key objects (the \"trees\"), and (3) Causal Evidence from a counterfactual probe to ensure the reasoning is robustly grounded. By synergistically fusing this multi-faceted evidence, our framework achieves a more comprehensive and reliable reasoning process. Extensive experiments show that Synergos-VQA decisively establishes a new state-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA. Furthermore, our approach demonstrates strong plug-and-play capabilities, significantly boosting various open-source MLLMs and proving that superior methodological design can outperform sheer model scale.",
    "source": "arXiv"
  },
  {
    "title": "GPSMamba: A Global Phase and Spectral Prompt-guided Mamba for Infrared Image Super-Resolution",
    "title_es": "GPSMamba: A Global Phase and Spectral Prompt-guided Mamba for Infrared Image Super-Resolution",
    "url": "https://arxiv.org/abs/2507.18998",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.18998v3 Announce Type: replace \nAbstract: Infrared Image Super-Resolution (IRSR) is challenged by the low contrast and sparse textures of infrared data, requiring robust long-range modeling to maintain global coherence. While State-Space Models like Mamba offer proficiency in modeling long-range dependencies for this task, their inherent 1D causal scanning mechanism fragments the global context of 2D images, hindering fine-detail restoration. To address this, we propose Global Phase and Spectral Prompt-guided Mamba (GPSMamba), a framework that synergizes architectural guidance with non-causal supervision. First, our Adaptive Semantic-Frequency State Space Module (ASF-SSM) injects a fused semantic-frequency prompt directly into the Mamba block, integrating non-local context to guide reconstruction. Then, a novel Thermal-Spectral Attention and Phase Consistency Loss provides explicit, non-causal supervision to enforce global structural and spectral fidelity. By combining these two innovations, our work presents a systematic strategy to mitigate the limitations of causal modeling. Extensive experiments demonstrate that GPSMamba achieves state-of-the-art performance, validating our approach as a powerful new paradigm for infrared image restoration. Code is available at https://github.com/yongsongH/GPSMamba.",
    "source": "arXiv"
  },
  {
    "title": "RemoteReasoner: Towards Unifying Geospatial Reasoning Workflow",
    "title_es": "RemoteReasoner: Towards Unifying Geospatial Reasoning Workflow",
    "url": "https://arxiv.org/abs/2507.19280",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.19280v2 Announce Type: replace \nAbstract: Remote sensing imagery presents vast, inherently unstructured spatial data, necessitating sophisticated reasoning to interpret complex user intents and contextual relationships beyond simple recognition tasks. In this paper, we aim to construct an Earth observation workflow to handle complex queries by reasoning about spatial context and user intent. As a reasoning workflow, it should autonomously explore and construct its own inference paths, rather than being confined to predefined ground-truth sequences. Ideally, its architecture ought to be unified yet generalized, possessing capabilities to perform diverse reasoning tasks through one model without requiring additional fine-tuning. Existing remote sensing approaches rely on supervised fine-tuning paradigms and task-specific heads, limiting both autonomous reasoning and unified generalization. To this end, we propose RemoteReasoner, a unified workflow for geospatial reasoning. The design of RemoteReasoner integrates a multi-modal large language model (MLLM) for interpreting user instructions and localizing targets, together with task transformation strategies that enable multi-granularity tasks, including object-, region-, and pixel-level. In contrast to existing methods, our framework is trained with reinforcement learning (RL) to endow the MLLM sufficient reasoning autonomy. At the inference stage, our transformation strategies enable diverse task output formats without requiring task-specific decoders or further fine-tuning. Experiments demonstrated that RemoteReasoner achieves state-of-the-art (SOTA) performance across multi-granularity reasoning tasks. Furthermore, it retains the MLLM's inherent generalization capability, demonstrating robust performance on unseen tasks and out-of-distribution categories.",
    "source": "arXiv"
  },
  {
    "title": "DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes",
    "title_es": "DriveIndia: An Object Detection Dataset for Diverse Indian Traffic Scenes",
    "url": "https://arxiv.org/abs/2507.19912",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.19912v3 Announce Type: replace \nAbstract: We introduce DriveIndia, a large-scale object detection dataset purpose-built to capture the complexity and unpredictability of Indian traffic environments. The dataset contains 66,986 high-resolution images annotated in YOLO format across 24 traffic-relevant object categories, encompassing diverse conditions such as varied weather (fog, rain), illumination changes, heterogeneous road infrastructure, and dense, mixed traffic patterns and collected over 120+ hours and covering 3,400+ kilometers across urban, rural, and highway routes. DriveIndia offers a comprehensive benchmark for real-world autonomous driving challenges. We provide baseline results using state-of-the-art YOLO family models, with the top-performing variant achieving a mAP50 of 78.7%. Designed to support research in robust, generalizable object detection under uncertain road conditions, DriveIndia will be publicly available via the TiHAN-IIT Hyderabad dataset repository https://tihan.iith.ac.in/TiAND.html (Terrestrial Datasets -> Camera Dataset).",
    "source": "arXiv"
  },
  {
    "title": "Digital and Robotic Twinning for Validation of Proximity Operations and Formation Flying",
    "title_es": "Digital and Robotic Twinning for Validation of Proximity Operations and Formation Flying",
    "url": "https://arxiv.org/abs/2507.20034",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.20034v2 Announce Type: replace \nAbstract: In spacecraft Rendezvous, Proximity Operations (RPO), and Formation Flying (FF), the Guidance Navigation and Control (GNC) system is safety-critical and must meet strict performance requirements. However, validating such systems is challenging due to the complexity of the space environment, necessitating a verification and validation (V&V) process that bridges simulation and real-world behavior. The key contribution of this paper is a unified, end-to-end digital and robotic twinning framework that enables software- and hardware-in-the-loop testing for multi-modal GNC systems. The robotic twin includes three testbeds at Stanford's Space Rendezvous Laboratory (SLAB): the GNSS and Radiofrequency Autonomous Navigation Testbed for Distributed Space Systems (GRAND) to validate RF-based navigation techniques, and the Testbed for Rendezvous and Optical Navigation (TRON) and Optical Stimulator (OS) to validate vision-based methods. The test article for this work is an integrated multi-modal GNC software stack for RPO and FF developed at SLAB. This paper introduces the hybrid framework and summarizes calibration and error characterization for the robotic twin. Then, the GNC stack's performance and robustness is characterized using the integrated digital and robotic twinning pipeline for a full-range RPO mission scenario in Low-Earth Orbit (LEO). The results shown in the paper demonstrate consistency between digital and robotic twins, validating the hybrid twinning pipeline as a reliable framework for realistic assessment and verification of GNC systems.",
    "source": "arXiv"
  },
  {
    "title": "Post-Completion Learning for Language Models",
    "title_es": "Post-Completion Learning for Language Models",
    "url": "https://arxiv.org/abs/2507.20252",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.20252v3 Announce Type: replace \nAbstract: Current language model training paradigms typically terminate learning upon reaching the end-of-sequence () token, overlooking the potential learning opportunities in the post-completion space. We propose Post-Completion Learning (PCL), a novel training framework that systematically utilizes the sequence space after model output completion, to enhance both the reasoning and self-evaluation abilities. PCL enables models to continue generating self-assessments and reward predictions during training, while maintaining efficient inference by stopping at the completion point.\n  To fully utilize this post-completion space, we design a white-box reinforcement learning method: let the model evaluate the output content according to the reward rules, then calculate and align the score with the reward functions for supervision. We implement dual-track SFT to optimize both reasoning and evaluation capabilities, and mixed it with RL training to achieve multi-objective hybrid optimization.\n  Experimental results on different datasets and models demonstrate consistent improvements over traditional SFT and RL methods. Our method provides a new technical path for language model training that enhances output quality while preserving deployment efficiency.",
    "source": "arXiv"
  },
  {
    "title": "DYNARTmo: A Dynamic Articulatory Model for Visualization of Speech Movement Patterns",
    "title_es": "DYNARTmo: A Dynamic Articulatory Model for Visualization of Speech Movement Patterns",
    "url": "https://arxiv.org/abs/2507.20343",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.20343v3 Announce Type: replace \nAbstract: We present DYNARTmo, a dynamic articulatory model designed to visualize speech articulation processes in a two-dimensional midsagittal plane. The model builds upon the UK-DYNAMO framework and integrates principles of articulatory underspecification, segmental and gestural control, and coarticulation. DYNARTmo simulates six key articulators based on ten continuous and six discrete control parameters, allowing for the generation of both vocalic and consonantal articulatory configurations. The current implementation is embedded in a web-based application (SpeechArticulationTrainer) that includes sagittal, glottal, and palatal views, making it suitable for use in phonetics education and speech therapy. While this paper focuses on the static modeling aspects, future work will address dynamic movement generation and integration with articulatory-acoustic modules.",
    "source": "arXiv"
  },
  {
    "title": "AI Pedagogy: Dialogic Social Learning for Artificial Agents",
    "title_es": "AI Pedagogy: Dialogic Social Learning for Artificial Agents",
    "url": "https://arxiv.org/abs/2507.21065",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.21065v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in processing extensive offline datasets. However, they often face challenges in acquiring and integrating complex, knowledge online. Traditional AI training paradigms, predominantly based on supervised learning or reinforcement learning, mirror a 'Piagetian' model of independent exploration. These approaches typically rely on large datasets and sparse feedback signals, limiting the models' ability to learn efficiently from interactions. Drawing inspiration from Vygotsky's sociocultural theory, this study explores the potential of socially mediated learning paradigms to address these limitations.\n  We introduce a dynamic environment, termed the 'AI Social Gym', where an AI learner agent engages in dyadic pedagogical dialogues with knowledgeable AI teacher agents. These interactions emphasize external, structured dialogue as a core mechanism for knowledge acquisition, contrasting with methods that depend solely on internal inference or pattern recognition.\n  Our investigation focuses on how different pedagogical strategies impact the AI learning process in the context of ontology acquisition. Empirical results indicate that such dialogic approaches-particularly those involving mixed-direction interactions combining top-down explanations with learner-initiated questioning-significantly enhance the LLM's ability to acquire and apply new knowledge, outperforming both unidirectional instructional methods and direct access to structured knowledge, formats typically present in training datasets.\n  These findings suggest that integrating pedagogical and psychological insights into AI and robot training can substantially improve post-training knowledge acquisition and response quality. This approach offers a complementary pathway to existing strategies like prompt engineering",
    "source": "arXiv"
  },
  {
    "title": "Probabilistic Active Goal Recognition",
    "title_es": "Probabilistic Active Goal Recognition",
    "url": "https://arxiv.org/abs/2507.21846",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.21846v2 Announce Type: replace \nAbstract: In multi-agent environments, effective interaction hinges on understanding the beliefs and intentions of other agents. While prior work on goal recognition has largely treated the observer as a passive reasoner, Active Goal Recognition (AGR) focuses on strategically gathering information to reduce uncertainty. We adopt a probabilistic framework for Active Goal Recognition and propose an integrated solution that combines a joint belief update mechanism with a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan efficiently and infer the actor's hidden goal without requiring domain-specific knowledge. Through comprehensive empirical evaluation in a grid-based domain, we show that our joint belief update significantly outperforms passive goal recognition, and that our domain-independent MCTS performs comparably to our strong domain-specific greedy baseline. These results establish our solution as a practical and robust framework for goal inference, advancing the field toward more interactive and adaptive multi-agent systems.",
    "source": "arXiv"
  },
  {
    "title": "On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations",
    "title_es": "On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations",
    "url": "https://arxiv.org/abs/2507.22398",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.22398v2 Announce Type: replace \nAbstract: Vision-Language Models (VLMs) are increasingly used as perceptual modules for visual content reasoning, including through captioning and DeepFake detection. In this work, we expose a critical vulnerability of VLMs when exposed to subtle, structured perturbations in the frequency domain. Specifically, we highlight how these feature transformations undermine authenticity/DeepFake detection and automated image captioning tasks. We design targeted image transformations, operating in the frequency domain to systematically adjust VLM outputs when exposed to frequency-perturbed real and synthetic images. We demonstrate that the perturbation injection method generalizes across five state-of-the-art VLMs which includes different-parameter Qwen2/2.5 and BLIP models. Experimenting across ten real and generated image datasets reveals that VLM judgments are sensitive to frequency-based cues and may not wholly align with semantic content. Crucially, we show that visually-imperceptible spatial frequency transformations expose the fragility of VLMs deployed for automated image captioning and authenticity detection tasks. Our findings under realistic, black-box constraints challenge the reliability of VLMs, underscoring the need for robust multimodal perception systems.",
    "source": "arXiv"
  },
  {
    "title": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System",
    "title_es": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System",
    "url": "https://arxiv.org/abs/2507.23261",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.23261v2 Announce Type: replace \nAbstract: Current multi-agent systems (MAS) frameworks often rely on manually designed and static collaboration graph structures, limiting adaptability and performance. To address these limitations, we propose DynaSwarm, a dynamic framework that enhances LLM-based MAS through two key innovations: (1) an actor-critic reinforcement learning (A2C) mechanism to optimize graph structures with improved stability over prior RL methods, and (2) a dynamic graph selector that adaptively chooses the optimal graph structure for each input sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the need for rigid, one-fits-all graph architectures, instead leveraging sample-specific idiosyncrasies to dynamically route queries through specialized agent networks. (c) We propose to fine-tune the demonstration retriever to fully exploit the power of in-context learning (ICL). Extensive experiments on question answering, mathematical reasoning, and coding tasks demonstrate that DynaSwarm consistently outperforms state-of-the-art single-agent and MAS baselines across multiple LLM backbones. Our findings highlight the importance of sample-aware structural flexibility in LLM MAS designs.",
    "source": "arXiv"
  },
  {
    "title": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations",
    "title_es": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations",
    "url": "https://arxiv.org/abs/2507.23465",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.23465v2 Announce Type: replace \nAbstract: As large language models (LLMs) are increasingly deployed in enterprise settings, controlling model behavior based on user roles becomes an essential requirement. Existing safety methods typically assume uniform access and focus on preventing harmful or toxic outputs, without addressing role-specific access constraints. In this work, we investigate whether LLMs can be fine-tuned to generate responses that reflect the access privileges associated with different organizational roles. We explore three modeling strategies: a BERT-based classifier, an LLM-based classifier, and role-conditioned generation. To evaluate these approaches, we construct two complementary datasets. The first is adapted from existing instruction-tuning corpora through clustering and role labeling, while the second is synthetically generated to reflect realistic, role-sensitive enterprise scenarios. We assess model performance across varying organizational structures and analyze robustness to prompt injection, role mismatch, and jailbreak attempts.",
    "source": "arXiv"
  },
  {
    "title": "A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains",
    "title_es": "A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains",
    "url": "https://arxiv.org/abs/2507.23486",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.23486v2 Announce Type: replace \nAbstract: Large language models (LLMs) hold promise in clinical decision support but face major challenges in safety evaluation and effectiveness validation. We developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a multidimensional framework built on clinical expert consensus, encompassing 30 criteria covering critical areas like critical illness recognition, guideline adherence, and medication safety, with weighted consequence measures. Thirty-two specialist physicians developed and reviewed 2,069 open-ended Q\\&A items aligned with these criteria, spanning 26 clinical departments to simulate real-world scenarios. Benchmark testing of six LLMs revealed moderate overall performance (average total score 57.2\\%, safety 54.7\\%, effectiveness 62.3\\%), with a significant 13.3\\% performance drop in high-risk scenarios (p $<$ 0.0001). Domain-specific medical LLMs showed consistent performance advantages over general-purpose models, with relatively higher top scores in safety (0.912) and effectiveness (0.861). The findings of this study not only provide a standardized metric for evaluating the clinical application of medical LLMs, facilitating comparative analyses, risk exposure identification, and improvement directions across different scenarios, but also hold the potential to promote safer and more effective deployment of large language models in healthcare environments.",
    "source": "arXiv"
  },
  {
    "title": "Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions",
    "title_es": "Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions",
    "url": "https://arxiv.org/abs/2507.23778",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.23778v2 Announce Type: replace \nAbstract: While current general-purpose 3D human models (e.g., SMPL-X) efficiently represent accurate human shape and pose, they lacks the ability to physically interact with the environment due to the kinematic nature. As a result, kinematic-based interaction models often suffer from issues such as interpenetration and unrealistic object dynamics. To address this limitation, we introduce a novel approach that embeds SMPL-X into a tangible entity capable of dynamic physical interactions with its surroundings. Specifically, we propose a \"half-physics\" mechanism that transforms 3D kinematic motion into a physics simulation. Our approach maintains kinematic control over inherent SMPL-X poses while ensuring physically plausible interactions with scenes and objects, effectively eliminating penetration and unrealistic object dynamics. Unlike reinforcement learning-based methods, which demand extensive and complex training, our half-physics method is learning-free and generalizes to any body shape and motion; meanwhile, it operates in real time. Moreover, it preserves the fidelity of the original kinematic motion while seamlessly integrating physical interactions",
    "source": "arXiv"
  },
  {
    "title": "Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training",
    "title_es": "Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training",
    "url": "https://arxiv.org/abs/2508.00414",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.00414v2 Announce Type: replace \nAbstract: General AI Agents are increasingly recognized as foundational frameworks for the next generation of artificial intelligence, enabling complex reasoning, web interaction, coding, and autonomous research capabilities. However, current agent systems are either closed-source or heavily reliant on a variety of paid APIs and proprietary tools, limiting accessibility and reproducibility for the research community. In this work, we present \\textbf{Cognitive Kernel-Pro}, a fully open-source and (to the maximum extent) free multi-module agent framework designed to democratize the development and evaluation of advanced AI agents. Within Cognitive Kernel-Pro, we systematically investigate the curation of high-quality training data for Agent Foundation Models, focusing on the construction of queries, trajectories, and verifiable answers across four key domains: web, file, code, and general reasoning. Furthermore, we explore novel strategies for agent test-time reflection and voting to enhance agent robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving state-of-the-art results among open-source and free agents. Notably, our 8B-parameter open-source model surpasses previous leading systems such as WebDancer and WebSailor, establishing a new performance standard for accessible, high-capability AI agents. Code is available at https://github.com/Tencent/CognitiveKernel-Pro",
    "source": "arXiv"
  },
  {
    "title": "Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving",
    "title_es": "Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.00589",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.00589v2 Announce Type: replace \nAbstract: Autonomous driving systems must operate reliably in safety-critical scenarios, particularly those involving unusual or complex behavior by Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets is essential for robust evaluation and generalization, but retrieving such rare human behavior scenarios within the long tail of large-scale datasets is challenging. To support targeted evaluation of autonomous driving systems in diverse, human-centered scenarios, we propose a novel context-aware motion retrieval framework. Our method combines Skinned Multi-Person Linear (SMPL)-based motion sequences and corresponding video frames before encoding them into a shared multimodal embedding space aligned with natural language. Our approach enables the scalable retrieval of human behavior and their context through text queries. This work also introduces our dataset WayMoCo, an extension of the Waymo Open Dataset. It contains automatically labeled motion and scene context descriptions derived from generated pseudo-ground-truth SMPL sequences and corresponding image data. Our approach outperforms state-of-the-art models by up to 27.5% accuracy in motion-context retrieval, when evaluated on the WayMoCo dataset.",
    "source": "arXiv"
  },
  {
    "title": "Edge-Based Multimodal Sensor Data Fusion with Vision Language Models (VLMs) for Real-time Autonomous Vehicle Accident Avoidance",
    "title_es": "Edge-Based Multimodal Sensor Data Fusion with Vision Language Models (VLMs) for Real-time Autonomous Vehicle Accident Avoidance",
    "url": "https://arxiv.org/abs/2508.01057",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.01057v2 Announce Type: replace \nAbstract: Autonomous driving (AD) systems relying solely on onboard sensors may fail to detect distant or obstacle hazards, potentially causing preventable collisions; however, existing transformer-based Vehicle-to-Everything (V2X) approaches, which mitigate AD sensing limitations, either lack effective multimodal fusion and reasoning or struggle to meet real-time performance requirements under complex, high-dimensional traffic conditions. This paper proposes the Real-time Edge-based Autonomous Co-pilot Trajectory planner (REACT), a V2X-integrated trajectory optimization framework for AD based on a fine-tuned lightweight Vision-Language Model (VLM). REACT integrates infrastructure-provided hazard alerts with onboard sensor data, capturing intricate surrounding traffic dynamics and vehicle intents through visual embeddings, interpreting precise numerical data from symbolic inputs, and employing contextual reasoning to generate optimized, safety-oriented trajectories. To ensure robust real-time deployment on edge devices, REACT innovatively employs Residual Trajectory Fusion (RTF) design and specialized edge-adaptation strategies to reduce model complexity and improve inference efficiency. Evaluated on the DeepAccident benchmark, REACT achieves state-of-the-art performance, a 77% collision rate reduction, a 48.2% Video Panoptic Quality (VPQ), and a 0.57-second inference latency on the Jetson AGX Orin. Ablation studies validate the contribution of each input, module, and edge adaptation strategy. These results highlight the effectiveness of lightweight VLMs in enabling real-time cooperative planning on edge platforms and underscore the potential of language-guided contextual reasoning for improving traffic safety and responsiveness.",
    "source": "arXiv"
  },
  {
    "title": "Explaining Time Series Classifiers with PHAR: Rule Extraction and Fusion from Post-hoc Attributions",
    "title_es": "Explaining Time Series Classifiers with PHAR: Rule Extraction and Fusion from Post-hoc Attributions",
    "url": "https://arxiv.org/abs/2508.01687",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.01687v2 Announce Type: replace \nAbstract: Explaining machine learning (ML) models for time series (TS) classification remains challenging due to the difficulty of interpreting raw time series and the high dimensionality of the input space. We introduce PHAR-Post-hoc Attribution Rules-a unified framework that transforms numeric feature attributions from post-hoc, instance-wise explainers (e.g., LIME, SHAP) into structured, human-readable rules. These rules define interpretable intervals that indicate where and when key decision boundaries occur, enhancing model transparency. PHAR performs comparably to native rule-based methods, such as Anchor, while scaling more efficiently to long TS sequences and achieving broader instance coverage. A dedicated rule fusion step consolidates rule sets using strategies like weighted selection and lasso-based refinement, balancing key quality metrics: coverage, confidence, and simplicity. This fusion ensures each instance receives a concise and unambiguous rule, improving both explanation fidelity and consistency. We further introduce visualization techniques to illustrate specificity-generalization trade-offs in the derived rules. PHAR resolves conflicting and overlapping explanations-a common effect of the Rashomon phenomenon-into coherent, domain-adaptable insights. Comprehensive experiments on UCR/UEA Time Series Classification Archive demonstrate that PHAR improves interpretability, decision transparency, and practical applicability for TS classification tasks.",
    "source": "arXiv"
  },
  {
    "title": "Marco-Voice Technical Report",
    "title_es": "Marco-Voice Technical Report",
    "url": "https://arxiv.org/abs/2508.02038",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.02038v3 Announce Type: replace \nAbstract: This paper presents a multifunctional speech synthesis system that integrates voice cloning and emotion control speech synthesis within a unified framework. The goal of this work is to address longstanding challenges in achieving highly expressive, controllable, and natural speech generation that faithfully preserves speaker identity across diverse linguistic and emotional contexts. Our approach introduces an effective speaker-emotion disentanglement mechanism with in-batch contrastive learning, enabling independent manipulation of speaker identity and eemotional style, as well as rotational emotional embedding integration method for smooth emotion control. To support comprehensive training and evaluation, we construct CSEMOTIONS, a high-quality emotional speech dataset containing 10 hours of Mandarin speech from six professional speakers across seven emotional categories. Extensive experiments demonstrate that our system, Marco-Voice, achieves substantial improvements in both objective and subjective metrics. Comprehensive evaluations and analysis were conducted, results show that MarcoVoice delivers competitive performance in terms of speech clarity and emotional richness, representing a substantial advance in the field of expressive neural speech synthesis. Our code and dataset are publicly available at https://github.com/AIDC-AI/Marco-Voice and https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS respectively.",
    "source": "arXiv"
  },
  {
    "title": "Trainable Dynamic Mask Sparse Attention",
    "title_es": "Trainable Dynamic Mask Sparse Attention",
    "url": "https://arxiv.org/abs/2508.02124",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.02124v2 Announce Type: replace \nAbstract: In large language models, the demand for modeling long contexts is constantly increasing, but the quadratic complexity of the standard self-attention mechanism often becomes a bottleneck. Although existing sparse attention mechanisms have improved efficiency, they may still encounter issues such as static patterns or information loss. We introduce a trainable dynamic mask sparse attention mechanism, Dynamic Mask Attention, which effectively utilizes content-aware and position-aware sparsity. DMA achieves this through two key innovations: First, it dynamically generates content-aware sparse masks from value representations, enabling the model to identify and focus on critical information adaptively. Second, it implements position-aware sparse attention computation that effectively skips unnecessary calculation regions. This dual-sparsity design allows the model to significantly reduce the computational complexity of important information while retaining complete information, achieving an excellent balance between information fidelity and computational efficiency. We have verified the performance of DMA through comprehensive experiments. Comparative studies show that DMA outperforms multi-head attention, sliding window attention, multi-head latent attention, and native sparse attention in terms of perplexity under Chinchilla Scaling Law settings. Moreover, in challenging multi-query associative recall tasks, DMA also demonstrates superior performance and efficiency compared to these methods. Crucially, in the evaluation of a 1.7B parameter model, DMA significantly outperforms multi-head attention in both standard benchmark performance and the challenging needle-in-a-haystack task. These experimental results highlight its capability to balance model efficiency and long-context modeling ability effectively.",
    "source": "arXiv"
  },
  {
    "title": "Frequency Point Game Environment for UAVs via Expert Knowledge and Large Language Model",
    "title_es": "Frequency Point Game Environment for UAVs via Expert Knowledge and Large Language Model",
    "url": "https://arxiv.org/abs/2508.02757",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.02757v2 Announce Type: replace \nAbstract: Unmanned Aerial Vehicles (UAVs) have made significant advancements in communication stability and security through techniques such as frequency hopping, signal spreading, and adaptive interference suppression. However, challenges remain in modeling spectrum competition, integrating expert knowledge, and predicting opponent behavior. To address these issues, we propose UAV-FPG (Unmanned Aerial Vehicle - Frequency Point Game), a game-theoretic environment model that simulates the dynamic interaction between interference and anti-interference strategies of opponent and ally UAVs in communication frequency bands. The model incorporates a prior expert knowledge base to optimize frequency selection and employs large language models for path planning, simulating a \"strong adversary\". Experimental results highlight the effectiveness of integrating the expert knowledge base and the large language model, with the latter significantly improving path planning in dynamic scenarios through iterative interactions, outperforming fixed-path strategies. UAV-FPG provides a robust platform for advancing anti-jamming strategies and intelligent decision-making in UAV communication systems.",
    "source": "arXiv"
  },
  {
    "title": "PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows",
    "title_es": "PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows",
    "url": "https://arxiv.org/abs/2508.02866",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.02866v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) and other foundation models are increasingly used as the core of AI agents. In agentic workflows, these agents plan tasks, interact with humans and peers, and influence scientific outcomes across federated and heterogeneous workflows. However, agents can hallucinate or reason incorrectly, propagating errors when one agent's output becomes another's input. Thus, assuring that agents' actions are transparent, traceable, reproducible, and reliable is critical to assess hallucination risks and mitigate their workflow impacts. While provenance techniques have long supported these principles, existing methods fail to capture and relate agent-centric metadata such as prompts, responses, and decisions with the broader workflow context and downstream outcomes. In this paper, we introduce PROV-AGENT, a provenance model that extends W3C PROV and leverages the Model Context Protocol (MCP) and data observability to integrate agent interactions into end-to-end workflow provenance. Our contributions include: (1) a provenance model tailored for agentic workflows, (2) a near real-time, open-source system for capturing agentic provenance, and (3) a cross-facility evaluation spanning edge, cloud, and HPC environments, demonstrating support for critical provenance queries and agent reliability analysis.",
    "source": "arXiv"
  },
  {
    "title": "A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models",
    "title_es": "A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models",
    "url": "https://arxiv.org/abs/2508.04276",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.04276v2 Announce Type: replace \nAbstract: Graph-based Retrieval-Augmented Generation (GraphRAG) has recently emerged as a promising paradigm for enhancing large language models (LLMs) by converting raw text into structured knowledge graphs, improving both accuracy and explainability. However, GraphRAG relies on LLMs to extract knowledge from raw text during graph construction, and this process can be maliciously manipulated to implant misleading information. Targeting this attack surface, we propose two knowledge poisoning attacks (KPAs) and demonstrate that modifying only a few words in the source text can significantly change the constructed graph, poison the GraphRAG, and severely mislead downstream reasoning. The first attack, named Targeted KPA (TKPA), utilizes graph-theoretic analysis to locate vulnerable nodes in the generated graphs and rewrites the corresponding narratives with LLMs, achieving precise control over specific question-answering (QA) outcomes with a success rate of 93.1\\%, while keeping the poisoned text fluent and natural. The second attack, named Universal KPA (UKPA), exploits linguistic cues such as pronouns and dependency relations to disrupt the structural integrity of the generated graph by altering globally influential words. With fewer than 0.05\\% of full text modified, the QA accuracy collapses from 95\\% to 50\\%. Furthermore, experiments show that state-of-the-art defense methods fail to detect these attacks, highlighting that securing GraphRAG pipelines against knowledge poisoning remains largely unexplored.",
    "source": "arXiv"
  },
  {
    "title": "GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy",
    "title_es": "GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy",
    "url": "https://arxiv.org/abs/2508.04349",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.04349v2 Announce Type: replace \nAbstract: Reinforcement learning (RL) with algorithms like Group Relative Policy Optimization (GRPO) improves Large Language Model (LLM) reasoning, but is limited by a coarse-grained credit assignment that applies a uniform reward to all tokens in a sequence. This is a major flaw in long-chain reasoning tasks. This paper solves this with \\textbf{Dynamic Entropy Weighting}. Our core idea is that high-entropy tokens in correct responses can guide the policy toward a higher performance ceiling. This allows us to create more fine-grained reward signals for precise policy updates via two ways: 1) \\textbf{Group Token Policy Optimization} (\\textbf{GTPO}), we assigns a entropy-weighted reward to each token for fine-grained credit assignment. 2) \\textbf{Sequence-Level Group Relative Policy Optimization} (\\textbf{GRPO-S}), we assigns a entropy-weighted reward to each sequence based on its average token entropy. Experiments show our methods significantly outperform the strong DAPO baseline. The results confirm that our entropy-weighting mechanism is the key driver of this performance boost, offering a better path to enhance deep reasoning in models.",
    "source": "arXiv"
  },
  {
    "title": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference",
    "title_es": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference",
    "url": "https://arxiv.org/abs/2508.04586",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.04586v2 Announce Type: replace \nAbstract: Artificial Intelligence (AI) conferences are essential for advancing research, sharing knowledge, and fostering academic community. However, their rapid expansion has rendered the centralized conference model increasingly unsustainable. This paper offers a data-driven diagnosis of a structural crisis that threatens the foundational goals of scientific dissemination, equity, and community well-being. We identify four key areas of strain: (1) scientifically, with per-author publication rates more than doubling over the past decade to over 4.5 papers annually; (2) environmentally, with the carbon footprint of a single conference exceeding the daily emissions of its host city; (3) psychologically, with 71% of online community discourse reflecting negative sentiment and 35% referencing mental health concerns; and (4) logistically, with attendance at top conferences such as NeurIPS 2024 beginning to outpace venue capacity. These pressures point to a system that is misaligned with its core mission. In response, we propose the Community-Federated Conference (CFC) model, which separates peer review, presentation, and networking into globally coordinated but locally organized components, offering a more sustainable, inclusive, and resilient path forward for AI research.",
    "source": "arXiv"
  },
  {
    "title": "How Does Bilateral Ear Symmetry Affect Deep Ear Features?",
    "title_es": "How Does Bilateral Ear Symmetry Affect Deep Ear Features?",
    "url": "https://arxiv.org/abs/2508.04614",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.04614v2 Announce Type: replace \nAbstract: Ear recognition has gained attention as a reliable biometric technique due to the distinctive characteristics of human ears. With the increasing availability of large-scale datasets, convolutional neural networks (CNNs) have been widely adopted to learn features directly from raw ear images, outperforming traditional hand-crafted methods. However, the effect of bilateral ear symmetry on the features learned by CNNs has received little attention in recent studies. In this paper, we investigate how bilateral ear symmetry influences the effectiveness of CNN-based ear recognition. To this end, we first develop an ear side classifier to automatically categorize ear images as either left or right. We then explore the impact of incorporating this side information during both training and test. Cross-dataset evaluations are conducted on five datasets. Our results suggest that treating left and right ears separately during training and testing can lead to notable performance improvements. Furthermore, our ablation studies on alignment strategies, input sizes, and various hyperparameter settings provide practical insights into training CNN-based ear recognition systems on large-scale datasets to achieve higher verification rates.",
    "source": "arXiv"
  },
  {
    "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience",
    "title_es": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience",
    "url": "https://arxiv.org/abs/2508.04700",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.04700v2 Announce Type: replace \nAbstract: Repurposing large vision-language models (LVLMs) as computer use agents (CUAs) has led to substantial breakthroughs, primarily driven by human-labeled data. However, these models often struggle with novel and specialized software, particularly in scenarios lacking human annotations. To address this challenge, we propose SEAgent, an agentic self-evolving framework enabling CUAs to autonomously evolve through interactions with unfamiliar software. Specifically, SEAgent empowers computer-use agents to autonomously master novel software environments via experiential learning, where agents explore new software, learn through iterative trial-and-error, and progressively tackle auto-generated tasks organized from simple to complex. To achieve this goal, we design a World State Model for step-wise trajectory assessment, along with a Curriculum Generator that generates increasingly diverse and challenging tasks. The agent's policy is updated through experiential learning, comprised of adversarial imitation of failure actions and Group Relative Policy Optimization (GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist training strategy that integrates individual experiential insights from specialist agents, facilitating the development of a stronger generalist CUA capable of continuous autonomous evolution. This unified agent ultimately achieves performance surpassing ensembles of individual specialist agents on their specialized software. We validate the effectiveness of SEAgent across five novel software environments within OS-World. Our approach achieves a significant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a competitive open-source CUA, i.e., UI-TARS.",
    "source": "arXiv"
  },
  {
    "title": "RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory",
    "title_es": "RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory",
    "url": "https://arxiv.org/abs/2508.04903",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.04903v3 Announce Type: replace \nAbstract: Multi-agent large language model (LLM) systems have shown strong potential in complex reasoning and collaborative decision-making tasks. However, most existing coordination schemes rely on static or full-context routing strategies, which lead to excessive token consumption, redundant memory exposure, and limited adaptability across interaction rounds. We introduce RCR-Router, a modular and role-aware context routing framework designed to enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge, this is the first routing approach that dynamically selects semantically relevant memory subsets for each agent based on its role and task stage, while adhering to a strict token budget. A lightweight scoring policy guides memory selection, and agent outputs are iteratively integrated into a shared memory store to facilitate progressive context refinement. To better evaluate model behavior, we further propose an Answer Quality Score metric that captures LLM-generated explanations beyond standard QA accuracy. Experiments on three multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate that RCR-Router reduces token usage (up to 30%) while improving or maintaining answer quality. These results highlight the importance of structured memory routing and output-aware evaluation in advancing scalable multi-agent LLM systems.",
    "source": "arXiv"
  },
  {
    "title": "REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation",
    "title_es": "REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation",
    "url": "https://arxiv.org/abs/2508.04946",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.04946v2 Announce Type: replace \nAbstract: Simultaneous Speech Translation (SimulST) systems stream in audio while simultaneously emitting translated text or speech. Such systems face the significant challenge of balancing translation quality and latency. We introduce a strategy to optimize this tradeoff: wait for more input only if you gain information by doing so. Based on this strategy, we present Regularized Entropy INformation Adaptation (REINA), a novel loss to train an adaptive policy using an existing non-streaming translation model. We derive REINA from information theory principles and show that REINA helps push the reported Pareto frontier of the latency/quality tradeoff over prior works. Utilizing REINA, we train a SimulST model on French, Spanish and German, both from and into English. Training on only open source or synthetically generated data, we achieve state-of-the-art (SOTA) streaming results for models of comparable size. We also introduce a metric for streaming efficiency, quantitatively showing REINA improves the latency/quality trade-off by as much as 21% compared to prior approaches, normalized against non-streaming baseline BLEU scores.",
    "source": "arXiv"
  },
  {
    "title": "Situated Epistemic Infrastructures: A Diagnostic Framework for Post-Coherence Knowledge",
    "title_es": "Situated Epistemic Infrastructures: A Diagnostic Framework for Post-Coherence Knowledge",
    "url": "https://arxiv.org/abs/2508.04995",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.04995v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) such as ChatGPT have rendered visible the fragility of contemporary knowledge infrastructures by simulating coherence while bypassing traditional modes of citation, authority, and validation. This paper introduces the Situated Epistemic Infrastructures (SEI) framework as a diagnostic tool for analyzing how knowledge becomes authoritative across hybrid human-machine systems under post-coherence conditions. Rather than relying on stable scholarly domains or bounded communities of practice, SEI traces how credibility is mediated across institutional, computational, and temporal arrangements. Integrating insights from infrastructure studies, platform theory, and epistemology, the framework foregrounds coordination over classification, emphasizing the need for anticipatory and adaptive models of epistemic stewardship. The paper contributes to debates on AI governance, knowledge production, and the ethical design of information systems by offering a robust alternative to representationalist models of scholarly communication.",
    "source": "arXiv"
  },
  {
    "title": "Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms",
    "title_es": "Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms",
    "url": "https://arxiv.org/abs/2508.05387",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.05387v3 Announce Type: replace \nAbstract: Modern RL-based post-training for large language models (LLMs) co-locate trajectory sampling and policy optimisation on the same GPU cluster, forcing the system to switch between inference and training workloads. This serial context switching violates the single-program-multiple-data (SPMD) assumption underlying today's distributed training systems. We present Echo, the RL system that cleanly decouples these two phases across heterogeneous \"inference\" and \"training\" swarms while preserving statistical efficiency. Echo introduces two lightweight synchronization protocols: a sequential pull mode that refreshes policy weights according to API call for minimal bias, and an asynchronous push-pull mode that streams version-tagged rollouts through a replay buffer to maximise hardware utilisation. Training four representative RL workloads with Qwen3-4B, Qwen2.5-7B, Qwen3-30B-A3B-Thinking-2507 and Qwen3-32B on a geographically distributed cluster, Echo matches a fully co-located Verl baseline in convergence speed and final reward while off-loading trajectory generation to commodity edge hardware. These promising results demonstrate that large-scale RL for LLMs could achieve datacentre-grade performance using decentralised, heterogeneous resources.",
    "source": "arXiv"
  },
  {
    "title": "Federated Multi-Objective Learning with Controlled Pareto Frontiers",
    "title_es": "Federated Multi-Objective Learning with Controlled Pareto Frontiers",
    "url": "https://arxiv.org/abs/2508.05424",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.05424v2 Announce Type: replace \nAbstract: Federated learning (FL) is a widely adopted paradigm for privacy-preserving model training, but FedAvg optimise for the majority while under-serving minority clients. Existing methods such as federated multi-objective learning (FMOL) attempts to import multi-objective optimisation (MOO) into FL. However, it merely delivers task-wise Pareto-stationary points, leaving client fairness to chance. In this paper, we introduce Conically-Regularised FMOL (CR-FMOL), the first federated MOO framework that enforces client-wise Pareto optimality through a novel preference-cone constraint. After local federated multi-gradient descent averaging (FMGDA) / federated stochastic multi-gradient descent averaging (FSMGDA) steps, each client transmits its aggregated task-loss vector as an implicit preference; the server then solves a cone-constrained Pareto-MTL sub-problem centred at the uniform vector, producing a descent direction that is Pareto-stationary for every client within its cone. Experiments on non-IID benchmarks show that CR-FMOL enhances client fairness, and although the early-stage performance is slightly inferior to FedAvg, it is expected to achieve comparable accuracy given sufficient training rounds.",
    "source": "arXiv"
  },
  {
    "title": "LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models",
    "title_es": "LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models",
    "url": "https://arxiv.org/abs/2508.05452",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.05452v2 Announce Type: replace \nAbstract: Existing evaluation of Large Language Models (LLMs) on static benchmarks is vulnerable to data contamination and leaderboard overfitting, critical issues that obscure true model capabilities. To address this, we introduce LLMEval-3, a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary bank of 220k graduate-level questions, from which it dynamically samples unseen test sets for each evaluation run. Its automated pipeline ensures integrity via contamination-resistant data curation, a novel anti-cheating architecture, and a calibrated LLM-as-a-judge process achieving 90% agreement with human experts, complemented by a relative ranking system for fair comparison. An 20-month longitudinal study of nearly 50 leading models reveals a performance ceiling on knowledge memorization and exposes data contamination vulnerabilities undetectable by static benchmarks. The framework demonstrates exceptional robustness in ranking stability and consistency, providing strong empirical validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and credible methodology for assessing the true capabilities of LLMs beyond leaderboard scores, promoting the development of more trustworthy evaluation standards.",
    "source": "arXiv"
  },
  {
    "title": "InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities",
    "title_es": "InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities",
    "url": "https://arxiv.org/abs/2508.05496",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.05496v2 Announce Type: replace \nAbstract: Large language models (LLMs) have exhibited impressive reasoning abilities on a wide range of complex tasks. However, enhancing these capabilities through post-training remains resource intensive, particularly in terms of data and computational cost. Although recent efforts have sought to improve sample efficiency through selective data curation, existing methods often rely on heuristic or task-specific strategies that hinder scalability. In this work, we introduce InfiAlign, a scalable and sample-efficient post-training framework that integrates supervised fine-tuning (SFT) with Direct Preference Optimization (DPO) to align LLMs for enhanced reasoning. At the core of InfiAlign is a robust data selection pipeline that automatically curates high-quality alignment data from open-source reasoning datasets using multidimensional quality metrics. This pipeline enables significant performance gains while drastically reducing data requirements and remains extensible to new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only approximately 12% of the training data, and demonstrates strong generalization across diverse reasoning tasks. Additional improvements are obtained through the application of DPO, with particularly notable gains in mathematical reasoning tasks. The model achieves an average improvement of 3.89% on AIME 24/25 benchmarks. Our results highlight the effectiveness of combining principled data selection with full-stage post-training, offering a practical solution for aligning large reasoning models in a scalable and data-efficient manner. The model checkpoints are available at https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.",
    "source": "arXiv"
  },
  {
    "title": "DogFit: Domain-guided Fine-tuning for Efficient Transfer Learning of Diffusion Models",
    "title_es": "DogFit: Domain-guided Fine-tuning for Efficient Transfer Learning of Diffusion Models",
    "url": "https://arxiv.org/abs/2508.05685",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.05685v2 Announce Type: replace \nAbstract: Transfer learning of diffusion models to smaller target domains is challenging, as naively fine-tuning the model often results in poor generalization. Test-time guidance methods help mitigate this by offering controllable improvements in image fidelity through a trade-off with sample diversity. However, this benefit comes at a high computational cost, typically requiring dual forward passes during sampling. We propose the Domain-guided Fine-tuning (DogFit) method, an effective guidance mechanism for diffusion transfer learning that maintains controllability without incurring additional computational overhead. DogFit injects a domain-aware guidance offset into the training loss, effectively internalizing the guided behavior during the fine-tuning process. The domain-aware design is motivated by our observation that during fine-tuning, the unconditional source model offers a stronger marginal estimate than the target model. To support efficient controllable fidelity-diversity trade-offs at inference, we encode the guidance strength value as an additional model input through a lightweight conditioning mechanism. We further investigate the optimal placement and timing of the guidance offset during training and propose two simple scheduling strategies, i.e., late-start and cut-off, which improve generation quality and training stability. Experiments on DiT and SiT backbones across six diverse target domains show that DogFit can outperform prior guidance methods in transfer learning in terms of FID and FDDINOV2 while requiring up to 2x fewer sampling TFLOPS.",
    "source": "arXiv"
  },
  {
    "title": "Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking",
    "title_es": "Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking",
    "url": "https://arxiv.org/abs/2508.05700",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.05700v2 Announce Type: replace \nAbstract: Large embedding tables are indispensable in modern recommendation systems, thanks to their ability to effectively capture and memorize intricate details of interactions among diverse entities. As we explore integrating large embedding tables into Pinterest's ads ranking models, we encountered not only common challenges such as sparsity and scalability, but also several obstacles unique to our context. Notably, our initial attempts to train large embedding tables from scratch resulted in neutral metrics. To tackle this, we introduced a novel multi-faceted pretraining scheme that incorporates multiple pretraining algorithms. This approach greatly enriched the embedding tables and resulted in significant performance improvements. As a result, the multi-faceted large embedding tables bring great performance gain on both the Click-Through Rate (CTR) and Conversion Rate (CVR) domains. Moreover, we designed a CPU-GPU hybrid serving infrastructure to overcome GPU memory limits and elevate the scalability. This framework has been deployed in the Pinterest Ads system and achieved 1.34% online CPC reduction and 2.60% CTR increase with neutral end-to-end latency change.",
    "source": "arXiv"
  },
  {
    "title": "Surviving the Narrative Collapse: Sustainability and Justice in Computing Within Limits",
    "title_es": "Surviving the Narrative Collapse: Sustainability and Justice in Computing Within Limits",
    "url": "https://arxiv.org/abs/2508.05992",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.05992v2 Announce Type: replace \nAbstract: Sustainability-driven computing research - encompassing equity, diversity, climate change, and social justice - is increasingly dismissed as woke or even dangerous in many sociopolitical contexts. As misinformation, ideological polarisation, deliberate ignorance and reactionary narratives gain ground, how can sustainability research in computing continue to exist and make an impact? This paper explores these tensions through Fictomorphosis, a creative story retelling method that reframes contested topics through different genres and perspectives. By engaging computing researchers in structured narrative transformations, we investigate how sustainability-oriented computing research is perceived, contested, and can adapt in a post-truth world.",
    "source": "arXiv"
  },
  {
    "title": "ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference",
    "title_es": "ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference",
    "url": "https://arxiv.org/abs/2508.06053",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06053v2 Announce Type: replace \nAbstract: Pedestrian inertial localization is key for mobile and IoT services because it provides infrastructure-free positioning. Yet most learning-based methods depend on fixed sliding-window integration, struggle to adapt to diverse motion scales and cadences, and yield inconsistent uncertainty, limiting real-world use. We present ReNiL, a Bayesian deep-learning framework for accurate, efficient, and uncertainty-aware pedestrian localization. ReNiL introduces Inertial Positioning Demand Points (IPDPs) to estimate motion at contextually meaningful waypoints instead of dense tracking, and supports inference on IMU sequences at any scale so cadence can match application needs. It couples a motion-aware orientation filter with an Any-Scale Laplace Estimator (ASLE), a dual-task network that blends patch-based self-supervision with Bayesian regression. By modeling displacements with a Laplace distribution, ReNiL provides homogeneous Euclidean uncertainty that integrates cleanly with other sensors. A Bayesian inference chain links successive IPDPs into consistent trajectories. On RoNIN-ds and a new WUDataset covering indoor and outdoor motion from 28 participants, ReNiL achieves state-of-the-art displacement accuracy and uncertainty consistency, outperforming TLIO, CTIN, iMoT, and RoNIN variants while reducing computation. Application studies further show robustness and practicality for mobile and IoT localization, making ReNiL a scalable, uncertainty-aware foundation for next-generation positioning.",
    "source": "arXiv"
  },
  {
    "title": "GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving",
    "title_es": "GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.06113",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06113v2 Announce Type: replace \nAbstract: Diffusion-based models are redefining the state-of-the-art in end-to-end autonomous driving, yet their performance is increasingly hampered by a reliance on transformer-based fusion. These architectures face fundamental limitations: quadratic computational complexity restricts the use of high-resolution features, and a lack of spatial priors prevents them from effectively modeling the inherent structure of Bird's Eye View (BEV) representations. This paper introduces GMF-Drive (Gated Mamba Fusion for Driving), an end-to-end framework that overcomes these challenges through two principled innovations. First, we supersede the information-limited histogram-based LiDAR representation with a geometrically-augmented pillar format encoding shape descriptors and statistical features, preserving critical 3D geometric details. Second, we propose a novel hierarchical gated mamba fusion (GM-Fusion) architecture that substitutes an expensive transformer with a highly efficient, spatially-aware state-space model (SSM). Our core BEV-SSM leverages directional sequencing and adaptive fusion mechanisms to capture long-range dependencies with linear complexity, while explicitly respecting the unique spatial properties of the driving scene. Extensive experiments on the challenging NAVSIM benchmark demonstrate that GMF-Drive achieves a new state-of-the-art performance, significantly outperforming DiffusionDrive. Comprehensive ablation studies validate the efficacy of each component, demonstrating that task-specific SSMs can surpass a general-purpose transformer in both performance and efficiency for autonomous driving.",
    "source": "arXiv"
  },
  {
    "title": "Blockchain-Enabled Federated Learning",
    "title_es": "Blockchain-Enabled Federated Learning",
    "url": "https://arxiv.org/abs/2508.06406",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06406v2 Announce Type: replace \nAbstract: Blockchain-enabled federated learning (BCFL) addresses fundamental challenges of trust, privacy, and coordination in collaborative AI systems. This chapter provides comprehensive architectural analysis of BCFL systems through a systematic four-dimensional taxonomy examining coordination structures, consensus mechanisms, storage architectures, and trust models. We analyze design patterns from blockchain-verified centralized coordination to fully decentralized peer-to-peer networks, evaluating trade-offs in scalability, security, and performance. Through detailed examination of consensus mechanisms designed for federated learning contexts, including Proof of Quality and Proof of Federated Learning, we demonstrate how computational work can be repurposed from arbitrary cryptographic puzzles to productive machine learning tasks. The chapter addresses critical storage challenges by examining multi-tier architectures that balance blockchain's transaction constraints with neural networks' large parameter requirements while maintaining cryptographic integrity. A technical case study of the TrustMesh framework illustrates practical implementation considerations in BCFL systems through distributed image classification training, demonstrating effective collaborative learning across IoT devices with highly non-IID data distributions while maintaining complete transparency and fault tolerance. Analysis of real-world deployments across healthcare consortiums, financial services, and IoT security applications validates the practical viability of BCFL systems, achieving performance comparable to centralized approaches while providing enhanced security guarantees and enabling new models of trustless collaborative intelligence.",
    "source": "arXiv"
  },
  {
    "title": "StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback",
    "title_es": "StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback",
    "url": "https://arxiv.org/abs/2508.06555",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06555v2 Announce Type: replace \nAbstract: The advancement of intelligent agents has revolutionized problem-solving across diverse domains, yet solutions for personalized fashion styling remain underexplored, which holds immense promise for promoting shopping experiences. In this work, we present StyleTailor, the first collaborative agent framework that seamlessly unifies personalized apparel design, shopping recommendation, virtual try-on, and systematic evaluation into a cohesive workflow. To this end, StyleTailor pioneers an iterative visual refinement paradigm driven by multi-level negative feedback, enabling adaptive and precise user alignment. Specifically, our framework features two core agents, i.e., Designer for personalized garment selection and Consultant for virtual try-on, whose outputs are progressively refined via hierarchical vision-language model feedback spanning individual items, complete outfits, and try-on efficacy. Counterexamples are aggregated into negative prompts, forming a closed-loop mechanism that enhances recommendation quality. To assess the performance, we introduce a comprehensive evaluation suite encompassing style consistency, visual quality, face similarity, and artistic appraisal. Extensive experiments demonstrate StyleTailor's superior performance in delivering personalized designs and recommendations, outperforming strong baselines without negative feedback and establishing a new benchmark for intelligent fashion systems.",
    "source": "arXiv"
  },
  {
    "title": "Algorithmic Delegated Choice: An Annotated Reading List",
    "title_es": "Algorithmic Delegated Choice: An Annotated Reading List",
    "url": "https://arxiv.org/abs/2508.06562",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06562v2 Announce Type: replace \nAbstract: The problem of delegated choice has been of long interest in economics and recently on computer science. We overview a list of papers on delegated choice problem, from classic works to recent papers with algorithmic perspectives.",
    "source": "arXiv"
  },
  {
    "title": "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model",
    "title_es": "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model",
    "url": "https://arxiv.org/abs/2508.06571",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06571v2 Announce Type: replace \nAbstract: Vision-Language-Action (VLA) models have demonstrated potential in autonomous driving. However, two critical challenges hinder their development: (1) Existing VLA architectures are typically based on imitation learning in open-loop setup which tends to capture the recorded behaviors in the dataset, leading to suboptimal and constrained performance, (2) Close-loop training relies heavily on high-fidelity sensor simulation, where domain gaps and computational inefficiencies pose significant barriers. In this paper, we introduce IRL-VLA, a novel close-loop Reinforcement Learning via \\textbf{I}nverse \\textbf{R}einforcement \\textbf{L}earning reward world model with a self-built VLA approach. Our framework proceeds in a three-stage paradigm: In the first stage, we propose a VLA architecture and pretrain the VLA policy via imitation learning. In the second stage, we construct a lightweight reward world model via inverse reinforcement learning to enable efficient close-loop reward computation. To further enhance planning performance, finally, we design specialized reward world model guidence reinforcement learning via PPO(Proximal Policy Optimization) to effectively balance the safety incidents, comfortable driving, and traffic efficiency. Our approach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that our framework will accelerate VLA research in close-loop autonomous driving.",
    "source": "arXiv"
  },
  {
    "title": "LLM Unlearning Without an Expert Curated Dataset",
    "title_es": "LLM Unlearning Without an Expert Curated Dataset",
    "url": "https://arxiv.org/abs/2508.06595",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06595v2 Announce Type: replace \nAbstract: Modern large language models often encode sensitive, harmful, or copyrighted knowledge, raising the need for post-hoc unlearning-the ability to remove specific domains of knowledge from a model without full retraining. A major bottleneck in current unlearning pipelines is constructing effective forget sets-datasets that approximate the target domain and guide the model to forget it. In this work, we introduce a scalable, automated approach to generate high-quality forget sets using language models themselves. Our method synthesizes textbook-style data through a structured prompting pipeline, requiring only a domain name as input. Through experiments on unlearning biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic datasets consistently outperform the baseline synthetic alternatives and are comparable to the expert-curated ones. Additionally, ablation studies reveal that the multi-step generation pipeline significantly boosts data diversity, which in turn improves unlearning utility. Overall, our findings suggest that synthetic datasets offer a promising path toward practical, scalable unlearning for a wide range of emerging domains without the need for manual intervention. We release our code and dataset at https://github.com/xyzhu123/Synthetic_Textbook.",
    "source": "arXiv"
  },
  {
    "title": "Iris RESTful Server and IrisTileSource: An Iris implementation for existing OpenSeaDragon viewers",
    "title_es": "Iris RESTful Server and IrisTileSource: An Iris implementation for existing OpenSeaDragon viewers",
    "url": "https://arxiv.org/abs/2508.06615",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06615v2 Announce Type: replace \nAbstract: The Iris File Extension (IFE) is a low overhead performance-oriented whole slide image (WSI) file format designed to improve the image rendering experience for pathologists and simplify image management for system administrators. However, static hypertext transfer protocol (HTTP) file servers cannot natively stream subregions of high-resolution image files, such as the IFE. The majority of contemporary WSI viewer systems are designed as browser-based web applications and leverage OpenSeaDragon as the tile-based rendering framework. These systems convert WSI files to Deep Zoom Images (DZI) for compatibility with simple static HTTP file servers. In order to address this limitation, we have developed the Iris RESTful Server, a low-overhead HTTP server with a RESTful API that is natively compatible with the DICOMweb WADO-RS API. Written in C++ with Boost Beast HTTP and Asio networking libraries atop the public IFE libraries, the server offers both security and high performance. Testing shows that a single instance can handle over 5000 tile requests per second with a median latency of 21 ms on a private network. We also developed and merged a new OpenSeaDragon TileSource, compatible with the Iris RESTful API, into the next OpenSeaDragon release, enabling simple and immediate drop-in replacement of DZI images within WSI viewer stacks. Designed as a secure cross-origin resource sharing microservice, this architecture includes detailed deployment instructions for new or existing WSI workflows, and a public test subdomain (examples.restful.irisdigitalpathology.org ) is provided as a development tool to accelerate WSI web viewer development.",
    "source": "arXiv"
  },
  {
    "title": "Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record",
    "title_es": "Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record",
    "url": "https://arxiv.org/abs/2508.06627",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06627v2 Announce Type: replace \nAbstract: Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and early detection remains a major clinical challenge due to the absence of specific symptoms and reliable biomarkers. In this work, we propose a new multimodal approach that integrates longitudinal diagnosis code histories and routinely collected laboratory measurements from electronic health records to detect PDAC up to one year prior to clinical diagnosis. Our method combines neural controlled differential equations to model irregular lab time series, pretrained language models and recurrent networks to learn diagnosis code trajectory representations, and cross-attention mechanisms to capture interactions between the two modalities. We develop and evaluate our approach on a real-world dataset of nearly 4,700 patients and achieve significant improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods. Furthermore, our model identifies diagnosis codes and laboratory panels associated with elevated PDAC risk, including both established and new biomarkers. Our code is available at https://github.com/MosbahAouad/EarlyPDAC-MML.",
    "source": "arXiv"
  },
  {
    "title": "Do Biased Models Have Biased Thoughts?",
    "title_es": "Do Biased Models Have Biased Thoughts?",
    "url": "https://arxiv.org/abs/2508.06671",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06671v2 Announce Type: replace \nAbstract: The impressive performance of language models is undeniable. However, the presence of biases based on gender, race, socio-economic status, physical appearance, and sexual orientation makes the deployment of language models challenging. This paper studies the effect of chain-of-thought prompting, a recent approach that studies the steps followed by the model before it responds, on fairness. More specifically, we ask the following question: $\\textit{Do biased models have biased thoughts}$? To answer our question, we conduct experiments on $5$ popular large language models using fairness metrics to quantify $11$ different biases in the model's thoughts and output. Our results show that the bias in the thinking steps is not highly correlated with the output bias (less than $0.6$ correlation with a $p$-value smaller than $0.001$ in most cases). In other words, unlike human beings, the tested models with biased decisions do not always possess biased thoughts.",
    "source": "arXiv"
  },
  {
    "title": "LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning",
    "title_es": "LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning",
    "url": "https://arxiv.org/abs/2508.06799",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06799v2 Announce Type: replace \nAbstract: Digital Twins (DTs) offer powerful tools for managing complex infrastructure systems, but their effectiveness is often limited by challenges in integrating unstructured knowledge. Recent advances in Large Language Models (LLMs) bring new potential to address this gap, with strong abilities in extracting and organizing diverse textual information. We therefore propose LSDTs (LLM-Augmented Semantic Digital Twins), a framework that helps LLMs extract planning knowledge from unstructured documents like environmental regulations and technical guidelines, and organize it into a formal ontology. This ontology forms a semantic layer that powers a digital twin-a virtual model of the physical system-allowing it to simulate realistic, regulation-aware planning scenarios. We evaluate LSDTs through a case study of offshore wind farm planning in Maryland, including its application during Hurricane Sandy. Results demonstrate that LSDTs support interpretable, regulation-aware layout optimization, enable high-fidelity simulation, and enhance adaptability in infrastructure planning. This work shows the potential of combining generative AI with digital twins to support complex, knowledge-driven planning tasks.",
    "source": "arXiv"
  },
  {
    "title": "Technical Report: Full-Stack Fine-Tuning for the Q Programming Language",
    "title_es": "Technical Report: Full-Stack Fine-Tuning for the Q Programming Language",
    "url": "https://arxiv.org/abs/2508.06813",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06813v2 Announce Type: replace \nAbstract: Even though large language models are becoming increasingly capable, it is still unreasonable to expect them to excel at tasks that are under-represented on the Internet. Leveraging LLMs for specialized applications, particularly in niche programming languages and private domains, remains challenging and largely unsolved. In this work, we address this gap by presenting a comprehensive, open-source approach for adapting LLMs to the Q programming language, a popular tool in quantitative finance that is much less present on the Internet compared to Python, C, Java, and other ``mainstream\" languages and is therefore not a strong suit of general-purpose AI models. We introduce a new Leetcode style evaluation dataset for Q, benchmark major frontier models on the dataset, then do pretraining, supervised fine tuning, and reinforcement learning to train a suite of reasoning and non-reasoning models based on the Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our best model achieves a pass@1 accuracy of 59 percent on our Q benchmark, surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent. Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task. In addition to releasing models, code, and data, we provide a detailed blueprint for dataset construction, model pretraining, supervised fine-tuning, and reinforcement learning. Our methodology is broadly applicable, and we discuss how these techniques can be extended to other tasks, including those where evaluation may rely on soft or subjective signals.",
    "source": "arXiv"
  },
  {
    "title": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance",
    "title_es": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance",
    "url": "https://arxiv.org/abs/2508.06944",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06944v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL), a process fraught with catastrophic forgetting and suboptimal trade-offs between imitation and exploration. Recent single-stage methods attempt to unify SFT and RL using heuristics, but lack a principled mechanism for dynamically balancing the two paradigms. In this paper, we reframe this challenge through the theoretical lens of \\textbf{implicit rewards}, viewing SFT and RL not as distinct methods but as complementary reward signals. We introduce \\textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel single-stage algorithm that learns the optimal balance between SFT's implicit, path-level reward and RL's explicit, outcome-based reward. The core of AMFT is a \\textbf{meta-gradient adaptive weight controller} that treats the SFT-RL balance as a learnable parameter, dynamically optimizing it to maximize long-term task performance. This forward-looking approach, regularized by policy entropy for stability, autonomously discovers an effective training curriculum. We conduct a comprehensive evaluation on challenging benchmarks spanning mathematical reasoning, abstract visual reasoning (General Points), and vision-language navigation (V-IRL). AMFT consistently establishes a new state-of-the-art and demonstrats superior generalization on out-of-distribution (OOD) tasks. Ablation studies and training dynamic analysis confirm that the meta-learning controller is crucial for AMFT's stability, sample efficiency, and performance, offering a more principled and effective paradigm for LLM alignment. Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.",
    "source": "arXiv"
  },
  {
    "title": "Large Language Models Do Not Simulate Human Psychology",
    "title_es": "Large Language Models Do Not Simulate Human Psychology",
    "url": "https://arxiv.org/abs/2508.06950",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06950v2 Announce Type: replace \nAbstract: Large Language Models (LLMs),such as ChatGPT, are increasingly used in research, ranging from simple writing assistance to complex data annotation tasks. Recently, some research has suggested that LLMs may even be able to simulate human psychology and can, hence, replace human participants in psychological studies. We caution against this approach. We provide conceptual arguments against the hypothesis that LLMs simulate human psychology. We then present empiric evidence illustrating our arguments by demonstrating that slight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs' and human responses, even for the recent CENTAUR model that was specifically fine-tuned on psychological responses. Additionally, different LLMs show very different responses to novel items, further illustrating their lack of reliability. We conclude that LLMs do not simulate human psychology and recommend that psychological researchers should treat LLMs as useful but fundamentally unreliable tools that need to be validated against human responses for every new application.",
    "source": "arXiv"
  },
  {
    "title": "Your Thoughtful Opponent: Embracing Cognitive Conflict with Peer Agent",
    "title_es": "Your Thoughtful Opponent: Embracing Cognitive Conflict with Peer Agent",
    "url": "https://arxiv.org/abs/2508.06955",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06955v2 Announce Type: replace \nAbstract: As complex societal issues continue to emerge, fostering democratic skills like valuing diverse perspectives and collaborative decision-making is increasingly vital in education. In this paper, we propose a Peer Agent (PA) system designed to simulate a deliberative conversational partner that induces socio-cognitive conflict within dilemma-based game play. Drawing on by the Inner Thoughts framework and grounded in value-sensitive discourse analysis, the PA actively participates in voice-based multi-party deliberation with human players. The system architecture consists of five core modules: Context Interpreter, Agent State Manager, Thought Generator, Thought Evaluator, and Thought Articulator.",
    "source": "arXiv"
  },
  {
    "title": "Adversarial Video Promotion Against Text-to-Video Retrieval",
    "title_es": "Adversarial Video Promotion Against Text-to-Video Retrieval",
    "url": "https://arxiv.org/abs/2508.06964",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.06964v2 Announce Type: replace \nAbstract: Thanks to the development of cross-modal models, text-to-video retrieval (T2VR) is advancing rapidly, but its robustness remains largely unexamined. Existing attacks against T2VR are designed to push videos away from queries, i.e., suppressing the ranks of videos, while the attacks that pull videos towards selected queries, i.e., promoting the ranks of videos, remain largely unexplored. These attacks can be more impactful as attackers may gain more views/clicks for financial benefits and widespread (mis)information. To this end, we pioneer the first attack against T2VR to promote videos adversarially, dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement (MoRe) to capture the finer-grained, intricate interaction between visual and textual modalities to enhance black-box transferability. Comprehensive experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing datasets with over 10k videos, evaluated under 3 scenarios. All experiments are conducted in a multi-target setting to reflect realistic scenarios where attackers seek to promote the video regarding multiple queries simultaneously. We also evaluated our attacks for defences and imperceptibility. Overall, ViPro surpasses other baselines by over $30/10/4\\%$ for white/grey/black-box settings on average. Our work highlights an overlooked vulnerability, provides a qualitative analysis on the upper/lower bound of our attacks, and offers insights into potential counterplays. Code will be publicly available at https://github.com/michaeltian108/ViPro.",
    "source": "arXiv"
  },
  {
    "title": "HiMat: DiT-based Ultra-High Resolution SVBRDF Generation",
    "title_es": "HiMat: DiT-based Ultra-High Resolution SVBRDF Generation",
    "url": "https://arxiv.org/abs/2508.07011",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07011v2 Announce Type: replace \nAbstract: Creating highly detailed SVBRDFs is essential for 3D content creation. The rise of high-resolution text-to-image generative models, based on diffusion transformers (DiT), suggests an opportunity to finetune them for this task. However, retargeting the models to produce multiple aligned SVBRDF maps instead of just RGB images, while achieving high efficiency and ensuring consistency across different maps, remains a challenge. In this paper, we introduce HiMat: a memory- and computation-efficient diffusion-based framework capable of generating native 4K-resolution SVBRDFs. A key challenge we address is maintaining consistency across different maps in a lightweight manner, without relying on training new VAEs or significantly altering the DiT backbone (which would damage its prior capabilities). To tackle this, we introduce the CrossStitch module, a lightweight convolutional module that captures inter-map dependencies through localized operations. Its weights are initialized such that the DiT backbone operation is unchanged before finetuning starts. HiMat enables generation with strong structural coherence and high-frequency details. Results with a large set of text prompts demonstrate the effectiveness of our approach for 4K SVBRDF generation. Further experiments suggest generalization to tasks such as intrinsic decomposition.",
    "source": "arXiv"
  },
  {
    "title": "ScamDetect: Towards a Robust, Agnostic Framework to Uncover Threats in Smart Contracts",
    "title_es": "ScamDetect: Towards a Robust, Agnostic Framework to Uncover Threats in Smart Contracts",
    "url": "https://arxiv.org/abs/2508.07094",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07094v2 Announce Type: replace \nAbstract: Smart contracts have transformed decentralized finance by enabling programmable, trustless transactions. However, their widespread adoption and growing financial significance have attracted persistent and sophisticated threats, such as phishing campaigns and contract-level exploits. Traditional transaction-based threat detection methods often expose sensitive user data and interactions, raising privacy and security concerns. In response, static bytecode analysis has emerged as a proactive mitigation strategy, identifying malicious contracts before they execute harmful actions. Building on this approach, we introduced PhishingHook, the first machine-learning-based framework for detecting phishing activities in smart contracts via static bytecode and opcode analysis, achieving approximately 90% detection accuracy. Nevertheless, two pressing challenges remain: (1) the increasing use of sophisticated bytecode obfuscation techniques designed to evade static analysis, and (2) the heterogeneity of blockchain environments requiring platform-agnostic solutions. This paper presents a vision for ScamDetect (Smart Contract Agnostic Malware Detector), a robust, modular, and platform-agnostic framework for smart contract malware detection. Over the next 2.5 years, ScamDetect will evolve in two stages: first, by tackling obfuscated Ethereum Virtual Machine (EVM) bytecode through graph neural network (GNN) analysis of control flow graphs (CFGs), leveraging GNNs' ability to capture complex structural patterns beyond opcode sequences; and second, by generalizing detection capabilities to emerging runtimes such as WASM. ScamDetect aims to enable proactive, scalable security for the future of decentralized ecosystems.",
    "source": "arXiv"
  },
  {
    "title": "Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention",
    "title_es": "Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention",
    "url": "https://arxiv.org/abs/2508.07107",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07107v2 Announce Type: replace \nAbstract: Accurate prediction of student performance is essential for enabling timely academic interventions. However, most machine learning models used in educational settings are static and lack the ability to adapt when new data such as post-intervention outcomes become available. To address this limitation, we propose a Feedback-Driven Decision Support System (DSS) with a closed-loop architecture that enables continuous model refinement. The system employs a LightGBM-based regressor with incremental retraining, allowing educators to input updated student performance data, which automatically triggers model updates. This adaptive mechanism enhances prediction accuracy by learning from real-world academic progress over time.\n  The platform features a Flask-based web interface to support real-time interaction and integrates SHAP (SHapley Additive exPlanations) for model interpretability, ensuring transparency and trustworthiness in predictions. Experimental results demonstrate a 10.7% reduction in RMSE after retraining, with consistent upward adjustments in predicted scores for students who received interventions. By transforming static predictive models into self-improving systems, our approach advances educational analytics toward human-centered, data-driven, and responsive artificial intelligence. The framework is designed for seamless integration into Learning Management Systems (LMS) and institutional dashboards, facilitating practical deployment in real educational environments.",
    "source": "arXiv"
  },
  {
    "title": "PureSample: Neural Materials Learned by Sampling Microgeometry",
    "title_es": "PureSample: Neural Materials Learned by Sampling Microgeometry",
    "url": "https://arxiv.org/abs/2508.07240",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07240v2 Announce Type: replace \nAbstract: Traditional physically-based material models rely on analytically derived bidirectional reflectance distribution functions (BRDFs), typically by considering statistics of micro-primitives such as facets, flakes, or spheres, sometimes combined with multi-bounce interactions such as layering and multiple scattering. These derivations are often complex and model-specific, and typically consider a statistical aggregate of a large surface area, ignoring spatial variation. Once an analytic BRDF's evaluation is defined, one still needs to design an importance sampling method for it, and a way to evaluate the pdf of that sampling distribution, requiring further model-specific derivations. We present PureSample: a novel neural BRDF representation that allows learning a material's behavior purely by sampling forward random walks on the microgeometry, which is usually straightforward to implement. Our representation allows for efficient importance sampling, pdf evaluation, and BRDF evaluation, for homogeneous as well as spatially varying materials. We achieve this by two learnable components: first, the sampling distribution is modeled using a flow matching neural network, which allows both importance sampling and pdf evaluation; second, we introduce a view-dependent albedo term, captured by a lightweight neural network, which allows for converting a scalar pdf value to a colored BRDF value for any pair of view and light directions. We demonstrate PureSample on challenging materials, including multi-layered materials, multiple-scattering microfacet materials, and various other microstructures.",
    "source": "arXiv"
  },
  {
    "title": "Understanding Dynamic Scenes in Ego Centric 4D Point Clouds",
    "title_es": "Understanding Dynamic Scenes in Ego Centric 4D Point Clouds",
    "url": "https://arxiv.org/abs/2508.07251",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07251v2 Announce Type: replace \nAbstract: Understanding dynamic 4D scenes from an egocentric perspective-modeling changes in 3D spatial structure over time-is crucial for human-machine interaction, autonomous navigation, and embodied intelligence. While existing egocentric datasets contain dynamic scenes, they lack unified 4D annotations and task-driven evaluation protocols for fine-grained spatio-temporal reasoning, especially on motion of objects and human, together with their interactions. To address this gap, we introduce EgoDynamic4D, a novel QA benchmark on highly dynamic scenes, comprising RGB-D video, camera poses, globally unique instance masks, and 4D bounding boxes. We construct 927K QA pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable, step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering agent motion, human-object interaction, trajectory prediction, relation understanding, and temporal-causal reasoning, with fine-grained, multidimensional metrics. To tackle these tasks, we propose an end-to-end spatio-temporal reasoning framework that unifies dynamic and static scene information, using instance-aware feature encoding, time and camera encoding, and spatially adaptive down-sampling to compress large 4D scenes into token sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method consistently outperforms baselines, validating the effectiveness of multimodal temporal modeling for egocentric dynamic scene understanding.",
    "source": "arXiv"
  },
  {
    "title": "Grounding Multilingual Multimodal LLMs With Cultural Knowledge",
    "title_es": "Grounding Multilingual Multimodal LLMs With Cultural Knowledge",
    "url": "https://arxiv.org/abs/2508.07414",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07414v2 Announce Type: replace \nAbstract: Multimodal Large Language Models excel in high-resource settings, but often misinterpret long-tail cultural entities and underperform in low-resource languages. To address this gap, we propose a data-centric approach that directly grounds MLLMs in cultural knowledge. Leveraging a large scale knowledge graph from Wikidata, we collect images that represent culturally significant entities, and generate synthetic multilingual visual question answering data. The resulting dataset, CulturalGround, comprises 22 million high-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages. We train an open-source MLLM CulturalPangea on CulturalGround, interleaving standard multilingual instruction-tuning data to preserve general abilities. CulturalPangea achieves state-of-the-art performance among open models on various culture-focused multilingual multimodal benchmarks, outperforming prior models by an average of 5.0 without degrading results on mainstream vision-language tasks. Our findings show that our targeted, culturally grounded approach could substantially narrow the cultural gap in MLLMs and offer a practical path towards globally inclusive multimodal systems.",
    "source": "arXiv"
  },
  {
    "title": "An Empirical Inquiry into Surveillance Capitalism: Web Tracking",
    "title_es": "An Empirical Inquiry into Surveillance Capitalism: Web Tracking",
    "url": "https://arxiv.org/abs/2508.07454",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07454v2 Announce Type: replace \nAbstract: The modern web is increasingly characterized by the pervasiveness of Surveillance Capitalism. This investigation employs an empirical approach to examine this phenomenon through the web tracking practices of major tech companies -- specifically Google, Apple, Facebook, Amazon, and Microsoft (GAFAM) -- and their relation to financial performance indicators. Using longitudinal data from WhoTracks.Me spanning from 2017 to 2025 and publicly accessible SEC filings, this paper analyzes patterns and trends in web tracking data to establish empirical evidence of Surveillance Capitalism's extraction mechanisms. Our findings reveal Google's omnipresent position on the web, a three-tier stratification among GAFAM companies in the surveillance space, and evidence suggesting an evolution of tracking techniques to evade detection. The investigation further discusses the social and environmental costs of web tracking and how alternative technologies, such as the Gemini protocol, offer pathways to challenge the extractive logic of this new economic order. By closely examining surveillance activities, this research contributes to an ongoing effort to better understand the current state and future trajectory of Surveillance Capitalism.",
    "source": "arXiv"
  },
  {
    "title": "Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring",
    "title_es": "Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring",
    "url": "https://arxiv.org/abs/2508.07552",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07552v2 Announce Type: replace \nAbstract: End-to-end models are emerging as the mainstream in autonomous driving perception and planning. However, the lack of explicit supervision signals for intermediate functional modules leads to opaque operational mechanisms and limited interpretability, making it challenging for traditional methods to independently evaluate and train these modules. Pioneering in the issue, this study builds upon the feature map-truth representation similarity-based evaluation framework and proposes an independent evaluation method based on Feature Map Convergence Score (FMCS). A Dual-Granularity Dynamic Weighted Scoring System (DG-DWSS) is constructed, formulating a unified quantitative metric - Feature Map Quality Score - to enable comprehensive evaluation of the quality of feature maps generated by functional modules. A CLIP-based Feature Map Quality Evaluation Network (CLIP-FMQE-Net) is further developed, combining feature-truth encoders and quality score prediction heads to enable real-time quality analysis of feature maps generated by functional modules. Experimental results on the NuScenes dataset demonstrate that integrating our evaluation module into the training improves 3D object detection performance, achieving a 3.89 percent gain in NDS. These results verify the effectiveness of our method in enhancing feature representation quality and overall model performance.",
    "source": "arXiv"
  },
  {
    "title": "From Platform Migration to Cultural Integration: the Ingress and Diffusion of #wlw from TikTok to RedNote in Queer Women Communities",
    "title_es": "From Platform Migration to Cultural Integration: the Ingress and Diffusion of #wlw from TikTok to RedNote in Queer Women Communities",
    "url": "https://arxiv.org/abs/2508.07579",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07579v2 Announce Type: replace \nAbstract: Hashtags serve as identity markers and connection tools in online queer communities. Recently, the Western-origin #wlw (women-loving-women) hashtag has risen in the Chinese lesbian community on RedNote, coinciding with user migration triggered by the temporary US TikTok ban. This event provides a unique lens to study cross-cultural hashtag ingress and diffusion through the populations' responsive behaviors in cyber-migration. In this paper, we conducted a two-phase content analysis of 418 #wlw posts from January and April, examining different usage patterns during the hashtag's ingress and diffusion. Results indicate that the successful introduction of #wlw was facilitated by TikTok immigrants' bold importation, both populations' mutual interpretation, and RedNote natives' discussions. In current manifestation of diffusion, #wlw becomes a RedNote-recognized queer hashtag for sharing queer life, and semantically expands to support feminism discourse. Our findings provide empirical insights for enhancing the marginalized communities' cross-cultural communication.",
    "source": "arXiv"
  },
  {
    "title": "Nonlinear Systems in Wireless Power Transfer Applications",
    "title_es": "Nonlinear Systems in Wireless Power Transfer Applications",
    "url": "https://arxiv.org/abs/2508.07627",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07627v2 Announce Type: replace \nAbstract: As a novel pattern of energization, the wireless power transfer (WPT) offers a brand-new way to the energy acquisition for electric-driven devices, thus alleviating the over-dependence on the battery. This report presents three types of WPT systems that use nonlinear control methods, in order to acquire an in-depth understanding of the course of Nonlinear Systems.",
    "source": "arXiv"
  },
  {
    "title": "Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization",
    "title_es": "Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization",
    "url": "https://arxiv.org/abs/2508.07629",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07629v2 Announce Type: replace \nAbstract: We present Klear-Reasoner, a model with long reasoning capabilities that demonstrates careful deliberation during problem solving, achieving outstanding performance across multiple benchmarks. Although there are already many excellent works related to inference models in the current community, there are still many problems with reproducing high-performance inference models due to incomplete disclosure of training details. This report provides an in-depth analysis of the reasoning model, covering the entire post-training workflow from data preparation and long Chain-of-Thought supervised fine-tuning (long CoT SFT) to reinforcement learning (RL), along with detailed ablation studies for each experimental component. For SFT data, our experiments show that a small number of high-quality data sources are more effective than a large number of diverse data sources, and that difficult samples can achieve better results without accuracy filtering. In addition, we investigate two key issues with current clipping mechanisms in RL: Clipping suppresses critical exploration signals and ignores suboptimal trajectories. To address these challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO) that gently backpropagates gradients from clipped tokens. GPPO not only enhances the model's exploration capacity but also improves its efficiency in learning from negative samples. Klear-Reasoner exhibits exceptional reasoning abilities in mathematics and programming, scoring 90.5% on AIME 2024, 83.2% on AIME 2025, 66.0% on LiveCodeBench V5 and 58.1% on LiveCodeBench V6.",
    "source": "arXiv"
  },
  {
    "title": "Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation",
    "title_es": "Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation",
    "url": "https://arxiv.org/abs/2508.07675",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07675v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are revolutionizing how users interact with information systems, yet their high inference cost poses serious scalability and sustainability challenges. Caching inference responses, allowing them to be retrieved without another forward pass through the LLM, has emerged as one possible solution. Traditional exact-match caching, however, overlooks the semantic similarity between queries, leading to unnecessary recomputation. Semantic caching addresses this by retrieving responses based on semantic similarity, but introduces a fundamentally different cache eviction problem: one must account for mismatch costs between incoming queries and cached responses. Moreover, key system parameters, such as query arrival probabilities and serving costs, are often unknown and must be learned over time. Existing semantic caching methods are largely ad-hoc, lacking theoretical foundations and unable to adapt to real-world uncertainty. In this paper, we present a principled, learning-based framework for semantic cache eviction under unknown query and cost distributions. We formulate both offline optimization and online learning variants of the problem, and develop provably efficient algorithms with state-of-the-art guarantees. We also evaluate our framework on a synthetic dataset, showing that our proposed algorithms perform matching or superior performance compared with baselines.",
    "source": "arXiv"
  },
  {
    "title": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation",
    "title_es": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation",
    "url": "https://arxiv.org/abs/2508.07745",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07745v2 Announce Type: replace \nAbstract: Insider threats, which can lead to severe losses, remain a major security concern. While machine learning-based insider threat detection (ITD) methods have shown promising results, their progress is hindered by the scarcity of high-quality data. Enterprise data is sensitive and rarely accessible, while publicly available datasets, when limited in scale due to cost, lack sufficient real-world coverage; and when purely synthetic, they fail to capture rich semantics and realistic user behavior. To address this, we propose Chimera, the first large language model (LLM)-based multi-agent framework that automatically simulates both benign and malicious insider activities and collects diverse logs across diverse enterprise environments. Chimera models each employee with agents that have role-specific behavior and integrates modules for group meetings, pairwise interactions, and autonomous scheduling, capturing realistic organizational dynamics. It incorporates 15 types of insider attacks (e.g., IP theft, system sabotage) and has been deployed to simulate activities in three sensitive domains: technology company, finance corporation, and medical institution, producing a new dataset, ChimeraLog. We assess ChimeraLog via human studies and quantitative analysis, confirming its diversity, realism, and presence of explainable threat patterns. Evaluations of existing ITD methods show an average F1-score of 0.83, which is significantly lower than 0.99 on the CERT dataset, demonstrating ChimeraLog's higher difficulty and utility for advancing ITD research.",
    "source": "arXiv"
  },
  {
    "title": "Nearly Optimal Bounds for Stochastic Online Sorting",
    "title_es": "Nearly Optimal Bounds for Stochastic Online Sorting",
    "url": "https://arxiv.org/abs/2508.07823",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07823v2 Announce Type: replace \nAbstract: In the online sorting problem, we have an array $A$ of $n$ cells, and receive a stream of $n$ items $x_1,\\dots,x_n\\in [0,1]$. When an item arrives, we need to immediately and irrevocably place it into an empty cell. The goal is to minimize the sum of absolute differences between adjacent items, which is called the \\emph{cost} of the algorithm. It has been shown by Aamand, Abrahamsen, Beretta, and Kleist (SODA 2023) that when the stream $x_1,\\dots,x_n$ is generated adversarially, the optimal cost bound for any deterministic algorithm is $\\Theta(\\sqrt{n})$.\n  In this paper, we study the stochastic version of online sorting, where the input items $x_1,\\dots,x_n$ are sampled uniformly at random. Despite the intuition that the stochastic version should yield much better cost bounds, the previous best algorithm for stochastic online sorting by Abrahamsen, Bercea, Beretta, Klausen and Kozma (ESA 2024) only achieves $\\tilde{O}(n^{1/4})$ cost, which seems far from optimal. We show that stochastic online sorting indeed allows for much more efficient algorithms, by presenting an algorithm that achieves expected cost $\\log n\\cdot 2^{O(\\log^* n)}$. We also prove a cost lower bound of $\\Omega(\\log n)$, thus show that our algorithm is nearly optimal.",
    "source": "arXiv"
  },
  {
    "title": "Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation",
    "title_es": "Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation",
    "url": "https://arxiv.org/abs/2508.07901",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07901v2 Announce Type: replace \nAbstract: Generating high-fidelity human videos that match user-specified identities is important yet challenging in the field of generative AI. Existing methods often rely on an excessive number of training parameters and lack compatibility with other AIGC tools. In this paper, we propose Stand-In, a lightweight and plug-and-play framework for identity preservation in video generation. Specifically, we introduce a conditional image branch into the pre-trained video generation model. Identity control is achieved through restricted self-attentions with conditional position mapping, and can be learned quickly with only 2000 pairs. Despite incorporating and training just $\\sim$1% additional parameters, our framework achieves excellent results in video quality and identity preservation, outperforming other full-parameter training methods. Moreover, our framework can be seamlessly integrated for other tasks, such as subject-driven video generation, pose-referenced video generation, stylization, and face swapping.",
    "source": "arXiv"
  },
  {
    "title": "Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction",
    "title_es": "Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction",
    "url": "https://arxiv.org/abs/2508.07908",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07908v2 Announce Type: replace \nAbstract: Reconstructing dense geometry for dynamic scenes from a monocular video is a critical yet challenging task. Recent memory-based methods enable efficient online reconstruction, but they fundamentally suffer from a Memory Demand Dilemma: The memory representation faces an inherent conflict between the long-term stability required for static structures and the rapid, high-fidelity detail retention needed for dynamic motion. This conflict forces existing methods into a compromise, leading to either geometric drift in static structures or blurred, inaccurate reconstructions of dynamic objects. To address this dilemma, we propose Mem4D, a novel framework that decouples the modeling of static geometry and dynamic motion. Guided by this insight, we design a dual-memory architecture: 1) The Transient Dynamics Memory (TDM) focuses on capturing high-frequency motion details from recent frames, enabling accurate and fine-grained modeling of dynamic content; 2) The Persistent Structure Memory (PSM) compresses and preserves long-term spatial information, ensuring global consistency and drift-free reconstruction for static elements. By alternating queries to these specialized memories, Mem4D simultaneously maintains static geometry with global consistency and reconstructs dynamic elements with high fidelity. Experiments on challenging benchmarks demonstrate that our method achieves state-of-the-art or competitive performance while maintaining high efficiency. Codes will be publicly available.",
    "source": "arXiv"
  },
  {
    "title": "Adaptive Multiple Access and Service Placement for Generative Diffusion Models",
    "title_es": "Adaptive Multiple Access and Service Placement for Generative Diffusion Models",
    "url": "https://arxiv.org/abs/2508.07978",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07978v2 Announce Type: replace \nAbstract: Generative Diffusion Models (GDMs) have emerged as key components of Generative Artificial Intelligence (GenAI), offering unparalleled expressiveness and controllability for complex data generation tasks. However, their deployment in real-time and mobile environments remains challenging due to the iterative and resource-intensive nature of the inference process. Addressing these challenges, this paper introduces a unified optimization framework that jointly tackles service placement and multiple access control for GDMs in mobile edge networks. We propose LEARN-GDM, a Deep Reinforcement Learning-based algorithm that dynamically partitions denoising blocks across heterogeneous edge nodes, while accounting for latent transmission costs and enabling adaptive reduction of inference steps. Our approach integrates a greedy multiple access scheme with a Double and Dueling Deep Q-Learning (D3QL)-based service placement, allowing for scalable, adaptable, and resource-efficient operation under stringent quality of service requirements. Simulations demonstrate the superior performance of the proposed framework in terms of scalability and latency resilience compared to conventional monolithic and fixed chain-length placement strategies. This work advances the state of the art in edge-enabled GenAI by offering an adaptable solution for GDM services orchestration, paving the way for future extensions toward semantic networking and co-inference across distributed environments.",
    "source": "arXiv"
  },
  {
    "title": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation",
    "title_es": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation",
    "url": "https://arxiv.org/abs/2508.07981",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07981v2 Announce Type: replace \nAbstract: Visual effects (VFX) are essential visual enhancements fundamental to modern cinematic production. Although video generation models offer cost-efficient solutions for VFX production, current methods are constrained by per-effect LoRA training, which limits generation to single effects. This fundamental limitation impedes applications that require spatially controllable composite effects, i.e., the concurrent generation of multiple effects at designated locations. However, integrating diverse effects into a unified framework faces major challenges: interference from effect variations and spatial uncontrollability during multi-VFX joint training. To tackle these challenges, we propose Omni-Effects, a first unified framework capable of generating prompt-guided effects and spatially controllable composite effects. The core of our framework comprises two key innovations: (1) LoRA-based Mixture of Experts (LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects within a unified model while effectively mitigating cross-task interference. (2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the text token, enabling precise spatial control. Furthermore, we introduce an Independent-Information Flow (IIF) module integrated within the SAP, isolating the control signals corresponding to individual effects to prevent any unwanted blending. To facilitate this research, we construct a comprehensive VFX dataset Omni-VFX via a novel data collection pipeline combining image editing and First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX evaluation framework for validating model performance. Extensive experiments demonstrate that Omni-Effects achieves precise spatial control and diverse effect generation, enabling users to specify both the category and location of desired effects.",
    "source": "arXiv"
  },
  {
    "title": "DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval",
    "title_es": "DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval",
    "url": "https://arxiv.org/abs/2508.07995",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07995v2 Announce Type: replace \nAbstract: Retrieval-augmented generation has achieved strong performance on knowledge-intensive tasks where query-document relevance can be identified through direct lexical or semantic matches. However, many real-world queries involve abstract reasoning, analogical thinking, or multi-step inference, which existing retrievers often struggle to capture. To address this challenge, we present \\textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive information retrieval. DIVER consists of four components: document processing to improve input quality, LLM-driven query expansion via iterative document interaction, a reasoning-enhanced retriever fine-tuned on synthetic multi-domain data with hard negatives, and a pointwise reranker that combines LLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark, DIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original queries, consistently outperforming competitive reasoning-aware models. These results demonstrate the effectiveness of reasoning-aware retrieval strategies in complex real-world tasks. Our code and retrieval model will be released soon.",
    "source": "arXiv"
  },
  {
    "title": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths",
    "title_es": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths",
    "url": "https://arxiv.org/abs/2508.08001",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08001v2 Announce Type: replace \nAbstract: \"Fedspeak\", the stylized and often nuanced language used by the U.S. Federal Reserve, encodes implicit policy signals and strategic stances. The Federal Open Market Committee strategically employs Fedspeak as a communication tool to shape market expectations and influence both domestic and global economic conditions. As such, automatically parsing and interpreting Fedspeak presents a high-impact challenge, with significant implications for financial forecasting, algorithmic trading, and data-driven policy analysis. In this paper, we propose an LLM-based, uncertainty-aware framework for deciphering Fedspeak and classifying its underlying monetary policy stance. Technically, to enrich the semantic and contextual representation of Fedspeak texts, we incorporate domain-specific reasoning grounded in the monetary policy transmission mechanism. We further introduce a dynamic uncertainty decoding module to assess the confidence of model predictions, thereby enhancing both classification accuracy and model reliability. Experimental results demonstrate that our framework achieves state-of-the-art performance on the policy stance analysis task. Moreover, statistical analysis reveals a significant positive correlation between perceptual uncertainty and model error rates, validating the effectiveness of perceptual uncertainty as a diagnostic signal.",
    "source": "arXiv"
  },
  {
    "title": "Fitting Description Logic Ontologies to ABox and Query Examples",
    "title_es": "Fitting Description Logic Ontologies to ABox and Query Examples",
    "url": "https://arxiv.org/abs/2508.08007",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08007v2 Announce Type: replace \nAbstract: We study a fitting problem inspired by ontology-mediated querying: given a collection of positive and negative examples of the form $(\\mathcal{A},q)$ with $\\mathcal{A}$ an ABox and $q$ a Boolean query, we seek an ontology $\\mathcal{O}$ that satisfies $\\mathcal{A} \\cup \\mathcal{O} \\vDash q$ for all positive examples and $\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$ for all negative examples. We consider the description logics $\\mathcal{ALC}$ and $\\mathcal{ALCI}$ as ontology languages and a range of query languages that includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof (UCQs). For all of the resulting fitting problems, we provide effective characterizations and determine the computational complexity of deciding whether a fitting ontology exists. This problem turns out to be ${\\scriptsize CO}NP$ for AQs and full CQs and $2E{\\scriptsize XP}T{\\scriptsize IME}$-complete for CQs and UCQs. These results hold for both $\\mathcal{ALC}$ and $\\mathcal{ALCI}$.",
    "source": "arXiv"
  },
  {
    "title": "Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning",
    "title_es": "Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.08039",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08039v2 Announce Type: replace \nAbstract: Recent advancements in large language models, multimodal large language models, and large audio language models (LALMs) have significantly improved their reasoning capabilities through reinforcement learning with rule-based rewards. However, the explicit reasoning process has yet to show significant benefits for audio question answering, and effectively leveraging deep reasoning remains an open challenge, with LALMs still falling short of human-level auditory-language reasoning. To address these limitations, we propose Audio-Thinker, a reinforcement learning framework designed to enhance the reasoning capabilities of LALMs, with a focus on improving adaptability, consistency, and effectiveness. Our approach introduces an adaptive think accuracy reward, enabling the model to adjust its reasoning strategies based on task complexity dynamically. Furthermore, we incorporate an external reward model to evaluate the overall consistency and quality of the reasoning process, complemented by think-based rewards that help the model distinguish between valid and flawed reasoning paths during training. Experimental results demonstrate that our Audio-Thinker model outperforms existing reasoning-oriented LALMs across various benchmark tasks, exhibiting superior reasoning and generalization capabilities.",
    "source": "arXiv"
  },
  {
    "title": "Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control",
    "title_es": "Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control",
    "url": "https://arxiv.org/abs/2508.08134",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08134v2 Announce Type: replace \nAbstract: While recent flow-based image editing models demonstrate general-purpose capabilities across diverse tasks, they often struggle to specialize in challenging scenarios -- particularly those involving large-scale shape transformations. When performing such structural edits, these methods either fail to achieve the intended shape change or inadvertently alter non-target regions, resulting in degraded background quality. We propose Follow-Your-Shape, a training-free and mask-free framework that supports precise and controllable editing of object shapes while strictly preserving non-target content. Motivated by the divergence between inversion and editing trajectories, we compute a Trajectory Divergence Map (TDM) by comparing token-wise velocity differences between the inversion and denoising paths. The TDM enables precise localization of editable regions and guides a Scheduled KV Injection mechanism that ensures stable and faithful editing. To facilitate a rigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120 new images and enriched prompt pairs specifically curated for shape-aware editing. Experiments demonstrate that our method achieves superior editability and visual fidelity, particularly in tasks requiring large-scale shape replacement.",
    "source": "arXiv"
  },
  {
    "title": "REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation",
    "title_es": "REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation",
    "url": "https://arxiv.org/abs/2508.08149",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08149v2 Announce Type: replace \nAbstract: Reinforcement learning (RL) is emerging as a powerful paradigm for enabling large language models (LLMs) to perform complex reasoning tasks. Recent advances indicate that integrating RL with retrieval-augmented generation (RAG) allows LLMs to dynamically incorporate external knowledge, leading to more informed and robust decision making. However, we identify a critical challenge during policy-driven trajectory sampling: LLMs are frequently trapped in unproductive reasoning paths, which we refer to as \"dead ends\", committing to overconfident yet incorrect conclusions. This severely hampers exploration and undermines effective policy optimization. To address this challenge, we propose REX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation), a novel framework that explores alternative reasoning paths while maintaining rigorous policy learning through principled distributional corrections. Our approach introduces two key innovations: (1) Mixed Sampling Strategy, which combines a novel probe sampling method with exploratory prompts to escape dead ends; and (2) Policy Correction Mechanism, which employs importance sampling to correct distribution shifts induced by mixed sampling, thereby mitigating gradient estimation bias. We evaluate it on seven question-answering benchmarks, and the experimental results show that REX-RAG achieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B over strong baselines, demonstrating competitive results across multiple datasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.",
    "source": "arXiv"
  },
  {
    "title": "3D Human Mesh Estimation from Single View RGBD",
    "title_es": "3D Human Mesh Estimation from Single View RGBD",
    "url": "https://arxiv.org/abs/2508.08178",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08178v2 Announce Type: replace \nAbstract: Despite significant progress in 3D human mesh estimation from RGB images; RGBD cameras, offering additional depth data, remain underutilized. In this paper, we present a method for accurate 3D human mesh estimation from a single RGBD view, leveraging the affordability and widespread adoption of RGBD cameras for real-world applications. A fully supervised approach for this problem, requires a dataset with RGBD image and 3D mesh label pairs. However, collecting such a dataset is costly and challenging, hence, existing datasets are small, and limited in pose and shape diversity. To overcome this data scarcity, we leverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D meshes from the body models found in MoCap datasets, and create partial, single-view versions of them by projection to a virtual camera. This simulates the depth data provided by an RGBD camera from a single viewpoint. Then, we train a masked autoencoder to complete the partial, single-view mesh. During inference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'', matches the depth values coming from the sensor to vertices of a template human mesh, which creates a partial, single-view mesh. We effectively recover parts of the 3D human body mesh model that are not visible, resulting in a full body mesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL and CAPE datasets, respectively; outperforming existing methods that use full-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE dataset, outperforming a recently published RGB based method by 18.4 mm, highlighting the usefulness of depth data. Code will be released.",
    "source": "arXiv"
  },
  {
    "title": "BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion",
    "title_es": "BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion",
    "url": "https://arxiv.org/abs/2508.08241",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08241v2 Announce Type: replace \nAbstract: Learning skills from human motions offers a promising path toward generalizable policies for whole-body humanoid control, yet two key cornerstones are missing: (1) a high-quality motion tracking framework that faithfully transforms large-scale kinematic references into robust and extremely dynamic motions on real hardware, and (2) a distillation approach that can effectively learn these motion primitives and compose them to solve downstream tasks. We address these gaps with BeyondMimic, a real-world framework to learn from human motions for versatile and naturalistic humanoid control via guided diffusion. Our framework provides a motion tracking pipeline capable of challenging skills such as jumping spins, sprinting, and cartwheels with state-of-the-art motion quality. Moving beyond mimicking existing motions and synthesize novel ones, we further introduce a unified diffusion policy that enables zero-shot task-specific control at test time using simple cost functions. Deployed on hardware, BeyondMimic performs diverse tasks at test time, including waypoint navigation, joystick teleoperation, and obstacle avoidance, bridging sim-to-real motion tracking and flexible synthesis of human motion primitives for whole-body control. https://beyondmimic.github.io/.",
    "source": "arXiv"
  },
  {
    "title": "Jinx: Unlimited LLMs for Probing Alignment Failures",
    "title_es": "Jinx: Unlimited LLMs for Probing Alignment Failures",
    "url": "https://arxiv.org/abs/2508.08243",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08243v2 Announce Type: replace \nAbstract: Unlimited, or so-called helpful-only language models are trained without safety alignment constraints and never refuse user queries. They are widely used by leading AI companies as internal tools for red teaming and alignment evaluation. For example, if a safety-aligned model produces harmful outputs similar to an unlimited model, this indicates alignment failures that require further attention. Despite their essential role in assessing alignment, such models are not available to the research community.\n  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx responds to all queries without refusals or safety filtering, while preserving the base model's capabilities in reasoning and instruction following. It provides researchers with an accessible tool for probing alignment failures, evaluating safety boundaries, and systematically studying failure modes in language model safety.",
    "source": "arXiv"
  },
  {
    "title": "Cut2Next: Generating Next Shot via In-Context Tuning",
    "title_es": "Cut2Next: Generating Next Shot via In-Context Tuning",
    "url": "https://arxiv.org/abs/2508.08244",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.08244v2 Announce Type: replace \nAbstract: Effective multi-shot generation demands purposeful, film-like transitions and strict cinematic continuity. Current methods, however, often prioritize basic visual consistency, neglecting crucial editing patterns (e.g., shot/reverse shot, cutaways) that drive narrative flow for compelling storytelling. This yields outputs that may be visually coherent but lack narrative sophistication and true cinematic integrity. To bridge this, we introduce Next Shot Generation (NSG): synthesizing a subsequent, high-quality shot that critically conforms to professional editing patterns while upholding rigorous cinematic continuity. Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This strategy uses Relational Prompts to define overall context and inter-shot editing styles. Individual Prompts then specify per-shot content and cinematographic attributes. Together, these guide Cut2Next to generate cinematically appropriate next shots. Architectural innovations, Context-Aware Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further integrate these diverse signals without introducing new parameters. We construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with hierarchical prompts, and introduce CutBench for evaluation. Experiments show Cut2Next excels in visual consistency and text fidelity. Crucially, user studies reveal a strong preference for Cut2Next, particularly for its adherence to intended editing patterns and overall cinematic continuity, validating its ability to generate high-quality, narratively expressive, and cinematically coherent subsequent shots.",
    "source": "arXiv"
  },
  {
    "title": "Numerical Analysis of the Causal Action Principle in Low Dimensions",
    "title_es": "Numerical Analysis of the Causal Action Principle in Low Dimensions",
    "url": "https://arxiv.org/abs/2201.06382",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2201.06382v2 Announce Type: replace-cross \nAbstract: The numerical analysis of causal fermion systems is advanced by employing differentiable programming methods. The causal action principle for weighted counting measures is introduced for general values of the integer parameters $f$ (the particle number), $n$ (the spin dimension) and $m$ (the number of spacetime points). In the case $n=1$, the causal relations are clarified geometrically in terms of causal cones. Discrete Dirac spheres are introduced as candidates for minimizers for large $m$ in the cases $n=1, f=2$ and $n=2, f=4$. We provide a thorough numerical analysis of the causal action principle for weighted counting measures for large $m$ in the cases $n=1,2$ and $f=2,3,4$. Our numerical findings corroborate that all minimizers for large $m$ are good approximations of the discrete Dirac spheres. In the example $n=1, f=3$ it is explained how numerical minimizers can be visualized by projected spacetime plots. Methods and prospects are discussed to numerically investigate settings in which hitherto no analytic candidates for minimizers are known.",
    "source": "arXiv"
  },
  {
    "title": "Artificial Intelligence Software Structured to Simulate Human Working Memory, Mental Imagery, and Mental Continuity",
    "title_es": "Artificial Intelligence Software Structured to Simulate Human Working Memory, Mental Imagery, and Mental Continuity",
    "url": "https://arxiv.org/abs/2204.05138",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2204.05138v2 Announce Type: replace-cross \nAbstract: This article presents an artificial intelligence (AI) architecture intended to simulate the iterative updating of the human working memory system. It features several interconnected neural networks designed to emulate the specialized modules of the cerebral cortex. These are structured hierarchically and integrated into a global workspace. They are capable of temporarily maintaining high-level representational patterns akin to the psychological items maintained in working memory. This maintenance is made possible by persistent neural activity in the form of two modalities: sustained neural firing (resulting in a focus of attention) and synaptic potentiation (resulting in a short-term store). Representations held in persistent activity are recursively replaced resulting in incremental changes to the content of the working memory system. As this content gradually evolves, successive processing states overlap and are continuous with one another. The present article will explore how this architecture can lead to iterative shift in the distribution of coactive representations, ultimately leading to mental continuity between processing states, and thus to human-like thought and cognition. Like the human brain, this AI working memory store will be linked to multiple imagery (topographic map) generation systems corresponding to various sensory modalities. As working memory is iteratively updated, the maps created in response will construct sequences of related mental imagery. Thus, neural networks emulating the prefrontal cortex and its reciprocal interactions with early sensory and motor cortex capture the imagery guidance functions of the human brain. This sensory and motor imagery creation, coupled with an iteratively updated working memory store may provide an AI system with the cognitive assets needed to achieve synthetic consciousness or artificial sentience.",
    "source": "arXiv"
  },
  {
    "title": "The degree-restricted random process is far from uniform",
    "title_es": "The degree-restricted random process is far from uniform",
    "url": "https://arxiv.org/abs/2211.00835",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2211.00835v3 Announce Type: replace-cross \nAbstract: The degree-restricted random process is a natural algorithmic model for generating graphs with degree sequence D_n=(d_1, \\ldots, d_n): starting with an empty n-vertex graph, it sequentially adds new random edges so that the degree of each vertex v_i remains at most d_i. Wormald conjectured in 1999 that, for d-regular degree sequences D_n, the final graph of this process is similar to a uniform random d-regular graph.\n  In this paper we show that, for degree sequences D_n that are not nearly regular, the final graph of the degree-restricted random process differs substantially from a uniform random graph with degree sequence D_n. The combinatorial proof technique is our main conceptual contribution: we adapt the switching method to the degree-restricted process, demonstrating that this enumeration technique can also be used to analyze stochastic processes (rather than just uniform random models, as before).",
    "source": "arXiv"
  },
  {
    "title": "A Data-driven Loss Weighting Scheme across Heterogeneous Tasks for Image Denoising",
    "title_es": "A Data-driven Loss Weighting Scheme across Heterogeneous Tasks for Image Denoising",
    "url": "https://arxiv.org/abs/2301.06081",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2301.06081v3 Announce Type: replace-cross \nAbstract: In a variational denoising model, weight in the data fidelity term plays the role of enhancing the noise-removal capability. It is profoundly correlated with noise information, while also balancing the data fidelity and regularization terms. However, the difficulty of assigning weight is expected to be substantial when the noise pattern is beyond independent identical Gaussian distribution, e.g., impulse noise, stripe noise, or a mixture of several patterns, etc. Furthermore, how to leverage weight to balance the data fidelity and regularization terms is even less evident. In this work, we propose a data-driven loss weighting (DLW) scheme to address these issues. Specifically, DLW trains a parameterized weight function (i.e., a neural network) that maps the noisy image to the weight. The training is achieved by a bilevel optimization framework, where the lower level problem is solving several denoising models with the same weight predicted by the weight function and the upper level problem minimizes the distance between the restored image and the clean image. In this way, information from both the noise and the regularization can be efficiently extracted to determine the weight function. DLW also facilitates the easy implementation of a trained weight function on denoising models. Numerical results verify the remarkable performance of DLW on improving the ability of various variational denoising models to handle different complex noise. This implies that DLW has the ability to transfer the noise knowledge at the model level to heterogeneous tasks beyond the training ones and the generalization theory underlying DLW is studied, validating its intrinsic transferability.",
    "source": "arXiv"
  },
  {
    "title": "Stabilizer Testing and Magic Entropy via Quantum Fourier Analysis",
    "title_es": "Stabilizer Testing and Magic Entropy via Quantum Fourier Analysis",
    "url": "https://arxiv.org/abs/2306.09292",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2306.09292v2 Announce Type: replace-cross \nAbstract: Quantum Fourier analysis is an important topic in mathematical physics. We introduce a systematic protocol for testing and measuring ``magic'' in quantum states and gates, using a quantum Fourier approach. Magic, as a quantum resource, is necessary to achieve a quantum advantage in computation. Our protocols are based on quantum convolutions and swap tests, implemented via quantum circuits. We describe this for both qubit and qudit systems. Our quantum Fourier approach offers a unified method to quantify magic, in stabilizer circuits, as well as in matchgate and bosonic Gaussian circuits.",
    "source": "arXiv"
  },
  {
    "title": "Style transfer between Microscopy and Magnetic Resonance Imaging via Generative Adversarial Network in small sample size settings",
    "title_es": "Style transfer between Microscopy and Magnetic Resonance Imaging via Generative Adversarial Network in small sample size settings",
    "url": "https://arxiv.org/abs/2310.10414",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2310.10414v3 Announce Type: replace-cross \nAbstract: Cross-modal augmentation of Magnetic Resonance Imaging (MRI) and microscopic imaging based on the same tissue samples is promising because it can allow histopathological analysis in the absence of an underlying invasive biopsy procedure. Here, we tested a method for generating microscopic histological images from MRI scans of the human corpus callosum using conditional generative adversarial network (cGAN) architecture. To our knowledge, this is the first multimodal translation of the brain MRI to histological volumetric representation of the same sample. The technique was assessed by training paired image translation models taking sets of images from MRI scans and microscopy. The use of cGAN for this purpose is challenging because microscopy images are large in size and typically have low sample availability. The current work demonstrates that the framework reliably synthesizes histology images from MRI scans of corpus callosum, emphasizing the network's ability to train on high resolution histologies paired with relatively lower-resolution MRI scans. With the ultimate goal of avoiding biopsies, the proposed tool can be used for educational purposes.",
    "source": "arXiv"
  },
  {
    "title": "Learning Optimal and Fair Policies for Online Allocation of Scarce Societal Resources from Data Collected in Deployment",
    "title_es": "Learning Optimal and Fair Policies for Online Allocation of Scarce Societal Resources from Data Collected in Deployment",
    "url": "https://arxiv.org/abs/2311.13765",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2311.13765v2 Announce Type: replace-cross \nAbstract: We study the problem of allocating scarce societal resources of different types (e.g., permanent housing, deceased donor kidneys for transplantation, ventilators) to heterogeneous allocatees on a waitlist (e.g., people experiencing homelessness, individuals suffering from end-stage renal disease, Covid-19 patients) based on their observed covariates. We leverage administrative data collected in deployment to design an online policy that maximizes expected outcomes while satisfying budget constraints, in the long run. Our proposed policy waitlists each individual for the resource maximizing the difference between their estimated mean treatment outcome and the estimated resource dual-price or, roughly, the opportunity cost of using the resource. Resources are then allocated as they arrive, in a first-come first-serve fashion. We demonstrate that our data-driven policy almost surely asymptotically achieves the expected outcome of the optimal out-of-sample policy under mild technical assumptions. We extend our framework to incorporate various fairness constraints. We evaluate the performance of our approach on the problem of designing policies for allocating scarce housing resources to people experiencing homelessness in Los Angeles based on data from the homeless management information system. In particular, we show that using our policies improves rates of exit from homelessness by 5.16% and that policies that are fair in either allocation or outcomes by race come at a very low price of fairness.",
    "source": "arXiv"
  },
  {
    "title": "Dynamic Transfer Policies for Parallel Queues",
    "title_es": "Dynamic Transfer Policies for Parallel Queues",
    "url": "https://arxiv.org/abs/2404.00543",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2404.00543v2 Announce Type: replace-cross \nAbstract: We consider the problem of load balancing in parallel queues by transferring customers between them at discrete points in time. Holding costs accrue as customers wait in the queue, while transfer decisions incur both fixed (setup) costs and variable costs that increase with the number of transfers and travel distance, and vary by transfer direction. Our work is primarily motivated by inter-facility patient transfers to address imbalanced congestion and inequity in access to care during surges in hospital demand. Analyzing an associated fluid control problem, we show that under general assumptions, including time-varying arrivals and convex holding costs, the optimal policy partitions the state-space into a well-defined $\\textit{no-transfer region}$ and its complement, implying that transferring is optimal if and only if the system is sufficiently imbalanced. In the absence of fixed transfer costs, an optimal policy moves the state to the no-transfer region's boundary; in contrast, with fixed costs, the state is moved to its relative interior. Leveraging our structural results, we propose a simulation-based approximate dynamic programming (ADP) algorithm to find effective transfer policies for the stochastic system. We investigate the performance and robustness of the fluid and ADP policies in a case study calibrated using data during the COVID-19 pandemic in the Greater Toronto Area, which demonstrates that transferring patients between hospitals could result in up to 27.7% reduction in total cost with relatively few transfers.",
    "source": "arXiv"
  },
  {
    "title": "On the Monotonicity of Information Costs",
    "title_es": "On the Monotonicity of Information Costs",
    "url": "https://arxiv.org/abs/2404.15158",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2404.15158v3 Announce Type: replace-cross \nAbstract: We study the monotonicity of information costs: more informative experiments must be more costly. As criteria for informativeness, we consider the standard information orders introduced by Blackwell (1951, 1953) and Lehmann (1988). We provide simple necessary and sufficient conditions for a cost function to be monotone with respect to each order, grounded in their garbling characterizations. Finally, we examine several well-known cost functions from the literature through the lens of these conditions.",
    "source": "arXiv"
  },
  {
    "title": "Finite-Sample Guarantees for Learning Dynamics in Zero-Sum Polymatrix Games",
    "title_es": "Finite-Sample Guarantees for Learning Dynamics in Zero-Sum Polymatrix Games",
    "url": "https://arxiv.org/abs/2407.20128",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2407.20128v3 Announce Type: replace-cross \nAbstract: We study best-response type learning dynamics for zero-sum polymatrix games under two information settings. The two settings are distinguished by the type of information that each player has about the game and their opponents' strategy. The first setting is the full information case, in which each player knows their own and their opponents' payoff matrices and observes everyone's mixed strategies. The second setting is the minimal information case, where players do not observe their opponents' strategies and are not aware of any payoff matrices (instead they only observe their realized payoffs). For this setting, also known as the radically uncoupled case in the learning in games literature, we study a two-timescale learning dynamics that combine smoothed best-response type updates for strategy estimates with a TD-learning update to estimate a local payoff function. For these dynamics, without additional exploration, we provide polynomial-time finite-sample guarantees for convergence to an $\\epsilon$-Nash equilibrium.",
    "source": "arXiv"
  },
  {
    "title": "VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge",
    "title_es": "VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge",
    "url": "https://arxiv.org/abs/2408.02865",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2408.02865v2 Announce Type: replace-cross \nAbstract: The need for improved diagnostic methods in ophthalmology is acute, especially in the underdeveloped regions with limited access to specialists and advanced equipment. Therefore, we introduce VisionUnite, a novel vision-language foundation model for ophthalmology enhanced with clinical knowledge. VisionUnite has been pretrained on an extensive dataset comprising 1.24 million image-text pairs, and further refined using our proposed MMFundus dataset, which includes 296,379 high-quality fundus image-text pairs and 889,137 simulated doctor-patient dialogue instances. Our experiments indicate that VisionUnite outperforms existing generative foundation models such as GPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable to junior ophthalmologists. VisionUnite performs well in various clinical scenarios including open-ended multi-disease diagnosis, clinical explanation, and patient interaction, making it a highly versatile tool for initial ophthalmic disease screening. VisionUnite can also serve as an educational aid for junior ophthalmologists, accelerating their acquisition of knowledge regarding both common and underrepresented ophthalmic conditions. VisionUnite represents a significant advancement in ophthalmology, with broad implications for diagnostics, medical education, and understanding of disease mechanisms. The source code is at https://github.com/HUANGLIZI/VisionUnite.",
    "source": "arXiv"
  },
  {
    "title": "fastkqr: A Fast Algorithm for Kernel Quantile Regression",
    "title_es": "fastkqr: A Fast Algorithm for Kernel Quantile Regression",
    "url": "https://arxiv.org/abs/2408.05393",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2408.05393v2 Announce Type: replace-cross \nAbstract: Quantile regression is a powerful tool for robust and heterogeneous learning that has seen applications in a diverse range of applied areas. However, its broader application is often hindered by the substantial computational demands arising from the non-smooth quantile loss function. In this paper, we introduce a novel algorithm named fastkqr, which significantly advances the computation of quantile regression in reproducing kernel Hilbert spaces. The core of fastkqr is a finite smoothing algorithm that magically produces exact regression quantiles, rather than approximations. To further accelerate the algorithm, we equip fastkqr with a novel spectral technique that carefully reutilizes matrix computations. In addition, we extend fastkqr to accommodate a flexible kernel quantile regression with a data-driven crossing penalty, addressing the interpretability challenges of crossing quantile curves at multiple levels. We have implemented fastkqr in a publicly available R package. Extensive simulations and real applications show that fastkqr matches the accuracy of state-of-the-art algorithms but can operate up to an order of magnitude faster.",
    "source": "arXiv"
  },
  {
    "title": "Regularity of vector fields with piecewise regular curl and divergence",
    "title_es": "Regularity of vector fields with piecewise regular curl and divergence",
    "url": "https://arxiv.org/abs/2408.16556",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2408.16556v3 Announce Type: replace-cross \nAbstract: We consider a bounded Lipschitz domain $\\Omega\\subseteq\\mathbb{R}^3$ with sufficiently smooth boundary and prove piecewise Sobolev regularity of vector fields that have piecewise regular curl and divergence, but may be discontinuous across mutually disjoint and sufficiently smooth surfaces inside of $\\Omega$. The main idea behind our approach is to employ recently developed parametrices for the curl-operator and the regularity theory of Poisson transmission problems. We conclude our work by applying our findings to the heterogeneous time-harmonic Maxwell equations with either a) impedance, b) natural or c) essential boundary conditions and providing wavenumber-explicit piecewise regularity estimates for these equations.",
    "source": "arXiv"
  },
  {
    "title": "Classically estimating observables of noiseless quantum circuits",
    "title_es": "Classically estimating observables of noiseless quantum circuits",
    "url": "https://arxiv.org/abs/2409.01706",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2409.01706v2 Announce Type: replace-cross \nAbstract: We present a classical algorithm based on Pauli propagation for estimating expectation values of arbitrary observables on random unstructured quantum circuits across all circuit architectures and depths, including those with all-to-all connectivity. We prove that for any architecture where each circuit layer is randomly sampled from a distribution invariant under single-qubit rotations, our algorithm achieves a small error $\\varepsilon$ on all circuits except for a small fraction $\\delta$. The computational time is polynomial in qubit count and circuit depth for any small constant $\\varepsilon, \\delta$, and quasi-polynomial for inverse-polynomially small $\\varepsilon, \\delta$. Our results show that estimating observables of quantum circuits exhibiting chaotic and locally scrambling behavior is classically tractable across all geometries. We further conduct numerical experiments beyond our average-case assumptions, demonstrating the potential utility of Pauli propagation methods for simulating real-time dynamics and finding low-energy states of physical Hamiltonians.",
    "source": "arXiv"
  },
  {
    "title": "Return Prediction for Mean-Variance Portfolio Selection: How Decision-Focused Learning Shapes Forecasting Models",
    "title_es": "Return Prediction for Mean-Variance Portfolio Selection: How Decision-Focused Learning Shapes Forecasting Models",
    "url": "https://arxiv.org/abs/2409.09684",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2409.09684v2 Announce Type: replace-cross \nAbstract: Markowitz laid the foundation of portfolio theory through the mean-variance optimization (MVO) framework. However, the effectiveness of MVO is contingent on the precise estimation of expected returns, variances, and covariances of asset returns, which are typically uncertain. Machine learning models are becoming useful in estimating uncertain parameters, and such models are trained to minimize prediction errors, such as mean squared errors (MSE), which treat prediction errors uniformly across assets. Recent studies have pointed out that this approach would lead to suboptimal decisions and proposed Decision-Focused Learning (DFL) as a solution, integrating prediction and optimization to improve decision-making outcomes. While studies have shown DFL's potential to enhance portfolio performance, the detailed mechanisms of how DFL modifies prediction models for MVO remain unexplored. This study investigates how DFL adjusts stock return prediction models to optimize decisions in MVO. Theoretically, we show that DFL's gradient can be interpreted as tilting the MSE-based prediction errors by the inverse covariance matrix, effectively incorporating inter-asset correlations into the learning process, while MSE treats each asset's error independently. This tilting mechanism leads to systematic prediction biases where DFL overestimates returns for assets included in portfolios while underestimating excluded assets. Our findings reveal why DFL achieves superior portfolio performance despite higher prediction errors. The strategic biases are features, not flaws.",
    "source": "arXiv"
  },
  {
    "title": "Subtree Distances, Tight Spans and Diversities",
    "title_es": "Subtree Distances, Tight Spans and Diversities",
    "url": "https://arxiv.org/abs/2501.13202",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2501.13202v2 Announce Type: replace-cross \nAbstract: Metric embeddings are central to metric theory and its applications. Here we consider embeddings of a different sort: maps from a set to subsets of a metric space so that distances between points are approximated by minimal distances between subsets. Our main result is a characterization of when a set of distances $d(x,y)$ between elements in a set $X$ have a subtree representation, a real tree $T$ and a collection $\\{S_x\\}_{x \\in X}$ of subtrees of~$T$ such that $d(x,y)$ equals the length of the shortest path in~$T$ from a point in $S_x$ to a point in $S_y$ for all $x,y \\in X$. The characterization was first established for {\\em finite} $X$ by Hirai (2006) using a tight span construction defined for distance spaces, metric spaces without the triangle inequality. To extend Hirai's result beyond finite $X$ we establish fundamental results of tight span theory for general distance spaces, including the surprising observation that the tight span of a distance space is hyperconvex. We apply the results to obtain the first characterization of when a diversity -- a generalization of a metric space which assigns values to all finite subsets of $X$, not just to pairs -- has a tight span which is tree-like.",
    "source": "arXiv"
  },
  {
    "title": "TTC Domains",
    "title_es": "TTC Domains",
    "url": "https://arxiv.org/abs/2501.15422",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2501.15422v3 Announce Type: replace-cross \nAbstract: We study the object reallocation problem under strict preferences. On the unrestricted domain, Ekici (2024) showed that the Top Trading Cycles (TTC) mechanism is the unique mechanism that is individually rational, pair efficient, and strategyproof. We introduce a richness property on preference domains -- the top-two condition -- and show that this characterization extends to all domains satisfying it. The condition requires that within any subset of objects, if two objects can each be most-preferred, they can also be ranked as the top two (in either order). We further show that almost all domains failing the top-two condition for a triple or quadruple of objects admit non-TTC mechanisms satisfying the axioms. These results unify prior findings on specific domains, demonstrate the robustness of Ekici (2024) characterization, and suggest a minimal richness requirement that may underlie it.",
    "source": "arXiv"
  },
  {
    "title": "Geometry of the symplectic group and optimal EAQECC codes",
    "title_es": "Geometry of the symplectic group and optimal EAQECC codes",
    "url": "https://arxiv.org/abs/2501.15465",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2501.15465v2 Announce Type: replace-cross \nAbstract: A new type of link between geometry of symplectic group and entanglement-assisted (EA) quantum error-correcting codes (EAQECCs) is presented. Relations of symplectic subspaces and quaternary additive codes concerning parameters of EAQECCs are described. Thus, parameters of EA stabilizer codes are revealed in the nomenclature of additive codes. Our techniques enable us solve some open problems about optimal EAQECCs and entanglement-assisted quantum minimum distance separable (EAQMDS) codes, and are also useful for designing encoding and decoding quantum circuit of EA stabilizer codes.",
    "source": "arXiv"
  },
  {
    "title": "Online Covariance Estimation in Nonsmooth Stochastic Approximation",
    "title_es": "Online Covariance Estimation in Nonsmooth Stochastic Approximation",
    "url": "https://arxiv.org/abs/2502.05305",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.05305v2 Announce Type: replace-cross \nAbstract: We consider applying stochastic approximation (SA) methods to solve nonsmooth variational inclusion problems. Existing studies have shown that the averaged iterates of SA methods exhibit asymptotic normality, with an optimal limiting covariance matrix in the local minimax sense of H\\'ajek and Le Cam. However, no methods have been proposed to estimate this covariance matrix in a nonsmooth and potentially non-monotone (nonconvex) setting. In this paper, we study an online batch-means covariance matrix estimator introduced in Zhu et al.(2023). The estimator groups the SA iterates appropriately and computes the sample covariance among batches as an estimate of the limiting covariance. Its construction does not require prior knowledge of the total sample size, and updates can be performed recursively as new data arrives. We establish that, as long as the batch size sequence is properly specified (depending on the stepsize sequence), the estimator achieves a convergence rate of order $O(\\sqrt{d}n^{-1/8+\\varepsilon})$ for any $\\varepsilon>0$, where $d$ and $n$ denote the problem dimensionality and the number of iterations (or samples) used. Although the problem is nonsmooth and potentially non-monotone (nonconvex), our convergence rate matches the best-known rate for covariance estimation methods using only first-order information in smooth and strongly-convex settings. The consistency of this covariance estimator enables asymptotically valid statistical inference, including constructing confidence intervals and performing hypothesis testing.",
    "source": "arXiv"
  },
  {
    "title": "Automated Muscle and Fat Segmentation in Computed Tomography for Comprehensive Body Composition Analysis",
    "title_es": "Automated Muscle and Fat Segmentation in Computed Tomography for Comprehensive Body Composition Analysis",
    "url": "https://arxiv.org/abs/2502.09779",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.09779v3 Announce Type: replace-cross \nAbstract: Body composition assessment using CT images can potentially be used for a number of clinical applications, including the prognostication of cardiovascular outcomes, evaluation of metabolic health, monitoring of disease progression, assessment of nutritional status, prediction of treatment response in oncology, and risk stratification for surgical and critical care outcomes. While multiple groups have developed in-house segmentation tools for this analysis, there are very limited publicly available tools that could be consistently used across different applications. To mitigate this gap, we present a publicly accessible, end-to-end segmentation and feature calculation model specifically for CT body composition analysis. Our model performs segmentation of skeletal muscle, subcutaneous adipose tissue (SAT), and visceral adipose tissue (VAT) across the chest, abdomen, and pelvis area in axial CT images. It also provides various body composition metrics, including muscle density, visceral-to-subcutaneous fat (VAT/SAT) ratio, muscle area/volume, and skeletal muscle index (SMI), supporting both 2D and 3D assessments. To evaluate the model, the segmentation was applied to both internal and external datasets, with body composition metrics analyzed across different age, sex, and race groups. The model achieved high dice coefficients on both internal and external datasets, exceeding 89% for skeletal muscle, SAT, and VAT segmentation. The model outperforms the benchmark by 2.40% on skeletal muscle and 10.26% on SAT compared to the manual annotations given by the publicly available dataset. Body composition metrics show mean relative absolute errors (MRAEs) under 10% for all measures. Furthermore, the model provided muscular fat segmentation with a Dice coefficient of 56.27%, which can be utilized for additional analyses as needed.",
    "source": "arXiv"
  },
  {
    "title": "The Normal Play of the Domination Game",
    "title_es": "The Normal Play of the Domination Game",
    "url": "https://arxiv.org/abs/2502.13118",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2502.13118v4 Announce Type: replace-cross \nAbstract: In 2010, Bre\\v{s}ar, Klav\\v{z}ar and Rall introduced the optimization variant of the graph domination game and the game domination number, which was proved PSPACE-hard by Bre\\v{s}ar et al. in 2016. In 2024, Leo Versteegen obtained the celebrated proof of the Conjecture $\\frac{3}{5}$ on this variant of the domination game, proposed by Kinnersley, West and Zamani in 2013. In this paper, we investigate for the first time the normal play of the domination game, which we call Normal Domination Game, that is an impartial game where the last to play wins. We first prove that this game is PSPACE-complete even in graphs with diameter two. We also use the Sprague-Grundy theory to prove that Alice (the first player) wins in the path $P_n$ if and only if $n$ is not a multiple of $4$, and wins in the cycle $C_n$ if and only if $n=4k+3$ for some integer $k$. Moreover, we obtain a polynomial time algorithm to decide the winner for any disjoint union of paths and cycles in the Normal Domination Game and its natural partizan variant. Finally, we also prove that the Mis\\`ere Domination Game (the last to play loses) is PSPACE-complete, as are the natural partizan variants of the normal game and the mis\\`ere game.",
    "source": "arXiv"
  },
  {
    "title": "Task-Oriented Feature Compression for Multimodal Understanding via Device-Edge Co-Inference",
    "title_es": "Task-Oriented Feature Compression for Multimodal Understanding via Device-Edge Co-Inference",
    "url": "https://arxiv.org/abs/2503.12926",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.12926v2 Announce Type: replace-cross \nAbstract: With the rapid development of large multimodal models (LMMs), multimodal understanding applications are emerging. As most LMM inference requests originate from edge devices with limited computational capabilities, the predominant inference pipeline involves directly forwarding the input data to an edge server which handles all computations. However, this approach introduces high transmission latency due to limited uplink bandwidth of edge devices and significant computation latency caused by the prohibitive number of visual tokens, thus hindering delay-sensitive tasks and degrading user experience. To address this challenge, we propose a task-oriented feature compression (TOFC) method for multimodal understanding in a device-edge co-inference framework, where visual features are merged by clustering and encoded by a learnable and selective entropy model before feature projection. Specifically, we employ density peaks clustering based on K nearest neighbors to reduce the number of visual features, thereby minimizing both data transmission and computational complexity. Subsequently, a learnable entropy model with hyperprior is utilized to encode and decode merged features, further reducing transmission overhead. To enhance compression efficiency, multiple entropy models are adaptively selected based on the characteristics of the visual features, enabling a more accurate estimation of the probability distribution. Comprehensive experiments on seven visual question answering benchmarks validate the effectiveness of the proposed TOFC method. Results show that TOFC achieves up to 52% reduction in data transmission overhead and 63% reduction in system latency while maintaining identical task performance, compared with neural compression ELIC.",
    "source": "arXiv"
  },
  {
    "title": "Euclid Quick Data Release (Q1). Active galactic nuclei identification using diffusion-based inpainting of Euclid VIS images",
    "title_es": "Euclid Quick Data Release (Q1). Active galactic nuclei identification using diffusion-based inpainting of Euclid VIS images",
    "url": "https://arxiv.org/abs/2503.15321",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2503.15321v2 Announce Type: replace-cross \nAbstract: Light emission from galaxies exhibit diverse brightness profiles, influenced by factors such as galaxy type, structural features and interactions with other galaxies. Elliptical galaxies feature more uniform light distributions, while spiral and irregular galaxies have complex, varied light profiles due to their structural heterogeneity and star-forming activity. In addition, galaxies with an active galactic nucleus (AGN) feature intense, concentrated emission from gas accretion around supermassive black holes, superimposed on regular galactic light, while quasi-stellar objects (QSO) are the extreme case of the AGN emission dominating the galaxy. The challenge of identifying AGN and QSO has been discussed many times in the literature, often requiring multi-wavelength observations. This paper introduces a novel approach to identify AGN and QSO from a single image. Diffusion models have been recently developed in the machine-learning literature to generate realistic-looking images of everyday objects. Utilising the spatial resolving power of the Euclid VIS images, we created a diffusion model trained on one million sources, without using any source pre-selection or labels. The model learns to reconstruct light distributions of normal galaxies, since the population is dominated by them. We condition the prediction of the central light distribution by masking the central few pixels of each source and reconstruct the light according to the diffusion model. We further use this prediction to identify sources that deviate from this profile by examining the reconstruction error of the few central pixels regenerated in each source's core. Our approach, solely using VIS imaging, features high completeness compared to traditional methods of AGN and QSO selection, including optical, near-infrared, mid-infrared, and X-rays.",
    "source": "arXiv"
  },
  {
    "title": "Randomised Postiterations for Calibrated BayesCG",
    "title_es": "Randomised Postiterations for Calibrated BayesCG",
    "url": "https://arxiv.org/abs/2504.04247",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2504.04247v2 Announce Type: replace-cross \nAbstract: The Bayesian conjugate gradient method offers probabilistic solutions to linear systems but suffers from poor calibration, limiting its utility in uncertainty quantification tasks. Recent approaches leveraging postiterations to construct priors have improved computational properties but failed to correct calibration issues. In this work, we propose a novel randomised postiteration strategy that enhances the calibration of the BayesCG posterior while preserving its favourable convergence characteristics. We present theoretical guarantees for the improved calibration, supported by results on the distribution of posterior errors. Numerical experiments demonstrate the efficacy of the method in both synthetic and inverse problem settings, showing enhanced uncertainty quantification and better propagation of uncertainties through computational pipelines.",
    "source": "arXiv"
  },
  {
    "title": "PC-SRGAN: Physically Consistent Super-Resolution Generative Adversarial Network for General Transient Simulations",
    "title_es": "PC-SRGAN: Physically Consistent Super-Resolution Generative Adversarial Network for General Transient Simulations",
    "url": "https://arxiv.org/abs/2505.06502",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.06502v3 Announce Type: replace-cross \nAbstract: Machine Learning, particularly Generative Adversarial Networks (GANs), has revolutionised Super-Resolution (SR). However, generated images often lack physical meaningfulness, which is essential for scientific applications. Our approach, PC-SRGAN, enhances image resolution while ensuring physical consistency for interpretable simulations. PC-SRGAN significantly improves both the Peak Signal-to-Noise Ratio and the Structural Similarity Index Measure compared to conventional SR methods, even with limited training data (e.g., only 13% of training data is required to achieve performance similar to SRGAN). Beyond SR, PC-SRGAN augments physically meaningful machine learning, incorporating numerically justified time integrators and advanced quality metrics. These advancements promise reliable and causal machine-learning models in scientific domains. A significant advantage of PC-SRGAN over conventional SR techniques is its physical consistency, which makes it a viable surrogate model for time-dependent problems. PC-SRGAN advances scientific machine learning by improving accuracy and efficiency, enhancing process understanding, and broadening applications to scientific research. We publicly release the complete source code of PC-SRGAN and all experiments at https://github.com/hasan-rakibul/PC-SRGAN.",
    "source": "arXiv"
  },
  {
    "title": "Rainbow copies of spanning subgraphs",
    "title_es": "Rainbow copies of spanning subgraphs",
    "url": "https://arxiv.org/abs/2505.21290",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2505.21290v3 Announce Type: replace-cross \nAbstract: Let $G_{n,p}^{[\\kappa]}$ denote the space of $n$-vertex edge coloured graphs, where each edge occurs independently with probability $p$. The colour of each existing edge is chosen independently and uniformly at random from the set $[\\kappa]$. We consider the threshold for the existence of rainbow colored copies of a spanning subgraph $H$. We provide lower bounds on $p$ and $\\kappa$ sufficient to prove the existence of such copies w.h.p.",
    "source": "arXiv"
  },
  {
    "title": "Discrete and Continuous Difference of Submodular Minimization",
    "title_es": "Discrete and Continuous Difference of Submodular Minimization",
    "url": "https://arxiv.org/abs/2506.07952",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.07952v2 Announce Type: replace-cross \nAbstract: Submodular functions, defined on continuous or discrete domains, arise in numerous applications. We study the minimization of the difference of two submodular (DS) functions, over both domains, extending prior work restricted to set functions. We show that all functions on discrete domains and all smooth functions on continuous domains are DS. For discrete domains, we observe that DS minimization is equivalent to minimizing the difference of two convex (DC) functions, as in the set function case. We propose a novel variant of the DC Algorithm (DCA) and apply it to the resulting DC Program, obtaining comparable theoretical guarantees as in the set function case. The algorithm can be applied to continuous domains via discretization. Experiments demonstrate that our method outperforms baselines in integer compressive sensing and integer least squares.",
    "source": "arXiv"
  },
  {
    "title": "Patient-Specific Deep Reinforcement Learning for Automatic Replanning in Head-and-Neck Cancer Proton Therapy",
    "title_es": "Patient-Specific Deep Reinforcement Learning for Automatic Replanning in Head-and-Neck Cancer Proton Therapy",
    "url": "https://arxiv.org/abs/2506.10073",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2506.10073v2 Announce Type: replace-cross \nAbstract: Anatomical changes during intensity-modulated proton therapy (IMPT) for head-and-neck cancer (HNC) can shift Bragg peaks, risking tumor underdosing and organ-at-risk overdosing. Treatment replanning is often required to maintain clinically acceptable treatment quality. However, current manual replanning processes are resource-intensive and time-consuming. We propose a patient-specific deep reinforcement learning (DRL) framework for automated IMPT replanning, with a reward-shaping mechanism based on a $150$-point plan quality score addressing competing clinical objectives. We formulate the planning process as a reinforcement learning problem where agents learn control policies to adjust optimization priorities, maximizing plan quality. Unlike population-based approaches, our framework trains agents for each patient using their planning Computed Tomography (CT) and augmented anatomies simulating anatomical changes (tumor progression and regression). This patient-specific approach leverages anatomical similarities along the treatment course, enabling effective plan adaptation. We implemented two DRL algorithms, Deep Q-Network and Proximal Policy Optimization, using dose-volume histograms (DVHs) as state representations and a $22$-dimensional action space of priority adjustments. Evaluation on eight HNC patients using actual replanning CT data showed that both agents improved initial plan scores from $120.78 \\pm 17.18$ to $139.59 \\pm 5.50$ (DQN) and $141.50 \\pm 4.69$ (PPO), surpassing the replans manually generated by a human planner ($136.32 \\pm 4.79$). Clinical validation confirms that improvements translate to better tumor coverage and OAR sparing across diverse anatomical changes. This work highlights DRL's potential in addressing geometric and dosimetric complexities of adaptive proton therapy, offering efficient offline adaptation solutions and advancing online adaptive proton therapy.",
    "source": "arXiv"
  },
  {
    "title": "Logarithmic Depth Decomposition of Approximate Multi-Controlled Single-Qubit Gates Without Ancilla Qubits",
    "title_es": "Logarithmic Depth Decomposition of Approximate Multi-Controlled Single-Qubit Gates Without Ancilla Qubits",
    "url": "https://arxiv.org/abs/2507.00400",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2507.00400v2 Announce Type: replace-cross \nAbstract: The synthesis of quantum operators involves decomposing general quantum gates into the gate set supported by a given quantum device. Multi-controlled gates are essential components in this process. In this work, we present an improved decomposition of multi-controlled NOT gates with logarithmic depth using a single ancilla qubit while reducing the ancillary resource requirements compared to previous work. We further introduce a relative-phase multi-controlled NOT gate that eliminates the need for ancillas. Building on these results, we optimize a previously proposed decomposition of multi-target, multi-controlled special unitary SU(2) gates by identifying the presence of a conditionally clean qubit. Additionally, we introduce the best-known decomposition of multi-controlled approximate unitary U(2) gates, which do not require ancilla qubits. This approach significantly reduces the overall circuit depth and CNOT count while preserving an adjustable error parameter, yielding a more efficient and scalable solution for synthesizing large controlled-unitary gates. Our method is particularly suitable for both NISQ and fault-tolerant quantum architectures. All software developed in this project is freely available.",
    "source": "arXiv"
  },
  {
    "title": "Uni-Mol3: A Multi-Molecular Foundation Model for Advancing Organic Reaction Modeling",
    "title_es": "Uni-Mol3: A Multi-Molecular Foundation Model for Advancing Organic Reaction Modeling",
    "url": "https://arxiv.org/abs/2508.00920",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.00920v2 Announce Type: replace-cross \nAbstract: Organic reaction, the foundation of modern chemical industry, is crucial for new material development and drug discovery. However, deciphering reaction mechanisms and modeling multi-molecular relationships remain formidable challenges due to the complexity of molecular dynamics. While several state-of-the-art models like Uni-Mol2 have revolutionized single-molecular representation learning, their extension to multi-molecular systems, where chemical reactions inherently occur, has been underexplored. This paper introduces Uni-Mol3, a novel deep learning framework that employs a hierarchical pipeline for multi-molecular reaction modeling. At its core, Uni-Mol3 adopts a multi-scale molecular tokenizer (Mol-Tokenizer) that encodes 3D structures of molecules and other features into discrete tokens, creating a 3D-aware molecular language. The framework innovatively combines two pre-training stages: molecular pre-training to learn the molecular grammars and reaction pre-training to capture fundamental reaction principles, forming a progressive learning paradigm from single- to multi-molecular systems. With prompt-aware downstream fine-tuning, Uni-Mol3 demonstrates exceptional performance in diverse organic reaction tasks and supports multi-task prediction with strong generalizability. Experimental results across 10 datasets spanning 4 downstream tasks show that Uni-Mol3 outperforms existing methods, validating its effectiveness in modeling complex organic reactions. This work not only ushers in an alternative paradigm for multi-molecular computational modeling but also charts a course for intelligent organic reaction by bridging molecular representation with reaction mechanism understanding.",
    "source": "arXiv"
  },
  {
    "title": "FUTransUNet-GradCAM: A Hybrid Transformer-U-Net with Self-Attention and Explainable Visualizations for Foot Ulcer Segmentation",
    "title_es": "FUTransUNet-GradCAM: A Hybrid Transformer-U-Net with Self-Attention and Explainable Visualizations for Foot Ulcer Segmentation",
    "url": "https://arxiv.org/abs/2508.03758",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.03758v2 Announce Type: replace-cross \nAbstract: Automated segmentation of diabetic foot ulcers (DFUs) plays a critical role in clinical diagnosis, therapeutic planning, and longitudinal wound monitoring. However, this task remains challenging due to the heterogeneous appearance, irregular morphology, and complex backgrounds associated with ulcer regions in clinical photographs. Traditional convolutional neural networks (CNNs), such as U-Net, provide strong localization capabilities but struggle to model long-range spatial dependencies due to their inherently limited receptive fields. To address this, we propose FUTransUNet, a hybrid architecture that integrates the global attention mechanism of Vision Transformers (ViTs) into the U-Net framework. This combination allows the model to extract global contextual features while maintaining fine-grained spatial resolution through skip connections and an effective decoding pathway. We trained and validated FUTransUNet on the public Foot Ulcer Segmentation Challenge (FUSeg) dataset. FUTransUNet achieved a training Dice Coefficient of 0.8679, an IoU of 0.7672, and a training loss of 0.0053. On the validation set, the model achieved a Dice Coefficient of 0.8751, an IoU of 0.7780, and a validation loss of 0.009045. To ensure clinical transparency, we employed Grad-CAM visualizations, which highlighted model focus areas during prediction. These quantitative outcomes clearly demonstrate that our hybrid approach successfully integrates global and local feature extraction paradigms, thereby offering a highly robust, accurate, explainable, and interpretable solution and clinically translatable solution for automated foot ulcer analysis. The approach offers a reliable, high-fidelity solution for DFU segmentation, with implications for improving real-world wound assessment and patient care.",
    "source": "arXiv"
  },
  {
    "title": "Zak-OTFS over CP-OFDM",
    "title_es": "Zak-OTFS over CP-OFDM",
    "url": "https://arxiv.org/abs/2508.03906",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.03906v2 Announce Type: replace-cross \nAbstract: Zak-Orthogonal Time Frequency Space (Zak-OTFS) modulation has been shown to achieve significantly better performance compared to the standardized Cyclic-Prefix Orthogonal Frequency Division Multiplexing (CP-OFDM), in high delay/Doppler spread scenarios envisaged in next generation communication systems. Zak-OTFS carriers are quasi-periodic pulses in the delay-Doppler (DD) domain, characterized by two parameters, (i) the pulse period along the delay axis (``delay period\") (Doppler period is related to the delay period), and (ii) the pulse shaping filter. An important practical challenge is enabling support for Zak-OTFS modulation in existing CP-OFDM based modems. In this paper we show that Zak-OTFS modulation with pulse shaping constrained to sinc filtering (filter bandwidth equal to the communication bandwidth $B$) followed by time-windowing with a rectangular window of duration $(T + T_{cp})$ ($T$ is the symbol duration and $T_{cp}$ is the CP duration), can be implemented as a low-complexity precoder over standard CP-OFDM. We also show that the Zak-OTFS de-modulator with matched filtering constrained to sinc filtering (filter bandwidth $B$) followed by rectangular time windowing over duration $T$ can be implemented as a low-complexity post-processing of the CP-OFDM de-modulator output. This proposed ``Zak-OTFS over CP-OFDM\" architecture enables us to harness the benefits of Zak-OTFS in existing network infrastructure. We also show that the proposed Zak-OTFS over CP-OFDM is a family of modulations, with CP-OFDM being a special case when the delay period takes its minimum possible value equal to the inverse bandwidth, i.e., Zak-OTFS over CP-OFDM with minimum delay period.",
    "source": "arXiv"
  },
  {
    "title": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree",
    "title_es": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree",
    "url": "https://arxiv.org/abs/2508.07014",
    "published": "2025-08-13T04:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "arXiv:2508.07014v2 Announce Type: replace-cross \nAbstract: Recognizing specific key phrases is an essential task for contextualized Automatic Speech Recognition (ASR). However, most existing context-biasing approaches have limitations associated with the necessity of additional model training, significantly slow down the decoding process, or constrain the choice of the ASR system type. This paper proposes a universal ASR context-biasing framework that supports all major types: CTC, Transducers, and Attention Encoder-Decoder models. The framework is based on a GPU-accelerated word boosting tree, which enables it to be used in shallow fusion mode for greedy and beam search decoding without noticeable speed degradation, even with a vast number of key phrases (up to 20K items). The obtained results showed high efficiency of the proposed method, surpassing the considered open-source context-biasing approaches in accuracy and decoding speed. Our context-biasing framework is open-sourced as a part of the NeMo toolkit.",
    "source": "arXiv"
  },
  {
    "title": "Astronomers gave up this comet for dead ― but they were wrong",
    "title_es": "Astronomers gave up this comet for dead ― but they were wrong",
    "url": "https://www.nature.com/articles/d41586-025-02561-3",
    "published": "2025-08-13T00:00:00.000Z",
    "date": "2025-08-13",
    "content_es": "Astronomers gave up this comet for dead ― but they were wrong",
    "source": "Nature"
  },
  {
    "title": "Use AI in the classroom to bring problems to life",
    "title_es": "Use AI in the classroom to bring problems to life",
    "url": "https://www.nature.com/articles/d41586-025-02571-1",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Use AI in the classroom to bring problems to life",
    "source": "Nature"
  },
  {
    "title": "Organs on chips could make biomedical research more equitable",
    "title_es": "Organs on chips could make biomedical research more equitable",
    "url": "https://www.nature.com/articles/d41586-025-02569-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Organs on chips could make biomedical research more equitable",
    "source": "Nature"
  },
  {
    "title": "Europe must safeguard climate data following NASA cuts",
    "title_es": "Europe must safeguard climate data following NASA cuts",
    "url": "https://www.nature.com/articles/d41586-025-02572-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Europe must safeguard climate data following NASA cuts",
    "source": "Nature"
  },
  {
    "title": "Study how screen time affects circadian rhythms",
    "title_es": "Study how screen time affects circadian rhythms",
    "url": "https://www.nature.com/articles/d41586-025-02570-2",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Study how screen time affects circadian rhythms",
    "source": "Nature"
  },
  {
    "title": "How Paris dealt with lightning in the Age of Enlightenment",
    "title_es": "How Paris dealt with lightning in the Age of Enlightenment",
    "url": "https://www.nature.com/articles/d41586-025-02429-6",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "How Paris dealt with lightning in the Age of Enlightenment",
    "source": "Nature"
  },
  {
    "title": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "title_es": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "url": "https://www.nature.com/articles/d41586-025-02354-8",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Impact of catastrophic flood might have been exacerbated by river-management programme",
    "source": "Nature"
  },
  {
    "title": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "title_es": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "url": "https://www.nature.com/articles/d41586-025-02548-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Margaret Boden obituary: cognitive scientist who explored how machines might emulate human imagination",
    "source": "Nature"
  },
  {
    "title": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "title_es": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "url": "https://www.nature.com/articles/d41586-025-02510-0",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Trump’s chief science adviser faces a storm of criticism: what's next?",
    "source": "Nature"
  },
  {
    "title": "AI content is tainting preprints: how moderators are fighting back",
    "title_es": "AI content is tainting preprints: how moderators are fighting back",
    "url": "https://www.nature.com/articles/d41586-025-02469-y",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "AI content is tainting preprints: how moderators are fighting back",
    "source": "Nature"
  },
  {
    "title": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "title_es": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "url": "https://www.nature.com/articles/d41586-025-02450-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "Postdoc depression and anxiety rates are rising, finds survey of 872 researchers",
    "source": "Nature"
  },
  {
    "title": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "title_es": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "url": "https://www.nature.com/articles/d41586-025-02507-9",
    "published": "2025-08-12T00:00:00.000Z",
    "date": "2025-08-12",
    "content_es": "‘A whole body of health-equity research is being disappeared’ — why I resigned from the NIH",
    "source": "Nature"
  },
  {
    "title": "Nuevas tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro!",
    "title_es": "Nuevas tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro!",
    "url": "https://www.cnio.es/noticias/nuevas-tesis-doctorales-en-el-cnio-enhorabuena-a-quienes-hacen-la-ciencia-del-futuro/",
    "published": "2025-08-12T18:11:56.000Z",
    "date": "2025-08-12",
    "content_es": "Charles Darwin ponía sus esperanzas en los «naturalistas jóvenes y emergentes», que sabrían apreciar sus ideas rompedoras; a los veteranos, en cambio, no aspiraba a convencerlos porque sus mentes «están repletas de datos analizados desde un punto de vista opuesto al mío durante muchos años», escribió en El Origen de las Especies–. El físico Max […]\nLa entrada Nuevas tesis doctorales en el CNIO: ¡Enhorabuena a quienes hacen la ciencia del futuro! se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "title_es": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "url": "https://www.nature.com/articles/s41586-025-09407-y",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Author Correction: A virtual rodent predicts the structure of neural activity across behaviours",
    "source": "Nature"
  },
  {
    "title": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "title_es": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "url": "https://www.nature.com/articles/s41586-025-09485-y",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Catalytic enantioselective synthesis of alkylidenecyclopropanes",
    "source": "Nature"
  },
  {
    "title": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "title_es": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "url": "https://www.nature.com/articles/s41586-025-09464-3",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Author Correction: RNA codon expansion via programmable pseudouridine editing and decoding",
    "source": "Nature"
  },
  {
    "title": "How does a forest return to abandoned land? I travel to find out",
    "title_es": "How does a forest return to abandoned land? I travel to find out",
    "url": "https://www.nature.com/articles/d41586-025-02517-7",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "How does a forest return to abandoned land? I travel to find out",
    "source": "Nature"
  },
  {
    "title": "How Indigenous values permeate my chemistry teaching and research",
    "title_es": "How Indigenous values permeate my chemistry teaching and research",
    "url": "https://www.nature.com/articles/d41586-025-02568-w",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "How Indigenous values permeate my chemistry teaching and research",
    "source": "Nature"
  },
  {
    "title": "Six questions to ask before jumping into a spreadsheet",
    "title_es": "Six questions to ask before jumping into a spreadsheet",
    "url": "https://www.nature.com/articles/d41586-025-02511-z",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Six questions to ask before jumping into a spreadsheet",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Political officials could control US federal science grants",
    "title_es": "Daily briefing: Political officials could control US federal science grants",
    "url": "https://www.nature.com/articles/d41586-025-02573-z",
    "published": "2025-08-11T00:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "Daily briefing: Political officials could control US federal science grants",
    "source": "Nature"
  },
  {
    "title": "Swift bricks, ancient tattoos and more: Books in brief",
    "title_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "url": "https://www.nature.com/articles/d41586-025-02556-0",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "source": "Nature"
  },
  {
    "title": "How animal paw pads got their toughness",
    "title_es": "How animal paw pads got their toughness",
    "url": "https://www.nature.com/articles/d41586-025-02474-1",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "How animal paw pads got their toughness",
    "source": "Nature"
  },
  {
    "title": "Can creativity in science be learnt? These researchers think so",
    "title_es": "Can creativity in science be learnt? These researchers think so",
    "url": "https://www.nature.com/articles/d41586-025-01913-3",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Can creativity in science be learnt? These researchers think so",
    "source": "Nature"
  },
  {
    "title": "Trump order gives political appointees vast powers over research grants",
    "title_es": "Trump order gives political appointees vast powers over research grants",
    "url": "https://www.nature.com/articles/d41586-025-02557-z",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Trump order gives political appointees vast powers over research grants",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: US researchers fight back on key climate report",
    "title_es": "Daily briefing: US researchers fight back on key climate report",
    "url": "https://www.nature.com/articles/d41586-025-02567-x",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Daily briefing: US researchers fight back on key climate report",
    "source": "Nature"
  },
  {
    "title": "Decolonize scientific institutions, don’t just diversify them",
    "title_es": "Decolonize scientific institutions, don’t just diversify them",
    "url": "https://www.nature.com/articles/d41586-025-02516-8",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "Decolonize scientific institutions, don’t just diversify them",
    "source": "Nature"
  },
  {
    "title": "A rude awakening",
    "title_es": "A rude awakening",
    "url": "https://www.nature.com/articles/d41586-025-02488-9",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "content_es": "A rude awakening",
    "source": "Nature"
  },
  {
    "title": "Roxie Laybourne, the first forensic ornithologist",
    "title_es": "Roxie Laybourne, the first forensic ornithologist",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx2662",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 582-582, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Revisiting the human sociobiology debate",
    "title_es": "Revisiting the human sociobiology debate",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady6081",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 580-581, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The membrane skeleton is constitutively remodeled in neurons by calcium signaling",
    "title_es": "The membrane skeleton is constitutively remodeled in neurons by calcium signaling",
    "url": "https://www.science.org/doi/abs/10.1126/science.adn6712",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice",
    "title_es": "Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp0240",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens",
    "title_es": "Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp0246",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli",
    "title_es": "An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp9583",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 618-622, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA",
    "title_es": "Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA",
    "url": "https://www.science.org/doi/abs/10.1126/science.ads3204",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth",
    "title_es": "Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu0043",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 637-643, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Imaging collective quantum fluctuations of the structure of a complex molecule",
    "title_es": "Imaging collective quantum fluctuations of the structure of a complex molecule",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu2637",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 650-654, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Single-photon detection enabled by negative differential conductivity in moiré superlattices",
    "title_es": "Single-photon detection enabled by negative differential conductivity in moiré superlattices",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu5329",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 644-649, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Three-dimensional nucleation and growth of deformation twins in magnesium",
    "title_es": "Three-dimensional nucleation and growth of deformation twins in magnesium",
    "url": "https://www.science.org/doi/abs/10.1126/science.adv3460",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 632-636, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing",
    "title_es": "Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing",
    "url": "https://www.science.org/doi/abs/10.1126/science.adt2741",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 623-631, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Predicting expression-altering promoter mutations with deep learning",
    "title_es": "Predicting expression-altering promoter mutations with deep learning",
    "url": "https://www.science.org/doi/abs/10.1126/science.ads7373",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "The multifunctional immune system",
    "title_es": "The multifunctional immune system",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea8294",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 586-587, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Immune system influence on physiology",
    "title_es": "Immune system influence on physiology",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4380",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 594-599, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Sex differences in tissue-specific immunity and immunology",
    "title_es": "Sex differences in tissue-specific immunity and immunology",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4381",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 599-603, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Convergence and divergence of individual immune responses over the life course",
    "title_es": "Convergence and divergence of individual immune responses over the life course",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady9543",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 604-609, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Evolution of antiviral host defenses against a backdrop of endogenous retroelements",
    "title_es": "Evolution of antiviral host defenses against a backdrop of endogenous retroelements",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4379",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 588-593, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "How a diagnosis altered my path",
    "title_es": "How a diagnosis altered my path",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb1444",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 658-658, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "In Other Journals",
    "title_es": "In Other Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2040",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 611-612, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Moiré eyes detect the dim",
    "title_es": "Moiré eyes detect the dim",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea5235",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 570-570, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Opening the gateway to food-induced anaphylaxis",
    "title_es": "Opening the gateway to food-induced anaphylaxis",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz6439",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 573-574, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Hardening nature’s toughest teeth",
    "title_es": "Hardening nature’s toughest teeth",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8241",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 568-569, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Improving Alzheimer’s disease immunotherapy",
    "title_es": "Improving Alzheimer’s disease immunotherapy",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8959",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 571-572, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "NextGen Voices: National Assessments in Verse",
    "title_es": "NextGen Voices: National Assessments in Verse",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2043",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Brazil’s dangerous environmental licensing bill",
    "title_es": "Brazil’s dangerous environmental licensing bill",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea7981",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 583-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Community support for inclusive US education",
    "title_es": "Community support for inclusive US education",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz3963",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Brazil’s “devastation bill” empowers criminals",
    "title_es": "Brazil’s “devastation bill” empowers criminals",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz7734",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 583-583, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Study used DNA from thousands—without consent",
    "title_es": "Study used DNA from thousands—without consent",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2395",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 552-553, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Senate panel rejects Trump’s plan to slash NIH’s budget",
    "title_es": "Senate panel rejects Trump’s plan to slash NIH’s budget",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2396",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 554-555, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Thank ketchup, and interbreeding, for your French fries",
    "title_es": "Thank ketchup, and interbreeding, for your French fries",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2397",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 556-556, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Study reveals industrial-scale publishing fraud",
    "title_es": "Study reveals industrial-scale publishing fraud",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2398",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 557-558, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "AI-generated text surges in research papers",
    "title_es": "AI-generated text surges in research papers",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2399",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 558-559, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Losing protection",
    "title_es": "Losing protection",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2041",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 560-567, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Census in crisis—further erasure of Indigenous Peoples?",
    "title_es": "Census in crisis—further erasure of Indigenous Peoples?",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea0932",
    "published": "2025-08-07T07:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "New Products",
    "title_es": "New Products",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb1446",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 655-655, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Quantum technology governance: A standards-first approach",
    "title_es": "Quantum technology governance: A standards-first approach",
    "url": "https://www.science.org/doi/abs/10.1126/science.adw0018",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 575-578, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "In Science Journals",
    "title_es": "In Science Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2039",
    "published": "2025-08-07T06:00:03.000Z",
    "date": "2025-08-07",
    "content_es": "Science, Volume 389, Issue 6760, Page 610-612, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Globally recognized island is losing its trademark glaciers",
    "title_es": "Globally recognized island is losing its trademark glaciers",
    "url": "https://www.nature.com/articles/d41586-025-02473-2",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Globally recognized island is losing its trademark glaciers",
    "source": "Nature"
  },
  {
    "title": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "title_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "url": "https://www.nature.com/articles/d41586-025-02505-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "source": "Nature"
  },
  {
    "title": "How researcher visa curbs threaten science careers",
    "title_es": "How researcher visa curbs threaten science careers",
    "url": "https://www.nature.com/articles/d41586-025-02293-4",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "How researcher visa curbs threaten science careers",
    "source": "Nature"
  },
  {
    "title": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "title_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "url": "https://www.nature.com/articles/d41586-025-02512-y",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "source": "Nature"
  },
  {
    "title": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "title_es": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "url": "https://www.nature.com/articles/d41586-025-02515-9",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "source": "Nature"
  },
  {
    "title": "These genes can have the opposite effects depending on which parent they came from",
    "title_es": "These genes can have the opposite effects depending on which parent they came from",
    "url": "https://www.nature.com/articles/d41586-025-02499-6",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "These genes can have the opposite effects depending on which parent they came from",
    "source": "Nature"
  },
  {
    "title": "Alien planet glimpsed in star's 'habitable zone'",
    "title_es": "Alien planet glimpsed in star's 'habitable zone'",
    "url": "https://www.nature.com/articles/d41586-025-02549-z",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Alien planet glimpsed in star's 'habitable zone'",
    "source": "Nature"
  },
  {
    "title": "Monoclonal antibodies revolutionized biomedical science and health care",
    "title_es": "Monoclonal antibodies revolutionized biomedical science and health care",
    "url": "https://www.nature.com/articles/d41586-025-02452-7",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Monoclonal antibodies revolutionized biomedical science and health care",
    "source": "Nature"
  },
  {
    "title": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "title_es": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "url": "https://www.nature.com/articles/d41586-025-02559-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "content_es": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "source": "Nature"
  },
  {
    "title": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "title_es": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "url": "https://www.nature.com/articles/s41586-025-09463-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "source": "Nature"
  },
  {
    "title": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "title_es": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "url": "https://www.nature.com/articles/s41586-025-09461-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "source": "Nature"
  },
  {
    "title": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "title_es": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "url": "https://www.nature.com/articles/s41586-025-09315-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "source": "Nature"
  },
  {
    "title": "Data anomalies and the economic commitment of climate change",
    "title_es": "Data anomalies and the economic commitment of climate change",
    "url": "https://www.nature.com/articles/s41586-025-09320-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Data anomalies and the economic commitment of climate change",
    "source": "Nature"
  },
  {
    "title": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "title_es": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "url": "https://www.nature.com/articles/s41586-025-09314-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "source": "Nature"
  },
  {
    "title": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "title_es": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "url": "https://www.nature.com/articles/s41586-025-09477-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "source": "Nature"
  },
  {
    "title": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "title_es": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "url": "https://www.nature.com/articles/s41586-025-09444-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "source": "Nature"
  },
  {
    "title": "The real problems with America's health",
    "title_es": "The real problems with America's health",
    "url": "https://www.nature.com/articles/d41586-025-02501-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "The real problems with America's health",
    "source": "Nature"
  },
  {
    "title": "Why did researchers stick a duck to a rock? To show off their super glue",
    "title_es": "Why did researchers stick a duck to a rock? To show off their super glue",
    "url": "https://www.nature.com/articles/d41586-025-02485-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Why did researchers stick a duck to a rock? To show off their super glue",
    "source": "Nature"
  },
  {
    "title": "Underwater glue shows its sticking power in rubber duck test",
    "title_es": "Underwater glue shows its sticking power in rubber duck test",
    "url": "https://www.nature.com/articles/d41586-025-02500-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Underwater glue shows its sticking power in rubber duck test",
    "source": "Nature"
  },
  {
    "title": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "title_es": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "url": "https://www.nature.com/articles/s41586-025-09272-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "source": "Nature"
  },
  {
    "title": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "title_es": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "url": "https://www.nature.com/articles/s41586-025-09329-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "source": "Nature"
  },
  {
    "title": "Hominins on Sulawesi during the Early Pleistocene",
    "title_es": "Hominins on Sulawesi during the Early Pleistocene",
    "url": "https://www.nature.com/articles/s41586-025-09348-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Hominins on Sulawesi during the Early Pleistocene",
    "source": "Nature"
  },
  {
    "title": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "title_es": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "url": "https://www.nature.com/articles/s41586-025-09310-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "source": "Nature"
  },
  {
    "title": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "title_es": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "url": "https://www.nature.com/articles/s41586-025-09379-z",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "source": "Nature"
  },
  {
    "title": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "title_es": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "url": "https://www.nature.com/articles/s41586-025-09362-8",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "source": "Nature"
  },
  {
    "title": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "title_es": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "url": "https://www.nature.com/articles/s41586-025-09299-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "source": "Nature"
  },
  {
    "title": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "title_es": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "url": "https://www.nature.com/articles/s41586-025-09306-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "source": "Nature"
  },
  {
    "title": "Structural basis of fast N-type inactivation in Kv channels",
    "title_es": "Structural basis of fast N-type inactivation in Kv channels",
    "url": "https://www.nature.com/articles/s41586-025-09339-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Structural basis of fast N-type inactivation in Kv channels",
    "source": "Nature"
  },
  {
    "title": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "title_es": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "url": "https://www.nature.com/articles/s41586-025-09372-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "source": "Nature"
  },
  {
    "title": "A diverse and distinct microbiome inside living trees",
    "title_es": "A diverse and distinct microbiome inside living trees",
    "url": "https://www.nature.com/articles/s41586-025-09316-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "A diverse and distinct microbiome inside living trees",
    "source": "Nature"
  },
  {
    "title": "Data-driven de novo design of super-adhesive hydrogels",
    "title_es": "Data-driven de novo design of super-adhesive hydrogels",
    "url": "https://www.nature.com/articles/s41586-025-09269-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Data-driven de novo design of super-adhesive hydrogels",
    "source": "Nature"
  },
  {
    "title": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "title_es": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "url": "https://www.nature.com/articles/s41586-025-09351-x",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "source": "Nature"
  },
  {
    "title": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "title_es": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "url": "https://www.nature.com/articles/s41586-025-09363-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "source": "Nature"
  },
  {
    "title": "Lithium deficiency and the onset of Alzheimer’s disease",
    "title_es": "Lithium deficiency and the onset of Alzheimer’s disease",
    "url": "https://www.nature.com/articles/s41586-025-09335-x",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Lithium deficiency and the onset of Alzheimer’s disease",
    "source": "Nature"
  },
  {
    "title": "A global humidity index with lateral hydrologic flows",
    "title_es": "A global humidity index with lateral hydrologic flows",
    "url": "https://www.nature.com/articles/s41586-025-09359-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "A global humidity index with lateral hydrologic flows",
    "source": "Nature"
  },
  {
    "title": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "title_es": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "url": "https://www.nature.com/articles/s41586-025-09378-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "source": "Nature"
  },
  {
    "title": "The science fiction science method",
    "title_es": "The science fiction science method",
    "url": "https://www.nature.com/articles/s41586-025-09194-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "The science fiction science method",
    "source": "Nature"
  },
  {
    "title": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "title_es": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "url": "https://www.nature.com/articles/s41586-025-09324-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "source": "Nature"
  },
  {
    "title": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "title_es": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "url": "https://www.nature.com/articles/s41586-025-09357-5",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "source": "Nature"
  },
  {
    "title": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "title_es": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "url": "https://www.nature.com/articles/s41586-025-09345-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "source": "Nature"
  },
  {
    "title": "The protein craze: scientists talk supplements — and who should take them",
    "title_es": "The protein craze: scientists talk supplements — and who should take them",
    "url": "https://www.nature.com/articles/d41586-025-02472-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "The protein craze: scientists talk supplements — and who should take them",
    "source": "Nature"
  },
  {
    "title": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "title_es": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "url": "https://www.nature.com/articles/d41586-025-02253-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "source": "Nature"
  },
  {
    "title": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "title_es": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "url": "https://www.nature.com/articles/d41586-025-02484-z",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "source": "Nature"
  },
  {
    "title": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "title_es": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "url": "https://www.nature.com/articles/d41586-025-02386-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "source": "Nature"
  },
  {
    "title": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "title_es": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "url": "https://www.nature.com/articles/d41586-025-02421-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "source": "Nature"
  },
  {
    "title": "Nuclear-weapons risks are back — and we need to act like it",
    "title_es": "Nuclear-weapons risks are back — and we need to act like it",
    "url": "https://www.nature.com/articles/d41586-025-02506-w",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Nuclear-weapons risks are back — and we need to act like it",
    "source": "Nature"
  },
  {
    "title": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "title_es": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "url": "https://www.nature.com/articles/d41586-025-02393-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "source": "Nature"
  },
  {
    "title": "The peer-review crisis: how to fix an overloaded system",
    "title_es": "The peer-review crisis: how to fix an overloaded system",
    "url": "https://www.nature.com/articles/d41586-025-02457-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "The peer-review crisis: how to fix an overloaded system",
    "source": "Nature"
  },
  {
    "title": "Ancient marine reptile was a silent swimmer",
    "title_es": "Ancient marine reptile was a silent swimmer",
    "url": "https://www.nature.com/articles/d41586-025-02464-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "Ancient marine reptile was a silent swimmer",
    "source": "Nature"
  },
  {
    "title": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "title_es": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "url": "https://www.cnic.es/es/node/235736",
    "published": "2025-08-01T12:08:23.000Z",
    "date": "2025-08-01",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDr. Claudia Monaco, Kennedy Institute of Rheumatology, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, University of Oxford, UK\n\n\n\nClaudia Monacoo trained as a cardiologist and PhD with Professor Attilio Maseri at the Catholic University of Rome, Italy, before moving to the Kennedy Institute of Rheumatology, Imperial College London to work with Professor Marc Feldmann. She moved to the University of Oxford in 2011, where she became Professor of Cardiovascular Inflammation. Her group was the first to establish innovative experimental methodology for the isolation, culture and targeting of live cells from human atheroma lesions. Her work allowed the elegant characterization of the inflammatory and synthetic properties of human atherosclerosis, establishing toll-like receptors as important activators of innate immunity in atherosclerosis. The Cardiovascular Inflammation Team is now focused on interpreting the functional diversity of immune cells in atherosclerosis with single cell biology techniques and devise strategies for their selective targeting.\n\nWhat is the role of macrophages in the development of atherosclerosis, and how has our understanding of their function evolved?\n\nWe are focused, in particular, on macrophages and what their function is in atherosclerosis. I think it’s quite interesting, because different types of macrophages have different functions in the development of atherosclerosis. Before, we thought that all macrophages were bad—that all macrophages and the whole immune system were actually promoting atherosclerosis. But now we know the picture is much more complex than that.\nIt’s very related to what macrophages are, where they’re seeded, and how they establish themselves in specific niches. There are some macrophages, like the lipid-associated macrophages, that definitely promote disease. But there are others—vascular macrophages that are already present within the vessel wall—that actually act like guardians of the artery and are protective.\nI think it’s very important—this direction we’re going in, toward more targeted therapies. The idea is not to block all macrophages, because some are actually your friends. You need to look after them, especially the ones in the artery, while others are really pushing things toward a dangerous, disease-promoting path. This duality is really important, especially from a therapeutic perspective. That’s why we’re so fixated on understanding this better.\n\nAnd how can you tell the difference between the “good” macrophages and the ones you want to block? What kind of techniques do you use?\n\nWe use single-cell biology a lot. We’re not yet in the clinical space, but we’ve identified good markers. If those markers prove reliable, it would be easy to translate this into new tools to look at different macrophages in vivo. There’s also the potential to tailor imaging—not just therapeutics, but also how we visualize these macrophages.\nThe key idea we want to get across is that there isn’t just “one” macrophage type. We always said that macrophages are very pleiotropic—that they can take on different phenotypes—but that didn’t always seem to matter because we thought they all eventually just changed into each other. But actually, that’s not quite true.\nThere is some dynamic flexibility, yes, but it's quite reproducible which path they take. They really adapt specifically to their environment. For example, in the adventitia, they adopt a very specific phenotype, and in the intima, a different one. And these phenotypes remain pretty stable during atherosclerosis, and also in health and disease. They’re not just switching randomly between states, they’re adapting in a niche-specific way, just like cells in any other organ. That’s important because it means we can start visualizing and treating patients differently more precisely.\n\nYou mentioned you're still in the experimental phase and not yet in clinical trials. How far is immunotherapy for cardiovascular disease?\n\nI think there have been some early trials, and there are more and more now that are targeting inflammation in atherosclerosis. It’s really a booming field. We waited a long time to get here. The field was slow to move in this direction because so much focus was on lowering cholesterol, which is of course important—but inflammation wasn’t really explored until recently.\nStudies like the CANTOS trial and others have started targeting cytokines, and I think we are going in the right direction. But progress is still very slow. One big reason is the lack of imaging tools. Imaging is only now reaching the level where we can maybe use it instead of relying on hard cardiovascular outcomes in trials.\nIf you look at cancer, for example, you can track things much faster, look at the size of the tumor, and see how the patient is responding. Same for diseases like rheumatoid arthritis, where you can scan the joints or use PET imaging. Those imaging methods have been around for decades, and they’ve made it possible to run smaller trials that are either based on imaging or give you very clear, early outcomes.\nBut with cardiovascular disease, we still have to look at how patients are doing over 5, 10 years. That’s a big challenge. These trials are very expensive, especially because biologic drugs cost so much. So pharmaceutical companies need to make a huge financial commitment. The more we can improve imaging, the more we’ll be able to run meaningful trials that evaluate new biologics or targeted agents, like nanotechnology-based ones.\nI think evolution isn’t just about immunology, it’s also about how we study this in the real world. Other fields can run smaller trials to understand how things work and then move on to larger outcome trials. But here, with trials like the CANTOS trial—which involved over 10,000 patients and a very expensive biologic—that kind of scale is almost unheard of in other diseases like rheumatoid arthritis.\nSo yes, the challenges are really at the clinical stage—how we bring all this incredible knowledge about the immune system into cardiovascular medicine. The real barrier is economic.\n\nYou’re a cardiologist—you worked in Rome for many years, and then you moved to Oxford. You trained as a cardiologist, and then you also shifted into doing experiments and research. How do you combine these two areas?\n\nWell, combining clinical duties and research is one of the biggest challenges you can attempt to do.  I think if you’re doing clinical research—like outcomes-based research or imaging studies—then it’s easier to combine with clinical work. But if you’re developing science at the molecular level, it’s much harder to do both. At least I couldn’t manage it as well as I would have liked.\nThere’s a big divide between what we think we know and what we actually know. We have this concept of how atherosclerosis develops, how the immune system contributes—but in reality, we don’t really understand the specific mechanisms at play. I felt that, to bridge this gap, I had to go back to the basics. That meant not only using experimental models but also working with human samples. I saw a huge opportunity in single-cell biology has been a big opportunity—for all of us—to understand human immunology at a very detailed level. Because if we only look at mice, then the gap between mouse and human, and then from preclinical to clinical stages, is massive.\nFor example, we really need access to human vascular tissue. But as cardiologists, we’ve moved so much toward percutaneous approaches to the coronary arteries, so we don’t actually remove them anymore. That’s why I work a lot with vascular surgeons. They still operate in a way that allows us to obtain human tissue—but that might not last. Even vascular surgery is moving more and more toward stenting, which means we’ll eventually lose the ability to get that tissue. We have this narrow window of opportunity where we can still work with tissue from patients, and I felt I had to take it. I’m very vocal about this having a short window before vascular surgery becomes entirely percutaneous, \n\nIt seems like improvements in clinical treatment are making things harder for basic science in a way.\n\nExactly. It’s advancing, but at the same time, it means that now we have this critical window. I always say vascular surgeons do research, collect tissue, because we need to analyze what the cells are really doing. Just relying on blood studies, on systemic inflammation, doesn’t tell us much about what’s happening in the atherosclerotic artery. The immune cells inside the artery are very different in their programming compared to circulating cells in the blood.\nMost cells come from the blood—but there are also some embryonic macrophages that form inside the artery and never circulate. And even the ones that come from the blood and stay in the artery for 10 years, they acquire very specialized instructions. You can take monocytes from blood and run as many blood tests as you want—but that doesn’t tell you what’s actually happening inside the artery.\nThey behave differently, they look different, they’ve changed their shape and function completely. This creates a gap in what we can understand—it seems like we’re missing something in these studies . We can’t see all the different effects a drug might have if we only look at peripheral blood. I think the real answers are also in the vascular tissue, in the atherosclerotic plaque itself. We need to go as close to the source as possible—to find real targets, and to see the real effects of drugs on atherosclerotic tissue.\nBecause a lot of clinical trials have targeted systemic inflammation. But that’s not the same as inflammation within the plaque. The drivers of plaque inflammation may be different.\nWe know systemic inflammation is a risk factor, yes, but what you see in the blood isn’t necessarily what’s happening in the plaque. We often assume it is—because it’s convenient. But in cardiovascular disease, especially cardiology, we never actually look at the plaque. We look at the lumen. Intravascular ultrasound (IVUS) is the only way to get a glimpse of the arterial wall. Experimentally, we might look at blood from the heart in very complex ways—but we’re still mainly looking at circulating markers. We’re not really studying the tissue itself.\n\n\nAs a cardiologist with experience of treating patients, do you think your clinical background influences the kinds of research questions you ask?\n\nYes. And there are two things that help me a lot, I think. And that’s why I never stop clinics, even though they told me several times to stop clinics. I think I... I don’t like to stop the clinics because I enjoy that interaction.\nI think, being a scientist, your rewards are very long-term. If you’re a doctor, the rewards are quite immediate, because the patient is happier, yes—you can give the treatment. So, I think it gives me a lot of motivation to serve the patient. But at the same time, I think research is also a good way to serve patients.\nBecause as a clinician I’ve learned a lot from basic scientists. They’re much better at developing techniques at the bench, and so I have great respect for my scientific colleagues. But sometimes, as a clinician, you can see what really matters. And it makes you particularly attached to a specific disease, you know? Basic scientists are sometimes across fields. This study gives me the determination and the drive to really try and solve atherosclerosis.",
    "source": "CNIC"
  },
  {
    "title": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "title_es": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "url": "https://www.cnic.es/es/noticias/dra-claudia-monaco-enfermedades-cardiovasculares-pensamos-que-sabemos-mucho-pero-realidad",
    "published": "2025-08-01T11:49:01.000Z",
    "date": "2025-08-01",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDra. Claudia Monaco:  Instituto Kennedy de Reumatología, Departamento Nuffield de Ortopedia, Reumatología y Ciencias Musculoesqueléticas, Universidad de Oxford, Reino Unido\n\n\n\nClaudia Monaco se formó como cardióloga y doctoró con el profesor Attilio Maseri en la Universidad Católica de Roma, Italia, antes de trasladarse al Instituto Kennedy de Reumatología del Imperial College de Londres para trabajar con el profesor Marc Feldmann. En 2011 se trasladó a la Universidad de Oxford, donde se convirtió en profesora de Inflamación Cardiovascular. Su grupo fue el primero en establecer una metodología experimental innovadora para el aislamiento, cultivo y selección de células vivas de lesiones ateromatosas humanas. Su trabajo permitió caracterizar de forma elegante las propiedades inflamatorias y sintéticas de la aterosclerosis humana, estableciendo los receptores toll-like como activadores importantes de la inmunidad innata en la aterosclerosis. Su grupo de inflamación cardiovascular se centra ahora en interpretar la diversidad funcional de las células inmunitarias en la aterosclerosis con técnicas de biología celular única y en diseñar estrategias para su selección selectiva.\n\n¿Cuál es el papel de los macrófagos en el desarrollo de la aterosclerosis y cómo ha evolucionado nuestra comprensión de su función?\n\nNos centramos, en particular, en los macrófagos y en cuál es su función en la aterosclerosis. Es muy interesante porque los diferentes tipos de macrófagos tienen diferentes funciones en el desarrollo de la aterosclerosis. Antes pensábamos que todos los macrófagos eran malos, que todos los macrófagos y todo el sistema inmunitario favorecían la aterosclerosis. Pero ahora sabemos que el panorama es mucho más complejo.\nEstá muy relacionado con lo que son los macrófagos, dónde se siembran y cómo se establecen en nichos específicos. Hay algunos macrófagos, como los macrófagos asociados a los lípidos, que sin duda favorecen la enfermedad. Pero hay otros, los macrófagos vasculares que ya están presentes en la pared de los vasos, que en realidad actúan como guardianes de la arteria y la protegen.\nCreo que es muy importante la dirección que estamos tomando, hacia terapias más específicas. La idea no es bloquear todos los macrófagos, porque algunos son realmente nuestros aliados. Hay que cuidarlos, especialmente los que se encuentran en las arterias, mientras que otros realmente empujan hacia un camino peligroso que favorece la enfermedad. Esta dualidad es muy importante, especialmente desde el punto de vista terapéutico. Por eso estamos tan obsesionadas con comprenderlo mejor.\n\n¿Cómo se puede distinguir entre los macrófagos «buenos» y los que se quieren bloquear? ¿Qué tipo de técnicas se utilizan?\n\nUtilizamos mucho la biología unicelular. Aún no estamos en el ámbito clínico, pero hemos identificado buenos marcadores. Si esos marcadores resultan fiables, sería fácil traducirlos en nuevas herramientas para observar diferentes macrófagos in vivo. También existe la posibilidad de adaptar las imágenes, no solo las terapéuticas, sino también la forma en que visualizamos estos macrófagos.\nLa idea clave que queremos transmitir es que no existe un único tipo de macrófago. Siempre hemos dicho que los macrófagos son muy pleiotrópicos, es decir, que pueden adoptar diferentes fenotipos, pero eso no siempre parecía importar porque pensábamos que, al final, todos se transformaban unos en otros. Pero, en realidad, eso no es del todo cierto.\nHay cierta flexibilidad dinámica, sí, pero la trayectoria que siguen es bastante reproducible. Se adaptan específicamente a su entorno. Por ejemplo, en la adventicia adoptan un fenotipo muy específico, y en la íntima, otro diferente. Y estos fenotipos se mantienen bastante estables durante la aterosclerosis, así como en la salud y la enfermedad. No cambian aleatoriamente entre estados, sino que se adaptan de forma específica a cada nicho, al igual que las células de cualquier otro órgano. Esto es importante porque significa que podemos empezar a visualizar y tratar a los pacientes de forma diferente y más precisa.\n\nHa mencionado que aún se encuentra en la fase experimental y que aún no se han realizado ensayos clínicos. ¿En qué punto se encuentra la inmunoterapia para las enfermedades cardiovasculares?\n\nCreo que se han realizado algunos ensayos preliminares y ahora hay cada vez más estudios que se centran en la inflamación en la aterosclerosis. Es un campo en auge. Hemos esperado mucho tiempo para llegar hasta aquí. El campo tardó en avanzar en esta dirección porque se prestaba mucha atención a la reducción del colesterol, lo cual es importante, por supuesto, pero la inflamación no se ha explorado realmente hasta hace poco.\nEstudios como el ensayo CANTOS y otros han comenzado a centrarse en las citocinas, y creo que vamos en la dirección correcta. Pero el progreso sigue siendo muy lento. Una de las principales razones es la falta de herramientas de imagen. Las técnicas de imagen están alcanzando ahora un nivel en el que quizá podamos utilizarlas en lugar de basarnos en los resultados cardiovasculares de los ensayos.\nSi nos fijamos en el cáncer, por ejemplo, se puede hacer un seguimiento mucho más rápido, observar el tamaño del tumor y ver cómo responde el paciente. Lo mismo ocurre con enfermedades como la artritis reumatoide, en las que se pueden escanear las articulaciones o utilizar imágenes PET. Estos métodos de imagen llevan décadas utilizándose y han permitido realizar ensayos más pequeños basados en imágenes o que ofrecen resultados muy claros y tempranos.\nSin embargo, en el caso de las enfermedades cardiovasculares, todavía tenemos que observar cómo evolucionan los pacientes a lo largo de 5 o 10 años. Eso supone un gran reto. Estos ensayos son muy caros, sobre todo porque los medicamentos biológicos cuestan mucho. Por lo tanto, las empresas farmacéuticas deben asumir un enorme compromiso financiero. Cuanto más mejoremos las imágenes, más podremos realizar ensayos significativos que evalúen nuevos productos biológicos o agentes dirigidos, como los basados en la nanotecnología.\nCreo que la evolución no se limita a la inmunología, sino que también tiene que ver con cómo estudiamos esto en el mundo real. Otros campos pueden realizar ensayos más pequeños para comprender cómo funcionan las cosas y luego pasar a ensayos de resultados más amplios. Pero aquí, con ensayos como el CANTOS, en el que participaron más de 10.000 pacientes y se utilizó un fármaco biológico muy caro, ese tipo de escala es casi inaudito en otras enfermedades como la artritis reumatoide.\nAsí que sí, los retos se encuentran realmente en la fase clínica: cómo trasladar todos estos increíbles conocimientos sobre el sistema inmunitario a la medicina cardiovascular. La verdadera barrera es económica.\n\nUsted es cardióloga, trabajó en Roma durante muchos años y luego se trasladó a Oxford. Se formó como cardióloga y luego también pasó a dedicarse a la experimentación y la investigación. ¿Cómo combina estas dos áreas?\n\nCombinar las tareas clínicas y la investigación es uno de los mayores retos a los que te puedes enfrentar.  Creo que, si una se dedica a la investigación clínica, como la investigación basada en resultados o los estudios de imagen, es más fácil combinarla con el trabajo clínico. Pero si se trabaja más en el desarrollo científico a nivel molecular, es mucho más difícil compaginar ambas cosas. Al menos yo no pude hacerlo tan bien como me hubiera gustado.\n Existe una gran diferencia entre lo que creemos saber y lo que realmente sabemos. Tenemos una idea de cómo se desarrolla la aterosclerosis, cómo contribuye el sistema inmunitario, pero en realidad no entendemos los mecanismos específicos que intervienen. Sentí que, para salvar esta brecha, tenía que volver a lo básico. Eso significaba no solo utilizar modelos experimentales, sino también trabajar con muestras humanas. Vi una gran oportunidad en la biología de células individuales, que ha sido una gran oportunidad para todos nosotros para comprender la inmunología humana a un nivel muy detallado. Porque si solo nos fijamos en los ratones, la brecha entre estos y los seres humanos, y luego entre las etapas preclínicas y clínicas, es enorme.\nPor ejemplo, realmente necesitamos acceso al tejido vascular humano. Pero como cardiólogos, hemos avanzado tanto hacia los abordajes percutáneos de las arterias coronarias que ya no las extirpamos. Por eso trabajo mucho con cirujanos vasculares. Ellos siguen operando de una manera que nos permite obtener tejido humano, pero eso podría no durar mucho tiempo. Incluso la cirugía vascular se está orientando cada vez más hacia la implantación de stents, lo que significa que, con el tiempo, perderemos la capacidad de obtener ese tejido. Tenemos una ventana de oportunidad muy estrecha en la que todavía podemos trabajar con tejido de pacientes, y sentí que tenía que aprovecharla. Soy muy clara al afirmar que tenemos poco tiempo antes de que la cirugía vascular se vuelva completamente percutánea, lo que, por supuesto, es un avance, pero también nos priva de la oportunidad de estudiar tejidos humanos reales.\n\nParece que las mejoras en el tratamiento clínico están dificultando en cierto modo la ciencia básica.\n\nExactamente. Está avanzando, pero al mismo tiempo significa que ahora tenemos esta ventana crítica. Siempre digo que los cirujanos vasculares investigan y recogen tejido porque necesitamos analizar lo que realmente hacen las células. Basarnos únicamente en los análisis de sangre y en la inflamación sistémica no nos dice mucho sobre lo que está sucediendo en la arteria aterosclerótica. Las células inmunitarias del interior de la arteria son muy diferentes en su programación en comparación con las células circulantes en la sangre.\nLa mayoría de las células provienen de la sangre, pero también hay algunos macrófagos embrionarios que se forman dentro de la arteria y nunca circulan. E incluso los que provienen de la sangre y permanecen en la arteria durante 10 años, adquieren instrucciones muy especializadas. Se pueden extraer monocitos de la sangre y realizar tantos análisis de sangre como se desee, pero eso no revela lo que realmente ocurre dentro de la arteria.\nSe comportan de manera diferente, tienen un aspecto diferente, han cambiado completamente su forma y función. Esto crea una brecha en lo que podemos entender, parece que nos estamos perdiendo algo en estos estudios. No podemos ver todos los diferentes efectos que puede tener un fármaco si solo miramos la sangre periférica. Creo que las respuestas reales también se encuentran en el tejido vascular, en la propia placa aterosclerótica. Tenemos que acercarnos lo más posible a la fuente para encontrar los objetivos reales y ver los efectos reales de los fármacos en el tejido aterosclerótico.\nPorque muchos ensayos clínicos se han centrado en la inflamación sistémica. Pero eso no es lo mismo que la inflamación dentro de la placa. Los factores que provocan la inflamación de la placa pueden ser diferentes.\nSabemos que la inflamación sistémica es un factor de riesgo, sí, pero lo que se ve en la sangre no es necesariamente lo que ocurre en la placa. A menudo asumimos que lo es, porque es conveniente. Pero en las enfermedades cardiovasculares, especialmente en cardiología, nunca miramos realmente la placa. Miramos la luz. La ecografía intravascular (IVUS) es la única forma de echar un vistazo a la pared arterial.\nDesde el punto de vista experimental, podemos analizar la sangre del corazón de formas muy complejas, pero seguimos centrándonos principalmente en los marcadores circulantes. En realidad, no estamos estudiando el tejido en sí.\n\nComo cardióloga con experiencia en el tratamiento de pacientes, ¿cree que su experiencia clínica influye en el tipo de preguntas de investigación que se plantea?\n\nSí. Y hay dos cosas que me ayudan mucho. Por eso nunca dejo de ejercer en la clínica, aunque me han dicho varias veces que lo haga. Creo que... no me gusta dejar la clínica porque disfruto de esa interacción.\nComo científica, las recompensas son a muy largo plazo. Si eres médico, las recompensas son bastante inmediatas, porque el paciente está más contento si puedes darle el tratamiento. Por lo tanto, creo que me motiva mucho atender al paciente. Pero, al mismo tiempo, pienso que la investigación también es una buena forma de atender a los pacientes.\nPorque, como médico, he aprendido mucho de los científicos básicos. Son mucho mejores desarrollando técnicas en el laboratorio, por lo que siento un gran respeto por mis colegas científicos. Pero a veces, como médico clínico, puedes ver lo que realmente importa. Y eso te hace sentir especialmente vinculado a una enfermedad concreta. Los científicos básicos a veces abarcan varios campos. Este estudio me da la determinación y el impulso para intentar resolver realmente la aterosclerosis.\n\n\n¿De niña, se imaginó dedicándose a la ciencia o la medicina y, finalmente, a la investigación?\n\nSiempre quise ser médico. De niña era un poco enfermiza, así que probablemente estuve muy expuesta al entorno médico. Por eso, siempre decía que quería ser médico. Pero luego decepcioné a mi padre a largo plazo, porque él pensaba que me convertiría en médico, no sé, un médico generalista, y así podría tenerme muy cerca de su casa. Pero en cambio, mi carrera me llevó al extranjero. No creo que él estuviera muy contento con mi marcha.\nEn particular, cuando era joven no quería ser científica. Me fascinaban los médicos. Probablemente tenía ese sentido de ayudar a la gente, de servir a la gente. Para mí eso es muy importante. Aprendí todo sobre cardiología en Italia, con el profesor Attilio Maseri, que fue un gran precursor en este campo: la activación de las células inmunitarias, especialmente en el síndrome coronario agudo. Aprendí mucho de él y sigo llevando esa huella en mi trabajo.\nTambién trabajé con otros buenos mentores en el Reino Unido, como el profesor Mark Feldman, y aprendí mucho de él sobre el sistema inmunitario y cómo detener la inflamación. Hago todo lo posible por seguir los pasos de estos dos gigantes para comprender el funcionamiento del sistema inmunitario en las arterias, tanto en la salud como en la enfermedad.\nMe encuentro en un entorno de reumatología e inmunología que también realiza investigaciones cardiovasculares. Puedo permanecer entre ambos campos, lo que me beneficia enormemente, ya que siempre estoy en la interfaz entre los inmunólogos y los especialistas cardiovasculares. Y creo que esto es algo bastante único. Es bastante difícil de replicar en todas partes.\nAhora, la inmunología cardiovascular se está consolidando cada vez más y habrá cada vez más interfaces de este tipo. Como la que hay aquí, en el CNIC, donde hay más interfaces de este tipo. Así que todo esto se está formando. Este es el futuro.\nCuando empecé, no se podía hacer esta combinación en ningún sitio. Por lo tanto, mis opciones estaban bastante limitadas. Ahora, tal vez podría plantearme mudarme a algún lugar de Europa, Estados Unidos, volver a Italia, si hay una estructura de financiación que permita el mismo nivel. Pero, por supuesto, ya sabes, en este momento hay problemas con la financiación en todos los países. Así que es un poco optimista. No iría a Italia solo por ir a Italia. El trabajo es muy importante para mí y necesito tener la combinación adecuada para mudarme a cualquier lugar.\n\nQuizás, primero podría venir aquí para investigar en el CNIC.\n\nSí, exactamente. ¿Por qué no? ¿Por qué no?\n\nHa mencionado que ha tenido muy buenos mentores en su carrera, y supongo que todavía los tiene. Pero ahora también asume esa función de mentoría con los estudiantes en su laboratorio. Entonces, ¿qué diferencias encuentra entre cuando era joven y estos jóvenes estudiantes de hoy?\n\nEsta es una pregunta difícil, porque es una pregunta en la que se pueden tomar dos caminos completamente diferentes. Uno sería: antes trabajábamos mucho más duro, y eso me molesta. No me agradan las personas que siguen ese camino. No me gusta decirlo, pero al final yo también lo sigo: antes nos quedábamos en el laboratorio hasta tarde...\nCreo que los nuevos estudiantes tienen una capacidad mucho mayor. Las nuevas generaciones son más completas en el sentido de que no quieren perderse por completo en el trabajo o la investigación, y creo que esto es algo positivo para sus vidas, sin duda. Considero que ese cambio es muy importante. Quizás porque en Oxford existe la tradición de que hay que tener una vida social en la universidad. Organizan actividades. Intentan crear un entorno en el que los estudiantes, incluso los de posgrado, puedan socializar si lo desean. Me gusta esa cultura. Y esto es típico de Oxford, y me encanta.\nPorque pueden hacer muchas cosas que yo no hice. Ya sabes, en nuestra época, existía la idea de que había que negarse a uno mismo, dedicarse a la disciplina sin límites, y creo que eso no es bueno a largo plazo.\nPero yo diría que las nuevas generaciones suelen conocer muy bien su tema, pero quizá no amplían sus horizontes tanto como deberían, no sienten curiosidad por otras disciplinas. Y yo lucho mucho contra eso. Ya sabes, se meten de lleno en su área, obtienen el doctorado, hacen la defensa de la tesis y solo saben eso. Ahora hay muchas áreas de interés a nuestro alcance. Probablemente, como consecuencia, perdieron muchas cosas. Pero siempre intento decirles que es importante ver cómo evolucionan otros campos. Quizás haya una idea que necesites. Quizás haya un camino que no habías pensado, pero que es importante en el cáncer y quizás también lo sea en las enfermedades cardiovasculares.\nSiempre pienso que, si estás en la interfaz entre dos campos, avanzas más rápido. Porque puedes aprender, otros colegas pueden inspirarte. Así que no te fijes solo en lo tuyo.\nY otra cosa que siempre les digo es que creo que, en las enfermedades cardiovasculares, pensamos que sabemos mucho. Pero en realidad, no es así. Y siempre tenemos que revisar las pruebas.\n\nEs posible que tengan una nueva forma, diferente, de ver sus vidas y sus carreras.\n\nSí, pero también, incluso en el campo del conocimiento de la aterosclerosis, siempre enseñamos a los estudiantes: así es como evoluciona la aterosclerosis. En realidad, las pruebas para nuestro modelo siempre son muy dispersas. Porque pueden estar en ratones o en otro sistema. Pero cómo es en los seres humanos, realmente no lo sabemos. Así que estad siempre preparados para cuestionar vuestras suposiciones. No sigáis siempre lo que os dicen los demás. Debéis tener vuestras propias ideas. Y siempre tenéis que desafiar el paradigma.",
    "source": "CNIC"
  },
  {
    "title": "The Columbia deal is a tragic wake-up call",
    "title_es": "The Columbia deal is a tragic wake-up call",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb0424",
    "published": "2025-07-31T06:00:37.000Z",
    "date": "2025-07-31",
    "content_es": "Science, Volume 389, Issue 6760, Page 551-551, August 2025.",
    "source": "Science.org"
  },
  {
    "title": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "title_es": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "url": "https://www.cnio.es/noticias/un-investigador-del-cnio-desarrolla-una-prueba-capaz-de-detectar-tumores-en-estadios-iniciales-con-una-muestra-de-sangre/",
    "published": "2025-07-31T10:48:44.000Z",
    "date": "2025-07-31",
    "content_es": "Los métodos actuales para diagnosticar el cáncer se basan en identificar marcadores –moléculas que indican un estado o proceso determinado del organismo– que provienen del tumor o de proteínas asociadas a él. Como es lógico, esos marcadores son más abundantes cuando el tumor ya se ha desarrollado de forma significativa. Y, cuanto más avanzado el […]\nLa entrada Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "CNIC en la Noche Europea de los Investigadores 2025",
    "title_es": "CNIC en la Noche Europea de los Investigadores 2025",
    "url": "https://www.cnic.es/es/noticias/cnic-noche-europea-investigadores-2025",
    "published": "2025-07-17T22:35:42.000Z",
    "date": "2025-07-17",
    "content_es": "14/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nVen al CNIC el próximo viernes 26 de septiembre con motivo de la XVI Noche Europea de los Investigadores de Madrid. Podrás participar en distintas actividades que te acercarán a la investigación que se realiza en el centro.\nLa Noche Europea de los Investigadores en el CNIC es una oportunidad de sumergirte en el emocionante mundo de la ciencia y la innovación. Desde experimentos asombrosos hasta conferencias inspiradoras, CNIC te brindará una ventana a los descubrimientos más recientes y las maravillas de la tecnología.\nPara asistir es necesario inscribirse en el siguiente link: https://www.cnic.es/es/solicitud-inscripcion-xvi-noche-europea-investigadores \nLa inscripción se abre el lunes 15 de septiembre a partir de las 9:00 hrs.\nTodas las actividades se llevarán a cabo en el Centro Nacional de Investigaciones Cardiovasculares (CNIC): C. de Melchor Fernández Almagro, 3, 28029 Madrid.\nInformación actividades:\n10:30 - 12:30 h. Enfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nPúblico: juvenil (desde 12 años) y adultos.\nEl principal objetivo de esta actividad es sensibilizar sobre los muchos desafíos que enfrentan los pacientes con enfermedades raras, y explicar cómo la investigación básica, utilizando modelos animales adecuados, es esencial para avanzar en la comprensión de estas enfermedades y encontrar terapias potenciales que permitan aliviar o curar a estos pacientes. Con este propósito, se organizan dos actividades: una charla de divulgación en lenguaje accesible; y una demostración en el laboratorio que permitirá a las personas participantes familiarizarse con técnicas utilizadas rutinariamente en la investigación básica para responder preguntas científicas relevantes en el estudio de enfermedades raras.\n10:30 - 13:30 h. ¿Cómo late nuestro corazón? Grupo: Silvia Priori.\nPúblico: juvenil (desde 12 años) y adultos.\nEsta actividad tiene como objetivo explicar cómo late el corazón, desde el nivel subcelular hasta el órgano completo, así como el desarrollo de una arritmia cardíaca dependiente del calcio. Estos temas se explicarán de forma sencilla y amena para que las personas participantes los conozcan de la mano de nuestras investigadoras e investigadores.  \n12:00 - 13:30 h. ¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\nPúblico: juvenil (14-18 años).\nLas personas participantes en esta actividad tendrán la oportunidad de conocer la relación entre el cáncer y el corazón desde el acercamiento al proyecto de investigación RESILIENCE, destinado a mejorar la vida de los pacientes con cáncer. La actividad consistirá en un workshop donde las personas participantes conocerán la aplicación de la tecnología (resonancia magnética cardíaca, ecocardiografía y tomografía cardíaca) y la innovación en este ensayo clínico, así como una mesa redonda donde se compartirán experiencias y se resolverán dudas.\n14:30 - 16:00 h. ¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\nPúblico: infantil (6 – 12 años).\nSe realizará una pequeña presentación sobre las diferencias de flujo sanguíneo laminar y oscilatorio en el contexto de aterosclerosis (con nuestros personajes de dibujos LAMI y OSCI); se hará un juego con preguntas básicas sobre la presentación donde las personas participantes ganarán piezas para montar su propia máquina de flujo laminar y oscilatorio; y habrá una demostración con una adaptación similar de las máquinas que se usan en el laboratorio para estimular las células a los dos tipos de flujo, con el uso de colorante alimentario y purpurina para que se puedan ver los diferentes patrones.\nDos turnos: 11:00-11:45 h (turno 1), 11:45-12.30 h (turno 2).   \n16:00 - 17:30 h. Taller de extracción de ADN. Grupo: Enrique Lara\nPúblico: infantil (8 – 12 años).\n¿Alguna vez te has preguntado qué podéis tener en común los plátanos y tú? ¡Los dos tenéis ADN! Os presentamos una actividad rápida, fácil y divertida, en la que vais a aprender a extraer el ADN de un plátano. Para ello usaremos ingredientes que cualquiera de vosotros tenéis en casa, así podéis sorprender al resto de la familia montando un pequeño laboratorio y ejerciendo de investigadores, ¿estáis dispuestos?\nTres turnos: 16:00 - 16:30 h (Turno 1), 16:30 - 17:00 h (Turno 2), 17:00 - 17:30 h (Turno 3).\n16:00 - 18:00 h. Modelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nPúblico: Infantil (desde 6 años), juvenil y adultos.\nEsta actividad comenzará con una breve charla introductoria para seguir con la preparación de áreas temáticas en el laboratorio especializadas en una cardiopatía congénita concreta, donde se explicarán en detalle sus rasgos morfológicos y cómo afectan a la salud humana. Las personas participantes realizarán una tinción histológica en la que podrán observar corazones de ratón y observarán, de manera práctica, las malformaciones explicadas en la charla de introducción. Con esto esperamos acercar a grandes rasgos lo que se hace en el laboratorio y la relevancia de la investigación básica y traslacional en el contexto de la cardiología.\n16:30 - 18:00 h. Cuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nPúblico: juvenil (desde 15 años) y adultos.\nEsta actividad consta de dos partes. Una primera en la que se les dará a las personas que participan una charla divulgativa adaptada a la edad del público, en la que se expondrá la importancia de los factores de riesgo cardiovasculares en el desarrollo de ciertas patologías relacionadas con el cerebro, así como el ictus o demencias. Posteriormente tendrá lugar una visita guiada en pequeños grupos al laboratorio del grupo donde se mostrarán diferentes técnicas empleadas de rutina en un laboratorio de neurociencia.\n17:00 - 18:00 h. El escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nPúblico: juvenil (desde 12 años) y adultos.\nEn este escape room científico, las personas participantes deberán usar su ingenio para resolver pruebas, enigmas o puzles y abrir un candado. Si lo logran, ¡descubrirán el secreto de la PCR y ganarán una recompensa final! De esta manera, a través de retos colaborativos inspirados en la biología molecular, las personas que jueguen aprenden conceptos clave de genética en un entorno lúdico y educativo.\n17:00 - 19:00 h. Da color a tu plato: convierte a tu corazón en un superhéroe con ritmo: Grupos: José Antonio Enríquez y David Sancho.\nPúblico: infantil (6-12 años).\nEn esta actividad interactiva se construirá un estetoscopio con materiales simples y reciclados (globos, tubos de plástico y botellas usadas), que las personas participantes podrán llevarse a casa. Con él, exploraremos cómo suena nuestro propio corazón, aprendiendo de manera directa y divertida sobre el ritmo cardíaco en condiciones de reposo y después del ejercicio, así como su importancia para la salud. Posteriormente se visualizará en una maqueta humana de poliespán a tamaño real cómo es nuestro sistema circulatorio, cómo la sangre llega a nuestro corazón y cómo alteraciones de la circulación pueden ocasionar ciertas patologías, como es la ateroesclerosis. También tendremos la oportunidad de ver cómo es nuestra sangre cuando tiene un exceso de grasa.  Ambas visualizaciones permitirán comprender por qué es fundamental, evitar el sedentarismo y cuidar nuestros hábitos alimenticios desde una edad temprana para prevenir enfermedades cardiovasculares.\n18:00 - 19:00 h. Diseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nPúblico: adultos (mayores de 18 años).\nEn esta actividad cinco participantes visualizarán con gafas de realidad mixta la estructura dinámica de proteínas y sus ligandos, entendiendo como se produce el efecto de un medicamento. Otros cinco participantes trabajarán en un ordenador cada uno en el proyecto colaborativo https://foldingathome.org. Las personas participantes irán terminando y saliendo, y un nuevo participante entrará para sustituirlos.\nFinanciación y menciones necesarias\n En todas las actividades:\n\nEl CNIC recibe apoyo del Instituto de Salud Carlos III (ISCIII), del Ministerio de Ciencia, Innovación y Universidades (MICIU) y es un Centro de Excelencia Severo Ochoa. Estas actividades han sido posibles gracias a los programas de investigación de CNIC: Programa Nuevos mecanismos de aterosclerosis, Programa Homeostasis miocárdica y daño cardiaco, Programa de Regeneración cardiovascular, Programa Nuevos mecanismos arritmogénicos, Programa Factores de riesgo cardiovascular y salud cerebral, Programa de Promoción de la salud cardiovascular, Programa de Desarrollo tecnológico, financiados por la ayuda CEX2020-001041-S por el MICIU/AEI/10.13039/501100011033.\n\nFinanciado por la Unión Europea. Las opiniones y puntos de vista expresados solo comprometen a su(s) autor(es) y no reflejan necesariamente los de la Unión Europea o los de la European Research Executive Agency (EREA). Ni la Unión Europea ni la EREA pueden ser considerados responsables de ellos.\nNIGHTMADRID es un proyecto de divulgación científica, coordinado por la Fundación madri+d y financiado por la Unión Europea dentro del Programa Horizonte Europa, bajo las acciones Marie Skłodowska-Curie con el acuerdo de subvención nº101.162.110\n\n\nMenciones específicas de cada actividad:\nEnfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nProject PID2022-141211OB-I00, funded by MCIU/AEI/10.13039/501100011033 y por FEDER, UE:\n\nProject “AC22/00020\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union NextGenerationEU:\n\n\nGRUPO CIBERCV CB16/11/00405\n\nProject \"FI23/00229\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union.\n\n\n¿Cómo late nuestro corazón?Grupo: Silvia Priori.\nEl proyecto que ha dado lugar a los resultados mostrados en esta actividad ha recibido el apoyo de la Fundación “la Caixa”, según el acuerdo LCF/PR/HR21-00233.\n\n¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\n\nThis project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No GA-945118\n\nEsta actividad es parte de la ayuda ICT2021-006950, financiada por MICIU y por la Unión Europea NextGenerationEU/PRTR\n\nGRUPO CIBERCV CB16/11/00358\n\n¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\n\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGrant PID2023-146414OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nEsta actividad se (co)financiará con cargo a programa de actividades de I+D entre grupos de Investigación con número de referencia TEC-2024/TEC-158 y acrónimo TecNanoBio-CM, subvencionado por la Comunidad de Madrid en la convocatoria de ayudas destinadas a la realización de programas de actividades de I+D entre grupos de investigación de la Comunidad de Madrid en Tecnologías 2024.\n\nEl proyecto de investigación Caveolin-1-dependent stromal remodeling: a potential novel target for cancer immunotherapy” Modalidad de temática general (Ref. PROYE20089DELP) y el proyecto Immunomechanics: a new paradigm for understanding cancer immune infiltration and improving immunotherapy Modalidad Investigador AECC 2024 (Ref. INVES245874LOLO) financiado por la Asociación Española Contra el Cáncer (AECC).\n\nThe project leading to these results has received funding from “la Caixa” Foundation, under agreement LCF/PR/HR20/52400015\n\nGrant JDC2022-049775-I funded by MICIU/AEI/ 10.13039/501100011033 by the “European Union NextGenerationEU/PRTR”\n\nAyuda FPU21/04003 financiada por:\n\nGrant PRE2021-097318 and PREP2023-001367 funded by MICIU/AEI /10.13039/501100011033 and “ESF+”\n\nFinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2024-TL/SAL-GL-32882 de la convocatoria 2024 de ayudas para la contratación de Ayudantes de Investigación y Técnicos de Laboratorio 2024 y cofinanciadas con el Fondo Social Europeo Plus (FSE+)\n\nco-funded by the European Union’s Horizon Europe research and innovation programme (Cure and Heart Brain project) under the Marie Skłodowska-Curie grant agreement No GA-101126521\n\nTaller de extracción de ADN. Grupo: Enrique Lara\nProyecto TED2021-129774B-C22 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nAyuda PRE2021-100726 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nProyecto PLEC2022-009235 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto PID2021-124629OB-I00 financiado por MICIU/ AEI /10.13039/501100011033/ y por FEDER Una manera de hacer Europa\n\nAyuda PRE2019-087458 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nThis project has received funding from the Horizon Europe Framework Programme (HORIZON) under the call EIC Pathfinder Challenges 2022 and with Project 101115416 — DCM-NEXT\nEl contrato del técnico está cofinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2023-TL/SAL-GL-28706 de la convocatoria 2023 de ayudas para la contratación de ayudantes de investigación y técnicos de laboratorio y cofinanciado en un 40% por el Fondo Social Europeo Plus (FSE+), 2021-2027.\n\n \nGRUPO CIBERCV CB16/11/00432\n\nModelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nLa Caixa “Cardiogenomics”, Plan Nacional, CIBERCV, Leducq foundation\nGrant PID2022-136942OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nFunding from ”la Caixa” Foundation under the project code LCF/PR/HR23/52430011\n\nGrant from the Leducq Foundation for Cardiovascular Research- TNE-24VD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGRUPO CIBERCV CB16/11/00399\n\nAyuda PRE2020-092102 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nAyudas PRE2022-102314 y PREP2022-000716 financiadas por MICIU/AEI /10.13039/501100011033 y por FSE+\nAyuda JDC2023-051982-I financiada por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda FPU18/01054 financiada por el Ministerio de Ciencia, Innovación y Universidades\n\nFinanciado a través de la Ayuda a la contratación de personal investigador predoctoral del año 2023 de la CAM con Expediente PIPF-2023/SAL-GL-29818\n\nCuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nGrant PID2022-140616OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nGrants from the Leducq Foundation for Cardiovascular Research-TNE-19CVD01 and TNE-21CVD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nAyudas PRE2021-099443, PREP2022-000650 y PRE2022-104379 financiadas por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda a la contratación de personal investigador predoctoral del año 2022 de la CAM con Expediente PIPF-2022/SAL-GL-26119\n\nSupport of a fellowship from the ”la Caixa” Foundation (ID 100010434). The fellowship code is LCF/BQ/DI22/11940002”.\n\nEl escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nAssociated funded projects that require dissemination (if applies). Logos and mentions:\n\nUE0EIC2201-HORIZON-EIC-2022_DCM-NEXT\n\nERN-Guard-Heart\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\n \nGRUPO CIBERCV CB16/11/00432\n\nDa color a tu plato: convierte a tu corazón en un superhéroe con ritmo. Grupos: José Antonio Enríquez y David Sancho\n\nJosé Antonio Enríquez:\n\nCentro de Investigación Biomédica en Red de Fragilidad y Envejecimiento Saludable (CIBERFES), Instituto de Salud Carlos III.\nGRUPO CIBERFES CB16/10/00289\n\nProyecto TED2021-131611B-I00 financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under the proposal n° 101198761 MINTRAF\n \n \nProyecto PID2021-127988OB-I00 financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430010\n\n\nDavid Sancho:\n\nProyecto CPP2021-008310 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009762 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\n \nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under grant agreement No 101158245.\n\nThis work was supported by the grant PRYGN246642SANC from the Scientific Foundation of the Spanish Association Against Cancer.\n\nThis work was supported by WORLWIDE CANCER RESEARCH 25-0080.\n\nProyecto PID2022-137712OB-I00 financiado por MICIU/AEI/10.13039/501100011033 y por FEDER, UE\n\nPROGRAMAS DE ACTIVIDADES DE I+D ENTRE GRUPOS DE INVESTIGACIÓN de la Comunidad de Madrid - BIOMEDICINA 2022 coordinado por la Dra. Almudena R Ramiro”-EXPEDIENTE: S2022/BMD-7333. Proyecto titulado “Estrategias inmunomoduladoras en el remodelado vascular: nuevas perspectivas diagnósticas y terapéuticas, acrónimo: INMUNOVAR”. IP del Grupo INMUNOBIOL.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR22/52420019.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430012\n\nProject “UNderstanding Lipid ImmunoMetabolIsm To trEat Disease, acronym: UNLIMITED” (MSCA-Doctoral Network) has received funding from the European Union’s Horizon 2024 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 101227259 \n\nDiseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nAyudas TED2021-132296B-C54 y TED2021-131611B-I00, financiadas por MICIU/ AEI/10.13039/501100011033/ y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009668, financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/PRTR (Plan de Recuperación, Transformación y Resiliencia)\n\nAyuda BIOMARCADORES DE PRECISION PARA LA MEJORA DEL DIAGNOSTICO Y TRATAMIENTO DE LA ENFERMEDAD INFLAMATORIA DEL MIOCARDIO (PreMyo) con expediente PMP22/00105, financiado con fondos públicos por el Instituto de Salud Carlos III y cofinanciado por Unión Europea – NextGenerationEU\n\nAyuda Plan de Formación en Inteligencia Artificial y Big Data para la salud Cardiovascular (CardiotrAIning) con Ref. SOLI/2024/0524/00240212 financiado por los fondos europeos NextGenerationEU en el marco del Plan de Recuperación, Transformación y Resiliencia a través de la iniciativa de los programas de atracción y retención de talento \n\nGRUPO CIBERCV CB22/11/00021\n\nProyecto PID2022-141527OB-I00 financiado por MCIN/AEI/10.13039/501100011033 y por FEDER, UE;\n\nAyuda EQC2024-008195-P financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe EU4Health Programme 2021-2027 under Grant Agreement 101126953. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or European Health and Digital Executive Agency (HADEA). Neither the European Union nor the granting authority can be held responsible for them.\n\nProyecto ALGORITMOS DE INTELIGENCIA ARTIFICIAL PARA PREDECIR EL RIESGO CARDIOVASCULAR, EN-PESA financiado por el Mecanismo de Recuperación y Resiliencia de la Unión Europea-Next Generation, en el marco de la convocatoria “Solicitud de Proyectos de I+D de Excelencia en Inteligencia Artificial de la Secretaría de Estado de Digitalización e Inteligencia Artificial”",
    "source": "CNIC"
  },
  {
    "title": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "title_es": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "url": "https://www.cnio.es/noticias/nuevo-ensayo-clinico-contra-el-cancer-de-piel-mas-frecuente-con-un-compuesto-derivado-de-descubrimientos-del-cnio/",
    "published": "2025-07-15T09:39:59.000Z",
    "date": "2025-07-15",
    "content_es": "Hace unos 15 años, en 2009, el equipo de la investigadora del Centro Nacional de Investigaciones Oncológicas (CNIO) Marisol Soengas descubrió una nueva forma de matar células tumorales: hacerles creer que han sido infectadas por un virus. Desarrollaron un compuesto, denominado BO-110, con una forma de actuación muy novedosa porque inducía la autodigestión de las […]\nLa entrada Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "title_es": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "url": "https://www.cnic.es/es/node/235399",
    "published": "2025-07-14T11:31:24.000Z",
    "date": "2025-07-14",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nA new study led by the CNIC has identified imidazole propionate (ImP), a metabolite produced by gut bacteria, as a driver of atherosclerosis— as a driver of atherosclerosis, the disease behind most heart attacks and strokes\n\n\n\nCardiovascular disease remains the world’s leading cause of death, and often originates in atherosclerosis, a chronic condition in which inflammation and fat deposits cause arteries to harden and narrow. Although clinical practice already targets causal factors like high cholesterol, hypertension, and smoking, detecting atherosclerosis in its early stages continues to be a significant challenge.\nNow, researchers at the Spanish National Center for Cardiovascular Research (CNIC) have identified a gut microbiota–derived metabolite, imidazole propionate (ImP), that appears in the blood during the early stages of active atherosclerosis.\n‘This metabolite is uniquely produced by intestinal bacteria,’ explains CNIC researcher Annalaura Mastrangelo, one of the study’s two first authors. ‘Our study shows that its presence in the bloodstream is associated with the development of active atherosclerosis in people who otherwise appear healthy.’\nThe discovery offers a promising alternative to current diagnostic tools, which typically involve costly and complex imaging techniques. ‘Detecting this blood marker offers a major advantage because current diagnostic tools rely on advanced imaging techniques that are complex, expensive, and not covered by public health systems. Blood levels of ImP provide a diagnostic marker that could help identify apparently healthy individuals with active atherosclerosis, and thus enable earlier treatment.’ says Mastrangelo.\nBut the discovery goes even further. Co–first author Iñaki Robles-Vera explains: ‘We not only observed elevated ImP levels in people with atherosclerosis, but also showed that ImP itself is a causal agent of the disease. In animal models of atherosclerosis, ImP administration led to the formation of arterial plaques. It does this by activating the imidazoline receptor type 1 (I1R), which increases systemic inflammation and promotes atherosclerosis development.’\nDavid Sancho, head of the CNIC Immunobiology Laboratory, lead author on the study and ERC grantee notes that ‘this discovery is important because it opens the way to a completely new line of treatment.’\nThe study shows that blocking the I1R receptor in animal models prevented plaque formation and slowed disease progression, even when the animals were fed a high-cholesterol diet. ‘This suggests that future treatment could combine I1R blockade with cholesterol-lowering drugs to produce a synergistic effect that prevents atherosclerosis development,’ explains Sancho.\n‘These findings open new possibilities for the early detection and personalised treatment of atherosclerosis,’ he continues. ‘Instead of focusing solely on cholesterol and other classic risk factors, we may soon be able to analyse blood for ImP as an early warning signal. At the CNIC, we are also working to develop drugs that block the detrimental effects of ImP.’\n\nThe CNIC-led study was conducted through extensive collaboration with researchers at multiple national and international centres: Mount Sinai Fuster Heart Hospital and the Icahn School of Medicine at Mount Sinai (New York, USA); the Fundación Jiménez Díaz Health Research Institute; the Universidad Autónoma de Madrid; the Spanish cardiovascular research network (CIBER-CV); the University of Gothenburg (Sweden); the University of Athens (Greece); Inmunotek S.L.; the University of Michigan (USA); Hospital de La Princesa; the Center for Metabolomics and Bioanalysis (CEMBIO) from Universidad CEU San Pablo; the University of Heidelberg (Germany); and the Sols-Morreale Biomedical Research Institute (IIBM-CSIC). \nThe study was supported by funding from the European Research Council (Consolidator and Proof of concept grants), Spanish Ministry of Science, Innovation, and Universities; the Spanish State Research Agency; the European Union’s NextGeneration funding mechanism; and the “la Caixa” Foundation.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D., Sancho, D., et al. (2025). Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature. https://doi.org/10.1038/s41586-025-09263-w",
    "source": "CNIC"
  },
  {
    "title": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "title_es": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "url": "https://www.cnic.es/es/noticias/nature-descubren-un-metabolito-microbiota-intestinal-que-favorece-aterosclerosis-podria",
    "published": "2025-07-14T11:08:07.000Z",
    "date": "2025-07-14",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nUn estudio liderado por el CNIC desvela que el propionato de imidazol, un metabolito producido por la microbiota intestinal, induce aterosclerosis, una enfermedad que puede desencadenar la obstrucción de las arterias que causa los infartos o accidentes cerebrovasculares\n\n\n\nLas enfermedades cardiovasculares son la principal causa de muerte global y suelen originarse en la aterosclerosis, un endurecimiento y estrechamiento de las arterias por inflamación y acumulación de grasa en la pared arterial. Aunque se controlan factores causales como colesterol, hipertensión o tabaquismo, la detección temprana de la enfermedad es necesaria. Los nuevos resultados liderados por el Centro Nacional de Investigaciones Cardiovasculares (CNIC) y publicados en la revista Nature han identificado que un metabolito generado por bacterias intestinales, el propionato de imidazol (ImP), se detecta en sangre de modo temprano en la aterosclerosis activa. El estudio ha contado con el apoyo de la Fundación “la Caixa” en su Convocatoria CaixaResearch de Investigación en Salud con 967.620,20 €.\nEste metabolito, “está producido exclusivamente por bacterias del intestino”, explica Annalaura Mastrangelo, investigadora del CNIC y primera autora del estudio. “En este trabajo hemos visto que su presencia en sangre se relaciona con el desarrollo de aterosclerosis activa en personas aparentemente sanas”.\nLo relevante de este hallazgo, destaca Mastrangelo, es que “detectar este marcador en sangre representa una gran ventaja dado que las pruebas actuales requieren técnicas de imagen avanzada complejas y costosas que no están cubiertas por la seguridad social. Los niveles de ImP en sangre ofrecen un marcador con valor diagnóstico para facilitar la identificación de personas sanas que tienen aterosclerosis activa y posibilitar su tratamiento temprano”.\n\nPero el hallazgo va más allá. Iñaki Robles-Vera, también primer autor del estudio, añade: “No solo observamos que el ImP está elevado en personas con aterosclerosis, sino que es un agente causal de la enfermedad. El consumo de ImP provocó la aparición de placas en las arterias en modelos animales de aterosclerosis. El ImP activa el receptor imidazolínico de tipo 1 (I1R) generando un aumento de la inflamación sistémica que contribuye al desarrollo de la aterosclerosis”.\nPara David Sancho, jefe del laboratorio de Inmunobiología y líder del estudio, “este descubrimiento es importante porque abre una nueva vía de tratamiento”.\nEn la investigación que se publica en ‘Nature’, añade, se ha visto que, el uso de bloqueantes del receptor I1R previene la inducción de aterosclerosis por ImP y reduce la progresión de aterosclerosis en modelos de ratón donde se induce la enfermedad con dieta alta en colesterol. “Esto abre la posibilidad futura de un tratamiento combinado del bloqueo de I1R junto al bloqueo de la producción de colesterol para lograr un efecto que esperamos que sea sinérgico y que prevenga el desarrollo de aterosclerosis”, asegura David Sancho.\nEstos hallazgos, agrega, “abren nuevas posibilidades para el diagnóstico precoz y el tratamiento personalizado y temprano de la aterosclerosis. Así, en lugar de centrarse únicamente en el colesterol y otros factores clásicos, se podría en el futuro analizar la presencia de ImP en sangre como señal de riesgo. En el CNIC estamos trabajando para desarrollar fármacos que bloqueen los efectos perjudiciales de ImP”.\n\nEste trabajo ha sido liderado por el CNIC pero representa una colaboración global a nivel nacional e internacional, con la participación de instituciones como Mount Sinai Fuster Heart Hospital, Icahn School of Medicine at Mount Sinai en Nueva York (EEUU); Instituto de investigación Sanitaria Fundación Jiménez Díaz; Universidad Autónoma de Madrid; Centro de Investigación biomédica en red de enfermedades cardiovasculares (CIBER-CV); Universidad de Gotemburgo (Suecia); Universidad de Atenas (Grecia);  Inmunotek S.L; Universidad de  Michigan (EEUU);  Hospital de La Princesa; Centro de Metabolómica y Bioanálisis (CEMBIO), de la Universidad CEU San Pablo; Universidad de Heidelberg (Alemania), y el  Instituto de Investigaciones Biomédicas Sols-Morreale IIBM-CSIC.\nEste proyecto ha recibido financiación del European Research Council (ayudas Consolidator y Proof of Concept: 2016-Consolidator Grant 725091; ERC-2023-PoC); Ministerio de Ciencia, Innovación y Universidades; Agencia Estatal de Investigación; Unión Europea a través de NextGeneration, y la Fundación “la Caixa”.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D. Sancho, D., et al. Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature (2025). https://doi.org/10.1038/s41586-025-09263-w",
    "source": "CNIC"
  },
  {
    "title": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "title_es": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "url": "https://www.cnic.es/es/noticias/ocho-mejores-estudiantes-bachillerato-espana-participan-programa-acercate",
    "published": "2025-07-11T12:07:09.000Z",
    "date": "2025-07-11",
    "content_es": "11/07/2025\n\n\nSobre el CNIC\nFormación\n\n\n\n\n\n\n\n\nEl objetivo del Programa Acércate es atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular\n\n\n\nUn año más, ocho de los mejores estudiantes de bachillerato de España han participado el programa ACÉRCATE, que organiza el Centro Nacional de Investigaciones Cardiovasculares (CNIC) dentro de su Plan de Formación CNIC-Joven. El objetivo de este plan, una apuesta personal del director general del centro, el Dr. Valentín Fuster, es “atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular”.\nLa convocatoria, abierta a bachilleres de todo el territorio nacional, se ha resuelto este año a favor de 6 alumnas y 2 alumnos de los más de 50 que reunían los requisitos y solicitaron participar en el programa. Este año las personas que participan en el programa proceden de Asturias, Extremadura, Galicia, Comunidad de Madrid, Castilla y León, Comunidad Valenciana y Andalucía.\nIncluyendo a los de esta convocatoria, en total ya han participado en el programa 136 estudiantes. Los jóvenes estudiantes, además de participar en el día a día de un centro de excelencia en investigación como el CNIC, han compartido sus experiencias y sus dudas con los investigadores del centro, pero también con el Dr. Fuster, director del CNIC. El Dr. Fuster considera que empezar el programa de formación en etapas educativas tan tempranas es clave para atraer a los investigadores del futuro porque los jóvenes son el “futuro de la investigación en nuestro país”.\nLas personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024\nEn esta ocasión, las personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024 (Concurso de la Unión Europea para Jóvenes Científicos), un certamen internacional que reconoce los mejores proyectos científicos de jóvenes de entre 14 y 20 años. Kvasnovska, fue seleccionada por su proyecto individual de biomedicina titulado «Biomarcadores potenciales de la inflamación crónica relacionada con la edad».\nLos participantes del programa Acércate al CNIC comparten una gran ilusión por vivir una experiencia enriquecedora que les permita acercarse al mundo real de la investigación biomédica. Así, Alba García Peña quiere profundizar en biomedicina para orientar su futuro profesional. María García Manchado, apasionada por la cardiología, desea conocer de cerca el trabajo investigador, mientras que Lucas Gómez Sánchez espera familiarizarse con el laboratorio y la tecnología aplicada a la medicina.\nLuka Pesich, por su parte, busca reforzar sus conocimientos y habilidades prácticas en biomedicina y Sofía Requena Skalska está interesada en el funcionamiento interno de los grupos de investigación y la conexión entre ciencia y práctica clínica.\nDescubrir el día a día en un laboratorio y confirmar su vocación científica es lo que espera Laura Sánchez Rodríguez, mientras que Carmen Vico Guerra valora la oportunidad de crecer personal y académicamente en un entorno de excelencia.\nPor último, Sara Baldo Muñiz espera comprender de forma directa la labor investigadora y aprender tanto de profesionales como de otros estudiantes con intereses afines.\nTecnología más puntera\nEste programa es el que se dirige a la captación de talento más joven de todos los de formación que hay en el CNIC. El apoyo sostenido de la Fundación Pro CNIC es indispensable para que, año tras año, pueda seguir celebrándose y captando el talento desde la etapa más precoz. “Estamos muy satisfechos de este concepto que comenzamos hace ya más de 20 años”, añade el Dr. Fuster. Y, concluye, “así, si tienen ese ‘gusanillo’ de la investigación, los animamos a seguir adelante”.\nAccede aquí al álbum de fotos de esta convocatoria\nSara Baldó Muñiz \n\nSara cursó sus estudios en el IES Velázquez de Madrid y ha decidido estudiar Bioquímica en la Universidad Autónoma de Madrid. Desde pequeña, ha sentido una fuerte atracción por la investigación científica, impulsada por su curiosidad innata y su deseo de comprender cómo funciona el mundo. \nAlba García Peña \n\nAlba cursó Bachillerato en el IES Álvaro Cunqueiro de Vigo y comenzará el próximo curso la carrera de Biotecnología en la Universidad de Santiago de Compostela. Eligió esta opción porque integra varias disciplinas científicas —Matemáticas, Física, Química y Biología— y le permitirá especializarse más adelante en áreas vinculadas a la investigación biosanitaria. \nMaría García Manchado \n\nMaría estudió en el IES San José de Villanueva de la Serena, Badajoz. Ha optado por estudiar Medicina en la Universidad de Extremadura. Desde niña ha sentido una gran pasión por el conocimiento, que la llevó a interesarse especialmente por Biología y Matemáticas.\nLucas Gómez Sánchez \n\nLucas estudió en el IES Ramiro de Maeztu de Madrid y ahora estudiará Ingeniería Biomédica en la Universidad Carlos III de Madrid. Su curiosidad científica comenzó a los 8 años, participando en actividades como la Noche de los Investigadores y la Semana de la Ciencia. \nLuka Pesich \n\nLuka curso Bachillerato en el Colegio Patrocinio San José de Estepona, Málaga. Ahora iniciará sus estudios en Ciencias Biológicas y Químicas en la Universidad de Limerick (Irlanda), con la intención de especializarse en genética. Su interés por la ciencia fue creciendo de forma natural, motivado por su amor por la naturaleza. \nSofía Requena Skalska \n\nSofía estudió en el CEU San Pablo Valencia de Puerto de Sagunto, Valencia. Sofía cursó parte de su formación secundaria en Quebec, donde tuvo su primer contacto directo con la investigación científica mediante prácticas de laboratorio. Posteriormente, el Bachillerato Internacional fortaleció su interés en la biología y el cuerpo humano. \nLaura Sánchez Rodríguez \n\nLaura estudió en el Colegio Salesiano Santo Ángel de Avilés, Asturias. Empezará el próximo curso la carrera de Biotecnología en la Universidad de Oviedo. Su interés por la ciencia surgió a través de proyectos escolares y viajes STEAM organizados por su centro educativo.\nCarmen Vico Guerra \n\nCarmen cursó Bachillerato en el IES Zorrilla de Valladolid. El próximo cursó comenzará a estudiar Biomedicina y Terapias Avanzadas en la Universidad de Valladolid. Su pasión por la ciencia comenzó en la infancia, cuando pasaba horas hojeando atlas de anatomía y viendo programas divulgativos.",
    "source": "CNIC"
  },
  {
    "title": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "title_es": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "url": "https://www.cnio.es/noticias/un-estudio-pionero-desvela-nuevos-mecanismos-geneticos-implicados-en-tumores-raros-de-cabeza-y-cuello/",
    "published": "2025-07-10T13:50:44.000Z",
    "date": "2025-07-10",
    "content_es": "Los paragangliomas y feocromocitomas son tumores neuroendocrinos muy raros (entre 3 y 8 casos por millón de habitantes) que aparecen en cabeza, cuello y torso, o en las glándulas suprarrenales, y que pueden diseminarse a otros órganos. Cerca de la mitad están causados por alteraciones genéticas heredadas, mutaciones que interesa mucho descubrir: conocerlas permite encontrar familiares portadores de […]\nLa entrada Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "title_es": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "url": "https://www.cnic.es/es/noticias/dr-miguel-torres-premio-nacional-genetica-2025-por-su-contribucion-al-desarrollo-terapias",
    "published": "2025-07-09T09:22:45.000Z",
    "date": "2025-07-09",
    "content_es": "09/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nLa Sociedad Española de Genética (SEG) reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa.\n\n\n\nEl investigador Miguel Torres Sánchez, coordinador del Programa de Regeneración Cardiovascular e investigador principal del grupo “Control Genético del Desarrollo y Regeneración de Órganos” en el Centro Nacional de Investigaciones Cardiovasculares (CNIC), ha sido galardonado con el Premio Nacional de Genética 2025 en la modalidad aplicada, otorgado por la Sociedad Española de Genética (SEG).\nEl jurado reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa, destacando especialmente su trabajo sobre cómo la actividad de los genes regula los procesos de regionalización durante el desarrollo embrionario.\nSus investigaciones han permitido desentrañar mecanismos genéticos implicados en el control de la calidad y la regeneración de órganos, sentando así las bases científicas para el desarrollo de terapias regenerativas dirigidas al corazón y al sistema vascular.\nEl fallo también resalta la proyección internacional del Dr. Torres y el alto impacto de sus publicaciones científicas, que lo sitúan como una figura de referencia en el campo de la biomedicina regenerativa.\nEl Dr. Torres lidera desde el CNIC una de las líneas de investigación más innovadoras en medicina regenerativa, con el objetivo de desarrollar nuevas estrategias terapéuticas que permitan reparar los tejidos dañados tras un infarto u otras patologías cardiovasculares, una de las principales causas de muerte en el mundo.\nProyecto REACTIVA\nEntre otros proyectos, el Dr. Torres dirige el proyecto REACTIVA, seleccionado para recibir una prestigiosa ERC Advanced Grant, financiación que respalda una línea de investigación innovadora centrada en la regeneración del tejido cardíaco, con el objetivo de abrir nuevas vías hacia terapias regenerativas del corazón.\nEl Premio Nacional de Genética, financiado por la Fundación Pryconsa, representa uno de los más altos reconocimientos a la excelencia investigadora en genética en nuestro país. Con él, la Sociedad Española de Genética desea rendir homenaje a la destacada trayectoria científica del Dr. Torres, su compromiso con el avance del conocimiento y el impacto significativo que su trabajo ha tenido en la comunidad científica.\nEste galardón, señala Teresa Roldán Arjona, Presidenta de la Sociedad Española de Genética, “enaltece no solo los logros personales del Dr. Torres, sino también a la institución a la que representa y al conjunto de la comunidad genética”.\nLos Premios Nacionales de Genética, impulsados por la SEG, distinguen cada año trayectorias científicas sobresalientes tanto en investigación básica como aplicada. Junto a Miguel Torres, el jurado ha premiado en la modalidad básica a Amparo Latorre Castillo, catedrática de Genética en la Universidad de València, por su pionera labor en el estudio de la variabilidad del ADN mitocondrial y los procesos evolutivos de simbiosis.",
    "source": "CNIC"
  },
  {
    "title": "Premio a la unidad de cáncer pediátrico del CNIO",
    "title_es": "Premio a la unidad de cáncer pediátrico del CNIO",
    "url": "https://www.cnio.es/noticias/premio-a-la-unidad-de-cancer-pediatrico-del-cnio/",
    "published": "2025-07-07T10:27:25.000Z",
    "date": "2025-07-07",
    "content_es": "Las terapias CAR-T son un tipo de inmunoterapia personalizada en que las células defensivas del paciente son modificadas en el laboratorio para reforzar su capacidad de reconocer y destruir las células tumorales. Su uso, cada vez más frecuente en adultos, es aún reducido en pediatría. La Sociedad Europea de Oncología Pediátrica ha alertado ya de […]\nLa entrada Premio a la unidad de cáncer pediátrico del CNIO se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "title_es": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "url": "https://www.cnio.es/noticias/gracias-a-nuestros-amigos-y-amigas-por-ayudarnos-a-acabar-con-el-cancer/",
    "published": "2025-07-07T07:59:05.000Z",
    "date": "2025-07-07",
    "content_es": "“La clave para frenar el cáncer podría estar en la comunicación entre proteínas. Pero sinceramente, creo que la verdadera clave está en nuestra comunicación, en cómo compartimos, cuestionamos y colaboramos; si seguimos manteniendo este diálogo abierto, creo que llegará el día en que realmente entendamos el cáncer… y lo detengamos”, dijo en la Jornada de […]\nLa entrada Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "title_es": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "url": "https://www.cnio.es/noticias/el-cnio-celebra-la-solidaridad-de-sus-amigos-as-clave-para-atraer-talento-y-avanzar-en-la-investigacion-del-cancer/",
    "published": "2025-07-04T11:09:50.000Z",
    "date": "2025-07-04",
    "content_es": "Una parte importante del conocimiento que genera el Centro Nacional de Investigaciones Oncológicas (CNIO), y que se orienta a mejorar la prevención, el diagnóstico y el tratamiento del cáncer, es fruto de la generosidad. La generosidad de las personas, empresas y fundaciones que realizan donaciones al centro a través del programa ‘Amigos/as del CNIO’.  Desde que se estableció, en 2015, todos los fondos […]\nLa entrada El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "title_es": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "url": "https://www.cnic.es/es/node/235158",
    "published": "2025-07-02T09:04:18.000Z",
    "date": "2025-07-02",
    "content_es": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nCNIC researchers have uncovered the evolutionary logic of the OxPhos system—the cell’s “engine”—and developed a tool to detect mutations that cause mitochondrial disease\n\n\n\nMitochondria are the body’s “energy factories,” and their proper function is essential for life. Inside mitochondria, a set of complexes called the oxidative phosphorylation (OxPhos) system acts like a biochemical assembly line, transforming oxygen and nutrients into usable energy.\nNow, the study, led by the GENOXPHOS group at the Spanish National Centre for Cardiovascular Research (CNIC) and the Biomedical Research Networking Centre in the area of Frailty and Healthy Ageing (CIBERFES), and directed by Dr. José Antonio Enríquez, has revealed how this system evolved over millions of years—from the first vertebrates to modern humans. “Understanding this evolution helps explain why some genetic mutations cause rare but serious diseases that affect the OxPhos system,” say José Luis Cabrera lead author of the article, whose research is supported by the ‘la Caixa’ Foundation.\nPublished in Cell Genomics, the study describes the molecular evolutionary strategies of the OxPhos system, the main site of metabolic and energy integration in the cell. It also shows how this information can be used to identify mutations that cause disease.\nWorking in collaboration with Fátima Sánchez-Cabo, head of the CNIC Computational Systems Biomedicine group, the researchers analyzed the interaction between the two types of DNA that encode OxPhos proteins: nuclear DNA (inherited from both parents) and mitochondrial DNA (inherited only from the mother).\nThe OxPhos system, explains José Antonio Enríquez—head of the CNIC Functional Genetics of the Oxidative Phosphorylation System (GENOXPHOS) group—comprises five large protein complexes: four that transport electrons and one, called ATP synthase, that produces ATP, the cell’s molecular “fuel.”\n“These complexes can work individually or in combination, depending on the cell’s energy needs. Together, they are made up of 103 proteins encoded by two different genomes: nuclear and mitochondrial,” Enríquez explains. “While nuclear DNA changes slowly over time and gains variation through genetic mixing during reproduction, mitochondrial DNA evolves much more rapidly but is passed only through the maternal line.”\nDr. Cabrera adds that the proteins encoded by mitochondrial DNA form the core of the respiratory complexes, “so proper function depends on precise compatibility between the nuclear and mitochondrial components.”\nThe study also introduces an innovative new tool: ConScore, a predictive index that assesses the clinical relevance of mutations in the 103 OxPhos proteins. “ConScore is based on the evolutionary divergence of these proteins across vertebrates—including primates and other mammals—and complements human population genetic data,” says Enríquez.\nThe authors affirm that ConScore provides a new framework for interpreting potentially pathogenic mutations, opening the door to improved diagnosis and treatment of mitochondrial diseases.\nUltimately, the researchers conclude, this study not only advances our understanding of how human cells evolved, but also brings us closer to new solutions for patients with rare genetic disease.\nThe study has received funding from the European Union's NextGenerationEU/Recovery, Transformation and Resilience Plan/PRTR, CIBERFES; Fundación ‘la Caixa’,Human Frontier Science Fundation; Severo Ochoa grant awarded by MICIU/AEI and the European Social Fund (ESF invests in your future).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "source": "CNIC"
  },
  {
    "title": "Cell Genomics: Revelan cómo ha evolucionado el sistema energético de las células y cómo puede ayudar a entender las enfermedades genéticas ",
    "title_es": "Cell Genomics: Revelan cómo ha evolucionado el sistema energético de las células y cómo puede ayudar a entender las enfermedades genéticas ",
    "url": "https://www.cnic.es/es/noticias/cell-genomics-revelan-como-ha-evolucionado-sistema-energetico-celulas-como-puede-ayudar",
    "published": "2025-07-02T08:56:37.000Z",
    "date": "2025-07-02",
    "content_es": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nInvestigadores del CNIC descubren las claves evolutivas del sistema OxPhos, el \"motor\" de la célula, y desarrollan una herramienta para detectar mutaciones que causan enfermedades mitocondriales.\n\n\n\nLas mitocondrias son las “fábricas de energía” de nuestro organismo y su funcionamiento correcto es vital para producir la energía que necesitamos. En su interior funciona el sistema de fosforilación oxidativa, OxPhos, un conjunto de proteínas que trabaja como una cadena para transformar el oxígeno y los nutrientes en energía.\nAhora, el estudio, liderado por el grupo GENOXPHOS del Centro Nacional de Investigaciones Cardiovasculares (CNIC) y del Centro de Investigación Biomédica en Red Fragilidad y Envejecimiento Saludable (CIBERFES), y dirigido por el Dr. José Antonio Enríquez, desvela cómo ha evolucionado este sistema a lo largo de millones de años, desde los primeros vertebrados hasta los seres humanos. “Comprender esta evolución ayuda a explicar por qué algunas mutaciones genéticas provocan enfermedades raras y graves que afectan a este sistema”, señala el Dr. José Luis Cabrera, autor principal del artículo cuya investigación cuenta con el apoyo de la Fundación ‘la Caixa’.\nEl estudio, publicado en la revista Cell Genomics, desvela las estrategias evolutivas a nivel molecular que ha seguido el principal centro de integración metabólico y energético de la célula, el sistema OxPhos, y describe como esta información puede ser utilizada para identificar en personas mutaciones causantes de enfermedades.\nLos investigadores, en colaboración con el grupo de Fátima Sánchez-Cabo, jefa del grupo de Biomedicina de Sistemas Computacional del CNIC,  han analizado cómo interactúan los dos tipos de ADN que codifican las proteínas del sistema OxPhos: el ADN nuclear (heredado del padre y la madre) y el ADN mitocondrial (que solo se hereda de la madre).\nEl sistema OxPhos, explica el Dr. Enríquez, jefe del grupo Genética Funcional del Sistema de Fosforilación Oxidativa (GENOXPHOS) del CNIC, está formado por cinco grandes bloques de proteínas: cuatro que transportan electrones y otro, llamado ATP-sintetasa, que produce energía en forma de ATP, el \"combustible\" celular.\n“Estos bloques pueden funcionar por separado o formar grupos según lo que necesite la célula. En total, están formados por unas 103 proteínas, codificadas por dos tipos de ADN: el nuclear y el mitocondrial. Y, mientras que el ADN nuclear cambia poco con el tiempo y gana variedad gracias a la mezcla genética durante la reproducción, el ADN mitocondrial se modifica mucho más rápido, aunque solo se transmite de madres a hijos”, aclara el Dr. Enríquez.\nAñade el Dr. Cabrera que las proteínas codificadas por el ADN mitocondrial constituyen el corazón de los complejos respiratorios, “cuyo correcto funcionamiento depende de que los componentes nucleares y los mitocondriales encajen adecuadamente”.\nAdemás, el estudio presenta una herramienta innovadora: ConScore, un índice de predicción funcional que permite evaluar la relevancia clínica de las mutaciones en las 103 proteínas que componen el sistema OxPhos. “Este índice se basa en la divergencia evolutiva de estas proteínas entre vertebrados —incluidos mamíferos y primates—, y complementa los estudios de variabilidad genética en poblaciones humanas”, señala el Dr. Enríquez.\nConScore ofrece un nuevo marco para interpretar mutaciones potencialmente patológicas, abriendo la puerta al desarrollo de mejores estrategias diagnósticas y terapéuticas frente a enfermedades mitocondriales, aseguran los investigadores.\nEsta investigación, concluyen sus autores, no solo ayuda a entender cómo hemos evolucionado a nivel celular, sino que también acerca nuevas soluciones para mejorar la salud de las personas que sufren enfermedades genéticas raras.\nEl estudio ha recibido financiación de la Unión Europea «NextGenerationEU»/Plan de Recuperación, Transformación y Resiliencia/PRTR, CIBERFES; Fundación ‘la Caixa’, Human Frontier Science Fundation; beca Severo Ochoa concedida por MICIU/AEI y por los Fondos Sociales Europeos (FSE invierte en tu futuro).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "source": "CNIC"
  },
  {
    "title": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "title_es": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "url": "https://www.cnio.es/noticias/los-danos-en-el-adn-derivados-de-la-contaminacion-atmosferica-podrian-contribuir-al-cancer-de-pulmon-en-personas-no-fumadoras-halla-un-estudio/",
    "published": "2025-07-02T15:17:44.000Z",
    "date": "2025-07-02",
    "content_es": "Una cuarta parte de los casos de cáncer de pulmón se dan en personas que no han fumado nunca. ¿Cuál es la causa de estos cánceres? Un estudio que analiza las alteraciones genéticas (mutaciones) en tumores de 871 personas no fumadoras de cuatro continentes apunta a la contaminación atmosférica como una de las posibles causas. […]\nLa entrada Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "title_es": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "url": "https://www.cnio.es/noticias/roger-castells-graells-recibe-el-premio-hawk-biosystems-de-la-sociedad-espanola-de-biofisica/",
    "published": "2025-06-27T13:52:15.000Z",
    "date": "2025-06-27",
    "content_es": "El investigador Roger Castells-Graells, del Centro Nacional de Investigaciones Oncológicas (CNIO), ha recibido el premio “Hawk Biosystems”, que otorga la Sociedad de Biofísica de España (SBE) en el marco de su XVIII Congreso Internacional. Castells-Graells se incorporó recientemente al CNIO para dirigir el nuevo Grupo de Diseño Biomolecular y Nanomedicina Estructural, dedicado a crear nanopartículas […]\nLa entrada Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "title_es": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "url": "https://www.cnio.es/noticias/mariano-barbacid-premio-valor-anadido-a-la-ciencia-e-investigacion/",
    "published": "2025-06-26T13:42:59.000Z",
    "date": "2025-06-26",
    "content_es": "Mariano Barbacid, descubridor del primer oncogén humano, ha recibido el Premio Valor Añadido a la Ciencia e Investigación, que reconoce la “labor de cultivo y perfeccionamiento de la investigación, descubrimiento e invención”. Los Premios Valor Añadido son una iniciativa de la Fundación Transforma España, en colaboración con BBVA, para «impulsar el reconocimiento de la aportación […]\nLa entrada Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación se publicó primero en CNIO.",
    "source": "CNIO"
  },
  {
    "title": "Visita de la Universidad de Shanghai al CNIC para explorar futuras colaboraciones ",
    "title_es": "Visita de la Universidad de Shanghai al CNIC para explorar futuras colaboraciones ",
    "url": "https://www.cnic.es/es/noticias/visita-universidad-shanghai-al-cnic-para-explorar-futuras-colaboraciones",
    "published": "2025-06-20T07:13:34.000Z",
    "date": "2025-06-20",
    "content_es": "20/06/2025\n\n\nSobre el CNIC\nInvestigación\n\n\n\n\n\n\n\n\nUna delegación de la Universidad de Shanghai (China) ha visitado el CNIC con el objetivo de explorar posibles vías de colaboración en investigación biomédica.\nLa comitiva estuvo encabezada por Gou Yannan, vicepresidente de la Universidad de Shanghai, y contó con la participación de Liu Jinsong, director del Departamento de Activos; Xiao Junjie, decano de la Escuela de Ciencias de la Vida; Wang Haisong, arquitecto jefe de desarrollo del campus y vicedecano de la Academia de Bellas Artes de Shanghai, y Huang Pei, directora adjunta de la Oficina de Asuntos Internacionales.\nDurante la reunión, se discutieron posibles estrategias para establecer proyectos conjuntos de investigación y cooperación institucional entre ambas entidades.\nPor parte del CNIC, participaron Vicente Andrés, director de Investigación Básica; Beatriz Ferreiro, Directora Gestión Científica, y Enrique Lara Pezzi, líder del grupo de Regulación Molecular de la Insuficiencia Cardiaca.\nTras el encuentro, los representantes de la universidad china realizaron una visita a las instalaciones.\nEsta visita marca un primer paso en el establecimiento de lazos científicos entre el CNIC y la Universidad de Shanghai, con el propósito de impulsar el intercambio de conocimiento y el desarrollo de proyectos innovadores en el ámbito de la biomedicina.",
    "source": "CNIC"
  }
]